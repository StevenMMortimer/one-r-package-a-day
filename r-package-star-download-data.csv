name,description,published,author,url,github_ind,github_url,downloads,stars,last_commit,downloads_per_star
abbyyR,"Get text from images of text using Abbyy Cloud Optical Character
    Recognition (OCR) API. Easily OCR images, barcodes, forms, documents with
    machine readable zones, e.g. passports. Get the results in a variety of formats
    including plain text and XML. To learn more about the Abbyy OCR API, see 
    <http://ocrsdk.com/>.",2019-06-25,Gaurav Sood,http://github.com/soodoku/abbyyR,TRUE,https://github.com/soodoku/abbyyr,38425,38,2019-06-30T01:53:13Z,1011.1842105263158
ABCoptim,"An implementation of Karaboga (2005) Artificial Bee Colony
    Optimization algorithm <http://mf.erciyes.edu.tr/abc/pub/tr06_2005.pdf>.
    This (working) version is a Work-in-progress, which is
    why it has been implemented using pure R code. This was developed upon the basic
    version programmed in C and distributed at the algorithm's official website.",2017-11-06,George Vega Yon,"http://github.com/gvegayon/ABCoptim, http://mf.erciyes.edu.tr/abc/",TRUE,https://github.com/gvegayon/abcoptim,32889,22,2020-05-31T18:09:24Z,1494.9545454545455
abdiv,"A collection of measures for measuring ecological diversity.
  Ecological diversity comes in two flavors: alpha diversity measures the
  diversity within a single site or sample, and beta diversity measures the
  diversity across two sites or samples. This package overlaps considerably
  with other R packages such as 'vegan', 'gUniFrac', 'betapart', and 'fossil'.
  We also include a wide range of functions that are implemented in software
  outside the R ecosystem, such as 'scipy', 'Mothur', and 'scikit-bio'.  The
  implementations here are designed to be basic and clear to the reader.",2020-01-20,Kyle Bittinger,https://github.com/kylebittinger/abdiv,TRUE,https://github.com/kylebittinger/abdiv,2831,0,2020-01-26T20:25:01Z,NA
abjutils,"The Brazilian Jurimetrics Association (ABJ in
    Portuguese, see <http://www.abjur.org.br/en/> for more information) is
    a non-profit organization which aims to investigate and promote the
    use of statistics and probability in the study of Law and its
    institutions.  This package implements general purpose tools used by
    ABJ, such as functions for sampling and basic manipulation of
    Brazilian lawsuits identification number. It also implements functions
    for text cleaning, such as accentuation removal.",2019-02-07,Caio Lente,https://github.com/abjur/abjutils,TRUE,https://github.com/abjur/abjutils,40051,19,2019-09-28T20:34:27Z,2107.9473684210525
ace2fastq,"The ACE file format is used in genomics to store contigs from sequencing machines.
  This tools converts it into FASTQ format. Both formats contain the 
  sequence characters and their
  corresponding quality information. Unlike the FASTQ file, the ace file stores the
  quality values numerically.
  The conversion algorithm uses the standard Sanger formula. The package facilitates insertion
  into pipelines, and content inspection.",2019-06-20,Reinhard Simon,https://github.com/c5sire/ace2fastq,TRUE,https://github.com/c5sire/ace2fastq,5850,0,2020-02-24T10:48:08Z,NA
ActFrag,"Recent studies haven shown that, on top of total daily active/sedentary volumes, the time 
  accumulation strategies provide more sensitive information. This package provides functions to extract 
  commonly used fragmentation metrics to quantify such time accumulation strategies based on minute level 
  actigraphy-measured activity counts data. ",2020-02-11,Junrui Di,https://github.com/junruidi/ActFrag,TRUE,https://github.com/junruidi/actfrag,5735,0,2020-02-28T02:22:27Z,NA
activityCounts,"ActiLife software generates activity counts from data collected by Actigraph accelerometers <https://s3.amazonaws.com/actigraphcorp.com/wp-content/uploads/2017/11/26205758/ActiGraph-White-Paper_What-is-a-Count_.pdf>.
  Actigraph is one of the most common research-grade accelerometers. There is considerable research
  validating and developing algorithms for human activity using ActiLife counts. Unfortunately,
  ActiLife counts are proprietary and difficult to implement if researchers use different accelerometer brands.
  The code  creates ActiLife counts from raw acceleration data for different accelerometer brands and it is developed
  based on the study done by Brond and others (2017) <doi:10.1249/MSS.0000000000001344>.",2019-07-31,SeyedJavad KhataeiPour,"https://github.com/walkabillylab/activityCounts,
https://github.com/jbrond/ActigraphCounts",TRUE,https://github.com/walkabillylab/activitycounts,5069,2,2019-11-20T17:12:22Z,2534.5
adapr,"Tracks reading and writing within R scripts that are organized into
    a directed acyclic graph. Contains an interactive shiny application adaprApp().
    Uses git2r package, Git and file hashes to track version histories of input
    and output. See package vignette for how to get started. V1.02 adds parallel
    execution of project scripts and function map in vignette. Makes project
    specification argument last in order. V2.0 adds project specific libraries, packrat option, and adaprSheet().",2017-11-30,Jon Gelfond,NA,TRUE,https://github.com/gelfondjal/adapr,19374,13,2020-01-28T22:56:18Z,1490.3076923076924
AdaptGauss,"Multimodal distributions can be modelled as a mixture of components. The model is derived using the Pareto Density Estimation (PDE) for an estimation of the pdf. PDE has been designed in particular to identify groups/classes in a dataset. Precise limits for the classes can be calculated using the theorem of Bayes. Verification of the model is possible by QQ plot, Chi-squared test and Kolmogorov-Smirnov test. The package is based on the publication of Ultsch, A., Thrun, M.C., Hansen-Goos, O., Lotsch, J. (2015)  <DOI:10.3390/ijms161025897>.",2020-02-03,Michael Thrun,https://www.uni-marburg.de/fb12/datenbionik/software-en,TRUE,https://github.com/mthrun/adaptgauss,29418,0,2020-02-03T17:16:37Z,NA
adaptMT,"Implementation of adaptive p-value thresholding (AdaPT), including both a framework that allows the user to specify any 
  algorithm to learn local false discovery rate and a pool of convenient functions that implement specific 
  algorithms. See Lei, Lihua and Fithian, William (2016) <arXiv:1609.06035>.",2018-07-31,Lihua Lei,"https://arxiv.org/abs/1609.06035,
https://github.com/lihualei71/adaptMT",TRUE,https://github.com/lihualei71/adaptmt,9397,6,2020-02-29T23:25:30Z,1566.1666666666667
add2ggplot,Create 'ggplot2' themes and color palettes.,2020-02-07,Jiaxiang Li,https://github.com/JiaxiangBU/add2ggplot,TRUE,https://github.com/jiaxiangbu/add2ggplot,2492,2,2020-02-08T12:07:44Z,1246
addinslist,"Browse through a continuously updated list of existing RStudio 
    addins and install/uninstall their corresponding packages.",2019-08-30,Dean Attali,https://github.com/daattali/addinslist,TRUE,https://github.com/daattali/addinslist,42488,567,2020-05-11T17:07:38Z,74.93474426807761
addinsOutline,"'RStudio' allows to show and navigate for the outline of a 
    R Markdown file, but not for R Markdown projects with multiple 
    files. For this reason, I have developed several 'RStudio' addins capable 
    of show project outline. Each addin is specialized in showing projects 
    of different types: R Markdown project, 'bookdown' package project 
    and 'LaTeX' project. There is a configuration file that allows you 
    to customize additional searches.",2019-12-02,Pedro L. Luque-Calvo,https://github.com/calote/addinsOutline,TRUE,https://github.com/calote/addinsoutline,3302,0,2019-11-29T09:25:38Z,NA
ade4,"Tools for multivariate data analysis. Several methods are provided for the analysis (i.e., ordination) of one-table (e.g., principal component analysis, correspondence analysis), two-table (e.g., coinertia analysis, redundancy analysis), three-table (e.g., RLQ analysis) and K-table (e.g., STATIS, multiple coinertia analysis). The philosophy of the package is described in Dray and Dufour (2007) <doi:10.18637/jss.v022.i04>.",2020-02-13,Stéphane Dray,http://pbil.univ-lyon1.fr/ADE-4,TRUE,https://github.com/sdray/ade4,1469321,13,2020-04-23T15:23:48Z,113024.69230769231
ade4TkGUI,A Tcl/Tk GUI for some basic functions in the 'ade4' package.,2019-09-17,Jean Thioulouse,"http://pbil.univ-lyon1.fr/ade4TkGUI, Mailing list:
http://listes.univ-lyon1.fr/wws/info/adelist",TRUE,https://github.com/aursiber/ade4tkgui,78145,0,2019-09-13T09:21:07Z,NA
adegenet,"Toolset for the exploration of genetic and genomic
    data. Adegenet provides formal (S4) classes for storing and handling
    various genetic data, including genetic markers with varying ploidy
    and hierarchical population structure ('genind' class), alleles counts
    by populations ('genpop'), and genome-wide SNP data ('genlight'). It
    also implements original multivariate methods (DAPC, sPCA), graphics,
    statistical tests, simulation tools, distance and similarity measures,
    and several spatial methods. A range of both empirical and simulated
    datasets is also provided to illustrate various methods.",2020-05-10,Thibaut Jombart,https://github.com/thibautjombart/adegenet,TRUE,https://github.com/thibautjombart/adegenet,300883,101,2020-05-20T00:21:46Z,2979.039603960396
adegraphics,Graphical functionalities for the representation of multivariate data. It is a complete re-implementation of the functions available in the 'ade4' package.,2018-12-18,Stéphane Dray,"http://pbil.univ-lyon1.fr/ADE-4, Mailing list:
http://listes.univ-lyon1.fr/wws/info/adelist",TRUE,https://github.com/sdray/adegraphics,132944,6,2020-06-03T14:04:53Z,22157.333333333332
adept,"Designed for optimal use in performing fast, 
    accurate walking strides segmentation from high-density 
    data collected from a wearable accelerometer worn 
    during continuous walking activity.",2019-06-18,Marta Karas,https://github.com/martakarass/adept,TRUE,https://github.com/martakarass/adept,5402,3,2019-06-18T06:17:42Z,1800.6666666666667
AdhereR,"Computation of adherence to medications from Electronic Health care 
    Data and visualization of individual medication histories and adherence 
    patterns. The package implements a set of S3 classes and
    functions consistent with current adherence guidelines and definitions. 
    It allows the computation of different measures of
    adherence (as defined in the literature, but also several original ones), 
    their publication-quality plotting,
    the estimation of event duration and time to initiation,
    the interactive exploration of patient medication history and 
    the real-time estimation of adherence given various parameter settings.
    It scales from very small datasets stored in flat CSV files to very large 
    databases and from single-thread processing on mid-range consumer
    laptops to parallel processing on large heterogeneous computing clusters.
    It exposes a standardized interface allowing it to be used from other
    programming languages and platforms, such as Python.",2020-05-12,Dan Dediu,https://github.com/ddediu/AdhereR,TRUE,https://github.com/ddediu/adherer,19940,14,2019-06-14T13:16:52Z,1424.2857142857142
AdhereRViz,"Interactive graphical user interface (GUI) for the package 
    'AdhereR', allowing the user to access different data sources, to explore 
    the patterns of medication use therein, and the computation of various  
    measures of adherence. It is implemented using Shiny and HTML/CSS/JavaScript. ",2020-05-16,Dan Dediu,https://github.com/ddediu/AdhereR,TRUE,https://github.com/ddediu/adherer,389,14,2019-06-14T13:16:52Z,27.785714285714285
adjclust,"Implements a constrained version of hierarchical agglomerative 
    clustering, in which each observation is associated to a position, and 
    only adjacent clusters can be merged. Typical application fields in 
    bioinformatics include Genome-Wide Association Studies or Hi-C data 
    analysis, where the similarity between items is a decreasing function of 
    their genomic distance. Taking advantage of this feature, the implemented 
    algorithm is time and memory efficient. This algorithm is described in 
    Chapter 4 of Alia Dehman (2015) 
    <https://hal.archives-ouvertes.fr/tel-01288568v1>.",2019-12-10,Pierre Neuvial,https://github.com/pneuvial/adjclust,TRUE,https://github.com/pneuvial/adjclust,13790,13,2020-06-08T14:59:19Z,1060.7692307692307
adjustedcranlogs,Adjusts output of 'cranlogs' package to account for 'CRAN'-wide daily automated downloads and re-downloads caused by package updates.,2017-11-23,Tyler Morgan-Wall,https://github.com/tylermorganwall/adjustedcranlogs,TRUE,https://github.com/tylermorganwall/adjustedcranlogs,11927,24,2020-02-24T00:56:11Z,496.9583333333333
AdMit,"Provides functions to perform the fitting of an adaptive mixture
    of Student-t distributions to a target density through its kernel function as described in
    Ardia et al. (2009) <doi:10.18637/jss.v029.i03>. The
    mixture approximation can then be used as the importance density in importance
    sampling or as the candidate density in the Metropolis-Hastings algorithm to
    obtain quantities of interest for the target density itself. ",2020-04-20,David Ardia,https://github.com/ArdiaD/AdMit,TRUE,https://github.com/ardiad/admit,41881,2,2020-04-19T20:50:45Z,20940.5
adoptr,"Optimize one or two-arm, two-stage designs for clinical trials with 
    respect to several pre-implemented objective criteria or implement custom 
    objectives.
    Optimization under uncertainty and conditional (given stage-one outcome) 
    constraints are supported.
    See Pilz M, Kunzmann K, Herrmann C, Rauch G, Kieser M. A variational 
    approach to optimal two-stage designs. Statistics in Medicine. 2019;38(21):4159–4171.
    <doi:10.1002/sim.8291> for details.",2020-01-09,Kevin Kunzmann,https://github.com/kkmann/adoptr,TRUE,https://github.com/kkmann/adoptr,8701,3,2020-02-10T15:02:50Z,2900.3333333333335
adpss,"Provides the functions for planning and conducting a
  clinical trial with adaptive sample size determination. Maximal statistical
  efficiency will be exploited even when dramatic or multiple adaptations
  are made. Such a trial consists of adaptive determination of sample size
  at an interim analysis and implementation of frequentist statistical test at the
  interim and final analysis with a prefixed significance level. The required
  assumptions for the stage-wise test statistics are independent and stationary
  increments and normality. Predetermination of adaptation rule is not required.",2018-09-20,Kosuke Kashiwabara,https://github.com/ca4wa/R-adpss,TRUE,https://github.com/ca4wa/r-adpss,8842,0,2020-01-07T02:52:34Z,NA
afex,"Convenience functions for analyzing factorial experiments using ANOVA or
         mixed models. aov_ez(), aov_car(), and aov_4() allow specification of
         between, within (i.e., repeated-measures), or mixed (i.e., split-plot) 
         ANOVAs for data in long format (i.e., one observation per row),
         automatically aggregating multiple observations per individual and cell 
         of the design. mixed() fits mixed models using lme4::lmer() and computes 
         p-values for all fixed effects using either Kenward-Roger or Satterthwaite 
         approximation for degrees of freedom (LMM only), parametric bootstrap 
         (LMMs and GLMMs), or likelihood ratio tests (LMMs and GLMMs). 
         afex_plot() provides a high-level interface for interaction or one-way 
         plots using ggplot2, combining raw data and model estimates. afex uses 
         type 3 sums of squares as default (imitating commercial statistical software).",2020-03-28,Henrik Singmann,"http://afex.singmann.science/, https://github.com/singmann/afex",TRUE,https://github.com/singmann/afex,224665,80,2020-06-09T20:32:59Z,2808.3125
afpt,"Allows estimation and modelling of flight costs in animal (vertebrate) flight,
    implementing the aerodynamic power model described in Klein Heerenbrink et al.
    (2015) <doi:10.1098/rspa.2014.0952>. Taking inspiration from the program
    'Flight', developed by Colin Pennycuick (Pennycuick (2008) ""Modelling the flying
    bird"". Amsterdam: Elsevier. ISBN 0-19-857721-4), flight performance is estimated
    based on basic morphological measurements such as body mass, wingspan and wing
    area. 'afpt' can be used to make predictions on how animals should adjust their
    flight behaviour and wingbeat kinematics to varying flight conditions.",2020-03-19,Marco KleinHeerenbrink,https://github.com/MarcoKlH/afpt-r/,TRUE,https://github.com/marcoklh/afpt-r,12870,1,2020-03-18T15:32:16Z,12870
aftgee,"A collection of methods for both the rank-based estimates and least-square estimates
	      to the Accelerated Failure Time (AFT) model.
	      For rank-based estimation, it provides approaches that include the computationally
	      efficient Gehan's weight and the general's weight such as the logrank weight.
	      Details of the rank-based estimation can be found in
	      Chiou et al. (2014) <doi:10.1007/s11222-013-9388-2> and
	      Chiou et al. (2015) <doi:10.1002/sim.6415>.
	      For the least-square estimation, the estimating equation is solved with
	      generalized estimating equations (GEE).
	      Moreover, in multivariate cases, the dependence working correlation structure
	      can be specified in GEE's setting.
	      Details on the least-squares estimation can be found in
	      Chiou et al. (2014) <doi:10.1007/s10985-014-9292-x>.",2018-07-24,Sy Han Chiou,http://github.com/stc04003/aftgee,TRUE,https://github.com/stc04003/aftgee,32629,0,2019-12-19T16:33:21Z,NA
AGD,"Tools for the analysis of growth data: to extract an 
    LMS table from a gamlss object, to calculate the standard 
    deviation scores and its inverse, and to superpose two wormplots 
    from different models. The package contains a some varieties of 
    reference tables, especially for The Netherlands.",2018-05-29,Stef van Buuren,https://github.com/stefvanbuuren/AGD,TRUE,https://github.com/stefvanbuuren/agd,104241,1,2020-05-05T19:48:54Z,104241
AGHmatrix,"Computation of A (pedigree), G (genomic-base), and H (A corrected
    by G) relationship matrices for diploid and autopolyploid species. Several methods
    are implemented considering additive and non-additive models.",2019-07-30,Rodrigo Amadeu,http://github.com/prmunoz/AGHmatrix,TRUE,https://github.com/prmunoz/aghmatrix,11668,5,2020-01-14T14:20:10Z,2333.6
agop,"Tools supporting multi-criteria and group decision making,
    including variable number of criteria, by means of
    aggregation operators, spread measures,
    fuzzy logic connectives, fusion functions,
    and preordered sets. Possible applications include,
    but are not limited to, quality management, scientometrics,
    software engineering, etc.",2020-01-08,Marek Gagolewski,http://www.gagolewski.com/software/,TRUE,https://github.com/gagolews/agop,25078,3,2020-01-10T05:51:35Z,8359.333333333334
AGread,"Standardize the process of bringing various modes of output files
    into R. Additionally, processes are provided to read and minimally pre-
    process raw data from primary accelerometer and inertial measurement unit files,
    as well as binary .gt3x files. ActiGraph monitors are used to estimate physical
    activity outcomes via body-worn sensors that measure (e.g.) acceleration or
    rotational velocity.",2020-02-26,Paul R. Hibbing,https://github.com/paulhibbing/AGread,TRUE,https://github.com/paulhibbing/agread,13402,7,2020-06-07T02:37:18Z,1914.5714285714287
agridat,"Datasets from books, papers, and websites related to agriculture.
    Example graphics and analyses are included. Data come from small-plot trials,
    multi-environment trials, uniformity trials, yield monitors, and more.",2018-07-06,Kevin Wright,https://github.com/kwstat/agridat,TRUE,https://github.com/kwstat/agridat,54968,64,2020-01-20T15:28:35Z,858.875
agriwater,"Spatial modeling of energy balance and actual 
    evapotranspiration using satellite images and meteorological data. 
    Options of satellite are: Landsat-8 (with and without thermal bands), 
    Sentinel-2 and MODIS. Respectively spatial resolutions are 30, 100, 
    10 and 250 meters. User can use data from a single meteorological 
    station or a grid of meteorological stations (using any spatial 
    interpolation method). Teixeira (2010) <doi:10.3390/rs0251287>. 
    Teixeira et al. (2015) <doi:10.3390/rs71114597>.
    Silva, Manzione, and Albuquerque Filho (2018) <doi:10.3390/horticulturae4040044>.",2019-01-30,Cesar de Oliveira Ferreira Silva,NA,TRUE,https://github.com/cesarofs/agriwater,7271,3,2020-03-03T20:44:34Z,2423.6666666666665
AHMbook,"Provides functions and data sets to accompany the two volume publication ""Applied Hierarchical Modeling in Ecology: Analysis of distribution, abundance and species richness in R and BUGS"" by Marc Kéry and Andy Royle: volume 1 (2016, ISBN: 978-0-12-801378-6) and volume 2 (2020, ISBN: 978-0-12-809585-0), <https://www.mbr-pwrc.usgs.gov/pubanalysis/keryroylebook>.",2020-06-09,Mike Meredith,"https://www.mbr-pwrc.usgs.gov/pubanalysis/keryroylebook/,
https://sites.google.com/site/appliedhierarchicalmodeling/home",TRUE,https://github.com/mikemeredith/ahmbook,18100,9,2020-06-08T13:14:36Z,2011.111111111111
aimsir17,"Named after the Irish name for weather, this package contains 
    tidied data from the Irish Meteorological Service's hourly observations for 2017. 
    In all, the data sets include observations from 25 weather stations, and also
    latitude and longitude coordinates for each weather station.",2019-12-02,Jim Duggan,"https://github.com/JimDuggan/aimsir17, https://www.met.ie",TRUE,https://github.com/jimduggan/aimsir17,3065,0,2019-12-04T14:14:22Z,NA
aire.zmvm,"Tools for downloading hourly averages, daily maximums and minimums from each of the 
    pollution, wind, and temperature measuring stations or geographic zones in the Mexico City 
    metro area. The package also includes the locations of each of the stations and zones. See 
    <http://aire.cdmx.gob.mx/> for more information.",2019-03-30,Diego Valle-Jones,"https://hoyodesmog.diegovalle.net/aire.zmvm/,
https://github.com/diegovalle/aire.zmvm",TRUE,https://github.com/diegovalle/aire.zmvm,16966,9,2020-05-05T02:50:57Z,1885.111111111111
aiRly,Get information about air quality using 'Airly' <https://airly.eu/> API through R.,2020-03-19,Piotr Janus,https://github.com/piotrekjanus/aiRly,TRUE,https://github.com/piotrekjanus/airly,1544,0,2020-03-19T22:31:01Z,NA
airportr,"Retrieves open source airport data and provides tools to look up information, translate names into codes and vice-verse, as well as some basic calculation functions for measuring distances. Data is licensed under the Open Database License. ",2019-10-09,Dmitry Shkolnik,https://github.com/dshkol/airportr,TRUE,https://github.com/dshkol/airportr,9904,4,2020-05-24T06:22:26Z,2476
airqualityES,"These dataset contains daily quality air measurements in 
  Spain over a period of 18 years (from 2001 to 2018). The measurements refer to 
  several pollutants. These data are openly published by the Government of Spain.  
  The datasets were originally spread over a number of files and formats. Here, 
  the same information is contained in simple dataframe for convenience of 
  researches, journalists or general public. See the Spanish Government website 
  <http://www.miteco.gob.es/> for more information.",2020-02-29,Jose V. Die,https://github.com/jdieramon/airqualityES,TRUE,https://github.com/jdieramon/airqualityes,2098,0,2020-03-03T18:02:08Z,NA
airr,"Schema definitions and read, write and validation tools for data 
    formatted in accordance with the AIRR Data Representation schemas defined 
    by the AIRR Community <http://docs.airr-community.org>.",2020-05-27,Jason Vander Heiden,http://docs.airr-community.org,TRUE,https://github.com/airr-community/airr-standards,11243,18,2020-06-01T21:21:28Z,624.6111111111111
akc,"A tidy framework for automatic knowledge classification and visualization. Currently, the core functionality of the framework is mainly supported by modularity-based clustering (community detection) in keyword co-occurrence network, and focuses on co-word analysis of bibliometric research. However, the designed functions in 'akc' are general, and could be extended to solve other tasks in text mining as well. ",2020-01-30,Tian-Yuan Huang,https://github.com/hope-data-science/akc,TRUE,https://github.com/hope-data-science/akc,3382,8,2020-02-17T01:01:31Z,422.75
ALA4R,"The Atlas of Living Australia (ALA) provides tools to enable users
    of biodiversity information to find, access, combine and visualise data on
    Australian plants and animals; these have been made available from
    <https://ala.org.au/>. ALA4R provides a subset of the tools to be
    directly used within R. It enables the R community to directly access data
    and resources hosted by the ALA.",2020-04-04,Peggy Newman,https://github.com/AtlasOfLivingAustralia/ALA4R,TRUE,https://github.com/atlasoflivingaustralia/ala4r,21946,32,2020-04-03T05:17:58Z,685.8125
albopictus,Implements discrete time deterministic and stochastic age-structured population dynamics models described in Erguler and others (2016) <doi:10.1371/journal.pone.0149282> and Erguler and others (2017) <doi:10.1371/journal.pone.0174293>.,2018-11-29,Kamil Erguler,https://github.com/kerguler/albopictusR,TRUE,https://github.com/kerguler/albopictusr,15595,0,2020-03-20T15:34:46Z,NA
alfr,"Allows you to connect to an 'Alfresco' content management repository and interact
  with its contents using simple and intuitive functions.  You will be able to establish a connection session to the 'Alfresco' repository,
  read and upload content and manage folder hierarchies.  For more details on the 'Alfresco' content management repository
  see <https://www.alfresco.com/ecm-software/document-management>.",2019-07-19,Roy Wetherall,"https://github.com/rwetherall/alfr,
https://rwetherall.github.io/alfr/",TRUE,https://github.com/rwetherall/alfr,5086,0,2019-07-19T02:21:15Z,NA
AlgDesign,"Algorithmic experimental designs. Calculates exact and
        approximate theory experimental designs for D,A, and I
        criteria. Very large designs may be created. Experimental
        designs may be blocked or blocked designs created from a
        candidate list, using several criteria.  The blocking can be
        done when whole and within plot factors interact.",2019-11-29,Bob Wheeler,https://github.com/jvbraun/AlgDesign,TRUE,https://github.com/jvbraun/algdesign,815651,6,2019-11-29T02:10:41Z,135941.83333333334
algorithmia,"The company, Algorithmia, houses the largest marketplace of online
    algorithms. This package essentially holds a bunch of REST wrappers that
    make it very easy to call algorithms in the Algorithmia platform and access
    files and directories in the Algorithmia data API. To learn more about the
    services they offer and the algorithms in the platform visit
    <http://algorithmia.com>. More information for developers can be found at
    <http://developers.algorithmia.com>.",2019-08-01,James Sutton,NA,TRUE,https://github.com/algorithmiaio/algorithmia-r,17860,10,2019-08-02T19:03:08Z,1786
aliases2entrez,"Queries multiple resources authors HGNC (2019) <https://www.genenames.org>, authors limma (2015) <doi:10.1093/nar/gkv007> 
    to find the correspondence between evolving nomenclature of human gene symbols, aliases, previous symbols or synonyms with 
    stable, curated gene entrezID from NCBI database. This allows fast, accurate and up-to-date correspondence
    between human gene expression datasets from various date and platform (e.g: gene symbol: BRCA1 - ID: 672).",2020-05-19,Raphael Bonnet,NA,TRUE,https://github.com/peyronlab/aliases2entrez,3859,1,2019-10-08T08:14:36Z,3859
almanac,"Provides tools for defining recurrence rules and
    recurrence bundles. Recurrence rules are a programmatic way to define
    a recurring event, like the first Monday of December. Multiple
    recurrence rules can be combined into larger recurrence bundles.
    Together, these provide a system for adjusting and generating
    sequences of dates while simultaneously skipping over dates in a
    recurrence bundle's event set.",2020-05-28,Davis Vaughan,https://github.com/DavisVaughan/almanac,TRUE,https://github.com/davisvaughan/almanac,138,52,2020-05-28T17:39:14Z,2.6538461538461537
alookr,"A collection of tools that support data splitting, predictive modeling, and model evaluation. 
    A typical function is to split a dataset into a training dataset and a test dataset. 
    Then compare the data distribution of the two datasets.
    Another feature is to support the development of predictive models and to compare the performance of several predictive models, 
    helping to select the best model. ",2020-06-07,Choonghyun Ryu,NA,TRUE,https://github.com/choonghyunryu/alookr,1660,6,2020-06-07T15:02:02Z,276.6666666666667
alpaca,"Provides a routine to concentrate out factors with many levels during the
  optimization of the log-likelihood function of the corresponding generalized linear model (glm).
  The package is based on the algorithm proposed by Stammann (2018) <arXiv:1707.01815> and is
  restricted to glm's that are based on maximum likelihood estimation and non-linear. It also offers
  an efficient algorithm to recover estimates of the fixed effects in a post-estimation routine and 
  includes robust and multi-way clustered standard errors. Further the package provides analytical 
  bias corrections for binary choice models (logit and probit) derived by Fernandez-Val 
  and Weidner (2016) <doi:10.1016/j.jeconom.2015.12.014> and Hinz, Stammann, and Wanner (2019).",2020-01-12,Amrei Stammann,https://github.com/amrei-stammann/alpaca,TRUE,https://github.com/amrei-stammann/alpaca,27931,23,2020-01-19T12:39:26Z,1214.391304347826
alphavantager,"
    Alpha Vantage has free historical financial information. 
    All you need to do is get a free API key at <https://www.alphavantage.co>.
    Then you can use the R interface to retrieve free equity information.
    Refer to the Alpha Vantage website for more information.",2020-03-01,Matt Dancho,https://github.com/business-science/alphavantager,TRUE,https://github.com/business-science/alphavantager,84585,44,2020-03-01T14:14:43Z,1922.3863636363637
altair,"Interface to 'Altair' <https://altair-viz.github.io>, which itself 
  is a 'Python' interface to 'Vega-Lite' <https://vega.github.io/vega-lite>.
  This package uses the 'Reticulate' framework 
  <https://rstudio.github.io/reticulate> to manage the interface between R
  and 'Python'.",2020-01-23,Ian Lyttle,https://github.com/vegawidget/altair,TRUE,https://github.com/vegawidget/altair,5680,68,2020-01-23T20:38:11Z,83.52941176470588
alterryx,"A tool to access each of the 'Alteryx' Gallery 'API' endpoints.
    Users can queue jobs, poll job status, and retrieve application output as
    a data frame. You will need an 'Alteryx' Server license and have 'Alteryx'
    Gallery running to utilize this package. The 'API' is accessed through the
    'URL' that you setup for the server running 'Alteryx' Gallery and more
    information on the endpoints can be found at
    <https://gallery.alteryx.com/api-docs/>.",2019-06-06,Michael Treadwell,"https://github.com/mtreadwell/alterryx,
https://gallery.alteryx.com/api-docs/",TRUE,https://github.com/mtreadwell/alterryx,17370,3,2019-09-03T17:15:38Z,5790
altR2,"Provides alternatives to the normal adjusted R-squared estimator for the estimation of the multiple squared correlation in regression models, 
              as fitted by the lm() function. The alternative estimators are described in Karch (2016) <DOI:10.31234/osf.io/v8dz5>.",2019-09-23,Julian Karch,https://github.com/karchjd/altR2,TRUE,https://github.com/karchjd/altr2,4061,0,2019-09-26T10:24:21Z,NA
ambient,"Generation of natural looking noise has many application within 
    simulation, procedural generation, and art, to name a few. The 'ambient' 
    package provides an interface to the 'FastNoise' C++ library and allows for
    efficient generation of perlin, simplex, worley, cubic, value, and white 
    noise with optional pertubation in either 2, 3, or 4 (in case of simplex and
    white noise) dimensions.",2020-03-21,Thomas Lin Pedersen,"https://ambient.data-imaginist.com,
https://github.com/thomasp85/ambient",TRUE,https://github.com/thomasp85/ambient,10102,59,2020-03-19T20:43:12Z,171.22033898305085
ameco,Annual macro-economic database provided by the European Commission.,2018-05-04,Eric Persson,http://github.com/expersso/ameco,TRUE,https://github.com/expersso/ameco,28191,6,2019-09-10T08:50:00Z,4698.5
amerika,"A color palette generator inspired by American politics, with colors ranging from blue on the 
    left to gray in the middle and red on the right. A variety of palettes allow for a range of applications 
    from brief discrete scales (e.g., three colors for Democrats, Independents, and Republicans) to 
    continuous interpolated arrays including dozens of shades graded from blue (left) to red (right). This
    package greatly benefitted from building on the source code (with permission) from Ram and Wickham (2015).",2019-05-03,Philip Waggoner,NA,TRUE,https://github.com/pdwaggoner/amerika,7873,0,2019-11-14T20:08:36Z,NA
AmpGram,"Predicts antimicrobial peptides using random forests trained on the
    n-gram encoded peptides. The implemented algorithm can be accessed from
    both the command line and shiny-based GUI. The AmpGram model is too large 
    for CRAN and it has to be downloaded separately from the repository:
    <https://github.com/michbur/AmpGramModel>.",2020-05-31,Michal Burdukiewicz,https://github.com/michbur/AmpGram,TRUE,https://github.com/michbur/ampgram,10,1,2020-05-22T09:21:48Z,10
ampir,"A toolkit to predict antimicrobial peptides from protein sequences on a genome-wide scale.
    It incorporates two support vector machine models (""precursor"" and ""mature"") trained on publicly available antimicrobial peptide data using calculated
    physico-chemical and compositional sequence properties described in Meher et al. (2017) <doi:10.1038/srep42362>.
    In order to support genome-wide analyses, these models are designed to accept any type of protein as input
    and calculation of compositional properties has been optimised for high-throughput use. For details see Fingerhut et al. 2020 <doi:10.1101/2020.05.07.082412>.",2020-05-11,Legana Fingerhut,https://github.com/Legana/ampir,TRUE,https://github.com/legana/ampir,3243,5,2020-05-11T12:00:38Z,648.6
amt,"Manage and analyze animal movement data. The functionality of 'amt' includes methods to calculate track statistics (e.g. step lengths, speed, or turning angles), prepare data for fitting habitat selection analyses (resource selection functions and step-selection functions <doi:10.1890/04-0953> and integrated step-selection functions <doi:10.1111/2041-210X.12528>), and simulation of space-use from fitted step-selection functions <doi:10.1002/ecs2.1771>.",2020-04-28,Johannes Signer,https://github.com/jmsigner/amt,TRUE,https://github.com/jmsigner/amt,19886,9,2020-05-22T11:29:08Z,2209.5555555555557
AmyloGram,"Predicts amyloid proteins using random forests trained on the
    n-gram encoded peptides. The implemented algorithm can be accessed from
    both the command line and shiny-based GUI.",2017-10-11,Michal Burdukiewicz,https://github.com/michbur/AmyloGram,TRUE,https://github.com/michbur/amylogram,15714,7,2020-05-21T19:41:56Z,2244.8571428571427
AnaCoDa,"Is a collection of models to analyze genome scale codon
        data using a Bayesian framework. Provides visualization
        routines and checkpointing for model fittings. Currently
        published models to analyze gene data for selection on codon
        usage based on Ribosome Overhead Cost (ROC) are: ROC (Gilchrist
        et al. (2015) <doi:10.1093/gbe/evv087>), and ROC with phi
        (Wallace & Drummond (2013) <doi:10.1093/molbev/mst051>). In
        addition 'AnaCoDa' contains three currently unpublished models.
        The FONSE (First order approximation On NonSense Error) model
        analyzes gene data for selection on codon usage against of
        nonsense error rates. The PA (PAusing time) and PANSE (PAusing
        time + NonSense Error) models use ribosome footprinting data to
        analyze estimate ribosome pausing times with and without
        nonsense error rate from ribosome footprinting data.",2019-05-11,Cedric Landerer,https://github.com/clandere/AnaCoDa,TRUE,https://github.com/clandere/anacoda,13327,1,2019-06-12T11:13:15Z,13327
analogsea,"Provides a set of functions for interacting with the 'Digital
    Ocean' API at <https://developers.digitalocean.com/documentation/v2>, including
    creating images, destroying them, rebooting, getting details on regions, and
    available images.",2020-01-30,Scott Chamberlain,https://github.com/sckott/analogsea,TRUE,https://github.com/sckott/analogsea,68685,108,2020-04-15T00:43:56Z,635.9722222222222
analogue,"Fits Modern Analogue Technique and Weighted Averaging transfer 
  	     function models for prediction of environmental data from species 
	     data, and related methods used in palaeoecology.",2020-02-06,Gavin L. Simpson,https://github.com/gavinsimpson/analogue,TRUE,https://github.com/gavinsimpson/analogue,58809,11,2020-02-04T04:26:31Z,5346.272727272727
analogueExtra,"Provides additional functionality for the analogue package
	     that is not required by all users of the main package.",2016-04-10,Gavin L. Simpson,https://github.com/gavinsimpson/analogueExtra,TRUE,https://github.com/gavinsimpson/analogueextra,20394,1,2019-08-26T23:20:36Z,20394
analysisPipelines,"Enables data scientists to compose pipelines of analysis which consist of data manipulation, exploratory analysis & reporting, as well as modeling steps. Data scientists can use tools of their choice through an R interface, and compose interoperable pipelines between R, Spark, and Python.
    Credits to Mu Sigma for supporting the development of the package.
    Note - To enable pipelines involving Spark tasks, the package uses the 'SparkR' package. 
    The SparkR package needs to be installed to use Spark as an engine within a pipeline. SparkR is distributed natively with Apache Spark and is not distributed on CRAN. The SparkR version needs to directly map to the Spark version (hence the native distribution), and care needs to be taken to ensure that this is configured properly.
    To install SparkR from Github, run the following command if you know the Spark version: 'devtools::install_github('apache/spark@v2.x.x', subdir='R/pkg')'.
    The other option is to install SparkR by running the following terminal commands if Spark has already been installed: '$ export SPARK_HOME=/path/to/spark/directory && cd $SPARK_HOME/R/lib/SparkR/ && R -e ""devtools::install('.')""'.",2020-05-05,Mu Sigma,https://github.com/Mu-Sigma/analysis-pipelines,TRUE,https://github.com/mu-sigma/analysis-pipelines,8539,18,2020-05-05T14:06:35Z,474.3888888888889
Andromeda,"Storing very large data objects on a local drive, while still making it possible to manipulate the data in an efficient manner.",2020-06-03,Martijn Schuemie,"https://ohdsi.github.io/Andromeda/,
https://github.com/OHDSI/Andromeda",TRUE,https://github.com/ohdsi/andromeda,588,0,2020-06-03T05:11:30Z,NA
anglr,"Gives direct access to generic 3D tools and provides a full suite 
 of mesh-creation and 3D plotting functions. By extending the 'rgl' package 
 conversion and visualization functions for the 'mesh3d' class a wide variety of
 complex spatial data can be brought into 3D scenes. These tools allow for 
 spatial raster, polygons, and lines that are common in 'GIS' contexts to be 
 converted into mesh forms with high flexibility and the ability to integrate 
 disparate data types. Vector and raster data can be seamlessly combined as 
 meshes, and surfaces can be set to have material properties based on data 
 values or with image textures. Textures and other data combinations use 
 projection transformations to map between coordinate systems, and objects can 
 be easily visualized in an interactive scene at any stage. This package relies 
 on the 'RTriangle' package for high-quality triangular meshing which is 
 licensed restrictively under 'CC BY-NC-SA 4.0'. ",2020-05-13,Michael D. Sumner,https://github.com/hypertidy/anglr,TRUE,https://github.com/hypertidy/anglr,1113,45,2020-05-21T10:39:40Z,24.733333333333334
angstroms,"Helper functions for working with Regional Ocean Modeling System 'ROMS' output. See
    <https://www.myroms.org/> for more information about 'ROMS'. ",2017-05-01,Michael D. Sumner,https://github.com/mdsumner/angstroms,TRUE,https://github.com/mdsumner/angstroms,12475,2,2020-04-12T14:20:27Z,6237.5
animation,"Provides functions for animations in statistics, covering topics
    in probability theory, mathematical statistics, multivariate statistics,
    non-parametric statistics, sampling survey, linear models, time series,
    computational statistics, data mining and machine learning. These functions
    may be helpful in teaching statistics and data analysis. Also provided in this
    package are a series of functions to save animations to various formats, e.g.
    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted
    into 'Sweave' / 'knitr' easily.",2018-12-11,Yihui Xie,https://yihui.name/animation,TRUE,https://github.com/yihui/animation,632661,162,2020-05-20T04:36:17Z,3905.314814814815
aniview,Animate Shiny and R Markdown content when it comes into view using 'animate-css' effects thanks to 'jQuery AniView'.,2020-03-31,Félix Luginbuhl,"https://felixluginbuhl.com/aniview,
https://github.com/lgnbhl/aniview",TRUE,https://github.com/lgnbhl/aniview,1240,1,2020-04-11T14:36:36Z,1240
ANN2,"Training of neural networks for classification and regression tasks
    using mini-batch gradient descent. Special features include a function for 
    training autoencoders, which can be used to detect anomalies, and some 
    related plotting functions. Multiple activation functions are supported, 
    including tanh, relu, step and ramp. For the use of the step and ramp 
    activation functions in detecting anomalies using autoencoders, see 
    Hawkins et al. (2002) <doi:10.1007/3-540-46145-0_17>. Furthermore, 
    several loss functions are supported, including robust ones such as Huber 
    and pseudo-Huber loss, as well as L1 and L2 regularization. The possible 
    options for optimization algorithms are RMSprop, Adam and SGD with momentum.
    The package contains a vectorized C++ implementation that facilitates 
    fast training through mini-batch learning.",2020-03-14,Bart Lammers,https://github.com/bflammers/ANN2,TRUE,https://github.com/bflammers/ann2,29442,6,2020-03-14T21:49:29Z,4907
AnnotationBustR,Extraction of subsequences into FASTA files from GenBank annotations where gene names may vary among accessions.,2018-04-09,Samuel R. Borstein,"https://github.com/sborstein/AnnotationBustR,
https://www.ncbi.nlm.nih.gov/nuccore,
https://en.wikipedia.org/wiki/FASTA_format",TRUE,https://github.com/sborstein/annotationbustr,15667,0,2019-11-12T18:51:33Z,NA
anomalize,"
    The 'anomalize' package enables a ""tidy"" workflow for detecting anomalies in data.
    The main functions are time_decompose(), anomalize(), and time_recompose().
    When combined, it's quite simple to decompose time series, detect anomalies,
    and create bands separating the ""normal"" data from the anomalous data at scale (i.e. for multiple time series). 
    Time series decomposition is used to remove trend and seasonal components via the time_decompose() function
    and methods include seasonal decomposition of time series by Loess (""stl"") and 
    seasonal decomposition by piecewise medians (""twitter""). The anomalize() function implements
    two methods for anomaly detection of residuals including using an inner quartile range (""iqr"")
    and generalized extreme studentized deviation (""gesd""). These methods are based on
    those used in the 'forecast' package and the Twitter 'AnomalyDetection' package. 
    Refer to the associated functions for specific references for these methods. ",2019-09-21,Matt Dancho,https://github.com/business-science/anomalize,TRUE,https://github.com/business-science/anomalize,58802,222,2020-04-24T20:06:48Z,264.8738738738739
antaresProcessing,"
    Process results generated by 'Antares', a powerful open source software developed by
    RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems (more information about
    'Antares' here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>).
    This package provides functions to create new columns like net load, load factors, upward and
    downward margins or to compute aggregated statistics like economic surpluses
    of consumers, producers and sectors.",2020-02-26,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresProcessing,TRUE,https://github.com/rte-antares-rpackage/antaresprocessing,29552,8,2020-02-28T14:38:34Z,3694
antaresRead,"Import, manipulate and explore results generated by 'Antares', a 
    powerful open source software developed by RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems
    (more information about 'Antares' here : <https://antares-simulator.org/>).",2020-03-18,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresRead,TRUE,https://github.com/rte-antares-rpackage/antaresread,38639,9,2020-03-04T08:58:03Z,4293.222222222223
antaresViz,"Visualize results generated by Antares, a powerful open source software
    developed by RTE to simulate and study electric power systems
    (more information about Antares here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>).
    This package provides functions that create interactive charts to help
    Antares users visually explore the results of their simulations.",2020-05-26,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresViz,TRUE,https://github.com/rte-antares-rpackage/antaresviz,21816,14,2020-05-26T08:56:49Z,1558.2857142857142
anthro,"Provides WHO Child Growth Standards (z-scores) with
             confidence intervals and standard errors around the
             prevalence estimates, taking into account complex sample designs.
             More information on the methods is
             available online:
             <http://www.who.int/childgrowth/standards/en/>.",2020-05-21,Dirk Schumacher,https://github.com/dirkschumacher/anthro,TRUE,https://github.com/dirkschumacher/anthro,9660,11,2020-05-21T11:01:43Z,878.1818181818181
AntWeb,"A complete programmatic interface to the AntWeb database from the
    California Academy of Sciences.",2014-08-14,Karthik Ram,https://github.com/ropensci/AntWeb,TRUE,https://github.com/ropensci/antweb,26568,8,2019-12-09T12:00:33Z,3321
anyflights,"Supplies a set of functions to query air travel data for user-
    specified years and airports. Datasets include on-time flights, airlines,
    airports, planes, and weather.",2020-04-27,Simon P. Couch,http://github.com/simonpcouch/anyflights,TRUE,https://github.com/simonpcouch/anyflights,3021,4,2020-05-01T18:11:34Z,755.25
anytime,"Convert input in any one of character, integer, numeric, factor,
 or ordered type into 'POSIXct' (or 'Date') objects, using one of a number of
 predefined formats, and relying on Boost facilities for date and time parsing.",2020-01-20,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/anytime.html,TRUE,https://github.com/eddelbuettel/anytime,445286,124,2020-04-14T21:29:59Z,3591.016129032258
aof,"A breakpoint-based method to detect ontogenetic shifts in 
  univariate time-activity budget series of central-place foraging insects. 
  The method finds a single breakpoint according to the likelihood function. 
  The method was developed with honey bees in order to detect the Age at 
  Onset of Foraging (AOF), but can be used for the detection of other 
  ontogenetic shifts in other central-place foraging insects. ",2020-03-09,Fabrice Requier,https://github.com/frareb/aof/,TRUE,https://github.com/frareb/aof,1643,1,2020-05-07T09:38:35Z,1643
aos,"Trigger animation effects on scroll on any HTML element 
    of 'shiny' and 'rmarkdown', such as any text or plot, thanks to 
    the 'AOS' Animate On Scroll jQuery library.",2020-04-29,Félix Luginbuhl,"https://felixluginbuhl.com/aos, https://github.com/lgnbhl/aos",TRUE,https://github.com/lgnbhl/aos,708,0,2020-04-25T16:12:17Z,NA
apa,"Formatter functions in the 'apa' package take the return value of a
    statistical test function, e.g. a call to chisq.test() and return a string
    formatted according to the guidelines of the APA (American Psychological
    Association).",2020-04-21,Daniel Gromer,https://github.com/dgromer/apa,TRUE,https://github.com/dgromer/apa,25777,23,2020-04-21T12:43:47Z,1120.7391304347825
apaTables,"A common task faced by researchers is the creation of APA style
    (i.e., American Psychological Association style) tables from statistical
    output. In R a large number of function calls are often needed to obtain all of
    the desired information for a single APA style table. As well, the process of
    manually creating APA style tables in a word processor is prone to transcription
    errors. This package creates Word files (.doc files) containing APA style tables
    for several types of analyses. Using this package minimizes transcription errors
    and reduces the number commands needed by the user.",2018-08-29,David Stanley,https://github.com/dstanley4/apaTables,TRUE,https://github.com/dstanley4/apatables,83807,32,2020-04-27T14:44:46Z,2618.96875
apcf,"The adapted pair correlation function transfers the concept of the
  pair correlation function from point patterns to patterns of objects of 
  finite size and irregular shape (e.g. lakes within a country). This is a 
  reimplementation of the method suggested by Nuske et al. (2009) 
  <doi:10.1016/j.foreco.2009.09.050> using the libraries 'GEOS' and 'GDAL' 
  directly instead of through 'PostGIS'. ",2020-02-04,Robert Nuske,https://github.com/rnuske/apcf,TRUE,https://github.com/rnuske/apcf,8446,6,2020-04-14T07:22:41Z,1407.6666666666667
apex,"Toolkit for the analysis of multiple gene data (Jombart et al. 2017) <doi:10.1111/1755-0998.12567>. 
    Apex implements the new S4 classes 'multidna', 'multiphyDat' and associated methods to handle aligned DNA sequences from multiple genes.",2020-04-11,Klaus Schliep,https://github.com/thibautjombart/apex,TRUE,https://github.com/thibautjombart/apex,36653,4,2020-05-06T05:52:57Z,9163.25
apexcharter,"Provides an 'htmlwidgets' interface to 'apexcharts.js'. 
  'Apexcharts' is a modern JavaScript charting library to build interactive charts and visualizations with simple API.
  'Apexcharts' examples and documentation are available here: <https://apexcharts.com/>.",2020-03-31,Victor Perrier,"https://github.com/dreamRs/apexcharter,
https://dreamrs.github.io/apexcharter",TRUE,https://github.com/dreamrs/apexcharter,7488,68,2020-06-09T15:03:49Z,110.11764705882354
aplot,"For many times, we are not just aligning plots as what 'cowplot' and 'patchwork' did. Users would like to align associated information that requires axes to be exactly matched in subplots, e.g. hierarchical clustering with a heatmap. This package provides utilities to aligns associated subplots to a main plot at different sides (left, right, top and bottom) with axes exactly matched. ",2020-04-07,Guangchuang Yu,https://github.com/YuLab-SMU/aplot,TRUE,https://github.com/yulab-smu/aplot,2976,32,2020-04-15T15:21:04Z,93
applicable,"A modeling package compiling applicability domain methods in R.
    It combines different methods to measure the amount of extrapolation new
    samples can have from the training set. See Netzeva et al (2005) 
    <doi:10.1177/026119290503300209> for an overview of applicability domains. ",2020-05-25,Marly Gotti,https://github.com/tidymodels/applicable,TRUE,https://github.com/tidymodels/applicable,172,23,2020-05-26T07:18:05Z,7.478260869565218
aprof,"Assists the evaluation of whether and
    where to focus code optimization, using Amdahl's law and visual aids
    based on line profiling. Amdahl's profiler organizes profiling output
    files (including memory profiling) in a visually appealing way.
    It is meant to help to balance development
    vs. execution time by helping to identify the most promising sections
    of code to optimize and projecting potential gains. The package is
    an addition to R's standard profiling tools and is not a wrapper for them.",2018-05-22,Marco D. Visser,http://github.com/MarcoDVisser/aprof,TRUE,https://github.com/marcodvisser/aprof,29453,22,2020-01-18T16:45:45Z,1338.7727272727273
apyramid,"Provides a quick method for visualizing non-aggregated line-list
    or aggregated census data stratified by age and one or two categorical
    variables (e.g. gender and health status) with any number of values. It
    returns a 'ggplot' object, allowing the user to further customize the
    output. This package is part of the 'R4Epis' project 
    <https://r4epis.netlify.com>.",2020-05-08,Zhian N. Kamvar,"https://github.com/R4EPI/apyramid, https://r4epis.netlify.com",TRUE,https://github.com/r4epi/apyramid,3199,4,2020-05-08T14:44:23Z,799.75
aqp,"The Algorithms for Quantitative Pedology (AQP) project was started in 2009 to organize a loosely-related set of concepts and source code on the topic of soil profile visualization, aggregation, and classification into this package (aqp). Over the past 8 years, the project has grown into a suite of related R packages that enhance and simplify the quantitative analysis of soil profile data. Central to the AQP project is a new vocabulary of specialized functions and data structures that can accommodate the inherent complexity of soil profile information; freeing the scientist to focus on ideas rather than boilerplate data processing tasks <doi:10.1016/j.cageo.2012.10.020>. These functions and data structures have been extensively tested and documented, applied to projects involving hundreds of thousands of soil profiles, and deeply integrated into widely used tools such as SoilWeb <https://casoilresource.lawr.ucdavis.edu/soilweb-apps/>. Components of the AQP project (aqp, soilDB, sharpshootR, soilReports packages) serve an important role in routine data analysis within the USDA-NRCS Soil Science Division. The AQP suite of R packages offer a convenient platform for bridging the gap between pedometric theory and practice.",2020-01-24,Dylan Beaudette,https://github.com/ncss-tech/aqp,TRUE,https://github.com/ncss-tech/aqp,146911,18,2020-06-09T19:28:39Z,8161.722222222223
ArchaeoPhases,"Provides a list of functions for the statistical analysis of archaeological dates and groups of dates (see <doi:10.18637/jss.v093.c01> for a description). It is based on the post-processing of the Markov Chains whose stationary distribution is the posterior distribution of a series of dates. Such output can be simulated by different applications as for instance 'ChronoModel' (see <http://www.chronomodel.fr>), 'Oxcal' (see <https://c14.arch.ox.ac.uk/oxcal.html>) or 'BCal' (see <http://bcal.shef.ac.uk/>). The only requirement is to have a csv file containing a sample from the posterior distribution.",2020-05-29,Anne Philippe,NA,TRUE,https://github.com/archaeostat/archaeophases,19960,2,2020-06-09T13:41:13Z,9980
archivist,"Data exploration and modelling is a process in which a lot of data
    artifacts are produced. Artifacts like: subsets, data aggregates, plots,
    statistical models, different versions of data sets and different versions
    of results. The more projects we work with the more artifacts are produced
    and the harder it is to manage these artifacts. Archivist helps to store
    and manage artifacts created in R. Archivist allows you to store selected
    artifacts as a binary files together with their metadata and relations.
    Archivist allows to share artifacts with others, either through shared
    folder or github. Archivist allows to look for already created artifacts by
    using it's class, name, date of the creation or other properties. Makes it
    easy to restore such artifacts. Archivist allows to check if new artifact
    is the exact copy that was produced some time ago. That might be useful
    either for testing or caching.",2019-08-31,Przemyslaw Biecek,https://pbiecek.github.io/archivist/,TRUE,https://github.com/pbiecek/archivist,101647,73,2019-08-26T21:27:49Z,1392.4246575342465
arcos,"A wrapper for the 'ARCOS API' <https://arcos-api.ext.nile.works/__swagger__/>
        that returns raw and summarized data frames from the 
        Drug Enforcement Administration’s Automation of Reports and Consolidated Orders System, 
        a database that monitors controlled substances transactions between manufacturers and 
        distributors which was made public by The Washington Post and The Charleston Gazette-Mail.",2020-05-18,Andrew Ba Tran,https://github.com/wpinvestigative/arcos,TRUE,https://github.com/wpinvestigative/arcos,4654,14,2020-04-20T03:44:32Z,332.42857142857144
ARDL,"Creates complex autoregressive distributed lag (ARDL) models
    providing just the order and automatically constructs the underlying
    unrestricted and restricted error correction model (ECM). It also performs
    the bounds-test for cointegration as described in Pesaran et al. (2001) <doi:10.1002/jae.616> and provides the multipliers and the cointegrating
    equation.",2020-04-10,Kleanthis Natsiopoulos,https://github.com/Natsiopoulos/ARDL,TRUE,https://github.com/natsiopoulos/ardl,1279,2,2020-04-08T23:44:43Z,639.5
areal,"A pipeable, transparent implementation of areal weighted interpolation
    with support for interpolating multiple variables in a single function call.
    These tools provide a full-featured workflow for validation and estimation
    that fits into both modern data management (e.g. tidyverse) and spatial 
    data (e.g. sf) frameworks.",2020-05-12,Christopher Prener,https://github.com/slu-openGIS/areal,TRUE,https://github.com/slu-opengis/areal,10582,64,2020-05-12T11:48:12Z,165.34375
argonDash,"Create awesome 'Bootstrap 4' dashboards powered by 'Argon'.
   See more here <https://rinterface.github.io/argonDash/>.",2019-11-27,David Granjon,https://github.com/RinteRface/argonDash,TRUE,https://github.com/rinterface/argondash,42173,84,2019-11-27T08:13:48Z,502.0595238095238
argonR,"R wrapper around the argon HTML library.
    More at <https://demos.creative-tim.com/argon-design-system/>.",2019-11-27,David Granjon,https://github.com/RinteRface/argonR,TRUE,https://github.com/rinterface/argonr,43416,38,2019-11-27T08:01:44Z,1142.5263157894738
argparse,"A command line parser to
    be used with Rscript to write ""#!"" shebang scripts that gracefully
    accept positional and optional arguments and automatically generate usage.",2019-03-08,Trevor L Davis,https://github.com/trevorld/r-argparse,TRUE,https://github.com/trevorld/r-argparse,582771,47,2020-02-01T09:24:08Z,12399.382978723404
ari,"Create videos from 'R Markdown' documents, or images and audio
    files. These images can come from image files or HTML slides, and the audio
    files can be provided by the user or computer voice narration can be created
    using 'Amazon Polly'. The purpose of this package is to allow users to create
    accessible, translatable, and reproducible lecture videos. See
    <https://aws.amazon.com/polly/> for more information.",2020-02-08,Sean Kross,http://github.com/seankross/ari,TRUE,https://github.com/seankross/ari,14529,83,2020-05-29T16:53:30Z,175.04819277108433
aricode,"Implements an efficient O(n) algorithm based on bucket-sorting for 
    fast computation of standard clustering comparison measures. Available measures
    include adjusted Rand index (ARI), normalized information distance (NID), 
    normalized mutual information (NMI), adjusted mutual information (AMI), 
    normalized variation information (NVI) and entropy, as described in Vinh et al (2009) 
    <doi:10.1145/1553374.1553511>.",2019-06-29,Julien Chiquet,https://github.com/jchiquet/aricode (dev version),TRUE,https://github.com/jchiquet/aricode,11730,8,2019-06-29T06:50:55Z,1466.25
arkdb,"Flat text files provide a robust, compressible, and portable
  way to store tables from databases.  This package provides convenient
  functions for exporting tables from relational database connections
  into compressed text files and streaming those text files back into
  a database without requiring the whole table to fit in working memory.",2018-10-31,Carl Boettiger,https://github.com/ropensci/arkdb,TRUE,https://github.com/ropensci/arkdb,15086,54,2020-03-11T22:18:24Z,279.3703703703704
arkhe,"A collection of classes that represent
    archaeological data. This package provides a set of S4 classes that
    extend the basic matrix data type (absolute/relative frequency,
    presence/absence data, co-occurrence matrix, etc.) upon which package
    developers can build subclasses. It also provides a set of generic
    methods (mutators and coercion mechanisms) and functions (e.g.
    predicates). In addition, a few classes of general interest (e.g. that
    represent stratigraphic relationships) are implemented.",2020-03-23,Nicolas Frerebeau,"http://arkhe.archaeo.science, https://github.com/nfrerebeau/arkhe,
https://cran.r-project.org/package=arkhe",TRUE,https://github.com/nfrerebeau/arkhe,4176,0,2020-05-20T16:51:21Z,NA
arm,"Functions to accompany A. Gelman and J. Hill, Data Analysis Using Regression and Multilevel/Hierarchical Models, Cambridge University Press, 2007.",2020-04-27,Yu-Sung Su,https://CRAN.R-project.org/package=arm,TRUE,https://github.com/suyusung/arm,1577259,16,2020-04-27T02:34:39Z,98578.6875
aroma.affymetrix,A cross-platform R framework that facilitates processing of any number of Affymetrix microarray samples regardless of computer system.  The only parameter that limits the number of chips that can be processed is the amount of available disk space.  The Aroma Framework has successfully been used in studies to process tens of thousands of arrays.  This package has actively been used since 2006.,2019-06-23,Henrik Bengtsson,"https://www.aroma-project.org/,
https://github.com/HenrikBengtsson/aroma.affymetrix",TRUE,https://github.com/henrikbengtsson/aroma.affymetrix,69721,5,2019-12-16T05:47:10Z,13944.2
aroma.cn,"Methods for analyzing DNA copy-number data.  Specifically,
  this package implements the multi-source copy-number normalization (MSCN)
  method for normalizing copy-number data obtained on various platforms and
  technologies.  It also implements the TumorBoost method for normalizing
  paired tumor-normal SNP data.",2015-10-28,Henrik Bengtsson,"http://www.aroma-project.org/,
https://github.com/HenrikBengtsson/aroma.cn",TRUE,https://github.com/henrikbengtsson/aroma.cn,24651,1,2019-12-15T01:58:27Z,24651
aroma.core,"Core methods and classes used by higher-level 'aroma.*' packages
        part of the Aroma Project, e.g. 'aroma.affymetrix' and 'aroma.cn'.",2020-02-04,Henrik Bengtsson,"https://github.com/HenrikBengtsson/aroma.core,
https://www.aroma-project.org/",TRUE,https://github.com/henrikbengtsson/aroma.core,79930,1,2020-02-04T18:11:00Z,79930
arsenal,"An Arsenal of 'R' functions for large-scale statistical summaries,
  which are streamlined to work within the latest reporting tools in 'R' and
  'RStudio' and which use formulas and versatile summary statistics for summary
  tables and models. The primary functions include tableby(), a Table-1-like
  summary of multiple variable types 'by' the levels of one or more categorical
  variables; paired(), a Table-1-like summary of multiple variable types paired across
  two time points; modelsum(), which performs simple model fits on one or more endpoints
  for many variables (univariate or adjusted for covariates);
  freqlist(), a powerful frequency table across many categorical variables;
  comparedf(), a function for comparing data.frames; and
  write2(), a function to output tables to a document.",2020-02-15,Ethan Heinzen,"https://github.com/eheinzen/arsenal,
https://cran.r-project.org/package=arsenal,
https://eheinzen.github.io/arsenal/",TRUE,https://github.com/eheinzen/arsenal,71898,144,2020-05-28T22:29:58Z,499.2916666666667
ARTool,"The Aligned Rank Transform for nonparametric
    factorial ANOVAs as described by J. O. Wobbrock,
    L. Findlater, D. Gergle, & J. J. Higgins, ""The Aligned
    Rank Transform for nonparametric factorial analyses
    using only ANOVA procedures"", CHI 2011 <DOI:10.1145/1978942.1978963>.",2020-03-20,Matthew Kay,https://github.com/mjskay/ARTool,TRUE,https://github.com/mjskay/artool,36708,22,2020-03-11T17:59:09Z,1668.5454545454545
ARTP2,Pathway and gene level association test using raw data or summary statistics.,2018-11-30,Han Zhang,https://github.com/zhangh12/ARTP2,TRUE,https://github.com/zhangh12/artp2,19596,4,2019-08-15T21:39:12Z,4899
arules,"Provides the infrastructure for representing,
    manipulating and analyzing transaction data and patterns (frequent
    itemsets and association rules). Also provides
    C implementations of the association mining algorithms Apriori and Eclat. 
    Hahsler, Gruen and Hornik (2005) <doi:10.18637/jss.v014.i15>.",2020-05-15,Michael Hahsler,https://github.com/mhahsler/arules,TRUE,https://github.com/mhahsler/arules,1539641,119,2020-06-08T14:57:43Z,12938.159663865546
arulesCBA,Provides the infrastructure for association rule-based classification including algorithms like Classification Based on Associations (CBA).,2020-04-20,Michael Hahsler,https://github.com/ianjjohnson/arulesCBA,TRUE,https://github.com/ianjjohnson/arulescba,41233,27,2020-05-09T03:48:08Z,1527.148148148148
arulesNBMiner,NBMiner is an implementation of the model-based mining algorithm for mining NB-frequent itemsets and NB-precise rules. Michael Hahsler (2006) <doi:10.1007/s10618-005-0026-2>. ,2020-04-26,Michael Hahsler,https://github.com/mhahsler/arulesNBMiner,TRUE,https://github.com/mhahsler/arulesnbminer,31586,3,2020-04-26T20:04:43Z,10528.666666666666
arulesViz,Extends package 'arules' with various visualization techniques for association rules and itemsets. The package also includes several interactive visualizations for rule exploration.,2019-05-20,Michael Hahsler,https://github.com/mhahsler/arulesViz,TRUE,https://github.com/mhahsler/arulesviz,733638,33,2020-04-27T16:58:20Z,22231.454545454544
aRxiv,"An interface to the API for 'arXiv'
    (<https://arxiv.org>), a repository of electronic preprints for
    computer science, mathematics, physics, quantitative biology,
    quantitative finance, and statistics.",2019-08-08,Karthik Ram,https://github.com/ropensci/aRxiv,TRUE,https://github.com/ropensci/arxiv,38466,40,2019-12-09T12:01:20Z,961.65
asciiSetupReader,"Lets you open a fixed-width ASCII file (.txt or
    .dat) that has an accompanying setup file (.sps or .sas). These file
    combinations are sometimes referred to as .txt+.sps, .txt+.sas,
    .dat+.sps, or .dat+.sas. This will only run in a txt-sps or txt-sas
    pair in which the setup file contains instructions to open that text
    file. It will NOT open other text files, .sav, .sas, or .por data
    files. Fixed-width ASCII files with setup files are common in older
    (pre-2000) government data.",2020-03-21,Jacob Kaplan,https://github.com/jacobkap/asciiSetupReader,TRUE,https://github.com/jacobkap/asciisetupreader,16489,3,2020-03-20T18:33:32Z,5496.333333333333
ashr,"The R package 'ashr' implements an Empirical Bayes
    approach for large-scale hypothesis testing and false discovery
    rate (FDR) estimation based on the methods proposed in
    M. Stephens, 2016, ""False discovery rates: a new deal"",
    <DOI:10.1093/biostatistics/kxw041>. These methods can be applied
    whenever two sets of summary statistics---estimated effects and
    standard errors---are available, just as 'qvalue' can be applied
    to previously computed p-values. Two main interfaces are
    provided: ash(), which is more user-friendly; and ash.workhorse(),
    which has more options and is geared toward advanced users. The
    ash() and ash.workhorse() also provides a flexible modeling
    interface that can accommodate a variety of likelihoods (e.g.,
    normal, Poisson) and mixture priors (e.g., uniform, normal).",2020-02-20,Peter Carbonetto,https://github.com/stephens999/ashr,TRUE,https://github.com/stephens999/ashr,35356,62,2020-04-08T14:01:08Z,570.258064516129
AsioHeaders,"'Asio' is a cross-platform C++ library for network and low-level
 I/O programming that provides developers with a consistent asynchronous model
 using a modern C++ approach. It is also included in Boost but requires linking
 when used with Boost. Standalone it can be used header-only (provided a recent
 compiler). 'Asio' is written and maintained by Christopher M. Kohlhoff, and
 released under the 'Boost Software License', Version 1.0.",2020-03-11,Dirk Eddelbuettel,NA,TRUE,https://github.com/eddelbuettel/asioheaders,56810,9,2020-05-12T23:09:01Z,6312.222222222223
aslib,"Provides an interface to the algorithm selection benchmark library
    at <http://www.aslib.net> and the 'LLAMA' package
    (<https://cran.r-project.org/package=llama>) for building
    algorithm selection models; see Bischl et al. (2016)
    <doi:10.1016/j.artint.2016.04.003>.",2020-05-24,Bernd Bischl,https://github.com/coseal/aslib-r/,TRUE,https://github.com/coseal/aslib-r,12741,6,2020-05-22T19:56:08Z,2123.5
aSPU,"R codes for the (adaptive) Sum of Powered Score ('SPU' and 'aSPU')
    tests, inverse variance weighted Sum of Powered score ('SPUw' and 'aSPUw') tests
    and gene-based and some pathway based association tests (Pathway based Sum of
    Powered Score tests ('SPUpath'), adaptive 'SPUpath' ('aSPUpath') test, 'GEEaSPU'
    test for multiple traits - single 'SNP' (single nucleotide polymorphism)
    association in generalized estimation equations, 'MTaSPUs' test for multiple
    traits - single 'SNP' association with Genome Wide Association Studies ('GWAS')
    summary statistics, Gene-based Association Test that uses an extended 'Simes'
    procedure ('GATES'), Hybrid Set-based Test ('HYST') and extended version
    of 'GATES' test for pathway-based association testing ('GATES-Simes'). ).
    The tests can be used with genetic and other data sets with covariates. The
    response variable is binary or quantitative. Summary; (1) Single trait-'SNP' set
    association with individual-level data ('aSPU', 'aSPUw', 'aSPUr'), (2) Single trait-'SNP'
    set association with summary statistics ('aSPUs'), (3) Single trait-pathway
    association with individual-level data ('aSPUpath'), (4) Single trait-pathway
    association with summary statistics ('aSPUsPath'), (5) Multiple traits-single
    'SNP' association with individual-level data ('GEEaSPU'), (6) Multiple traits-
    single 'SNP' association with summary statistics ('MTaSPUs'), (7) Multiple traits-'SNP' set association with summary statistics('MTaSPUsSet'), (8) Multiple traits-pathway association with summary statistics('MTaSPUsSetPath').",2020-05-13,Il-Youp Kwak and others,https://github.com/ikwak2/aSPU,TRUE,https://github.com/ikwak2/aspu,29550,5,2020-05-13T04:58:29Z,5910
assignPOP,"Use Monte-Carlo and K-fold cross-validation coupled with machine-
    learning classification algorithms to perform population assignment, with
    functionalities of evaluating discriminatory power of independent training
    samples, identifying informative loci, reducing data dimensionality for genomic
    data, integrating genetic and non-genetic data, and visualizing results.",2020-03-16,Kuan-Yu (Alex) Chen,https://github.com/alexkychen/assignPOP,TRUE,https://github.com/alexkychen/assignpop,19011,10,2020-03-16T13:36:36Z,1901.1
ASSISTant,"Clinical trial design for subgroup selection in three-stage group
    sequential trial. Includes facilities for design, exploration and analysis of
    such trials. An implementation of the initial DEFUSE-3 trial is also provided
    as a vignette.",2019-05-03,Balasubramanian Narasimhan,https://github.com/bnaras/ASSISTant,TRUE,https://github.com/bnaras/assistant,16799,0,2019-11-22T03:30:19Z,NA
astsa,"Data sets and scripts to accompany Time Series Analysis and Its Applications: With R Examples (4th ed), by R.H. Shumway and D.S. Stoffer. Springer Texts in Statistics, 2017, <DOI:10.1007/978-3-319-52452-8>, and Time Series:  A Data Analysis Approach Using R. Chapman-Hall, 2019, <ISBN: 978-0367221096>. ",2020-05-01,David Stoffer,"https://github.com/nickpoison/astsa,
http://www.stat.pitt.edu/stoffer/tsa4/,
http://www.stat.pitt.edu/stoffer/tsda/",TRUE,https://github.com/nickpoison/astsa,300866,44,2020-06-09T19:51:46Z,6837.863636363636
atable,"Create Tables for Reporting Clinical Trials.
  Calculates descriptive statistics and hypothesis tests, 
  arranges the results in a table ready for reporting with LaTeX, HTML or Word.",2020-04-13,Armin Ströbel,https://github.com/arminstroebel/atable,TRUE,https://github.com/arminstroebel/atable,10065,2,2020-04-13T12:09:08Z,5032.5
attachment,"Tools to help manage dependencies during package
    development.  This can retrieve all dependencies that are used in R
    files in the ""R"" directory, in Rmd files in ""vignettes"" directory and
    in 'roxygen2' documentation of functions. There is a function to
    update the Description file of your package and a function to create a
    file with the R commands to install all dependencies of your package.
    All functions to retrieve dependencies of R scripts and Rmd files can
    be used independently of a package development.",2020-03-15,Vincent Guyader,https://github.com/Thinkr-open/attachment,TRUE,https://github.com/thinkr-open/attachment,15143,54,2020-06-03T10:01:45Z,280.4259259259259
attempt,"Tools for defensive programming, inspired by 'purrr' mappers and 
    based on 'rlang'.'attempt' extends and facilitates defensive programming by 
    providing a consistent grammar, and provides a set of easy to use functions 
    for common tests and conditions. 'attempt' only depends on 'rlang', and 
    focuses on speed, so it can be easily integrated in other functions and 
    used in data analysis. ",2020-05-03,Colin Fay,https://github.com/ColinFay/attempt,TRUE,https://github.com/colinfay/attempt,46918,85,2020-04-17T10:38:35Z,551.9764705882353
attenuation,"Confidence curves, confidence intervals and p-values for 
   correlation coefficients corrected for attenuation due to measurement error.
   Implements the methods described in Moss (2019, <arxiv:1911.01576>).",2019-11-08,Jonas Moss,https://github.com/JonasMoss/attenuation/,TRUE,https://github.com/jonasmoss/attenuation,3183,0,2019-11-08T14:26:00Z,NA
auditor,"Provides an easy to use unified interface for creating validation plots for any model. 
  The 'auditor' helps to avoid repetitive work consisting of writing code needed to create residual plots. 
  This visualizations allow to asses and compare the goodness of fit, performance, and similarity of models. ",2020-05-28,Alicja Gosiewska,https://github.com/ModelOriented/auditor,TRUE,https://github.com/modeloriented/auditor,18470,47,2020-05-28T13:26:48Z,392.97872340425533
auk,"Extract and process bird sightings records from
    eBird (<http://ebird.org>), an online tool for recording bird
    observations.  Public access to the full eBird database is via the
    eBird Basic Dataset (EBD; see <http://ebird.org/ebird/data/download>
    for access), a downloadable text file. This package is an interface to
    AWK for extracting data from the EBD based on taxonomic, spatial, or
    temporal filters, to produce a manageable file size that can be
    imported into R.",2020-04-03,Matthew Strimas-Mackey,"https://github.com/CornellLabofOrnithology/auk,
http://CornellLabofOrnithology.github.io/auk/",TRUE,https://github.com/cornelllabofornithology/auk,24565,68,2020-06-09T17:24:17Z,361.25
auth0,"Uses Auth0 API (see <https://auth0.com> for more 
    information) to use a simple and secure authentication system. It provides 
    tools to log in and out a shiny application using social networks or a list
    of e-mails.",2019-09-26,Julio Trecenti,NA,TRUE,https://github.com/curso-r/auth0,10817,78,2020-04-21T21:52:36Z,138.67948717948718
autocogs,Automatically calculates cognostic groups for plot objects and list column plot objects.  Results are returned in a nested data frame.,2020-04-03,Barret Schloerke,https://github.com/schloerke/autocogs,TRUE,https://github.com/schloerke/autocogs,17603,3,2020-04-03T01:11:27Z,5867.666666666667
AutoDeskR,"An interface to the 'AutoDesk' 'API' Platform including the Authentication 
    'API' for obtaining authentication to the 'AutoDesk' Forge Platform, Data Management 
    'API' for managing data across the platform's cloud services, Design Automation 'API'
    for performing automated tasks on design files in the cloud, Model
    Derivative 'API' for translating design files into different formats, sending
    them to the viewer app, and extracting design data, and Viewer for rendering
    2D and 3D models (see <https://developer.autodesk.com> for more information).",2017-07-10,Paul Govan,https://github.com/paulgovan/autodeskr,TRUE,https://github.com/paulgovan/autodeskr,15800,5,2020-04-01T00:47:32Z,3160
autoimage,"Functions for displaying multiple images  or scatterplots with a color 
    scale, i.e., heat maps, possibly with projected coordinates.  The
    package relies on the base graphics system, so graphics are
    rendered rapidly.",2020-05-27,Joshua French,NA,TRUE,https://github.com/jpfrench81/autoimage,24036,5,2020-05-26T20:13:21Z,4807.2
autokeras,"R Interface to 'AutoKeras' <https://autokeras.com/>.
    'AutoKeras' is an open source software library for Automated Machine
    Learning (AutoML). The ultimate goal of AutoML is to provide easily
    accessible deep learning tools to domain experts with limited data science
    or machine learning background. 'AutoKeras' provides functions to
    automatically search for architecture and hyperparameters of deep
    learning models.",2020-02-20,Juan Cruz Rodriguez,https://github.com/r-tensorflow/autokeras,TRUE,https://github.com/r-tensorflow/autokeras,2239,62,2020-02-11T00:05:25Z,36.11290322580645
automultinomial,"Fits the autologistic model described in Besag's famous 1974 paper on auto- models <http://www.jstor.org/stable/2984812>. Fits a multicategory generalization of the autologistic model when there are more than 2 response categories. Provides support for both asymptotic and bootstrap confidence intervals. For full model descriptions and a guide to the use of this package, please see the vignette.",2018-10-31,Stephen Berg,NA,TRUE,https://github.com/stephenberg/automultinomial,14891,4,2019-10-23T21:29:38Z,3722.75
autoplotly,"Functionalities to automatically generate interactive visualizations for
             statistical results supported by 'ggfortify', such as time series, PCA,
             clustering and survival analysis, with 'plotly.js' <https://plot.ly/>  and
             'ggplot2' style. The generated visualizations can also be easily extended
             using 'ggplot2' and 'plotly' syntax while staying interactive.",2018-04-21,Yuan Tang,https://github.com/terrytangyuan/autoplotly,TRUE,https://github.com/terrytangyuan/autoplotly,15715,55,2020-01-23T16:04:32Z,285.72727272727275
autoTS,"Offers a set of functions to easily make predictions for univariate time series. 
             'autoTS' is a wrapper of existing functions of the 'forecast' and 'prophet' packages, 
             harmonising their outputs in tidy dataframes and using default values for each.
             The core function getBestModel() allows the user to effortlessly benchmark seven 
             algorithms along with a bagged estimator to identify which one performs the best 
             for a given time series.",2020-06-05,Vivien Roussez,https://github.com/vivienroussez/autoTS,TRUE,https://github.com/vivienroussez/autots,0,6,2020-06-05T12:31:14Z,0
av,"Bindings to 'FFmpeg' <http://www.ffmpeg.org/> AV library for working with 
    audio and video in R. Generates high quality video from images or R graphics with 
    custom audio. Also offers high performance tools for reading raw audio, creating
    'spectrograms', and converting between countless audio / video formats. This package 
    interfaces directly to the C API and does not require any command line utilities.",2020-01-29,Jeroen Ooms,"https://docs.ropensci.org/av (website),
https://github.com/ropensci/av (devel)",TRUE,https://github.com/ropensci/av,208420,66,2020-05-16T09:48:52Z,3157.878787878788
available,"Check if a given package name is available to use. It checks the
  name's validity. Checks if it is used on 'GitHub', 'CRAN' and 'Bioconductor'. Checks
  for unintended meanings by querying Urban Dictionary, 'Wiktionary' and Wikipedia.",2019-07-19,Jim Hester,https://github.com/ropenscilabs/available,TRUE,https://github.com/ropenscilabs/available,20287,112,2020-05-15T12:01:09Z,181.13392857142858
avar,"Implements the allan variance and allan variance linear regression estimator for latent time series models. More details about the method can be found, for example, in Guerrier, S., Molinari, R., & Stebler, Y. (2016) <doi:10.1109/LSP.2016.2541867>. ",2020-01-15,Stéphane Guerrier,https://github.com/SMAC-Group/avar,TRUE,https://github.com/smac-group/avar,4585,0,2020-01-26T20:39:26Z,NA
AWAPer,"NetCDF files of the Bureau of Meteorology Australian Water Availability Project daily national climate grids are built and used for the efficient extraction of daily point and catchment area weighted precipitation, daily minimum temperature, daily maximum temperature, vapour pressure deficit, solar radiation and various measures of evapotranspiration. For details on the source climate data see <http://www.bom.gov.au/jsp/awap/>.",2020-02-01,Tim Peterson,https://github.com/peterson-tim-j/AWAPer,TRUE,https://github.com/peterson-tim-j/awaper,2364,4,2020-06-02T05:18:06Z,591
aweek,"Which day a week starts depends heavily on the either the local or
  professional context. This package is designed to be a lightweight solution
  to easily switching between week-based date definitions. ",2020-04-29,Zhian N. Kamvar,https://www.repidemicsconsortium.org/aweek,TRUE,https://github.com/reconhub/aweek,30433,10,2019-06-21T14:31:22Z,3043.3
aws.comprehend,"Client for 'AWS Comprehend' <https://aws.amazon.com/comprehend>, a cloud natural language processing service that can perform a number of quantitative text analyses, including language detection, sentiment analysis, and feature extraction.",2020-03-18,Thomas J. Leeper,https://github.com/cloudyr/aws.comprehend,TRUE,https://github.com/cloudyr/aws.comprehend,9276,11,2020-03-18T14:58:34Z,843.2727272727273
aws.ec2metadata,Retrieve Amazon EC2 instance metadata from within the running instance.,2019-07-15,Thomas J. Leeper,https://github.com/cloudyr/aws.ec2metadata,TRUE,https://github.com/cloudyr/aws.ec2metadata,37038411,9,2019-07-15T14:25:30Z,4115379
aws.iam,"A simple client for the Amazon Web Services ('AWS') Identity
    and Access Management ('IAM') 'API' <https://aws.amazon.com/iam/>.",2020-04-07,Thomas J. Leeper,https://github.com/cloudyr/aws.iam,TRUE,https://github.com/cloudyr/aws.iam,22115,10,2020-05-11T04:54:42Z,2211.5
aws.kms,"Client package for the 'AWS Key Management Service' <https://aws.amazon.com/kms/>, a cloud service for managing encryption keys.",2020-04-14,Thomas J. Leeper,https://github.com/cloudyr/aws.kms,TRUE,https://github.com/cloudyr/aws.kms,7226,0,2020-04-13T23:22:47Z,NA
aws.lambda,"A simple client package for the Amazon Web Services ('AWS') Lambda 
    API <https://aws.amazon.com/lambda/>.",2020-04-15,Thomas J. Leeper,https://github.com/cloudyr/aws.lambda,TRUE,https://github.com/cloudyr/aws.lambda,17596,21,2020-04-29T15:53:42Z,837.9047619047619
aws.polly,"A client for AWS Polly <http://aws.amazon.com/documentation/polly>, a speech synthesis service.",2020-03-11,Thomas J. Leeper,https://github.com/cloudyr/aws.polly,TRUE,https://github.com/cloudyr/aws.polly,23628,19,2020-03-18T11:17:18Z,1243.578947368421
aws.s3,"A simple client package for the Amazon Web Services ('AWS') Simple
    Storage Service ('S3') 'REST' 'API' <https://aws.amazon.com/s3/>.",2020-04-07,Simon Urbanek,https://github.com/cloudyr/aws.s3,TRUE,https://github.com/cloudyr/aws.s3,32914965,274,2020-05-27T21:58:33Z,120127.6094890511
aws.signature,"Generates version 2 and version 4 request signatures for Amazon Web Services ('AWS') <https://aws.amazon.com/> Application Programming Interfaces ('APIs') and provides a mechanism for retrieving credentials from environment variables, 'AWS' credentials files, and 'EC2' instance metadata. For use on 'EC2' instances, users will need to install the suggested package 'aws.ec2metadata' <https://cran.r-project.org/package=aws.ec2metadata>.",2020-06-01,Thomas J. Leeper,https://github.com/cloudyr/aws.signature,TRUE,https://github.com/cloudyr/aws.signature,1759157,21,2020-06-01T09:50:45Z,83769.38095238095
aws.transcribe,"Client for 'AWS Transcribe' <https://aws.amazon.com/documentation/transcribe>, a cloud transcription service that can convert an audio media file in English and other languages into a text transcript.",2020-03-11,Thomas J. Leeper,https://github.com/cloudyr/aws.transcribe,TRUE,https://github.com/cloudyr/aws.transcribe,8686,4,2020-03-18T13:11:10Z,2171.5
aws.translate,"A client for 'AWS Translate' <https://aws.amazon.com/documentation/translate>, a machine translation service that will convert a text input in one language into a text output in another language.",2020-03-11,Thomas J. Leeper,https://github.com/cloudyr/aws.translate,TRUE,https://github.com/cloudyr/aws.translate,8735,3,2020-03-18T12:58:06Z,2911.6666666666665
AzureAuth,"Provides Azure Active Directory (AAD) authentication functionality for R users of Microsoft's 'Azure' cloud <https://azure.microsoft.com/>. Use this package to obtain 'OAuth' 2.0 tokens for services including Azure Resource Manager, Azure Storage and others. It supports both AAD v1.0 and v2.0, as well as multiple authentication methods, including device code and resource owner grant. Tokens are cached in a user-specific directory obtained using the 'rappdirs' package. The interface is based on the 'OAuth' framework in the 'httr' package, but customised and streamlined for Azure. Part of the 'AzureR' family of packages.",2020-05-23,Hong Ooi,https://github.com/Azure/AzureAuth https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azureauth,108428,19,2020-05-23T01:25:11Z,5706.736842105263
azuremlsdk,"Interface to the 'Azure Machine Learning' Software Development Kit
    ('SDK'). Data scientists can use the 'SDK' to train, deploy, automate, and
    manage machine learning models on the 'Azure Machine Learning' service. To
    learn more about 'Azure Machine Learning' visit the website:
    <https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml>.",2020-02-05,Heemanshu Suri,https://github.com/azure/azureml-sdk-for-r,TRUE,https://github.com/azure/azureml-sdk-for-r,11969,43,2020-05-20T23:27:58Z,278.3488372093023
AzureRMR,"A lightweight but powerful R interface to the 'Azure Resource Manager' REST API. The package exposes a comprehensive class framework and related tools for creating, updating and deleting 'Azure' resource groups, resources and templates. While 'AzureRMR' can be used to manage any 'Azure' service, it can also be extended by other packages to provide extra functionality for specific services. Part of the 'AzureR' family of packages.",2020-05-15,Hong Ooi,https://github.com/Azure/AzureRMR https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azurermr,111172,7,2020-06-09T11:58:54Z,15881.714285714286
AzureStor,"Manage storage in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/services/storage>. On the admin side, 'AzureStor' includes features to create, modify and delete storage accounts. On the client side, it includes an interface to blob storage, file storage, and 'Azure Data Lake Storage Gen2': upload and download files and blobs; list containers and files/blobs; create containers; and so on. Authenticated access to storage is supported, via either a shared access key or a shared access signature (SAS). Part of the 'AzureR' family of packages.",2020-06-05,Hong Ooi,https://github.com/Azure/AzureStor https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azurestor,109014,18,2020-06-09T13:58:24Z,6056.333333333333
AzureVM,"Functionality for working with virtual machines (VMs) in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/en-us/services/virtual-machines/>. Includes facilities to deploy, startup, shutdown, and cleanly delete VMs and VM clusters. Deployment configurations can be highly customised, and can make use of existing resources as well as creating new ones. A selection of predefined configurations is provided to allow easy deployment of commonly used Linux and Windows images, including Data Science Virtual Machines. With a running VM, execute scripts and install optional extensions. Part of the 'AzureR' family of packages.",2020-02-06,Hong Ooi,https://github.com/Azure/AzureVM https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azurevm,11425,7,2020-02-06T18:11:01Z,1632.142857142857
babelwhale,"Provides a unified interface to interact with 'docker' and 'singularity' containers.
   You can execute a command inside a container, mount a volume or copy a file.",2019-10-03,Robrecht Cannoodt (<https://orcid.org/0000-0003-3641-729X>,https://github.com/dynverse/babelwhale,TRUE,https://github.com/dynverse/babelwhale,7312,10,2019-10-03T13:01:36Z,731.2
BacArena,"Can be used for simulation of organisms living in
    communities (Bauer and Zimmermann (2017) <doi:10.1371/journal.pcbi.1005544>). 
    Each organism is represented individually and genome scale
    metabolic models determine the uptake and release of compounds. Biological
    processes such as movement, diffusion, chemotaxis and kinetics are available
    along with data analysis techniques.",2020-05-20,Johannes Zimmermann,https://BacArena.github.io/,TRUE,https://github.com/euba/bacarena,21783,14,2020-05-20T15:49:49Z,1555.9285714285713
backbone,"Provides methods for extracting from a weighted graph 
    a binary or signed backbone that retains only the significant edges. 
    The user may input a weighted graph, or a bipartite graph 
    from which a weighted graph is first constructed via projection.
    Backbone extraction methods include the stochastic degree sequence model (Neal, Z. P. (2014). <doi:10.1016/j.socnet.2014.06.001>),
    hypergeometric model (Neal, Z. (2013). <doi:10.1007/s13278-013-0107-y>), 
    the fixed degree sequence model (Zweig, K. A., and Kaufmann, M. (2011). <doi:10.1007/s13278-011-0021-0>),
    as well as a universal threshold method. ",2020-05-15,Rachel Domagalski,"https://github.com/domagal9/backbone,
https://www.zacharyneal.com/backbone",TRUE,https://github.com/domagal9/backbone,4293,11,2020-05-19T15:18:54Z,390.27272727272725
backports,"
    Functions introduced or changed since R v3.0.0 are re-implemented in this
    package. The backports are conditionally exported in order to let R resolve
    the function name to either the implemented backport, or the respective base
    version, if available. Package developers can make use of new functions or
    arguments by selectively importing specific backports to
    support older installations.",2020-05-13,Michel Lang,https://github.com/r-lib/backports,TRUE,https://github.com/r-lib/backports,16755091,45,2020-06-06T20:20:07Z,372335.35555555555
badger,Query information and generate badge for using in README and GitHub Pages.,2019-11-15,Guangchuang Yu,https://github.com/GuangchuangYu/badger,TRUE,https://github.com/guangchuangyu/badger,15235,89,2020-06-05T03:43:33Z,171.17977528089887
baggr,"Running and comparing meta-analyses of data with hierarchical 
    Bayesian models in Stan, including convenience functions for formatting
    data, plotting and pooling measures specific to meta-analysis.",2020-02-28,Witold Wiecek,https://github.com/wwiecek/baggr,TRUE,https://github.com/wwiecek/baggr,5302,9,2020-02-27T14:09:39Z,589.1111111111111
baguette,"Tree- and rule-based models can be bagged using 
    this package and their predictions equations are stored 
    in an efficient format to reduce the model objects size 
    and speed. ",2020-04-14,Max Kuhn,https://github.com/tidymodels/baguette,TRUE,https://github.com/tidymodels/baguette,1097,8,2020-04-24T19:44:45Z,137.125
balance,"Balances have become a cornerstone of compositional data analysis. However,
 conceptualizing balances is difficult, especially for high-dimensional data. Most often,
 investigators visualize balances with ""balance dendrograms"". However, this visualization
 tool does not scale well for large data. This package provides an alternative scheme for
 visualizing balances, described in [Quinn (2018) <DOI:10.12688/f1000research.15858.1>].
 This package also provides a method for principal balance analysis.",2019-07-10,Thomas Quinn,http://github.com/tpq/balance,TRUE,https://github.com/tpq/balance,9967,2,2019-07-10T04:47:48Z,4983.5
Ball,"Hypothesis tests and sure independence screening (SIS) procedure based on ball statistics, including ball divergence <doi:10.1214/17-AOS1579>, ball covariance <doi:10.1080/01621459.2018.1543600>, and ball correlation <doi:10.1080/01621459.2018.1462709>, are developed to analyze complex data in metric spaces, e.g, shape, directional, compositional and symmetric positive definite matrix data. The ball divergence and ball covariance based distribution-free tests are implemented to detecting distribution difference and association in metric spaces <arXiv:1811.03750>. Furthermore, several generic non-parametric feature selection procedures based on ball correlation, BCor-SIS and all of its variants, are implemented to tackle the challenge in the context of ultra high dimensional data.",2019-12-17,Xueqin Wang,https://github.com/Mamba413/Ball,TRUE,https://github.com/mamba413/ball,22081,12,2020-05-16T03:00:12Z,1840.0833333333333
bama,"Perform mediation analysis in the presence of high-dimensional
    mediators based on the potential outcome framework. Bayesian Mediation
    Analysis (BAMA), developed by Song et al (2019) <doi:10.1111/biom.13189>,
    relies on two Bayesian sparse linear mixed models to simultaneously analyze
    a relatively large number of mediators for a continuous exposure and outcome
    assuming a small number of mediators are truly active. This sparsity
    assumption also allows the extension of univariate mediator analysis by
    casting the identification of active mediators as a variable selection
    problem and applying Bayesian methods with continuous shrinkage priors on
    the effects.",2020-05-02,Alexander Rix,https://github.com/umich-cphds/bama,TRUE,https://github.com/umich-cphds/bama,3970,0,2020-05-01T14:45:33Z,NA
BAMBI,Fit (using Bayesian methods) and simulate mixtures of univariate and bivariate angular distributions. Chakraborty and Wong (2017) <arXiv:1708.07804> .,2019-12-18,Saptarshi Chakraborty,https://arxiv.org/abs/1708.07804,TRUE,https://github.com/c7rishi/bambi,22297,1,2020-04-23T06:32:07Z,22297
bamboo,"Implementation of the Bamboo methods described in Li, Dahl, Vannucci, Joo, and Tsai (2014) <DOI:10.1371/journal.pone.0109832>.",2020-04-02,David B. Dahl,https://github.com/dbdahl/bamboo,TRUE,https://github.com/dbdahl/bamboo,19345,3,2020-04-02T21:40:17Z,6448.333333333333
bamp,"Bayesian Age-Period-Cohort Modeling and Prediction using efficient Markov Chain Monte Carlo Methods. This is the R version of the previous BAMP software as described in Volker Schmid and Leonhard Held (2007) <DOI:10.18637/jss.v021.i08> Bayesian Age-Period-Cohort Modeling and Prediction - BAMP, Journal of Statistical Software 21:8. This package includes checks of convergence using Gelman's R.",2020-01-23,Volker Schmid,https://volkerschmid.github.io/bamp/,TRUE,https://github.com/volkerschmid/bamp,8608,3,2020-01-21T21:50:12Z,2869.3333333333335
bang,"Provides functions for the Bayesian analysis of some simple 
    commonly-used models, without using Markov Chain Monte Carlo (MCMC) 
    methods such as Gibbs sampling.  The 'rust' package
    <https://cran.r-project.org/package=rust> is used to simulate a random 
    sample from the required posterior distribution, using the generalized 
    ratio-of-uniforms method.  See Wakefield, Gelfand and Smith (1991) 
    <DOI:10.1007/BF01889987> for details. At the moment three conjugate 
    hierarchical models are available: beta-binomial, gamma-Poisson and a 1-way 
    analysis of variance (ANOVA).",2020-02-24,Paul J. Northrop,"https://paulnorthrop.github.io/bang/,
http://github.com/paulnorthrop/bang",TRUE,https://github.com/paulnorthrop/bang,14158,3,2020-02-25T10:20:04Z,4719.333333333333
banR,"A client for the ""Base Adresses Nationale"" (BAN) API, which allows to (batch)
    geocode and reverse-geocode French addresses. For more information about the BAN and its API, please see <https://adresse.data.gouv.fr/api>. ",2020-05-11,Joel Gombin,"http://joelgombin.github.io/banR/,
http://github.com/joelgombin/banR/",TRUE,https://github.com/joelgombin/banr,13837,18,2020-05-11T08:54:10Z,768.7222222222222
BARIS,"Allows the user to access and import data from the rich French open data portal through the provided free API <https://doc.data.gouv.fr/api/reference/>. 
    The portal is free, and no credential is required for extracting datasets. ",2020-05-25,Mohamed El Fodil Ihaddaden,https://github.com/feddelegrand7/BARIS,TRUE,https://github.com/feddelegrand7/baris,1953,13,2020-06-03T12:46:38Z,150.23076923076923
bartCause,Contains a variety of methods to generate typical causal inference estimates using Bayesian Additive Regression Trees (BART) as the underlying regression model (Hill (2012) <doi:10.1198/jcgs.2010.08162>).,2020-04-02,Vincent Dorie,https://github.com/vdorie/bartCause,TRUE,https://github.com/vdorie/bartcause,1163,28,2020-03-31T21:00:54Z,41.535714285714285
baRulho,"Intended to facilitate acoustic analysis of (animal) sound transmission experiments, which typically aim to quantify changes in signal structure when transmitted in a given habitat by broadcasting and re-recording animal sounds at increasing distances. The package offers a workflow with functions to prepare the data set for analysis as well as to calculate and visualize several degradation metrics, including blur ratio, signal-to-noise ratio, excess attenuation and envelope correlation among others (Dabelsteen et al 1993 <doi:10.1121/1.406682>).",2020-06-07,Marcelo Araya-Salas,https://github.com/maRce10/baRulho,TRUE,https://github.com/marce10/barulho,2117,0,2020-05-11T21:35:16Z,NA
BAS,"Package for Bayesian Variable Selection and  Model Averaging 
    in linear models and generalized linear models using stochastic or
    deterministic sampling without replacement from posterior
    distributions.  Prior distributions on coefficients are
    from Zellner's g-prior or mixtures of g-priors
    corresponding to the Zellner-Siow Cauchy Priors or the
    mixture of g-priors from Liang et al (2008)
    <DOI:10.1198/016214507000001337>
    for linear models or mixtures of g-priors from  Li and Clyde
    (2019) <DOI:10.1080/01621459.2018.1469992> in generalized linear models.
    Other model selection criteria include AIC, BIC and Empirical Bayes 
    estimates of g. Sampling probabilities may be updated based on the sampled
    models using sampling w/out replacement or an efficient MCMC algorithm which
    samples models using a tree structure of the model space 
    as an efficient hash table.  See  Clyde, Ghosh and Littman (2010) 
    <DOI:10.1198/jcgs.2010.09049> for  details on the sampling algorithms.
    Uniform priors over all models or beta-binomial prior distributions on
    model size are allowed, and for large p truncated priors on the model
    space may be used to enforce sampling models that are full rank.  
    The user may force variables to always be included in addition to imposing
    constraints that higher order interactions are included only if their 
    parents are included in the model.
    This material is based upon work supported by the National Science
    Foundation under Division of Mathematical Sciences grant 1106891.
    Any opinions, findings, and
    conclusions or recommendations expressed in this material are those of
    the author(s) and do not necessarily reflect the views of the
    National Science Foundation.",2020-01-24,Merlise Clyde,"https://www.r-project.org, https://github.com/merliseclyde/BAS",TRUE,https://github.com/merliseclyde/bas,90339,26,2020-03-09T00:48:42Z,3474.576923076923
base64url,"In contrast to RFC3548, the 62nd character (""+"") is replaced with
    ""-"", the 63rd character (""/"") is replaced with ""_"". Furthermore, the encoder
    does not fill the string with trailing ""="". The resulting encoded strings
    comply to the regular expression pattern ""[A-Za-z0-9_-]"" and thus are
    safe to use in URLs or for file names.
    The package also comes with a simple base32 encoder/decoder suited for
    case insensitive file systems.",2018-05-14,Michel Lang,https://github.com/mllg/base64url,TRUE,https://github.com/mllg/base64url,79794,10,2020-01-11T00:16:27Z,7979.4
basetheme,Functions to create and select graphical themes for the base plotting system. Contains: 1) several custom pre-made themes 2) mechanism for creating new themes by making persistent changes to the graphical parameters of base plots.,2019-10-17,Karolis Koncevičius,https://github.com/KKPMW/basetheme,TRUE,https://github.com/kkpmw/basetheme,7445,84,2019-10-17T23:35:30Z,88.63095238095238
basf,"Resurrects the standard plot for shapes established by the
 'base' and 'graphics' packages. This is suited to workflows that require
 plotting using the established and traditional idioms of plotting spatially
 coincident data where it belongs. This package depends on 'sf' and only replaces 
 the plot method. ",2020-04-15,Michael Sumner,https://github.com/mdsumner/basf,TRUE,https://github.com/mdsumner/basf,1007,0,2020-04-12T13:57:11Z,NA
basictabler,"Easily create tables from data 
    frames/matrices.  Create/manipulate tables 
    row-by-row, column-by-column or cell-by-cell.  
    Use common formatting/styling to output 
    rich tables as 'HTML', 'HTML widgets' or to 
    'Excel'. ",2020-03-07,Christopher Bailiss,https://github.com/cbailiss/basictabler,TRUE,https://github.com/cbailiss/basictabler,16490,23,2020-03-07T10:04:51Z,716.9565217391304
basket,"Implementation of multisource exchangeability models for Bayesian analyses of prespecified subgroups arising in the context of basket trial design and monitoring.  The R 'basket' package facilitates implementation of the binary, symmetric multi-source exchangeability model (MEM) with posterior inference arising from both exact computation and Markov chain Monte Carlo sampling. Analysis output includes full posterior samples as well as posterior probabilities, highest posterior density (HPD) interval boundaries, effective sample sizes (ESS), mean and median estimations, posterior exchangeability probability matrices, and maximum a posteriori MEMs. In addition to providing ""basketwise"" analyses, the package includes similar calculations for ""clusterwise"" analyses for which subgroups are combined into meta-baskets, or clusters, using graphical clustering algorithms that treat the posterior exchangeability probabilities as edge weights. In addition plotting tools are provided to visualize basket and cluster densities as well as their exchangeability.  References include Hyman, D.M., Puzanov, I., Subbiah, V., Faris, J.E., Chau, I., Blay, J.Y., Wolf, J., Raje, N.S., Diamond, E.L., Hollebecque, A. and Gervais, R (2015) <doi:10.1056/NEJMoa1502309>; Hobbs, B.P. and Landin, R. (2018) <doi:10.1002/sim.7893>; Hobbs, B.P., Kane, M.J., Hong, D.S. and Landin, R. (2018) <doi:10.1093/annonc/mdy457>; and Kaizer, A.M., Koopmeiners, J.S. and Hobbs, B.P. (2017) <doi:10.1093/biostatistics/kxx031>.",2020-04-07,Michael J. Kane,https://github.com/kaneplusplus/basket,TRUE,https://github.com/kaneplusplus/basket,5769,1,2020-04-22T22:40:59Z,5769
batata,"
    Allows the user to manage easily R packages removal. It offers many functions to display installed packages according to
    specific dates and removes them if needed. The user is always prompted when running the removal functions in order to confirm
    the required action. It offers also a function that removes all the installed packages in case one wants to switch from one R version 
    to another and start fresh. ",2020-06-09,Mohamed El Fodil Ihaddaden,https://github.com/feddelegrand7/batata,TRUE,https://github.com/feddelegrand7/batata,0,16,2020-06-09T14:07:19Z,0
BatchExperiments,"Extends the BatchJobs package to run statistical experiments on
    batch computing clusters. For further details see the project web page.",2017-11-30,Bernd Bischl,https://github.com/tudo-r/BatchExperiments,TRUE,https://github.com/tudo-r/batchexperiments,33444,15,2020-05-19T20:00:48Z,2229.6
BatchJobs,"Provides Map, Reduce and Filter variants to generate jobs on batch
    computing systems like PBS/Torque, LSF, SLURM and Sun Grid Engine.
    Multicore and SSH systems are also supported. For further details see the
    project web page.",2019-05-14,Bernd Bischl,https://github.com/tudo-r/BatchJobs,TRUE,https://github.com/tudo-r/batchjobs,139938,74,2020-05-19T19:59:59Z,1891.054054054054
batchtools,"As a successor of the packages 'BatchJobs' and 'BatchExperiments',
    this package provides a parallel implementation of the Map function for high
    performance computing systems managed by schedulers 'IBM Spectrum LSF'
    (<https://www.ibm.com/us-en/marketplace/hpc-workload-management>),
    'OpenLava' (<http://www.openlava.org/>), 'Univa Grid Engine'/'Oracle Grid
    Engine' (<http://www.univa.com/>), 'Slurm' (<http://slurm.schedmd.com/>),
    'TORQUE/PBS'
    (<https://adaptivecomputing.com/cherry-services/torque-resource-manager/>),
    or 'Docker Swarm' (<https://docs.docker.com/swarm/>).
    A multicore and socket mode allow the parallelization on a local machines,
    and multiple machines can be hooked up via SSH to create a makeshift
    cluster. Moreover, the package provides an abstraction mechanism to define
    large-scale computer experiments in a well-organized and reproducible way.",2020-03-19,Michel Lang,https://github.com/mllg/batchtools,TRUE,https://github.com/mllg/batchtools,93065,113,2020-05-03T19:35:23Z,823.5840707964602
bayes4psy,Contains several Bayesian models for data analysis of psychological tests. A user friendly interface for these models should enable students and researchers to perform professional level Bayesian data analysis without advanced knowledge in programming and Bayesian statistics. This package is based on the Stan platform (Carpenter et el. 2017 <doi:10.18637/jss.v076.i01>).,2020-02-20,Jure Demšar,https://github.com/bstatcomp/bayes4psy,TRUE,https://github.com/bstatcomp/bayes4psy,5754,3,2020-02-21T10:15:20Z,1918
bayesAB,"A suite of functions that allow the user to analyze A/B test
    data in a Bayesian framework. Intended to be a drop-in replacement for
    common frequentist hypothesis test such as the t-test and chi-sq test.",2019-07-02,Frank Portman,https://github.com/FrankPortman/bayesAB,TRUE,https://github.com/frankportman/bayesab,36276,253,2019-11-13T21:25:11Z,143.38339920948616
bayescopulareg,"Tools for Bayesian copula generalized linear models (GLMs). 
             The sampling scheme is based on Pitt, Chan, and Kohn (2006) <doi:10.1093/biomet/93.3.537>. 
             Regression parameters (including coefficients and dispersion parameters) are
             estimated via the adaptive random walk Metropolis approach developed by
             Haario, Saksman, and Tamminen (1999) <doi:10.1007/s001800050022>.
             The prior for the correlation matrix is based on Hoff (2007) <doi:10.1214/07-AOAS107>.",2020-05-28,Ethan Alt,https://github.com/ethan-alt/bayescopulareg,TRUE,https://github.com/ethan-alt/bayescopulareg,658,0,2020-05-28T00:42:48Z,NA
BayesCTDesign,"A set of functions to help clinical trial researchers calculate power and sample size for two-arm Bayesian randomized clinical trials that do or do not incorporate historical control data.  At some point during the design process, a clinical trial researcher who is designing a basic two-arm Bayesian randomized clinical trial needs to make decisions about power and sample size within the context of hypothesized treatment effects.  Through simulation, the simple_sim() function will estimate power and other user specified clinical trial characteristics at user specified sample sizes given user defined scenarios about treatment effect,control group characteristics, and outcome.  If the clinical trial researcher has access to historical control data, then the researcher can design a two-arm Bayesian randomized clinical trial that incorporates the historical data.  In such a case, the researcher needs to work through the potential consequences of historical and randomized control differences on trial characteristics, in addition to working through issues regarding power in the context of sample size, treatment effect size, and outcome.  If a researcher designs a clinical trial that will incorporate historical control data, the researcher needs the randomized controls to be from the same population as the historical controls.  What if this is not the case when the designed trial is implemented?  During the design phase, the researcher needs to investigate the negative effects of possible historic/randomized control differences on power, type one error, and other trial characteristics.  Using this information, the researcher should design the trial to mitigate these negative effects.  Through simulation, the historic_sim() function will estimate power and other user specified clinical trial characteristics at user specified sample sizes given user defined scenarios about historical and randomized control differences as well as treatment effects and outcomes.  The results from historic_sim() and simple_sim() can be printed with print_table() and graphed with plot_table() methods.  Outcomes considered are Gaussian, Poisson, Bernoulli, Lognormal, Weibull, and Piecewise Exponential.  ",2019-08-02,Barry Eggleston,http://github.com/begglest/BayesCTDesign,TRUE,https://github.com/begglest/bayesctdesign,7694,0,2020-04-21T15:16:58Z,NA
bayesdfa,"Implements Bayesian dynamic factor analysis with 'Stan'. Dynamic 
    factor analysis is a dimension reduction tool for multivariate time series.
    'bayesdfa' extends conventional dynamic factor models in several ways. 
    First, extreme events may be estimated in the latent trend by modeling
    process error with a student-t distribution. Second, autoregressive and 
    moving average components can be optionally included. Third, the estimated
    dynamic factors can be analyzed with hidden Markov models to evaluate
    support for latent regimes.",2019-05-22,Eric J. Ward,https://github.com/fate-ewi/bayesdfa,TRUE,https://github.com/fate-ewi/bayesdfa,10562,17,2020-06-07T20:42:05Z,621.2941176470588
bayesDP,"Functions for data augmentation using the
    Bayesian discount prior function for 1 arm and 2 arm clinical trials.",2020-02-03,Hickey Graeme L.,https://github.com/graemeleehickey/bayesDP,TRUE,https://github.com/graemeleehickey/bayesdp,23200,0,2020-03-16T16:38:09Z,NA
bayesGARCH,"Provides the bayesGARCH() function which performs the
    Bayesian estimation of the GARCH(1,1) model with Student's t innovations as described in Ardia (2008) <doi:10.1007/978-3-540-78657-3>.",2020-04-20,David Ardia,https://github.com/ArdiaD/bayesGARCH,TRUE,https://github.com/ardiad/bayesgarch,40792,4,2020-04-19T20:50:32Z,10198
BayesianNetwork,"A 'Shiny' web application for creating interactive Bayesian Network models,
    learning the structure and parameters of Bayesian networks, and utilities for classic
    network analysis.",2018-12-02,Paul Govan,https://github.com/paulgovan/bayesiannetwork,TRUE,https://github.com/paulgovan/bayesiannetwork,20088,77,2020-03-09T15:33:11Z,260.8831168831169
BayesianTools,"General-purpose MCMC and SMC samplers, as well as plot and
    diagnostic functions for Bayesian statistics, with a particular focus on
    calibrating complex system models. Implemented samplers include various
    Metropolis MCMC variants (including adaptive and/or delayed rejection MH), the
    T-walk, two differential evolution MCMCs, two DREAM MCMCs, and a sequential
    Monte Carlo (SMC) particle filter.",2019-12-09,Florian Hartig,https://github.com/florianhartig/BayesianTools,TRUE,https://github.com/florianhartig/bayesiantools,31878,58,2020-06-03T19:07:47Z,549.6206896551724
BayesLogit,"Tools for sampling from the PolyaGamma distribution based on Polson, Scott, and Windle (2013) <doi:10.1080/01621459.2013.829001>.  Useful for logistic regression.",2019-09-26,Jesse Windle,https://github.com/jwindle/BayesLogit,TRUE,https://github.com/jwindle/bayeslogit,25943,3,2019-09-25T15:20:06Z,8647.666666666666
BayesMallows,"An implementation of the Bayesian version of the Mallows rank model (Vitelli et al., Journal of Machine Learning Research, 2018 <http://jmlr.org/papers/v18/15-481.html>; Crispino et al., to appear in Annals of Applied Statistics). Both Cayley, footrule, Hamming, Kendall, Spearman, and Ulam distances are supported in the models. The rank data to be analyzed can be in the form of complete rankings, top-k rankings, partially missing rankings, as well as consistent and inconsistent pairwise preferences. Several functions for plotting and studying the posterior distributions of parameters are provided. The package also provides functions for estimating the partition function (normalizing constant) of the Mallows rank model, both with the importance sampling algorithm of Vitelli et al. and asymptotic approximation with the IPFP algorithm (Mukherjee, Annals of Statistics, 2016 <doi:10.1214/15-AOS1389>).",2020-03-23,Oystein Sorensen,https://github.com/ocbe-uio/BayesMallows,TRUE,https://github.com/ocbe-uio/bayesmallows,11213,5,2020-05-11T08:38:09Z,2242.6
BayesNetBP,"Belief propagation methods in Bayesian Networks to propagate evidence through the network. The implementation of these methods are based on the article: Cowell, RG (2005). Local Propagation in Conditional Gaussian Bayesian Networks <http://www.jmlr.org/papers/volume6/cowell05a/>. The optional 'cyjShiny' package for running the Shiny app is available at <https://github.com/cytoscape/cyjShiny>. Please see the example in the documentation of 'runBayesNetApp' function for installing 'cyjShiny' package from GitHub.",2020-04-14,Han Yu,NA,TRUE,https://github.com/hyu-ub/bayesnetbp,15588,6,2020-04-10T14:31:37Z,2598
bayesplot,"Plotting functions for posterior analysis, MCMC diagnostics,
    prior and posterior predictive checks, and other visualizations 
    to support the applied Bayesian workflow advocated in
    Gabry, Simpson, Vehtari, Betancourt, and Gelman (2019) <doi:10.1111/rssa.12378>.
    The package is designed not only to provide convenient functionality 
    for users, but also a common set of functions that can be easily used by 
    developers working on a variety of R packages for Bayesian modeling, 
    particularly (but not exclusively) packages interfacing with 'Stan'.",2020-05-28,Jonah Gabry,https://mc-stan.org/bayesplot,TRUE,https://github.com/stan-dev/bayesplot,570039,225,2020-06-03T22:25:37Z,2533.5066666666667
BayesPostEst,"An implementation of functions to generate and plot postestimation quantities after estimating Bayesian regression models using Markov chain Monte Carlo (MCMC). Functionality includes the estimation of the Precision-Recall curves (see Beger, 2016 <doi:10.2139/ssrn.2765419>), the implementation of the observed values method of calculating predicted probabilities by Hanmer and Kalkan (2013) <doi:10.1111/j.1540-5907.2012.00602.x>, the implementation of the average value method of calculating predicted probabilities (see King, Tomz, and Wittenberg, 2000 <doi:10.2307/2669316>), and the generation and plotting of first differences to summarize typical effects across covariates (see Long 1997, ISBN:9780803973749; King, Tomz, and Wittenberg, 2000 <doi:10.2307/2669316>). This package can be used with MCMC output generated by any Bayesian estimation tool including 'JAGS', 'BUGS', 'MCMCpack', and 'Stan'.",2020-05-28,Johannes Karreth,https://github.com/ShanaScogin/BayesPostEst,TRUE,https://github.com/shanascogin/bayespostest,4379,6,2020-06-09T23:26:05Z,729.8333333333334
BayesSampling,"Allows the user to apply the Bayes Linear approach to finite population with the Simple Random Sampling - BLE_SRS() - and
    the Stratified Simple Random Sampling design - BLE_SSRS() - (both without replacement) and to the Ratio estimator (using auxiliary
    information) - BLE_Ratio().     
    The Bayes linear estimation approach is applied to a general linear regression model for finite population prediction in BLE_Reg()
    and it is also possible to achieve the design based estimators using vague prior distributions.    
    Based on Gonçalves, K.C.M, Moura, F.A.S and  Migon, H.S.(2014) <https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X201400111886>.",2020-04-24,Pedro Soares Figueiredo,"https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X201400111886,
https://github.com/pedrosfig/BayesSampling",TRUE,https://github.com/pedrosfig/bayessampling,684,1,2020-04-20T13:25:01Z,684
bayestestR,"Provides utilities to describe posterior distributions and Bayesian models. It includes point-estimates such as Maximum A Posteriori (MAP), measures of dispersion (Highest Density Interval - HDI; Kruschke, 2015 <doi:10.1016/C2012-0-00477-2>) and indices used for null-hypothesis testing (such as ROPE percentage, pd and Bayes factors).",2020-04-20,Dominique Makowski,https://easystats.github.io/bayestestR/,TRUE,https://github.com/easystats/bayestestr,264586,219,2020-05-29T08:35:47Z,1208.1552511415525
BayesVarSel,"Conceived to calculate Bayes factors in Linear models and then to provide a formal Bayesian answer to testing and variable selection problems. From a theoretical side, the emphasis in this package is placed on the prior distributions and it allows a wide range of them: Jeffreys (1961); Zellner and Siow(1980)<DOI:10.1007/bf02888369>; Zellner and Siow(1984); Zellner (1986)<DOI:10.2307/2233941>; Fernandez et al. (2001)<DOI:10.1016/s0304-4076(00)00076-2>; Liang et al. (2008)<DOI:10.1198/016214507000001337>  and Bayarri et al. (2012)<DOI:10.1214/12-aos1013>. The interaction with the package is through a friendly interface that syntactically mimics the well-known lm() command of R. The resulting objects can be easily explored providing the user very valuable information (like marginal, joint and conditional inclusion probabilities of potential variables; the highest posterior probability model, HPM; the median probability model, MPM) about the structure of the true -data generating- model. Additionally, this package incorporates abilities to handle problems with a large number of potential explanatory variables through parallel and heuristic versions of the main commands, Garcia-Donato and Martinez-Beneito (2013)<DOI:10.1080/01621459.2012.742443>. It also allows problems with p>n and p>>n and also incorporates routines to handle problems with variable selection with factors.",2020-02-18,Anabel Forte,https://github.com/comodin19/BayesVarSel,TRUE,https://github.com/comodin19/bayesvarsel,32299,5,2020-05-19T09:12:54Z,6459.8
bayesvl,"Provides users with its associated functions for pedagogical purposes in visually learning Bayesian networks and Markov chain Monte Carlo (MCMC) computations. It enables users to: a) Create and examine the (starting) graphical structure of Bayesian networks; b) Create random Bayesian networks using a dataset with customized constraints; c) Generate 'Stan' code for structures of Bayesian networks for sampling the data and learning parameters; d) Plot the network graphs; e) Perform Markov chain Monte Carlo computations and produce graphs for posteriors checks. The package refers to one reference item, which describes the methods and algorithms: Vuong, Quan-Hoang and La, Viet-Phuong (2019) <doi:10.31219/osf.io/w5dx6> The 'bayesvl' R package. Open Science Framework (May 18).",2019-05-24,Viet-Phuong La,https://github.com/sshpa/bayesvl,TRUE,https://github.com/sshpa/bayesvl,4929,4,2020-05-09T11:01:32Z,1232.25
BayLum,"Bayesian analysis of luminescence data and C-14 age estimates. Bayesian models are based on the following publications: Combes, B. & Philippe, A. (2017) <doi:10.1016/j.quageo.2017.02.003> and Combes et al (2015) <doi:10.1016/j.quageo.2015.04.001>. This includes, amongst others, data import, export, application of age models and palaeodose model.",2018-09-19,Anne Philippe,NA,TRUE,https://github.com/r-lum/baylum,13738,3,2020-05-27T20:59:26Z,4579.333333333333
baymedr,"BAYesian inference for MEDical designs in R. Convenience functions 
    for the computation of Bayes factors for common biomedical research 
    designs. Implemented are functions to test the equivalence (equiv_bf), 
    non-inferiority (infer_bf), and superiority (super_bf) of an experimental 
    group compared to a control group. Bayes factors for these three tests can
    be computed based on raw data (x, y) or summary statistics (n_x, n_y,
    mean_x, mean_y, sd_x, sd_y [or ci_margin and ci_level]), making it possible 
    to reanalyse findings (e.g., from publications) without the need to obtain 
    the raw data.",2019-10-21,Maximilian Linde,https://github.com/maxlinde/baymedr,TRUE,https://github.com/maxlinde/baymedr,3322,0,2019-10-17T12:04:48Z,NA
baytrends,"Enable users to evaluate long-term trends using a Generalized 
    Additive Modeling (GAM) approach. The model development includes selecting a 
    GAM structure to describe nonlinear seasonally-varying changes over time, 
    incorporation of hydrologic variability via either a river flow or salinity, 
    the use of an intervention to deal with method or laboratory changes 
    suspected to impact data values, and representation of left- and 
    interval-censored data. The approach has been applied to water quality data 
    in the Chesapeake Bay, a major estuary on the east coast of the United 
    States to provide insights to a range of management- and research-focused 
    questions.",2020-03-31,Rebecca Murphy,https://github.com/tetratech/baytrends,TRUE,https://github.com/tetratech/baytrends,9346,3,2020-03-31T16:03:19Z,3115.3333333333335
bazar,"A collection of miscellaneous functions for 
    copying objects to the clipboard ('Copy');
    manipulating strings ('concat', 'mgsub', 'trim', 'verlan'); 
    loading or showing packages ('library_with_dep', 'require_with_dep', 
    'sessionPackages'); 
    creating or testing for named lists ('nlist', 'as.nlist', 'is.nlist'), 
    formulas ('is.formula'), empty objects ('as.empty', 'is.empty'), 
    whole numbers ('as.wholenumber', 'is.wholenumber'); 
    testing for equality ('almost.equal', 'almost.zero') and computing 
    uniqueness ('almost.unique'); 
    getting modified versions of usual functions ('rle2', 'sumNA'); 
    making a pause or a stop ('pause', 'stopif'); 
    converting into a function ('as.fun'); 
    providing a C like ternary operator ('condition %?% true %:% false'); 
    finding packages and functions ('get_all_pkgs', 'get_all_funs');
    and others ('erase', '%nin%', 'unwhich', 'top', 'bot', 'normalize'). ",2019-03-15,Paul Poncet,https://github.com/paulponcet/bazar,TRUE,https://github.com/paulponcet/bazar,78202,0,2019-07-13T23:51:42Z,NA
BBmisc,"Miscellaneous helper functions for and from B. Bischl and
    some other guys, mainly for package development.",2017-03-10,Bernd Bischl,https://github.com/berndbischl/BBmisc,TRUE,https://github.com/berndbischl/bbmisc,561546,13,2020-05-25T08:07:27Z,43195.846153846156
bbmle,Methods and functions for fitting maximum likelihood models in R.,2020-02-03,Ben Bolker,https://github.com/bbolker/bbmle,TRUE,https://github.com/bbolker/bbmle,366916,14,2020-04-29T00:21:36Z,26208.285714285714
bbricks,"A set of frequently used Bayesian parametric and nonparametric model structures, as well as a set of tools for common analytical tasks. Structures include linear Gaussian systems, Gaussian and Normal-Inverse-Wishart conjugate structure, Gaussian and Normal-Inverse-Gamma conjugate structure, Categorical and Dirichlet conjugate structure, Dirichlet Process on positive integers, Dirichlet Process in general, Hierarchical Dirichlet Process ... Tasks include updating posteriors, sampling from posteriors, calculating marginal likelihood, calculating posterior predictive densities, sampling from posterior predictive distributions, calculating ""Maximum A Posteriori"" (MAP) estimates ... See <https://chenhaotian.github.io/Bayesian-Bricks/> to get started.",2020-05-07,Haotian Chen,https://github.com/chenhaotian/Bayesian-Bricks,TRUE,https://github.com/chenhaotian/bayesian-bricks,1790,3,2020-05-07T19:04:49Z,596.6666666666666
bbsBayes,"The North American Breeding Bird Survey (BBS) is a long-running
  program that seeks to monitor the status and trends of the breeding birds in
  North America. Since its start in 1966, the BBS has accumulated over 50 years 
  of data for over 300 species of North American Birds. Given the temporal and 
  spatial structure of the data, hierarchical Bayesian models are used to assess 
  the status and trends of these 300+ species of birds. 'bbsBayes' allows you to perform 
  hierarchical Bayesian analysis of BBS data. You can run a full
  model analysis for one or more species that you choose, or you can take
  more control and specify how the data should be stratified, prepared
  for 'JAGS', or modelled. The functions provided here allow you to replicate
  analyses performed by the United State Geological Survey (USGS, see Link 
  and Sauer (2011) <doi:10.1525/auk.2010.09220>) and Canadian Wildlife Service
  (CWS, see Smith and Edwards (2020) <doi:10.1101/2020.03.26.010215>).",2020-05-31,Brandon P.M. Edwards,https://github.com/BrandonEdwards/bbsBayes,TRUE,https://github.com/brandonedwards/bbsbayes,136,12,2020-05-30T20:04:14Z,11.333333333333334
bbw,"The blocked weighted bootstrap (BBW) is an estimation technique 
    for use with data from two-stage cluster sampled surveys in which either 
    prior weighting (e.g. population-proportional sampling or PPS as used in 
    Standardized Monitoring and Assessment of Relief and Transitions or SMART 
    surveys) or posterior weighting (e.g. as used in rapid assessment method or
    RAM and simple spatial sampling method or S3M surveys). The method was 
    developed by Accion Contra la Faim, Brixton Health, Concern Worldwide, 
    Global Alliance for Improved Nutrition, UNICEF Sierra Leone,  UNICEF Sudan
    and Valid International. It has been tested by the Centers for Disease
    Control (CDC) using infant and young child feeding (IYCF) data. See Cameron
    et al (2008) <doi:10.1162/rest.90.3.414> for application of bootstrap
    to cluster samples. See Aaron et al (2016) <doi:10.1371/journal.pone.0163176> 
    and Aaron et al (2016) <doi:10.1371/journal.pone.0162462> for application 
    of the blocked weighted bootstrap to estimate indicators from two-stage 
    cluster sampled surveys.",2018-01-17,Mark Myatt,https://github.com/validmeasures/bbw,TRUE,https://github.com/validmeasures/bbw,10257,2,2020-01-05T22:36:22Z,5128.5
bcdata,"Search, query, and download tabular and
    'geospatial' data from the British Columbia Data Catalogue
    (<https://catalogue.data.gov.bc.ca/>).  Search catalogue data records
    based on keywords, data licence, sector, data format, and B.C.
    government organization. View metadata directly in R, download many
    data formats, and query 'geospatial' data available via the B.C.
    government Web Feature Service ('WFS') using 'dplyr' syntax.",2019-12-17,Andy Teucher,"https://bcgov.github.io/bcdata/,
https://catalogue.data.gov.bc.ca/,
https://github.com/bcgov/bcdata",TRUE,https://github.com/bcgov/bcdata,3949,45,2020-06-04T23:32:36Z,87.75555555555556
Bchron,"Enables quick calibration of radiocarbon dates under various 
  calibration curves (including user generated ones); age-depth modelling 
  as per the algorithm of Haslett and Parnell (2008) <DOI:10.1111/j.1467-9876.2008.00623.x>; Relative sea level 
  rate estimation incorporating time uncertainty in polynomial regression 
  models (Parnell and Gehrels 2015) <DOI:10.1002/9781118452547.ch32>; non-parametric phase modelling via 
  Gaussian mixtures as a means to determine the activity of a site 
  (and as an alternative to the Oxcal function SUM; currently 
  unpublished), and reverse calibration of dates from calibrated into 
  un-calibrated years (also unpublished).",2020-04-13,Andrew Parnell,http://andrewcparnell.github.io/Bchron/,TRUE,https://github.com/andrewcparnell/bchron,48248,17,2020-04-13T12:00:31Z,2838.1176470588234
bcmaps,"Provides access to various spatial layers for B.C., such as 
    administrative boundaries, natural resource management boundaries, etc. 
    All layers are imported from the 'bcmapsdata' package as 'sf' or 'Spatial' objects
    through function calls in this package. All layers are in B.C. 'Albers' equal-area projection 
    <http://spatialreference.org/ref/epsg/nad83-bc-albers/>, which is the B.C. 
    government standard.",2020-04-29,Andy Teucher,https://github.com/bcgov/bcmaps,TRUE,https://github.com/bcgov/bcmaps,13558,42,2020-04-28T16:41:00Z,322.8095238095238
bcrm,"Implements a wide variety of one- and two-parameter Bayesian CRM
    designs. The program can run interactively, allowing the user to enter outcomes
    after each cohort has been recruited, or via simulation to assess operating
    characteristics. See Sweeting et al. (2013): <doi:10.18637/jss.v054.i13>.",2019-08-23,Graham Wheeler,https://github.com/mikesweeting/bcrm,TRUE,https://github.com/mikesweeting/bcrm,30575,0,2019-08-19T09:40:49Z,NA
bcTSNE,"Implements the projected t-SNE method for batch correction of 
  high-dimensional data. Please see Aliverti et al. (2020) 
  <doi:10.1093/bioinformatics/btaa189> for more information.",2020-04-28,Dayne L Filer,https://github.com/emanuelealiverti/BC_tSNE,TRUE,https://github.com/emanuelealiverti/bc_tsne,660,4,2020-04-15T14:38:19Z,165
bdchecks,Supplies a Shiny app and a set of functions to perform and managing data checks for biodiversity data. ,2019-02-18,Povilas Gibas,https://github.com/bd-R/bdchecks,TRUE,https://github.com/bd-r/bdchecks,6698,1,2020-03-28T04:33:26Z,6698
bdclean,"Provides features to manage the complete workflow for biodiversity data cleaning. Uploading data, gathering input from users (in order to adjust cleaning procedures), cleaning data and finally, generating various reports and several versions of the data. Facilitates user-level data cleaning, designed for the inexperienced R user. T Gueta et al (2018) <doi:10.3897/biss.2.25564>. T Gueta et al (2017) <doi:10.3897/tdwgproceedings.1.20311>.",2019-04-11,Thiloshon Nagarajah,"https://github.com/bd-R/bdclean,
https://bd-r.github.io/The-bdverse/index.html",TRUE,https://github.com/bd-r/bdclean,5786,5,2020-05-16T10:51:58Z,1157.2
bdl,"Interface to Local Data Bank ('Bank Danych Lokalnych' - 'bdl') API 
    <https://api.stat.gov.pl/Home/BdlApi?lang=en> with set of useful tools like 
    quick plotting and map generating using data from bank. ",2020-04-01,Artur Sławomirski,https://github.com/statisticspoland/R_Package_to_API_BDL,TRUE,https://github.com/statisticspoland/r_package_to_api_bdl,3656,10,2020-03-29T21:54:24Z,365.6
bdpar,"
        Provide a tool to easily build customized data flows to pre-process large volumes 
    of information from different sources. To this end, 'bdpar' allows to (i) easily use and 
    create new functionalities and (ii) develop new data source extractors according to the 
    user needs. Additionally, the package provides by default a predefined data flow 
    to extract and pre-process the most relevant information (tokens, dates, ... ) from some textual 
    sources (SMS, Email, tweets, YouTube comments).",2020-02-20,Miguel Ferreiro-Díaz,https://github.com/miferreiro/bdpar,TRUE,https://github.com/miferreiro/bdpar,4928,4,2020-02-20T09:47:40Z,1232
beakr,"A minimalist web framework for developing application programming 
    interfaces in R that provides a flexible framework for handling common 
    HTTP-requests, errors, logging, and an ability to integrate any R code as 
    server middle-ware.",2020-02-10,Jonathan Callahan,https://github.com/MazamaScience/beakr,TRUE,https://github.com/mazamascience/beakr,2069,55,2020-02-21T22:35:38Z,37.61818181818182
beam,"Fast Bayesian inference of marginal and conditional independence structures from high-dimensional data. Leday and Richardson (2019), Biometrics, <doi:10.1111/biom.13064>.",2020-05-28,Gwenael G.R. Leday,https://github.com/gleday/beam,TRUE,https://github.com/gleday/beam,11032,0,2020-05-28T17:52:32Z,NA
beats,"Import and process electrocardiogram (ECG) data.
    Reads binary data files from UFI devices (.ube files) and provides a
    Shiny app for finding and exporting heart beats.",2020-02-28,Max Czapanskiy,https://github.com/FlukeAndFeather/beats,TRUE,https://github.com/flukeandfeather/beats,1812,1,2020-02-20T15:59:05Z,1812
beautier,"'BEAST2' (<https://www.beast2.org>) is a widely used
  Bayesian phylogenetic tool, that uses DNA/RNA/protein data
  and many model priors to create a posterior of jointly estimated 
  phylogenies and parameters.
  'BEAUti 2' (which is part of 'BEAST2') is a GUI tool 
  that allows users to specify the many possible setups
  and generates the XML file 'BEAST2' needs to run.
  This package provides a way to create 'BEAST2' input
  files without active user input, but using
  R function calls instead.",2020-05-06,Richèl J.C. Bilderbeek,"https://docs.ropensci.org/beautier,
https://github.com/ropensci/beautier",TRUE,https://github.com/ropensci/beautier,9420,6,2020-04-22T11:56:07Z,1570
BEDMatrix,"A matrix-like data structure that allows for efficient,
    convenient, and scalable subsetting of binary genotype/phenotype files
    generated by PLINK (<https://www.cog-genomics.org/plink2>), the whole
    genome association analysis toolset, without loading the entire file into
    memory.",2020-03-11,Alexander Grueneberg,https://github.com/QuantGen/BEDMatrix,TRUE,https://github.com/quantgen/bedmatrix,26565,10,2020-03-11T17:54:51Z,2656.5
beezdemand,"Facilitates many of the analyses performed in studies of
    behavioral economic demand. The package supports commonly-used options for
		modeling operant demand including (1) data screening proposed by Stein,
		Koffarnus, Snider, Quisenberry, & Bickel (2015; <doi:10.1037/pha0000020>),
		(2) fitting models of demand such as linear (Hursh, Raslear, Bauman,
		& Black, 1989, <doi:10.1007/978-94-009-2470-3_22>), exponential	(Hursh & Silberberg, 2008,
		<doi:10.1037/0033-295X.115.1.186>) and modified exponential (Koffarnus,
		Franck, Stein, & Bickel, 2015, <doi:10.1037/pha0000045>), and (3) calculating
		numerous measures	relevant to applied behavioral economists (Intensity,
		Pmax, Omax). Also	supports plotting and comparing data.",2018-07-31,Brent Kaplan,https://github.com/brentkaplan/beezdemand,TRUE,https://github.com/brentkaplan/beezdemand,8349,8,2020-06-08T15:57:20Z,1043.625
beginr,"Useful functions for R beginners, including hints for the arguments of the 'plot()' function, self-defined functions for error bars, user-customized pair plots and hist plots, enhanced linear regression figures, etc.. This package could be helpful to R experts as well.",2019-05-02,Peng Zhao,https://github.com/pzhaonet/beginr,TRUE,https://github.com/pzhaonet/beginr,16187,12,2020-02-10T08:52:24Z,1348.9166666666667
behavr,Implements an S3 class based on 'data.table' to store and process efficiently ethomics (high-throughput behavioural) data.,2019-01-03,Quentin Geissmann,https://github.com/rethomics/behavr,TRUE,https://github.com/rethomics/behavr,12218,4,2020-06-09T01:45:46Z,3054.5
belg,"Calculates the Boltzmann entropy of a landscape gradient.
    This package uses the analytical method created by Gao, P., Zhang, H.
    and Li, Z., 2018 (<doi:10.1111/tgis.12315>) and by Gao, P. and Li, Z., 2019
    (<doi:10.1007/s10980-019-00854-3>). It also extend the original ideas by
    allowing calculations on data with missing values.",2020-04-01,Jakub Nowosad,https://r-spatialecology.github.io/belg/,TRUE,https://github.com/r-spatialecology/belg,12220,9,2020-04-29T12:16:21Z,1357.7777777777778
bench,Tools to accurately benchmark and analyze execution times for R expressions.,2020-01-13,Jim Hester,https://github.com/r-lib/bench,TRUE,https://github.com/r-lib/bench,72927,176,2020-05-20T12:43:06Z,414.35795454545456
benchmarkme,"Benchmark your CPU and compare against other CPUs.
    Also provides functions for obtaining system specifications, such as
    RAM, CPU type, and R version.",2020-05-09,Colin Gillespie,https://github.com/csgillespie/benchmarkme,TRUE,https://github.com/csgillespie/benchmarkme,52838,27,2020-05-09T20:59:15Z,1956.962962962963
benchmarkmeData,"Crowd sourced benchmarks from running the
    'benchmarkme' package.",2020-04-23,Colin Gillespie,https://github.com/csgillespie/benchmarkme-data,TRUE,https://github.com/csgillespie/benchmarkme-data,52627,1,2020-04-23T14:31:48Z,52627
benford.analysis,Provides tools that make it easier to validate data using Benford's Law.,2018-12-21,Carlos Cinelli,http://github.com/carloscinelli/benford.analysis,TRUE,https://github.com/carloscinelli/benford.analysis,36968,28,2019-08-24T05:04:03Z,1320.2857142857142
berryFunctions,"Draw horizontal histograms, color scattered points by 3rd dimension,
    enhance date- and log-axis plots, zoom in X11 graphics, trace errors and warnings, 
    use the unit hydrograph in a linear storage cascade, convert lists to data.frames and arrays, 
    fit multiple functions.",2020-06-06,Berry Boessenkool,https://github.com/brry/berryFunctions,TRUE,https://github.com/brry/berryfunctions,61949,8,2020-06-09T12:04:45Z,7743.625
BEST,"An alternative to t-tests, producing posterior estimates
  for group means and standard deviations and their differences and
  effect sizes.",2020-05-18,John K. Kruschke and Mike Meredith,NA,TRUE,https://github.com/mikemeredith/best,50153,15,2020-05-22T06:35:25Z,3343.5333333333333
bestNormalize,"Estimate a suite of normalizing transformations, including 
    a new adaptation of a technique based on ranks which can guarantee 
    normally distributed transformed data if there are no ties: ordered 
    quantile normalization (ORQ). ORQ normalization combines a rank-mapping
    approach with a shifted logit approximation that allows
    the transformation to work on data outside the original domain. It is 
    also able to handle new data within the original domain via linear 
    interpolation. The package is built to estimate the best normalizing 
    transformation for a vector consistently and accurately. It implements 
    the Box-Cox transformation, the Yeo-Johnson transformation, three types 
    of Lambert WxF transformations, and the ordered quantile normalization 
    transformation. It also estimates the normalization efficacy of other
    commonly used transformations, and finally it allows users to specify 
    custom transformations or normalization statistics.",2020-06-08,Ryan Andrew Peterson,https://github.com/petersonR/bestNormalize,TRUE,https://github.com/petersonr/bestnormalize,95532,17,2020-06-09T14:14:52Z,5619.529411764706
bets.covid19,"Implements likelihood inference for early epidemic analysis. BETS is short for the four key epidemiological events being modeled: Begin of exposure, End of exposure, time of Transmission, and time of Symptom onset. The package contains a dataset of the trajectory of confirmed cases during the coronavirus disease (COVID-19) early outbreak. More detail of the statistical methods can be found in Zhao et al. (2020) <arXiv:2004.07743>.",2020-05-12,Qingyuan Zhao,https://github.com/qingyuanzhao/bets.covid19,TRUE,https://github.com/qingyuanzhao/bets.covid19,463,26,2020-06-01T18:24:53Z,17.807692307692307
BFpack,"Implementation of various default Bayes factors
    for testing statistical hypotheses. The package is
    intended for applied quantitative researchers in the
    social and behavioral sciences, medical research,
    and related fields. The Bayes factor tests can be
    executed for statistical models such as 
    univariate and multivariate normal linear models,
    generalized linear models, special cases of 
    linear mixed models, survival models, relational
    event models. Parameters that can be tested are
    location parameters (e.g., regression coefficients),
    variances (e.g., group variances), and measures of 
    association (e.g,. bivariate correlations).
    The statistical underpinnings are
    described in 
    Mulder, Hoijtink, and Xin (2019) <arXiv:1904.00679>,
    Mulder and Gelissen (2019) <arXiv:1807.05819>,
    Mulder (2016) <DOI:10.1016/j.jmp.2014.09.004>,
    Mulder and Fox (2019) <DOI:10.1214/18-BA1115>,
    Mulder and Fox (2013) <DOI:10.1007/s11222-011-9295-3>,
    Boeing-Messing, van Assen, Hofman, Hoijtink, and Mulder <DOI:10.1037/met0000116>,
    Hoijtink, Mulder, van Lissa, and Gu, (2018) <DOI:10.31234/osf.io/v3shc>,
    Gu, Mulder, and Hoijtink, (2018) <DOI:10.1111/bmsp.12110>,
    Hoijtink, Gu, and Mulder, (2018) <DOI:10.1111/bmsp.12145>, and
    Hoijtink, Gu, Mulder, and Rosseel, (2018) <DOI:10.1037/met0000187>.",2020-05-11,Joris Mulder,https://github.com/jomulder/BFpack,TRUE,https://github.com/jomulder/bfpack,4090,6,2020-05-22T15:03:18Z,681.6666666666666
BFS,Search and download data from the Swiss Federal Statistical Office <https://www.bfs.admin.ch/>.,2020-03-25,Félix Luginbuhl,"https://felixluginbuhl.com/BFS, https://github.com/lgnbhl/BFS",TRUE,https://github.com/lgnbhl/bfs,3996,4,2020-03-30T16:58:08Z,999
bfsl,"Provides the solution from York (1968) <doi:10.1016/S0012-821X(68)80059-7>
  for fitting a straight line to bivariate data with errors in both coordinates.
  It gives unbiased estimates of the intercept, slope and standard errors of the
  best-fit straight line to independent points with (possibly correlated) 
  normally distributed errors in both x and y. Other commonly used 
  errors-in-variables methods, such as orthogonal distance regression, geometric
  mean regression or Deming regression are special cases of York’s solution.",2018-12-16,Patrick Sturm,https://github.com/pasturm/bfsl,TRUE,https://github.com/pasturm/bfsl,6165,0,2020-04-17T10:26:03Z,NA
bfsMaps,"At the Swiss Federal Statistical Office (SFSO), spatial maps of Switzerland are available free of charge as 'Cartographic bases for small-scale thematic mapping'. This package contains convenience functions to import ESRI (Environmental Systems Research Institute) shape files using the package 'rgdal' and to plot them easily and quickly without having to worry too much about the technical details.
      It contains utilities to combine multiple areas to one single polygon and to find neighbours for single regions. For any point on a map, a special locator can be used to determine to which municipality, district or canton it belongs.",2020-04-17,Andri Signorell,https://github.com/AndriSignorell/bfsMaps/,TRUE,https://github.com/andrisignorell/bfsmaps,1275,0,2020-04-28T15:45:34Z,NA
bfw,"Derived from the work of Kruschke (2015, <ISBN:9780124058880>),
    the present package aims to provide a framework for conducting Bayesian
    analysis using Markov chain Monte Carlo (MCMC) sampling utilizing the
    Just Another Gibbs Sampler ('JAGS', Plummer, 2003, <http://mcmc-jags.sourceforge.net/>).
    The initial version includes several modules for conducting Bayesian
    equivalents of chi-squared tests, analysis of variance (ANOVA),
    multiple (hierarchical) regression, softmax regression, and for fitting data
    (e.g., structural equation modeling).",2019-11-25,Øystein Olav Skaar,https://github.com/oeysan/bfw/,TRUE,https://github.com/oeysan/bfw,11096,9,2019-11-25T08:02:17Z,1232.888888888889
BGData,"An umbrella package providing a phenotype/genotype data structure
    and scalable and efficient computational methods for large genomic datasets
    in combination with several other packages: 'BEDMatrix', 'LinkedMatrix',
    and 'symDMatrix'.",2019-01-25,Alexander Grueneberg,https://github.com/QuantGen/BGData,TRUE,https://github.com/quantgen/bgdata,14333,17,2020-05-12T21:18:25Z,843.1176470588235
BGGM,"Fit Bayesian Gaussian graphical models. The methods are separated into 
    two Bayesian approaches for inference: hypothesis testing and estimation. There are 
    extensions for confirmatory hypothesis testing, comparing Gaussian graphical models, 
    and node wise predictability. These methods were recently introduced in the Gaussian 
    graphical model literature, including 
    Williams (2019) <doi:10.31234/osf.io/x8dpr>, 
    Williams and Mulder (2019) <doi:10.31234/osf.io/ypxd8>,
    Williams, Rast, Pericchi, and Mulder (2019) <doi:10.31234/osf.io/yt386>.",2020-05-31,Donald Williams,NA,TRUE,https://github.com/donaldrwilliams/bggm,2572,20,2020-06-08T22:17:02Z,128.6
bggum,"Provides a Metropolis-coupled Markov chain Monte Carlo sampler,
    post-processing and parameter estimation functions, and plotting utilities
    for the generalized graded unfolding model of Roberts, Donoghue, and
    Laughlin (2000) <doi:10.1177/01466216000241001>.",2020-01-19,JBrandon Duck-Mayr,https://github.com/duckmayr/bggum,TRUE,https://github.com/duckmayr/bggum,2731,2,2020-01-19T13:37:45Z,1365.5
BH,"Boost provides free peer-reviewed portable C++ source 
 libraries.  A large part of Boost is provided as C++ template code
 which is resolved entirely at compile-time without linking.  This 
 package aims to provide the most useful subset of Boost libraries 
 for template use among CRAN packages. By placing these libraries in 
 this package, we offer a more efficient distribution system for CRAN 
 as replication of this code in the sources of other packages is 
 avoided. As of release 1.72.0-3, the following Boost libraries are
 included: 'accumulators' 'algorithm' 'align' 'any' 'atomic' 'bimap'
 'bind' 'circular_buffer' 'compute' 'concept' 'config' 'container'
 'date_time' 'detail' 'dynamic_bitset' 'exception' 'flyweight'
 'foreach' 'functional' 'fusion' 'geometry' 'graph' 'heap' 'icl'
 'integer' 'interprocess' 'intrusive' 'io' 'iostreams' 'iterator'
 'math' 'move' 'mp11' 'mpl' 'multiprcecision' 'numeric' 'pending'
 'phoenix' 'polygon' 'preprocessor' 'propery_tree' 'random' 'range'
 'scope_exit' 'smart_ptr' 'sort' 'spirit' 'tuple' 'type_traits'
 'typeof' 'unordered' 'utility' 'uuid'.",2020-01-08,Dirk Eddelbuettel,https://github.com/eddelbuettel/bh,TRUE,https://github.com/eddelbuettel/bh,19932259,66,2020-05-03T19:22:25Z,302003.92424242425
bib2df,Parse a BibTeX file to a data.frame to make it accessible for further analysis and visualization.,2019-05-22,Philipp Ottolinger,https://github.com/ropensci/bib2df,TRUE,https://github.com/ropensci/bib2df,16578,81,2019-12-09T12:07:40Z,204.66666666666666
bibliometrix,"Tool for quantitative research in scientometrics and bibliometrics.
    It provides various routines for importing bibliographic data from 'SCOPUS' (<http://scopus.com>),
    'Clarivate Analytics Web of Science' (<http://www.webofknowledge.com/>), 'Digital Science Dimensions' 
	(<https://www.dimensions.ai/>), 'Cochrane Library' (<http://www.cochranelibrary.com/>) 
	and 'PubMed' (<https://www.ncbi.nlm.nih.gov/pubmed/>) databases, performing bibliometric analysis 
    and building networks for co-citation, coupling, scientific collaboration and co-word analysis.",2020-05-25,Massimo Aria,"https://www.bibliometrix.org,
https://github.com/massimoaria/bibliometrix",TRUE,https://github.com/massimoaria/bibliometrix,181549,148,2020-06-01T19:01:45Z,1226.6824324324325
biclique,"A tool for enumerating maximal complete bipartite graphs. The input should be a edge list file or a binary matrix file. 
             The output are maximal complete bipartite graphs. Algorithms used can be found in this paper Y. Lu et al. BMC Res Notes 13, 88 (2020) <doi:10.1186/s13104-020-04955-0>.",2020-03-03,Yuping Lu,https://github.com/YupingLu/biclique,TRUE,https://github.com/yupinglu/biclique,10895,14,2020-03-03T21:51:21Z,778.2142857142857
biclustermd,"Biclustering is a statistical learning technique that simultaneously 
    partitions and clusters rows and columns of a data matrix. Since the solution 
    space of biclustering is in infeasible to completely search with current 
    computational mechanisms, this package uses a greedy heuristic. The algorithm 
    featured in this package is, to the best our knowledge, the first biclustering 
    algorithm to work on data with missing values. Li, J., Reisner, J., Pham, H., 
    Olafsson, S., and Vardeman, S. (2020) Biclustering with Missing Data. Information 
    Sciences, 510, 304–316.",2020-04-15,John Reisner,http://github.com/jreisner/biclustermd,TRUE,https://github.com/jreisner/biclustermd,4669,3,2020-04-15T01:03:16Z,1556.3333333333333
BifactorIndicesCalculator,"The calculator computes bifactor indices such as explained common variance (ECV), hierarchical Omega (OmegaH), percentage of uncontaminated correlations (PUC), item explained common variance (I-ECV), and more. This package is an R version of the 'Excel' based 'Bifactor Indices Calculator' (Dueber, 2017)  <doi:10.13023/edp.tool.01> with added convenience features for directly utilizing output from several programs that can fit confirmatory factor analysis or item response models.",2020-04-11,David Dueber,https://github.com/ddueber/BifactorIndicesCalculator,TRUE,https://github.com/ddueber/bifactorindicescalculator,3501,2,2020-04-10T01:44:49Z,1750.5
bife,"Estimates fixed effects binary choice models (logit and probit) with potentially many
  individual fixed effects and computes average partial effects. Incidental parameter bias can be
  reduced with an asymptotic bias-correction proposed by Fernandez-Val (2009) 
  <doi:10.1016/j.jeconom.2009.02.007>.",2020-01-12,Amrei Stammann,https://github.com/amrei-stammann/bife,TRUE,https://github.com/amrei-stammann/bife,38053,1,2020-01-19T12:42:15Z,38053
BIFIEsurvey,"
    Contains tools for survey statistics (especially in educational
    assessment) for datasets with replication designs (jackknife, 
    bootstrap, replicate weights; see Kolenikov, 2010;
    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,
    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, 
    <doi:10.1080/02331889708802523>). 
    Descriptive statistics, linear and logistic regression, 
    path models for manifest variables with measurement error 
    correction and two-level hierarchical regressions for weighted 
    samples are included. Statistical inference can be conducted for 
    multiply imputed datasets and nested multiply imputed datasets
    and is in particularly suited for the analysis of plausible values
    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; 
    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &
    Yanagida, 2016; <doi:10.17888/fdb-demo:bistE813I-16a>).    
    The package development was supported by BIFIE (Federal Institute for 
    Educational Research, Innovation and Development of the Austrian 
    School System; Salzburg, Austria).",2019-06-12,Alexander Robitzsch,"http://www.bifie.at,
https://www.bifie.at/bildungsforschung/forschungsdatenbibliothek,
https://www.bifie.at/large-scale-assessment-mit-r-methodische-grundlagen-der-oesterreichischen-bildungsstandardueberpruefung,
https://github.com/alexanderrobitzsch/BIFIEsurvey,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/bifiesurvey,125753,1,2019-06-12T15:24:00Z,125753
bigassertr,"
    Enhanced message functions (cat() / message() / warning() / error()) 
    using wrappers around sprintf(). Also, multiple assertion functions 
    (e.g. to check class, length, values, files, arguments, etc.).",2020-04-01,Florian Privé,https://github.com/privefl/bigassertr,TRUE,https://github.com/privefl/bigassertr,16977,1,2020-04-01T07:55:39Z,16977
BIGDAWG,"Data sets and functions for chi-squared Hardy-Weinberg and case-control association tests of highly polymorphic genetic data [e.g., human leukocyte antigen (HLA) data]. Performs association tests at multiple levels of polymorphism (haplotype, locus and HLA amino-acids) as described in Pappas DJ, Marin W, Hollenbach JA, Mack SJ (2016) <doi:10.1016/j.humimm.2015.12.006>. Combines rare variants to a common class to account for sparse cells in tables as described by Hollenbach JA, Mack SJ, Thomson G, Gourraud PA (2012) <doi:10.1007/978-1-61779-842-9_14>.",2019-11-12,Derek Pappas,"http://tools.immunogenomics.org/,
https://github.com/IgDAWG/BIGDAWG",TRUE,https://github.com/igdawg/bigdawg,30306,2,2019-10-18T01:52:44Z,15153
BIGL,"Response surface methods for drug synergy analysis. Available
    methods include generalized and classical Loewe formulations as well as Highest
    Single Agent methodology. Response surfaces can be plotted in an interactive
    3-D plot and formal statistical tests for presence of synergistic effects are
    available. Implemented methods and tests are described in the article 
    ""BIGL: Biochemically Intuitive Generalized Loewe null model for prediction 
    of the expected combined effect compatible with partial agonism and antagonism""
    by Koen Van der Borght, Annelies Tourny, Rytis Bagdziunas, Olivier Thas, 
    Maxim Nazarov, Heather Turner, Bie Verbist & Hugo Ceulemans (2017) 
    <doi:10.1038/s41598-017-18068-5>.",2020-02-20,Heather Turner,https://github.com/openanalytics/BIGL,TRUE,https://github.com/openanalytics/bigl,22107,4,2020-02-04T14:29:06Z,5526.75
biglasso,"Extend lasso and elastic-net model fitting for ultrahigh-dimensional, 
    multi-gigabyte data sets that cannot be loaded into memory. It's much more 
    memory- and computation-efficient as compared to existing lasso-fitting packages 
    like 'glmnet' and 'ncvreg', thus allowing for very powerful big data analysis 
    even with an ordinary laptop.",2019-09-09,Yaohui Zeng,"https://github.com/YaohuiZeng/biglasso,
https://arxiv.org/abs/1701.05936",TRUE,https://github.com/yaohuizeng/biglasso,43694,70,2020-02-13T17:56:46Z,624.2
bigmemory,"Create, store, access, and manipulate massive matrices.
    Matrices are allocated to shared memory and may use memory-mapped
    files.  Packages 'biganalytics', 'bigtabulate', 'synchronicity', and
    'bigalgebra' provide advanced functionality.",2019-12-23,Michael J. Kane,https://github.com/kaneplusplus/bigmemory,TRUE,https://github.com/kaneplusplus/bigmemory,431107,87,2019-12-23T00:36:01Z,4955.252873563219
bigparallelr,"Utility functions for easy parallelism in R. Include some reexports
    from other packages, utility functions for splitting and parallelizing over
    blocks, and choosing and setting the number of cores used.",2020-01-09,Florian Privé,https://github.com/privefl/bigparallelr,TRUE,https://github.com/privefl/bigparallelr,12175,1,2020-02-29T17:23:47Z,12175
bigQueryR,"Interface with 'Google BigQuery',
    see <https://cloud.google.com/bigquery/> for more information.
    This package uses 'googleAuthR' so is compatible with similar packages, 
    including 'Google Cloud Storage' (<https://cloud.google.com/storage/>) for result extracts. ",2019-10-09,Mark Edmondson,http://code.markedmondson.me/bigQueryR/,TRUE,https://github.com/cloudyr/bigqueryr,47510,31,2020-03-12T11:53:12Z,1532.5806451612902
bigreadr,"Read large text files by splitting them in smaller files.
    Package 'bigreadr' also provides some convenient wrappers around fread()
    and fwrite() from package 'data.table'. ",2019-10-18,Florian Privé,https://github.com/privefl/bigreadr,TRUE,https://github.com/privefl/bigreadr,23452,27,2019-11-02T08:25:29Z,868.5925925925926
bigrquery,Easily talk to Google's 'BigQuery' database from R.,2020-05-15,Hadley Wickham,https://github.com/rstats-db/bigrquery,TRUE,https://github.com/rstats-db/bigrquery,431039,393,2020-05-15T16:09:57Z,1096.7913486005089
bigsnpr,"Easy-to-use, efficient, flexible and scalable tools
    for analyzing massive SNP arrays <doi:10.1093/bioinformatics/bty185>.",2020-03-09,Florian Privé,https://privefl.github.io/bigsnpr,TRUE,https://github.com/privefl/bigsnpr,3693,55,2020-06-01T05:40:05Z,67.14545454545454
bigsparser,"Provides a sparse matrix format with data stored on disk, to be
    used in both R and C++. This is intended for more efficient use of sparse 
    data in C++ and also when parallelizing, since data on disk does not need
    copying. Only a limited number of features will be implemented. For now,
    conversion can be performed from a 'dgCMatrix' of R package 'Matrix'.",2020-05-25,Florian Privé,https://github.com/privefl/bigsparser,TRUE,https://github.com/privefl/bigsparser,1281,2,2020-05-15T14:54:49Z,640.5
bigstatsr,"Easy-to-use, efficient, flexible and scalable statistical tools.
  Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping.
  It provides for instance matrix operations, Principal Component Analysis,
  sparse linear supervised models, utility functions and more
  <doi:10.1093/bioinformatics/bty185>.",2020-03-12,Florian Privé,https://privefl.github.io/bigstatsr,TRUE,https://github.com/privefl/bigstatsr,23776,101,2020-03-11T17:15:11Z,235.40594059405942
bigstep,"Selecting linear and generalized linear models for large data sets
    using modified stepwise procedure and modern selection criteria (like
    modifications of Bayesian Information Criterion). Selection can be
    performed on data which exceed RAM capacity.",2019-07-25,Piotr Szulc,http://github.com/pmszulc/bigstep,TRUE,https://github.com/pmszulc/bigstep,16186,1,2019-07-23T06:55:23Z,16186
bigutilsr,"Utility functions for large-scale data. For now, package 'bigutilsr'
    mainly includes functions for outlier detection and PCA projection.",2020-05-15,Florian Privé,https://github.com/privefl/bigutilsr,TRUE,https://github.com/privefl/bigutilsr,9604,6,2020-03-30T16:06:58Z,1600.6666666666667
BigVAR,Estimates VAR and VARX models with structured Lasso Penalties.,2019-12-02,Will Nicholson,http://www.github.com/wbnicholson/BigVAR,TRUE,https://github.com/wbnicholson/bigvar,25067,31,2020-03-07T17:53:16Z,808.6129032258065
billboarder,"Provides an 'htmlwidgets' interface to 'billboard.js', 
    a re-usable easy interface JavaScript chart library, based on D3 v4+.
    Chart types include line charts, scatterplots, bar/lollipop charts, histogram/density plots, pie/donut charts and gauge charts.
    All charts are interactive, and a proxy method is implemented to smoothly update a chart without rendering it again in 'shiny' apps. ",2020-01-09,Victor Perrier,https://github.com/dreamRs/billboarder,TRUE,https://github.com/dreamrs/billboarder,43810,145,2020-05-18T10:32:01Z,302.13793103448273
binb,"A collection of 'LaTeX' styles using 'Beamer' customization for
 pdf-based presentation slides in 'RMarkdown'. At present it contains
 'RMarkdown' adaptations of the LaTeX themes 'Metropolis' (formerly 'mtheme')
 theme by Matthias Vogelgesang and others (now included in 'TeXLive'), the
 'IQSS' by Ista Zahn (which is included here), and the 'Monash' theme by
 Rob J Hyndman. Additional (free) fonts may be needed: 'Metropolis' prefers
 'Fira', and 'IQSS' requires 'Libertinus'.",2019-11-02,Dirk Eddelbuettel,https://github.com/eddelbuettel/binb,TRUE,https://github.com/eddelbuettel/binb,13082,136,2020-06-09T03:03:27Z,96.19117647058823
binman,"Tools and functions for managing the download of binary files.
    Binary repositories are defined in 'YAML' format. Defining new 
    pre-download, download and post-download templates allow additional 
    repositories to be added.",2018-07-18,John Harrison,https://github.com/ropensci/binman,TRUE,https://github.com/ropensci/binman,135582,12,2019-12-09T12:08:28Z,11298.5
binmapr,"The raw NGS (Next Generation Sequencing) variants called 
    from GBS (Genotyping by Sequencing) / WES (Whole Exon Sequencing)/
    WGS (Whole Genome Sequencing) may include many error sites. The 
    'binmapr' could fix the potential error sites and generate highly
    confident markers for downstream analysis, such as QTL (quantitative
    trait locus) mapping, genetic map construction. 
    Davey, J.W. (2011) <doi:10.1038/nrg3012>.",2019-10-20,Zhougeng Xu,https://github.com/xuzhougeng/binmapr,TRUE,https://github.com/xuzhougeng/binmapr,3130,8,2019-10-15T07:51:47Z,391.25
bioacoustics,"Contains all the necessary tools to process audio recordings of
             various formats (e.g., WAV, WAC, MP3, ZC), filter noisy files, 
             display audio signals, detect and extract automatically acoustic
             features for further analysis such as classification.",2020-05-24,Jean Marchal,https://github.com/wavx/bioacoustics/,TRUE,https://github.com/wavx/bioacoustics,22254,23,2020-05-23T18:34:05Z,967.5652173913044
bioC.logs,Download stats reports from the BioConductor.org stats website.,2020-02-13,Marcelo Ponce,https://github.com/mponce0/bioC.logs,TRUE,https://github.com/mponce0/bioc.logs,2155,0,2020-02-26T18:41:15Z,NA
BiocManager,A convenient tool to install and update Bioconductor packages.,2019-11-16,Martin Morgan,NA,TRUE,https://github.com/bioconductor/biocmanager,1444786,28,2020-05-23T20:05:55Z,51599.5
biocompute,"Tools to create, validate, and export BioCompute Objects
    described in King et al. (2019) <doi:10.17605/osf.io/h59uh>.
    Users can encode information in data frames, and compose
    BioCompute Objects from the domains defined by the standard.
    A checksum validator and a JSON schema validator are provided.
    This package also supports exporting BioCompute Objects as JSON,
    PDF, HTML, or 'Word' documents, and exporting to cloud-based platforms.",2019-11-28,Nan Xiao,"https://sbg.github.io/biocompute/,
https://github.com/sbg/biocompute",TRUE,https://github.com/sbg/biocompute,3071,1,2020-04-23T16:11:09Z,3071
biogram,"Tools for extraction and analysis of various
    n-grams (k-mers) derived from biological sequences (proteins
    or nucleic acids). Contains QuiPT (quick permutation test) for fast
    feature-filtering of the n-gram data.",2020-03-31,Michal Burdukiewicz,https://github.com/michbur/biogram,TRUE,https://github.com/michbur/biogram,25558,6,2020-04-04T19:59:18Z,4259.666666666667
bioimagetools,"Tools for 3D imaging, mostly for biology/microscopy. 
    Read and write TIFF stacks. Functions for segmentation, filtering and analyzing 3D point patterns.",2020-05-29,Volker Schmid,https://bioimaginggroup.github.io/bioimagetools,TRUE,https://github.com/bioimaginggroup/bioimagetools,19344,3,2020-05-29T11:12:05Z,6448
BioInstaller,"
    Can be used to integrate massive bioinformatics resources, such as tool/script and database. It provides the R functions and Shiny web application. Hundreds of bioinformatics tool/script and database have been included.",2018-11-20,Jianfeng Li,https://github.com/JhuangLab/BioInstaller,TRUE,https://github.com/jhuanglab/bioinstaller,38832,34,2019-11-28T07:59:31Z,1142.1176470588234
biomartr,"Perform large scale genomic data retrieval and functional annotation retrieval. This package aims to provide users with a standardized
                way to automate genome, proteome, 'RNA', coding sequence ('CDS'), 'GFF', and metagenome
                retrieval from 'NCBI RefSeq', 'NCBI Genbank', 'ENSEMBL', 'ENSEMBLGENOMES',
                and 'UniProt' databases. Furthermore, an interface to the 'BioMart' database
                (Smedley et al. (2009) <doi:10.1186/1471-2164-10-22>) allows users to retrieve
                functional annotation for genomic loci. In addition, users can download entire databases such
                as 'NCBI RefSeq' (Pruitt et al. (2007) <doi:10.1093/nar/gkl842>), 'NCBI nr',
                'NCBI nt', 'NCBI Genbank' (Benson et al. (2013) <doi:10.1093/nar/gks1195>), etc. as
                well as 'ENSEMBL' and 'ENSEMBLGENOMES' with only one command.",2020-01-10,Hajk-Georg Drost,"https://docs.ropensci.org/biomartr,
https://github.com/ropensci/biomartr",TRUE,https://github.com/ropensci/biomartr,58748,127,2020-06-04T07:21:25Z,462.5826771653543
BIOMASS,"Contains functions to estimate aboveground biomass/carbon and its uncertainty in tropical forests. 
	These functions allow to (1) retrieve and to correct taxonomy, (2) estimate wood density and its uncertainty, 
	(3) construct height-diameter models, (4) manage tree and plot coordinates, 
	(5) estimate the aboveground biomass/carbon at the stand level with associated uncertainty. 
	To cite BIOMASS, please use citation(""BIOMASS""). 
	See more in the article of Réjou-Méchain et al. (2017) <doi:10.1111/2041-210X.12753>.",2019-05-03,Maxime Réjou-Méchain,https://github.com/AMAP-dev/BIOMASS,TRUE,https://github.com/amap-dev/biomass,21519,5,2020-04-02T13:00:27Z,4303.8
BioMedR,"Calculating 293 chemical descriptors and 14 kinds of chemical fingerprints, 9920 protein descriptors based on protein sequences, more than 6000 DNA/RNA descriptors from nucleotide sequences, and six types of interaction descriptors using three different combining strategies. ",2019-07-05,Min-feng Zhu,https://github.com/wind22zhu/BioMedR,TRUE,https://github.com/wind22zhu/biomedr,6654,4,2019-10-19T11:02:19Z,1663.5
bioRad,"Extract, visualize and summarize aerial movements of birds and
    insects from weather radar data. See <doi:10.1111/ecog.04028>
    for a software paper describing package and methodologies.",2020-05-11,Adriaan M. Dokter,"https://github.com/adokter/bioRad,
https://adokter.github.io/bioRad",TRUE,https://github.com/adokter/biorad,8126,11,2020-05-27T18:27:10Z,738.7272727272727
bipartite,"Functions to visualise webs and calculate a series of indices commonly used to describe pattern in (ecological) webs. It focuses on webs consisting of only two levels (bipartite), e.g. pollination webs or predator-prey-webs. Visualisation is important to get an idea of what we are actually looking at, while the indices summarise different aspects of the web's topology. ",2020-04-03,Carsten F. Dormann,https://github.com/biometry/bipartite,TRUE,https://github.com/biometry/bipartite,119467,15,2020-05-29T12:57:01Z,7964.466666666666
BIRDS,"It helps making the evaluation and preparation of biodiversity data
   easy, systematic and reproducible. It also helps the users to overlay the 
   point observations into a custom grid that is useful for further analysis. 
   The review summarise statistics that helps evaluate whether a set of species 
   observations is fit-for-use and take decisions upon its use of on further 
   analyses. It does so by quantifying the sampling effort (amount of effort
   expended during an event) and data completeness (data gaps) to help judge 
   whether the data is representative, valid and fit for any intended purpose. 
   The 'BIRDS' package is most useful when working with heterogeneous data sets 
   with variation in the sampling process, i.e. where data have been collected 
   and reported in various ways and therefore varying in sampling effort 
   and data completeness (i.e. how well the reported observations describe the 
   true state). Primary biodiversity data (PBD) combining data from different 
   data sets, like e.g. Global Biodiversity Information Facility (GBIF) mediated
   data, commonly vary in the ways data has been generated - containing 
   opportunistically collected presence-only data together with and data from 
   systematic monitoring programs. The set of tools provided is aimed at 
   understanding the process that generated the data (i.e. observing, recording 
   and reporting species into databases). There is a non-vital function on this 
   package (makeDggrid()) that depends the package 'dggridR' that is no longer on CRAN. 
   You can find it here <https://github.com/r-barnes/dggridR>. References: 
   Ruete (2015) <doi:10.3897/BDJ.3.e5361>; Szabo, Vesk, Baxter & Possingham (2010) 
   <doi:10.1890/09-0877.1>; Telfer, Preston 6 Rothery (2002) <doi:10.1016/S0006-3207(02)00050-2>.",2020-03-20,Debora Arlt,https://github.com/greensway/BIRDS,TRUE,https://github.com/greensway/birds,1614,3,2020-06-04T21:19:56Z,538
biscale,"Provides a 'ggplot2' centric approach to bivariate mapping. This is a 
    technique that maps two quantities simultaneously rather than the single value 
    that most thematic maps display. The package provides a suite of tools 
    for calculating breaks using multiple different approaches, a selection of 
    palettes appropriate for bivariate mapping and a scale function for 'ggplot2' 
    calls that adds those palettes to maps. A tool for creating bivariate legends 
    is also included.",2020-05-06,Christopher Prener,https://github.com/slu-openGIS/biscale,TRUE,https://github.com/slu-opengis/biscale,5627,58,2020-05-06T17:02:54Z,97.01724137931035
BisqueRNA,"Provides tools to accurately estimate cell type abundances 
    from heterogeneous bulk expression. A reference-based method utilizes
    single-cell information to generate a signature matrix and transformation
    of bulk expression for accurate regression based estimates. A marker-based
    method utilizes known cell-specific marker genes to measure relative
    abundances across samples.
    For more details, see Jew and Alvarez et al (2019) <doi:10.1101/669911>.",2020-05-04,Brandon Jew,https://www.biorxiv.org/content/10.1101/669911v1,TRUE,https://github.com/cozygene/bisque,5749,23,2020-05-04T04:24:22Z,249.95652173913044
bitmexr,"A client for cryptocurrency exchange BitMEX
    <https://www.bitmex.com/> including the ability to obtain historic
    trade data and place, edit and cancel orders. BitMEX's Testnet and
    live API are both supported.",2020-05-25,Harry Fisher,"https://github.com/hfshr/bitmexr, https://hfshr.github.io/bitmexr",TRUE,https://github.com/hfshr/bitmexr,718,2,2020-06-02T17:53:55Z,359
bitsqueezr,"Provides a implementation of floating-point quantization algorithms for use in precision-preserving 
             compression, similar to the approach taken in the 'netCDF operators' (NCO) software package and 
             described in Zender (2016) <doi:10.5194/gmd-2016-63>.",2020-01-17,Daniel Baston,https://github.com/dbaston/bitsqueezr,TRUE,https://github.com/dbaston/bitsqueezr,6571,0,2019-09-30T17:35:23Z,NA
BivRec,"A collection of models for bivariate alternating recurrent event data analysis. 
             Includes non-parametric and semi-parametric methods.",2020-01-15,Sandra Castro-Pearson,https://github.com/SandraCastroPearson/BivRec,TRUE,https://github.com/sandracastropearson/bivrec,7594,1,2020-01-19T18:18:52Z,7594
bjscrapeR,"Drawing heavy influence from 'blscrapeR', this package scrapes crime data from <https://www.bjs.gov/>. Specifically, it scrapes data from the National Crime Victimization Survey which tracks personal and household crime in the USA. The idea is to utilize the 'tidyverse' methodology to create an efficient work flow when dealing with crime statistics.",2018-06-06,Dylan McDowell,https://github.com/dylanjm/bjscrapeR,TRUE,https://github.com/dylanjm/bjscraper,8124,4,2019-06-28T04:46:29Z,2031
bkmr,"Implementation of a statistical approach 
  for estimating the joint health effects of multiple 
  concurrent exposures.",2017-03-24,Jennifer F. Bobb,https://github.com/jenfb/bkmr,TRUE,https://github.com/jenfb/bkmr,16825,12,2020-05-25T20:57:54Z,1402.0833333333333
blandr,"Carries out Bland Altman analyses (also known as a Tukey
    mean-difference plot) as described by JM Bland and DG Altman in
    1986 <doi:10.1016/S0140-6736(86)90837-8>. This package was created in 
    2015 as existing Bland-Altman analysis functions did not calculate 
    confidence intervals. This package was created to rectify this, 
    and create reproducible plots. This package is also available as a module
    for the 'jamovi' statistical spreadsheet (see <https://www.jamovi.org>
    for more information).",2018-05-10,Deepankar Datta,https://github.com/deepankardatta/blandr/,TRUE,https://github.com/deepankardatta/blandr,15914,10,2020-03-28T07:15:04Z,1591.4
blastula,"Compose and send out responsive HTML email messages that render
    perfectly across a range of email clients and device sizes. Helper functions
    let the user insert embedded images, web link buttons, and 'ggplot2' plot
    objects into the message body. Messages can be sent through an 'SMTP'
    server, through the 'RStudio Connect' service, or through the 'Mailgun' API
    service <http://mailgun.com/>.",2020-05-19,Richard Iannone,https://github.com/rich-iannone/blastula,TRUE,https://github.com/rich-iannone/blastula,37627,297,2020-05-19T16:43:28Z,126.6902356902357
blindrecalc,"Computation of key characteristics and plots for blinded sample size recalculation.
   Continuous as well as binary endpoints are supported in superiority and non-inferiority trials.
   The implemented methods include the approaches by
   Lu, K. (2019) <doi:10.1002/pst.1737>,
   Kieser, M. and Friede, T. (2000) <doi:10.1002/(SICI)1097-0258(20000415)19:7%3C901::AID-SIM405%3E3.0.CO;2-L>,
   Friede, T. and Kieser, M. (2004) <doi:10.1002/pst.140>, 
   Friede, T., Mitchell, C., Mueller-Veltern, G. (2007) <doi:10.1002/bimj.200610373>, and
   Friede, T. and Kieser, M. (2011) <doi:10.3414/ME09-01-0063>.",2020-05-11,Maximilian Pilz,https://github.com/imbi-heidelberg/blindrecalc,TRUE,https://github.com/imbi-heidelberg/blindrecalc,389,2,2020-05-11T14:35:39Z,194.5
blme,"Maximum a posteriori estimation for linear and generalized
             linear mixed-effects models in a Bayesian setting. Extends
             'lme4' by Douglas Bates, Martin Maechler, Ben Bolker, and Steve Walker.",2015-06-14,Vincent Dorie,https://github.com/vdorie/blme,TRUE,https://github.com/vdorie/blme,169550,25,2020-02-26T19:20:44Z,6782
blob,"R's raw vector is useful for storing a single
    binary object.  What if you want to put a vector of them in a data
    frame? The 'blob' package provides the blob object, a list of raw
    vectors, suitable for use as a column in data frame.",2020-01-20,Kirill Müller,https://github.com/tidyverse/blob,TRUE,https://github.com/tidyverse/blob,3104956,28,2020-01-23T12:25:21Z,110891.28571428571
blockCV,"Creating spatially or environmentally separated folds for cross-validation to provide a robust error estimation in spatially structured environments; Investigating and visualising the effective range of spatial autocorrelation in continuous raster covariates to find an initial realistic distance band to separate training and testing datasets spatially described in Valavi, R. et al. (2019) <doi:10.1111/2041-210X.13107>.",2020-02-23,Roozbeh Valavi,https://github.com/rvalavi/blockCV,TRUE,https://github.com/rvalavi/blockcv,2912,58,2020-04-22T13:30:58Z,50.206896551724135
blockForest,"A random forest variant 'block forest' ('BlockForest') tailored to the 
  prediction of binary, survival and continuous outcomes using block-structured 
  covariate data, for example, clinical covariates plus measurements of a certain 
  omics data type or multi-omics data, that is, data for which measurements of 
  different types of omics data and/or clinical data for each patient exist. Examples 
  of different omics data types include gene expression measurements, mutation data
  and copy number variation measurements.
  Block forest are presented in Hornung & Wright (2019). The package includes four
  other random forest variants for multi-omics data: 'RandomBlock', 'BlockVarSel', 
  'VarProb', and 'SplitWeights'. These were also considered in Hornung & Wright (2019), 
  but performed worse than block forest in their comparison study based on 20 real 
  multi-omics data sets. Therefore, we recommend to use block forest ('BlockForest') 
  in applications. The other random forest variants can, however, be consulted for 
  academic purposes, for example, in the context of further methodological 
  developments. 
  Reference: Hornung, R. & Wright, M. N. (2019) Block Forests: random forests for blocks of clinical and omics covariate data. BMC Bioinformatics 20:358. <doi:10.1186/s12859-019-2942-y>.",2019-12-06,Roman Hornung,https://github.com/bips-hb/blockForest,TRUE,https://github.com/bips-hb/blockforest,8250,3,2019-12-06T08:01:03Z,2750
blockRAR,"Computes power for response-adaptive randomization with a block design that captures both the time and treatment effect. T. Chandereng, R. Chappell (2019) <arXiv:1904.07758>.",2020-01-21,Thevaa Chandereng,https://github.com/thevaachandereng/blockRAR/,TRUE,https://github.com/thevaachandereng/blockrar,5652,2,2020-06-07T17:51:49Z,2826
blogdown,"Write blog posts and web pages in R Markdown. This package supports
    the static site generator 'Hugo' (<https://gohugo.io>) best, and it also
    supports 'Jekyll' (<http://jekyllrb.com>) and 'Hexo' (<https://hexo.io>).",2020-05-22,Yihui Xie,https://github.com/rstudio/blogdown,TRUE,https://github.com/rstudio/blogdown,144961,1156,2020-05-28T15:33:27Z,125.39878892733564
blorr,"Tools designed to make it easier for beginner and intermediate users to build and validate 
    binary logistic regression models. Includes bivariate analysis, comprehensive regression output, 
    model fit statistics, variable selection procedures, model validation techniques and a 'shiny' 
    app for interactive model building.",2020-05-28,Aravind Hebbali,"URL: https://blorr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/blorr",TRUE,https://github.com/rsquaredacademy/blorr,15594,12,2020-05-28T13:25:52Z,1299.5
blscrapeR,"Scrapes various data from <https://www.bls.gov/>. The U.S. Bureau of Labor Statistics is the statistical branch of the United States Department of Labor. The package has additional functions to help parse, analyze and visualize the data.",2019-12-17,Kris Eberwein,https://github.com/keberwein/blscrapeR,TRUE,https://github.com/keberwein/blscraper,34028,70,2019-12-17T16:56:17Z,486.1142857142857
bltm,"Fits latent threshold model for simulated data
    and describes how to adjust model using real data. Implements algorithm
    proposed by Nakajima and West (2013) <doi:10.1080/07350015.2012.747847>. 
    This package has a function to generate data, a function to configure 
    priors and a function to fit the model. Examples may be checked inside 
    the demonstration files.",2019-07-18,Julio Trecenti,https://github.com/curso-r/bltm,TRUE,https://github.com/curso-r/bltm,4238,1,2019-07-13T18:39:36Z,4238
BMA,"Package for Bayesian model averaging and variable selection for linear models,
        generalized linear models and survival models (cox
        regression).",2020-03-11,Adrian Raftery,"http://stats.research.att.com/volinsky/bma.html,
https://github.com/hanase/BMA",TRUE,https://github.com/hanase/bma,195487,6,2020-03-10T23:13:48Z,32581.166666666668
bmass,"Multivariate tool for analyzing genome-wide association
    study results in the form of univariate summary statistics. The 
    goal of 'bmass' is to comprehensively test all possible multivariate
    models given the phenotypes and datasets provided. Multivariate
    models are determined by assigning each phenotype to being either
    Unassociated (U), Directly associated (D) or Indirectly associated
    (I) with the genetic variant of interest. Test results for each model 
    are presented in the form of Bayes factors, thereby allowing direct
    comparisons between models. The underlying framework implemented
    here is based on the modeling developed in ""A Unified Framework 
    for Association Analysis with Multiple Related Phenotypes"",
    M. Stephens (2013) <doi:10.1371/journal.pone.0065245>.",2019-05-17,Michael Turchin,https://github.com/mturchin20/bmass,TRUE,https://github.com/mturchin20/bmass,4654,8,2020-05-17T00:57:35Z,581.75
BMTME,"Genomic selection and prediction models with the capacity to use multiple traits and environments, through ready-to-use Bayesian models. It consists a group of functions 
             that help to create regression models for some genomic models proposed by Montesinos-López, et al. (2016) <doi:10.1534/g3.116.032359>
             also in Montesinos-López et al. (2018) <doi:10.1534/g3.118.200728> and Montesinos-López et al. (2018) <doi:10.2134/agronj2018.06.0362>.",2020-05-26,Francisco Javier Luna-Vazquez,https://github.com/frahik/BMTME,TRUE,https://github.com/frahik/bmtme,7983,6,2019-10-17T21:30:09Z,1330.5
bnclassify,"State-of-the art algorithms for learning discrete Bayesian network classifiers from data, including a number of those described in Bielza & Larranaga (2014) <doi:10.1145/2576868>, with functions for prediction, model evaluation and inspection.",2020-03-12,Mihaljevic Bojan,http://github.com/bmihaljevic/bnclassify,TRUE,https://github.com/bmihaljevic/bnclassify,29535,15,2020-04-02T14:17:15Z,1969
bnpsd,"The Pritchard-Stephens-Donnelly (PSD) admixture model has k intermediate subpopulations from which n individuals draw their alleles dictated by their individual-specific admixture proportions.  The BN-PSD model additionally imposes the Balding-Nichols (BN) allele frequency model to the intermediate populations, which therefore evolved independently from a common ancestral population T with subpopulation-specific FST (Wright's fixation index) parameters.  The BN-PSD model can be used to yield complex population structures.  Method described in Ochoa and Storey (2016) <doi:10.1101/083923>.",2020-01-10,Alejandro Ochoa,https://github.com/StoreyLab/bnpsd/,TRUE,https://github.com/storeylab/bnpsd,10854,6,2020-05-28T20:34:05Z,1809
BNrich,"Maleknia et al. (2020) <doi:10.1101/2020.01.13.905448>. A novel pathway enrichment analysis package based on Bayesian network to investigate the topology features of the pathways. firstly, 187 kyoto encyclopedia of genes and genomes (KEGG) human non-metabolic pathways which their cycles were eliminated by biological approach, enter in analysis as Bayesian network structures. The constructed Bayesian network were optimized by the Least Absolute Shrinkage Selector Operator (lasso) and the parameters were learned based on gene expression data. Finally, the impacted pathways were enriched by Fisher’s Exact Test on significant parameters.",2020-04-04,Samaneh Maleknia,https://github.com/Samaneh-Bioinformatics/BNrich,TRUE,https://github.com/samaneh-bioinformatics/bnrich,1581,0,2020-04-04T07:37:58Z,NA
bnspatial,"Allows spatial implementation of Bayesian networks and mapping in geographical space. It makes maps of expected value (or most likely state) given known and unknown conditions, maps of uncertainty measured as coefficient of variation or Shannon index (entropy), maps of probability associated to any states of any node of the network. Some additional features are provided as well: parallel processing options, data discretization routines and function wrappers designed for users with minimal knowledge of the R language. Outputs can be exported to any common GIS format. ",2020-01-17,Dario Masante,http://github.com/dariomasante/bnspatial,TRUE,https://github.com/dariomasante/bnspatial,21968,13,2020-01-30T12:10:29Z,1689.8461538461538
bold,"A programmatic interface to the Web Service methods provided by
    Bold Systems (<http://www.boldsystems.org/>) for genetic 'barcode' data.
    Functions include methods for searching by sequences by taxonomic names,
    ids, collectors, and institutions; as well as a function for searching
    for specimens, and downloading trace files.",2020-05-01,Scott Chamberlain,"https://docs.ropensci.org/bold, https://github.com/ropensci/bold",TRUE,https://github.com/ropensci/bold,148265,12,2020-05-01T21:15:40Z,12355.416666666666
bomrang,"Provides functions to interface with Australian Government Bureau
    of Meteorology ('BOM') data, fetching data and returning a tidy data frame
    of precis forecasts, historical and current weather data from stations,
    agriculture bulletin data, 'BOM' 0900 or 1500 weather bulletins and
    downloading and importing radar and satellite imagery files.  Data (c)
    Australian Government Bureau of Meteorology Creative Commons (CC)
    Attribution 3.0 licence or Public Access Licence (PAL) as appropriate.  See
    <http://www.bom.gov.au/other/copyright.shtml> for further details.",2020-01-20,Adam H. Sparks,"https://github.com/ropensci/bomrang,
https://docs.ropensci.org/bomrang/",TRUE,https://github.com/ropensci/bomrang,30733,66,2020-01-20T22:31:56Z,465.6515151515151
bookdown,Output formats and utilities for authoring books and technical documents with R Markdown.,2020-05-15,Yihui Xie,https://github.com/rstudio/bookdown,TRUE,https://github.com/rstudio/bookdown,620701,1955,2020-05-23T19:10:02Z,317.49411764705883
bookdownplus,"A collection and selector of R 'bookdown' templates. 'bookdownplus' helps you write academic journal articles, guitar books, chemical equations, mails, calendars, and diaries. R 'bookdownplus' extends the features of 'bookdown', and simplifies the procedure. Users only have to choose a template, clarify the book title and author name, and then focus on writing the text. No need to struggle in 'YAML' and 'LaTeX'.",2020-02-26,Peng Zhao,https://github.com/pzhaonet/bookdownplus,TRUE,https://github.com/pzhaonet/bookdownplus,31933,173,2020-03-17T21:21:46Z,184.58381502890174
boot.heterogeneity,"Implements a bootstrap-based heterogeneity test for standardized mean differences (d), Fisher-transformed Pearson's correlations (r), and natural-logarithm-transformed odds ratio (or) in meta-analysis studies. Depending on the presence of moderators, this Monte Carlo based test can be implemented in the random- or mixed-effects model. This package uses rma() function from the R package 'metafor' to obtain parameter estimates and likelihoods, so installation of R package 'metafor' is required. This approach refers to the studies of Anscombe (1956) <doi:10.2307/2332926>, Haldane (1940) <doi:10.2307/2332614>, Hedges (1981) <doi:10.3102/10769986006002107>, Hedges & Olkin (1985, ISBN:978-0123363800), Silagy, Lancaster, Stead, Mant, & Fowler (2004) <doi:10.1002/14651858.CD000146.pub2>, Viechtbauer (2010) <doi:10.18637/jss.v036.i03>, and Zuckerman (1994, ISBN:978-0521432009). ",2020-05-08,Ge Jiang,https://github.com/gabriellajg/boot.heterogeneity/,TRUE,https://github.com/gabriellajg/boot.heterogeneity,429,0,2020-05-07T06:31:49Z,NA
bootstrapFP,"Finite Population bootstrap algorithms to estimate the variance
    of the Horvitz-Thompson estimator for single-stage sampling. 
    For a survey of bootstrap methods for finite populations, see Mashreghi et Al. (2016) <doi:10.1214/16-SS113>.",2019-02-24,Roberto Sichera,NA,TRUE,https://github.com/rhobis/bootstrapfp,6378,0,2019-12-04T11:38:48Z,NA
BOSSreg,"Best orthogonalized subset selection (BOSS) is a least-squares (LS) based subset selection method, that performs best subset selection upon an orthogonalized basis of ordered predictors, with the computational effort of a single ordinary LS fit. This package provides a highly optimized implementation of BOSS and estimates a heuristic degrees of freedom for BOSS, which can be plugged into an information criterion (IC) such as AICc in order to select the subset from candidates. It provides various choices of IC, including AIC, BIC, AICc, Cp and GCV. It also implements the forward stepwise selection (FS) with no additional computational cost, where the subset of FS is selected via cross-validation (CV). CV is also an option for BOSS. For details see: Tian, Hurvich and Simonoff (2019), ""On the Use of Information Criteria for Subset Selection in Least Squares Regression"", <arXiv:1911.10191>.",2019-12-06,Sen Tian,https://github.com/sentian/BOSSreg,TRUE,https://github.com/sentian/bossreg,2688,1,2020-01-15T04:16:54Z,2688
botor,"Fork-safe, raw access to the 'Amazon Web Services' ('AWS') 'SDK' via the 'boto3' 'Python' module, and convenient helper functions to query the 'Simple Storage Service' ('S3') and 'Key Management Service' ('KMS'), partial support for 'IAM', the 'Systems Manager Parameter Store' and 'Secrets Manager'.",2020-02-16,Gergely Daróczi,https://daroczig.github.io/botor,TRUE,https://github.com/daroczig/botor,4658,22,2020-05-22T19:07:41Z,211.72727272727272
boundingbox,"Generate ground truth cases for object localization algorithms. 
    Cycle through a list of images, select points around which to generate bounding 
    boxes and assign classifiers. Output the coordinates, and images annotated with 
    boxes and labels. For an example study that uses bounding boxes for image 
    localization and classification see Ibrahim, Badr, Abdallah, and Eissa (2012)
    ""Bounding Box Object Localization Based on Image Superpixelization""
    <doi:10.1016/j.procs.2012.09.119>.",2020-06-09,David Stomski,<https://github.com/stomperusa/boundingbox>,TRUE,https://github.com/stomperusa/boundingbox,0,1,2020-06-06T00:15:06Z,0
boxr,"An R interface for the remote file hosting service 'Box'
    (<https://www.box.com/>). In addition to uploading and downloading files,
    this package includes functions which mirror base R operations for local
    files, (e.g. box_load(), box_save(), box_read(), box_setwd(), etc.), as well
    as 'git' style functions for entire directories (e.g. box_fetch(),
    box_push()).",2019-11-19,Ian Lyttle,https://github.com/r-box/boxr/,TRUE,https://github.com/r-box/boxr,32003,43,2020-04-27T16:32:38Z,744.2558139534884
bpbounds,"Implementation of the nonparametric bounds for the average causal 
    effect under an instrumental variable model by Balke and Pearl (Bounds on 
    Treatment Effects from Studies with Imperfect Compliance, JASA, 1997, 92, 
    439, 1171-1176). The package can calculate bounds for a binary outcome, a 
    binary treatment/phenotype, and an instrument with either 2 or 3 
    categories. The package implements bounds for situations where these 3 
    variables are measured in the same dataset (trivariate data) or where the 
    outcome and instrument are measured in one study and the 
    treatment/phenotype and instrument are measured in another study 
    (bivariate data).",2020-01-21,Tom Palmer,https://github.com/remlapmot/bpbounds,TRUE,https://github.com/remlapmot/bpbounds,7782,0,2020-06-07T09:13:36Z,NA
bpnreg,"Fitting Bayesian multiple and mixed-effect regression models for 
    circular data based on the projected normal distribution. Both continuous 
    and categorical predictors can be included. Sampling from the posterior is 
    performed via an MCMC algorithm. Posterior descriptives of all parameters, 
    model fit statistics and Bayes factors for hypothesis tests for inequality 
    constrained hypotheses are provided. See Cremers, Mulder & Klugkist (2018) 
    <doi:10.1111/bmsp.12108> and Nuñez-Antonio & Guttiérez-Peña (2014) 
    <doi:10.1016/j.csda.2012.07.025>.",2020-02-04,Jolien Cremers,https://github.com/joliencremers/bpnreg,TRUE,https://github.com/joliencremers/bpnreg,9477,2,2020-02-05T08:11:37Z,4738.5
bracer,"Performs brace expansions on strings.  Made popular by Unix shells, brace expansion allows users to concisely generate certain character vectors by taking a single string and (recursively) expanding the comma-separated lists and double-period-separated integer and character sequences enclosed within braces in that string.  The double-period-separated numeric integer expansion also supports padding the resulting numbers with zeros.",2019-09-03,Trevor Davis,https://github.com/trevorld/bracer,TRUE,https://github.com/trevorld/bracer,4153,1,2019-11-24T19:09:12Z,4153
brainGraph,"A set of tools for performing graph theory analysis of brain MRI
    data. It works with data from a Freesurfer analysis (cortical thickness,
    volumes, local gyrification index, surface area), diffusion tensor
    tractography data (e.g., from FSL) and resting-state fMRI data (e.g., from
    DPABI). It contains a graphical user interface for graph visualization and
    data exploration, along with several functions for generating useful
    figures.",2019-11-07,Christopher G. Watson,https://github.com/cwatson/brainGraph,TRUE,https://github.com/cwatson/braingraph,27726,79,2019-11-06T05:31:18Z,350.9620253164557
BRDT,"This is an implementation of design methods for binomial reliability demonstration tests (BRDTs) with failure count data. 
    The acceptance decision uncertainty of BRDT has been quantified and the impacts of the uncertainty on related reliability assurance activities such as reliability growth (RG) and warranty services (WS) are evaluated.
    This package is associated with the work from the published paper ""Optimal Binomial Reliability Demonstration Tests Design under Acceptance Decision Uncertainty"" by Suiyao Chen et al. (2020) <doi:10.1080/08982112.2020.1757703>.",2020-06-09,Suiyao Chen,https://github.com/ericchen12377/BRDT,TRUE,https://github.com/ericchen12377/brdt,0,2,2020-06-09T19:08:00Z,0
breakDown,"Model agnostic tool for decomposition of predictions from black boxes.
    Break Down Table shows contributions of every variable to a final prediction. 
    Break Down Plot presents variable contributions in a concise graphical way. 
    This package work for binary classifiers and general regression models. ",2020-04-05,Przemyslaw Biecek,https://pbiecek.github.io/breakDown/,TRUE,https://github.com/pbiecek/breakdown,29388,87,2020-04-04T23:57:50Z,337.7931034482759
breathtestcore,"Reads several formats of 13C data (IRIS/Wagner,
    BreathID) and CSV.  Creates artificial sample data for testing.  Fits
    Maes/Ghoos, Bluck-Coward self-correcting formula using 'nls', 'nlme'.
    Methods to fit breath test curves with Bayesian Stan methods are
    refactored to package 'breathteststan'. For a Shiny GUI, see package
    'dmenne/breathtestshiny' on github.",2020-03-22,Dieter Menne,https://github.com/dmenne/breathtestcore,TRUE,https://github.com/dmenne/breathtestcore,14985,1,2020-06-08T08:03:44Z,14985
breathteststan,"Stan-based curve-fitting function
  for use with package 'breathtestcore' by the same author.
  Stan functions are refactored here for easier testing.",2020-03-22,Dieter Menne,https://github.com/dmenne/breathteststan,TRUE,https://github.com/dmenne/breathteststan,17500,3,2020-04-13T07:36:34Z,5833.333333333333
brglm2,"Estimation and inference from generalized linear models based on various methods for bias reduction and maximum penalized likelihood with powers of the Jeffreys prior as penalty. The 'brglmFit' fitting method can achieve reduction of estimation bias by solving either the mean bias-reducing adjusted score equations in Firth (1993) <doi:10.1093/biomet/80.1.27> and Kosmidis and Firth (2009) <doi:10.1093/biomet/asp055>, or the median bias-reduction adjusted score equations in Kenne et al. (2016) <arXiv:1604.04768>, or through the direct subtraction of an estimate of the bias of the maximum likelihood estimator from the maximum likelihood estimates as in Cordeiro and McCullagh (1991) <http://www.jstor.org/stable/2345592>. See Kosmidis et al (2019) <doi:10.1007/s11222-019-09860-6> for more details. Estimation in all cases takes place via a quasi Fisher scoring algorithm, and S3 methods for the construction of of confidence intervals for the reduced-bias estimates are provided. In the special case of generalized linear models for binomial and multinomial responses (both ordinal and nominal), the adjusted score approaches return estimates with improved frequentist properties, that are also always finite, even in cases where the maximum likelihood estimates are infinite (e.g. complete and quasi-complete separation). 'brglm2' also provides pre-fit and post-fit methods for detecting separation and infinite maximum likelihood estimates in binomial response generalized linear models.",2020-03-19,Ioannis Kosmidis,https://github.com/ikosmidis/brglm2,TRUE,https://github.com/ikosmidis/brglm2,27917,5,2020-03-19T15:35:26Z,5583.4
brickr,"
    Generate digital LEGO models using 'tidyverse' functions. 
    Convert image files into 2D and 3D LEGO mosaics, complete with piece counts and instructions. 
    Render 3D models using simple data frame instructions.
    Developed under the LEGO Group's Fair Play policy <https://www.lego.com/en-us/legal/notices-and-policies/fair-play/>.",2020-05-09,Ryan Timpe,https://github.com/ryantimpe/brickr,TRUE,https://github.com/ryantimpe/brickr,1930,312,2020-05-09T20:02:55Z,6.185897435897436
bridgesampling,"Provides functions for estimating marginal likelihoods, Bayes
    factors, posterior model probabilities, and normalizing constants in general,
    via different versions of bridge sampling (Meng & Wong, 1996, 
    <http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n43/j6n43.htm>).
    Gronau, Singmann, & Wagenmakers (2020) <doi:10.18637/jss.v092.i10>.",2020-02-26,Quentin F. Gronau,https://github.com/quentingronau/bridgesampling,TRUE,https://github.com/quentingronau/bridgesampling,208871,19,2020-02-24T23:15:25Z,10993.21052631579
brio,"Functions to handle basic input output, these functions always
  read and write UTF-8 (8-bit Unicode Transformation Format) files and provide
  more explicit control over line endings.",2020-03-26,Jim Hester,https://github.com/r-lib/brio,TRUE,https://github.com/r-lib/brio,1670,20,2020-04-20T13:08:53Z,83.5
BRISC,Fits Bootstrap with univariate spatial regression models using Bootstrap for Rapid Inference on Spatial Covariances (BRISC) for large datasets using Nearest Neighbor Gaussian Processes detailed in Saha and Datta (2018) <doi:10.1002/sta4.184>.,2019-08-19,Arkajyoti Saha,https://github.com/ArkajyotiSaha/BRISC,TRUE,https://github.com/arkajyotisaha/brisc,8546,1,2019-08-22T18:41:21Z,8546
BRL,"Implementation of the record linkage methodology proposed by Sadinle (2017) <doi:10.1080/01621459.2016.1148612>.  It handles the bipartite record linkage problem, where two duplicate-free datafiles are to be merged.",2020-01-13,Mauricio Sadinle,https://github.com/msadinle/BRL,TRUE,https://github.com/msadinle/brl,3256,3,2020-01-11T01:25:32Z,1085.3333333333333
brms,"Fit Bayesian generalized (non-)linear multivariate multilevel models
    using 'Stan' for full Bayesian inference. A wide range of distributions 
    and link functions are supported, allowing users to fit -- among others -- 
    linear, robust linear, count data, survival, response times, ordinal, 
    zero-inflated, hurdle, and even self-defined mixture models all in a 
    multilevel context. Further modeling options include non-linear and 
    smooth terms, auto-correlation structures, censored data, meta-analytic 
    standard errors, and quite a few more. In addition, all parameters of the 
    response distribution can be predicted in order to perform distributional 
    regression. Prior specifications are flexible and explicitly encourage 
    users to apply prior distributions that actually reflect their beliefs.
    Model fit can easily be assessed and compared with posterior predictive 
    checks and leave-one-out cross-validation. References: Bürkner (2017)
    <doi:10.18637/jss.v080.i01>; Bürkner (2018) <doi:10.32614/RJ-2018-017>;
    Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",2020-05-27,Paul-Christian Bürkner,"https://github.com/paul-buerkner/brms,
http://discourse.mc-stan.org",TRUE,https://github.com/paul-buerkner/brms,411359,714,2020-06-09T16:24:28Z,576.1330532212885
Brobdingnag,"Handles very large numbers in R.  Real numbers are held
        using their natural logarithms, plus a logical flag indicating
        sign.  The package includes a vignette that gives a
        step-by-step introduction to using S4 methods.",2018-08-13,Robin K. S. Hankin,https://github.com/RobinHankin/Brobdingnag.git,TRUE,https://github.com/robinhankin/brobdingnag,211351,1,2020-04-30T08:43:11Z,211351
broman,"Miscellaneous R functions, including functions related to
    graphics (mostly for base graphics), permutation tests, running
    mean/median, and general utilities.",2020-05-22,Karl W Broman,https://github.com/kbroman/broman,TRUE,https://github.com/kbroman/broman,43235,157,2020-05-21T15:29:32Z,275.38216560509557
broom,"Summarizes key information about statistical
    objects in tidy tibbles. This makes it easy to report results, create
    plots and consistently work with large numbers of models at once.
    Broom provides three verbs that each provide different types of
    information about a model. tidy() summarizes information about model
    components such as coefficients of a regression. glance() reports
    information about an entire model, such as goodness of fit measures
    like AIC and BIC. augment() adds information about individual
    observations to a dataset, such as fitted values or influence
    measures.",2020-04-20,Alex Hayes,http://github.com/tidyverse/broom,TRUE,https://github.com/tidyverse/broom,10361715,953,2020-06-09T16:03:05Z,10872.733473242393
broom.mixed,"Convert fitted objects from various R mixed-model packages
    into tidy data frames along the lines of the 'broom' package.
    The package provides three
    S3 generics for each model: tidy(), which summarizes a model's statistical findings such as
    coefficients of a regression; augment(), which adds columns to the original
    data such as predictions, residuals and cluster assignments; and glance(), which
    provides a one-row summary of model-level statistics.",2020-05-17,Ben Bolker,http://github.com/bbolker/broom.mixed,TRUE,https://github.com/bbolker/broom.mixed,73266,158,2020-05-29T00:44:08Z,463.7088607594937
broomExtra,"Provides helper functions that assist in data
    analysis workflows involving regression analyses. The goal is to
    combine the functionality offered by different set of packages
    ('broom', 'broom.mixed', 'parameters', and 'performance') through a
    common syntax to return tidy dataframes containing model parameters
    and performance measure summaries. The 'grouped_' variants of the
    generics provides a convenient way to execute functions across a
    combination of grouping variable(s) in a dataframe.",2020-05-11,Indrajeet Patil,"https://indrajeetpatil.github.io/broomExtra/,
https://github.com/IndrajeetPatil/broomExtra",TRUE,https://github.com/indrajeetpatil/broomextra,52301,30,2020-05-30T21:16:09Z,1743.3666666666666
brranching,"Includes methods for fetching 'phylogenies' from a variety
    of sources, including the 'Phylomatic' web service 
    (<http://phylodiversity.net/phylomatic>), and 'Phylocom' 
    (<https://github.com/phylocom/phylocom/>).",2019-07-27,Scott Chamberlain,https://github.com/ropensci/brranching,TRUE,https://github.com/ropensci/brranching,27516,13,2020-06-03T23:30:36Z,2116.6153846153848
brunnermunzel,"Provides the functions for Brunner-Munzel test and
    permuted Brunner-Munzel test,
    which enable to use formula, matrix, and table as argument.
    These functions are based on Brunner and Munzel (2000)
     <doi:10.1002/(SICI)1521-4036(200001)42:1%3C17::AID-BIMJ17%3E3.0.CO;2-U>
    and Neubert and Brunner (2007) <doi:10.1016/j.csda.2006.05.024>,
    and are written with FORTRAN.",2020-01-08,Toshiaki Ara,https://github.com/toshi-ara/brunnermunzel,TRUE,https://github.com/toshi-ara/brunnermunzel,8462,3,2020-01-07T13:07:33Z,2820.6666666666665
bs4Dash,"Make 'Bootstrap 4' dashboards. Use the full power
    of 'AdminLTE3', a dashboard template built on top of 'Bootstrap 4' 
    <https://github.com/ColorlibHQ/AdminLTE>.",2019-11-27,David Granjon,"https://rinterface.github.io/bs4Dash/index.html,
https://github.com/RinteRface/bs4Dash",TRUE,https://github.com/rinterface/bs4dash,52042,189,2020-05-27T23:08:18Z,275.35449735449737
bsam,"Tools to fit Bayesian state-space models to animal tracking data. Models are provided for location 
    filtering, location filtering and behavioural state estimation, and their hierarchical versions. 
    The models are primarily intended for fitting to ARGOS satellite tracking data but options exist to fit 
    to other tracking data types. For Global Positioning System data, consider the 'moveHMM' package. 
    Simplified Markov Chain Monte Carlo convergence diagnostic plotting is provided but users are encouraged 
    to explore tools available in packages such as 'coda' and 'boa'.",2017-07-01,Ian Jonsen,https://github.com/ianjonsen/bsam,TRUE,https://github.com/ianjonsen/bsam,17634,13,2020-01-24T13:07:27Z,1356.4615384615386
bSims,"A highly scientific and utterly addictive 
  bird point count simulator 
  to test statistical assumptions, aid survey design,
  and have fun while doing it.
  The simulations follow time-removal and distance sampling models 
  based on Matsuoka et al. (2012) <doi:10.1525/auk.2012.11190>,
  Solymos et al. (2013) <doi:10.1111/2041-210X.12106>,
  and Solymos et al. (2018) <doi:10.1650/CONDOR-18-32.1>,
  and sound attenuation experiments by 
  Yip et al. (2017) <doi:10.1650/CONDOR-16-93.1>.",2019-12-20,Peter Solymos,https://github.com/psolymos/bSims,TRUE,https://github.com/psolymos/bsims,2686,1,2020-05-28T21:54:21Z,2686
bsplus,"The Bootstrap framework lets you add some JavaScript functionality to your web site by
  adding attributes to your HTML tags - Bootstrap takes care of the JavaScript
  <https://getbootstrap.com/javascript>. If you are using R Markdown or Shiny, you can
  use these functions to create collapsible sections, accordion panels, modals, tooltips,
  popovers, and an accordion sidebar framework (not described at Bootstrap site).",2018-04-05,Ian Lyttle,https://github.com/ijlyttle/bsplus,TRUE,https://github.com/ijlyttle/bsplus,26670,118,2020-05-16T18:38:47Z,226.01694915254237
bssm,"Efficient methods for Bayesian inference of state space models 
    via particle Markov chain Monte Carlo (MCMC) and MCMC based on parallel 
    importance sampling type weighted estimators 
    (Vihola, Helske, and Franks, 2020, <arXiv:1609.02541>). 
    Gaussian, Poisson, binomial, negative binomial, and Gamma
    observation densities and basic stochastic volatility models with Gaussian state 
    dynamics, as well as general non-linear Gaussian models and discretised 
    diffusion models are supported.",2020-06-09,Jouni Helske,NA,TRUE,https://github.com/helske/bssm,28538,15,2020-06-09T13:49:25Z,1902.5333333333333
BSW,Implements a modified Newton-type algorithm (BSW algorithm) for solving the maximum likelihood estimation problem in fitting a log-binomial model under linear inequality constraints.,2020-03-25,Adam Bekhit,https://github.com/adam-bec/BSW,TRUE,https://github.com/adam-bec/bsw,1157,0,2020-03-24T14:24:27Z,NA
btergm,"Temporal Exponential Random Graph Models (TERGM) estimated by maximum pseudolikelihood with bootstrapped confidence intervals or Markov Chain Monte Carlo maximum likelihood. Goodness of fit assessment for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs.",2020-04-07,Philip Leifeld,http://github.com/leifeld/btergm,TRUE,https://github.com/leifeld/btergm,128371,6,2020-04-06T19:19:02Z,21395.166666666668
BTM,"Biterm Topic Models find topics in collections of short texts. 
    It is a word co-occurrence based topic model that learns topics by modeling word-word co-occurrences patterns which are called biterms.
    This in contrast to traditional topic models like Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis 
    which are word-document co-occurrence topic models.
    A biterm consists of two words co-occurring in the same short text window.  
    This context window can for example be a twitter message, a short answer on a survey, a sentence of a text or a document identifier. 
    The techniques are explained in detail in the paper 'A Biterm Topic Model For Short Text' by Xiaohui Yan, Jiafeng Guo, Yanyan Lan, Xueqi Cheng (2013) <https://github.com/xiaohuiyan/xiaohuiyan.github.io/blob/master/paper/BTM-WWW13.pdf>.",2020-05-02,Jan Wijffels,https://github.com/bnosac/BTM,TRUE,https://github.com/bnosac/btm,10324,47,2020-05-27T18:01:45Z,219.6595744680851
bucky,"Provides functions for various statistical techniques commonly used in the social sciences, including functions to compute clustered robust standard errors, combine results across multiply-imputed data sets, and simplify the addition of robust and clustered robust standard errors.",2019-12-17,Alexander Tahk,http://github.com/atahk/bucky,TRUE,https://github.com/atahk/bucky,13011,6,2019-12-17T19:00:36Z,2168.5
buildmer,"Finds the largest possible regression model that will still converge
    for various types of regression analyses (including mixed models and generalized
    additive models) and then optionally performs stepwise elimination similar to the
    forward and backward effect-selection methods in SAS, based on the change in
    log-likelihood or its significance, Akaike's Information Criterion, the Bayesian
    Information Criterion, or the explained deviance.",2020-05-27,Cesko C. Voeten,NA,TRUE,https://github.com/cvoeten/buildmer,10016,1,2020-06-07T18:18:51Z,10016
buildr,Working with reproducible reports or any other similar projects often requires to run the script that builds the output file in a specified way. One can become tired from repeatedly switching to the build script and sourcing it. The 'buildr' package does this one simple thing via 'RStudio' addin – user can set up the keyboard shortcut and run the build script with one keystroke anywhere anytime. The second way is to pass buildr() command to console which does the same thing. Both ways source the build.R (case insensitive) file present in the current working directory.,2020-05-12,Jan Netik,https://github.com/netique/buildr,TRUE,https://github.com/netique/buildr,669,1,2020-05-12T10:53:05Z,669
bunching,"Implementation of the bunching estimator for kinks and notches. 
        Allows for flexible estimation of counterfactual (e.g. controlling for round number bunching, accounting for other bunching masses within bunching window, fixing bunching point to be minimum, maximum or median value in its bin, etc.). 
        It produces publication-ready plots in the style followed since Chetty et al. (2011) <DOI:10.1093/qje/qjr013>, with lots of functionality to set plot options.",2019-09-23,Panos Mavrokonstantis,http://github.com/mavpanos/bunching,TRUE,https://github.com/mavpanos/bunching,3713,1,2020-05-19T09:48:45Z,3713
bupaR,"Comprehensive Business Process Analysis toolkit. Creates S3-class for event log objects, and related handler functions. Imports related packages for filtering event data, computation of descriptive statistics, handling of 'Petri Net' objects and visualization of process maps. See also packages 'edeaR','processmapR', 'eventdataR' and 'processmonitR'.",2020-01-22,Gert Janssenswillen,"https://www.bupar.net, https://github.com/bupaverse/bupaR",TRUE,https://github.com/bupaverse/bupar,42098,14,2020-04-30T06:52:58Z,3007
burnr,"Tools to read, write, parse, and analyze forest fire history data (e.g. FHX). Described in Malevich et al. (2018) <doi:10.1016/j.dendro.2018.02.005>.",2019-08-21,Steven Malevich,https://github.com/ltrr-arizona-edu/burnr/,TRUE,https://github.com/ltrr-arizona-edu/burnr,23656,8,2020-03-30T18:25:04Z,2957
butcher,Provides a set of five S3 generics to axe components of fitted model objects and help reduce the size of model objects saved to disk.,2020-01-23,Joyce Cahoon,"https://tidymodels.github.io/butcher,
https://github.com/tidymodels/butcher",TRUE,https://github.com/tidymodels/butcher,6314,62,2020-05-14T17:40:15Z,101.83870967741936
BuyseTest,"Implementation of the Generalized Pairwise Comparisons (GPC)
             as defined in Buyse (2010) <doi:10.1002/sim.3923> for complete observations,
             and extended in Peron (2018) <doi:10.1177/0962280216658320> to deal with right-censoring.        
             GPC compare two groups of observations (intervention vs. control group)
			 regarding several prioritized endpoints to estimate the probability that a random observation drawn from
			 one group performs better than a random observation drawn from the other group (Mann-Whitney parameter).
			 The net benefit and win ratio statistics,
			 i.e. the difference and ratio between the probabilities relative to the intervention and control groups,
			 can then also be estimated. Confidence intervals and p-values are obtained using permutations, a non-parametric bootstrap, or the asymptotic theory.
			 The software enables the use of thresholds of minimal importance difference,
			 stratification, non-prioritized endpoints (O'Brien test), and can handle right-censoring and competing-risks.",2020-05-07,Brice Ozenne,https://github.com/bozenne/BuyseTest,TRUE,https://github.com/bozenne/buysetest,20311,1,2020-05-27T13:27:15Z,20311
BVAR,"Estimation of hierarchical Bayesian vector autoregressive models.
    Implements hierarchical prior selection for conjugate priors in the fashion
    of Giannone, Lenza & Primiceri (2015) <doi:10.1162/REST_a_00483>. Functions
    to compute and identify impulse responses, calculate forecasts,
    forecast error variance decompositions and scenarios are available.
    Several methods to print, plot and summarise results facilitate analysis.",2020-05-05,Nikolas Kuschnig,https://github.com/nk027/bvar,TRUE,https://github.com/nk027/bvar,8466,9,2020-05-11T10:50:51Z,940.6666666666666
bvartools,"Assists in the set-up of algorithms for Bayesian inference of vector autoregressive (VAR) models. Functions for posterior simulation, forecasting, impulse response analysis and forecast error variance decomposition are largely based on the introductory texts of Koop and Korobilis (2010) <doi:10.1561/0800000013> and Luetkepohl (2007, ISBN: 9783540262398). ",2019-08-20,Franz X. Mohr,https://github.com/franzmohr/bvartools,TRUE,https://github.com/franzmohr/bvartools,6318,6,2020-06-03T20:57:04Z,1053
BWStest,"Performs the 'Baumgartner-Weiss-Schindler' two-sample test of equal
   probability distributions, <doi:10.2307/2533862>. Also performs
   similar rank-based tests for equal probability distributions due to
   Neuhauser <doi:10.1080/10485250108832874> and
   Murakami <doi:10.1080/00949655.2010.551516>.",2018-10-18,Steven E. Pav,https://github.com/shabbychef/BWStest,TRUE,https://github.com/shabbychef/bwstest,41480,0,2019-09-02T16:25:04Z,NA
bwsTools,"Tools to design best-worst scaling designs (i.e., balanced incomplete block designs) and
    to analyze data from these designs, using aggregate and individual methods such as: difference 
    scores, Louviere, Lings, Islam, Gudergan, & Flynn (2013) <doi:10.1016/j.ijresmar.2012.10.002>; 
    analytical estimation, Lipovetsky & Conklin (2014) <doi:10.1016/j.jocm.2014.02.001>; empirical 
    Bayes, Lipovetsky & Conklin (2015) <doi:10.1142/S1793536915500028>; Elo, Hollis (2018) 
    <doi:10.3758/s13428-017-0898-2>; and network-based measures.",2020-03-19,Mark White,https://github.com/markhwhiteii/bwsTools,TRUE,https://github.com/markhwhiteii/bwstools,2598,3,2020-06-09T01:35:57Z,866
bysykkel,"Functions to get and download city bike data from 
    the website and API service of each city bike service in Norway. The
    package aims to reduce time spent on getting Norwegian city bike data,
    and lower barriers to start analyzing it. The data is retrieved from
    Oslo City Bike, Bergen City Bike, and Trondheim City Bike. The data is 
    made available under NLOD 2.0 <https://data.norge.no/nlod/en/2.0>.",2020-04-19,Iman Ghayoornia,http://github.com/imangR/bysykkel,TRUE,https://github.com/imangr/bysykkel,6294,0,2020-04-19T14:02:25Z,NA
c14bazAAR,"Query different C14 date databases and apply basic data cleaning, merging and calibration steps.",2020-01-12,Clemens Schmid,"https://docs.ropensci.org/c14bazAAR,
https://github.com/ropensci/c14bazAAR",TRUE,https://github.com/ropensci/c14bazaar,8334,19,2020-04-23T13:07:10Z,438.63157894736844
c3,"Create interactive charts with the 'C3.js' <http://c3js.org/> charting library. All plot 
    types in 'C3.js' are available and include line, bar, scatter, and mixed geometry plots. Plot 
    annotations, labels and axis are highly adjustable. Interactive web based charts can be embedded 
    in R Markdown documents or Shiny web applications. ",2020-03-16,Matt Johnson,https://github.com/mrjoh3/c3,TRUE,https://github.com/mrjoh3/c3,10613,36,2020-03-16T13:02:49Z,294.80555555555554
C50,"C5.0 decision trees and rule-based models for pattern recognition that extend the work of Quinlan (1993, ISBN:1-55860-238-0).",2020-05-26,Max Kuhn,https://topepo.github.io/C5.0,TRUE,https://github.com/topepo/c5.0,525329,40,2020-01-09T20:20:51Z,13133.225
CAISEr,"Functions for performing experimental comparisons of algorithms 
             using adequate sample sizes for power and accuracy. Implements the 
             methodology originally presented in Campelo and Takahashi (2019) 
             <doi:10.1007/s10732-018-9396-7> 
             for the comparison of two algorithms, and later generalised in 
             Campelo and Wanner (Submitted, 2019) <arxiv:1908.01720>.",2020-02-04,Felipe Campelo,https://fcampelo.github.io/CAISEr/,TRUE,https://github.com/fcampelo/caiser,12204,1,2020-02-04T10:08:04Z,12204
calculus,"Efficient C++ optimized functions for numerical and symbolic calculus. It includes basic symbolic arithmetic, tensor calculus, Einstein summing convention, fast computation of the Levi-Civita symbol and generalized Kronecker delta, Taylor series expansion, multivariate Hermite polynomials, accurate high-order derivatives, differential operators (Gradient, Jacobian, Hessian, Divergence, Curl, Laplacian) and numerical integration in arbitrary orthogonal coordinate systems: cartesian, polar, spherical, cylindrical, parabolic or user defined by custom scale factors. ",2020-03-23,Emanuele Guidotti,https://github.com/emanuele-guidotti/calculus,TRUE,https://github.com/emanuele-guidotti/calculus,4391,24,2020-05-20T23:42:33Z,182.95833333333334
calcUnique,"This is a one-function package that will pass only unique values to a computationally-expensive function that returns an output of the same length as the input.
    In importing and working with tidy data, it is common to have index columns, often including time stamps that are far from unique. Some functions to work with these such as text conversion to other variable types (e.g. as.POSIXct()), various grep()-based functions, and often the cut() function are relatively slow when working with tens of millions of rows or more.",2020-05-04,Stephen Froehlich,https://github.com/stephenbfroehlich/calcUnique,TRUE,https://github.com/stephenbfroehlich/calcunique,691,0,2020-05-04T18:45:11Z,NA
calibrar,"Automated parameter estimation for complex (ecological) models in R. 
  This package allows the parameter estimation or calibration of complex models, 
  including stochastic ones. It is a generic tool that can be used for fitting 
  any type of models, especially those with non-differentiable objective functions. 
  It supports multiple phases and constrained optimization. 
  It implements maximum likelihood estimation methods and automated construction 
  of the objective function from simulated model outputs. 
  See <http://roliveros-ramos.github.io/calibrar> for more details.",2016-02-17,Ricardo Oliveros-Ramos,http://roliveros-ramos.github.io/calibrar,TRUE,https://github.com/roliveros-ramos/calibrar,14720,4,2020-02-04T01:50:10Z,3680
calibrator,"Performs Bayesian calibration of computer models as per
 Kennedy and O'Hagan 2001.  The package includes routines to find the
 hyperparameters and parameters; see the help page for stage1() for a
 worked example using the toy dataset.  A tutorial is provided in the
 calex.Rnw vignette; and a suite of especially simple one dimensional
 examples appears in inst/doc/one.dim/.",2019-03-07,Robin K. S. Hankin,https://github.com/RobinHankin/calibrator.git,TRUE,https://github.com/robinhankin/calibrator,35397,1,2020-05-05T21:26:27Z,35397
calmate,A multi-array post-processing method of allele-specific copy-number estimates (ASCNs).,2015-10-27,Henrik Bengtsson,https://github.com/HenrikBengtsson/calmate/,TRUE,https://github.com/henrikbengtsson/calmate,20755,0,2019-12-09T00:29:10Z,NA
camsRad,"Copernicus Atmosphere Monitoring Service (CAMS) radiations service 
    provides time series of global, direct, and diffuse irradiations on horizontal
    surface, and direct irradiation on normal plane for the actual weather 
    conditions as well as for clear-sky conditions.
    The geographical coverage is the field-of-view of the Meteosat satellite,
    roughly speaking Europe, Africa, Atlantic Ocean, Middle East. The time coverage
    of data is from 2004-02-01 up to 2 days ago. Data are available with a time step
    ranging from 15 min to 1 month. For license terms and to create an account,
    please see <http://www.soda-pro.com/web-services/radiation/cams-radiation-service>. ",2016-11-30,Lukas Lundstrom,https://github.com/ropenscilabs/camsRad,TRUE,https://github.com/ropenscilabs/camsrad,12475,8,2019-12-09T12:16:03Z,1559.375
camtrapR,"Management of and data extraction from camera trap data in wildlife studies. The package provides a workflow for storing and sorting camera trap photos (and videos), tabulates records of species and individuals, and creates detection/non-detection matrices for occupancy and spatial capture-recapture analyses with great flexibility. In addition, it can visualise species activity data and provides simple mapping functions with GIS export.",2020-04-23,Juergen Niedballa,"https://github.com/jniedballa/camtrapR,
https://jniedballa.github.io/camtrapR,
https://groups.google.com/forum/#!forum/camtrapr",TRUE,https://github.com/jniedballa/camtrapr,47112,2,2020-05-25T19:10:24Z,23556
cancensus,"Integrated, convenient, and uniform access to Canadian
    Census data and geography retrieved using the 'CensusMapper' API. This package produces analysis-ready 
    tidy data frames and spatial data in multiple formats, as well as convenience functions
    for working with Census variables, variable hierarchies, and region selection. API
    keys are freely available with free registration at <https://censusmapper.ca/api>.
    Census data and boundary geometries are reproduced and distributed on an ""as
    is"" basis with the permission of Statistics Canada (Statistics Canada 2001; 2006;
    2011; 2016).",2020-05-12,Jens von Bergmann,"https://github.com/mountainMath/cancensus,
https://mountainmath.github.io/cancensus/,
https://censusmapper.ca/api",TRUE,https://github.com/mountainmath/cancensus,15416,45,2020-05-30T09:12:48Z,342.5777777777778
candisc,"Functions for computing and visualizing 
	generalized canonical discriminant analyses and canonical correlation analysis
	for a multivariate linear model.
	Traditional canonical discriminant analysis is restricted to a one-way 'MANOVA'
	design and is equivalent to canonical correlation analysis between a set of quantitative
	response variables and a set of dummy variables coded from the factor variable.
	The 'candisc' package generalizes this to higher-way 'MANOVA' designs
	for all factors in a multivariate linear model,
	computing canonical scores and vectors for each term. The graphic functions provide low-rank (1D, 2D, 3D) 
	visualizations of terms in an 'mlm' via the 'plot.candisc' and 'heplot.candisc' methods. Related plots are
	now provided for canonical correlation analysis when all predictors are quantitative.",2020-04-22,Michael Friendly,NA,TRUE,https://github.com/friendly/candisc,159436,2,2020-05-17T17:06:12Z,79718
Canopy,"A statistical framework and computational procedure for identifying
  the sub-populations within a tumor, determining the mutation profiles of each 
  subpopulation, and inferring the tumor's phylogenetic history. The input are 
  variant allele frequencies (VAFs) of somatic single nucleotide alterations 
  (SNAs) along with allele-specific coverage ratios between the tumor and matched
  normal sample for somatic copy number alterations (CNAs). These quantities can
  be directly taken from the output of existing software. Canopy provides a 
  general mathematical framework for pooling data across samples and sites to 
  infer the underlying parameters. For SNAs that fall within CNA regions, Canopy
  infers their temporal ordering and resolves their phase.  When there are 
  multiple evolutionary configurations consistent with the data, Canopy outputs 
  all configurations along with their confidence assessment.",2017-12-18,Yuchao Jiang,https://github.com/yuchaojiang/Canopy,TRUE,https://github.com/yuchaojiang/canopy,17935,42,2019-06-19T14:45:10Z,427.0238095238095
canprot,"Compositional analysis of differentially expressed proteins in
  cancer and cell culture proteomics experiments. The data include lists of up-
  and down-regulated proteins in different cancer types (breast, colorectal,
  liver, lung, pancreatic, prostate) and laboratory conditions (hypoxia,
  hyperosmotic stress, high glucose, 3D cell culture, and proteins secreted in
  hypoxia), together with amino acid compositions computed for protein sequences
  obtained from UniProt. Functions are provided to calculate compositional metrics
  including protein length, carbon oxidation state, and stoichiometric hydration
  state. In addition, phylostrata (evolutionary ages) of protein-coding genes are
  compiled using data from Liebeskind et al. (2016) <doi:10.1093/gbe/evw113> or
  Trigos et al. (2017) <doi:10.1073/pnas.1617743114>. The vignettes contain
  plots of compositional differences, phylostrata for human proteins, and
  references for all datasets.",2020-05-11,Jeffrey Dick,http://github.com/jedick/canprot,TRUE,https://github.com/jedick/canprot,12453,2,2020-06-08T01:02:46Z,6226.5
cansim,"Searches for, accesses, and retrieves new-format and old-format Statistics Canada data 
    tables, as well as individual vectors, as tidy data frames. This package deals with encoding issues, allows for 
    bilingual English or French language data retrieval, and bundles convenience functions 
    to make it easier to work with retrieved table data. Optional caching features are provided.",2020-03-13,Jens von Bergmann,"https://github.com/mountainMath/cansim,
https://mountainmath.github.io/cansim/",TRUE,https://github.com/mountainmath/cansim,10903,19,2020-05-13T01:51:44Z,573.8421052631579
canvasXpress,"Enables creation of visualizations using the CanvasXpress framework
    in R. CanvasXpress is a standalone JavaScript library for reproducible research
    with complete tracking of data and end-user modifications stored in a single
    PNG image that can be played back. See <https://www.canvasxpress.org> for more
    information.",2020-04-11,Connie Brett,https://github.com/neuhausi/canvasXpress.git,TRUE,https://github.com/neuhausi/canvasxpress,47364,233,2020-06-02T19:58:25Z,203.27896995708156
canvasXpress.data,"Contains the prepared data that is needed for the 'shiny' application examples in the 
    'canvasXpress' package.  This package also includes datasets used for automated 'testthat' tests.
    Scotto L, Narayan G, Nandula SV, Arias-Pulido H et al. (2008) <doi:10.1002/gcc.20577>.
    Davis S, Meltzer PS (2007) <doi:10.1093/bioinformatics/btm254>.",2020-05-19,Connie Brett,https://github.com/neuhausi/canvasXpress.data.git,TRUE,https://github.com/neuhausi/canvasxpress.data,1725,0,2020-05-19T21:40:42Z,NA
captioner,"Provides a method for automatically numbering figures,
    tables, or other objects.  Captions can be displayed in full, or as citations.
    This is especially useful for adding figures and tables to R markdown
    documents without having to numbering them manually.",2015-07-16,Letaw Alathea,https://github.com/adletaw/captioner,TRUE,https://github.com/adletaw/captioner,35044,101,2020-02-13T19:26:46Z,346.970297029703
caracas,"Computer algebra via the 'SymPy' library (<https://www.sympy.org/>). 
  This makes it possible to solve equations symbolically, 
  find symbolic integrals, symbolic sums and other important quantities. ",2020-05-21,Mikkel Meyer Andersen,https://github.com/r-cas/caracas,TRUE,https://github.com/r-cas/caracas,2095,6,2020-06-08T13:03:28Z,349.1666666666667
caRamel,"Multi-objective optimizer initially developed for the calibration of hydrological models.
     The algorithm is a hybrid of the MEAS algorithm (Efstratiadis and Koutsoyiannis (2005) <doi:10.13140/RG.2.2.32963.81446>) by using the directional search method based on the simplexes of the objective space 
     and the epsilon-NGSA-II algorithm with the method of classification of the parameter vectors archiving management by epsilon-dominance (Reed and Devireddy <doi:10.1142/9789812567796_0004>).",2019-05-28,Fabrice Zaoui,https://github.com/fzao/caRamel,TRUE,https://github.com/fzao/caramel,10586,1,2019-09-30T13:10:04Z,10586
CARBayes,"Implements a class of univariate and multivariate spatial generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, multinomial, Poisson or zero-inflated Poisson (ZIP), and spatial autocorrelation is modelled by a set of random effects that are assigned a conditional autoregressive (CAR) prior distribution. A number of different models are available for univariate spatial data, including models with no random effects as well as random effects modelled by different types of CAR prior, including the BYM model (Besag et al. (1991) <doi:10.1007/BF00116466>), the Leroux model (Leroux et al. (2000) <doi:10.1007/978-1-4612-1284-3_4>) and the localised model (Lee et al. (2015) <doi:10.1002/env.2348>). Additionally,  a multivariate CAR (MCAR) model for multivariate spatial data is available, as is a two-level hierarchical model for modelling data relating to individuals within areas. Full details are given in the vignette accompanying this package. The initial creation of this package was supported by the Economic and Social Research Council (ESRC) grant RES-000-22-4256, and on-going development has been supported by the Engineering and Physical Science Research Council (EPSRC) grant EP/J017442/1, ESRC grant ES/K006460/1, Innovate UK / Natural Environment Research Council (NERC) grant NE/N007352/1 and the TB Alliance. ",2020-03-13,Duncan Lee,http://github.com/duncanplee/CARBayes,TRUE,https://github.com/duncanplee/carbayes,103977,3,2020-03-13T08:29:50Z,34659
CARBayesST,"Implements a class of spatio-temporal generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, or Poisson, but for some models only the binomial and Poisson data likelihoods are available. The spatio-temporal autocorrelation is modelled by  random effects, which are assigned conditional autoregressive (CAR) style prior distributions. A number of different random effects structures are available, including models similar to Bernardinelli et al. (1995) <doi:10.1002/sim.4780142112>, Rushworth et al. (2014) <doi:10.1016/j.sste.2014.05.001> and Lee et al. (2016) <doi:10.1214/16-AOAS941>. Full details are given in the vignette accompanying this package. The creation of this package was supported by the Engineering and Physical Sciences Research Council (EPSRC) grant EP/J017442/1 and the Medical Research Council (MRC) grant MR/L022184/1.",2020-03-09,Duncan Lee,http://github.com/duncanplee/CARBayesST,TRUE,https://github.com/duncanplee/carbayesst,36116,4,2020-03-06T12:50:52Z,9029
carbonate,"Create beautiful images of source code using
    'carbon.js'<https://carbon.now.sh/about>.",2020-02-07,Jonathan Sidi,https://github.com/yonicd/carbonate,TRUE,https://github.com/yonicd/carbonate,9488,143,2020-05-30T04:56:55Z,66.34965034965035
caret,"Misc functions for training and plotting classification and
    regression models.",2020-03-20,Max Kuhn,https://github.com/topepo/caret/,TRUE,https://github.com/topepo/caret,6106514,1212,2020-03-20T03:07:25Z,5038.377887788779
caretEnsemble,"Functions for creating ensembles of caret models: caretList()
    and caretStack().  caretList() is a convenience function for fitting multiple
    caret::train() models to the same dataset. caretStack() will make linear or
    non-linear combinations of these models, using a caret::train() model as a
    meta-model, and caretEnsemble() will make a robust linear combination of
    models using a GLM.",2019-12-12,Zachary A. Deane-Mayer,https://github.com/zachmayer/caretEnsemble,TRUE,https://github.com/zachmayer/caretensemble,131548,210,2020-05-01T11:15:12Z,626.4190476190477
Carlson,"Evaluation of the Carlson elliptic integrals and the incomplete elliptic integrals with complex arguments. The implementations use Carlson's algorithms <doi.org/10.1007/BF02198293>. Applications of elliptic integrals include probability distributions, geometry, physics, mechanics, electrodynamics, statistical mechanics, astronomy, geodesy, geodesics on conics, and magnetic field calculations.",2020-03-04,Stéphane Laurent,https://github.com/stla/Carlson,TRUE,https://github.com/stla/carlson,1681,0,2020-02-26T09:40:27Z,NA
cartograflow,"Functions to prepare and filter an origin-destination matrix for thematic flow mapping purposes.   
             This comes after Bahoken, Francoise (2016), Mapping flow matrix a contribution, PhD in Geography - Territorial sciences. See Bahoken (2017) <doi:10.4000/netcom.2565>.",2020-06-03,Sylvain Blondeau,https://github.com/fbahoken/cartogRaflow,TRUE,https://github.com/fbahoken/cartograflow,5109,6,2020-06-05T20:59:34Z,851.5
cartogram,Construct continuous and non-contiguous area cartograms.,2019-12-07,Sebastian Jeworutzki,https://github.com/sjewo/cartogram,TRUE,https://github.com/sjewo/cartogram,118226,91,2020-02-18T19:58:56Z,1299.1868131868132
cartography,"Create and integrate maps in your R workflow. This package helps 
    to design cartographic representations such as proportional symbols, 
    choropleth, typology, flows or discontinuities maps. It also offers several 
    features that improve the graphic presentation of maps, for instance, map 
    palettes, layout elements (scale, north arrow, title...), labels or legends. 
    See Giraud and Lambert (2017) <doi:10.1007/978-3-319-57336-6_13>.",2020-04-20,Timothée Giraud,https://github.com/riatelab/cartography/,TRUE,https://github.com/riatelab/cartography,103149,329,2020-06-09T11:07:13Z,313.5227963525836
Cascade,"A modeling tool allowing gene selection, reverse engineering, and prediction in cascade networks. Jung, N., Bertrand, F., Bahram, S., Vallat, L., and Maumy-Bertrand, M. (2014) <doi:10.1093/bioinformatics/btt705>.",2019-08-24,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/Cascade",TRUE,https://github.com/fbertran/cascade,7323,1,2019-10-01T10:30:34Z,7323
CascadeData,"These experimental expression data (5 leukemic 'CLL' B-lymphocyte of aggressive form from 'GSE39411', <doi:10.1073/pnas.1211130110>), after B-cell receptor stimulation, are used as examples by packages such as the 'Cascade' one, a modeling tool allowing gene selection, reverse engineering, and prediction in cascade networks. Jung, N., Bertrand, F., Bahram, S., Vallat, L., and Maumy-Bertrand, M. (2014) <doi:10.1093/bioinformatics/btt705>.",2019-02-07,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/CascadeData",TRUE,https://github.com/fbertran/cascadedata,7343,1,2019-10-01T10:35:07Z,7343
casebase,"Implements the case-base sampling approach of Hanley and Miettinen (2009) <DOI:10.2202/1557-4679.1125>, 
    Saarela and Arjas (2015) <DOI:10.1111/sjos.12125>, and Saarela (2015) <DOI:10.1007/s10985-015-9352-x>, for fitting flexible hazard 
    regression models to survival data with single event type or multiple competing causes via logistic and multinomial regression. 
    From the fitted hazard function, cumulative incidence, risk functions of time, treatment and profile 
    can be derived. This approach accommodates any log-linear hazard function of prognostic time, treatment, 
    and covariates, and readily allows for non-proportionality. We also provide a plot method for visualizing 
    incidence density via population time plots.",2017-04-28,Sahir Bhatnagar,http://sahirbhatnagar.com/casebase/,TRUE,https://github.com/sahirbhatnagar/casebase,11289,4,2020-05-28T15:59:42Z,2822.25
casen,"Funciones para realizar estadistica descriptiva e inferencia con el
 disenio complejo de la Encuesta CASEN (Encuesta de Caracterizacion 
 Socio-Economica). Incluye datasets que permiten armonizar los codigos de 
 comunas que cambian entre anios y permite convertir a los codigos oficiales de 
 SUBDERE.
 (Functions to compute descriptive and inferential statistics with CASEN
 Survey [Socio-Economic Characterization Survey] complex design. Includes 
 datasets to harmonize commune codes that change across years and allows to 
 convert to official SUBDERE codes.)",2020-04-08,Mauricio Vargas,https://pachamaltese.github.io/casen/,TRUE,https://github.com/pachamaltese/casen,1755,3,2020-04-08T04:39:39Z,585
CAST,"Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. This package includes functions to improve spatial-temporal modelling tasks using 'caret'. It prepares data for Leave-Location-Out and Leave-Time-Out cross-validation which are target-oriented validation strategies for spatial-temporal models. To decrease overfitting and improve model performances, the package implements a forward feature selection that selects suitable predictor variables in view to their contribution to the target-oriented performance.",2020-05-19,Hanna Meyer,https://github.com/HannaMeyer/CAST,TRUE,https://github.com/hannameyer/cast,17071,29,2020-06-05T12:29:45Z,588.6551724137931
cat.dt,"Implements the Merged Tree-CAT method (Javier Rodriguez-Cuadrado et al., 2020, <doi:10.1016/j.eswa.2019.113066>) to generate Computerized Adaptive Tests (CATs) based on a decision tree. The tree growth is controlled by merging branches with similar trait distributions and estimations. This package has the necessary tools for creating CATs and estimate the subject's ability level. ",2020-04-23,Javier Rodriguez-Cuadrado,https://github.com/jlaria/cat.dt,TRUE,https://github.com/jlaria/cat.dt,4353,1,2020-05-02T16:20:13Z,4353
categoryEncodings,"Simple, fast, and automatic encodings for category data using 
             a data.table backend. Most of the methods are an implementation 
             of ""Sufficient Representation for Categorical Variables"" by
             Johannemann, Hadad, Athey, Wager (2019) <arXiv:1908.09874>,
             particularly their mean, sparse principal component analysis, 
             low rank representation, and multinomial logit encodings.",2020-03-02,Juraj Szitas,https://github.com/JSzitas/categoryEncodings,TRUE,https://github.com/jszitas/categoryencodings,1714,0,2020-01-30T17:08:53Z,NA
cati,"Detect and quantify community assembly processes using trait values of individuals or populations, the T-statistics (Violle et al. (2012) <doi:10.1016/j.tree.2011.11.014>) and other metrics, and dedicated null models described in Taudiere & Violle (2016) <doi:10.1111/ecog.01433>.",2020-03-02,Adrien Taudiere,https://github.com/adrientaudiere/cati,TRUE,https://github.com/adrientaudiere/cati,23166,7,2019-12-16T14:34:36Z,3309.4285714285716
catsim,"Computes a structural similarity metric (after the style of
    MS-SSIM for images) for binary and categorical 2D and 3D images. Can be
    based on accuracy (simple matching), Cohen's kappa, Rand index, adjusted
    Rand index, Jaccard index, Dice index, normalized mutual information, or
    adjusted mutual information. In addition, has fast computation
    of Cohen's kappa, the Rand indices, and the two mutual informations.
    Implements the methods of Thompson and Maitra (2020) <arXiv:2004.09073>.",2020-05-06,Geoffrey Thompson,"http://github.com/gzt/catsim, https://gzt.github.io/catsim",TRUE,https://github.com/gzt/catsim,793,2,2020-05-06T03:46:17Z,396.5
catSurv,"Provides methods of computerized adaptive testing for survey researchers.  See Montgomery and Rossiter (2019) <doi:10.1093/jssam/smz027>. Includes functionality for data fit with the classic item response methods including the latent trait model, Birnbaum`s three parameter model, the graded response, and the generalized partial credit model.  Additionally, includes several ability parameter estimation and item selection routines.  During item selection, all calculations are done in compiled C++ code.",2019-12-09,Erin Rossiter,NA,TRUE,https://github.com/erossiter/catsurv,11590,6,2019-12-09T20:29:30Z,1931.6666666666667
cattonum,"Functions for aggregate encoding, dummy encoding,
    frequency encoding, label encoding, leave-one-out encoding,
    mean encoding, median encoding, and one-hot encoding.",2020-02-09,Bernie Gray,https://github.com/bfgray3/cattonum,TRUE,https://github.com/bfgray3/cattonum,11674,29,2020-06-07T00:30:51Z,402.55172413793105
causaloptim,"When causal quantities are not identifiable from the observed data, it still may be possible 
            to bound these quantities using the observed data. We outline a class of problems for which the 
            derivation of tight bounds is always a linear programming problem and can therefore, at least 
            theoretically, be solved using a symbolic linear optimizer. We extend and generalize the 
            approach of Balke and Pearl (1994) <doi:10.1016/B978-1-55860-332-5.50011-0> and we provide 
            a user friendly graphical interface for setting up such problems via directed acyclic 
            graphs (DAG), which only allow for problems within this class to be depicted. The user can 
            then define linear constraints to further refine their assumptions to meet their specific 
            problem, and then specify a causal query using a text interface. The program converts this 
            user defined DAG, query, and constraints, and returns tight bounds. The bounds can be 
            converted to R functions to evaluate them for specific datasets, and to latex code for 
            publication. The methods and proofs of tightness and validity of the bounds are described in
            a preprint by Sachs, Gabriel, and Sjölander (2020) 
            <https://sachsmc.github.io/causaloptim/articles/CausalBoundsMethods.pdf>.",2020-05-07,Michael C Sachs,https://github.com/sachsmc/causaloptim,TRUE,https://github.com/sachsmc/causaloptim,1746,7,2020-05-07T14:36:26Z,249.42857142857142
CAWaR,"Tools to process ground-truth data on crop types and perform a phenology based crop type classification. These tools were developed in the scope of the CAWa project and extend on the work of Conrad et al. (2011) <doi:10.1080/01431161.2010.550647>. Moreover, they introduce an innovative classification and validation scheme that utilizes spatially independent samples as proposed by Remelgado et al. (2017) <doi:10.1002/rse2.70>.",2020-06-04,Ruben Remelgado,https://github.com/RRemelgado/fieldRS/,TRUE,https://github.com/rremelgado/fieldrs,2724,10,2020-06-02T13:27:19Z,272.4
CBDA,"Classification performed on Big Data. It uses concepts from compressive sensing, and implements ensemble predictor (i.e., 'SuperLearner') and knockoff filtering as the main machine learning and feature mining engines.",2018-04-16,Simeone Marino,https://github.com/SOCR/CBDA,TRUE,https://github.com/socr/cbda,8576,12,2020-01-23T00:51:37Z,714.6666666666666
cbsodataR,"The data and meta data from Statistics
    Netherlands (<https://www.cbs.nl>) can be browsed and downloaded. The client uses
    the open data API of Statistics Netherlands.",2020-02-20,Edwin de Jonge,https://github.com/edwindj/cbsodataR,TRUE,https://github.com/edwindj/cbsodatar,26311,15,2020-05-27T21:51:48Z,1754.0666666666666
ccafs,"Client for Climate Change, Agriculture, and Food Security ('CCAFS')
    General Circulation Models ('GCM') data. Data is stored in Amazon 'S3', from
    which we provide functions to fetch data.",2017-02-24,Scott Chamberlain,https://github.com/ropensci/ccafs,TRUE,https://github.com/ropensci/ccafs,12556,10,2019-12-09T12:18:13Z,1255.6
CCAMLRGIS,"Loads and creates spatial data, including layers and tools that are relevant
    to the activities of the Commission for the Conservation of Antarctic Marine Living
    Resources. Provides two categories of functions: load functions and create functions.
    Load functions are used to import existing spatial layers from the online CCAMLR GIS
    such as the ASD boundaries. Create functions are used to create layers from user data
    such as polygons and grids.",2020-06-07,Stephane Thanassekos,https://github.com/ccamlr/CCAMLRGIS,TRUE,https://github.com/ccamlr/ccamlrgis,2600,3,2020-06-06T11:11:19Z,866.6666666666666
cchsflow,"Supporting the use of the Canadian Community Health Survey 
             (CCHS) by transforming variables from each cycle into harmonized, 
             consistent versions that span survey cycles (currently, 2001 to 
             2014). CCHS data used in this library is accessed and adapted in 
             accordance to the Statistics Canada Open Licence Agreement. This 
             package uses rec_with_table(), which was developed from 'sjmisc' 
             rec(). Lüdecke D (2018). ""sjmisc: Data and Variable Transformation 
             Functions"". Journal of Open Source Software, 3(26), 754. 
             <doi:10.21105/joss.00754>.",2020-03-30,Doug Manuel,https://github.com/Big-Life-Lab/cchsflow,TRUE,https://github.com/big-life-lab/cchsflow,2334,8,2020-03-30T16:10:11Z,291.75
cdata,"Supplies higher-order coordinatized data specification and fluid transform operators that include pivot and anti-pivot as special cases. 
    The methodology is describe in 'Zumel', 2018, ""Fluid data reshaping with 'cdata'"", <http://winvector.github.io/FluidData/FluidDataReshapingWithCdata.html> , doi:10.5281/zenodo.1173299 .
    This package introduces the idea of explicit control table specification of data transforms.
    Works on in-memory data or on remote data using 'rquery' and 'SQL' database interfaces.",2020-02-01,John Mount,"https://github.com/WinVector/cdata/,
https://winvector.github.io/cdata/",TRUE,https://github.com/winvector/cdata,69573,40,2020-02-15T17:51:40Z,1739.325
cdcfluview,"The 'U.S.' Centers for Disease Control and Prevention (CDC) maintain
    a portal <https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html> for
    accessing state, regional and national influenza statistics as well as
    mortality surveillance data. The web interface makes it difficult and
    time-consuming to select and retrieve influenza data. Tools are provided 
    to access the data provided by the portal's underlying 'API'.",2020-04-02,Bob Rudis,https://github.com/hrbrmstr/cdcfluview,TRUE,https://github.com/hrbrmstr/cdcfluview,23424,44,2020-04-01T19:57:14Z,532.3636363636364
cdcsis,"Conditional distance correlation <doi:10.1080/01621459.2014.993081> is a novel conditional dependence measurement of two multivariate random variables given a confounding variable. This package provides conditional distance correlation, performs the conditional distance correlation sure independence screening procedure for ultrahigh dimensional data <http://www3.stat.sinica.edu.tw/statistica/J28N1/J28N114/J28N114.html>, and conducts conditional distance covariance test for conditional independence assumption of two multivariate variable.",2019-07-10,Wenhao Hu,https://github.com/Mamba413/cdcsis,TRUE,https://github.com/mamba413/cdcsis,20105,1,2019-07-11T02:07:51Z,20105
cde,"Facilitates searching, download and plotting of Water Framework 
  Directive (WFD) reporting data for all waterbodies within the UK Environment 
  Agency area. The types of data that can be downloaded are: WFD status 
  classification data, Reasons for Not Achieving Good (RNAG) status, 
  objectives set for waterbodies, measures put in place to improve water 
  quality and details of associated protected areas. The site accessed is 
  <https://environment.data.gov.uk/catchment-planning/>. The data are made 
  available under the Open Government Licence v3.0 
  <https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/>.
  This package has been peer-reviewed by rOpenSci (v. 0.4.0).",2019-09-04,Rob Briers,https://github.com/ropensci/cde,TRUE,https://github.com/ropensci/cde,3845,4,2020-02-06T12:57:53Z,961.25
cder,"Connect to the California Data Exchange Center (CDEC) 
    Web Service <http://cdec.water.ca.gov/>. 'CDEC' provides a centralized 
    database to store, process, and exchange real-time hydrologic information 
    gathered by various cooperators throughout California. The 'CDEC' Web Service 
    <http://cdec.water.ca.gov/dynamicapp/wsSensorData> provides a data download 
    service for accessing historical records. ",2020-01-24,Michael Koohafkan,https://github.com/mkoohafkan/cder,TRUE,https://github.com/mkoohafkan/cder,4643,1,2020-01-24T17:59:37Z,4643
CDM,"
    Functions for cognitive diagnosis modeling and multidimensional item response modeling 
    for dichotomous and polytomous item responses. This package enables the estimation of 
    the DINA and DINO model (Junker & Sijtsma, 2001, <doi:10.1177/01466210122032064>),
    the multiple group (polytomous) GDINA model (de la Torre, 2011, 
    <doi:10.1007/s11336-011-9207-7>), the multiple choice DINA model (de la Torre, 2009, 
    <doi:10.1177/0146621608320523>), the general diagnostic model (GDM; von Davier, 2008, 
    <doi:10.1348/000711007X193957>), the structured latent class model (SLCA; Formann, 1992, 
    <doi:10.1080/01621459.1992.10475229>) and regularized latent class analysis 
    (Chen, Li, Liu, & Ying, 2017, <doi:10.1007/s11336-016-9545-6>). 
    See George, Robitzsch, Kiefer, Gross, and Uenlue (2017) <doi:10.18637/jss.v074.i02> 
    or Robitzsch and George (2019, <doi:10.1007/978-3-030-05584-4_26>)     
    for further details on estimation and the package structure.
    For tutorials on how to use the CDM package see 
    George and Robitzsch (2015, <doi:10.20982/tqmp.11.3.p189>) as well as
    Ravand and Robitzsch (2015).",2020-03-10,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/CDM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/cdm,231327,9,2020-03-11T14:58:36Z,25703
cdom,Wrapper functions to model and extract various quantitative information from absorption spectra of chromophoric dissolved organic matter (CDOM).,2016-03-04,Philippe Massicotte,https://github.com/PMassicotte/cdom,TRUE,https://github.com/pmassicotte/cdom,15408,4,2020-04-13T23:21:58Z,3852
censusapi,"A wrapper for the U.S. Census Bureau APIs that returns data frames of 
	Census data and metadata. Available datasets include the 
	Decennial Census, American Community Survey, Small Area Health Insurance Estimates,
	Small Area Income and Poverty Estimates, Population Estimates and Projections, and more.",2019-04-13,Hannah Recht,https://github.com/hrecht/censusapi,TRUE,https://github.com/hrecht/censusapi,54265,100,2020-03-28T14:37:14Z,542.65
censusxy,"Provides access to the U.S. Census Bureau's A.P.I for matching American
    street addresses with their longitude and latitude. This includes both single address matching
    as well as batch functionality for multiple addresses. Census geographies can be appended to 
    addresses if desired, and reverse geocoding of point locations to census geographies is also 
    supported. ",2020-05-28,Christopher Prener,https://github.com/slu-openGIS/censusxy,TRUE,https://github.com/slu-opengis/censusxy,4609,6,2020-05-28T18:46:28Z,768.1666666666666
CePa,Use pathway topology information to assign weight to pathway nodes.,2020-02-25,Zuguang Gu,https://github.com/jokergoo/CePa,TRUE,https://github.com/jokergoo/cepa,25818,0,2020-05-23T20:01:40Z,NA
cepR,"
    Retorna detalhes de dados de CEPs brasileiros, bairros, logradouros 
    e tal. (Returns info of Brazilian postal codes, city names, addresses 
    and so on.)",2020-06-02,Robert Myles McDonnell,https://github.com/RobertMyles/cepR,TRUE,https://github.com/robertmyles/cepr,10812,13,2020-06-02T15:29:11Z,831.6923076923077
cepreader,"Read Condensed Cornell Ecology Program ('CEP') and legacy
    'CANOCO' files into R data frames.",2019-05-08,Jari Oksanen,"https://cran.r-project.org/,
https://github.com/vegandevs/cepreader/",TRUE,https://github.com/vegandevs/cepreader,9737,0,2020-02-06T12:46:34Z,NA
ceramic,"Download imagery tiles to a standard cache and load the data into raster objects. 
 Facilities for 'AWS' terrain <https://aws.amazon.com/public-datasets/terrain/> terrain and 'Mapbox' 
 <https://www.mapbox.com/> servers are provided. ",2019-07-20,Michael Sumner,https://github.com/hypertidy/ceramic,TRUE,https://github.com/hypertidy/ceramic,4260,64,2020-06-07T08:05:54Z,66.5625
cetcolor,"Collection of perceptually uniform colour maps made by Peter Kovesi
    (2015) ""Good Colour Maps: How to Design Them"" <arXiv:1509.03700> 
    at the Centre for Exploration Targeting (CET).",2018-07-10,James Balamuta,"https://github.com/coatless/cetcolor,
http://thecoatlessprofessor.com/projects/cetcolor/,
http://peterkovesi.com/projects/colourmaps/",TRUE,https://github.com/coatless/cetcolor,11226,22,2020-01-07T19:51:51Z,510.27272727272725
ceterisParibus,"Ceteris Paribus Profiles (What-If Plots) are designed to present model 
    responses around selected points in a feature space. 
    For example around a single prediction for an interesting observation. 
    Plots are designed to work in a model-agnostic fashion, they are working 
    for any predictive Machine Learning model and allow for model comparisons.
    Ceteris Paribus Plots supplement the Break Down Plots from 'breakDown' package.",2020-03-28,Przemyslaw Biecek,https://pbiecek.github.io/ceterisParibus/,TRUE,https://github.com/pbiecek/ceterisparibus,11941,38,2020-03-26T10:31:57Z,314.2368421052632
cgdsr,"Provides a basic set of R functions for querying the Cancer
  Genomics Data Server (CGDS), hosted by the Computational Biology Center at
  Memorial-Sloan-Kettering Cancer Center (MSKCC) at <www.cbioportal.org>.",2019-06-26,Anders Jacobsen,https://github.com/cBioPortal/cgdsr,TRUE,https://github.com/cbioportal/cgdsr,61715,17,2019-06-25T20:17:02Z,3630.294117647059
CGE,"Developing general equilibrium models, computing general equilibrium and simulating economic dynamics with structural dynamic models in LI (2019, ISBN: 9787521804225) ""General Equilibrium and Structural Dynamics: Perspectives of New Structural Economics. Beijing: Economic Science Press"". When developing complex general equilibrium models, GE package should be used in addition to this package.",2020-05-24,LI Wu,NA,TRUE,https://github.com/liwur/cge,13465,0,2020-01-31T02:42:46Z,NA
CGGP,"Run computer experiments using the adaptive composite grid
    algorithm with a Gaussian process model.
    The algorithm works best when running an experiment that can evaluate thousands
    of points from a deterministic computer simulation.
    This package is an implementation of a forthcoming paper by Plumlee,
    Erickson, Ankenman, et al. For a preprint of the paper,
    contact the maintainer of this package.",2020-03-29,Collin Erickson,https://github.com/CollinErickson/CGGP,TRUE,https://github.com/collinerickson/cggp,4674,1,2020-03-31T00:06:03Z,4674
cghRA,"Provides functions to import data from Agilent CGH arrays and process them according to the cghRA workflow. Implements several algorithms such as WACA, STEPS and cnvScore and an interactive graphical interface.",2017-03-03,Sylvain Mareschal,http://www.ovsa.fr/cghRA,TRUE,https://github.com/maressyl/r.cghra,13310,0,2020-05-03T10:33:49Z,NA
CGPfunctions,Miscellaneous functions useful for teaching statistics as well as actually practicing the art. They typically are not new methods but rather wrappers around either base R or other packages.,2020-05-27,Chuck Powell,https://github.com/ibecav/CGPfunctions,TRUE,https://github.com/ibecav/cgpfunctions,18777,10,2020-05-27T17:58:24Z,1877.7
cgraph,"Allows to create, evaluate, and differentiate computational graphs in R. A computational graph is a graph representation of a multivariate function decomposed by its (elementary) operations. Nodes in the graph represent arrays while edges represent dependencies among the arrays. An advantage of expressing a function as a computational graph is that this enables to differentiate the function by automatic differentiation. The 'cgraph' package supports various operations including basic arithmetic, trigonometry operations, and linear algebra operations. It differentiates computational graphs by reverse automatic differentiation. The flexible architecture of the package makes it applicable to solve a variety of problems including local sensitivity analysis, gradient-based optimization, and machine learning.",2020-02-09,Ron Triepels,https://cgraph.org/,TRUE,https://github.com/triepels/cgraph,18971,11,2020-04-16T12:19:50Z,1724.6363636363637
chandwich,"Performs adjustments of a user-supplied independence loglikelihood 
    function using a robust sandwich estimator of the parameter covariance 
    matrix, based on the methodology in Chandler and Bate (2007) 
    <doi:10.1093/biomet/asm015>.  This can be used for cluster correlated data 
    when interest lies in the parameters of the marginal distributions or for 
    performing inferences that are robust to certain types of model 
    misspecification.  Functions for profiling the adjusted loglikelihoods are 
    also provided, as are functions for calculating and plotting confidence 
    intervals, for single model parameters, and confidence regions, for pairs 
    of model parameters.  Nested models can be compared using an adjusted 
    likelihood ratio test.",2019-07-11,Paul J. Northrop,http://github.com/paulnorthrop/chandwich,TRUE,https://github.com/paulnorthrop/chandwich,10354,1,2019-11-26T22:58:02Z,10354
changepoint,"Implements various mainstream and specialised changepoint methods for finding single and multiple changepoints within data.  Many popular non-parametric and frequentist methods are included.  The cpt.mean(), cpt.var(), cpt.meanvar() functions should be your first point of call.",2016-10-04,Rebecca Killick,https://github.com/rkillick/changepoint/,TRUE,https://github.com/rkillick/changepoint,167781,79,2019-07-19T09:31:01Z,2123.8101265822784
changepoint.geo,Implements the high-dimensional changepoint detection method GeomCP and the related mappings used for changepoint detection. These methods view the changepoint problem from a geometrical viewpoint and aim to extract relevant geometrical features in order to detect changepoints. The geomcp() function should be your first point of call. References: Grundy et al. (2020) <doi:10.1007/s11222-020-09940-y>. ,2020-03-31,Thomas Grundy,https://github.com/grundy95/changepoint.geo/,TRUE,https://github.com/grundy95/changepoint.geo,1026,2,2020-03-31T13:12:13Z,513
changer,Changing the name of an existing R package is annoying but common task especially in the early stages of package development. This package (mostly) automates this task.,2018-10-21,Jouni Helske,https://github.com/helske/changer,TRUE,https://github.com/helske/changer,7866,13,2020-02-17T16:03:08Z,605.0769230769231
cheatR,"A set of functions to compare texts for similarity, and plot a graph of similarities among the compared texts. These functions were originally developed for detection of overlap in course hand-in.",2020-05-06,Mattan S. Ben-Shachar,https://mattansb.github.io/cheatR,TRUE,https://github.com/mattansb/cheatr,525,16,2020-05-06T19:48:15Z,32.8125
chebpol,"Contains methods for creating multivariate/multidimensional
  interpolations of functions on a hypercube. If available through fftw3, the DCT-II/FFT
  is used to compute coefficients for a Chebyshev interpolation.
  Other interpolation methods for arbitrary Cartesian grids are also provided, a piecewise multilinear,
  and the Floater-Hormann barycenter method. For scattered data polyharmonic splines with a linear term
  is provided. The time-critical parts are written in C for speed. All interpolants are parallelized if
  used to evaluate more than one point.",2019-12-09,Simen Gaure,https://github.com/sgaure/chebpol,TRUE,https://github.com/sgaure/chebpol,41808,5,2019-12-09T11:45:16Z,8361.6
checkdown,"Creates auto checking check-fields and check-boxes for 'rmarkdown' html. It could be used in class, when teacher share materials and tasks, so student can solve some problems and check themselves. In contrast with the 'learnr' package the 'checkdown' package works without 'shiny'.",2020-05-17,George Moroz,https://agricolamz.github.io/checkdown/,TRUE,https://github.com/agricolamz/checkdown,2193,15,2020-05-20T13:01:06Z,146.2
checkLuhn,"Confirms if the number is Luhn compliant.
    Can check if credit card, IMEI number or any other Luhn based number is correct. 
    For more info see: <https://en.wikipedia.org/wiki/Luhn_algorithm>.",2018-09-24,Adam Deacon,https://github.com/adamjdeacon/checkLuhn,TRUE,https://github.com/adamjdeacon/checkluhn,9871,2,2020-05-19T14:21:59Z,4935.5
checkmate,"Tests and assertions to perform frequent argument checks. A
    substantial part of the package was written in C to minimize any worries
    about execution time overhead.",2020-02-06,Michel Lang,https://github.com/mllg/checkmate,TRUE,https://github.com/mllg/checkmate,6056273,151,2020-06-06T20:14:30Z,40107.76821192053
checkpoint,"The goal of checkpoint is to solve the problem of package
    reproducibility in R. Specifically, checkpoint allows you to install packages
    as they existed on CRAN on a specific snapshot date as if you had a CRAN time
    machine. To achieve reproducibility, the checkpoint() function installs the
    packages required or called by your project and scripts to a local library
    exactly as they existed at the specified point in time. Only those packages
    are available to your project, thereby avoiding any package updates that came
    later and may have altered your results. In this way, anyone using checkpoint's
    checkpoint() can ensure the reproducibility of your scripts or projects at any
    time. To create the snapshot archives, once a day (at midnight UTC) Microsoft
    refreshes the Austria CRAN mirror on the ""Microsoft R Archived Network""
    server (<https://mran.microsoft.com/>). Immediately after completion
    of the rsync mirror process, the process takes a snapshot, thus creating the
    archive. Snapshot archives exist starting from 2014-09-17.",2020-02-23,Hong Ooi,https://github.com/RevolutionAnalytics/checkpoint,TRUE,https://github.com/revolutionanalytics/checkpoint,103366,136,2020-04-24T09:03:37Z,760.0441176470588
checkr,"Expressive, assertive, pipe-friendly functions 
  to check the properties of common R objects.
  In the case of failure the functions issue informative error messages.",2019-04-25,Joe Thorley,https://github.com/poissonconsulting/checkr,TRUE,https://github.com/poissonconsulting/checkr,21015,9,2020-05-12T19:54:40Z,2335
cheddar,"Provides a flexible, extendable representation of an ecological community and a range of functions for analysis and visualisation, focusing on food web, body mass and numerical abundance data. Allows inter-web comparisons such as examining changes in community structure over environmental, temporal or spatial gradients.",2020-02-13,Lawrence Hudson with contributions from Dan Reuman and Rob Emerson,https://github.com/quicklizard99/cheddar/,TRUE,https://github.com/quicklizard99/cheddar,30470,12,2020-02-12T20:37:21Z,2539.1666666666665
cheese,"Contains tools for working with data during statistical analysis, promoting flexible, intuitive, and reproducible workflows. There are functions designated for specific statistical tasks such building a custom univariate descriptive table, computing pairwise association statistics, etc. These are built on a collection of data manipulation tools designed for general use that are motivated by the functional programming concept.",2020-04-30,Alex Zajichek,"https://zajichek.github.io/cheese,
https://github.com/zajichek/cheese",TRUE,https://github.com/zajichek/cheese,6629,0,2020-04-30T13:07:00Z,NA
chemCal,"Simple functions for plotting linear
	calibration functions and estimating standard errors for measurements
	according to the Handbook of Chemometrics and Qualimetrics: Part A
	by Massart et al. There are also functions estimating the limit
	of detection (LOD) and limit of quantification (LOQ).
	The functions work on model objects from - optionally weighted - linear
	regression (lm) or robust linear regression ('rlm' from the 'MASS' package).",2018-07-17,Johannes Ranke,"https://pkgdown.jrwb.de/chemCal,
https://cgit.jrwb.de/chemCal/about",TRUE,https://github.com/jranke/chemcal,29528,2,2020-05-20T06:44:47Z,14764
ChemometricsWithR,"Functions and scripts used in the book ""Chemometrics with R - Multivariate Data Analysis in the Natural Sciences and Life Sciences"" by Ron Wehrens, Springer (2011). Data used in the package are available from github.",2019-01-07,Ron Wehrens,https://github.com/rwehrens/CWR,TRUE,https://github.com/rwehrens/cwr,42082,4,2019-12-18T11:24:57Z,10520.5
ChemoSpec,"A collection of functions for top-down exploratory data analysis
    of spectral data including nuclear magnetic resonance (NMR), infrared (IR),
    Raman, X-ray fluorescence (XRF) and other similar types of spectroscopy.
    Includes functions for plotting and inspecting spectra, peak alignment,
    hierarchical cluster analysis (HCA), principal components analysis (PCA) and
    model-based clustering. Robust methods appropriate for this type of
    high-dimensional data are available. ChemoSpec is designed for structured
    experiments, such as metabolomics investigations, where the samples fall into
    treatment and control groups. Graphical output is formatted consistently for
    publication quality plots. ChemoSpec is intended to be very user friendly and
    to help you get usable results quickly. A vignette covering typical operations
    is available.",2020-01-24,Bryan A. Hanson,https://bryanhanson.github.io/ChemoSpec/,TRUE,https://github.com/bryanhanson/chemospec,58648,32,2020-01-24T20:03:09Z,1832.75
ChemoSpec2D,"A collection of functions for exploratory chemometrics of 2D spectroscopic data sets such as COSY (correlated spectroscopy) and HSQC (heteronuclear single quantum coherence) 2D NMR (nuclear magnetic resonance) spectra. 'ChemoSpec2D' deploys methods aimed primarily at classification of samples and the identification of spectral features which are important in distinguishing samples from each other. Each 2D spectrum (a matrix) is treated as the unit of observation, and thus the physical sample in the spectrometer corresponds to the  sample from a statistical perspective.  In addition to chemometric tools, a few tools are provided for plotting 2D spectra, but these are not intended to replace the functionality typically available on the spectrometer. 'ChemoSpec2D' takes many of its cues from 'ChemoSpec' and tries to create consistent graphical output and to be very user friendly.",2020-02-19,Bryan A. Hanson,https://github.com/bryanhanson/ChemoSpec2D,TRUE,https://github.com/bryanhanson/chemospec2d,8109,1,2020-02-19T16:50:01Z,8109
ChemoSpecUtils,Functions supporting the common needs of packages 'ChemoSpec' and 'ChemoSpec2D'.,2020-04-20,Bryan A. Hanson,https://github.com/bryanhanson/ChemoSpecUtils,TRUE,https://github.com/bryanhanson/chemospecutils,18241,0,2020-04-20T13:12:01Z,NA
childesr,"Tools for connecting to 'CHILDES', an open repository for
    transcripts of parent-child interaction. For more information on the
    underlying data, see <http://childes-db.stanford.edu>.",2019-10-17,Mika Braginsky,https://github.com/langcog/childesr,TRUE,https://github.com/langcog/childesr,9761,7,2019-10-16T23:04:44Z,1394.4285714285713
chilemapas,"Mapas terrestres con topologias simplificadas. Estos mapas no 
  tienen precision geodesica, por lo que aplica el DFL-83 de 1979 de la Republica
  de Chile y se consideran referenciales sin validez legal.
  No se incluyen los territorios antarticos y bajo ningun evento estos mapas
  significan que exista una cesion u ocupacion de territorios soberanos en
  contra del Derecho Internacional por parte de Chile. Esta paquete esta 
  documentado intencionalmente en castellano asciificado para que funcione sin 
  problema en diferentes plataformas.
  (Terrestrial maps with simplified toplogies. These maps lack geodesic
  precision, therefore DFL-83 1979 of the Republic of Chile applies and are
  considered to have no legal validity.
  Antartic territories are excluded and under no event these maps mean
  there is a cession or occupation of sovereign territories against International
  Laws from Chile. This package was intentionally documented in asciified
  spanish to make it work without problem on different platforms.)",2020-03-28,Mauricio Vargas,https://pachamaltese.github.io/chilemapas/,TRUE,https://github.com/pachamaltese/chilemapas,2876,11,2020-04-23T17:32:41Z,261.45454545454544
chisq.posthoc.test,Perform post hoc analysis based on residuals of Pearson's Chi-squared Test for Count Data based on T. Mark Beasley & Randall E. Schumacker (1995) <doi: 10.1080/00220973.1995.9943797>.,2019-10-25,Daniel Ebbert,http://chisq-posthoc-test.ebbert.nrw/,TRUE,https://github.com/ebbertd/chisq.posthoc.test,4588,0,2019-11-06T11:01:56Z,NA
chk,"For developers to check user-supplied function
    arguments.  It is designed to be simple, fast and customizable.  Error
    messages follow the tidyverse style guide.",2020-05-29,Joe Thorley,https://github.com/poissonconsulting/chk,TRUE,https://github.com/poissonconsulting/chk,11567,23,2020-05-29T17:36:36Z,502.9130434782609
chlorpromazineR,"As different antipsychotic medications have different potencies,
    the doses of different medications cannot be directly compared. Various
    strategies are used to convert doses into a common reference so that
    comparison is meaningful. Chlorpromazine (CPZ) has historically been used
    as a reference medication into which other antipsychotic doses can be
    converted, as ""chlorpromazine-equivalent doses"". Using conversion keys
    generated from widely-cited scientific papers (Gardner et. al 2010
    <doi:10.1176/appi.ajp.2009.09060802>, Leucht et al. 2016
    <doi:10.1093/schbul/sbv167>), antipsychotic doses are converted
    to CPZ (or any specified antipsychotic) equivalents. The use of the package
    is described in the included vignette. Not for clinical use.",2019-10-11,Eric Brown,https://github.com/ropensci/chlorpromazineR,TRUE,https://github.com/ropensci/chlorpromaziner,3354,5,2020-02-12T01:47:27Z,670.8
cholera,"Amends errors, augments data and aids analysis of John Snow's map
  of the 1854 London cholera outbreak.",2019-08-28,Peter Li,https://github.com/lindbrook/cholera,TRUE,https://github.com/lindbrook/cholera,15617,111,2020-06-05T21:37:29Z,140.6936936936937
chorrrds,"Extracts music chords from the 'CifraClub' website <https://www.cifraclub.com.br/>.
	The package also has functions for cleaning the extracted data and 
	feature extraction.",2020-03-16,Bruna Wundervald,https://github.com/r-music/chorrrds,TRUE,https://github.com/r-music/chorrrds,14576,78,2020-03-16T12:24:23Z,186.87179487179486
chromer,"A programmatic interface to the Chromosome Counts Database
    (http://ccdb.tau.ac.il/). This package is part of the rOpenSci suite
    (http://ropensci.org)",2015-01-13,Matthew Pennell,http://www.github.com/ropensci/chromer,TRUE,https://github.com/ropensci/chromer,18400,6,2019-11-29T04:55:48Z,3066.6666666666665
chromseq,"Chromosome files in the 'Fasta' format usually contain large sequences like human genome.
  Sometimes users have to split these chromosomes into different files according to their 
  chromosome number. The 'chromseq' can help to handle this. So the selected chromosome sequence can be
  used for downstream analysis like motif finding. Howard Y. Chang(2019)
  <doi:10.1038/s41587-019-0206-z>.",2020-05-11,Shaoqian Ma,https://github.com/MSQ-123/chromseq,TRUE,https://github.com/msq-123/chromseq,439,0,2020-05-19T08:34:02Z,NA
chunked,"Data stored in text file can be processed chunkwise using 'dplyr' commands. These
    are recorded and executed per data chunk, so large files can be processed with
    limited memory using the 'LaF' package.",2020-03-24,Edwin de Jonge,https://github.com/edwindj/chunked,TRUE,https://github.com/edwindj/chunked,20865,145,2020-05-14T13:58:52Z,143.89655172413794
cicerone,Provide step by step guided tours of 'Shiny' applications.,2020-02-29,John Coene,https://cicerone.john-coene.com/,TRUE,https://github.com/johncoene/cicerone,1758,69,2020-04-03T16:57:53Z,25.47826086956522
cimir,"Connect to the California Irrigation Management 
    Information System (CIMIS) Web API. See the CIMIS main page 
    <https://cimis.water.ca.gov> and web API documentation
    <https://et.water.ca.gov> for more information.",2020-01-22,Michael Koohafkan,https://github.com/mkoohafkan/cimir,TRUE,https://github.com/mkoohafkan/cimir,7188,3,2020-01-24T18:00:33Z,2396
circlize,"Circular layout is an efficient way for the visualization of huge 
    amounts of information. Here this package provides an implementation 
    of circular layout generation in R as well as an enhancement of available 
    software. The flexibility of the package is based on the usage of low-level 
    graphics functions such that self-defined high-level graphics can be easily 
    implemented by users for specific purposes. Together with the seamless 
    connection between the powerful computational and visual environment in R, 
    it gives users more convenience and freedom to design figures for 
    better understanding complex patterns behind multiple dimensional data. 
    The package is described in Gu et al. 2014 <doi:10.1093/bioinformatics/btu393>.",2020-04-30,Zuguang Gu,"https://github.com/jokergoo/circlize,
http://jokergoo.github.io/circlize_book/book/",TRUE,https://github.com/jokergoo/circlize,562765,545,2020-06-09T12:21:15Z,1032.5963302752293
circumplex,"Tools for analyzing and visualizing circular data,
    including scoring functions for relevant instruments and a
    generalization of the bootstrapped structural summary method from
    Zimmermann & Wright (2017) <doi:10.1177/1073191115621795> and
    functions for creating publication-ready tables and figures from the
    results. Future versions will include tools for circular fit and
    reliability analyses, as well as visualization enhancements.",2020-04-29,Jeffrey Girard,https://github.com/jmgirard/circumplex,TRUE,https://github.com/jmgirard/circumplex,15600,6,2020-06-03T02:40:49Z,2600
cIRT,"Jointly model the accuracy of cognitive responses and item choices
    within a Bayesian hierarchical framework as described by Culpepper and
    Balamuta (2015) <doi:10.1007/s11336-015-9484-7>. In addition, the package
    contains the datasets used within the analysis of the paper.",2020-03-23,Steven Andrew Culpepper,"https://tmsalab.github.io/cIRT, https://github.com/tmsalab/cIRT",TRUE,https://github.com/tmsalab/cirt,19292,3,2020-03-22T20:03:15Z,6430.666666666667
citecorp,"Client for the Open Citations Corpus (<http://opencitations.net/>).
    Includes a set of functions for getting one identifier type from another,
    as well as getting references and citations for a given identifier.",2020-04-16,Scott Chamberlain,"https://github.com/ropenscilabs/citecorp (devel),
https://docs.ropensci.org/citecorp/ (docs)",TRUE,https://github.com/ropenscilabs/citecorp,4740,10,2020-04-15T16:48:07Z,474
ciTools,"Functions to append confidence intervals, prediction intervals,
    and other quantities of interest to data frames. All appended quantities
    are for the response variable, after conditioning on the model and covariates.
    This package has a data frame first syntax that allows for easy piping.
    Currently supported models include (log-) linear, (log-) linear mixed,
    generalized linear models, generalized linear mixed models, and
    accelerated failure time models.",2019-01-08,John Haman,https://github.com/jthaman/ciTools,TRUE,https://github.com/jthaman/citools,30413,93,2019-07-10T22:42:16Z,327.02150537634407
citr,"Functions and an 'RStudio' add-in that search 'Bib(La)TeX'-files or
  'Zotero' libraries (via the 'Better BibTeX' plugin) to insert formatted Markdown
  citations into the current document.",2019-08-19,Frederik Aust,https://github.com/crsh/citr,TRUE,https://github.com/crsh/citr,42918,286,2020-06-04T08:42:08Z,150.06293706293707
civis,"A convenient interface for making
  requests directly to the 'Civis Platform API' <https://www.civisanalytics.com/platform/>.
  Full documentation available 'here' <https://civisanalytics.github.io/civis-r/>.",2020-02-24,Patrick Miller,https://github.com/civisanalytics/civis-r,TRUE,https://github.com/civisanalytics/civis-r,96642,13,2020-05-20T20:18:26Z,7434
classInt,Selected commonly used methods for choosing univariate class intervals for mapping or other graphics purposes.,2020-04-07,Roger Bivand,"https://r-spatial.github.io/classInt/,
https://github.com/r-spatial/classInt/",TRUE,https://github.com/r-spatial/classint,2930670,20,2020-03-27T19:03:29Z,146533.5
classyfireR,Access to the ClassyFire RESTful API <http://classyfire.wishartlab.com>. Retrieve existing entity classifications and submit new entities for classification. ,2020-02-18,Tom Wilson,https://github.com/aberHRML/classyfireR,TRUE,https://github.com/aberhrml/classyfirer,11564,2,2020-02-18T10:42:33Z,5782
cld2,"Bindings to Google's C++ library Compact Language Detector 2
    (see <https://github.com/cld2owners/cld2#readme> for more information). Probabilistically
    detects over 80 languages in plain text or HTML. For mixed-language input it returns the
    top three detected languages and their approximate proportion of the total classified 
    text bytes (e.g. 80% English and 20% French out of 1000 bytes). There is also a 'cld3'
    package on CRAN which uses a neural network model instead.",2018-05-11,Jeroen Ooms,"https://github.com/ropensci/cld2 (devel)
https://github.com/cld2owners/cld2 (upstream)",TRUE,https://github.com/ropensci/cld2,25117,31,2019-12-08T22:40:50Z,810.2258064516129
cld3,"Google's Compact Language Detector 3 is a neural network model for language 
    identification and the successor of 'cld2' (available from CRAN). The algorithm is still
    experimental and takes a novel approach to language detection with different properties
    and outcomes. It can be useful to combine this with the Bayesian classifier results 
    from 'cld2'. See <https://github.com/google/cld3#readme> for more information.",2020-01-31,Jeroen Ooms,"https://docs.ropensci.org/cld3, https://github.com/ropensci/cld3
(devel) https://github.com/google/cld3 (upstream)",TRUE,https://github.com/ropensci/cld3,20096,23,2020-01-31T11:29:27Z,873.7391304347826
clean,"A wrapper around the new 'cleaner' package, that allows
  data cleaning functions for classes 'logical', 'factor', 'numeric', 
  'character', 'currency' and 'Date' to make data cleaning fast and
  easy. Relying on very few dependencies, it provides smart guessing,
  but with user options to override anything if needed.",2020-06-01,Matthijs S. Berends,https://github.com/msberends/cleaner,TRUE,https://github.com/msberends/cleaner,6775,9,2020-06-01T13:43:34Z,752.7777777777778
cleaner,"Data cleaning functions for classes logical,
  factor, numeric, character, currency and Date to make
  data cleaning fast and easy. Relying on very few dependencies, it 
  provides smart guessing, but with user options to override 
  anything if needed.",2020-06-01,Matthijs S. Berends,https://github.com/msberends/cleaner,TRUE,https://github.com/msberends/cleaner,7095,9,2020-06-01T13:43:34Z,788.3333333333334
cleangeo,"
  Provides a set of utility tools to inspect spatial objects, facilitate
  handling and reporting of topology errors and geometry validity issues.
  Finally, it provides a geometry cleaner that will fix all geometry problems,
  and eliminate (at least reduce) the likelihood of having issues when doing
  spatial data processing.",2019-12-04,Emmanuel Blondel,https://github.com/eblondel/cleangeo,TRUE,https://github.com/eblondel/cleangeo,35268,39,2019-12-04T15:27:07Z,904.3076923076923
cleanNLP,"Provides a set of fast tools for converting a textual corpus into
  a set of normalized tables. Users may make use of the 'udpipe' back end with
  no external dependencies, or two Python back ends with 'spaCy'
  <https://spacy.io> or 'CoreNLP' <http://stanfordnlp.github.io/CoreNLP/>.
  Exposed annotation tasks include tokenization, part of speech tagging, named
  entity recognition, and dependency parsing.",2020-03-08,Taylor B. Arnold,https://statsmaths.github.io/cleanNLP/,TRUE,https://github.com/statsmaths/cleannlp,27935,166,2020-03-30T08:37:41Z,168.28313253012047
clere,"Implements an empirical Bayes approach for
    simultaneous variable clustering and regression. This version also
    (re)implements in C++ an R script proposed by Howard Bondell that fits
    the Pairwise Absolute Clustering and Sparsity (PACS) methodology (see
    Sharma et al (2013) <DOI:10.1080/15533174.2012.707849>).",2020-02-06,Loic Yengo,https://github.com/mcanouil/clere,TRUE,https://github.com/mcanouil/clere,19466,0,2020-02-07T09:35:43Z,NA
clhs,"Conditioned Latin hypercube sampling, as published by Minasny and McBratney (2006) <DOI:10.1016/j.cageo.2005.12.009>. This method proposes to stratify sampling in presence of ancillary data. An extension of this method, which propose to associate a cost to each individual and take it into account during the optimisation process, is also proposed (Roudier et al., 2012, <DOI:10.1201/b12728>).",2020-04-15,Pierre Roudier,https://github.com/pierreroudier/clhs/,TRUE,https://github.com/pierreroudier/clhs,29382,7,2020-04-15T23:25:21Z,4197.428571428572
clifford,"A suite of routines for Clifford algebras, using the
   'Map' class of the Standard Template Library.  Canonical
   reference: Hestenes (1987, ISBN 90-277-1673-0, ""Clifford algebra
   to geometric calculus"").  Special cases including Lorentz transforms,
   quaternion multiplication, and Grassman algebra, are discussed.
   Conformal geometric algebra theory is implemented.",2020-03-08,Robin K. S. Hankin,https://github.com/RobinHankin/clifford.git,TRUE,https://github.com/robinhankin/clifford,2406,0,2020-06-03T22:17:52Z,NA
clifro,"CliFlo is a web portal to the New Zealand National Climate
    Database and provides public access (via subscription) to around 6,500
    various climate stations (see <https://cliflo.niwa.co.nz/> for more
    information). Collating and manipulating data from CliFlo
    (hence clifro) and importing into R for further analysis, exploration and
    visualisation is now straightforward and coherent. The user is required to
    have an internet connection, and a current CliFlo subscription (free) if
    data from stations, other than the public Reefton electronic weather
    station, is sought.",2019-03-20,Blake Seers,https://github.com/ropensci/clifro,TRUE,https://github.com/ropensci/clifro,32944,19,2019-12-09T12:19:14Z,1733.8947368421052
climate,"Automatize downloading of meteorological and hydrological data from publicly available repositories:
    OGIMET (<http://ogimet.com/index.phtml.en>), 
    University of Wyoming - atmospheric vertical profiling data (<http://weather.uwyo.edu/upperair>),
    Polish Institute of Meterology and Water Management - National Research Institute (<https://dane.imgw.pl>),
    and National Oceanic & Atmospheric Administration (NOAA).
    This package also allows for adding geographical coordinates for each observation.",2020-06-03,Bartosz Czernecki,https://github.com/bczernecki/climate,TRUE,https://github.com/bczernecki/climate,5128,26,2020-05-27T10:40:27Z,197.23076923076923
climateStability,"Climate stability measures are not formalized in the literature and
  tools for generating stability metrics from existing data are nascent.
  This package provides tools for calculating climate stability from raster data
  encapsulating climate change as a series of time slices. The methods follow
  Owens and Guralnick <doi:10.17161/bi.v14i0.9786> Biodiversity Informatics.",2019-11-21,Hannah Owens,https://github.com/hannahlowens/climateStability,TRUE,https://github.com/hannahlowens/climatestability,4904,3,2020-02-18T16:02:12Z,1634.6666666666667
climatrends,"Supports analysis of trends in climate change, ecological and crop modelling.",2020-05-22,Kauê de Sousa,https://agrobioinfoservices.github.io/climatrends,TRUE,https://github.com/agrobioinfoservices/climatrends,2172,1,2020-05-26T06:55:24Z,2172
climdex.pcic,"PCIC's implementation of Climdex routines for computation of
    extreme climate indices. Further details on the extreme climate indices
    can be found at <http://etccdi.pacificclimate.org/list_27_indices.shtml>
    and in the package manual.",2020-01-22,"David Bronaugh <bronaugh@uvic.ca> for the Pacific Climate Impacts
    Consortium",https://www.r-project.org,TRUE,https://github.com/pacificclimate/climdex.pcic,45447,9,2020-01-21T18:56:49Z,5049.666666666667
ClimMobTools,"API client for 'ClimMob', an open source software for crowdsourcing 
    citizen science in agriculture under the 'tricot' method <https://climmob.net/>. 
    Developed by van Etten et al. (2019) <doi:10.1017/S0014479716000739>, it turns the 
    research paradigm on its head; instead of a few researchers designing complicated 
    trials to compare several technologies in search of the best solutions, 
    it enables many farmers to carry out reasonably simple experiments that 
    taken together can offer even more information. 'ClimMobTools' enables project 
    managers to deep explore and analyse their 'ClimMob' data in R.",2020-05-08,Kaue de Sousa,https://agrobioinfoservices.github.io/ClimMobTools/,TRUE,https://github.com/agrobioinfoservices/climmobtools,4691,2,2020-05-08T14:14:07Z,2345.5
climwin,"Contains functions to detect and visualise periods of climate
    sensitivity (climate windows) for a given biological response. 
    Please see van de Pol et al. (2016) <doi:10.1111/2041-210X.12590> 
    and Bailey and van de Pol (2016) <doi:10.1371/journal.pone.0167980> for details.",2020-05-26,Liam D. Bailey and Martijn van de Pol,https://github.com/LiamDBailey/climwin,TRUE,https://github.com/liamdbailey/climwin,25025,5,2020-05-20T16:16:34Z,5005
clipr,"Simple utility functions to read from and write to
    the Windows, OS X, and X11 clipboards.",2019-07-23,Matthew Lincoln,https://github.com/mdlincoln/clipr,TRUE,https://github.com/mdlincoln/clipr,8582919,102,2019-09-14T12:47:43Z,84146.26470588235
CLME,"Estimation and inference for linear models where some or all of the
    fixed-effects coefficients are subject to order restrictions. This package uses
    the robust residual bootstrap methodology for inference, and can handle some
    structure in the residual variance matrix.",2020-06-07,Casey M. Jelsema,NA,TRUE,https://github.com/jelsema/clme,24946,1,2020-06-07T17:55:32Z,24946
clubSandwich,"Provides several cluster-robust variance estimators (i.e.,
    sandwich estimators) for ordinary and weighted least squares linear regression
    models, including the bias-reduced linearization estimator introduced by Bell
    and McCaffrey (2002) 
    <http://www.statcan.gc.ca/pub/12-001-x/2002002/article/9058-eng.pdf> and 
    developed further by Pustejovsky and Tipton (2017) 
    <DOI:10.1080/07350015.2016.1247004>. The package includes functions for estimating
    the variance- covariance matrix and for testing single- and multiple-
    contrast hypotheses based on Wald test statistics. Tests of single regression
    coefficients use Satterthwaite or saddle-point corrections. Tests of multiple-
    contrast hypotheses use an approximation to Hotelling's T-squared distribution.
    Methods are provided for a variety of fitted models, including lm() and mlm
    objects, glm(), ivreg() (from package 'AER'), plm() (from package 'plm'), gls()
    and lme() (from 'nlme'), lmer() (from `lme4`), robu() (from 'robumeta'), and 
    rma.uni() and rma.mv() (from 'metafor').",2020-04-17,James Pustejovsky,https://github.com/jepusto/clubSandwich,TRUE,https://github.com/jepusto/clubsandwich,98753,30,2020-05-31T01:55:51Z,3291.766666666667
clustcurv,"A method for determining groups in multiple 
    curves with an automatic selection of their number based on k-means or 
    k-medians algorithms. The selection of the optimal number is provided by 
    bootstrap methods. The methodology can be applied both in regression and survival framework.
     Implemented methods are:
    Grouping multiple survival curves described by Villanueva et al. (2018) <doi:10.1002/sim.8016>.",2020-03-21,Nora M. Villanueva,https://github.com/noramvillanueva/clustcurv,TRUE,https://github.com/noramvillanueva/clustcurv,5586,0,2020-03-21T12:24:57Z,NA
Cluster.OBeu,"Estimate and return the needed parameters for visualisations designed for 'OpenBudgets' <http://openbudgets.eu/> data. Calculate cluster analysis measures in Budget data of municipalities across Europe, according to the 'OpenBudgets' data model. It involves a set of techniques and algorithms used to find and divide the data into groups of similar observations. Also, can be used generally to extract visualisation parameters convert them to 'JSON' format and use them as input in a different graphical interface.",2019-12-17,Kleanthis Koupidis,https://github.com/okgreece/Cluster.OBeu,TRUE,https://github.com/okgreece/cluster.obeu,10368,1,2019-12-17T12:37:55Z,10368
ClusterBootstrap,Provides functionality for the analysis of clustered data using the cluster bootstrap. ,2020-02-24,Mathijs Deen,https://github.com/mathijsdeen/ClusterBootstrap,TRUE,https://github.com/mathijsdeen/clusterbootstrap,14570,1,2020-02-24T14:05:33Z,14570
clusteredinterference,"Estimating causal effects from observational studies assuming 
    clustered (or partial) interference. These inverse probability-weighted
    estimators target new estimands arising from population-level treatment 
    policies. The estimands and estimators are introduced in Barkley et al. 
    (2017) <arXiv:1711.04834>.",2019-03-18,Brian G. Barkley,http://github.com/BarkleyBG/clusteredinterference,TRUE,https://github.com/barkleybg/clusteredinterference,9225,3,2019-07-17T23:39:10Z,3075
clustermole,Assignment of cell type labels to single-cell RNA sequencing (scRNA-seq) clusters is often a time-consuming process that involves manual inspection of the cluster marker genes complemented with a detailed literature search. This is especially challenging when unexpected or poorly described populations are present. The clustermole R package provides methods to query thousands of human and mouse cell identity markers sourced from a variety of databases.,2020-01-27,Igor Dolgalev,https://github.com/igordot/clustermole,TRUE,https://github.com/igordot/clustermole,2709,1,2020-01-27T19:58:35Z,2709
clustermq,"Evaluate arbitrary function calls using workers on HPC schedulers
    in single line of code. All processing is done on the network without
    accessing the file system. Remote schedulers are supported via SSH.",2020-02-29,Michael Schubert,https://github.com/mschubert/clustermq,TRUE,https://github.com/mschubert/clustermq,37706,90,2020-05-10T10:10:10Z,418.9555555555556
ClusterR,"Gaussian mixture models, k-means, mini-batch-kmeans, k-medoids and affinity propagation clustering with the option to plot, validate, predict (new data) and estimate the optimal number of clusters. The package takes advantage of 'RcppArmadillo' to speed up the computationally intensive parts of the functions. For more information, see (i) ""Clustering in an Object-Oriented Environment"" by Anja Struyf, Mia Hubert, Peter Rousseeuw (1997), Journal of Statistical Software, <doi:10.18637/jss.v001.i04>; (ii) ""Web-scale k-means clustering"" by D. Sculley (2010), ACM Digital Library, <doi:10.1145/1772690.1772862>; (iii) ""Armadillo: a template-based C++ library for linear algebra"" by Sanderson et al (2016), The Journal of Open Source Software, <doi:10.21105/joss.00026>; (iv) ""Clustering by Passing Messages Between Data Points"" by Brendan J. Frey and Delbert Dueck, Science 16 Feb 2007: Vol. 315, Issue 5814, pp. 972-976, <doi:10.1126/science.1136800>.",2020-05-12,Lampros Mouselimis,https://github.com/mlampros/ClusterR,TRUE,https://github.com/mlampros/clusterr,122679,54,2020-05-25T08:37:54Z,2271.8333333333335
clustree,"Deciding what resolution to use can be a difficult question when
    approaching a clustering analysis. One way to approach this problem is to
    look at how samples move as the number of clusters increases. This package
    allows you to produce clustering trees, a visualisation for interrogating
    clusterings as resolution increases.",2020-01-29,Luke Zappia,https://github.com/lazappi/clustree,TRUE,https://github.com/lazappi/clustree,81037,88,2020-01-29T11:23:32Z,920.875
CLVTools,"Probabilistic latent customer attrition models (also known as ""buy-'til-you-die models"") are used to 
    predict future purchase behavior of customers. This package includes fast and accurate implementations of various 
    probabilistic latent customer attrition models for non-contractual settings (e.g., retail business) with and 
    without time-invariant and time-varying covariates. Currently, the package includes the Pareto/NBD model 
    (Pareto/Negative-Binomial-Distribution) for the purchase and the attrition processes as well as the Gamma/Gamma model 
    for the spending process. For reference to the Pareto/NBD model, see Schmittlein DC, Morrison DG, Colombo R (1987) <doi:10.1287/mnsc.33.1.1>. 
    For reference to the Gamma/Gamma model, see Fader PS, Hardie BG, Lee K (2005) <doi:10.1509/jmkr.2005.42.4.415>.",2020-05-08,Patrick Bachmann,https://github.com/bachmannpatrick/CLVTools,TRUE,https://github.com/bachmannpatrick/clvtools,424,5,2020-05-08T23:14:39Z,84.8
CMapViz,"Automatically displays graphical visualization for exported data table (permutated results) from Connectivity Map (CMap) (2006) <doi:10.1126/science.1132939>. 
  It allows the representation of the statistics (p-value and enrichment) according to each cell lines in the form of a bubble plot. ",2019-11-07,Raphaël Bonnet,NA,TRUE,https://github.com/peyronlab/cmapviz,3106,0,2019-11-07T10:10:04Z,NA
cmmr,"CEU (CEU San Pablo University) Mass Mediator is an on-line tool for aiding researchers in 
  performing metabolite annotation. 'cmmr' (CEU Mass Mediator RESTful API) allows 
  for programmatic access in R: batch search, batch advanced search, MS/MS (tandem mass spectrometry) search, etc.
  For more information about the API Endpoint please go to <https://github.com/lzyacht/cmmr>.",2019-04-16,Yaoxiang Li,https://github.com/lzyacht/cmmr,TRUE,https://github.com/lzyacht/cmmr,4986,8,2019-10-24T19:16:31Z,623.25
cmna,"Provides the source and examples for James P. Howard, II, 
             ""Computational Methods for Numerical Analysis with R,"" 
             <http://howardjp.github.io/cmna/>, a book on numerical
             methods in R.",2019-07-23,James Howard,https://howardjp.github.io/cmna/,TRUE,https://github.com/howardjp/cmna,19456,8,2019-07-23T16:42:58Z,2432
cmocean,"Perceptually uniform palettes for commonly used
	variables in oceanography as functions taking an integer
	and producing character vectors	of colours.
	See Thyng, K.M., Greene, C.A., Hetland, R.D., Zimmerle, H.M.
	and S.F. DiMarco (2016) <doi:10.5670/oceanog.2016.66> for
	the guidelines adhered to when creating the palettes.",2019-05-06,Ivan Krylov,https://matplotlib.org/cmocean/,TRUE,https://github.com/aitap/cmocean,6062,1,2020-02-11T18:02:02Z,6062
CMplot,"Manhattan plot, a type of scatter plot, was widely used to display the association results. However, it is usually time-consuming and laborious for a non-specialist user to write scripts and adjust parameters of an elaborate plot. Moreover, the ever-growing traits measured have necessitated the integration of results from different Genome-wide association study researches. Circle Manhattan Plot is the first open R package that can lay out. Genome-wide association study P-value results in both traditional rectangular patterns, QQ-plot and novel circular ones. United in only one bull's eye style plot, association results from multiple traits can be compared interactively, thereby to reveal both similarities and differences between signals. Additional functions include: highlight signals, a group of SNPs, chromosome visualization and candidate genes around SNPs.",2020-04-04,LiLin-Yin,https://github.com/YinLiLin/R-CMplot,TRUE,https://github.com/yinlilin/r-cmplot,41577,178,2020-06-08T05:46:47Z,233.57865168539325
cmvnorm,Various utilities for the complex multivariate Gaussian distribution.,2019-05-20,Robin K. S. Hankin,https://github.com/RobinHankin/cmvnorm.git,TRUE,https://github.com/robinhankin/cmvnorm,23153,2,2019-07-08T09:50:09Z,11576.5
cNORM,"Conventional methods for producing standard scores in psychometrics or biometrics 
    are often plagued with ""jumps"" or ""gaps"" (i.e., discontinuities) in norm tables and low 
    confidence for assessing extreme scores. The continuous norming method introduced by A. 
    Lenhard et al. (2016, <doi:10.1177/1073191116656437>; 2019, <doi:10.1371/journal.pone.0222279>) and generates continuous test norm 
    scores on the basis of the raw data from standardization samples, without requiring 
    assumptions about the distribution of the raw data: Norm scores are directly established 
    from raw data by modeling the latter ones as a function of both percentile scores and an 
    explanatory variable (e.g., age). The method minimizes bias arising from sampling and 
    measurement error, while handling marked deviations from normality, addressing bottom 
    or ceiling effects and capturing almost all of the variance in the original norm data 
    sample.",2019-09-19,Wolfgang Lenhard,"https://www.psychometrica.de/cNorm_en.html,
https://github.com/WLenhard/cNORM",TRUE,https://github.com/wlenhard/cnorm,11260,0,2020-05-15T07:44:30Z,NA
cnum,"Chinese numerals processing in R, such as conversion between 
    Chinese numerals and Arabic numerals as well as detection and extraction of
    Chinese numerals in character objects and string. This package supports 
    the casual scale naming system and the respective SI prefix systems used 
    in mainland China and Taiwan: 
    ""China Statutory Measurement Units""
    State Administration for Market Regulation (2019) <http://gkml.samr.gov.cn/nsjg/jls/201902/t20190225_291134.html>
    ""Names, Definitions and Symbols of the Legal Units of Measurement and the Decimal Multiples and Submultiples"" 
    Ministry of Economic Affairs (2019) <https://gazette.nat.gov.tw/egFront/detail.do?metaid=108965>.",2020-05-02,Elgar Teo,https://github.com/elgarteo/cnum/,TRUE,https://github.com/elgarteo/cnum,1905,4,2020-05-02T14:41:05Z,476.25
CNVScope,"Provides the ability to create interaction maps, discover CNV map domains (edges), gene annotate interactions, and create interactive visualizations of these CNV interaction maps.",2020-04-29,James Dalgeish,https://github.com/jamesdalg/CNVScope/,TRUE,https://github.com/jamesdalg/cnvscope,8603,4,2020-04-29T01:06:15Z,2150.75
coala,"Coalescent simulators can rapidly simulate biological sequences
    evolving according to a given model of evolution.
    You can use this package to specify such models, to conduct the simulations
    and to calculate additional statistics from the results.
    It relies on existing simulators for doing the simulation, and currently
    supports the programs 'ms', 'msms' and 'scrm'. It also supports finite-sites
    mutation models by combining the simulators with the program 'seq-gen'.",2020-01-19,Paul Staab,https://github.com/statgenlmu/coala,TRUE,https://github.com/statgenlmu/coala,24743,14,2020-01-19T13:10:30Z,1767.357142857143
coalitions,"An implementation of a Bayesian framework for the opinion poll
    based estimation of event probabilities in multi-party electoral systems
    (Bender and Bauer (2018) <doi:10.21105/joss.00606>).",2020-02-06,Andreas Bender,http://adibender.github.io/coalitions/,TRUE,https://github.com/adibender/coalitions,12723,11,2020-02-05T22:01:12Z,1156.6363636363637
cobalt,"Generate balance tables and plots for covariates of groups preprocessed through matching, weighting or subclassification, for example, using propensity scores. Includes integration with 'MatchIt', 'twang', 'Matching', 'optmatch', 'CBPS', 'ebal', 'WeightIt', 'cem', 'sbw', and 'designmatch' for assessing balance on the output of their preprocessing functions. Users can also specify data for balance assessment not generated through the above packages. Also included are methods for assessing balance in clustered or multiply imputed data sets or data sets with longitudinal treatments.",2020-06-04,Noah Greifer,https://github.com/ngreifer/cobalt,TRUE,https://github.com/ngreifer/cobalt,75258,20,2020-06-09T03:52:31Z,3762.9
coca,Contains the R functions needed to perform Cluster-Of-Clusters Analysis (COCA)  and Consensus Clustering (CC). For further details please see Cabassi and Kirk (2019) <arXiv:1904.07701>.,2020-03-26,Alessandra Cabassi,http://github.com/acabassi/coca,TRUE,https://github.com/acabassi/coca,1157,2,2020-05-20T10:39:28Z,578.5
cocktailApp,"A 'shiny' app to discover cocktails. The
    app allows one to search for cocktails by ingredient,
    filter on rating, and number of ingredients. The
    package also contains data with the ingredients of
    nearly 26 thousand cocktails scraped from the web.",2019-07-02,Steven E. Pav,https://github.com/shabbychef/cocktailApp,TRUE,https://github.com/shabbychef/cocktailapp,9304,32,2019-07-02T05:42:53Z,290.75
cocorresp,"Fits predictive and symmetric co-correspondence analysis (CoCA) models to relate one data matrix to another data matrix. More specifically, CoCA maximises the weighted covariance between the weighted averaged species scores of one community and the weighted averaged species scores of another community. CoCA attempts to find patterns that are common to both communities.",2019-12-19,"Original Matlab routines by C.J.F. ter Braak and A.P. Schaffers. R port by Gavin L. Simpson.
  Function simpls based on simpls.fit (package pls) by Ron Wehrens and Bjorn-Helge Mevik.",https://github.com/gavinsimpson/cocorresp,TRUE,https://github.com/gavinsimpson/cocorresp,33365,2,2020-03-25T21:36:55Z,16682.5
coda.base,"A minimum set of functions to perform compositional data analysis
    using the log-ratio approach introduced by John Aitchison (1982) <http://www.jstor.org/stable/2345821>. Main functions
    have been implemented in c++ for better performance.",2020-05-14,Marc Comas-Cufí,"https://mcomas.github.io/coda.base,
https://github.com/mcomas/coda.base",TRUE,https://github.com/mcomas/coda.base,21849,1,2020-06-03T08:22:50Z,21849
codebook,"Easily automate the following tasks to describe data frames:
		Summarise the distributions, and labelled missings of variables graphically
		and using descriptive statistics.
		For surveys, compute and summarise reliabilities (internal consistencies, 
		retest, multilevel) for psychological scales.
		Combine this information with metadata (such as item labels and labelled 
		values) that is derived from R attributes.
		To do so, the package relies on 'rmarkdown' partials, so you can generate 
		HTML, PDF, and Word documents. 
		Codebooks are also available as tables (CSV, Excel, etc.) and in JSON-LD, so
		that search engines can find your data and index the metadata.
		The metadata are also available at your fingertips via RStudio Addins.",2020-06-06,Ruben Arslan,https://github.com/rubenarslan/codebook,TRUE,https://github.com/rubenarslan/codebook,20233,84,2020-06-08T14:29:30Z,240.86904761904762
CodeDepends,"Tools for analyzing R expressions
  or blocks of code and determining the dependencies between them.
  It focuses on R scripts, but can be used on the bodies of functions.
  There are many facilities including the ability to summarize  or get a high-level
  view of code, determining dependencies between variables,  code improvement
  suggestions.",2018-07-17,Duncan Temple Lang,https://github.com/duncantl/CodeDepends,TRUE,https://github.com/duncantl/codedepends,25082,60,2020-01-06T23:44:55Z,418.03333333333336
codemetar,"The 'Codemeta' Project defines a 'JSON-LD' format for describing
  software metadata, as detailed at <https://codemeta.github.io>. This package
  provides utilities to generate, parse, and modify 'codemeta.json' files 
  automatically for R packages, as well as tools and examples for working with
  'codemeta.json' 'JSON-LD' more generally.",2019-04-22,Carl Boettiger,"https://github.com/ropensci/codemetar,
https://ropensci.github.io/codemetar",TRUE,https://github.com/ropensci/codemetar,13814,43,2020-05-08T13:06:26Z,321.25581395348837
codyn,"Univariate and multivariate temporal and spatial diversity indices, 
    rank abundance curves, and community stability measures. The functions 
    implement measures that are either explicitly temporal and include the 
    option to calculate them over multiple replicates, or spatial and include 
    the option to calculate them over multiple time points. Functions fall into 
    five categories: static diversity indices, temporal diversity indices, 
    spatial diversity indices, rank abundance curves, and community stability 
    measures. The diversity indices are temporal and spatial analogs to 
    traditional diversity indices. Specifically, the package includes functions 
    to calculate community richness, evenness and diversity at a given point in 
    space and time. In addition, it contains functions to calculate species 
    turnover, mean rank shifts, and lags in community similarity between two 
    time points.",2020-05-06,Matthew B. Jones,https://github.com/NCEAS/codyn/,TRUE,https://github.com/nceas/codyn,22197,20,2020-05-06T06:29:49Z,1109.85
coga,"Evaluation for density and distribution function of convolution of gamma
    distributions in R. Two related exact methods and one approximate method are
    implemented with efficient algorithm and C++ code. A quick guide for choosing
    correct method and usage of this package is given in package vignette. For the
    detail of methods used in this package, we refer the user to
    Mathai(1982)<doi:10.1007/BF02481056>,
    Moschopoulos(1984)<doi:10.1007/BF02481123>,
    Hu et al.(2019)<doi:10.1007/s00180-019-00924-9>.",2019-10-08,Chaoran Hu,https://github.com/ChaoranHu/coga,TRUE,https://github.com/chaoranhu/coga,16973,3,2019-10-22T03:50:31Z,5657.666666666667
cognitoR,Provides authentication for Shiny applications using 'Amazon Cognito' ( <https://aws.amazon.com/es/cognito/>).,2020-04-15,Pablo Pagnone,NA,TRUE,https://github.com/chi2labs/cognitor,1416,4,2020-04-14T16:28:32Z,354
coindeskr,Extract real-time Bitcoin price details by accessing 'CoinDesk' Bitcoin price Index API <https://www.coindesk.com/api/>. ,2018-01-05,AbdulMajedRaja RS,https://github.com/amrrs/coindeskr,TRUE,https://github.com/amrrs/coindeskr,13014,3,2020-04-18T20:54:29Z,4338
coinmarketcapr,Extract and monitor price and market cap of 'Cryptocurrencies' from 'Coin Market Cap' <https://coinmarketcap.com/api/>. ,2020-03-25,AbdulMajedRaja RS,http://github.com/amrrs/coinmarketcapr,TRUE,https://github.com/amrrs/coinmarketcapr,15661,34,2020-03-25T18:03:03Z,460.61764705882354
Coinprofile,"Builds the 
  coincident profile proposed by Martinez, W and Nieto, Fabio H and Poncela, P (2016) 
  <doi:10.1016/j.spl.2015.11.008>.
  This methodology studies the relationship between a couple of
  time series based on the the set of turning points of each
  time series. The coincident profile establishes if two time
  series are coincident, or one of them leads the second.",2019-08-25,Wilmer Martinez,https://github.com/WilmerMartinezR/Coinprofile,TRUE,https://github.com/wilmermartinezr/coinprofile,4041,0,2019-08-25T17:19:13Z,NA
collapse,"A C/C++ based package for advanced data transformation in R that is 
    extremely fast, flexible and parsimonious to code with and programmer 
    friendly. It is well integrated with 'dplyr', 'plm' and 'data.table'.
    --- Key Features: ---
    (1) Advanced data programming: A full set of fast statistical functions 
        supporting grouped and weighted computations on vectors, matrices and 
        data frames. Fast (ordered) and programmable grouping, factor 
        generation, manipulation of data frames and data object conversions.
    (2) Advanced aggregation: Fast and easy multi-data-type, multi-function, 
        weighted, parallelized and fully customized data aggregation.
    (3) Advanced transformations: Fast (grouped, weighted) replacing and 
        sweeping out of statistics, scaling / standardizing, centering (i.e. 
        between and within transformations), higher-dimensional centering 
        (i.e. multiple fixed effects transformations), linear 
        prediction and partialling-out.
    (4) Advanced time-computations: Fast (sequences of) lags / leads, and 
        (lagged / leaded, iterated, quasi-, log-) differences and growth 
        rates on (unordered) time-series and panel data. Multivariate auto, 
        partial and cross-correlation functions for panel data. 
        Panel data to (ts-)array conversions.
    (5) List processing: (Recursive) list search / identification, extraction / 
        subsetting, data-apply, and generalized row-binding / unlisting in 2D.
    (6) Advanced data exploration: Fast (grouped, weighted, panel-decomposed) 
        summary statistics for complex multilevel / panel data.",2020-05-26,Sebastian Krantz,NA,TRUE,https://github.com/sebkrantz/collapse,2703,39,2020-06-08T23:57:19Z,69.3076923076923
collections,"Provides high performance container data types such
    as queues, stacks, deques, dicts and ordered dicts. Benchmarks
    <https://randy3k.github.io/collections/articles/benchmark.html> have
    shown that these containers are asymptotically more efficient than
    those offered by other packages.",2020-06-01,Randy Lai,https://github.com/randy3k/collections,TRUE,https://github.com/randy3k/collections,55387,59,2020-06-01T07:46:42Z,938.7627118644068
collector,"An open source process for collecting quantified data inputs from 
  subject matter experts. Intended for feeding into an OpenFAIR analysis 
  <https://www2.opengroup.org/ogsys/catalog/C13K> using 
  a tool such as 'evaluator' <https://evaluator.tidyrisk.org>.",2020-02-18,David Severski,https://collector.tidyrisk.org,TRUE,https://github.com/davidski/collector,3953,13,2020-02-17T20:29:00Z,304.0769230769231
collidr,Check for namespace collisions between a string input (your function or package name) and a quarter of a million packages and functions on CRAN.,2019-09-08,Steve Condylios,https://github.com/collidrpackage/collidr,TRUE,https://github.com/collidrpackage/collidr,4952,0,2019-07-16T16:11:25Z,NA
coloc,"Performs the colocalisation tests described in
    Plagnol et al (2009) <doi:10.1093/biostatistics/kxn039>,
    Wallace et al (2013) <doi:10.1002/gepi.21765> and
    Giambartolomei et al (2013) <doi:10.1371/journal.pgen.1004383>.",2019-05-17,Chris Wallace,https://github.com/chr1swallace/coloc,TRUE,https://github.com/chr1swallace/coloc,25637,21,2020-05-27T05:57:59Z,1220.8095238095239
colocr,"Automate the co-localization analysis of fluorescence microscopy 
  images. Selecting regions of interest, extract pixel intensities from 
  the image channels and calculate different co-localization statistics. The
  methods implemented in this package are based on Dunn et al. (2011) 
  <doi:10.1152/ajpcell.00462.2010>.",2020-05-08,Mahmoud Ahmed,"https://docs.ropensci.org/colocr,
https://github.com/ropensci/colocr",TRUE,https://github.com/ropensci/colocr,2608,17,2020-01-04T04:10:25Z,153.41176470588235
colorednoise,"Temporally autocorrelated populations are correlated in their vital rates (growth, death, etc.) from year to year. It is very common for populations, whether they be bacteria, plants, or humans, to be temporally autocorrelated. This poses a challenge for stochastic population modeling, because a temporally correlated population will behave differently from an uncorrelated one.
    This package provides tools for simulating populations with white noise (no temporal autocorrelation), red noise (positive temporal autocorrelation), and blue noise (negative temporal autocorrelation).  The algebraic formulation for autocorrelated noise comes from Ruokolainen et al. (2009) <doi:10.1016/j.tree.2009.04.009>. Models for unstructured populations and for structured populations (matrix models) are available.",2019-09-27,Julia Pilowsky,NA,TRUE,https://github.com/japilo/colorednoise,13869,3,2019-09-27T11:31:25Z,4623
colorist,"Color and visualize wildlife distributions in
    space-time using raster data. In addition to enabling display of
    sequential change in distributions through the use of small multiples,
    'colorist' provides functions for extracting several features of
    interest from a sequence of distributions and for visualizing those
    features using HCL (hue-chroma-luminance) color palettes. Resulting
    maps allow for ""fair"" visual comparison of intensity values (e.g.,
    occurrence, abundance, or density) across space and time and can be
    used to address questions about where, when, and how consistently a
    species, group, or individual is likely to be found.",2020-03-26,Justin Schuetz,https://github.com/mstrimas/colorist,TRUE,https://github.com/mstrimas/colorist,1170,3,2020-03-31T15:52:16Z,390
colourpicker,"A colour picker that can be used as an input in Shiny apps
    or Rmarkdown documents. The colour picker supports alpha opacity, custom
    colour palettes, and many more options. A Plot Colour Helper tool is
    available as an RStudio Addin, which helps you pick colours to use in your
    plots. A more generic Colour Picker RStudio Addin is also provided to let 
    you select colours to use in your R code.",2017-09-27,Dean Attali,https://github.com/daattali/colourpicker,TRUE,https://github.com/daattali/colourpicker,658708,124,2020-06-09T02:27:52Z,5312.1612903225805
colourvalues,"Maps one of the viridis colour palettes, or a user-specified palette to values. 
    Viridis colour maps are created by Stéfan van der Walt and Nathaniel Smith, 
    and were set as the default palette for the 'Python' 'Matplotlib' library <https://matplotlib.org/>. 
    Other palettes available in this library have been derived from 
    'RColorBrewer' <https://CRAN.R-project.org/package=RColorBrewer> and 
    'colorspace' <https://CRAN.R-project.org/package=colorspace> packages.",2020-04-29,David Cooley,https://symbolixau.github.io/colourvalues/,TRUE,https://github.com/symbolixau/colourvalues,71919,33,2020-04-28T22:35:14Z,2179.3636363636365
comat,"Builds co-occurrence matrices based on spatial raster data.
    It includes creation of weighted co-occurrence matrices (wecoma) and 
    integrated co-occurrence matrices 
    (incoma; Vadivel et al. (2007) <doi:10.1016/j.patrec.2007.01.004>).",2020-03-17,Jakub Nowosad,https://nowosad.github.io/comat/,TRUE,https://github.com/nowosad/comat,4651,3,2020-06-02T16:33:09Z,1550.3333333333333
cometr,"A convenient 'R' wrapper to the 'Comet' API, which is a cloud
    platform allowing you to track, compare, explain and optimize machine
    learning experiments and models. Experiments can be viewed on the 'Comet'
    online dashboard at <https://www.comet.ml>.",2020-05-08,Doug Blank,https://github.com/comet-ml/cometr,TRUE,https://github.com/comet-ml/cometr,1059,5,2020-06-07T15:11:04Z,211.8
commonmark,"The CommonMark specification defines a rationalized version of markdown
    syntax. This package uses the 'cmark' reference implementation for converting
    markdown text into various formats including html, latex and groff man. In
    addition it exposes the markdown parse tree in xml format. Also includes opt-in
    support for GFM extensions including tables, autolinks, and strikethrough text.",2018-12-01,Jeroen Ooms,"http://github.com/jeroen/commonmark (devel)
https://github.github.com/gfm/ (spec)",TRUE,https://github.com/jeroen/commonmark,2896641,65,2019-10-14T18:14:58Z,44563.70769230769
commonsMath,Java JAR files for the Apache Commons Mathematics Library for use by users and other packages.,2020-02-10,David B. Dahl,https://github.com/dbdahl/commonsMath,TRUE,https://github.com/dbdahl/commonsmath,17447,3,2020-02-10T15:38:44Z,5815.666666666667
comorbidity,"Computing comorbidity scores such as the weighted Charlson score
  (Charlson, 1987 <doi:10.1016/0021-9681(87)90171-8>) and the Elixhauser
  comorbidity score (Elixhauser, 1998 <doi:10.1097/00005650-199801000-00004>)
  using ICD-9-CM or ICD-10 codes (Quan, 2005 <doi:10.1097/01.mlr.0000182534.19832.83>).",2020-01-09,Alessandro Gasparini,https://ellessenne.github.io/comorbidity,TRUE,https://github.com/ellessenne/comorbidity,17787,27,2020-05-31T08:49:57Z,658.7777777777778
CompareCausalNetworks,"Unified interface for the estimation of causal networks, including
    the methods 'backShift' (from package 'backShift'), 'bivariateANM' (bivariate
    additive noise model), 'bivariateCAM' (bivariate causal additive model),
    'CAM' (causal additive model) (from package 'CAM'; the package is 
    temporarily unavailable on the CRAN repository; formerly available versions 
    can be obtained from the archive), 'hiddenICP' (invariant
    causal prediction with hidden variables), 'ICP' (invariant causal prediction)
    (from package 'InvariantCausalPrediction'), 'GES' (greedy equivalence
    search), 'GIES' (greedy interventional equivalence search), 'LINGAM', 'PC' (PC
    Algorithm), 'FCI' (fast causal inference), 
    'RFCI' (really fast causal inference) (all from package 'pcalg') and
    regression.",2020-02-17,Christina Heinze-Deml,https://github.com/christinaheinze/CompareCausalNetworks,TRUE,https://github.com/christinaheinze/comparecausalnetworks,24473,14,2020-02-17T16:24:33Z,1748.0714285714287
comparer,"Quickly run experiments to compare the run time and output of
    code blocks. The function mbc() can make fast comparisons of code,
    and will calculate statistics comparing the resulting outputs.
    It can be used to compare model fits to the same data or
    see which function runs faster.
    The function ffexp() runs a function using all possible combinations
    of selected inputs. This is useful for comparing the effect of
    different parameter values. It can also run in parallel and
    automatically save intermediate results, which is very useful
    for long computations.",2020-03-25,Collin Erickson,https://github.com/CollinErickson/comparer,TRUE,https://github.com/collinerickson/comparer,9935,2,2020-06-06T01:50:26Z,4967.5
comperank,"Compute ranking and rating based on competition
    results. Methods of different nature are implemented: with fixed
    Head-to-Head structure, with variable Head-to-Head structure and with
    iterative nature. All algorithms are taken from the book 'Who’s #1?:
    The science of rating and ranking' by Amy N. Langville and Carl D.
    Meyer (2012, ISBN:978-0-691-15422-0).",2020-03-03,Evgeni Chasnovski,https://github.com/echasnovski/comperank,TRUE,https://github.com/echasnovski/comperank,8464,10,2020-05-31T19:04:21Z,846.4
comperes,"Tools for storing and managing competition results.
    Competition is understood as a set of games in which players gain some
    abstract scores.  There are two ways for storing results: in long (one
    row per game-player) and wide (one row per game with fixed amount of
    players) formats. This package provides functions for creation and
    conversion between them. Also there are functions for computing their
    summary and Head-to-Head values for players. They leverage grammar of
    data manipulation from 'dplyr'.",2020-05-09,Evgeni Chasnovski,https://github.com/echasnovski/comperes,TRUE,https://github.com/echasnovski/comperes,10781,5,2020-06-08T12:52:57Z,2156.2
completejourney,"Retail shopping transactions for 2,469 households over one year.
    Originates from the 84.51° Complete Journey 2.0 source files 
    <https://www.8451.com/area51> which also includes useful metadata on 
    products, coupons, campaigns, and promotions.",2019-09-28,Brad Boehmke,https://github.com/bradleyboehmke/completejourney,TRUE,https://github.com/bradleyboehmke/completejourney,4124,15,2020-01-16T14:19:39Z,274.93333333333334
complmrob,"Robust regression methods for compositional data.
    The distribution of the estimates can be approximated with various bootstrap
    methods. These bootstrap methods are available for the compositional as well
    as for standard robust regression estimates. This allows for direct
    comparison between them.",2019-09-17,David Kepplinger,https://github.com/dakep/complmrob,TRUE,https://github.com/dakep/complmrob,20997,0,2019-09-17T18:25:06Z,NA
COMPoissonReg,"Fit Conway-Maxwell Poisson (COM-Poisson or CMP) regression models
    to count data (Sellers & Shmueli, 2010) <doi:10.1214/09-AOAS306>. The
    package provides functions for model estimation, dispersion testing, and
    diagnostics. Zero-inflated CMP regression (Sellers & Raim, 2016)
    <doi:10.1016/j.csda.2016.01.007> is also supported.",2019-11-30,Kimberly Sellers,https://github.com/lotze/COMPoissonReg,TRUE,https://github.com/lotze/compoissonreg,30613,1,2020-04-10T19:40:10Z,30613
comprehenr,"Provides 'Python'-style list comprehensions.
    List comprehension expressions use usual loops (for(), while() and repeat()) and
    usual if() as list producers. In many cases it gives more concise notation than
    standard ""*apply + filter"" strategy.",2019-06-17,Gregory Demin,https://github.com/gdemin/comprehenr,TRUE,https://github.com/gdemin/comprehenr,10801,9,2019-06-29T18:05:26Z,1200.111111111111
compstatr,"Provides a set of tools for creating yearly data sets of St. Louis 
    Metropolitan Police Department (SLMPD) crime data, which are available from
    January 2008 onward as monthly CSV releases on their website 
    (<http:www.slmpd.org/Crimereports.shtml>). Once data are validated and created 
    (monthly data releases have varying numbers of columns 
    as well as different column names and formats), 'compstatr' also provides 
    functions for categorizing and mapping crimes in St. Louis. The categorization 
    tools that are provided will also work with any police department that uses 5 
    and 6 digit numeric codes to identify specific crimes. These data provide researchers
    and policy makers detailed data for St. Louis, which in the last several years 
    has had some of the highest or the highest violent crime rates in the United States.",2020-05-14,Christopher Prener,https://github.com/slu-openGIS/compstatr,TRUE,https://github.com/slu-opengis/compstatr,5012,6,2020-05-13T14:39:47Z,835.3333333333334
comtradr,"Interface with and extract data from the United Nations Comtrade 
  API <https://comtrade.un.org/data/>. Comtrade provides country level shipping 
  data for a variety of commodities, these functions allow for easy API query 
  and data returned as a tidy data frame.",2018-10-05,Chris Muir,https://github.com/ropensci/comtradr,TRUE,https://github.com/ropensci/comtradr,17947,25,2020-05-16T04:43:41Z,717.88
concaveman,The concaveman function ports the 'concaveman' (<https://github.com/mapbox/concaveman>) library from 'mapbox'. It computes the concave polygon(s) for one or several set of points.,2020-05-11,Joël Gombin,"https://joelgombin.github.io/concaveman/,
http://www.github.com/joelgombin/concaveman/",TRUE,https://github.com/joelgombin/concaveman,66172,47,2020-05-10T21:56:49Z,1407.9148936170213
concordance,"A set of utilities for matching products in different
	     classification codes used in international trade
	     research. It supports concordance between the Harmonized
	     System (HS0, HS1, HS2, HS3, HS4, HS5, HS combined), the Standard 
	     International Trade Classification (SITC1, SITC2, SITC3, SITC4), 
	     the North American Industry Classification System (NAICS combined),
	     as well as the Broad Economic Categories (BEC), the International 
	     Standard of Industrial Classification (ISIC), and the Standard Industrial 
	     Classification (SIC). It also provides code nomenclature/descriptions 
	     look-up, Rauch classification look-up (via concordance to SITC2), and
	     trade elasticity look-up (via concordance to HS0 or SITC3
	     codes).",2020-04-24,Steven Liao,NA,TRUE,https://github.com/insongkim/concordance,17491,3,2020-06-09T00:19:54Z,5830.333333333333
concorR,"Contains the CONCOR (CONvergence of iterated CORrelations) 
    algorithm and a series of supplemental functions for easy running, 
    plotting, and blockmodeling. The CONCOR algorithm is used on social network
    data to identify network positions based off a definition of structural 
    equivalence; see Breiger, Boorman, and Arabie (1975) 
    <doi:10.1016/0022-2496(75)90028-0> and Wasserman and Faust's book Social 
    Network Analysis: Methods and Applications (1994). This version allows 
    multiple relationships for the same set of nodes and uses both incoming and
    outgoing ties to find positions.",2020-06-03,Adrienne Traxler,https://github.com/ATraxLab/concorR,TRUE,https://github.com/atraxlab/concorr,0,0,2020-06-03T17:16:06Z,NA
concurve,"Allows one to compute compatibility (confidence)
    intervals for various statistical tests along with their corresponding
    P-values, S-values, and likelihoods. The intervals can be plotted to
    create consonance, surprisal, and likelihood functions allowing one to
    see what effect sizes are compatible with the test model at various
    compatibility levels rather than being limited to one interval estimate
    such as 95\%. Functions can also be compared to one another to see how much
    they overlap with one another and differ. Results can also be exported for 
    Word, Powerpoint, and TeX documents. The package currently supports bootstrapping,
    linear models, generalized linear models, linear mixed-effects models, 
    survival analysis, and meta-analysis. These methods are discussed by 
    Poole C. (1987) <doi:10.2105/AJPH.77.2.195>, Schweder T, Hjort NL. (2002)
    <doi:10.1111/1467-9469.00285>, Singh K, Xie M, Strawderman WE. (2007)
    <arXiv:0708.0976>, Rothman KJ, Greenland S, Lash TL. (2008,
    ISBN:9781451190052), Greenland S. (2019)
    <doi:10.1080/00031305.2018.1529625>, Chow ZR, Greenland S. (2019)
    <arXiv:1909.08579>, and Greenland S, Chow ZR. (2019)
    <arXiv:1909.08583>.",2020-04-20,Zad Rafi,"https://data.lesslikely.com/concurve/,
https://github.com/zadrafi/concurve, https://lesslikely.com/",TRUE,https://github.com/zadrafi/concurve,8676,12,2020-06-07T00:56:24Z,723
condformat,"Apply and visualize conditional formatting to data frames in R.
    It renders a data frame with cells formatted according to
    criteria defined by rules, using a tidy evaluation syntax. The table is
    printed either opening a web browser or within the 'RStudio' viewer if
    available. The conditional formatting rules allow to highlight cells
    matching a condition or add a gradient background to a given column. This
    package supports both 'HTML' and 'LaTeX' outputs in 'knitr' reports, and
    exporting to an 'xlsx' file.",2020-05-14,Sergio Oller Moreno,http://github.com/zeehio/condformat,TRUE,https://github.com/zeehio/condformat,27766,14,2020-05-15T15:32:58Z,1983.2857142857142
CondIndTests,"Code for a variety of nonlinear conditional independence tests: 
  Kernel conditional independence test (Zhang et al., UAI 2011, <arXiv:1202.3775>),
  Residual Prediction test (based on Shah and Buehlmann, <arXiv:1511.03334>),
  Invariant environment prediction,
  Invariant target prediction,
  Invariant residual distribution test,
  Invariant conditional quantile prediction (all from Heinze-Deml et al., <arXiv:1706.08576>).",2019-11-12,Christina Heinze-Deml,https://github.com/christinaheinze/nonlinearICP-and-CondIndTests,TRUE,https://github.com/christinaheinze/nonlinearicp-and-condindtests,13802,10,2019-11-12T14:45:32Z,1380.2
condir,Set of functions for the easy analyses of conditioning data.,2020-03-06,Angelos-Miltiadis Krypotos,https://github.com/AngelosPsy/condir,TRUE,https://github.com/angelospsy/condir,10844,1,2020-03-06T12:28:50Z,10844
conditionz,"Provides ability to control how many times in function
    calls conditions are thrown (shown to the user). Includes control of
    warnings and messages.",2019-04-24,Scott Chamberlain,https://github.com/ropenscilabs/conditionz,TRUE,https://github.com/ropenscilabs/conditionz,7448,1,2020-03-13T16:37:52Z,7448
condusco,"Runs a function iteratively over each row of either a dataframe 
    or the results of a query.  Use the 'BigQuery' and 'DBI' wrappers to 
    iteratively pass each row of query results to a function.  If a field 
    contains a 'JSON' string, it will be converted to an object.  This is 
    helpful for queries that return 'JSON' strings that represent objects.  
    These fields can then be treated as objects by the pipeline.",2017-11-08,Roland Stevenson,https://github.com/ras44/condusco,TRUE,https://github.com/ras44/condusco,9610,10,2019-06-13T17:44:24Z,961
condvis2,"Constructs a shiny app function with interactive displays for conditional visualization of models, 
     data and density functions. An extended version of package 'condvis'. 
     Mark O'Connell, Catherine B. Hurley, Katarina Domijan (2017) <doi:10.18637/jss.v081.i05>.",2019-06-28,Catherine Hurley,https://github.com/cbhurley/condvis2,TRUE,https://github.com/cbhurley/condvis2,4438,5,2019-09-03T15:04:54Z,887.6
configural,"R functions for criterion profile analysis, Davison and Davenport (2002) <doi:10.1037/1082-989X.7.4.468> and meta-analytic criterion profile analysis, Wiernik, Wilmot, Davison, and Ones (2019). Sensitivity analyses to aid in interpreting criterion profile analysis results are also included.",2019-02-19,Brenton M. Wiernik,NA,TRUE,https://github.com/bwiernik/configural,5681,0,2020-05-31T01:00:43Z,NA
confintr,"Calculates classic and/or bootstrap confidence
    intervals for many parameters such as the population mean, variance,
    interquartile range (IQR), median absolute deviation (MAD), skewness,
    kurtosis, Cramer's V, R-squared, quantiles (incl. median),
    proportions, different types of correlation measures, difference in
    means, quantiles and medians. Many of the classic confidence intervals
    are described in Smithson, M. (2003, ISBN: 978-0761924999). Bootstrap
    confidence intervals are calculated with the R package 'boot'. Both
    one- and two-sided intervals are supported.",2020-06-04,Michael Mayer,https://github.com/mayer79/confintr,TRUE,https://github.com/mayer79/confintr,0,1,2020-06-05T13:50:11Z,0
conflicted,"R's default conflict management system gives the most recently
    loaded package precedence. This can make it hard to detect conflicts, 
    particularly when they arise because a package update creates ambiguity
    that did not previously exist. 'conflicted' takes a different approach, 
    making every conflict an error and forcing you to choose which function 
    to use.",2019-06-21,Hadley Wickham,https://github.com/r-lib/conflicted,TRUE,https://github.com/r-lib/conflicted,64175,172,2019-06-22T14:38:07Z,373.11046511627904
conflr,"Provides utilities for working with various 'Confluence' API 
    <https://docs.atlassian.com/ConfluenceServer/rest/latest/>, including a
    functionality to convert an R Markdown document to 'Confluence' format and
    upload it to 'Confluence' automatically.",2020-04-08,Hiroaki Yutani,"https://line.github.io/conflr/, https://github.com/line/conflr",TRUE,https://github.com/line/conflr,1804,79,2020-06-06T06:33:21Z,22.835443037974684
confoundr,"Implements three covariate-balance diagnostics for time-varying confounding and selection-bias in complex longitudinal data, as described in Jackson (2016) <doi:10.1097/EDE.0000000000000547> and Jackson (2019) <doi:10.1093/aje/kwz136>. Diagnostic 1 assesses measured confounding/selection-bias, diagnostic 2 assesses exposure-covariate feedback, and diagnostic 3 assesses residual confounding/selection-bias after inverse probability weighting or propensity score stratification. All diagnostics appropriately account for exposure history, can be adapted to assess a particular depth of covariate history, and can be implemented in right-censored data. Balance assessments can be obtained for all times, selected-times, or averaged across person-time. The balance measures are reported as tables or plots. These diagnostics can be applied to the study of multivariate exposures including time-varying exposures, direct effects, interaction, and censoring.",2019-09-20,John W. Jackson,NA,TRUE,https://github.com/jwjackson/confoundr,3523,8,2020-01-09T01:36:48Z,440.375
CongreveLamsdell2016,"Includes the 100 datasets simulated by Congreve and Lamsdell (2016)
  <doi:10.1111/pala.12236>, and analyses of the partition and quartet distance of
  reconstructed trees from the generative tree, as analysed by Smith (2019)
  <doi:10.1098/rsbl.2018.0632>.",2020-01-07,Martin R. Smith,https://github.com/ms609/CongreveLamsdell2016,TRUE,https://github.com/ms609/congrevelamsdell2016,6844,0,2020-04-16T12:33:08Z,NA
conjurer,Builds synthetic data applicable across multiple domains. This package also provides flexibility to control data distribution to make it relevant to many industry examples.,2020-03-22,Sidharth Macherla,https://github.com/SidharthMacherla/conjurer,TRUE,https://github.com/sidharthmacherla/conjurer,2885,3,2020-04-20T01:33:13Z,961.6666666666666
connections,"Enables 'DBI' compliant packages to integrate with the 'RStudio' connections 
  pane, and the 'pins' package. It automates the display of schemata, tables, views, as well 
  as the preview of the table's top 1000 records. ",2020-02-07,Javier Luraschi,https://github.com/edgararuiz/connections,TRUE,https://github.com/edgararuiz/connections,2982,34,2020-02-07T14:43:20Z,87.70588235294117
ConnMatTools,"Collects several different methods for analyzing and
    working with connectivity data in R.  Though primarily oriented towards
    marine larval dispersal, many of the methods are general and useful for
    terrestrial systems as well.",2020-02-03,David M. Kaplan,https://github.com/dmkaplan2000/ConnMatTools.git,TRUE,https://github.com/dmkaplan2000/connmattools,19004,0,2020-02-03T09:21:10Z,NA
conquer,Fast and accurate convolution-type smoothed quantile regression. Implemented using Barzilai-Borwein gradient descent with a Huber regression warm start. Construct confidence intervals for regression coefficients using multiplier bootstrap.,2020-05-06,Xiaoou Pan,https://github.com/XiaoouPan/conquer,TRUE,https://github.com/xiaooupan/conquer,951,2,2020-05-06T05:04:38Z,475.5
ConR,"Multi-species estimation of geographical range parameters
	for preliminary assessment of conservation status following Criterion B of the 
	International Union for Conservation of Nature (IUCN, 
	see <http://www.iucnredlist.org>).",2020-05-18,Gilles Dauby,https://gdauby.github.io/ConR/,TRUE,https://github.com/gdauby/conr,16938,3,2020-05-18T15:13:23Z,5646
ConsReg,"Fits or generalized linear models either a regression with Autoregressive moving-average (ARMA) errors for time series data. 
       The package makes it easy to incorporate constraints into the model's coefficients. 
          The model is specified by an objective function (Gaussian, Binomial or Poisson) or an ARMA order (p,q), 
          a vector of bound constraints 
          for the coefficients (i.e beta1 > 0) and the possibility to incorporate restrictions
          among coefficients (i.e beta1 > beta2).
          The references of this packages are the same as 'stats' package for glm() and arima() functions.
          See Brockwell, P. J. and Davis, R. A. (1996, ISBN-10: 9783319298528).
          For the different optimizers implemented, it is recommended to consult the documentation of the corresponding packages. ",2020-04-05,Josep Puig Sallés,https://github.com/puigjos/ConsReg,TRUE,https://github.com/puigjos/consreg,1050,0,2020-04-03T13:29:22Z,NA
contact,"Process spatially- and temporally-discrete data into contact and 
   social networks, and facilitate network analysis by randomizing 
   individuals' movement paths and/or related categorical variables. To use 
   this package, users need only have a dataset containing spatial data 
   (i.e., latitude/longitude, or planar x & y coordinates), individual IDs 
   relating spatial data to specific individuals, and date/time information 
   relating spatial locations to temporal locations. The functionality of this 
   package ranges from data ""cleaning"" via multiple filtration functions, to 
   spatial and temporal data interpolation, and network creation and analysis. 
   Functions within this package are not limited to describing interpersonal 
   contacts. Package functions can also identify and quantify ""contacts"" 
   between individuals and fixed areas (e.g., home ranges, water bodies, 
   buildings, etc.). As such, this package is an incredibly useful resource 
   for facilitating epidemiological, ecological, ethological and sociological 
   research.",2020-06-02,Trevor Farthing,NA,TRUE,https://github.com/lanzaslab/contact,2727,1,2020-06-02T10:17:01Z,2727
contextual,"Facilitates the simulation and evaluation of context-free
    and contextual multi-Armed Bandit policies or algorithms to ease the
    implementation, evaluation, and dissemination of both existing and
    new bandit algorithms and policies.",2020-03-04,Robin van Emden,https://github.com/Nth-iteration-labs/contextual,TRUE,https://github.com/nth-iteration-labs/contextual,10321,44,2020-05-20T14:20:40Z,234.5681818181818
contfrac,Various utilities for evaluating continued fractions.,2018-05-17,Robin K. S. Hankin,https://github.com/RobinHankin/contfrac.git,TRUE,https://github.com/robinhankin/contfrac,478915,0,2020-05-01T21:32:19Z,NA
ContourFunctions,"Provides functions for making contour plots.
  The contour plot can be created from grid data, a function,
  or a data set. If non-grid data is given, then a Gaussian
  process is fit to the data and used to create the contour plot.",2019-05-20,Collin Erickson,https://github.com/CollinErickson/contour,TRUE,https://github.com/collinerickson/contour,13646,6,2019-08-11T14:28:13Z,2274.3333333333335
contrast,"One degree of freedom contrasts for 'lm', 'glm', 'gls', and 'geese' objects.",2020-03-19,Alan OCallaghan,https://github.com/topepo/contrast,TRUE,https://github.com/topepo/contrast,54815,1,2020-03-03T00:12:26Z,54815
contribution,"Contribution table for credit assignment based on 'ggplot2'.
    This can improve the author contribution information in academic journals and personal CV.  ",2019-07-18,Shixiang Wang,https://github.com/ShixiangWang/contribution,TRUE,https://github.com/shixiangwang/contribution,5094,3,2019-10-22T02:25:37Z,1698
control,"Solves control systems problems relating to time/frequency response, LTI systems design and analysis, transfer function manipulations, and system conversion.",2017-12-12,Ben C. Ubah,NA,TRUE,https://github.com/benubah/control,10336,12,2020-04-30T20:32:06Z,861.3333333333334
ConvergenceClubs,"Functions for clustering regions that form convergence clubs, according to the definition of Phillips and Sul (2009) <doi:10.1002/jae.1080>. A package description is available in Sichera and Pizzuto (2019).",2019-11-21,Roberto Sichera,https://CRAN.R-project.org/package=ConvergenceClubs,TRUE,https://github.com/rhobis/convergenceclubs,12367,1,2020-02-02T17:19:17Z,12367
convey,"Variance estimation on indicators of income concentration and
    poverty using complex sample survey designs. Wrapper around the
    'survey' package.",2020-05-22,Djalma Pessoa,https://guilhermejacob.github.io/context/,TRUE,https://github.com/djalmapessoa/convey,23962,9,2020-05-23T15:11:43Z,2662.4444444444443
CoordinateCleaner,"Automated flagging of common spatial and temporal errors in biological and paleontological collection data, for the use in conservation, ecology and paleontology. Includes automated tests to easily flag (and exclude) records assigned to country or province centroid, the open ocean, the headquarters of the Global Biodiversity Information Facility, urban areas or the location of biodiversity institutions (museums, zoos, botanical gardens, universities). Furthermore identifies per species outlier coordinates, zero coordinates, identical latitude/longitude and invalid coordinates. Also implements an algorithm to identify data sets with a significant proportion of rounded coordinates. Especially suited for large data sets. The reference for the methodology is: Zizka et al. (2019) doi:10.1111/2041-210X.13152.",2020-05-11,Alexander Zizka,https://ropensci.github.io/CoordinateCleaner/,TRUE,https://github.com/ropensci/coordinatecleaner,22998,44,2020-05-11T16:51:36Z,522.6818181818181
copent,"The nonparametric method for estimating copula entropy is implemented. The method composes of two simple steps: estimating empirical copula by rank statistic and estimating copula entropy with k-Nearest-Neighbour method. Copula Entropy is a mathematical concept for multivariate statistical independence measuring and testing, and proved to be equivalent to mutual information. Estimating copula entropy can be applied to many cases, including but not limited to variable selection and causal discovery (by estimating transfer entropy). Please refer to Ma and Sun (2011) <doi: 10.1016/S1007-0214(11)70008-6> for more information.",2020-04-16,MA Jian,https://github.com/majianthu/copent,TRUE,https://github.com/majianthu/copent,928,0,2020-05-24T00:51:48Z,NA
coppeCosenzaR,"The program implements the COPPE-Cosenza Fuzzy Hierarchy Model. 
    The model was based on the evaluation of local alternatives, representing 
    regional potentialities, so as to fulfill demands of economic projects. 
    After defining demand profiles in terms of their technological coefficients, 
    the degree of importance of factors is defined so as to represent  
    the productive activity. The method can detect a surplus of supply without 
    the restriction of the distance of classical algebra, defining a hierarchy 
    of location alternatives. In COPPE-Cosenza Model, the distance between 
    factors is measured in terms of the difference between grades of memberships
    of the same factors belonging to two or more  sets under comparison. The 
    required factors are classified under the following linguistic variables: 
    Critical (CR); Conditioning (C); Little Conditioning (LC); and Irrelevant 
    (I). And the alternatives can assume the following linguistic variables: 
    Excellent (Ex), Good (G), Regular (R), Weak (W), Empty (Em), Zero (Z) and 
    Inexistent (In). The model also provides flexibility, allowing different 
    aggregation rules to be performed and defined by the Decision Maker. Such 
    feature is considered in this package, allowing the user to define other 
    aggregation matrices, since it considers the same linguistic variables 
    mentioned. ",2017-10-28,Pier Taranti,https://github.com/ptaranti/coppeCosenzaR,TRUE,https://github.com/ptaranti/coppecosenzar,11992,0,2020-03-17T11:04:46Z,NA
coRanking,"Calculates the co-ranking matrix to assess the
    quality of a dimensionality reduction.",2020-02-12,Guido Kraemer,https://github.com/gdkrmr/coRanking,TRUE,https://github.com/gdkrmr/coranking,35114,5,2020-02-12T13:14:27Z,7022.8
Corbi,"Provides a bundle of basic and fundamental bioinformatics tools,
    such as network querying and alignment, subnetwork extraction and search,
    network biomarker identification.",2019-11-22,Ling-Yun Wu,https://github.com/wulingyun/Corbi,TRUE,https://github.com/wulingyun/corbi,18969,4,2019-11-22T03:20:44Z,4742.25
coreCT,"Computed tomography (CT) imaging is a powerful tool for understanding the composition of sediment cores. This package streamlines and accelerates the analysis of CT data generated in the context of environmental science. Included are tools for processing raw DICOM images to characterize sediment composition (sand, peat, etc.). Root analyses are also enabled, including measures of external surface area and volumes for user-defined root size classes. For a detailed description of the application of computed tomography imaging for sediment characterization, see: Davey, E., C. Wigand, R. Johnson, K. Sundberg, J. Morris, and C. Roman. (2011) <DOI: 10.1890/10-2037.1>.",2019-11-28,Troy D. Hill,https://github.com/troyhill/coreCT,TRUE,https://github.com/troyhill/corect,12549,1,2019-11-27T22:10:22Z,12549
cornet,Implements lasso and ridge regression for dichotomised outcomes (Rauschenberger et al. 2019). Such outcomes are not naturally but artificially binary. They indicate whether an underlying measurement is greater than a threshold.,2020-03-18,Armin Rauschenberger,https://github.com/rauschenberger/cornet,TRUE,https://github.com/rauschenberger/cornet,6429,1,2020-03-18T07:51:37Z,6429
coroICA,"Contains an implementation of a confounding robust independent component analysis (ICA) for noisy and grouped data. The main function coroICA() performs a blind source separation, by maximizing an independence across sources and allows to adjust for varying confounding based on user-specified groups. Additionally, the package contains the function uwedge() which can be used to approximately jointly diagonalize a list of matrices. For more details see the project website <https://sweichwald.de/coroICA/>.",2020-05-15,Niklas Pfister and Sebastian Weichwald,https://github.com/sweichwald/coroICA-R,TRUE,https://github.com/sweichwald/coroica-r,6287,1,2020-05-15T08:05:37Z,6287
coronavirus,Provides a daily summary of the Coronavirus (COVID-19) cases by state/province. Data source: Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus <https://systems.jhu.edu/research/public-health/ncov/>.,2020-05-13,Rami Krispin,https://github.com/RamiKrispin/coronavirus,TRUE,https://github.com/ramikrispin/coronavirus,17006,314,2020-06-09T08:08:23Z,54.15923566878981
corporaexplorer,"Facilitates dynamic exploration of text collections through an
    intuitive graphical user interface and the power of regular expressions.
    The package contains 1) a helper function to convert a data frame to a
    'corporaexplorerobject', 2) a 'Shiny' app for fast and flexible exploration
    of a 'corporaexplorerobject', and 3) a 'Shiny' app for simple
    retrieval/extraction of documents from a 'corporaexplorerobject' in a
    reading-friendly format. The package also includes demo apps with which
    one can explore Jane Austen's novels and the State of the Union Addresses
    (data from the 'janeaustenr' and 'sotu' packages respectively).",2020-03-07,Kristian Lundby Gjerde,"https://kgjerde.github.io/corporaexplorer,
https://github.com/kgjerde/corporaexplorer",TRUE,https://github.com/kgjerde/corporaexplorer,4959,39,2020-06-04T09:00:53Z,127.15384615384616
CoRpower,"Calculates power for assessment of intermediate biomarker responses as correlates of risk in the active treatment group in clinical efficacy trials, as described in Gilbert, Janes, and Huang, Power/Sample Size Calculations for Assessing Correlates of Risk in Clinical Efficacy Trials (2016, Statistics in Medicine). The methods differ from past approaches by accounting for the level of clinical treatment efficacy overall and in biomarker response subgroups, which enables the correlates of risk results to be interpreted in terms of potential correlates of efficacy/protection. The methods also account for inter-individual variability of the observed biomarker response that is not biologically relevant (e.g., due to technical measurement error of the laboratory assay used to measure the biomarker response), which is important because power to detect a specified correlate of risk effect size is heavily affected by the biomarker's measurement error. The methods can be used for a general binary clinical endpoint model with a univariate dichotomous, trichotomous, or continuous biomarker response measured in active treatment recipients at a fixed timepoint after randomization, with either case-cohort Bernoulli sampling or case-control without-replacement sampling of the biomarker (a baseline biomarker is handled as a trivial special case). In a specified two-group trial design, the computeN() function can initially be used for calculating additional requisite design parameters pertaining to the target population of active treatment recipients observed to be at risk at the biomarker sampling timepoint. Subsequently, the power calculation employs an inverse probability weighted logistic regression model fitted by the tps() function in the 'osDesign' package. Power results as well as the relationship between the correlate of risk effect size and treatment efficacy can be visualized using various plotting functions. To link power calculations for detecting a correlate of risk and a correlate of treatment efficacy, a baseline immunogenicity predictor (BIP) can be simulated according to a specified classification rule (for dichotomous or trichotomous BIPs) or correlation with the biomarker response (for continuous BIPs), then outputted along with biomarker response data under assignment to treatment, and clinical endpoint data for both treatment and placebo groups.",2019-09-27,Michal Juraska,https://github.com/mjuraska/CoRpower,TRUE,https://github.com/mjuraska/corpower,7661,0,2019-09-27T21:39:07Z,NA
corpus,"Text corpus data analysis, with full support for international text (Unicode).  Functions for reading data from newline-delimited 'JSON' files, for normalizing and tokenizing text, for searching for term occurrences, and for computing term occurrence frequencies, including n-grams.",2020-04-16,Leslie Huang,"https://leslie-huang.github.io/r-corpus/,
https://github.com/leslie-huang/r-corpus",TRUE,https://github.com/leslie-huang/r-corpus,64797,0,2020-04-15T18:53:36Z,NA
corpustools,"Provides text analysis in R, focusing on the use of a tokenized text format. In this format, the positions of tokens are maintained, and each token can be annotated (e.g., part-of-speech tags, dependency relations).
    Prominent features include advanced Lucene-like querying for specific tokens or contexts (e.g., documents, sentences),
    similarity statistics for words and documents, exporting to DTM for compatibility with many text analysis packages,
    and the possibility to reconstruct original text from tokens to facilitate interpretation.",2020-01-23,Kasper Welbers and Wouter van Atteveldt,http://github.com/kasperwelbers/corpustools,TRUE,https://github.com/kasperwelbers/corpustools,17130,19,2020-03-24T13:58:22Z,901.578947368421
corrcoverage,"Using a computationally efficient method, the package can
    be used to find the corrected coverage estimate of a credible set 
    of putative causal variants from Bayesian genetic fine-mapping. 
    The package can also be used to obtain a corrected credible set
    if required; that is, the smallest set of variants required such 
    that the corrected coverage estimate of the resultant credible set is  
    within some user defined accuracy of the desired coverage.
    Maller et al. (2012) <doi:10.1038/ng.2435>,
    Wakefield (2009) <doi:10.1002/gepi.20359>,
    Fortune and Wallace (2018) <doi:10.1093/bioinformatics/bty898>.",2019-12-06,Anna Hutchinson,https://annahutch.github.io/corrcoverage,TRUE,https://github.com/annahutch/corrcoverage,3137,2,2020-06-08T11:56:33Z,1568.5
correlation,"Lightweight package for computing different kinds of correlations, such as partial correlations, Bayesian correlations, multilevel correlations, polychoric correlations, biweight correlations, distance correlations and more. Relies on the easystats ecosystem (Lüdecke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>).",2020-05-05,Dominique Makowski,https://easystats.github.io/correlation/,TRUE,https://github.com/easystats/correlation,10606,88,2020-05-25T08:39:22Z,120.52272727272727
correlationfunnel,"
    Speeds up exploratory data analysis (EDA)
    by providing a succinct workflow and interactive visualization tools for understanding
    which features have relationships to target (response). Uses binary correlation analysis
    to determine relationship. Default correlation method is the Pearson method. 
    Lian Duan, W Nick Street, Yanchi Liu, Songhua Xu, and Brook Wu (2014) <doi:10.1145/2637484>.",2020-06-09,Matt Dancho,https://github.com/business-science/correlationfunnel,TRUE,https://github.com/business-science/correlationfunnel,7070,59,2020-06-09T00:32:54Z,119.83050847457628
corrgram,"Calculates correlation of variables and displays the results
    graphically. Included panel functions can display points, shading, ellipses, and
    correlation values with confidence intervals. See Friendly (2002) <doi:10.1198/000313002533>.",2018-07-09,Kevin Wright,https://github.com/kwstat/corrgram,TRUE,https://github.com/kwstat/corrgram,438270,11,2020-01-20T15:29:15Z,39842.72727272727
corrgrapher,"When exploring data or models we often examine variables one by one. 
  This analysis is incomplete if the relationship between these variables is 
  not taken into account. The 'corrgrapher' package facilitates simultaneous 
  exploration of the Partial Dependence Profiles and the correlation between 
  variables in the model.
  The package 'corrgrapher' is a part of the 'DrWhy.AI' universe.",2020-06-04,Pawel Morgen,"https://modeloriented.github.io/corrgrapher/,
https://github.com/ModelOriented/corrgrapher",TRUE,https://github.com/modeloriented/corrgrapher,0,9,2020-05-05T07:32:39Z,0
corrplot,"A graphical display of a correlation matrix or general matrix.
    It also contains some algorithms to do matrix reordering. In addition,
    corrplot is good at details, including choosing color, text labels,
    color labels, layout, etc.",2017-10-16,Taiyun Wei,https://github.com/taiyun/corrplot,TRUE,https://github.com/taiyun/corrplot,2792860,196,2020-06-06T17:47:39Z,14249.285714285714
corrr,"A tool for exploring correlations.
    It makes it possible to easily perform routine tasks when
    exploring correlation matrices such as ignoring the diagonal,
    focusing on the correlations of certain variables against others,
    or rearranging and visualizing the matrix in terms of the
    strength of the correlations.",2020-03-22,Max Kuhn,https://github.com/tidymodels/corrr,TRUE,https://github.com/tidymodels/corrr,100628,375,2020-05-13T14:21:37Z,268.34133333333335
cort,"Provides S4 classes and methods to fit several copula models: The classic empirical checkerboard copula and the empirical checkerboard copula with known margins, see Cuberos, Masiello and Maume-Deschamps (2019) <doi:10.1080/03610926.2019.1586936> are proposed. These two models allow to fit copulas in high dimension with a small number of observations, and they are always proper copulas. Some flexibility is added via a possibility to differentiate the checkerboard parameter by dimension. The last model consist of the implementation of the Copula Recursive Tree algorithm proposed by Laverny, Maume-Deschamps, Masiello and Rullière (2020) <arXiv:2005.02912>, including the localised dimension reduction, which fits a copula by recursive splitting of the copula domain. We also provide an efficient way of mixing copulas, allowing to bag the algorithm into a forest, and a generic way of measuring d-dimensional boxes with a copula.",2020-05-13,Oskar Laverny,https://github.com/lrnv/cort,TRUE,https://github.com/lrnv/cort,1332,0,2020-05-14T07:28:48Z,NA
cosinor,"cosinor is a set of simple functions that transforms longitudinal
    data to estimate the cosinor linear model as described in Tong (1976).
    Methods are given to summarize the mean, amplitude and acrophase, to
    predict the mean annual outcome value, and to test the coefficients.",2014-07-28,Michael Sachs,http://github.com/sachsmc/cosinor,TRUE,https://github.com/sachsmc/cosinor,20030,3,2020-05-09T10:50:14Z,6676.666666666667
costsensitive,"Reduction-based techniques for cost-sensitive multi-class classification, in which each observation has a different cost for classifying it into one class, and the goal is to predict the class with the minimum expected cost for each new observation.
	Implements Weighted All-Pairs (Beygelzimer, A., Langford, J., & Zadrozny, B., 2008, <doi:10.1007/978-0-387-79361-0_1>), Weighted One-Vs-Rest (Beygelzimer, A., Dani, V., Hayes, T., Langford, J., & Zadrozny, B., 2005, <https://dl.acm.org/citation.cfm?id=1102358>) and Regression One-Vs-Rest.
	Works with arbitrary classifiers taking observation weights, or with regressors. Also implements cost-proportionate rejection sampling for working with classifiers
	that don't accept observation weights.",2019-07-28,David Cortes,https://github.com/david-cortes/costsensitive,TRUE,https://github.com/david-cortes/costsensitive,8199,24,2020-04-04T18:19:31Z,341.625
countfitteR,"A large number of measurements generate count data. This is a statistical data type that only assumes non-negative integer values and is generated by counting. Typically, counting data can be found in biomedical applications, such as the analysis of DNA double-strand breaks. The number of DNA double-strand breaks can be counted in individual cells using various bioanalytical methods. For diagnostic applications, it is relevant to record the distribution of the number data in order to determine their biomedical significance (Roediger, S. et al., 2018. Journal of Laboratory and Precision Medicine. <doi:10.21037/jlpm.2018.04.10>). The software offers functions for a comprehensive automated evaluation of distribution models of count data. In addition to programmatic interaction, a graphical user interface (web server) is included, which enables fast and interactive data-scientific analyses. The user is supported in selecting the most suitable counting distribution for his own data set.",2019-02-03,Jaroslaw Chilimoniuk,https://github.com/jarochi/countfitteR,TRUE,https://github.com/jarochi/countfitter,5836,2,2020-05-08T09:19:42Z,2918
countrycode,"Standardize country names, convert them into one of
    40 different coding schemes, convert between coding schemes, and
    assign region descriptors.",2020-05-22,Vincent Arel-Bundock,https://github.com/vincentarelbundock/countrycode,TRUE,https://github.com/vincentarelbundock/countrycode,230891,202,2020-05-26T01:52:03Z,1143.0247524752476
countToFPKM,"Implements the algorithm described in Trapnell,C. et al. (2010) <doi: 10.1038/nbt.1621>. This function takes read counts matrix of RNA-Seq data, feature lengths which can be retrieved using 'biomaRt' package, and the mean fragment lengths which can be calculated using the 'CollectInsertSizeMetrics(Picard)' tool. It then returns a matrix of FPKM normalised data by library size and feature effective length. It also provides the user with a quick and reliable function to generate FPKM heatmap plot of the highly variable features in RNA-Seq dataset.",2019-04-07,Ahmed Alhendi,https://github.com/AAlhendi1707/countToFPKM,TRUE,https://github.com/aalhendi1707/counttofpkm,13731,14,2019-08-07T17:09:31Z,980.7857142857143
covafillr,"Facilitates local polynomial regression for state dependent covariates in state-space models. The functionality can also be used from 'C++' based model builder tools such as 'Rcpp'/'inline', 'TMB', or 'JAGS'.",2019-11-22,Christoffer Moesgaard Albertsen,https://github.com/calbertsen/covafillr,TRUE,https://github.com/calbertsen/covafillr,17810,1,2019-11-22T10:44:46Z,17810
coveffectsplot,"Produce forest plots to visualize covariate effects using either
    the command line or an interactive 'Shiny' application.",2020-04-03,Samer Mouksassi,https://github.com/smouksassi/interactiveforestplot,TRUE,https://github.com/smouksassi/interactiveforestplot,9011,9,2020-06-03T09:33:45Z,1001.2222222222222
COVID19,"Unified datasets for a better understanding of COVID-19. 
  The package collects COVID-19 data across governmental sources, 
  includes policy measures from 'Oxford COVID-19 Government Response Tracker' <https://www.bsg.ox.ac.uk/covidtracker>, 
  and extends the dataset via an interface to 'World Bank Open Data' <https://data.worldbank.org/>, 'Google Mobility Reports' <https://www.google.com/covid19/mobility/>, 'Apple Mobility Reports' <https://www.apple.com/covid19/mobility>.",2020-05-18,Emanuele Guidotti,https://covid19datahub.io,TRUE,https://github.com/covid19datahub/r,5220,2,2020-06-05T21:14:05Z,2610
covid19.analytics,"Load and analyze updated time series worldwide data of reported cases for the Novel CoronaVirus Disease (CoViD-19) from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) data repository <https://github.com/CSSEGISandData/COVID-19>. The datasets are available in two main modalities, as a time series sequences and aggregated for the last day with greater spatial resolution. Several analysis, visualization and modelling functions are available in the package that will allow the user to compute and visualize total number of cases, total number of changes and growth rate globally or for an specific geographical location, while at the same time generating models using these trends; generate interactive visualizations and generate Susceptible-Infected-Recovered (SIR) model for the disease spread.",2020-05-03,Marcelo Ponce,https://mponce0.github.io/covid19.analytics/,TRUE,https://github.com/mponce0/covid19.analytics,4573,13,2020-06-09T17:02:57Z,351.7692307692308
covid19italy,"Provides a daily summary of the Coronavirus (COVID-19) cases in Italy by country, region and province level. Data source: Presidenza del Consiglio dei Ministri - Dipartimento della Protezione Civile <http://www.protezionecivile.it/>.",2020-04-26,Rami Krispin,https://github.com/Covid19R/covid19italy,TRUE,https://github.com/covid19r/covid19italy,2312,3,2020-05-16T19:17:38Z,770.6666666666666
covid19nytimes,"Accesses the NY Times Covid-19 county-level data
    for the US, described in
    <https://www.nytimes.com/article/coronavirus-county-data-us.html> and
    available at <https://github.com/nytimes/covid-19-data>. It then returns
    the data in a tidy data format according to the Covid19R Project data
    specification. If you plan to use the data or publicly display the data
    or results, please make sure cite the original NY Times source. Please read and
    follow the terms laid out in the data license at 
    <https://github.com/nytimes/covid-19-data/blob/master/LICENSE>.",2020-05-08,Jarrett Byrnes,https://github.com/Covid19R/covid19nytimes,TRUE,https://github.com/covid19r/covid19nytimes,513,14,2020-05-14T19:10:53Z,36.642857142857146
covr,"Track and report code coverage for your package and (optionally)
    upload the results to a coverage service like 'Codecov' <http://codecov.io> or
    'Coveralls' <http://coveralls.io>. Code coverage is a measure of the amount of
    code being exercised by a set of tests. It is an indirect measure of test
    quality and completeness. This package is compatible with any testing
    methodology or framework and tracks coverage of both R code and compiled
    C/C++/FORTRAN code.",2020-03-06,Jim Hester,"https://covr.r-lib.org, https://github.com/r-lib/covr",TRUE,https://github.com/r-lib/covr,5015537,267,2020-06-02T14:48:08Z,18784.78277153558
covTestR,"Testing functions for Covariance Matrices. These tests include high-dimension homogeneity of covariance
  matrix testing described by Schott (2007) <doi:10.1016/j.csda.2007.03.004> and high-dimensional one-sample tests of 
  covariance matrix structure described by Fisher, et al. (2010) <doi:10.1016/j.jmva.2010.07.004>. Covariance matrix
  tests use C++ to speed performance and allow larger data sets.",2018-08-17,Ben Barnard,https://covtestr.bearstatistics.com,TRUE,https://github.com/benbarnard/covtestr,16086,0,2019-11-30T17:37:18Z,NA
cowplot,"
    Provides various features that help with creating publication-quality figures
    with 'ggplot2', such as a set of themes, functions to align plots and arrange
    them into complex compound figures, and functions that make it easy to annotate
    plots and or mix plots with images. The package was originally written for
    internal use in the Wilke lab, hence the name (Claus O. Wilke's plot package).
    It has also been used extensively in the book Fundamentals of Data
    Visualization.",2019-07-11,Claus O. Wilke,https://wilkelab.org/cowplot,TRUE,https://github.com/wilkelab/cowplot,3212371,480,2019-12-03T01:06:46Z,6692.439583333334
cowsay,"Allows printing of character strings as messages/warnings/etc.
    with ASCII animals, including cats, cows, frogs, chickens, ghosts,
    and more.",2020-02-06,Scott Chamberlain,https://github.com/sckott/cowsay,TRUE,https://github.com/sckott/cowsay,45988,205,2020-02-07T19:07:46Z,224.33170731707318
coxed,"Functions for generating, simulating, and visualizing expected durations and marginal changes in duration from the Cox proportional hazards model as described in Kropko and Harden (2017) <doi:10.1017/S000712341700045X> and Harden and Kropko (2018) <doi:10.1017/psrm.2018.19>.",2020-01-10,Kropko,https://github.com/jkropko/coxed,TRUE,https://github.com/jkropko/coxed,12501,7,2020-01-10T15:01:46Z,1785.857142857143
coxrt,Fits Cox regression based on retrospectively ascertained times-to-event. The method uses Inverse-Probability-Weighting estimating equations. ,2020-01-07,Bella Vakulenko-Lagun,https://github.com/Bella2001/coxrt,TRUE,https://github.com/bella2001/coxrt,9198,0,2019-07-31T19:52:32Z,NA
cppRouting,"Calculation of distances, shortest paths and isochrones on weighted graphs using several variants of Dijkstra algorithm.
    Proposed algorithms are unidirectional Dijkstra (Dijkstra, E. W. (1959) <doi:10.1007/BF01386390>),
    bidirectional Dijkstra (Goldberg, Andrew & Fonseca F. Werneck, Renato (2005) <https://pdfs.semanticscholar.org/0761/18dfbe1d5a220f6ac59b4de4ad07b50283ac.pdf>),
    A* search (P. E. Hart, N. J. Nilsson et B. Raphael (1968) <doi:10.1109/TSSC.1968.300136>),
    new bidirectional A* (Pijls & Post (2009) <http://repub.eur.nl/pub/16100/ei2009-10.pdf>),
    Contraction hierarchies (R. Geisberger, P. Sanders, D. Schultes and D. Delling (2008) <doi:10.1007/978-3-540-68552-4_24>),
    PHAST (D. Delling, A.Goldberg, A. Nowatzyk, R. Werneck (2011) <doi:10.1016/j.jpdc.2012.02.007>).",2020-01-07,Vincent Larmet,https://github.com/vlarmet/cppRouting,TRUE,https://github.com/vlarmet/cpprouting,5943,46,2020-01-03T10:58:44Z,129.19565217391303
cpr,"Implementation of the Control Polygon Reduction and Control Net
    Reduction methods for finding parsimonious B-spline regression models.",2017-03-07,Peter DeWitt,https://github.com/dewittpe/cpr/,TRUE,https://github.com/dewittpe/cpr,11388,2,2019-09-06T15:47:15Z,5694
cptcity,Incorporates colour gradients from the 'cpt-city' web archive available at <http://soliton.vm.bytemark.co.uk/pub/cpt-city/>. ,2019-03-07,Sergio Ibarra-Espinosa,https://github.com/ibarraespinosa/cptcity,TRUE,https://github.com/ibarraespinosa/cptcity,11559,7,2019-11-07T04:56:40Z,1651.2857142857142
cqcr,"Access data from the 'Care Quality Commission', the health 
    and adult social care regulator for England. The 'Care Quality Commission' 
    operates an API 
    <https://www.cqc.org.uk/about-us/transparency/using-cqc-data#api>, with data
    available under the Open Government License. Data includes information on 
    service providers, locations such as hospitals, care homes and 
    medical clinics, and ratings and inspection reports.",2019-10-07,Evan Odell,"https://github.com/evanodell/cqcr, https://docs.evanodell.com/cqcr",TRUE,https://github.com/evanodell/cqcr,3466,0,2020-04-22T12:51:11Z,NA
cranlike,"A set of functions to manage 'CRAN'-like repositories
    efficiently.",2018-11-26,Gábor Csárdi,https://github.com/r-hub/cranlike,TRUE,https://github.com/r-hub/cranlike,14106,22,2020-03-07T10:03:26Z,641.1818181818181
cranlogs,"'API' to the database of 'CRAN' package downloads from the
    'RStudio' 'CRAN mirror'. The database itself is at <http://cranlogs.r-pkg.org>,
    see <https://github.com/r-hub/cranlogs.app> for the raw 'API'.",2019-04-29,Gábor Csárdi,"https://github.com/r-hub/cranlogs,
https://r-hub.github.io/cranlogs",TRUE,https://github.com/r-hub/cranlogs,41093,61,2019-12-03T09:04:10Z,673.655737704918
cranly,"Core visualizations and summaries for the CRAN package database. The package provides comprehensive methods for cleaning up and organizing the information in the CRAN package database, for building package directives networks (depends, imports, suggests, enhances, linking to) and collaboration networks, producing package dependence trees, and for computing useful summaries and producing interactive visualizations from the resulting networks and summaries. The resulting networks can be coerced to 'igraph' <https://CRAN.R-project.org/package=igraph> objects for further analyses and modelling.",2019-10-08,Ioannis Kosmidis,https://github.com/ikosmidis/cranly,TRUE,https://github.com/ikosmidis/cranly,11123,40,2019-10-08T16:41:24Z,278.075
CREAM,"Provides a new method for identification of clusters of genomic
 regions within chromosomes. Primarily, it is used for calling clusters of 
 cis-regulatory elements (COREs). 'CREAM' uses genome-wide maps of genomic regions
 in the tissue or cell type of interest, such as those generated from chromatin-based 
 assays including DNaseI, ATAC or ChIP-Seq. 'CREAM' considers proximity of the elements 
 within chromosomes of a given sample to identify COREs in the following steps:
 1) It identifies window size or the maximum allowed distance between the elements 
 within each CORE, 2) It identifies number of elements which should be clustered 
 as a CORE, 3) It calls COREs, 4) It filters the COREs with lowest order which 
 does not pass the threshold considered in the approach.",2018-06-06,Benjamin Haibe-Kains,https://github.com/bhklab/CREAM,TRUE,https://github.com/bhklab/cream,10722,7,2020-01-31T20:59:21Z,1531.7142857142858
cregg,"Simple tidying, analysis, and visualization of conjoint (factorial) experiments, including estimation and visualization of average marginal component effects ('AMCEs') and marginal means ('MMs') for weighted and un-weighted survey data, along with useful reference category diagnostics and statistical tests. Estimation of 'AMCEs' is based upon methods described by Hainmueller, Hopkins, and Yamamoto (2014) <doi:10.1093/pan/mpt024>.",2018-07-30,Thomas J. Leeper,https://github.com/leeper/cregg,TRUE,https://github.com/leeper/cregg,7206,38,2020-05-23T12:26:41Z,189.6315789473684
cRegulome,"Builds a 'SQLite' database file of pre-calculated transcription 
    factor/microRNA-gene correlations (co-expression) in cancer from the 
    Cistrome Cancer Liu et al. (2011) <doi:10.1186/gb-2011-12-8-r83> and 
    'miRCancerdb' databases (in press). Provides custom classes and functions 
    to query, tidy and plot the correlation data.",2020-05-08,Mahmoud Ahmed,"https://docs.ropensci.org/cRegulome,
https://github.com/ropensci/cRegulome",TRUE,https://github.com/ropensci/cregulome,12431,2,2020-04-04T08:17:42Z,6215.5
CRF,"Implements modeling and computational tools for conditional
    random fields (CRF) model as well as other probabilistic undirected
    graphical models of discrete data with pairwise and unary potentials.",2019-12-01,Ling-Yun Wu,https://github.com/wulingyun/CRF,TRUE,https://github.com/wulingyun/crf,31768,12,2019-11-30T02:14:41Z,2647.3333333333335
crfsuite,"Wraps the 'CRFsuite' library <https://github.com/chokkan/crfsuite> allowing users 
    to fit a Conditional Random Field model and to apply it on existing data.
    The focus of the implementation is in the area of Natural Language Processing where this R package allows you to easily build and apply models 
    for named entity recognition, text chunking, part of speech tagging, intent recognition or classification of any category you have in mind. Next to training, a small web application
    is included in the package to allow you to easily construct training data.",2020-05-18,Jan Wijffels,https://github.com/bnosac/crfsuite,TRUE,https://github.com/bnosac/crfsuite,11037,44,2020-05-12T08:55:48Z,250.8409090909091
cricketr,"Tools for analyzing performances of cricketers based on stats in
    ESPN Cricinfo Statsguru. The toolset can  be used for analysis of Tests,ODIs 
    and Twenty20 matches of both batsmen and bowlers. The package can also be used to
    analyze team performances.",2020-03-28,Tinniam V Ganesh,https://github.com/tvganesh/cricketr,TRUE,https://github.com/tvganesh/cricketr,23937,45,2020-03-28T14:12:21Z,531.9333333333333
crispRdesignR,"Designs guide sequences for CRISPR/Cas9 genome editing and 
    provides information on sequence features pertinent to guide 
    efficiency. Sequence features include annotated off-target 
    predictions in a user-selected genome and a predicted efficiency 
    score based on the model described in Doench et al. (2016) 
    <doi:10.1038/nbt.3437>. Users are able to import additional genomes 
    and genome annotation files to use when searching and annotating 
    off-target hits. All guide sequences and off-target data can be 
    generated through the 'R' console with sgRNA_Design() or through 
    'crispRdesignR's' user interface with crispRdesignRUI(). CRISPR 
    (Clustered Regularly Interspaced Short Palindromic Repeats) and the 
    associated protein Cas9 refer to a technique used in genome editing.",2020-05-26,Dylan Beeber,<https://github.com/dylanbeeber/crispRdesignR>,TRUE,https://github.com/dylanbeeber/crisprdesignr,121,5,2020-05-29T03:05:10Z,24.2
crminer,"Text mining client for 'Crossref' (<https://crossref.org>). Includes
    functions for getting getting links to full text of articles, fetching full
    text articles from those links or Digital Object Identifiers ('DOIs'),
    and text extraction from 'PDFs'.",2020-04-07,Scott Chamberlain,"https://github.com/ropensci/crminer (devel)
https://docs.ropensci.org/crminer (docs)",TRUE,https://github.com/ropensci/crminer,22428,17,2020-06-01T17:56:50Z,1319.2941176470588
crmn,"Implements the Cross-contribution Compensating Multiple
    standard Normalization (CCMN) method described in Redestig et
    al. (2009) Analytical Chemistry <doi:10.1021/ac901143w>
    and other normalization algorithms.",2020-02-10,Henning Redestig,https://github.com/hredestig/crmn,TRUE,https://github.com/hredestig/crmn,26422,0,2020-02-10T07:37:47Z,NA
crmPack,"Implements a wide range of model-based dose
    escalation designs, ranging from classical and modern continual
    reassessment methods (CRMs) based on dose-limiting toxicity endpoints to
    dual-endpoint designs taking into account a biomarker/efficacy outcome. The
    focus is on Bayesian inference, making it very easy to setup a new design
    with its own JAGS code. However, it is also possible to implement 3+3
    designs for comparison or models with non-Bayesian estimation. The whole
    package is written in a modular form in the S4 class system, making it very
    flexible for adaptation to new models, escalation or stopping rules.",2019-06-13,Giuseppe Palermo,https://github.com/roche/crmPack,TRUE,https://github.com/roche/crmpack,22851,3,2019-10-26T18:23:28Z,7617
crochet,"Functions to help implement the extraction / subsetting / indexing
    function '[' and replacement function '[<-' of custom matrix-like types
    (based on S3, S4, etc.), modeled as closely to the base matrix class as
    possible (with tests to prove it).",2020-05-20,Alexander Grueneberg,https://github.com/agrueneberg/crochet,TRUE,https://github.com/agrueneberg/crochet,17466,4,2020-05-20T19:55:14Z,4366.5
CropDetectR,"A helpful tool for the identification of crop rows. Methods of this package include: Excess Green color scale <https://www.researchgate.net/publication/270613992_Color_Indices_for_Weed_Identification_Under_Various_Soil_Residue_and_Lighting_Conditions>, Otsu Thresholding <https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4310076>, and Morphology <https://en.wikipedia.org/wiki/Mathematical_morphology>.",2019-09-20,Nicolaas VanSteenbergen,NA,TRUE,https://github.com/niconaut/cropdetectr,3823,0,2019-12-31T20:35:43Z,NA
crossrun,"Joint distribution of number of crossings and the 
  longest run in a series of independent Bernoulli trials. The
  computations uses an iterative procedure where computations 
  are based on results from shorter series. The procedure 
  conditions on the start value and partitions by further 
  conditioning on the position of the first crossing (or none).",2018-10-08,Tore Wentzel-Larsen,https://github.com/ToreWentzel-Larsen/crossrun,TRUE,https://github.com/torewentzel-larsen/crossrun,6192,0,2020-06-07T07:02:07Z,NA
crosstalk,"Provides building blocks for allowing HTML widgets to communicate
    with each other, with Shiny or without (i.e. static .html files). Currently
    supports linked brushing and filtering.",2020-03-13,Joe Cheng,https://rstudio.github.io/crosstalk/,TRUE,https://github.com/rstudio/crosstalk,6323249,202,2020-05-19T16:16:16Z,31303.212871287127
crosswalkr,"A pair of functions for renaming and encoding data frames
	     using external crosswalk files. It is especially useful when
	     constructing master data sets from multiple smaller data
	     sets that do not name or encode variables consistently
	     across files. Based on similar commands in 'Stata'.",2020-01-08,Benjamin Skinner,https://github.com/btskinner/crosswalkr,TRUE,https://github.com/btskinner/crosswalkr,13059,6,2019-12-18T20:29:16Z,2176.5
crplyr,"In order to facilitate analysis of datasets hosted on the Crunch
    data platform <http://crunch.io/>, the 'crplyr' package implements 'dplyr'
    methods on top of the Crunch backend. The usual methods 'select', 'filter',
    'group_by', 'summarize', and 'collect' are implemented in such a way as to
    perform as much computation on the server and pull as little data locally
    as possible.",2020-04-24,Greg Freedman Ellis,"https://crunch.io/r/crplyr/, https://github.com/Crunch-io/crplyr",TRUE,https://github.com/crunch-io/crplyr,13359,4,2020-04-27T14:14:37Z,3339.75
crs,"Regression splines that handle a mix of continuous and categorical (discrete) data often encountered in applied settings. I would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <http://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <http://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://www.sharcnet.ca>).",2019-11-25,Jeffrey S. Racine,https://github.com/JeffreyRacine/R-Package-crs,TRUE,https://github.com/jeffreyracine/r-package-crs,90612,10,2019-11-19T14:44:07Z,9061.2
crseEventStudy,"Based on Dutta et al. (2018) <doi:10.1016/j.jempfin.2018.02.004>, this package provides their standardized test for abnormal returns in long-horizon event studies. The methods used improve the major weaknesses of size, power, and robustness of long-run statistical tests described in Kothari/Warner (2007) <doi:10.1016/B978-0-444-53265-7.50015-9>. Abnormal returns are weighted by their statistical precision (i.e., standard deviation), resulting in abnormal standardized returns. This procedure efficiently captures the heteroskedasticity problem. Clustering techniques following Cameron et al. (2011) <10.1198/jbes.2010.07136> are adopted for computing cross-sectional correlation robust standard errors. The statistical tests in this package therefore accounts for potential biases arising from returns' cross-sectional correlation, autocorrelation, and volatility clustering without power loss.",2019-08-20,Siegfried Köstlmeier,https://github.com/skoestlmeier/crseEventStudy,TRUE,https://github.com/skoestlmeier/crseeventstudy,8486,1,2019-08-20T08:21:55Z,8486
crsmeta,"Obtain coordinate system metadata from various data formats. There 
 are functions to extract a 'CRS' (coordinate reference system, 
 <https://en.wikipedia.org/wiki/Spatial_reference_system>) in 'EPSG' (European 
 Petroleum Survey Group, <http://www.epsg.org/>), 'PROJ4' <https://proj.org/>, 
 or 'WKT2' (Well-Known Text 2, 
 <http://docs.opengeospatial.org/is/12-063r5/12-063r5.html>) forms. This is 
 purely for getting simple metadata from in-memory formats, please use other 
 tools for out of memory data sources. ",2020-03-29,Michael Sumner,https://github.com/hypertidy/crsmeta,TRUE,https://github.com/hypertidy/crsmeta,4213,5,2020-03-29T09:57:42Z,842.6
crsra,"Tidies and performs preliminary analysis of 'Coursera' research
    export data. These export data can be downloaded by anyone who has classes
    on Coursera and wants to analyze the data. Coursera is one of the leading 
    providers of MOOCs and was launched in January 2012. With over 25 million 
    learners, Coursera is the most popular provider in the world being followed 
    by EdX, the MOOC provider that was a result of a collaboration between 
    Harvard University and MIT, with over 10 million users. Coursera has over 
    150 university partners from 29 countries and offers a total of 2000+ 
    courses from computer science to philosophy. Besides, Coursera offers 180+ 
    specialization, Coursera's credential system, and four fully online Masters 
    degrees. For more information about Coursera check Coursera's
    About page on <https://blog.coursera.org/about/>.",2018-05-05,Aboozar Hadavand,NA,TRUE,https://github.com/jhudsl/crsra,7671,1,2020-04-30T20:28:01Z,7671
CRUF,"Miscellaneous functions for clinical research data analysis. Format table of descriptive statistics, regression models, pvalues according to medical journals standards.",2020-03-05,Yves Gallien,https://github.com/Ygall/CRUF,TRUE,https://github.com/ygall/cruf,1608,0,2020-03-06T09:56:12Z,NA
crunch,"The Crunch.io service <http://crunch.io/> provides a cloud-based
    data store and analytic engine, as well as an intuitive web interface.
    Using this package, analysts can interact with and manipulate Crunch
    datasets from within R. Importantly, this allows technical researchers to
    collaborate naturally with team members, managers, and clients who prefer a
    point-and-click interface.",2020-03-12,Greg Freedman Ellis,"https://crunch.io/r/crunch/, https://github.com/Crunch-io/rcrunch",TRUE,https://github.com/crunch-io/rcrunch,63831,7,2020-06-09T12:37:52Z,9118.714285714286
csa,"Integration of Earth system data from various sources is a challenging task. Except for their qualitative heterogeneity, different data records exist for describing similar Earth system process at different spatio-temporal scales. Data inter-comparison and validation are usually performed at a single spatial or temporal scale, which could hamper the identification of potential discrepancies in other scales. 'csa' package offers a simple, yet efficient, graphical method for synthesizing and comparing observed and modelled data across a range of spatio-temporal scales. Instead of focusing at specific scales, such as annual means or original grid resolution, we examine how their statistical properties change across spatio-temporal continuum.  ",2020-05-16,Yannis Markonis,http://github.com/imarkonis/csa,TRUE,https://github.com/imarkonis/csa,345,0,2020-05-12T20:10:20Z,NA
cSEM,"Estimate, assess, test, and study linear, nonlinear, hierarchical 
  and multigroup structural equation models using composite-based approaches 
  and procedures, including estimation techniques such as partial least squares 
  path modeling (PLS-PM) and its derivatives (PLSc, ordPLSc, robustPLSc), 
  generalized structured component analysis (GSCA), generalized structured 
  component analysis with uniqueness terms (GSCAm), generalized canonical 
  correlation analysis (GCCA), principal component analysis (PCA), 
  factor score regression (FSR) using sum score, regression or 
  bartlett scores (including bias correction using Croon’s approach), 
  as well as several tests and typical postestimation procedures 
  (e.g., verify admissibility of the estimates, assess the model fit, 
  test the model fit etc.).",2020-03-29,Manuel E. Rademaker,"https://github.com/M-E-Rademaker/cSEM,
https://m-e-rademaker.github.io/cSEM/",TRUE,https://github.com/m-e-rademaker/csem,2760,8,2020-05-19T10:57:59Z,345
cstab,"Selection of the number of clusters in cluster analysis using
    stability methods.",2018-06-19,Jonas M. B. Haslbeck,NA,TRUE,https://github.com/jmbh/cstab,16090,2,2019-07-27T21:36:17Z,8045
ctDNAtools,"Contains tools to analyze minimal residual disease and cell-free DNA fragmentation from aligned sequencing data.
    More details on the methods can be found in:
    Amjad Alkodsi, Leo Meriranta, Annika Pasanen, Sirpa Leppä (2020) <doi:10.1101/2020.01.27.912790>.",2020-03-04,Amjad Alkodsi,https://github.com/alkodsi/ctDNAtools,TRUE,https://github.com/alkodsi/ctdnatools,994,10,2020-03-05T18:34:49Z,99.4
ctmm,"Functions for identifying, fitting, and applying continuous-space, continuous-time stochastic movement models to animal tracking data.
  The package is described in Calabrese et al (2016) <doi:10.1111/2041-210X.12559>, with models and methods based on those introduced in
  Fleming & Calabrese et al (2014) <doi:10.1086/675504>,
  Fleming et al (2014) <doi:10.1111/2041-210X.12176>,
  Fleming et al (2015) <doi:10.1103/PhysRevE.91.032107>,
  Fleming et al (2015) <doi:10.1890/14-2010.1>,
  Fleming et al (2016) <doi:10.1890/15-1607>,
  Péron & Fleming et al (2016) <doi:10.1186/s40462-016-0084-7>,
  Fleming & Calabrese (2017) <doi:10.1111/2041-210X.12673>,
  Péron et al (2017) <doi:10.1002/ecm.1260>,
  Fleming et al (2017) <doi:10.1016/j.ecoinf.2017.04.008>,
  Fleming et al (2018) <doi:10.1002/eap.1704>,
  Winner & Noonan et al (2018) <doi:10.1111/2041-210X.13027>,
  Fleming et al (2019) <doi:10.1111/2041-210X.13270>,
  and
  Noonan & Fleming et al (2019) <doi:10.1186/s40462-019-0177-1>.",2020-05-07,Christen H. Fleming,"https://github.com/ctmm-initiative/ctmm,
http://biology.umd.edu/movement.html",TRUE,https://github.com/ctmm-initiative/ctmm,48688,9,2020-05-15T21:51:44Z,5409.777777777777
ctrdata,"Provides functions for querying, retrieving and analysing
        protocol- and results-related information on clinical trials from
        two public registers, the European Union Clinical Trials Register
        (EUCTR, <https://www.clinicaltrialsregister.eu/>) and
        ClinicalTrials.gov (CTGOV, <https://clinicaltrials.gov/>). The
        information is transformed and then stored in a database (nodbi).
        Functions are provided for accessing and analysing the locally
        stored information on the clinical trials, as well as for
        identifying duplicate records. The package is motivated by the need
        for aggregating and trend-analysing the design, conduct and outcomes
        across clinical trials.",2020-05-18,Ralf Herold,https://github.com/rfhb/ctrdata,TRUE,https://github.com/rfhb/ctrdata,7703,13,2020-05-19T06:16:55Z,592.5384615384615
cubature,"R wrappers around the cubature C library of Steven
    G. Johnson for adaptive multivariate integration over hypercubes
    and the Cuba C library of Thomas Hahn for deterministic and
    Monte Carlo integration. Scalar and vector interfaces for 
    cubature and Cuba routines are provided; the vector interfaces
    are highly recommended as demonstrated in the package
    vignette.",2019-12-04,Balasubramanian Narasimhan,https://bnaras.github.io/cubature,TRUE,https://github.com/bnaras/cubature,729949,5,2019-12-03T19:23:48Z,145989.8
cubelyr,"An implementation of a data cube extracted out of
    'dplyr' for backward compatibility.",2020-02-29,Hadley Wickham,https://github.com/hadley/cubelyr,TRUE,https://github.com/hadley/cubelyr,9425,20,2020-03-02T23:37:33Z,471.25
Cubist,Regression modeling using rules with added instance-based corrections.,2020-01-10,Max Kuhn,https://topepo.github.io/Cubist,TRUE,https://github.com/topepo/cubist,980201,24,2020-01-09T19:48:50Z,40841.708333333336
CUFF,"Utility functions that provides wrapper to descriptive base functions
  like cor, mean and table.  It makes use of the formula interface to pass
  variables to functions.  It also provides operators to concatenate (%+%), to
  repeat (%n%) and manage character vectors for nice display.",2019-01-22,Charles-Édouard Giguère,https://github.com/giguerch/CUFF,TRUE,https://github.com/giguerch/cuff,17751,0,2020-03-13T03:34:05Z,NA
cumulocityr,"Access the 'Cumulocity' API and retrieve data on devices, measurements, and events. Documentation for the API can be found at <https://www.cumulocity.com/guides/reference/rest-implementation/>.",2019-10-20,Dmitriy Bolotov,"https://softwareag.github.io/cumulocityr/,
https://github.com/SoftwareAG/cumulocityr",TRUE,https://github.com/softwareag/cumulocityr,2991,3,2020-04-29T20:37:46Z,997
cuRe,"Contains functions for estimating generalized parametric mixture and non-mixture cure models, loss of lifetime, mean residual lifetime, and crude event probabilities.",2020-04-23,Lasse Hjort Jakobsen,http://github.com/LasseHjort/cuRe,TRUE,https://github.com/lassehjort/cure,2408,0,2020-05-11T19:27:03Z,NA
customLayout,"Create complicated drawing areas for multiple elements by combining much simpler layouts. It is an extended version of layout function from the 'graphics' package, but it also works with 'grid' graphics. It also supports arranging elements inside 'PowerPoint' slides created using the 'officer' package.",2020-01-17,Zygmunt Zawadzki,"https://www.customlayout.zstat.pl/,
https://github.com/zzawadz/customLayout",TRUE,https://github.com/zzawadz/customlayout,12486,47,2020-01-17T13:05:20Z,265.6595744680851
cutoff,"Seek the significant cutoff value for a continuous variable, which will 
    be transformed into a classification, for linear regression, 
    logistic regression, logrank analysis and cox regression. First of all, 
    all combinations will be gotten by combn() function. Then n.per argument, 
    abbreviated of total number percentage, will be used to remove the combination 
    of smaller data group. In logistic, Cox regression and logrank analysis, 
    we will also use p.per argument, patient percentage, to filter the lower 
    proportion of patients in each group. Finally, p value in regression 
    results will be used to get the significant combinations and output 
    relevant parameters. In this package, there is no limit to the number of 
    cutoff points, which can be 1, 2, 3 or more. Still, we provide 2 methods, 
    typical Bonferroni and Duglas G (1994) <doi: 10.1093/jnci/86.11.829>, to 
    adjust the p value, Missing values will be deleted by na.omit() function 
    before analysis.",2019-12-20,Jing Zhang,https://github.com/yikeshu0611/cutoff,TRUE,https://github.com/yikeshu0611/cutoff,2955,1,2019-12-01T01:22:29Z,2955
cutpointr,"Estimate cutpoints that optimize a specified metric in binary classification tasks
    and validate performance using bootstrapping. Some methods for more robust cutpoint
    estimation and various plotting functions are included.",2020-04-14,Christian Thiele,https://github.com/thie1e/cutpointr,TRUE,https://github.com/thie1e/cutpointr,18228,51,2020-06-03T14:22:02Z,357.4117647058824
cvar,"Compute expected shortfall (ES) and Value at Risk (VaR) from a
    quantile function, distribution function, random number generator or
    probability density function.  ES is also known as Conditional Value at
    Risk (CVaR). Virtually any continuous distribution can be specified.
    The functions are vectorized over the arguments. The computations are
    done directly from the definitions, see e.g. Acerbi and Tasche (2002)
    <doi:10.1111/1468-0300.00091>. Some support for GARCH models is provided,
    as well.",2019-03-15,Georgi N. Boshnakov,https://github.com/GeoBosh/cvar https://geobosh.github.io/cvar/,TRUE,https://github.com/geobosh/cvar,17053,1,2020-03-07T20:58:37Z,17053
cvcqv,"Provides some easy-to-use functions and classes to calculate 
    variability measures such as coefficient of variation with confidence 
    intervals provided with all available methods. References are 
    Panichkitkosolkul (2013) <doi:10.1155/2013/324940> ,
    Altunkaynak & Gamgam (2018) <doi:10.1080/03610918.2018.1435800> ,
    Albatineh, Kibria, Wilcox & Zogheib (2014) <doi:10.1080/02664763.2013.847405> .",2019-08-06,Maani Beigy,https://github.com/MaaniBeigy/cvcqv,TRUE,https://github.com/maanibeigy/cvcqv,4286,6,2019-08-20T23:01:55Z,714.3333333333334
cvequality,"Contains functions for testing for significant differences between multiple coefficients of variation. Includes Feltz and Miller's (1996) <DOI:10.1002/(SICI)1097-0258(19960330)15:6%3C647::AID-SIM184%3E3.0.CO;2-P> asymptotic test and Krishnamoorthy and Lee's (2014) <DOI:10.1007/s00180-013-0445-2> modified signed-likelihood ratio test. See the vignette for more, including full details of citations.",2019-01-07,Ben Marwick,https://github.com/benmarwick/cvequality,TRUE,https://github.com/benmarwick/cvequality,15716,7,2019-11-06T04:50:41Z,2245.1428571428573
cvGEE,"Calculates predictions from generalized estimating equations and internally cross-validates them using the logarithmic, quadratic and spherical proper scoring rules; Kung-Yee Liang and Scott L. Zeger (1986) <doi:10.1093/biomet/73.1.13>.",2019-07-23,Dimitris Rizopoulos,"https://drizopoulos.github.io/cvGEE/,
https://github.com/drizopoulos/cvGEE",TRUE,https://github.com/drizopoulos/cvgee,3908,3,2019-07-30T00:55:30Z,1302.6666666666667
cvms,"Cross-validate one or multiple regression and classification models
    and get relevant evaluation metrics in a tidy format. Validate the
    best model on a test set and compare it to a baseline evaluation.
    Alternatively, evaluate predictions from an external model. Currently
    supports regression and classification (binary and multiclass).
    Described in chp. 5 of Jeyaraman, B. P., Olsen, L. R., 
    & Wambugu M. (2019, ISBN: 9781838550134).",2020-05-29,Ludvig Renbo Olsen,https://github.com/ludvigolsen/cvms,TRUE,https://github.com/ludvigolsen/cvms,6936,19,2020-05-29T12:47:56Z,365.05263157894734
CVXR,"An object-oriented modeling language for disciplined convex
    programming (DCP). It allows the user to formulate convex optimization problems
    in a natural way following mathematical convention and DCP rules. The system
    analyzes the problem, verifies its convexity, converts it into a canonical form,
    and hands it off to an appropriate solver to obtain the solution.",2020-04-02,Anqi Fu,"https://github.com/cvxgrp/CVXR, https://cvxr.rbind.io,
https://www.cvxgrp.org/CVXR/",TRUE,https://github.com/cvxgrp/cvxr,41932,112,2020-04-09T18:11:57Z,374.39285714285717
cwbtools,"The 'Corpus Workbench' ('CWB', <http://cwb.sourceforge.net/>) offers a classic and mature
 approach for working with large, linguistically and structurally annotated corpora. The 'CWB'
 is memory efficient and its design makes running queries fast (Evert and Hardie 2011,
 <http://www.stefan-evert.de/PUB/EvertHardie2011.pdf>). The 'cwbtools' package offers
 pure R tools to create indexed corpus files as well as high-level wrappers for the original C
 implementation of CWB as exposed by the 'RcppCWB' package
 <https://CRAN.R-project.org/package=RcppCWB>. Additional functionality to add and
 modify annotations of corpora from within R makes working with CWB indexed corpora
 much more flexible and convenient. The 'cwbtools' package in combination with the R packages
 'RcppCWB' (<https://CRAN.R-project.org/package=RcppCWB>) and 'polmineR'
 (<https://CRAN.R-project.org/package=polmineR>) offers a lightweight infrastructure
 to support the combination of quantitative and qualitative approaches for working
 with textual data.",2020-04-14,Andreas Blaette,https://www.github.com/PolMine/cwbtools,TRUE,https://github.com/polmine/cwbtools,4029,0,2019-12-10T09:01:43Z,NA
cyanoFilter,"An approach to filter out and/or identify synechococcus type cyanobacteria cells from all particles measured via flow cytometry.
    It combines known characteristics of these cyanobacteria strains alongside gating techniques developed by Mehrnoush, M. et al. (2015) <doi:10.1093/bioinformatics/btu677> 
    in the 'flowDensity' package to identify and separate these cyanobacteria cells from other cell types.
    Aside the gating techniques in the 'flowDensity' package, an EM style clustering technique
    is also developed to identify these cyanobacteria cell populations.",2020-01-09,Oluwafemi Olusoji,https://github.com/fomotis/cyanoFilter,TRUE,https://github.com/fomotis/cyanofilter,3513,1,2020-03-10T21:12:27Z,3513
Cyclops,"This model fitting tool incorporates cyclic coordinate descent and
    majorization-minimization approaches to fit a variety of regression models
    found in large-scale observational healthcare data.  Implementations focus
    on computational optimization and fine-scale parallelization to yield
    efficient inference in massive datasets.  Please see:
    Suchard, Simpson, Zorych, Ryan and Madigan (2013) <doi:10.1145/2414416.2414791>.",2020-06-05,Marc A. Suchard,https://github.com/ohdsi/cyclops,TRUE,https://github.com/ohdsi/cyclops,24043,25,2020-06-08T06:18:06Z,961.72
cyphr,"Encryption wrappers, using low-level support from
    'sodium' and 'openssl'.  'cyphr' tries to smooth over some pain
    points when using encryption within applications and data analysis
    by wrapping around differences in function names and arguments in
    different encryption providing packages.  It also provides
    high-level wrappers for input/output functions for seamlessly
    adding encryption to existing analyses.",2020-03-09,Rich FitzJohn,"https://github.com/ropensci/cyphr, https://docs.ropensci.org/cyphr",TRUE,https://github.com/ropensci/cyphr,9010,81,2020-03-09T15:52:40Z,111.23456790123457
cystiSim,"The cystiSim package provides an agent-based model for Taenia solium transmission and control. cystiSim was developed within the framework of CYSTINET, the European Network on taeniosis/cysticercosis, COST ACTION TD1302.",2016-05-15,Brecht Devleesschauwer,https://github.com/brechtdv/cystiSim,TRUE,https://github.com/brechtdv/cystisim,11417,0,2020-02-26T14:38:11Z,NA
cytofan,"An implementation of Fan plots for cytometry data in 'ggplot2'. 
    For reference see Britton, E.; Fisher, P. & J. Whitley (1998) The Inflation Report Projections: Understanding the Fan Chart 
    <https://www.bankofengland.co.uk/quarterly-bulletin/1998/q1/the-inflation-report-projections-understanding-the-fan-chart>).",2018-07-30,Yann Abraham,https://github.com/yannabraham/cytofan,TRUE,https://github.com/yannabraham/cytofan,7632,2,2019-11-29T11:24:32Z,3816
cytometree,"Given the hypothesis of a bi-modal distribution of cells for
    each marker, the algorithm constructs a binary tree, the nodes of which are
    subpopulations of cells. At each node, observed cells and markers are modeled
    by both a family of normal distributions and a family of bi-modal normal mixture
    distributions. Splitting is done according to a normalized difference of AIC
    between the two families. Method is detailed in: Commenges, Alkhassim, Gottardo, 
    Hejblum & Thiebaut (2018) <doi: 10.1002/cyto.a.23601>. ",2019-12-04,Chariff Alkhassim,NA,TRUE,https://github.com/sistm/cytometree,13953,4,2020-04-06T20:04:28Z,3488.25
cytominer,"Typical morphological profiling datasets have millions of cells
    and hundreds of features per cell. When working with this data, you must
    clean the data, normalize the features to make them comparable across
    experiments, transform the features, select features based on their
    quality, and aggregate the single-cell data, if needed. 'cytominer' makes
    these steps fast and easy. Methods used in practice in the field are
    discussed in Caicedo (2017) <doi:10.1038/nmeth.4397>. An overview of the
    field is presented in Caicedo (2016) <doi:10.1016/j.copbio.2016.04.003>.",2020-05-09,Shantanu Singh,https://github.com/cytomining/cytominer,TRUE,https://github.com/cytomining/cytominer,5911,24,2020-05-09T12:00:49Z,246.29166666666666
czechrates,"
  Interface to interest rates as published by the Czech National Bank. Currently supported are the PRIBOR rates (PRague InterBank Offered Rate - the CZK member of the IBOR family of rates) and two-week repo rate - a key policy rate of CNB.",2020-06-03,Jindra Lacko,https://github.com/jla-data/czechrates,TRUE,https://github.com/jla-data/czechrates,0,0,2020-06-09T17:27:11Z,NA
czso,"Get programmatic access to the open data provided by the
    Czech Statistical Office (CZSO, <https://czso.cz>).",2020-04-07,Petr Bouchal,https://github.com/petrbouchal/czso,TRUE,https://github.com/petrbouchal/czso,1001,6,2020-06-06T11:09:24Z,166.83333333333334
d3r,"Provides a suite of functions to help ease the use of 'd3.js' in R.
              These helpers include 'htmltools::htmlDependency' functions, hierarchy
              builders, and conversion tools for 'partykit', 'igraph,' 'table',
              and 'data.frame' R objects into the 'JSON' that 'd3.js' expects.",2020-05-25,Mike Bostock,https://github.com/timelyportfolio/d3r,TRUE,https://github.com/timelyportfolio/d3r,291339,125,2020-05-25T15:14:51Z,2330.712
d3Tree,"Create and customize interactive collapsible 'D3' trees using the 'D3'
    JavaScript library and the 'htmlwidgets' package. These trees can be used
    directly from the R console, from 'RStudio', in Shiny apps and R Markdown documents.
    When in Shiny the tree layout is observed by the server and can be used as a reactive filter
    of structured data.",2017-06-13,Jonathan Sidi,https://github.com/metrumresearchgroup/d3Tree,TRUE,https://github.com/metrumresearchgroup/d3tree,18250,68,2019-10-14T23:59:03Z,268.38235294117646
dabestr,"Data Analysis using Bootstrap-Coupled ESTimation.
    Estimation statistics is a simple framework that avoids the pitfalls of
    significance testing. It uses familiar statistical concepts: means,
    mean differences, and error bars. More importantly, it focuses on the
    effect size of one's experiment/intervention, as opposed to a false
    dichotomy engendered by P values.
    An estimation plot has two key features:
    1. It presents all datapoints as a swarmplot, which orders each point to
    display the underlying distribution.
    2. It presents the effect size as a bootstrap 95% confidence interval on a
    separate but aligned axes.
    Estimation plots are introduced in Ho et al., Nature Methods 2019, 1548-7105.
    <doi:10.1038/s41592-019-0470-3>.
    The free-to-view PDF is located at <https://rdcu.be/bHhJ4>.",2020-04-20,Joses W. Ho,https://github.com/ACCLAB/dabestr,TRUE,https://github.com/acclab/dabestr,11654,151,2020-04-21T07:58:02Z,77.17880794701986
dagitty,"A port of the web-based software 'DAGitty', available at 
    <http://dagitty.net>, for analyzing structural causal models 
    (also known as directed acyclic graphs or DAGs).
    This package computes covariate adjustment sets for estimating causal
    effects, enumerates instrumental variables, derives testable
    implications (d-separation and vanishing tetrads), generates equivalent
    models, and includes a simple facility for data simulation. ",2016-08-26,Johannes Textor,"http://www.dagitty.net, https://github.com/jtextor/dagitty",TRUE,https://github.com/jtextor/dagitty,61540,115,2020-04-16T14:29:09Z,535.1304347826087
DALEX,"Unverified black box model is the path to the failure. Opaqueness leads to distrust. 
  Distrust leads to ignoration. Ignoration leads to rejection. 
  DALEX package xrays any model and helps to explore and explain its behaviour.
  Machine Learning (ML) models are widely used and have various applications in classification 
  or regression. Models created with boosting, bagging, stacking or similar techniques are often
  used due to their high performance. But such black-box models usually lack of direct interpretability.
  DALEX package contains various methods that help to understand the link between input variables 
  and model output. Implemented methods help to explore model on the level of a single instance 
  as well as a level of the whole dataset.
  All model explainers are model agnostic and can be compared across different models.
  DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration.
  Find more details in (Biecek 2018) <arXiv:1806.08915>.",2020-04-25,Przemyslaw Biecek,"https://ModelOriented.github.io/DALEX/,
https://github.com/ModelOriented/DALEX",TRUE,https://github.com/modeloriented/dalex,58629,571,2020-06-05T09:54:48Z,102.67775831873905
DALEXtra,"Provides wrapper of various machine learning models. 
  In applied machine learning, there 
  is a strong belief that we need to strike a balance 
  between interpretability and accuracy. 
  However, in field of the interpretable machine learning, 
  there are more and more new ideas for explaining black-box models, 
  that are implemented in 'R'. 
  'DALEXtra' creates 'DALEX' Biecek (2018) <arXiv:1806.08915> explainer for many type of models
  including those created using 'python' 'scikit-learn' and 'keras' libraries, 'java' 'h2o' library and
  'mljar' API. Important part of the package is Champion-Challenger analysis and innovative approach
  to model performance across subsets of test data presented in Funnel Plot. 
  Third branch of 'DALEXtra' package is aspect importance analysis
  that provides instance-level explanations for the groups of explanatory variables.",2020-03-29,Szymon Maksymiuk,"https://ModelOriented.github.io/DALEXtra/,
https://github.com/ModelOriented/DALEXtra",TRUE,https://github.com/modeloriented/dalextra,4800,23,2020-05-29T17:17:52Z,208.69565217391303
damr,"Loads behavioural data from the widely used Drosophila Activity Monitor System (DAMS, TriKinetics <https://trikinetics.com/>) into the rethomics framework.",2019-07-15,Quentin Geissmann,https://github.com/rethomics/damr,TRUE,https://github.com/rethomics/damr,9533,2,2020-06-09T01:43:49Z,4766.5
dams,"The single largest source of dams in the United States is the
    National Inventory of Dams (NID) <http://nid.usace.army.mil> from the US
    Army Corps of Engineers. Entire data from the NID cannot be obtained all at
    once and NID's website limits extraction of more than a couple of thousand
    records at a time. Moreover, selected data from the NID's user interface
    cannot not be saved to a file. In order to make the analysis of this data
    easier, all the data from NID was extracted manually. Subsequently, the raw
    data was checked for potential errors and cleaned. This package provides
    sample cleaned data from the NID and provides functionality to access the
    entire cleaned NID data.",2020-05-20,Joseph Stachelek,https://github.com/jsta/dams,TRUE,https://github.com/jsta/dams,17452,5,2020-05-20T17:43:35Z,3490.4
DAP,An implementation of Discriminant Analysis via Projections (DAP) method for high-dimensional binary classification in the case of unequal covariance matrices. See Irina Gaynanova and Tianying Wang (2018) <arXiv:1711.04817v2>.,2018-03-05,Tianying Wang and Irina Gaynanova,http://github.com/irinagain/DAP,TRUE,https://github.com/irinagain/dap,8185,1,2019-08-28T21:36:06Z,8185
dapr,"An easy-to-use, dependency-free set of functions for iterating over
    elements of various input objects. Functions are wrappers around base
    apply()/lapply()/vapply() functions but designed to have similar
    functionality to the mapping functions in the 'purrr' package
    <https://purrr.tidyverse.org/>. Specifically, function names more explicitly
    communicate the expected class of the output and functions also allow for
    the convenient shortcut of '~ .x' instead of the more verbose
    'function(.x) .x'.",2019-05-06,Michael W. Kearney,https://github.com/mkearney/dapr,TRUE,https://github.com/mkearney/dapr,11772,53,2019-06-28T18:49:27Z,222.11320754716982
darksky,"Provides programmatic access to the 'Dark Sky' 'API' 
    <https://darksky.net/dev/docs>, which provides current or historical global 
    weather conditions.",2017-09-20,Bob Rudis,https://github.com/hrbrmstr/darksky,TRUE,https://github.com/hrbrmstr/darksky,17841,78,2020-04-04T11:37:15Z,228.73076923076923
dash,"A framework for building analytical web applications, 'dash' offers a pleasant and productive development experience. No JavaScript required.",2020-06-04,Ryan Patrick Kyle,https://github.com/plotly/dashR,TRUE,https://github.com/plotly/dashr,0,298,2020-06-04T15:04:43Z,0
dashCoreComponents,"'Dash' ships with supercharged components for interactive user interfaces. A core set of components, written and maintained by the 'Dash' team, is available in the 'dashCoreComponents' package. The source for this package is on GitHub: plotly/dash-core-components.",2020-05-06,Ryan Patrick Kyle,https://github.com/plotly/dash-core-components,TRUE,https://github.com/plotly/dash-core-components,823,201,2020-06-02T21:16:00Z,4.0945273631840795
dashHtmlComponents,"'Dash' is a web application framework that provides pure Python and R abstraction around HTML, CSS, and JavaScript. Instead of writing HTML or using an HTML templating engine, you compose your layout using R functions within the 'dashHtmlComponents' package. The source for this package is on GitHub: plotly/dash-html-components.",2020-05-06,Ryan Patrick Kyle,https://github.com/plotly/dash-html-components,TRUE,https://github.com/plotly/dash-html-components,813,112,2020-06-02T19:02:43Z,7.258928571428571
dashTable,"An interactive table component designed for editing and exploring large datasets, 'dashDataTable' is rendered with standard, semantic HTML <table/> markup, which makes it accessible, responsive, and easy to style. This component was written from scratch in 'React.js' specifically for the 'dash' community. Its API was designed to be ergonomic and its behaviour is completely customizable through its  properties.",2020-05-14,Ryan Patrick Kyle,https://github.com/plotly/dash-table,TRUE,https://github.com/plotly/dash-table,504,322,2020-06-02T21:20:20Z,1.565217391304348
dat,"An implementation of common higher order functions with syntactic
    sugar for anonymous function. Provides also a link to 'dplyr' and
    'data.table' for common transformations on data frames to work around non
    standard evaluation by default.",2020-05-15,Sebastian Warnholz,NA,TRUE,https://github.com/wahani/dat,19217,13,2020-05-16T06:33:48Z,1478.2307692307693
data.table,"Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.",2019-12-09,Matt Dowle,"http://r-datatable.com, https://Rdatatable.gitlab.io/data.table,
https://github.com/Rdatatable/data.table",TRUE,https://github.com/rdatatable/data.table,17954368,2375,2020-06-09T06:46:06Z,7559.733894736843
data.tree,"Create tree structures from hierarchical data, and traverse the
    tree in various orders. Aggregate, cumulate, print, plot, convert to and from
    data.frame and more. Useful for decision trees, machine learning, finance,
    conversion from and to JSON, and many other applications.",2019-11-09,Russ Hyde [ctb,http://github.com/gluc/data.tree,TRUE,https://github.com/gluc/data.tree,570369,152,2019-11-09T08:11:39Z,3752.4276315789475
data360r,"Makes it easy to engage with the Application Program Interface (API)
    of the 'TCdata360' and 'Govdata360' platforms at <https://tcdata360.worldbank.org/>
    and <https://govdata360.worldbank.org/>, respectively.
    These application program interfaces provide access to over 5000 trade, competitiveness, and governance
    indicator data, metadata, and related information from sources
    both inside and outside the World Bank Group.
    Package functions include easier download of data sets, metadata, and
    related information, as well as searching based on user-inputted query.",2020-04-30,Ramin Aliyev,https://github.com/mrpsonglao/data360r,TRUE,https://github.com/mrpsonglao/data360r,5531,21,2020-04-29T13:15:51Z,263.3809523809524
DatabaseConnector,"An R 'DataBase Interface' ('DBI') compatible interface to various database platforms ('PostgreSQL', 'Oracle', 'Microsoft SQL Server', 
    'Amazon Redshift', 'Microsoft Parallel Database Warehouse', 'IBM Netezza', 'Apache Impala', 'Google BigQuery', and 'SQLite'). Also includes support for
    fetching data as 'Andromeda' objects. Uses 'Java Database Connectivity' ('JDBC') to connect to databases (except SQLite).",2020-06-06,Martijn Schuemie,"https://ohdsi.github.io/DatabaseConnector,
https://github.com/OHDSI/DatabaseConnector",TRUE,https://github.com/ohdsi/databaseconnector,21654,25,2020-06-05T08:48:02Z,866.16
DatabionicSwarm,"Algorithms implementing populations of agents that interact with one another and sense their environment may exhibit emergent behavior such as self-organization and swarm intelligence. Here, a swarm system called Databionic swarm (DBS) is introduced which was published in Thrun, M.C., Ultsch A.: ""Swarm Intelligence for Self-Organized Clustering"" (2020), Artificial Intelligence, <DOI:10.1016/j.artint.2020.103237>. DBS is able to adapt itself to structures of high-dimensional data such as natural clusters characterized by distance and/or density based structures in the data space. The first module is the parameter-free projection method called Pswarm (Pswarm()), which exploits the concepts of self-organization and emergence, game theory, swarm intelligence and symmetry considerations. The second module is the parameter-free high-dimensional data visualization technique, which generates projected points on the topographic map with hypsometric tints defined by the generalized U-matrix (GeneratePswarmVisualization()). The third module is the clustering method itself with non-critical parameters (DBSclustering()). Clustering can be verified by the visualization and vice versa. The term DBS refers to the method as a whole. It enables even a non-professional in the field of data mining to apply its algorithms for visualization and/or clustering to data sets with completely different structures drawn from diverse research fields. The comparison to common projection methods can be found in the book of Thrun, M.C.: ""Projection Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <DOI:10.1007/978-3-658-20540-9>. A comparison to 26 common clustering algorithms on 15 datasets is presented on the website.",2020-02-03,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/databionicswarm,17396,5,2020-05-05T07:33:59Z,3479.2
dataCompareR,"Easy comparison of two tabular data
    objects in R. Specifically designed to show differences between two sets of
    data in a useful way that should make it easier to understand the differences,
    and if necessary, help you work out how to remedy them. Aims
    to offer a more useful output than all.equal() when your two data sets do not
    match, but isn't intended to replace all.equal() as a way to test for equality.",2020-04-30,Sarah Johnston,https://github.com/capitalone/dataCompareR,TRUE,https://github.com/capitalone/datacomparer,16923,54,2020-04-28T08:25:28Z,313.3888888888889
DataExplorer,"Automated data exploration process for analytic tasks and predictive modeling, so
    that users could focus on understanding data and extracting insights. The package scans and
    analyzes each variable, and visualizes them with typical graphical techniques. Common
    data processing methods are also available to treat and format data.",2020-01-07,Boxuan Cui,http://boxuancui.github.io/DataExplorer/,TRUE,https://github.com/boxuancui/dataexplorer,174372,304,2020-01-10T15:22:14Z,573.5921052631579
datafsm,"Automatic generation of finite state machine models of dynamic 
    decision-making that both have strong predictive power and are 
    interpretable in human terms. We use an efficient model representation and 
    a genetic algorithm-based estimation process to generate simple 
    deterministic approximations that explain most of the structure of complex 
    stochastic processes. We have applied the software to empirical data, and 
    demonstrated it's ability to recover known data-generating processes by 
    simulating data with agent-based models and correctly deriving the 
    underlying decision models for multiple agent models and degrees of
    stochasticity.",2019-11-28,Gilligan Jonathan M.,https://github.com/jonathan-g/datafsm,TRUE,https://github.com/jonathan-g/datafsm,17648,8,2019-12-05T06:40:52Z,2206
dataMaid,"Data screening is an important first step of any statistical
    analysis. dataMaid auto generates a customizable data report with a thorough
    summary of the checks and the results that a human can use to identify possible
    errors. It provides an extendable suite of test for common potential
    errors in a dataset. ",2019-12-10,Claus Thorn Ekstrøm,"https://github.com/ekstroem/dataMaid,
https://doi.org/10.18637/jss.v090.i06",TRUE,https://github.com/ekstroem/datamaid,41306,101,2020-03-06T00:47:32Z,408.970297029703
dataMeta,Designed to create a basic data dictionary and append to the original dataset's attributes list. The package makes use of a tidy dataset and creates a data frame that will serve as a linker that will aid in building the dictionary. The dictionary is then appended to the list of the original dataset's attributes. The user will have the option of entering variable and item descriptions by writing code or use alternate functions that will prompt the user to add these.,2017-08-12,Dania M. Rodriguez,https://github.com/dmrodz/dataMeta,TRUE,https://github.com/dmrodz/datameta,12634,14,2019-06-16T23:24:03Z,902.4285714285714
dataone,"Provides read and write access to data and metadata from
    the DataONE network <https://www.dataone.org> of data repositories.  
    Each DataONE repository implements a consistent repository application 
    programming interface. Users call methods in R to access these remote 
    repository functions, such as methods to query the metadata catalog, get 
    access to metadata for particular data packages, and read the data objects 
    from the data repository. Users can also insert and update data objects on 
    repositories that support these methods.",2020-02-16,Matthew B. Jones,https://github.com/DataONEorg/rdataone,TRUE,https://github.com/dataoneorg/rdataone,25794,25,2020-06-09T22:15:35Z,1031.76
datapack,"Provides a flexible container to transport and manipulate complex
    sets of data. These data may consist of multiple data files and associated
    meta data and ancillary files. Individual data objects have associated system
    level meta data, and data files are linked together using the OAI-ORE standard
    resource map which describes the relationships between the files. The OAI-
    ORE standard is described at <https://www.openarchives.org/ore>. Data packages
    can be serialized and transported as structured files that have been created
    following the BagIt specification. The BagIt specification is described at
    <https://tools.ietf.org/html/draft-kunze-bagit-08>.",2019-10-15,Matthew B. Jones,NA,TRUE,https://github.com/ropensci/datapack,25343,36,2019-12-09T09:29:38Z,703.9722222222222
datapackage.r,"Work with 'Frictionless Data Packages' (<https://frictionlessdata.io/specs/data-package/>). Allows to load and validate any descriptor for a data package profile, create and modify descriptors and provides expose methods for reading and streaming data in the package. When a descriptor is a 'Tabular Data Package', it uses the 'Table Schema' package (<https://CRAN.R-project.org/package=tableschema.r>) and exposes its functionality, for each resource object in the resources field.",2020-05-06,Kleanthis Koupidis,https://github.com/frictionlessdata/datapackage-r,TRUE,https://github.com/frictionlessdata/datapackage-r,5906,23,2020-05-06T17:07:04Z,256.7826086956522
datapasta,RStudio addins and R functions that make copy-pasting vectors and tables to text painless.,2020-01-17,Miles McBain,https://github.com/milesmcbain/datapasta,TRUE,https://github.com/milesmcbain/datapasta,45927,611,2020-01-17T12:03:17Z,75.16693944353518
dataPreparation,Do most of the painful data preparation for a data science project with a minimum amount of code; Take advantages of data.table efficiency and use some algorithmic trick in order to perform data preparation in a time and RAM efficient way.,2020-02-12,Emmanuel-Lin Toulemonde,NA,TRUE,https://github.com/eltoulemonde/datapreparation,42851,23,2020-02-12T13:56:55Z,1863.0869565217392
dataRetrieval,"Collection of functions to help retrieve U.S. Geological Survey
    (USGS) and U.S. Environmental Protection Agency (EPA) water quality and
    hydrology data from web services. USGS web services are discovered from 
    National Water Information System (NWIS) <https://waterservices.usgs.gov/> and <https://waterdata.usgs.gov/nwis>. 
    Both EPA and USGS water quality data are obtained from the Water Quality Portal <https://www.waterqualitydata.us/>.",2020-03-11,Laura DeCicco,https://pubs.usgs.gov/tm/04/a10/,TRUE,https://github.com/usgs-r/dataretrieval,71924,148,2020-05-11T13:06:36Z,485.97297297297297
datarium,"Contains data organized by topics: categorical data, regression model, 
            means comparisons, independent and repeated measures ANOVA, mixed ANOVA and ANCOVA.",2019-05-21,Alboukadel Kassambara,NA,TRUE,https://github.com/kassambara/datarium,20108,5,2020-04-28T11:15:06Z,4021.6
datasauRus,"The Datasaurus Dozen is a set of datasets with the same summary statistics. They 
             retain the same summary statistics despite having radically different distributions.
             The datasets represent a larger and quirkier object lesson that is typically taught
             via Anscombe's Quartet (available in the 'datasets' package). Anscombe's Quartet
             contains four very different distributions with the same summary statistics and as 
             such highlights the value of visualisation in understanding data, over and above
             summary statistics. As well as being an engaging variant on the Quartet, the data
             is generated in a novel way. The simulated annealing process used to derive datasets 
             from the original Datasaurus is detailed in ""Same Stats, Different Graphs: Generating 
             Datasets with Varied Appearance and Identical Statistics through Simulated Annealing"" 
             <doi:10.1145/3025453.3025912>.",2018-09-20,Steph Locke,"https://github.com/lockedata/datasauRus,
https://itsalocke.com/datasaurus/",TRUE,https://github.com/lockedata/datasaurus,27533,177,2020-01-27T15:39:44Z,155.5536723163842
DataSpaceR,"Provides a convenient API interface to access immunological data
    within 'the CAVD DataSpace'(<https://dataspace.cavd.org>), a data sharing 
    and discovery tool that facilitates exploration of HIV immunological data 
    from pre-clinical and clinical HIV vaccine studies.",2020-01-08,Ju Yeong Kim,"https://docs.ropensci.org/DataSpaceR,
https://github.com/ropensci/DataSpaceR",TRUE,https://github.com/ropensci/dataspacer,5783,5,2020-05-29T21:16:26Z,1156.6
dataverse,"Provides access to Dataverse version 4 APIs <https://dataverse.org/>, 
    enabling data search, retrieval, and deposit. For Dataverse versions <= 4.0, 
    use the deprecated 'dvn' package <https://cran.r-project.org/package=dvn>.",2017-06-15,Thomas J. Leeper,https://github.com/iqss/dataverse-client-r,TRUE,https://github.com/iqss/dataverse-client-r,12236,29,2020-05-29T18:16:09Z,421.9310344827586
DataVisualizations,"Gives access to data visualisation methods that are relevant from the data scientist's point of view. The flagship idea of 'DataVisualizations' is the mirrored density plot (MD-plot) for either classified or non-classified multivariate data presented in Thrun et al. (2019) <arXiv:1908.06081>. The MD-plot outperforms the box-and-whisker diagram (box plot), violin plot and bean plot. Furthermore, a collection of various visualization methods for univariate data is provided. In the case of exploratory data analysis, 'DataVisualizations' makes it possible to inspect the distribution of each feature of a dataset visually through a combination of four methods. One of these methods is the Pareto density estimation (PDE) of the probability density function (pdf). Additionally, visualizations of the distribution of distances using PDE, the scatter-density plot using PDE for two variables as well as the Shepard density plot and the Bland-Altman plot are presented here. Pertaining to classified high-dimensional data, a number of visualizations are described, such as f.ex. the heat map and silhouette plot. A political map of the world or Germany can be visualized with the additional information defined by a classification of countries or regions. By extending the political map further, an uncomplicated function for a Choropleth map can be used which is useful for measurements across a geographic area. For categorical features, the Pie charts, slope charts and fan plots, improved by the ABC analysis, become usable. More detailed explanations are found in the book by Thrun, M.C.: ""Projection-Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <doi:10.1007/978-3-658-20540-9>.",2020-05-17,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/datavisualizations,18307,3,2020-06-07T14:44:49Z,6102.333333333333
daterangepicker,"A Shiny Input for date-ranges, which pops up two calendars for selecting dates, times, or predefined ranges like ""Last 30 Days"". It wraps the JavaScript library 'daterangepicker' which is available at <https://www.daterangepicker.com>.",2020-03-20,Sebastian Gatscha,"https://github.com/trafficonese/daterangepicker/,
https://www.daterangepicker.com",TRUE,https://github.com/trafficonese/daterangepicker,1395,7,2020-03-27T14:25:39Z,199.28571428571428
datetimeutils,"Utilities for handling dates and times, such
   as selecting particular days of the week or month,
   formatting timestamps as required by RSS feeds, or
   converting timestamp representations of other software
   (such as 'MATLAB' and 'Excel') to R. The package is
   lightweight (no dependencies, pure R implementations) and
   relies only on R's standard classes to represent dates
   and times ('Date' and 'POSIXt'); it aims to provide
   efficient implementations, through vectorisation and the
   use of R's native numeric representations of timestamps
   where possible.",2020-03-25,Enrico Schumann,"http://enricoschumann.net/R/packages/datetimeutils/,
https://github.com/enricoschumann/datetimeutils",TRUE,https://github.com/enricoschumann/datetimeutils,15502,0,2020-03-25T19:21:16Z,NA
datoramar,"A thin wrapper around the 'Datorama' API.
    Ideal for analyzing marketing data from <https://datorama.com>.",2017-12-20,Kade Killary,https://github.com/beigebrucewayne/datoramar,TRUE,https://github.com/beigebrucewayne/datoramar,9074,5,2019-06-28T09:03:53Z,1814.8
datr,"Interface with the 'Dat' p2p network protocol <https://datproject.org>. Clone archives from the network, share your own files, and install packages from the network.",2018-03-26,Chris Hartgerink,https://github.com/libscie/datr,TRUE,https://github.com/libscie/datr,8105,53,2019-12-09T12:49:35Z,152.9245283018868
datrProfile,"Profiles datasets (collecting statistics and informative summaries 
    about that data) on data frames and 'ODBC' tables: maximum, minimum, mean, standard deviation, nulls,
    distinct values, data patterns, data/format frequencies.",2019-08-02,Arnaldo Vitaliano,https://github.com/avitaliano/datrProfile,TRUE,https://github.com/avitaliano/datrprofile,3781,0,2019-07-31T12:48:39Z,NA
daymetr,"Programmatic interface to the 'Daymet' web services
    (<http://daymet.ornl.gov>). Allows for easy downloads of
    'Daymet' climate data directly to your R workspace or your computer.
    Routines for both single pixel data downloads and
    gridded (netCDF) data are provided.",2019-02-07,Hufkens Koen,https://github.com/khufkens/daymetr,TRUE,https://github.com/khufkens/daymetr,13012,8,2020-06-02T18:10:43Z,1626.5
dbarts,"Fits Bayesian additive regression trees (BART; Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>) while allowing the updating of predictors or response so that BART can be incorporated as a conditional model in a Gibbs/Metropolis-Hastings sampler. Also serves as a drop-in replacement for package 'BayesTree'.",2020-03-20,Vincent Dorie,https://github.com/vdorie/dbarts,TRUE,https://github.com/vdorie/dbarts,37937,33,2020-03-27T21:59:22Z,1149.6060606060605
dbflobr,"Reads and writes files to SQLite databases <https://www.sqlite.org/index.html> as flobs 
    (a flob is a blob that preserves the file extension).",2020-05-13,Sebastian Dalgarno,https://github.com/poissonconsulting/dbflobr,TRUE,https://github.com/poissonconsulting/dbflobr,4252,4,2020-05-27T16:30:28Z,1063
DBI,"A database interface definition for communication
    between R and relational database management systems.  All classes in
    this package are virtual and need to be extended by the various R/DBMS
    implementations.",2019-12-15,Kirill Müller,"http://r-dbi.github.io/DBI, https://github.com/r-dbi/DBI",TRUE,https://github.com/r-dbi/dbi,12689394,192,2020-02-23T21:43:51Z,66090.59375
DBItest,"A helper that tests 'DBI' back ends for conformity
    to the interface.",2019-12-16,Kirill Müller,"https://dbitest.r-dbi.org, https://github.com/r-dbi/DBItest",TRUE,https://github.com/r-dbi/dbitest,201694,14,2019-12-30T12:11:55Z,14406.714285714286
dbmss,"Simple computation of spatial statistic functions of distance to characterize the spatial structures of mapped objects, following Marcon, Traissac, Puech, and Lang (2015) <doi:10.18637/jss.v067.c03>.
             Includes classical functions (Ripley's K and others) and more recent ones used by spatial economists (Duranton and Overman's Kd, Marcon and Puech's M). 
             Relies on 'spatstat' for some core calculation.",2020-01-08,Eric Marcon,https://github.com/EricMarcon/dbmss,TRUE,https://github.com/ericmarcon/dbmss,38844,2,2020-04-18T21:13:38Z,19422
dbnR,"Learning and inference over dynamic Bayesian networks of arbitrary 
    Markovian order.  Extends some of the functionality offered by the 'bnlearn' 
    package to learn the networks from data and perform exact inference. 
    It offers a modification of Trabelsi (2013) <doi:10.1007/978-3-642-41398-8_34> 
    dynamic max-min hill climbing algorithm for structure learning and 
    the possibility to perform forecasts of arbitrary length. A tool for 
    visualizing the structure of the net is also provided via the 'visNetwork' package.",2020-03-25,David Quesada,https://github.com/dkesada/dbnR,TRUE,https://github.com/dkesada/dbnr,1298,0,2020-06-04T13:31:50Z,NA
dbparser,"This tool is for parsing the 'DrugBank' XML database <http://drugbank.ca/>. The parsed 
    data are then returned in a proper 'R' dataframe with the ability to save 
    them in a given database.",2020-06-08,Mohammed Ali,"https://docs.ropensci.org/dbparser,
https://github.com/ropensci/dbparser",TRUE,https://github.com/ropensci/dbparser,9591,19,2020-06-09T04:58:35Z,504.7894736842105
dbplot,"Leverages 'dplyr' to process the calculations of a plot inside a database. 
    This package provides helper functions that abstract the work at three levels:
    outputs a 'ggplot', outputs the calculations, outputs the formula
    needed to calculate bins.",2020-02-07,Edgar Ruiz,https://github.com/edgararuiz/dbplot,TRUE,https://github.com/edgararuiz/dbplot,40463,116,2020-02-06T21:31:14Z,348.8189655172414
dbplyr,"A 'dplyr' back end for databases that allows you to
    work with remote database tables as if they are in-memory data frames.
    Basic features works with any database that has a 'DBI' back end; more
    advanced features require 'SQL' translation to be provided by the
    package author.",2020-05-27,Hadley Wickham,"https://dbplyr.tidyverse.org/, https://github.com/tidyverse/dbplyr",TRUE,https://github.com/tidyverse/dbplyr,7558796,235,2020-05-27T12:10:57Z,32165.08936170213
dbscan,"A fast reimplementation of several density-based algorithms of
    the DBSCAN family for spatial data. Includes the DBSCAN (density-based spatial
    clustering of applications with noise) and OPTICS (ordering points to identify
    the clustering structure) clustering algorithms HDBSCAN (hierarchical DBSCAN) and the LOF (local outlier
    factor) algorithm. The implementations use the kd-tree data structure (from
    library ANN) for faster k-nearest neighbor search. An R interface to fast kNN
    and fixed-radius NN search is also provided. 
    See Hahsler M, Piekenbrock M and Doran D (2019) <doi:10.18637/jss.v091.i01>.",2019-10-23,Michael Hahsler,https://github.com/mhahsler/dbscan,TRUE,https://github.com/mhahsler/dbscan,450785,141,2020-05-18T16:22:56Z,3197.0567375886526
dbx,"Provides select, insert, update, upsert, and delete database operations. Supports 'PostgreSQL', 'MySQL', 'SQLite', and more, and plays nicely with the 'DBI' package.",2019-04-24,Andrew Kane,https://github.com/ankane/dbx,TRUE,https://github.com/ankane/dbx,15313,139,2020-02-17T03:02:29Z,110.16546762589928
dccvalidator,"Performs checks for common metadata quality issues. Used by the
    data coordinating centers for the 'AMP-AD' consortium
    (<https://adknowledgeportal.synapse.org>), 'PsychENCODE' consortium
    (<http://www.psychencode.org>), and others to validate metadata prior to
    data releases.",2020-03-13,Nicole Kauer,"https://sage-bionetworks.github.io/dccvalidator,
https://github.com/Sage-Bionetworks/dccvalidator",TRUE,https://github.com/sage-bionetworks/dccvalidator,2601,3,2020-06-02T22:31:08Z,867
dclust,"Contains a single function dclust() for divisive hierarchical clustering based on 
    recursive k-means partitioning (k = 2). Useful for clustering large datasets
    where computation of a n x n distance matrix is not feasible (e.g. n > 10,000 records).
    For further information see Steinbach, Karypis and Kumar (2000) <http://glaros.dtc.umn.edu/gkhome/fetch/papers/docclusterKDDTMW00.pdf>.",2019-09-05,Shaun Wilkinson,http://github.com/shaunpwilkinson/dclust,TRUE,https://github.com/shaunpwilkinson/dclust,3825,1,2019-08-28T23:46:59Z,3825
dde,"Solves ordinary and delay differential equations, where
    the objective function is written in either R or C.  Suitable only
    for non-stiff equations, the solver uses a 'Dormand-Prince' method
    that allows interpolation of the solution at any point.  This
    approach is as described by Hairer, Norsett and Wanner (1993)
    <ISBN:3540604529>.  Support is also included for iterating
    difference equations.",2020-01-16,Rich FitzJohn,https://github.com/mrc-ide/dde,TRUE,https://github.com/mrc-ide/dde,6257,13,2020-03-27T13:14:36Z,481.3076923076923
ddi,"Implements Meng's data defect index (ddi), which represents
    the degree of sample bias relative to an iid sample. The data defect 
    correlation (ddc) represents the correlation between the outcome of interest
    and the selection into the sample; when the sample selection is independent
    across the population, the ddc is zero. Details are in Meng (2018) 
    <doi:10.1214/18-AOAS1161SF>, ""Statistical Paradises and Paradoxes in Big Data (I): 
    Law of Large Populations, Big Data Paradox, and the 2016 US Presidential 
    Election."" Survey estimates from the Cooperative Congressional Election Study 
    (CCES) is included to replicate the article's results. ",2020-01-26,Shiro Kuriwaki,https://github.com/kuriwaki/ddi,TRUE,https://github.com/kuriwaki/ddi,2088,2,2020-05-09T01:04:05Z,1044
ddpcr,"An interface to explore, analyze, and visualize droplet digital PCR
    (ddPCR) data in R. This is the first non-proprietary software for analyzing
    two-channel ddPCR data. An interactive tool was also created and is available
    online to facilitate this analysis for anyone who is not comfortable with
    using R.",2020-06-02,Dean Attali,https://github.com/daattali/ddpcr,TRUE,https://github.com/daattali/ddpcr,22722,42,2020-06-09T04:10:18Z,541
deBInfer,"A Bayesian framework for parameter inference in differential equations.
    This approach offers a rigorous methodology for parameter inference as well as
    modeling the link between unobservable model states and parameters, and
    observable quantities. Provides templates for the DE model, the
    observation model and data likelihood, and the model parameters and their prior
    distributions. A Markov chain Monte Carlo (MCMC) procedure processes these inputs
    to estimate the posterior distributions of the parameters and any derived
    quantities, including the model trajectories. Further functionality is provided
    to facilitate MCMC diagnostics and the visualisation of the posterior distributions
    of model parameters and trajectories.",2018-04-18,Philipp H Boersch-Supan,https://github.com/pboesu/debinfer,TRUE,https://github.com/pboesu/debinfer,14780,8,2020-03-02T14:48:00Z,1847.5
DeCAFS,"Detect abrupt changes in time series with local fluctuations as a random walk process and autocorrelated noise as an AR(1) process. See Romano, G., Rigaill, G., Runge, V., Fearnhead, P. (2020) <arXiv:2005.01379>.",2020-05-18,Gaetano Romano,NA,TRUE,https://github.com/gtromano/decafs,552,0,2020-05-12T19:55:03Z,NA
decido,"Provides constrained triangulation of polygons. Ear cutting (or 
 ear clipping) applies constrained triangulation by successively 'cutting'
 triangles from a polygon defined by path/s. Holes are supported by introducing
 a bridge segment between polygon paths. This package wraps the 'header-only' 
 library 'earcut.hpp' <https://github.com/mapbox/earcut.hpp.git> which includes
 a reference to the method used by Held, M. (2001) <doi:10.1007/s00453-001-0028-4>. ",2020-05-19,Michael Sumner,https://hypertidy.github.io/decido,TRUE,https://github.com/hypertidy/decido,13155,13,2020-05-21T21:59:12Z,1011.9230769230769
deckgl,"Makes 'deck.gl' <https://deck.gl/>, a WebGL-powered open-source JavaScript framework
  for visual exploratory data analysis of large datasets, available within R via the 'htmlwidgets' package.
  Furthermore, it supports basemaps from 'mapbox' <https://www.mapbox.com/> via
  'mapbox-gl-js' <https://github.com/mapbox/mapbox-gl-js>.",2020-05-06,Stefan Kuethe,"https://github.com/crazycapivara/deckgl/,
https://crazycapivara.github.io/deckgl/",TRUE,https://github.com/crazycapivara/deckgl,7145,53,2020-05-27T16:06:08Z,134.81132075471697
DeclareDesign,"Researchers can characterize and learn about the properties of
    research designs before implementation using `DeclareDesign`. Ex ante
    declaration and diagnosis of designs can help researchers clarify the 
    strengths and limitations of their designs and to improve their 
    properties, and can help readers evaluate a research strategy prior
    to implementation and without access to results. It can also make it
    easier for designs to be shared, replicated, and critiqued.",2020-03-24,Graeme Blair,"https://declaredesign.org,
https://github.com/DeclareDesign/DeclareDesign",TRUE,https://github.com/declaredesign/declaredesign,15599,75,2020-04-30T17:26:46Z,207.98666666666668
decompr,"Two global-value-chain decompositions are implemented. Firstly, the
    Wang-Wei-Zhu (Wang, Wei, and Zhu, 2013) algorithm splits bilateral gross exports
    into 16 value-added components. Secondly, the Leontief decomposition (default)
    derives the value added origin of exports by country and industry, which is also
    based on Wang, Wei, and Zhu (Wang, Z., S.-J. Wei, and K. Zhu. 2013. ""Quantifying
    International Production Sharing at the Bilateral and Sector Levels."").",2016-08-17,Bastiaan Quast,"http://qua.st/decompr, https://github.com/bquast/decompr",TRUE,https://github.com/bquast/decompr,28017,6,2020-04-26T07:21:35Z,4669.5
deconstructSigs,"Takes sample information in the form of the fraction of mutations
    in each of 96 trinucleotide contexts and identifies the weighted combination
    of published signatures that, when summed, most closely reconstructs the
    mutational profile.",2016-07-29,Rachel Rosenthal,https://github.com/raerose01/deconstructSigs,TRUE,https://github.com/raerose01/deconstructsigs,20999,83,2020-03-12T12:06:01Z,253
deductive,"Attempt to repair inconsistencies and missing values in data 
    records by using information from valid values and validation rules 
    restricting the data.",2019-04-10,Mark van der Loo,https://github.com/data-cleaning/deductive,TRUE,https://github.com/data-cleaning/deductive,16054,8,2019-06-25T13:11:26Z,2006.75
deepdep,"Provides tools for exploration of R package dependencies. 
    The main deepdep() function allows to acquire deep dependencies of any package and plot them in an elegant way.
    It also adds some popularity measures for the packages e.g. in the form of download count through the 'cranlogs' package. 
    Uses the CRAN metadata database <http://crandb.r-pkg.org> and Bioconductor metadata <http://bioconductor.org>.
    Other data acquire functions are: get_dependencies(), get_downloads() and get_description(). 
    The deepdep_shiny() function runs shiny application that helps to produce a nice 'deepdep' plot. ",2020-05-06,Dominik Rafacz,"https://dominikrafacz.github.io/deepdep/,
https://github.com/DominikRafacz/deepdep",TRUE,https://github.com/dominikrafacz/deepdep,1922,20,2020-05-06T13:19:48Z,96.1
Delaporte,"Provides probability mass, distribution, quantile, random-variate generation, and method-of-moments parameter-estimation functions for the Delaporte distribution. The Delaporte is a discrete probability distribution which can be considered the convolution of a negative binomial distribution with a Poisson distribution. Alternatively, it can be considered a counting distribution with both Poisson and negative binomial components. It has been studied in actuarial science as a frequency distribution which has more variability than the Poisson, but less than the negative binomial.",2020-06-01,Avraham Adler,https://github.com/aadler/Delaporte,TRUE,https://github.com/aadler/delaporte,54141,0,2020-06-01T07:19:10Z,NA
delayed,"Mechanisms to parallelize dependent tasks in a manner that
    optimizes the compute resources available. It provides access to ""delayed""
    computations, which may be parallelized using futures. It is, to an extent,
    a facsimile of the 'Dask' library (<https://dask.org/>), for the 'Python'
    language.",2020-02-28,Jeremy Coyle,https://tlverse.org/delayed,TRUE,https://github.com/tlverse/delayed,1989,11,2020-02-29T20:24:59Z,180.8181818181818
DemoDecomp,"Two general demographic decomposition methods are offered: Pseudo-continuous decomposition proposed by Horiuchi, Wilmoth, and Pletcher (2008) <doi:10.1353/dem.0.0033> and stepwise replacement decomposition proposed by Andreev, Shkolnikov and Begun (2002) <doi:10.4054/DemRes.2002.7.14>.",2018-08-14,Tim Riffe,NA,TRUE,https://github.com/timriffe/demodecomp,7435,0,2020-01-02T10:39:42Z,NA
DemografixeR,"Connects to the <https://genderize.io/>, <https://agify.io/> and <https://nationalize.io/> APIs to estimate gender, age and nationality of a first name.",2020-05-06,Matthias Brenninkmeijer,"https://matbmeijer.github.io/DemografixeR,
https://github.com/matbmeijer/DemografixeR",TRUE,https://github.com/matbmeijer/demografixer,723,2,2020-05-14T11:11:15Z,361.5
dendextend,"Offers a set of functions for extending
    'dendrogram' objects in R, letting you visualize and compare trees of
    'hierarchical clusterings'. You can (1) Adjust a tree's graphical parameters
    - the color, size, type, etc of its branches, nodes and labels. (2)
    Visually and statistically compare different 'dendrograms' to one another.",2020-02-28,Tal Galili,"http://talgalili.github.io/dendextend/,
https://github.com/talgalili/dendextend/,
https://cran.r-project.org/package=dendextend,
https://www.r-statistics.com/tag/dendextend/,
https://academic.oup.com/bioinformatics/article/31/22/3718/240978/dendextend-an-R-package-for-visualizing-adjusting",TRUE,https://github.com/talgalili/dendextend,2369441,119,2020-05-31T21:11:40Z,19911.268907563026
dendroTools,"Provides novel dendroclimatological methods, primarily used by the
    Tree-ring research community. There are four core functions. The first one is 
    daily_response(), which finds the optimal sequence of days that are related 
    to one or more tree-ring proxy records. Similar function is daily_response_seascorr(), 
    which implements partial correlations in the analysis of daily response functions.
    For the enthusiast of monthly data, there is monthly_response() function.
    The last core function is compare_methods(), which effectively compares several 
    linear and nonlinear regression algorithms on the task of climate reconstruction.   ",2020-01-07,Jernej Jevsenak,http://github.com/jernejjevsenak/dendroTools,TRUE,https://github.com/jernejjevsenak/dendrotools,25016,2,2019-12-21T22:14:33Z,12508
densitr,"Provides various tools for analysing density profiles
    obtained by resistance drilling. It can load individual or
    multiple files and trim the starting and ending part of each
    density profile. Tools are also provided to trim profiles
    manually, to remove the trend from measurements using several
    methods, to plot the profiles and to detect tree rings
    automatically. Written with a focus on forestry use of resistance
    drilling in standing trees.",2020-04-07,Luka Krajnc,https://github.com/krajnc/densitr,TRUE,https://github.com/krajnc/densitr,949,0,2020-04-06T09:14:09Z,NA
densratio,"Density ratio estimation.
    The estimated density ratio function can be used in many applications such as
    anomaly detection, change-point detection, covariate shift adaptation.
    The implemented methods are uLSIF (Hido et al. (2011) <doi:10.1007/s10115-010-0283-2>),
    RuLSIF (Yamada et al. (2011) <doi:10.1162/NECO_a_00442>),
    and KLIEP (Sugiyama et al. (2007) <doi:10.1007/s10463-008-0197-x>).",2019-06-30,Koji Makiyama,https://github.com/hoxo-m/densratio,TRUE,https://github.com/hoxo-m/densratio,16712,11,2019-06-30T10:55:08Z,1519.2727272727273
DEploid,"Traditional phasing programs are limited to diploid organisms.
 Our method modifies Li and Stephens algorithm with Markov chain Monte Carlo
 (MCMC) approaches, and builds a generic framework that allows haplotype searches
 in a multiple infection setting. This package is primarily developed as part of
 the Pf3k project, which is a global collaboration using the latest
 sequencing technologies to provide a high-resolution view of natural variation
 in the malaria parasite Plasmodium falciparum. Parasite DNA are extracted from
 patient blood sample, which often contains more than one parasite strain, with
 unknown proportions. This package is used for deconvoluting mixed haplotypes,
 and reporting the mixture proportions from each sample.",2020-04-21,Joe Zhu,https://github.com/DEploid-dev/DEploid-r,TRUE,https://github.com/deploid-dev/deploid-r,18477,1,2020-04-21T19:53:06Z,18477
DepthProc,"Data depth concept offers a variety of powerful and user friendly
    tools for robust exploration and inference for multivariate data. The offered
    techniques may be successfully used in cases of lack of our knowledge on
    parametric models generating data due to their nature. The
    package consist of among others implementations of several data depth techniques
    involving multivariate quantile-quantile plots, multivariate scatter estimators,
    multivariate Wilcoxon tests and robust regressions.",2020-02-19,Zygmunt Zawadzki,"https://www.depthproc.zstat.pl/,
https://github.com/zzawadz/DepthProc",TRUE,https://github.com/zzawadz/depthproc,32422,3,2020-02-19T19:36:32Z,10807.333333333334
Deriv,"R-based solution for symbolic differentiation. It admits
    user-defined function as well as function substitution
    in arguments of functions to be differentiated. Some symbolic
    simplification is part of the work.",2019-12-10,Serguei Sokol,NA,TRUE,https://github.com/sgsokol/deriv,471508,18,2019-12-10T14:51:17Z,26194.88888888889
DescriptiveStats.OBeu,"Estimate and return the needed parameters for visualizations designed for 'OpenBudgets.eu' <http://openbudgets.eu/> datasets. Calculate descriptive statistical measures in budget data of municipalities across Europe, according to the 'OpenBudgets.eu' data model. There are functions for measuring central tendency and dispersion of amount variables along with their distributions and correlations and the frequencies of categorical variables for a given dataset. Also, can be used generally to other datasets, to extract visualization parameters, convert them to 'JSON' format and use them as input in a different graphical interface. ",2020-05-04,Kleanthis Koupidis,https://github.com/okgreece/DescriptiveStats.OBeu,TRUE,https://github.com/okgreece/descriptivestats.obeu,14724,1,2020-05-05T19:17:23Z,14724
descriptr,"Generate descriptive statistics such as measures of location,
    dispersion, frequency tables, cross tables, group summaries and multiple
    one/two way tables. ",2020-02-01,Aravind Hebbali,"https://descriptr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/descriptr",TRUE,https://github.com/rsquaredacademy/descriptr,31314,29,2020-02-01T10:20:44Z,1079.7931034482758
desctable,"Easily create descriptive and comparative tables.
    It makes use and integrates directly with the tidyverse family of packages, and pipes.
    Tables are produced as data frames/lists of data frames for easy manipulation after creation,
    and ready to be saved as csv, or piped to DT::datatable() or pander::pander() to integrate into reports.",2020-02-03,Maxime Wack,https://github.com/maximewack/desctable,TRUE,https://github.com/maximewack/desctable,18435,42,2020-02-03T15:53:32Z,438.92857142857144
DescTools,"A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.",2020-05-23,Andri Signorell,"https://andrisignorell.github.io/DescTools/,
https://github.com/AndriSignorell/DescTools/",TRUE,https://github.com/andrisignorell/desctools,974289,19,2020-06-09T23:24:35Z,51278.36842105263
DescToolsAddIns,"'RStudio' as of recently offers the option to define addins and assign shortcuts to them. This package contains addins for a few most frequently used functions in a data scientist's (at least mine) daily work (like str(), example(), plot(), head(), view(), Desc()). Most of these functions will use the current selection in the editor window and send the specific command to the console while instantly executing it. Assigning shortcuts to these addins will save you quite a few keystrokes.",2020-03-08,Andri Signorell,https://github.com/AndriSignorell/DescToolsAddIns/,TRUE,https://github.com/andrisignorell/desctoolsaddins,27318,1,2020-03-14T09:49:59Z,27318
DesignLibrary,"
    A simple interface to build designs using the package 'DeclareDesign'. 
    In one line of code, users can specify the parameters of individual 
    designs and diagnose their properties. The designers can also be used 
    to compare performance of a given design across a range of combinations 
    of parameters, such as effect size, sample size, and assignment probabilities.",2019-06-17,Jasper Cooper,"https://declaredesign.org/library/,
https://github.com/DeclareDesign/DesignLibrary",TRUE,https://github.com/declaredesign/designlibrary,17397,23,2020-04-21T19:47:06Z,756.3913043478261
designr,Generate balanced factorial designs with crossed and nested random and fixed effects <https://github.com/mmrabe/designr>.,2020-05-25,Maximilian Rabe,https://maxrabe.com/designr,TRUE,https://github.com/mmrabe/designr,3261,0,2020-05-25T10:37:30Z,NA
desplot,"A function for plotting maps of agricultural field experiments that
    are laid out in grids.",2019-09-13,Kevin Wright,https://github.com/kwstat/desplot,TRUE,https://github.com/kwstat/desplot,25810,11,2020-01-20T15:29:45Z,2346.3636363636365
details,"Create a details HTML tag around R objects to place
    in a Markdown, 'Rmarkdown' and 'roxygen2' documentation.",2020-01-12,Jonathan Sidi,https://github.com/yonicd/details,TRUE,https://github.com/yonicd/details,8037,70,2020-04-21T13:52:25Z,114.81428571428572
detectseparation,"Provides pre-fit and post-fit methods for detecting separation and infinite maximum likelihood estimates in generalized linear models with categorical responses. The pre-fit methods apply on binomial-response generalized liner models such as logit, probit and cloglog regression, and can be directly supplied as fitting methods to the glm() function. They solve the linear programming problems for the detection of separation developed in Konis (2007, <https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a>) using 'ROI' <https://cran.r-project.org/package=ROI> or 'lpSolveAPI' <https://cran.r-project.org/package=lpSolveAPI>. The post-fit methods apply to models with categorical responses, including binomial-response generalized linear models and multinomial-response models, such as baseline category logits and adjacent category logits models; for example, the models implemented in the 'brglm2' <https://cran.r-project.org/package=brglm2> package. The post-fit methods successively refit the model with increasing number of iteratively reweighted least squares iterations, and monitor the ratio of the estimated standard error for each parameter to what it has been in the first iteration. According to the results in Lesaffre & Albert (1989, <https://www.jstor.org/stable/2345845>), divergence of those ratios indicates data separation.",2020-03-25,Ioannis Kosmidis,https://github.com/ikosmidis/detectseparation,TRUE,https://github.com/ikosmidis/detectseparation,1306,1,2020-03-26T11:06:43Z,1306
detzrcr,"Compare detrital zircon suites by uploading univariate,
      U-Pb age, or bivariate, U-Pb age and Lu-Hf data, in a 'shiny'-based
      user-interface. Outputs publication quality figures using 'ggplot2', and
      tables of statistics currently in use in the detrital zircon geochronology
      community.",2020-01-09,Magnus Kristoffersen,https://github.com/magnuskristoffersen/detzrcr,TRUE,https://github.com/magnuskristoffersen/detzrcr,24072,6,2020-06-08T11:18:59Z,4012
devRate,"A set of functions to quantify the relationship between development
    rate and temperature and to build phenological models. The package comprises 
    a set of models and estimated parameters borrowed from a literature review 
    in ectotherms. The methods and literature review are described in Rebaudo 
    et al. (2018) <doi:10.1111/2041-210X.12935> and Rebaudo and Rabhi (2018) 
    <doi:10.1111/eea.12693>. An example can be found in Rebaudo et al. (2017) 
    <doi:10.1007/s13355-017-0480-5>.",2019-05-27,Francois Rebaudo,https://github.com/frareb/devRate/,TRUE,https://github.com/frareb/devrate,22175,2,2020-06-09T08:39:58Z,11087.5
devtools,Collection of package development tools.,2020-04-10,Jim Hester,"https://devtools.r-lib.org/, https://github.com/r-lib/devtools",TRUE,https://github.com/r-lib/devtools,17883816,1956,2020-05-05T13:33:59Z,9143.055214723927
dexter,"A system for the management, assessment, and psychometric analysis of data from educational and psychological tests. ",2020-04-02,Gunter Maris,http://dexterities.netlify.com,TRUE,https://github.com/jessekps/dexter,34257,4,2020-04-06T11:14:00Z,8564.25
dextergui,"Classical Test and Item analysis, 
  Item Response analysis and data management for educational and psychological tests.",2020-02-20,jesse koops,NA,TRUE,https://github.com/jessekps/dexter,12765,4,2020-04-06T11:14:00Z,3191.25
dexterMST,"Conditional Maximum Likelihood Calibration and data management of multistage tests. 
  Functions for calibration of the Extended Nominal Response and the Interaction models, DIF and profile analysis.
  See Robert J. Zwitser and Gunter Maris (2015)<doi:10.1007/s11336-013-9369-6>.",2019-08-20,Timo Bechger,http://dexterities.netlify.com,TRUE,https://github.com/jessekps/dexter,10243,4,2020-04-06T11:14:00Z,2560.75
dfadjust,"Computes small-sample degrees of freedom adjustment for
    heteroskedasticity robust standard errors, and for clustered standard errors
    in linear regression. See Imbens and Kolesár (2016)
    <doi:10.1162/REST_a_00552> for a discussion of these adjustments.",2019-12-16,Michal Kolesár,https://github.com/kolesarm/Robust-Small-Sample-Standard-Errors,TRUE,https://github.com/kolesarm/robust-small-sample-standard-errors,4030,15,2019-12-16T16:13:42Z,268.6666666666667
dfoliatR,"Tools to identify, quantify, analyze, and visualize growth
    suppression events in tree rings that are often produced by insect
    defoliation.",2020-03-04,Chris Guiterman,https://chguiterman.github.io/dfoliatR/,TRUE,https://github.com/chguiterman/dfoliatr,1465,2,2020-05-21T14:33:38Z,732.5
dformula,"A tool for manipulating data using the generic formula. A single formula allows to easily add, replace and remove variables before running the analysis. ",2020-06-04,Alessio Serafini,https://github.com/dataallaround/dformula,TRUE,https://github.com/dataallaround/dformula,0,0,2020-06-04T19:55:06Z,NA
dfvad,"Decomposing value added growth into explanatory factors.
    A cost constrained value added function is defined to specify the 
    production frontier. Industry estimates can also be aggregated
    using a weighted average approach.
    Details about the methodology and data can be found in Diewert and Fox (2018)
    <doi:10.1093/oxfordhb/9780190226718.013.19>
    and Zeng, Parsons, Diewert and Fox (2018)
    <https://www.business.unsw.edu.au/research-site/centreforappliedeconomicresearch-site/Documents/emg2018-6_SZeng_EMG-Slides.pdf>.",2020-03-05,Shipei Zeng,https://github.com/shipei-zeng/dfvad,TRUE,https://github.com/shipei-zeng/dfvad,1531,0,2020-05-31T15:15:59Z,NA
dggridR,"Spatial analyses involving binning require that every bin have the same area, but this is impossible using a rectangular grid laid over the Earth or over any projection of the Earth. Discrete global grids use hexagons, triangles, and diamonds to overcome this issue, overlaying the Earth with equally-sized bins. This package provides utilities for working with discrete global grids, along with utilities to aid in plotting such data.",2020-04-29,Richard Barnes,https://github.com/r-barnes/dggridR/,TRUE,https://github.com/r-barnes/dggridr,19086,94,2020-04-29T17:15:36Z,203.04255319148936
dgumbel,"Gumbel distribution functions (De Haan L. (2007)
    <doi:10.1007/0-387-34471-3>) implemented with the techniques of automatic
    differentiation (Griewank A. (2008) <isbn:978-0-89871-659-7>).
    With this tool, a user should be able to quickly model extreme
    events for which the Gumbel distribution is the domain of attraction.
    The package makes available the density function, the distribution
    function the quantile function and a random generating function. In
    addition, it supports gradient functions. The package combines 'Adept'
    (C++ templated automatic differentiation) (Hogan R. (2017)
    <doi:10.5281/zenodo.1004730>) and 'Eigen' (templated matrix-vector
    library) for fast computations of both objective functions and exact
    gradients. It relies on 'RcppEigen' for easy access to 'Eigen' and
    bindings to R.",2020-04-16,Berent Ånund Strømnes Lunde,https://github.com/blunde1/dgumbel,TRUE,https://github.com/blunde1/dgumbel,1147,1,2020-04-13T18:57:50Z,1147
DHARMa,"The 'DHARMa' package uses a simulation-based approach to create
    readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed
    models. Currently supported are linear and generalized linear (mixed) models from 'lme4'
    (classes 'lmerMod', 'glmerMod'), 'glmmTMB' and 'spaMM', generalized additive models ('gam' from
    'mgcv'), 'glm' (including 'negbin' from 'MASS', but excluding quasi-distributions) and 'lm' model
    classes. Moreover, externally created simulations, e.g. posterior predictive simulations
    from Bayesian software such as 'JAGS', 'STAN', or 'BUGS' can be processed as well.
    The resulting residuals are standardized to values between 0 and 1 and can be interpreted
    as intuitively as residuals from a linear regression. The package also provides a number of
    plot and test functions for typical model misspecification problems, such as
    over/underdispersion, zero-inflation, and residual spatial and temporal autocorrelation.",2020-05-12,Florian Hartig,http://florianhartig.github.io/DHARMa/,TRUE,https://github.com/florianhartig/dharma,95760,104,2020-06-07T11:43:08Z,920.7692307692307
diagis,"Fast functions for effective sample size, weighted multivariate mean and variance computation, 
    and weight diagnostic plot for generic importance sampling type results.",2020-06-04,Jouni Helske,NA,TRUE,https://github.com/helske/diagis,17127,0,2020-06-04T12:23:51Z,NA
diagmeta,Provides methods by Steinhauser et al. (2016) <DOI:10.1186/s12874-016-0196-1> for meta-analysis of diagnostic accuracy studies with several cutpoints.,2020-04-02,Guido Schwarzer,https://github.com/guido-s/diagmeta,TRUE,https://github.com/guido-s/diagmeta,10701,2,2020-04-07T19:39:59Z,5350.5
diagonals,"Several tools for handling block-matrix diagonals and similar
    constructs are implemented. Block-diagonal matrices can be extracted or removed
    using two small functions implemented here. In addition, non-square matrices
    are supported. Block diagonal matrices occur when two dimensions of a data set
    are combined along one edge of a matrix. For example, trade-flow data in the
    'decompr' and 'gvc' packages have each country-industry combination occur along
    both edges of the matrix.",2020-04-28,Bastiaan Quast,"https://qua.st/diagonals, https://github.com/bquast/diagonals",TRUE,https://github.com/bquast/diagonals,24094,1,2020-04-28T06:08:51Z,24094
DiagrammeR,"
    Build graph/network structures using functions for stepwise addition and
    deletion of nodes and edges. Work with data available in tables for bulk
    addition of nodes, edges, and associated metadata. Use graph selections
    and traversals to apply changes to specific nodes or edges. A wide
    selection of graph algorithms allow for the analysis of graphs. Visualize
    the graphs and take advantage of any aesthetic properties assigned to
    nodes and edges.",2020-05-08,Richard Iannone,https://github.com/rich-iannone/DiagrammeR,TRUE,https://github.com/rich-iannone/diagrammer,958256,1327,2020-05-15T01:17:22Z,722.1220798794272
DiagrammeRsvg,Allows for export of DiagrammeR Graphviz objects to SVG.,2016-02-04,Richard Iannone,https://github.com/rich-iannone/DiagrammeRsvg,TRUE,https://github.com/rich-iannone/diagrammersvg,108579,23,2019-12-10T14:02:56Z,4720.826086956522
dialr,"Parse, format, and validate international phone
    numbers using Google's 'libphonenumber' java library,
    <https://github.com/google/libphonenumber>.",2020-04-04,Danny Smith,"https://socialresearchcentre.github.io/dialr,
https://github.com/socialresearchcentre/dialr,
https://github.com/socialresearchcentre/dialrjars,
https://github.com/google/libphonenumber",TRUE,https://github.com/socialresearchcentre/dialr,6946,1,2020-05-16T09:28:07Z,6946
dialrjars,"Collects 'libphonenumber' jars required for the
    'dialr' package.",2020-03-23,Danny Smith,"https://github.com/socialresearchcentre/dialrjars,
https://github.com/googlei18n/libphonenumber",TRUE,https://github.com/socialresearchcentre/dialrjars,8103,1,2020-05-16T08:40:01Z,8103
dials,"Many models contain tuning parameters (i.e. parameters that cannot be directly estimated from the data). These tools can be used to define objects for creating, simulating, or validating values for such parameters. ",2020-04-03,Max Kuhn,"https://tidymodels.github.io/dials,
https://github.com/tidymodels/dials",TRUE,https://github.com/tidymodels/dials,59050,71,2020-06-09T23:03:27Z,831.6901408450705
diceR,"Performs cluster analysis using an ensemble
    clustering framework, Chiu & Talhouk (2018)
    <doi:10.1186/s12859-017-1996-y>.  Results from a diverse set of
    algorithms are pooled together using methods such as majority voting,
    K-Modes, LinkCluE, and CSPA. There are options to compare cluster
    assignments across algorithms using internal and external indices,
    visualizations such as heatmaps, and significance testing for the
    existence of clusters.",2019-07-25,Derek Chiu,"https://github.com/AlineTalhouk/diceR,
https://alinetalhouk.github.io/diceR",TRUE,https://github.com/alinetalhouk/dicer,19245,21,2019-12-08T22:25:43Z,916.4285714285714
Dict,A key-value dictionary data structure based on R6 class which is designed to be similar usages with other languages dictionary (e.g. 'Python') with reference semantics and extendabilities by R6.,2020-06-02,Shun Asai,https://github.com/five-dots/Dict,TRUE,https://github.com/five-dots/dict,0,1,2020-06-03T05:50:03Z,0
dief,"An implementation of the metrics dief@t and dief@k to measure the diefficiency (or continuous efficiency) of incremental approaches, see Acosta, M., Vidal, M. E., & Sure-Vetter, Y. (2017) <doi:10.1007/978-3-319-68204-4_1>. The metrics dief@t and dief@k allow for measuring the diefficiency during an elapsed time period t or while k answers are produced, respectively. dief@t and dief@k rely on the computation of the area under the curve of answer traces, and thus capturing the answer rate concentration over a time interval.    ",2019-02-28,Maribel Acosta,https://github.com/maribelacosta/dief,TRUE,https://github.com/maribelacosta/dief,10125,5,2019-10-03T10:56:44Z,2025
dietr,"Estimates fractional trophic level from quantitative and qualitative diet data and calculates electivity indices in R. Froese & Pauly (2000, ISBN: 9718709991).",2019-11-13,Samuel R. Borstein,https://github.com/sborstein/dietr,TRUE,https://github.com/sborstein/dietr,2726,0,2019-12-11T21:13:39Z,NA
diffdf,"Functions for comparing two data.frames against 
    each other. The core functionality is to provide a detailed breakdown of any differences 
    between two data.frames as well as providing utility functions to help narrow down the 
    source of problems and differences.",2020-03-17,Craig Gower-Page,https://github.com/gowerc/diffdf,TRUE,https://github.com/gowerc/diffdf,11564,9,2020-03-16T19:10:11Z,1284.888888888889
diffee,"This is an R implementation of Fast and Scalable Learning of Sparse Changes in High-Dimensional Gaussian Graphical Model Structure (DIFFEE). The DIFFEE algorithm can be used to fast estimate the differential network between two related datasets. For instance, it can identify differential gene network from datasets of case and control. By performing data-driven network inference from two high-dimensional data sets, this tool can help users effectively translate two aggregated data blocks into knowledge of the changes among entities between two Gaussian Graphical Model. Please run demo(diffeeDemo) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Arshdeep Sekhon, Yanjun Qi (2018) <arXiv:1710.11223>.",2018-07-03,Beilun Wang,https://github.com/QData/DIFFEE,TRUE,https://github.com/qdata/diffee,7995,0,2019-08-28T16:29:38Z,NA
diffEnrich,"Compare functional enrichment between two experimentally-derived groups of genes or proteins (Peterson, DR., et al.(2018)) <doi: 10.1371/journal.pone.0198139>. Given a list of gene symbols, 'diffEnrich'  will
  perform differential enrichment analysis using the Kyoto Encyclopedia of Genes
  and Genomes (KEGG) REST API. This package provides a number of functions that are 
  intended to be used in a pipeline. Briefly, the user provides a KEGG formatted species id for either human, mouse or rat, and the package will
  download and clean species specific ENTREZ gene IDs and map them to their respective
  KEGG pathways by accessing KEGG's REST API. KEGG's API is used to guarantee the most up-to-date pathway data from KEGG. Next, the user will identify significantly
  enriched pathways from two gene sets, and finally, the user will identify 
  pathways that are differentially enriched between the two gene sets. In addition to 
  the analysis pipeline, this package also provides a plotting function. ",2019-11-21,Harry Smith,https://github.com/SabaLab/diffEnrich,TRUE,https://github.com/sabalab/diffenrich,3060,0,2020-04-13T17:30:32Z,NA
diffeqr,"An interface to 'DifferentialEquations.jl' <http://docs.juliadiffeq.org/latest/> from the R programming language.
  It has unique high performance methods for solving ordinary differential equations (ODE), stochastic differential equations (SDE),
  delay differential equations (DDE), differential-algebraic equations (DAE), and more. Much of the functionality,
  including features like adaptive time stepping in SDEs, are unique and allow for multiple orders of magnitude speedup over more common methods.
  'diffeqr' attaches an R interface onto the package, allowing seamless use of this tooling by R users.",2019-09-22,Christopher Rackauckas,https://github.com/JuliaDiffEq/diffeqr,TRUE,https://github.com/juliadiffeq/diffeqr,10368,51,2020-04-22T13:39:59Z,203.2941176470588
diffeR,Metrics of difference for comparing pairs of variables or pairs of maps representing real or categorical variables at original and multiple resolutions.,2019-01-22,Robert Gilmore Pontius Jr.,"http://amsantac.co/software.html,
https://github.com/amsantac/diffeR",TRUE,https://github.com/amsantac/differ,20659,0,2019-12-11T17:01:28Z,NA
diffobj,"Generate a colorized diff of two R objects for an intuitive
    visualization of their differences.",2020-05-11,Brodie Gaslam,https://github.com/brodieG/diffobj,TRUE,https://github.com/brodieg/diffobj,326416,168,2020-05-11T18:28:46Z,1942.952380952381
diffusion,"Various diffusion models to forecast new product growth. Currently
    the package contains Bass, Gompertz and Gamma/Shifted Gompertz curves. See
    Meade and Islam (2006) <doi:10.1016/j.ijforecast.2006.01.005>.",2018-01-05,Oliver Schaer,https://github.com/mamut86/diffusion,TRUE,https://github.com/mamut86/diffusion,10355,6,2020-04-30T19:52:45Z,1725.8333333333333
diffusionMap,"Implements diffusion map method of data
    parametrization, including creation and visualization of
    diffusion map, clustering with diffusion K-means and
	  regression using adaptive regression model.
	  Richards (2009) <doi:10.1088/0004-637X/691/1/32>.",2019-09-10,Joseph Richards,https://github.com/rcannood/diffusionMap,TRUE,https://github.com/rcannood/diffusionmap,76475,0,2019-09-10T11:16:27Z,NA
diffusr,"Implementation of network diffusion algorithms such as
  heat diffusion or Markov random walks. Network diffusion algorithms generally
  spread information in the form of node weights along the edges of a graph to other nodes.
  These weights can for example be interpreted as temperature, an initial amount
  of water, the activation of neurons in the brain, or the location of a random
  surfer in the internet. The information (node weights) is iteratively propagated
  to other nodes until a equilibrium state or stop criterion occurs.",2018-05-17,Simon Dirmeier,https://github.com/dirmeier/diffusr,TRUE,https://github.com/dirmeier/diffusr,14930,16,2019-09-22T19:17:06Z,933.125
difNLR,"Detection of differential item functioning (DIF) among dichotomously scored items and differential distractor functioning (DDF) among unscored items with non-linear regression procedures based on generalized logistic regression models (Drabinova and Martinkova, 2017, doi:10.1111/jedm.12158).",2020-05-04,Adela Hladka,NA,TRUE,https://github.com/adelahladka/difnlr,32686,2,2020-05-04T14:31:56Z,16343
digest,"Implementation of a function 'digest()' for the creation 
 of hash digests of arbitrary R objects (using the 'md5', 'sha-1', 'sha-256', 
 'crc32', 'xxhash', 'murmurhash' and 'spookyhash' algorithms) permitting easy
 comparison of R language objects, as well as functions such as'hmac()' to
 create hash-based message authentication code. Please note that this package
 is not meant to be deployed for cryptographic purposes for which more
 comprehensive (and widely tested) libraries such as 'OpenSSL' should be
 used.",2020-02-23,"Dirk Eddelbuettel <edd@debian.org> with contributions 
 by Antoine Lucas",http://dirk.eddelbuettel.com/code/digest.html,TRUE,https://github.com/eddelbuettel/digest,26769060,71,2020-05-21T12:04:39Z,377029.0140845071
dimensionsR,A set of tools to extract bibliographic content from 'Digital Science Dimensions' using 'DSL' API <https://www.dimensions.ai/dimensions-apis/>.,2020-03-20,Massimo Aria,https://github.com/massimoaria/dimensionsR,TRUE,https://github.com/massimoaria/dimensionsr,5892,4,2020-05-17T06:15:02Z,1473
dimRed,"A collection of dimensionality reduction
    techniques from R packages and a common
    interface for calling the methods.",2019-05-08,Guido Kraemer,https://github.com/gdkrmr/dimRed,TRUE,https://github.com/gdkrmr/dimred,938457,59,2019-11-11T12:43:52Z,15906.050847457627
dina,"Estimate the Deterministic Input, Noisy ""And"" Gate (DINA)
    cognitive diagnostic model parameters using the Gibbs sampler described
    by Culpepper (2015) <doi:10.3102/1076998615595403>.",2019-02-01,Steven Andrew Culpepper,https://github.com/tmsalab/dina,TRUE,https://github.com/tmsalab/dina,17125,6,2020-03-22T17:01:22Z,2854.1666666666665
dint,"S3 classes and methods to create and work
    with year-quarter, year-month and year-isoweek vectors. Basic
    arithmetic operations (such as adding and subtracting) are supported,
    as well as formatting and converting to and from standard R date
    types.",2020-02-06,Stefan Fleck,https://github.com/s-fleck/dint,TRUE,https://github.com/s-fleck/dint,13833,9,2020-03-23T13:04:45Z,1537
dipsaus,"Works as an ""add-on"" to packages like 'shiny', 'future', as well as 
    'rlang', and provides utility functions. Just like dipping sauce adding 
    flavors to potato chips or pita bread, 'dipsaus' for data analysis and 
    visualizations adds handy functions and enhancements to popular packages. 
    The goal is to provide simple solutions that are frequently asked for 
    online, such as how to synchronize 'shiny' inputs without freezing the app,
    or how to get memory size on 'Linux' or 'MacOS' system. The enhancements 
    roughly fall into these four categories: 1. 'shiny' input widgets; 2. 
    high-performance computing using 'RcppParallel' and 'future' package; 3. 
    modify R calls and convert among numbers, strings, and other objects. 4. 
    utility functions to get system information such like CPU chip-set, memory 
    limit, etc.",2020-05-12,Zhengjia Wang,https://github.com/dipterix/dipsaus,TRUE,https://github.com/dipterix/dipsaus,3818,5,2020-05-19T16:09:26Z,763.6
directlabels,"An extensible framework
 for automatically placing direct labels onto multicolor 'lattice' or
 'ggplot2' plots.
 Label positions are described using Positioning Methods
 which can be re-used across several different plots.
 There are heuristics for examining ""trellis"" and ""ggplot"" objects
 and inferring an appropriate Positioning Method.",2020-02-01,Toby Dylan Hocking,https://github.com/tdhock/directlabels,TRUE,https://github.com/tdhock/directlabels,184902,32,2020-01-31T17:00:59Z,5778.1875
dirichletprocess,"Perform nonparametric Bayesian analysis using Dirichlet 
    processes without the need to program the inference algorithms. 
    Utilise included pre-built models or specify custom 
    models and allow the 'dirichletprocess' package to handle the 
    Markov chain Monte Carlo sampling. 
    Our Dirichlet process objects can act as building blocks for a variety 
    of statistical models including and not limited to: density estimation, 
    clustering and prior distributions in hierarchical models.
    See Teh, Y. W. (2011) 
    <https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf>, 
    among many other sources.",2020-04-03,Dean Markwick,https://github.com/dm13450/dirichletprocess,TRUE,https://github.com/dm13450/dirichletprocess,12670,27,2020-06-07T18:29:53Z,469.25925925925924
discgolf,"Client for the Discourse API. Discourse is a open source
    discussion forum platform (<https://www.discourse.org/>). It comes with 'RESTful'
    API access to an installation. This client requires that you are authorized
    to access a Discourse installation, either yours or another.",2018-01-03,Scott Chamberlain,https://github.com/sckott/discgolf,TRUE,https://github.com/sckott/discgolf,14554,8,2019-09-12T22:14:54Z,1819.25
disclapmix,"Make inference in a mixture of discrete Laplace distributions using the EM algorithm. This can e.g. be used for modelling the distribution of Y chromosomal haplotypes as described in [1, 2] (refer to the URL section).",2019-03-12,Mikkel Meyer Andersen,"http://dx.doi.org/10.1016/j.jtbi.2013.03.009
http://arxiv.org/abs/1304.2129",TRUE,https://github.com/mikldk/disclapmix,25167,0,2020-02-11T13:55:30Z,NA
discord,"Functions for discordant kinship modeling (and other sibling-based quasi-experimental designs). Currently, the package contains data restructuring functions; functions for generating genetically- and environmentally-informed data for kin pairs.",2017-05-02,S. Mason Garrison; Cermet Ream,https://github.com/smasongarrison/discord,TRUE,https://github.com/smasongarrison/discord,9859,1,2020-05-27T18:42:56Z,9859
discrim,"Bindings for additional classification models for use with the 
    'parsnip' package. Models include flavors of discriminant analysis, such as 
    linear (Fisher (1936) <doi:10.1111/j.1469-1809.1936.tb02137.x>), regularized 
    (Friedman (1989) <doi:10.1080/01621459.1989.10478752>), and flexible 
    (Hastie, Tibshirani, and Buja (1994) <doi:10.1080/01621459.1994.10476866>), 
    as well as naive Bayes classifiers (Hand and Yu (2007) 
    <doi:10.1111/j.1751-5823.2001.tb00465.x>). ",2020-04-09,Max Kuhn,https://github.com/tidymodels/discrim,TRUE,https://github.com/tidymodels/discrim,5209,16,2020-05-05T16:13:52Z,325.5625
diseq,"Provides estimation methods for markets in equilibrium and
    disequilibrium. Specifically, it supports the estimation of an equilibrium and
    four disequilibrium models with both correlated and independent shocks.
    It also provides post-estimation analysis tools, such as aggregation and
    marginal effects calculations. The estimation methods are based on full
    information maximum likelihood techniques given in Maddala and Nelson (1974)
    <doi:10.2307/1914215>. They are implemented using the analytic derivative
    expressions calculated in Karapanagiotis (2020) <doi:10.2139/ssrn.3525622>.
    The equilibrium estimation constitutes a special case of
    a system of simultaneous equations. The disequilibrium models, instead, replace
    the market clearing condition with a short side rule and
    allow for different specifications of price dynamics. ",2020-04-28,Pantelis Karapanagiotis,https://github.com/pi-kappa-devel/diseq/,TRUE,https://github.com/pi-kappa-devel/diseq,643,0,2020-05-26T22:09:35Z,NA
DisImpact,"Implements methods for calculating disproportionate impact: the percentage point gap, proportionality index, and the 80% index.
 California Community Colleges Chancellor's Office (2017).  Percentage Point Gap Method. <https://www.cccco.edu/-/media/CCCCO-Website/About-Us/Divisions/Digital-Innovation-and-Infrastructure/Research/Files/PercentagePointGapMethod2017.ashx>.
 California Community Colleges Chancellor's Office (2014).  Guidelines for Measuring Disproportionate Impact in Equity Plans. <https://www.cccco.edu/-/media/CCCCO-Website/Files/DII/guidelines-for-measuring-disproportionate-impact-in-equity-plans-tfa-ada.pdf>.",2020-06-02,Vinh Nguyen,https://github.com/vinhdizzo/DisImpact,TRUE,https://github.com/vinhdizzo/disimpact,10110,1,2020-06-01T16:43:51Z,10110
disk.frame,"A disk-based data manipulation tool for working with 
  large-than-RAM datasets. Aims to lower the barrier-to-entry for 
  manipulating large datasets by adhering closely to popular and 
  familiar data manipulation paradigms like dplyr verbs and 
  data.table syntax.",2020-05-08,Dai ZJ,https://diskframe.com,TRUE,https://github.com/xiaodaigh/disk.frame,10825,424,2020-05-08T00:17:26Z,25.53066037735849
dispRity,"A modular package for measuring disparity (multidimensional space occupancy). Disparity can be calculated from any matrix defining a multidimensional space. The package provides a set of implemented metrics to measure properties of the space and allows users to provide and test their own metrics (Guillerme (2018) <doi:10.1111/2041-210X.13022>). The package also provides functions for looking at disparity in a serial way (e.g. disparity through time - Guillerme and Cooper (2018) <doi:10.1111/pala.12364>) or per groups as well as visualising the results. Finally, this package provides several statistical tests for disparity analysis.",2020-06-03,Thomas Guillerme,https://github.com/TGuillerme/dispRity,TRUE,https://github.com/tguillerme/disprity,16012,11,2020-06-03T11:27:18Z,1455.6363636363637
dissever,"Spatial downscaling of coarse grid mapping to fine grid
    mapping using predictive covariates and a model fitted using the 'caret'
    package. The original dissever algorithm was published by Malone et al. 
    (2012) <doi:10.1016/j.cageo.2011.08.021>, and extended by Roudier et al.
    (2017) <doi:10.1016/j.compag.2017.08.021>.",2018-04-20,Pierre Roudier,https://github.com/pierreroudier/dissever,TRUE,https://github.com/pierreroudier/dissever,10760,5,2020-06-09T09:28:04Z,2152
Distance,"A simple way of fitting detection functions to distance sampling
    data for both line and point transects. Adjustment term selection, left and
    right truncation as well as monotonicity constraints and binning are
    supported. Abundance and density estimates can also be calculated (via a
    Horvitz-Thompson-like estimator) if survey area information is provided.",2020-01-31,David Lawrence Miller,http://github.com/DistanceDevelopment/Distance/,TRUE,https://github.com/distancedevelopment/distance,44706,0,2020-06-08T13:37:24Z,NA
distances,"Provides tools for constructing, manipulating and using distance metrics.",2019-09-22,Fredrik Savje,https://github.com/fsavje/distances,TRUE,https://github.com/fsavje/distances,31080,13,2019-09-18T20:51:30Z,2390.769230769231
distill,"Scientific and technical article format for the web. 'Distill' articles 
    feature attractive, reader-friendly typography, flexible layout options
    for visualizations, and full support for footnotes and citations.",2020-06-04,JJ Allaire,https://github.com/rstudio/distill,TRUE,https://github.com/rstudio/distill,9390,192,2020-06-05T14:03:26Z,48.90625
distr6,"An R6 object oriented distributions package. Unified interface for 42 probability distributions and 11 kernels including functionality for multiple scientific types. Additionally functionality for composite distributions and numerical imputation. Design patterns including wrappers and decorators are described in Gamma et al. (1994, ISBN:0-201-63361-2). For quick reference of probability distributions including d/p/q/r functions and results we refer to McLaughlin, M. P. (2001). Additionally Devroye (1986, ISBN:0-387-96305-7) for sampling the Dirichlet distribution, Gentle (2009) <doi:10.1007/978-0-387-98144-4> for sampling the Multivariate Normal distribution and Michael et al. (1976) <doi:10.2307/2683801> for sampling the Wald distribution.",2020-05-20,Raphael Sonabend,"https://alan-turing-institute.github.io/distr6/,
https://github.com/alan-turing-institute/distr6/",TRUE,https://github.com/alan-turing-institute/distr6,16813,41,2020-06-09T15:31:10Z,410.0731707317073
distreg.vis,"Functions for visualizing distributional regression models fitted using the 'gamlss', 'bamlss' or 'betareg' R package. The core of the package consists of a 'shiny' application, where the model results can be interactively explored and visualized.",2019-09-03,Stanislaus Stadlmann,https://github.com/Stan125/distreg.vis,TRUE,https://github.com/stan125/distreg.vis,8163,1,2020-05-15T01:55:07Z,8163
Distributacalcul,"Calculates expected values, variance, different moments (kth 
    moment, truncated mean), stop-loss, mean excess loss, Value-at-Risk (VaR)
    and Tail Value-at-Risk (TVaR) as well as some density and cumulative 
    (survival) functions of continuous, discrete and compound distributions. 
    This package also includes a visual 'Shiny' component to enable students 
    to visualize distributions and understand the impact of their parameters.
    This package is intended to expand the 'stats' and 'actuar' packages so as
    to enable students to develop an intuition for probability.",2020-06-09,Alec James van Rassel,https://github.com/alec42/Distributacalcul_Package,TRUE,https://github.com/alec42/distributacalcul_package,0,0,2020-06-09T16:49:35Z,NA
distributional,"Vectorised distribution objects with tools for manipulating, 
    visualising, and using probability distributions. Designed to allow model
    prediction outputs to return distributions rather than their parameters, 
    allowing users to directly interact with predictive distributions in a
    data-oriented workflow. In addition to providing generic replacements for
    p/d/q/r functions, other useful statistics can be computed including means,
    variances, intervals, and highest density regions.",2020-06-09,Mitchell OHara-Wild,"https://pkg.mitchelloharawild.com/distributional/,
https://github.com/mitchelloharawild/distributional",TRUE,https://github.com/mitchelloharawild/distributional,0,7,2020-06-09T13:53:01Z,0
distributions3,"Tools to create and manipulate probability
    distributions using S3.  Generics random(), pdf(), cdf() and
    quantile() provide replacements for base R's r/d/p/q style functions.
    Functions and arguments have been named carefully to minimize
    confusion for students in intro stats courses. The documentation for
    each distribution contains detailed mathematical notes.",2019-09-03,Alex Hayes,https://github.com/alexpghayes/distributions3,TRUE,https://github.com/alexpghayes/distributions3,5861,76,2020-02-12T13:20:08Z,77.11842105263158
distrr,"Tools to estimate and manage empirical distributions,
    which should work with survey data. One of the main features is the 
    possibility to create data cubes of estimated statistics, that include
    all the combinations of the variables of interest (see for example functions
    dcc5() and dcc6()).",2019-01-03,Sandro Petrillo Burri,"https://gibonet.github.io/distrr,
https://github.com/gibonet/distrr",TRUE,https://github.com/gibonet/distrr,10530,5,2020-06-09T14:48:10Z,2106
distTails,"A full definition for Weibull tails and Full-Tails Gamma and tools for fitting these distributions to empirical tails. This package build upon the paper by del Castillo, Joan & Daoudi, Jalila & Serra, Isabel. (2012) <doi:10.1017/asb.2017.9>.",2019-09-07,Sergi Vilardell,https://github.com/SergiVilardell/distTails,TRUE,https://github.com/sergivilardell/disttails,3389,0,2019-09-09T15:04:35Z,NA
divDyn,"Functions to describe sampling and diversity dynamics of fossil occurrence datasets (e.g. from the Paleobiology Database). The package includes methods to calculate range- and occurrence-based metrics of taxonomic richness, extinction and origination rates, along with traditional sampling measures. A powerful subsampling tool is also included that implements frequently used sampling standardization methods in a multiple bin-framework. The plotting of time series and the occurrence data can be simplified by the functions incorporated in the package, as well other calculations, such as environmental affinities and extinction selectivity testing. Details can be found in: Kocsis, A.T.; Reddin, C.J.; Alroy, J. and Kiessling, W. (2019) <doi:10.1101/423780>.",2019-06-12,Adam T. Kocsis,NA,TRUE,https://github.com/divdyn/r_package,8167,5,2019-09-30T12:43:19Z,1633.4
diveMove,"Utilities to represent, visualize, filter, analyse, and summarize
	     time-depth recorder (TDR) data.  Miscellaneous functions for
	     handling location data are also provided.",2020-04-29,Sebastian P. Luque,https://github.com/spluque/diveMove,TRUE,https://github.com/spluque/divemove,109088,1,2020-04-29T09:00:24Z,109088
divest,"Provides tools to sort DICOM-format medical image files, and
    convert them to NIfTI-1 format.",2020-01-10,Jon Clayden,https://github.com/jonclayden/divest,TRUE,https://github.com/jonclayden/divest,32498,9,2020-01-14T17:55:11Z,3610.8888888888887
diyar,"Perform multistage deterministic linkages, apply case definitions to datasets, and deduplicate records.
    Records (rows) from datasets are linked by different matching criteria and sub-criteria (columns) in a specified order of certainty. 
    The linkage process handles missing data and conflicting matches based on this same order of certainty.
    For episode grouping, rows of dated events (e.g. sample collection) or interval of events (e.g. hospital admission) are 
    grouped into chronological episodes beginning with a ""Case"". The process permits several options such as 
    episode lengths and recurrence periods which are used to build custom preferences for case assignment (definition).
    The record linkage and episode grouping processes assign unique group IDs to matching records or those grouped into episodes. 
    This then allows for record deduplication or sub-analysis within these groups.  ",2019-12-08,Olisaeloka Nsonwu,https://cran.r-project.org/package=diyar,TRUE,https://github.com/olisansonwu/diyar,3806,1,2020-06-04T18:53:20Z,3806
DLMtool,"Development, simulation testing, and implementation of management
    procedures for data-limited fisheries 
    (see Carruthers & Hordyk (2018) <doi:10.1111/2041-210X.13081>).",2020-06-02,Tom Carruthers,http://www.datalimitedtoolkit.org/,TRUE,https://github.com/dlmtool/dlmtool,61777,12,2020-06-09T22:24:32Z,5148.083333333333
dlnm,Collection of functions for distributed lag linear and non-linear models.,2020-05-22,Antonio Gasparrini,"https://github.com/gasparrini/dlnm,
http://www.ag-myresearch.com/package-dlnm",TRUE,https://github.com/gasparrini/dlnm,75135,18,2020-05-22T15:32:31Z,4174.166666666667
dlookr,"A collection of tools that support data diagnosis, exploration, and transformation. 
    Data diagnostics provides information and visualization of missing values and outliers and 
    unique and negative values to help you understand the distribution and quality of your data. 
    Data exploration provides information and visualization of the descriptive statistics of 
    univariate variables, normality tests and outliers, correlation of two variables, and 
    relationship between target variable and predictor. Data transformation supports binning 
    for categorizing continuous variables, imputates missing values and outliers, resolving skewness. 
    And it creates automated reports that support these three tasks.",2020-01-09,Choonghyun Ryu,NA,TRUE,https://github.com/choonghyunryu/dlookr,40175,68,2020-04-27T06:12:54Z,590.8088235294117
dlstats,"Monthly download stats of 'CRAN' and 'Bioconductor' packages.
	     Download stats of 'CRAN' packages is from the 'RStudio' 'CRAN mirror', see <http://cranlogs.r-pkg.org>.
	     'Bioconductor' package download stats is at <https://bioconductor.org/packages/stats/>.",2019-11-14,Guangchuang Yu,https://github.com/GuangchuangYu/dlstats,TRUE,https://github.com/guangchuangyu/dlstats,22876,8,2019-11-14T02:11:53Z,2859.5
dm,"Provides tools for working with multiple related
    tables, stored as data frames or in a relational database.  Multiple
    tables (data and metadata) are stored in a compound object, which can
    then be manipulated with a pipe-friendly syntax.",2020-06-07,Kirill Müller,"https://krlmlr.github.io/dm, https://github.com/krlmlr/dm",TRUE,https://github.com/krlmlr/dm,2246,175,2020-06-09T07:18:41Z,12.834285714285715
dmacs,Computes measurement nonequivalence effect size indices described in Nye and Drasgow (2011) <doi:10.1037/a0022955>. ,2019-10-24,David Dueber,https://github.com/ddueber/dmacs,TRUE,https://github.com/ddueber/dmacs,2932,0,2020-03-02T14:23:02Z,NA
dmdScheme,"Forms the core for developing own domain specific metadata schemes. 
                  It contains the basic functionality needed for all metadata schemes based on the
                  'dmdScheme'. See R.M. Krug and O.L. Petchey (2019) <DOI:10.5281/zenodo.3581970>.",2020-05-29,Rainer M. Krug,"https://exp-micro-ecol-hub.github.io/dmdScheme/,
https://github.com/Exp-Micro-Ecol-Hub/dmdScheme",TRUE,https://github.com/exp-micro-ecol-hub/dmdscheme,1982,1,2020-06-08T15:19:09Z,1982
dml,"The state-of-the-art algorithms for distance metric learning, including global and local methods such as Relevant Component Analysis, Discriminative Component Analysis, Local Fisher Discriminant Analysis, etc. These distance metric learning methods are widely applied in feature extraction, dimensionality reduction, clustering, classification, information retrieval, and computer vision problems.",2015-08-29,Yuan Tang,https://github.com/terrytangyuan/dml,TRUE,https://github.com/terrytangyuan/dml,26584,56,2019-12-19T03:32:41Z,474.7142857142857
dmtools,"For checking the dataset from EDC(Electronic Data Capture) in clinical trials.
             'dmtools' can check laboratory, dates, WBCs(White Blood Cells) count and rename the dataset.
             Laboratory - does the investigator correctly estimate the laboratory analyzes?
             Dates - do all dates correspond to the protocol's timeline?
             WBCs count - do absolute equal (all * relative) / 100?
             If the clinical trial has different lab reference ranges, 'dmtools' also can help.",2020-05-12,Konstantin Ryabov,https://github.com/chachabooms/dmtools,TRUE,https://github.com/chachabooms/dmtools,373,0,2020-06-07T18:36:45Z,NA
DNAtools,"Computationally efficient tools for comparing all pairs of profiles
    in a DNA database. The expectation and covariance of the summary statistic
    is implemented for fast computing. Routines for estimating proportions of
    close related individuals are available. The use of wildcards (also called F-
    designation) is implemented. Dedicated functions ease plotting the results.",2020-03-03,Mikkel Meyer Andersen,NA,TRUE,https://github.com/mikldk/dnatools,24601,0,2020-03-03T14:47:33Z,NA
dnet,"The focus of the dnet by Fang and Gough (2014) <doi:10.1186/s13073-014-0064-8> is to make sense of omics data (such as gene expression and mutations) from different angles including: integration with molecular networks, enrichments using ontologies, and relevance to gene evolutionary ages. Integration is achieved to identify a gene subnetwork from the whole gene network whose nodes/genes are labelled with informative data (such as the significant levels of differential expression or survival risks). To help make sense of identified gene networks, enrichment analysis is also supported using a wide variety of pre-compiled ontologies and phylostratific gene age information in major organisms including: human, mouse, rat, chicken, C.elegans, fruit fly, zebrafish and arabidopsis. Add-on functionalities are supports for calculating semantic similarity between ontology terms (and between genes) and for calculating network affinity based on random walk; both can be done via high-performance parallel computing.",2020-02-20,Hai Fang and Julian Gough,"http://dnet.r-forge.r-project.org,
https://github.com/hfang-bristol/dnet",TRUE,https://github.com/hfang-bristol/dnet,65092,10,2020-02-20T09:42:01Z,6509.2
do,"Flexibly convert data between long and wide format using just two
    functions: reshape_toLong() and reshape_toWide().",2020-04-01,Jing Zhang,https://github.com/yikeshu0611/do,TRUE,https://github.com/yikeshu0611/do,6400,2,2019-12-16T23:43:40Z,3200
docuSignr,"Connect to the 'DocuSign' Rest API <https://www.docusign.com/p/RESTAPIGuide/RESTAPIGuide.htm>, 
  which supports embedded signing, and sending of documents. ",2017-10-22,Carl Ganz,https://github.com/CannaData/docuSignr,TRUE,https://github.com/cannadata/docusignr,12448,4,2019-07-02T22:43:10Z,3112
docxtools,"A set of helper functions for using R Markdown to create documents
    in docx format, especially documents for use in a classroom or workshop
    setting.",2020-06-03,Richard Layton,https://github.com/graphdr/docxtools,TRUE,https://github.com/graphdr/docxtools,18381,18,2020-06-03T18:17:08Z,1021.1666666666666
dodgr,"Distances on dual-weighted directed graphs using priority-queue
    shortest paths (Padgham (2019) <doi:10.32866/6945>). Weighted directed
    graphs have weights from A to B which may differ from those from B to A.
    Dual-weighted directed graphs have two sets of such weights. A canonical
    example is a street network to be used for routing in which routes are
    calculated by weighting distances according to the type of way and mode of
    transport, yet lengths of routes must be calculated from direct distances.",2020-05-05,Mark Padgham,https://github.com/ATFutures/dodgr,TRUE,https://github.com/atfutures/dodgr,22164,76,2020-05-26T14:52:15Z,291.63157894736844
doFuture,"Provides a '%dopar%' adapter such that any type of futures can
    be used as backends for the 'foreach' framework.",2020-01-11,Henrik Bengtsson,https://github.com/HenrikBengtsson/doFuture,TRUE,https://github.com/henrikbengtsson/dofuture,68128,52,2020-05-01T20:02:00Z,1310.1538461538462
donut,"Finds the k nearest neighbours in a dataset of specified points, 
  adding the option to wrap certain variables on a torus.  The user chooses
  the algorithm to use to find the nearest neighbours. Two such algorithms,
  provided by the packages 'RANN' <https://cran.r-project.org/package=RANN>, 
  and 'nabor' <https://cran.r-project.org/package=nabor>, are suggested.",2020-02-18,Paul J. Northrop,"http://github.com/paulnorthrop/donut,
https://paulnorthrop.github.io/donut/",TRUE,https://github.com/paulnorthrop/donut,3292,0,2020-02-27T09:36:59Z,NA
doRedis,"A parallel back end for the 'foreach' package using the 'Redis'
    database.",2020-01-28,B. W. Lewis,NA,TRUE,https://github.com/bwlewis/doredis,85047,64,2020-05-28T23:26:04Z,1328.859375
doRNG,"Provides functions to perform
    reproducible parallel foreach loops, using independent
    random streams as generated by L'Ecuyer's combined
    multiple-recursive generator [L'Ecuyer (1999), <DOI:10.1287/opre.47.1.159>].
    It enables to easily convert standard %dopar% loops into
    fully reproducible loops, independently of the number
    of workers, the task scheduling strategy, or the chosen
    parallel environment and associated foreach backend.",2020-01-27,Renaud Gaujoux,https://renozao.github.io/doRNG,TRUE,https://github.com/renozao/dorng,508940,11,2020-01-26T15:57:16Z,46267.27272727273
dosresmeta,"Estimates dose-response relations from summarized dose-response
    data and to combines them according to principles of (multivariate)
    random-effects models.  ",2017-09-12,Alessio Crippa,https://alecri.github.io/software/dosresmeta.html,TRUE,https://github.com/alecri/dosresmeta,26600,4,2019-07-25T08:43:31Z,6650
DOT,"Renders DOT diagram markup language in R and also provides the possibility to
    export the graphs in PostScript and SVG (Scalable Vector Graphics) formats.
    In addition, it supports literate programming packages such as 'knitr' and
    'rmarkdown'.",2016-04-16,E. F. Haghish,http://haghish.com/dot,TRUE,https://github.com/haghish/dot,15725,3,2020-02-10T00:53:37Z,5241.666666666667
dotwhisker,Quick and easy dot-and-whisker plots of regression results.,2018-06-27,Frederick Solt,NA,TRUE,https://github.com/fsolt/dotwhisker,74507,45,2020-02-14T16:22:24Z,1655.7111111111112
downloadthis,Implement download buttons in HTML output from 'rmarkdown' without the need for 'runtime:shiny'.,2020-05-04,Felipe Mattioni Maturana,https://github.com/fmmattioni/downloadthis,TRUE,https://github.com/fmmattioni/downloadthis,2628,39,2020-05-04T18:54:30Z,67.38461538461539
dplR,"Perform tree-ring analyses such as detrending, chronology
        building, and cross dating.  Read and write standard file formats
        used in dendrochronology.",2020-03-19,Andy Bunn,https://github.com/AndyBunn/dplR,TRUE,https://github.com/andybunn/dplr,129715,6,2020-03-20T21:42:35Z,21619.166666666668
dplyr,"A fast, consistent tool for working with data frame
    like objects, both in memory and out of memory.",2020-05-29,Hadley Wickham,"https://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr",TRUE,https://github.com/tidyverse/dplyr,28615272,3372,2020-06-09T10:08:50Z,8486.142348754449
dqrng,"Several fast random number generators are provided as C++
  header only libraries: The PCG family by O'Neill (2014
  <https://www.cs.hmc.edu/tr/hmc-cs-2014-0905.pdf>) as well as
  Xoroshiro128+ and Xoshiro256+ by Blackman and Vigna (2018
  <arXiv:1805.01407>). In addition fast functions for generating random
  numbers according to a uniform, normal and exponential distribution
  are included. The latter two use the Ziggurat algorithm originally
  proposed by Marsaglia and Tsang (2000, <doi:10.18637/jss.v005.i08>).
  These functions are exported to R and as a C++ interface and are
  enabled for use with the default 64 bit generator from the PCG family,
  Xoroshiro128+ and Xoshiro256+ as well as the 64 bit version of the 20 rounds
  Threefry engine (Salmon et al., 2011 <doi:10.1145/2063384.2063405>) as
  provided by the package 'sitmo'.",2019-05-17,Ralf Stubner,"https://www.daqana.org/dqrng, https://github.com/daqana/dqrng",TRUE,https://github.com/daqana/dqrng,106413,16,2020-06-04T13:01:06Z,6650.8125
dqshiny,"Provides highly customizable modules to enhance your shiny apps.
    Includes layout independent collapsible boxes and value boxes, a very fast
    autocomplete input, rhandsontable extensions for filtering and paging and
    much more.",2020-05-10,Richard Kunze,https://github.com/daqana/dqshiny,TRUE,https://github.com/daqana/dqshiny,11099,46,2020-05-10T19:36:07Z,241.2826086956522
dragon,Visualization and manipulation of the mineral-chemistry network across deep time on earth. ,2019-10-20,Stephanie J. Spielman,https://github.com/spielmanlab/dragon,TRUE,https://github.com/spielmanlab/dragon,4635,1,2020-01-23T13:02:03Z,4635
drake,"A general-purpose computational engine for data
  analysis, drake rebuilds intermediate data objects when their
  dependencies change, and it skips work when the results are already up
  to date.  Not every execution starts from scratch, there is native
  support for parallel and distributed computing, and completed projects
  have tangible evidence that they are reproducible.  Extensive
  documentation, from beginner-friendly tutorials to practical examples
  and more, is available at the reference website
  <https://docs.ropensci.org/drake/> and the online manual
  <https://books.ropensci.org/drake/>.",2020-06-02,William Michael Landau,"https://github.com/ropensci/drake,
https://docs.ropensci.org/drake,
https://books.ropensci.org/drake/",TRUE,https://github.com/ropensci/drake,78840,1134,2020-06-08T20:27:38Z,69.52380952380952
drat,"Creation and use of R Repositories via helper functions 
 to insert packages into a repository, and to add repository information 
 to the current R session. Two primary types of repositories are support:
 gh-pages at GitHub, as well as local repositories on either the same machine
 or a local network. Drat is a recursive acronym: Drat R Archive Template. ",2020-05-30,Dirk Eddelbuettel with contributions by Carl Boettiger,http://dirk.eddelbuettel.com/code/drat.html,TRUE,https://github.com/eddelbuettel/drat,221552,117,2020-05-30T00:21:44Z,1893.6068376068376
DRDID,"Implements the locally efficient doubly robust difference-in-differences (DiD)
    estimators for the average treatment effect proposed by Sant'Anna and Zhao (2020)
    <arXiv:1812.01723>. The estimator combines inverse probability weighting and outcome
    regression estimators (also implemented in the package) to form estimators with
    more attractive statistical properties. Two different estimation methods can be used
    to estimate the nuisance functions.",2020-05-18,Pedro H. C. SantAnna,"https://pedrohcgs.github.io/DRDID/,
https://github.com/pedrohcgs/DRDID",TRUE,https://github.com/pedrohcgs/drdid,285,7,2020-05-12T17:44:49Z,40.714285714285715
dreamerr,"Set of tools to facilitate package development and make R a more user-friendly place. Mostly for developers (or anyone who writes/shares functions). Provides a simple, powerful and flexible way to check the arguments passed to functions. 
    The developer can easily describe the type of argument needed. If the user provides a wrong argument, then an informative error message is prompted with the requested type and the problem clearly stated--saving the user a lot of time in debugging. ",2020-06-08,Laurent Berge,NA,TRUE,https://github.com/lrberge/dreamerr,1093,5,2020-05-03T08:23:40Z,218.6
DriftBurstHypothesis,"Calculates the T-Statistic for the drift burst hypothesis from the working paper Christensen, Oomen and Reno (2018) <DOI:10.2139/ssrn.2842535>. The authors' MATLAB code is available upon request, see: <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2842535>.",2020-03-25,Emil Sjoerup,https://github.com/emilsjoerup/DriftBurstHypothesis,TRUE,https://github.com/emilsjoerup/driftbursthypothesis,9883,2,2019-11-30T13:19:14Z,4941.5
drifter,"Concept drift refers to the change in the data distribution or 
  in the relationships between variables over time.
  'drifter' calculates distances between variable distributions or 
  variable relations and identifies both types of drift. 
  Key functions are: 
  calculate_covariate_drift() checks distance between corresponding variables in two datasets,
  calculate_residuals_drift() checks distance between residual distributions for two models,
  calculate_model_drift() checks distance between partial dependency profiles for two models,
  check_drift() executes all checks against drift.
  'drifter' is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.",2019-05-31,Przemyslaw Biecek,https://ModelOriented.github.io/drifter/,TRUE,https://github.com/modeloriented/drifter,5335,5,2019-09-24T08:31:48Z,1067
driftR,"A tidy implementation of equations that correct for instrumental drift in 
    continuous water quality monitoring data.  There are many sources of water quality data 
    including private (ex: YSI instruments) and open source (ex: USGS and NDBC), each of 
    which are susceptible to errors/inaccuracies due to drift. This package allows the 
    user to correct their data using one or two standard reference values in a uniform, 
    reproducible way. The equations implemented are from Hasenmueller (2011)
    <doi:10.7936/K7N014KS>.",2018-06-13,Andrew Shaughnessy,https://github.com/shaughnessyar/driftR,TRUE,https://github.com/shaughnessyar/driftr,10082,4,2020-03-04T22:21:35Z,2520.5
DRomics,"Several functions are provided for dose-response (or concentration-response) characterization from omics data. 'DRomics' is especially dedicated to omics data obtained using a typical dose-response design, favoring a great number of tested doses (or concentrations, at least 5, and the more the better) rather than a great number of replicates (no need of three replicates). 'DRomics' provides functions 1) to check, normalize and or transform data, 2) to select monotonic or biphasic significantly responding items (e.g. probes, metabolites), 3) to choose the best-fit model among a predefined family of monotonic and biphasic models to describe each selected item 4) to derive a benchmark dose or concentration and a typology of response from each fitted curve. In the available version data are supposed to be single-channel microarray data in log2, RNAseq data in raw counts or already pretreated metabolomic data in log scale. For further details see Larras et al (2018) <DOI:10.1021/acs.est.8b04752>.",2019-09-16,Aurelie Siberchicot,https://github.com/aursiber/DRomics,TRUE,https://github.com/aursiber/dromics,6293,0,2020-02-18T14:56:13Z,NA
DRR,"An Implementation of Dimensionality Reduction
    via Regression using Kernel Ridge Regression.",2020-02-12,Guido Kraemer,https://github.com/gdkrmr/DRR,TRUE,https://github.com/gdkrmr/drr,891913,7,2020-02-12T13:07:59Z,127416.14285714286
drtmle,"Targeted minimum loss-based estimators of counterfactual means and
    causal effects that are doubly-robust with respect both to consistency and
    asymptotic normality (Benkeser et al (2017), <doi:10.1093/biomet/asx053>; MJ
    van der Laan (2014), <doi:10.1515/ijb-2012-0038>).",2020-01-09,David Benkeser,https://github.com/benkeser/drtmle,TRUE,https://github.com/benkeser/drtmle,11547,9,2020-01-10T14:51:52Z,1283
ds4psy,"All datasets and functions required for the examples and exercises of the book ""Data Science for Psychologists"" (by Hansjoerg Neth, Konstanz University, 2020), available at <https://bookdown.org/hneth/ds4psy/>. The book and course introduce principles and methods of data science to students of psychology and other biological or social sciences. The 'ds4psy' package primarily provides datasets, but also functions for data generation and manipulation (e.g., of text and time data) and graphics that are used in the book and its exercises. All functions included in 'ds4psy' are designed to be instructive and entertaining, rather than elegant or efficient. ",2020-05-06,Hansjoerg Neth,"https://bookdown.org/hneth/ds4psy/,
https://github.com/hneth/ds4psy/",TRUE,https://github.com/hneth/ds4psy,4820,3,2020-05-30T07:20:22Z,1606.6666666666667
DSAIDE,"Exploration of simulation models (apps) of various infectious disease transmission dynamics scenarios.
    The purpose of the package is to help individuals learn 
    about infectious disease epidemiology (ecology/evolution) from a dynamical systems perspective.
    All apps include explanations of the underlying models and instructions on what to do with the models. ",2020-01-09,Andreas Handel,"https://ahgroup.github.io/DSAIDE,
https://github.com/ahgroup/DSAIDE",TRUE,https://github.com/ahgroup/dsaide,16538,9,2020-05-22T19:47:13Z,1837.5555555555557
DSAIRM,"A collection of 'shiny' apps that allow for the simulation and
    exploration of various within-host immune response scenarios.
    The purpose of the package is to help individuals learn 
    about within-host infection and immune response modeling from a dynamical systems perspective.
    All apps include explanations of the underlying models and instructions on
    what to do with the models. 
    The development of this package was partially supported by NIH grant U19AI117891.",2019-07-08,Andreas Handel,"https://ahgroup.github.io/DSAIRM,
https://github.com/ahgroup/DSAIRM/",TRUE,https://github.com/ahgroup/dsairm,9473,7,2020-05-31T01:03:07Z,1353.2857142857142
dscore,"The D-score is a quantitative measure of child development. 
    The D-score follows the Rasch model. See Jacobusse, van Buuren and 
    Verkerk (2006) <doi:10.1002/sim.2351>. The user can convert 
    milestone scores from 19 assessment instruments into the D-score 
    and the DAZ (D-score adjusted for age). Several tools assist in 
    mapping milestone names into the 9-position Global Scale of Early 
    Development (GSED) convention. Supports calculation of the D-score 
    using 'dutch' <doi:10.1177/0962280212473300>, 
    'gcdg' <doi:10.1136/bmjgh-2019-001724> and 'gsed' conversion keys.
    The user can calculate DAZ using 'dutch' and 'gcdg' age-conditional 
    references.",2020-05-12,Stef van Buuren,"https://github.com/stefvanbuuren/dscore,
https://stefvanbuuren.name/dscore/,
https://stefvanbuuren.name/dbook1/",TRUE,https://github.com/stefvanbuuren/dscore,2967,2,2020-05-12T15:51:09Z,1483.5
DSI,"'DataSHIELD' is an infrastructure and series of R packages that 
    enables the remote and 'non-disclosive' analysis of sensitive research data. 
    This package defines the API that is to be implemented by 'DataSHIELD' compliant 
    data repositories.",2020-05-18,Yannick Marcon,http://datashield.ac.uk,TRUE,https://github.com/datashield/dsi,1500,0,2020-05-29T12:06:50Z,NA
DSLite,"'DataSHIELD' is an infrastructure and series of R packages that 
    enables the remote and 'non-disclosive' analysis of sensitive research data.
    This 'DataSHIELD Interface' implementation is for analyzing datasets living
    in the current R session. The purpose of this is primarily for lightweight
    'DataSHIELD' analysis package development.",2020-05-18,Yannick Marcon,http://www.datashield.ac.uk https://doi.org/10.1093/ije/dyu188,TRUE,https://github.com/datashield/dslite,1352,0,2020-05-18T12:20:27Z,NA
dsm,"Density surface modelling of line transect data. A Generalized
    Additive Model-based approach is used to calculate spatially-explicit estimates
    of animal abundance from distance sampling (also presence/absence and strip
    transect) data. Several utility functions are provided for model checking,
    plotting and variance estimation.",2020-04-22,David L. Miller,http://github.com/DistanceDevelopment/dsm,TRUE,https://github.com/distancedevelopment/dsm,29611,4,2020-06-08T13:27:31Z,7402.75
DSOpal,"'DataSHIELD' is an infrastructure and series of R packages that 
    enables the remote and 'non-disclosive' analysis of sensitive research data.
    This package is the 'DataSHIELD' interface implementation for 'Opal', which is
    the data integration application for biobanks by 'OBiBa'. Participant data, once
    collected from any data source, must be integrated and stored in a central
    data repository under a uniform model. 'Opal' is such a central repository.
    It can import, process, validate, query, analyze, report, and export data.
    'Opal' is the reference implementation of the 'DataSHIELD' infrastructure.",2020-05-18,Yannick Marcon,"https://www.obiba.org https://www.obiba.org/pages/products/opal/
http://www.datashield.ac.uk https://doi.org/10.1093/ije/dyu188",TRUE,https://github.com/datashield/dsopal,1056,0,2020-05-18T12:40:07Z,NA
DSpoty,"You can retrieve 'Spotify' API Information such as artists, albums, tracks, features tracks, recommendations or related artists.
    This package allows you to search all the information by name and also includes a distance based algorithm to find similar songs.
	More information: <https://developer.spotify.com/documentation/web-api/> .",2020-01-16,Alberto Almuiña,https://github.com/AlbertoAlmuinha/DSpoty,TRUE,https://github.com/albertoalmuinha/dspoty,3285,1,2020-04-27T18:23:10Z,3285
dsr,"A set of functions to compute and compare directly standardized rates, rate differences and ratios. A variety of user defined options for analysis (e.g confidence intervals) and formatting are included.",2019-08-23,Matthew Kumar,https://github.com/mattkumar/dsr,TRUE,https://github.com/mattkumar/dsr,11619,2,2019-08-23T14:38:29Z,5809.5
DSSAT,"The purpose of this package is to provide a comprehensive
    R interface to the Decision Support System for Agrotechnology
    Transfer Cropping Systems Model (DSSAT-CSM) documented by
    Jones et al (2003) <doi:10.1016/S1161-0301(02)00107-7>. The package
    provides cross-platform functions to read and write input files,
    run DSSAT-CSM, and read output files.",2020-05-18,Phillip D. Alderman,NA,TRUE,https://github.com/palderman/dssat,1603,6,2020-05-18T14:20:36Z,267.1666666666667
dssd,"Creates survey designs for distance sampling surveys. These
    designs can be assessed for various effort and coverage statistics.
    Once the user is satisfied with the design characteristics they can 
    generate a set of transects to use in their distance sampling survey.
    Many of the designs implemented in this R package were first made 
    available in our 'Distance' for Windows software and are detailed in 
    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, 
    ISBN-13: 978-0199225873). Find out more about estimating animal/plant 
    abundance with distance sampling at <http://distancesampling.org/>. ",2020-02-20,Laura Marshall,NA,TRUE,https://github.com/distancedevelopment/dssd,4872,0,2020-02-19T18:21:40Z,NA
dst,"Using the Theory of Belief Functions for evidence calculus. Basic probability assignments, or mass functions, can be defined on the subsets of a set of possible values and combined. A mass function can be extended to a larger frame. Marginalization, i.e. reduction to a smaller frame can also be done. These features can be combined to analyze small belief networks and take into account situations where information cannot be satisfactorily described by probability distributions.",2020-03-28,Claude Boivin,NA,TRUE,https://github.com/rapler/dst-1,19526,2,2020-04-05T15:09:40Z,9763
dstack,"A native R package that allows to publish, share and track revisions 
  of plots using your favorite plotting package, e.g. 'ggplot2'. It also provides
  a kind of interactivity for such plots by specifying certain parameters for any 
  specific plot view. See <https://docs.dstack.ai> for more information.",2020-04-09,Vitaly Khudobakhshov,https://dstack.ai,TRUE,https://github.com/dstackai/dstack-r,1327,1,2020-04-09T13:49:51Z,1327
DstarM,"A collection of functions to estimate parameters of a diffusion model via a D*M analysis. Build in models are: the Ratcliff diffusion model, the RWiener diffusion model, and Linear Ballistic Accumulator models. Custom models functions can be specified as long as they have a density function.",2018-05-18,Don van den Bergh,https://github.com/vandenman/DstarM,TRUE,https://github.com/vandenman/dstarm,14209,1,2020-01-03T10:33:44Z,14209
DT,"Data objects in R can be rendered as HTML tables using the
    JavaScript library 'DataTables' (typically via R Markdown or Shiny). The
    'DataTables' library has been included in this R package. The package name
    'DT' is an abbreviation of 'DataTables'.",2020-03-23,Yihui Xie,https://github.com/rstudio/DT,TRUE,https://github.com/rstudio/dt,5158894,408,2020-05-20T19:28:06Z,12644.348039215687
DtD,"Provides fast methods to work with Merton's distance to default 
  model introduced in Merton (1974) <doi:10.1111/j.1540-6261.1974.tb03058.x>. 
  The methods includes simulation and estimation of the parameters.",2020-02-11,Benjamin Christoffersen,NA,TRUE,https://github.com/boennecd/dtd,12252,1,2020-02-07T09:31:26Z,12252
dtplyr,"Provides a data.table backend for 'dplyr'. The goal of 'dtplyr' 
    is to allow you to write 'dplyr' code that is automatically translated to 
    the equivalent, but usually much faster, data.table code.",2020-01-23,Hadley Wickham,https://github.com/tidyverse/dtplyr,TRUE,https://github.com/tidyverse/dtplyr,642700,384,2020-05-28T13:54:09Z,1673.6979166666667
DTSg,"Basic time series functionalities such as listing of missing
    values, application of arbitrary aggregation as well as rolling (asymmetric)
    window functions and automatic detection of periodicity. As it is mainly
    based on 'data.table', it is fast and - in combination with the 'R6'
    package - offers reference semantics. In addition to its native R6
    interface, it provides an S3 interface inclusive an S3 wrapper method 
    generator for those who prefer the latter.",2020-06-09,Gerold Hepp,https://github.com/gisler/DTSg,TRUE,https://github.com/gisler/dtsg,6943,0,2020-06-09T18:44:08Z,NA
dttr2,"Manipulates date ('Date'), datetime ('POSIXct') and
    time ('hms') vectors.  Date/times are considered discrete and are
    floored whenever encountered.  Times are wrapped and time zones are
    maintained unless explicitly altered by the user.",2020-05-01,Joe Thorley,https://github.com/poissonconsulting/dttr2,TRUE,https://github.com/poissonconsulting/dttr2,6064,7,2020-05-29T17:39:19Z,866.2857142857143
dtwclust,"Time series clustering along with optimized techniques related
    to the Dynamic Time Warping distance and its corresponding lower bounds.
    Implementations of partitional, hierarchical, fuzzy, k-Shape and TADPole
    clustering are available. Functionality can be easily extended with
    custom distance measures and centroid definitions. Implementations of
    DTW barycenter averaging, a distance based on global alignment kernels,
    and the soft-DTW distance and centroid routines are also provided. 
    All included distance functions have custom loops optimized for the 
    calculation of cross-distance matrices, including parallelization support.
    Several cluster validity indices are included.",2019-12-11,Alexis Sarda-Espinosa,https://github.com/asardaes/dtwclust,TRUE,https://github.com/asardaes/dtwclust,123743,174,2020-03-23T13:40:55Z,711.1666666666666
dtwSat,"Provides an implementation of the Time-Weighted Dynamic Time
    Warping (TWDTW) method for land cover mapping using satellite image time series.
    TWDTW compares unclassified satellite image time series with a set of known
    temporal patterns (e.g. phenological cycles associated with the vegetation).
    Using 'dtwSat' the user can build temporal patterns for land cover types, apply
    the TWDTW analysis for satellite datasets, visualize the results of the time
    series analysis, produce land cover maps, create temporal plots for land cover
    change, and compute accuracy assessment metrics.",2020-03-03,Victor Maus,https://github.com/vwmaus/dtwSat/,TRUE,https://github.com/vwmaus/dtwsat,22001,79,2020-03-03T09:09:49Z,278.49367088607596
duawranglr,"Create shareable data sets from raw data files that
	     contain protected elements. Relying on master crosswalk
	     files that list restricted variables, package functions
	     warn users about possible violations of data usage
	     agreement and prevent writing protected elements.",2019-11-19,Benjamin Skinner,https://github.com/btskinner/duawranglr,TRUE,https://github.com/btskinner/duawranglr,7550,0,2019-11-19T22:00:52Z,NA
dupree,"Identifies code blocks that have a high level of similarity
  within a set of R files.",2020-04-21,Russ Hyde,https://github.com/russHyde/dupree,TRUE,https://github.com/russhyde/dupree,3082,8,2020-04-28T13:18:34Z,385.25
durmod,"Estimation of piecewise constant mixed proportional hazard competing risk model with NPMLE.
 The model is described in S. Gaure et al. (2007) <doi:10.1016/j.jeconom.2007.01.015>,
 J. Heckman and B. Singer (1984) <doi:10.2307/1911491>, and
 B.G. Lindsay (1983) <doi:10.1214/aos/1176346059>.",2020-03-30,Simen Gaure,https://github.com/sgaure/durmod,TRUE,https://github.com/sgaure/durmod,5793,0,2019-12-10T10:18:46Z,NA
DVHmetrics,"Functionality for analyzing dose-volume histograms (DVH)
        in radiation oncology: Read DVH text files, calculate DVH
        metrics as well as generalized equivalent uniform dose (gEUD),
        biologically effective dose (BED), equivalent dose in 2 Gy
        fractions (EQD2), normal tissue complication probability
        (NTCP), and tumor control probability (TCP). Show DVH
        diagrams, check and visualize quality assurance constraints
        for the DVH. Includes web-based graphical user interface.",2020-03-19,Daniel Wollschlaeger,https://github.com/dwoll/DVHmetrics/,TRUE,https://github.com/dwoll/dvhmetrics,21942,3,2020-04-30T06:53:25Z,7314
dynamac,"While autoregressive distributed lag (ARDL) models allow for extremely flexible dynamics, interpreting substantive significance of complex lag structures remains difficult. This package is designed to assist users in dynamically simulating and plotting the results of various ARDL models. It also contains post-estimation diagnostics, including a test for cointegration when estimating the error-correction variant of the autoregressive distributed lag model (Pesaran, Shin, and Smith 2001 <doi:10.1002/jae.616>).",2020-04-03,Soren Jordan,https://github.com/andyphilips/dynamac/,TRUE,https://github.com/andyphilips/dynamac,15059,2,2020-06-02T13:34:58Z,7529.5
dynamichazard,"Contains functions that lets you fit dynamic hazard models using 
  state space models. The first implemented model is described in Fahrmeir 
  (1992) <doi:10.1080/01621459.1992.10475232> and Fahrmeir (1994) 
  <doi:10.1093/biomet/81.2.317>. Extensions hereof are available where the  
  Extended Kalman filter is replaced by an unscented Kalman filter and other 
  options including particle filters. The implemented particle filters support
  more general state space models. ",2019-10-14,Benjamin Christoffersen,https://github.com/boennecd/dynamichazard,TRUE,https://github.com/boennecd/dynamichazard,34175,4,2019-10-14T08:18:54Z,8543.75
DynaRankR,"Provides functions for inferring longitudinal dominance hierarchies, which describe dominance relationships and their dynamics in a single latent hierarchy over time. Strauss & Holekamp (in press). ",2020-02-13,Eli D. Strauss,https://github.com/straussed/DynaRankR,TRUE,https://github.com/straussed/dynarankr,6205,1,2020-02-13T14:33:37Z,6205
dyndimred,"
  Provides a common interface for applying dimensionality reduction methods,
  such as Principal Component Analysis ('PCA'), Independent Component Analysis ('ICA'), diffusion maps, 
  Locally-Linear Embedding ('LLE'), t-distributed Stochastic Neighbor Embedding ('t-SNE'), 
  and Uniform Manifold Approximation and Projection ('UMAP'). 
  Has built-in support for sparse matrices.",2020-03-08,Robrecht Cannoodt (<https://orcid.org/0000-0003-3641-729X>,https://github.com/dynverse/dyndimred,TRUE,https://github.com/dynverse/dyndimred,5327,3,2020-02-24T13:51:34Z,1775.6666666666667
dynprog,"A domain-specific language for specifying translating recursions
    into dynamic-programming algorithms. See 
    <https://en.wikipedia.org/wiki/Dynamic_programming> for a description
    of dynamic programming.",2019-12-09,Thomas Mailund,https://github.com/mailund/dynprog,TRUE,https://github.com/mailund/dynprog,8182,11,2019-12-11T10:29:46Z,743.8181818181819
dynsurv,"Time-varying coefficient models for interval censored and
    right censored survival data including
    1) Bayesian Cox model with time-independent, time-varying or
    dynamic coefficients for right censored and interval censored data studied by
    Sinha et al. (1999) <doi:10.1111/j.0006-341X.1999.00585.x> and
    Wang et al. (2013) <doi:10.1007/s10985-013-9246-8>,
    2) Spline based time-varying coefficient Cox model for right censored data
    proposed by Perperoglou et al. (2006) <doi:10.1016/j.cmpb.2005.11.006>, and
    3) Transformation model with time-varying coefficients for right censored data
    using estimating equations proposed by
    Peng and Huang (2007) <doi:10.1093/biomet/asm058>.",2019-08-27,Wenjie Wang,https://github.com/wenjie2wang/dynsurv,TRUE,https://github.com/wenjie2wang/dynsurv,38836,5,2020-03-26T00:47:47Z,7767.2
dynutils,"
  Provides common functionality for the 'dynverse' packages. 
  'dynverse' is created to support the development, execution, and benchmarking of trajectory inference methods.
  For more information, check out <https://dynverse.org>.",2020-02-21,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,https://github.com/dynverse/dynutils,TRUE,https://github.com/dynverse/dynutils,16859,1,2020-02-21T12:58:51Z,16859
dynwrap,"Provides functionality to infer trajectories from single-cell data,
  represent them into a common format, and adapt them. Other biological information
  can also be added, such as cellular grouping, RNA velocity and annotation.
  Saelens et al. (2019) <doi:10.1038/s41587-019-0071-9>.",2020-05-14,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,https://github.com/dynverse/dynwrap,TRUE,https://github.com/dynverse/dynwrap,4297,10,2020-05-15T08:58:06Z,429.7
eaf,"Computation and visualization of the empirical attainment function (EAF) for the analysis of random sets in multi-criterion optimization. M. Lopez-Ibanez, L. Paquete, and T. Stuetzle (2010) <doi:10.1007/978-3-642-02538-9_9>. ",2020-03-05,Manuel López-Ibáñez,"http://lopez-ibanez.eu/eaftools,
https://github.com/MLopez-Ibanez/eaf",TRUE,https://github.com/mlopez-ibanez/eaf,49032,8,2020-05-26T17:45:17Z,6129
earlyR,"Implements a simple, likelihood-based estimation of the reproduction number (R0) using a branching process with a Poisson likelihood. This model requires knowledge of the serial interval distribution, and dates of symptom onsets. Infectiousness is determined by weighting R0 by the probability mass function of the serial interval on the corresponding day. It is a simplified version of the model introduced by Cori et al. (2013) <doi:10.1093/aje/kwt133>.",2017-12-06,Thibaut Jombart,http://www.repidemicsconsortium.org/earlyR,TRUE,https://github.com/reconhub/earlyr,13558,5,2019-06-10T09:31:29Z,2711.6
earthtide,"This is a port of 'Fortran ETERNA 3.4' 
             <http://igets.u-strasbg.fr/soft_and_tool.php> by H.G. Wenzel
             for calculating synthetic Earth tides using the 
             Hartmann and Wenzel (1994) <doi:10.1029/95GL03324> or 
             Kudryavtsev (2004) <doi:10.1007/s00190-003-0361-2> tidal catalogs. ",2020-03-13,Jonathan Kennel,https://github.com/jkennel/earthtide,TRUE,https://github.com/jkennel/earthtide,6549,5,2020-03-13T15:52:33Z,1309.8
easyalluvial,"Alluvial plots are similar to sankey diagrams and visualise categorical data 
    over multiple dimensions as flows. (Rosvall M, Bergstrom CT (2010) Mapping Change in 
    Large Networks. PLoS ONE 5(1): e8694. <doi:10.1371/journal.pone.0008694> 
    Their graphical grammar however is a bit more complex then that of a regular x/y 
    plots. The 'ggalluvial' package made a great job of translating that grammar into 
    'ggplot2' syntax and gives you many options to tweak the appearance of an alluvial 
    plot, however there still remains a multi-layered complexity that makes it difficult
    to use 'ggalluvial' for explorative data analysis. 'easyalluvial' provides a simple 
    interface to this package that allows you to produce a decent alluvial plot from any 
    dataframe in either long or wide format from a single line of code while also handling 
    continuous data. It is meant to allow a quick visualisation of entire dataframes 
    with a focus on different colouring options that can make alluvial plots a great 
    tool for data exploration. ",2020-05-07,Bjoern Koneswarakantha,https://github.com/erblast/easyalluvial,TRUE,https://github.com/erblast/easyalluvial,14320,39,2020-05-06T22:01:47Z,367.1794871794872
easyCODA,"Univariate and multivariate methods for compositional data 
    analysis, based on logratios. The package implements the approach in the
    book Compositional Data Analysis in Practice by Michael Greenacre (2018),
    where accent is given to simple pairwise logratios. Selection can be made
    of logratios that account for a maximum percentage of logratio variance.
    Various multivariate analyses of logratios are included in the package. ",2019-03-10,Michael Greenacre,https://github.com/michaelgreenacre/CODAinPractice/,TRUE,https://github.com/michaelgreenacre/codainpractice,11102,5,2020-04-08T08:54:32Z,2220.4
easycsv,"Allows users to easily read multiple comma separated tables and create a data frame under the same name.
    Is able to read multiple comma separated tables from a local directory, a zip file or a zip file on a remote directory. ",2018-05-21,Dror Bogin,https://github.com/bogind/easycsv,TRUE,https://github.com/bogind/easycsv,15120,4,2019-09-23T08:01:28Z,3780
easyr,"Makes difficult operations easy. Includes these types of functions: 
    shorthand, type conversion, data wrangling, and workflow. 
    Also includes some helpful data objects: NA strings, U.S. state list, color blind charting colors. 
    Built and shared by Oliver Wyman Actuarial Consulting. Accepting proposed contributions through GitHub.",2020-06-02,Bryce Chamberlain,https://github.com/oliver-wyman-actuarial/easyr,TRUE,https://github.com/oliver-wyman-actuarial/easyr,3358,8,2020-06-05T17:44:40Z,419.75
easySdcTable,"The main function, ProtectTable(), performs table suppression according to a 
 frequency rule with a data set as the only required input. Within this function, 
 protectTable(), protectLinkedTables() or runArgusBatchFile() in package 'sdcTable' is called. 
 Lists of level-hierarchy (parameter 'dimList') and other required input to these functions 
 are created automatically. 
 The function, PTgui(), starts a graphical user interface based on the shiny package.",2020-04-04,Øyvind Langsrud,https://github.com/statisticsnorway/easySdcTable,TRUE,https://github.com/statisticsnorway/easysdctable,15719,0,2020-04-30T06:44:53Z,NA
ebirdst,"Tools to download, map, plot and analyze eBird
    Status and Trends data
    (<https://ebird.org/science/status-and-trends>). eBird
    (<https://ebird.org>) is a global database of bird observations
    collected by citizen scientists. eBird Status and Trends uses these
    data to analyze continental bird abundances, range boundaries,
    habitats, and trends.",2020-03-23,Matthew Strimas-Mackey,https://github.com/CornellLabofOrnithology/ebirdst,TRUE,https://github.com/cornelllabofornithology/ebirdst,6370,24,2020-05-03T01:58:02Z,265.4166666666667
EBMAforecast,Create forecasts from multiple predictions using ensemble Bayesian model averaging (EBMA). EBMA models can be estimated using an expectation maximization (EM) algorithm or as fully Bayesian models via Gibbs sampling.,2020-05-20,Florian M. Hollenbach,<https://github.com/fhollenbach/EBMA/>,TRUE,https://github.com/fhollenbach/ebma,17755,0,2020-05-20T11:14:29Z,NA
echarts4r,"Easily create interactive charts by leveraging the 'Echarts Javascript' library which includes
    34 chart types, themes, 'Shiny' proxies and animations.",2019-07-18,John Coene,http://echarts4r.john-coene.com/,TRUE,https://github.com/johncoene/echarts4r,45837,255,2020-06-09T17:04:46Z,179.75294117647059
eChem,"Simulates cyclic voltammetry, linear-sweep voltammetry 
    (both with and without stirring of the solution), and single-pulse 
    and double-pulse chronoamperometry and chronocoulometry 
    experiments using the implicit finite difference method outlined in 
    Gosser (1993, ISBN: 9781560810261) and in Brown (2015) 
    <doi:10.1021/acs.jchemed.5b00225>. Additional functions provide 
    ways to display and to examine the results of these simulations.
    The primary purpose of this package is to provide tools for
    use in courses in analytical chemistry.",2018-07-01,David Harvey,https://github.com/dtharvey/eChem,TRUE,https://github.com/dtharvey/echem,7418,2,2019-07-06T12:23:44Z,3709
echo.find,"Provides a function (echo_find()) designed to find rhythms 
    from data using extended harmonic oscillators. For more information,
    see H. De los Santos et al. (2020) <doi:10.1093/bioinformatics/btz617> .",2020-05-28,Hannah De los Santos,https://github.com/delosh653/ECHO,TRUE,https://github.com/delosh653/echo,11255,3,2020-05-13T20:12:44Z,3751.6666666666665
echor,"An R interface to United States Environmental 
    Protection Agency (EPA) Environmental Compliance 
    History Online ('ECHO') Application Program Interface
    (API). 'ECHO' provides information about EPA permitted 
    facilities, discharges, and other reporting info 
    associated with permitted entities. Data are obtained 
    from <https://echo.epa.gov/>. ",2020-01-29,Michael Schramm,NA,TRUE,https://github.com/mps9506/echor,10430,4,2020-01-31T19:48:56Z,2607.5
ecmwfr,"Programmatic interface to the European Centre for Medium-Range
    Weather Forecasts dataset web services (ECMWF; <https://www.ecmwf.int/>)
    and Copernicus's Climate Data Store (CDS; 
    <https://cds.climate.copernicus.eu>). Allows for easy downloads of weather 
    forecasts and climate reanalysis data in R.",2020-05-17,Koen Hufkens,https://github.com/khufkens/ecmwfr,TRUE,https://github.com/khufkens/ecmwfr,11440,41,2020-06-05T13:51:30Z,279.0243902439024
EcoDiet,"Biotracers and stomach content analyses are combined in a Bayesian hierarchical model
    to estimate a probabilistic topology matrix (all trophic link probabilities) and a diet matrix 
    (all diet proportions).
    The package relies on the JAGS software and the 'rjags' package to run a Markov chain Monte Carlo 
    approximation of the different variables.",2020-03-05,Pierre-Yves Hernvann,https://github.com/pyhernvann/EcoDiet,TRUE,https://github.com/pyhernvann/ecodiet,1238,1,2020-03-11T14:11:16Z,1238
ecodist,"Dissimilarity-based analysis functions including ordination and Mantel test functions, intended for use with spatial and community data. The original package description is in Goslee and Urban (2007) <doi:10.18637/jss.v022.i07>, with further statistical detail in Goslee (2010) <doi:10.1007/s11258-009-9641-0>.",2020-04-07,Sarah Goslee,NA,TRUE,https://github.com/phiala/ecodist,178635,2,2020-04-02T18:24:45Z,89317.5
EcoGenetics,"Management and exploratory analysis of spatial data in landscape genetics. Easy integration of information from multiple sources with ""ecogen"" objects.",2020-05-24,Leandro Roser,"https://github.com/cran/EcoGenetics,
https://leandroroser.github.io/EcoGenetics-Tutorial",TRUE,https://github.com/cran/ecogenetics,28606,1,2020-05-24T14:20:17Z,28606
ECoL,"Provides measures to characterize the complexity of classification 
    and regression problems based on aspects that quantify the linearity of the 
    data, the presence of informative feature, the sparsity and dimensionality 
    of the datasets. This package provides bug fixes, generalizations and 
    implementations of many state of the art measures. The measures are 
    described in the papers: Lorena et al. (2019) <doi:10.1145/3347711> and 
    Lorena et al. (2018) <doi:10.1007/s10994-017-5681-1>.",2019-11-05,Luis Garcia,https://github.com/lpfgarcia/ECoL/,TRUE,https://github.com/lpfgarcia/ecol,9782,29,2019-11-04T23:11:30Z,337.3103448275862
ecolottery,"Coalescent-Based Simulation of Ecological Communities as proposed
    by Munoz et al. (2017) <doi:10.13140/RG.2.2.31737.26728>. The package includes
    a tool for estimating parameters of community assembly by using Approximate 
    Bayesian Computation.",2017-07-03,François Munoz,https://github.com/frmunoz/ecolottery,TRUE,https://github.com/frmunoz/ecolottery,10053,9,2020-05-28T09:00:20Z,1117
EcoNetGen,"Randomly generate a wide range of interaction networks with
             specified size, average degree, modularity, and topological
             structure. Sample nodes and links from within simulated networks
             randomly, by degree, by module, or by abundance. Simulations
             and sampling routines are implemented in 'FORTRAN', providing
             efficient generation times even for large networks. Basic
             visualization methods also included. Algorithms implemented
             here are described in de Aguiar et al. (2017) <arXiv:1708.01242>.",2019-07-13,Carl Boettiger,https://github.com/cboettig/EcoNetGen,TRUE,https://github.com/cboettig/econetgen,11495,7,2019-07-12T15:17:56Z,1642.142857142857
economiccomplexity,"A wrapper of different methods from Linear Algebra for the equations
  introduced in The Atlas of Economic Complexity and related literature. This
  package provides standard matrix and graph output that can be used seamlessly
  with other packages.",2020-02-20,Mauricio Vargas,https://pachamaltese.github.io/economiccomplexity,TRUE,https://github.com/pachamaltese/economiccomplexity,5306,13,2020-02-20T03:38:30Z,408.15384615384613
ECOSolveR,"R interface to the Embedded COnic Solver (ECOS), an efficient
	     and robust C library for convex problems. Conic and equality
	     constraints can be specified in addition to integer and
	     boolean variable constraints for mixed-integer problems. This
	     R interface is inspired by the python interface and has
	     similar calling conventions.",2019-11-06,Balasubramanian Narasimhan,https://bnaras.github.io/ECOSolveR,TRUE,https://github.com/bnaras/ecosolver,48641,5,2019-11-05T19:47:05Z,9728.2
ecospat,"Collection of R functions and data sets for the support of spatial ecology analyses with a focus on pre, core and post modelling analyses of species distribution, niche quantification and community assembly. Written by current and former members and collaborators of the ecospat group of Antoine Guisan, Department of Ecology and Evolution (DEE) and Institute of Earth Surface Dynamics (IDYST), University of Lausanne, Switzerland. Read Di Cola et al. (2016) <doi:10.1111/ecog.02671> for details.",2020-03-25,Olivier Broennimann,http://www.unil.ch/ecospat/home/menuguid/ecospat-resources/tools.html,TRUE,https://github.com/ecospat/ecospat,38763,12,2020-03-23T08:08:05Z,3230.25
ecr,"Framework for building evolutionary algorithms for both single- and multi-objective continuous or discrete optimization problems. A set of predefined evolutionary building blocks and operators is included. Moreover, the user can easily set up custom objective functions, operators, building blocks and representations sticking to few conventions. The package allows both a black-box approach for standard tasks (plug-and-play style) and a much more flexible white-box approach where the evolutionary cycle is written by hand.",2017-07-10,Jakob Bossek,https://github.com/jakobbossek/ecr2,TRUE,https://github.com/jakobbossek/ecr2,16771,24,2020-03-24T13:26:58Z,698.7916666666666
edbuildmapr,"Import US Census Bureau, Education Demographic and Geographic Estimates Program,
  Composite School District Boundaries Files for 2013-2017 with the option to attach the 'EdBuild'
  master dataset of school district finance, student demographics, and community economic
  indicators for every school district in the United States. The master dataset is built
  from the US Census, Annual Survey of School System Finances (F33) and joins data from the
  National Center for Education Statistics, Common Core of Data; the US Census, Small Area
  Income and Poverty Estimates; and the US Census, Education Demographic and Geographic
  Estimates. Additional functions in the package create a dataset of all pairs of school
  district neighbors as either a dataframe or a shapefile and create formatted maps of
  selected districts at the state or neighbor level, symbolized by a selected variable
  in the 'EdBuild' master dataset. For full details about 'EdBuild' data processing please
  see 'EdBuild' (2019) <https://edbuild.org/content/dividing-lines/main/methodology>. ",2020-04-16,Megan Brodzik,"https://github.com/EdBuild/edbuildmapr, https://edbuild.github.io/",TRUE,https://github.com/edbuild/edbuildmapr,1646,1,2020-04-16T17:11:37Z,1646
eddi,"Finds and downloads raw Evaporative Demand Drought
    Index (EDDI) data, then reads the data into 'R' using the 'raster'
    package. The EDDI product detects drought at multiple time scales,
    from weekly ""flash droughts"" to long-term droughts. More information
    about the EDDI data product can be found at
    <https://www.esrl.noaa.gov/psd/eddi/>.",2019-05-22,Max Joseph,https://github.com/earthlab/eddi,TRUE,https://github.com/earthlab/eddi,4350,0,2019-12-17T17:01:01Z,NA
eddington,"Compute a cyclist's Eddington number, including efficiently
    computing cumulative E over a vector. A cyclist's Eddington number
    <https://en.wikipedia.org/wiki/Arthur_Eddington#Eddington_number_for_cycling>
    is the maximum number satisfying the condition such that a cyclist has
    ridden E miles or greater in E days. The algorithm in this package is an
    improvement over the conventional approach because both summary statistics
    and cumulative statistics can be computed in linear time, since it does not
    require initial sorting of the data. These functions may also be used for
    computing h-indices for authors, a metric described by Hirsch (2005)
    <doi:10.1073/pnas.0507655102>. Both are specific applications of computing
    the side length of a Durfee square 
    <https://en.wikipedia.org/wiki/Durfee_square>.",2020-03-24,Paul Egeler,https://github.com/pegeler/eddington2,TRUE,https://github.com/pegeler/eddington2,1105,1,2020-06-06T07:24:38Z,1105
edeaR,"Exploratory and descriptive analysis of event based data. Provides methods for describing and selecting process data, and for preparing event log data for process mining. Builds on the S3-class for event logs implemented in the package 'bupaR'.",2020-02-25,Gert Janssenswillen,"https://www.bupar.net, https://github.com/bupaverse/edeaR",TRUE,https://github.com/bupaverse/edear,44900,2,2020-04-30T12:18:35Z,22450
edina,"Perform a Bayesian estimation of the exploratory 
    deterministic input, noisy and gate (EDINA)
    cognitive diagnostic model described by Chen et al. (2018)
    <doi:10.1007/s11336-017-9579-4>.",2020-03-25,James Joseph Balamuta,https://github.com/tmsalab/edina,TRUE,https://github.com/tmsalab/edina,1221,0,2020-03-24T14:57:22Z,NA
editData,"An 'RStudio' addin for editing a 'data.frame' or a 'tibble'. You can delete, add or update a 'data.frame'
    without coding. You can get resultant data as a 'data.frame'. In the package, modularized 'shiny' app codes are provided. 
    These modules are intended for reuse across applications.",2017-10-07,Keon-Woong Moon,https://github.com/cardiomoon/editData,TRUE,https://github.com/cardiomoon/editdata,37902,10,2020-03-06T05:46:48Z,3790.2
EDOIF,"A non-parametric framework based on  estimation statistics principle. Its main purpose is to  infer orders of empirical distributions from different categories based on a probability of finding a value in one distribution that is greater than an expectation of another distribution. Given a set of ordered-pair of real-category values the framework is capable of 1) inferring orders of  domination  of  categories  and  representing  orders  in  the form of a graph; 2) estimating  magnitude  of  difference  between  a  pair  of categories in forms of mean-difference confidence intervals; and 3) visualizing  domination  orders  and  magnitudes  of  difference of categories. The publication of this package is at Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok, and Suttipong Thajchayapong (2019) <arXiv:1911.06723>.",2019-12-02,Chainarong Amornbunchornvej,https://github.com/DarkEyes/EDOIF,TRUE,https://github.com/darkeyes/edoif,2596,0,2020-03-16T04:03:39Z,NA
edwards97,"Implements the Edwards (1997) <doi:10.1002/j.1551-8833.1997.tb08229.x>
    Langmuir-based semi-empirical coagulation model, which predicts the concentration
    of organic carbon remaining in water after treatment with an Al- or Fe-based
    coagulant. Data and methods are provided to optimise empirical coefficients.",2020-03-23,Dewey Dunnington,"https://paleolimbot.github.io/edwards97/,
https://github.com/paleolimbot/edwards97",TRUE,https://github.com/paleolimbot/edwards97,1073,0,2020-03-20T16:37:07Z,NA
eechidna,"Data from the seven Australian Federal Elections (House of
    Representatives) between 2001 and 2019, and from the four Australian
    Censuses over the same period. Includes tools for visualizing and
    analysing the data, as well as imputing Census data for years in
    which a Census does not occur. This package incorporates
    data that is copyright Commonwealth of Australia (Australian
    Electoral Commission and Australian Bureau of Statistics) 2019.",2019-11-08,Jeremy Forbes,https://github.com/ropenscilabs/eechidna,TRUE,https://github.com/ropenscilabs/eechidna,13841,30,2020-04-19T07:36:19Z,461.3666666666667
eemR,"Provides various tools for preprocessing Emission-Excitation-Matrix (EEM) for Parallel Factor Analysis (PARAFAC). Different
  methods are also provided to calculate common metrics such as humification index and fluorescence index.",2019-06-26,Philippe Massicotte,https://github.com/PMassicotte/eemR,TRUE,https://github.com/pmassicotte/eemr,18779,10,2020-03-19T14:24:53Z,1877.9
eeptools,"Collection of convenience functions to make working with
    administrative records easier and more consistent. Includes functions to
    clean strings, and identify cut points. Also includes three example data 
    sets of administrative education records for learning how to process records 
    with errors.",2020-05-02,Jared E. Knowles,https://github.com/jknowles/eeptools,TRUE,https://github.com/jknowles/eeptools,83218,25,2020-04-02T15:24:42Z,3328.72
EffectLiteR,"Use structural equation modeling to estimate average and
    conditional effects of a treatment variable on an outcome variable, taking into
    account multiple continuous and categorical covariates.",2019-12-10,Axel Mayer,https://github.com/amayer2010/EffectLiteR,TRUE,https://github.com/amayer2010/effectliter,21970,3,2020-01-17T10:06:18Z,7323.333333333333
effectsize,"Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see support list of insight; Lüdecke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation and conversion of indices such as Cohen's d, r, odds, etc.",2020-05-19,Mattan S. Ben-Shachar,https://easystats.github.io/effectsize,TRUE,https://github.com/easystats/effectsize,132818,76,2020-06-09T19:38:50Z,1747.6052631578948
effsize,"A collection of functions to compute the standardized 
  effect sizes for experiments (Cohen d, Hedges g, Cliff delta, Vargha-Delaney A). 
  The computation algorithms have been optimized to allow efficient computation even 
  with very large data sets.",2020-04-09,Marco Torchiano,http://github.com/mtorchiano/effsize/,TRUE,https://github.com/mtorchiano/effsize,170843,92,2020-04-09T21:05:02Z,1856.9891304347825
egor,"Tools for importing, analyzing and visualizing ego-centered
    network data. Supports several data formats, including the export formats of
    'EgoNet', 'EgoWeb 2.0' and 'openeddi'. An interactive (shiny) app for the
    intuitive visualization of ego-centered networks is provided. Also included
    are procedures for creating and visualizing Clustered Graphs 
    (Lerner 2008 <DOI:10.1109/PACIFICVIS.2008.4475458>).",2020-03-03,Till Krenz,"https://github.com/tilltnet/egor, https://tilltnet.github.io/egor/",TRUE,https://github.com/tilltnet/egor,10357,10,2020-06-03T18:12:10Z,1035.7
EGRETci,"Collection of functions to evaluate uncertainty of results from
    water quality analysis using the Weighted Regressions on Time Discharge and
    Season (WRTDS) method. This package is an add-on to the EGRET package that
    performs the WRTDS analysis. The WRTDS modeling
    method was initially introduced and discussed in Hirsch et al. (2010) <doi:10.1111/j.1752-1688.2010.00482.x>,
    and expanded in Hirsch and De Cicco (2015) <doi:10.3133/tm4A10>. The 
    paper describing the uncertainty and confidence interval calculations 
    is Hirsch et al. (2015) <doi:10.1016/j.envsoft.2015.07.017>.",2019-03-15,Laura DeCicco,https://github.com/USGS-R/EGRETci,TRUE,https://github.com/usgs-r/egretci,18193,5,2019-12-20T17:36:24Z,3638.6
eGST,"Genetic predisposition for complex traits is often manifested through multiple tissues of interest at different time points in the development. As an example, the genetic predisposition for obesity could be manifested through inherited variants that control metabolism through regulation of genes expressed in the brain and/or through the control of fat storage in the adipose tissue by dysregulation of genes expressed in adipose tissue. We present a method eGST (eQTL-based genetic subtyper) that integrates tissue-specific eQTLs with GWAS data for a complex trait to probabilistically assign a tissue of interest to the phenotype of each individual in the study. eGST estimates the posterior probability that an individual's phenotype can be assigned to a tissue based on individual-level genotype data of tissue-specific eQTLs and marginal phenotype data in a genome-wide association study (GWAS) cohort. Under a Bayesian framework of mixture model, eGST employs a maximum a posteriori (MAP) expectation-maximization (EM) algorithm to estimate the tissue-specific posterior probability across individuals. Methodology is available from: A Majumdar, C Giambartolomei, N Cai, MK Freund, T Haldar, T Schwarz, J Flint, B Pasaniuc (2019) <doi:10.1101/674226>.",2019-07-02,Arunabha Majumdar,https://github.com/ArunabhaCodes/eGST,TRUE,https://github.com/arunabhacodes/egst,3992,0,2019-07-01T06:43:24Z,NA
eha,"Sampling of risk sets in Cox regression, selections in 
        the Lexis diagram, bootstrapping. Parametric proportional 
        hazards fitting with left truncation and right censoring for 
        common families of distributions, piecewise constant hazards, 
        and discrete models. Parametric accelerated failure time models 
        for left truncated and right censored data.",2020-04-01,Göran Broström,https://goranbrostrom.github.io/eha/,TRUE,https://github.com/goranbrostrom/eha,165326,1,2020-03-31T20:11:40Z,165326
ehelp,"By overloading the R help() function, this package allows users to use ""docstring"" style comments within their own defined functions. The package also provides additional functions to mimic the R basic example() function and the prototyping of packages.",2020-04-05,Marcelo Ponce,https://github.com/mponce0/eHelp,TRUE,https://github.com/mponce0/ehelp,3567,1,2020-04-12T23:45:46Z,3567
EHRtemporalVariability,"Functions to delineate temporal dataset shifts in Electronic Health 
             Records through the projection and visualization of dissimilarities 
             among data temporal batches. This is done through the estimation of 
             data statistical distributions over time and their projection in 
             non-parametric statistical manifolds, uncovering the patterns of the 
             data latent temporal variability. 'EHRtemporalVariability' is 
             particularly suitable for multi-modal data and categorical variables 
             with a high number of values, common features of biomedical data where 
             traditional statistical process control or time-series methods may not 
             be appropriate. 'EHRtemporalVariability' allows you to explore and 
             identify dataset shifts through visual analytics formats such as 
             Data Temporal heatmaps and Information Geometric Temporal (IGT) plots. 
             An additional 'EHRtemporalVariability' Shiny app can be used to load 
             and explore the package results and even to allow the use of these 
             functions to those users non-experienced in R coding. Preprint published 
             in medRxiv (Sáez et al. 2020) <doi:10.1101/2020.04.07.20056564>.",2020-05-25,Carlos Sáez,http://github.com/hms-dbmi/EHRtemporalVariability,TRUE,https://github.com/hms-dbmi/ehrtemporalvariability,6641,3,2020-05-25T08:50:18Z,2213.6666666666665
EIAdata,"An R wrapper to allow the user to query categories and Series IDs, and import data, from the EIA's API <https://www.eia.gov/opendata/>.",2020-05-12,Matthew Brigida and others,https://github.com/Matt-Brigida/EIAdata,TRUE,https://github.com/matt-brigida/eiadata,24362,11,2020-05-12T18:04:26Z,2214.7272727272725
eicm,"Model fitting and species biotic interaction network topology selection for explicit
  interaction community models. Explicit interaction community models are an extension of binomial
  linear models for joint modelling of species communities, that incorporate both the effects of
  species biotic interactions and the effects of missing covariates. Species interactions are modelled
  as direct effects of each species on each of the others, and are estimated alongside the effects of
  missing covariates, modelled as latent factors. The package includes a penalized maximum likelihood
  fitting function, and a genetic algorithm for selecting the most parsimonious species interaction
  network topology.",2020-03-26,Miguel Porto,https://github.com/miguel-porto/eicm,TRUE,https://github.com/miguel-porto/eicm,1103,2,2020-04-01T15:18:08Z,551.5
eikosograms,"An eikosogram (ancient Greek for probability picture) divides the unit square 
    into rectangular regions whose areas, sides, and widths, represent various probabilities
    associated with the values of one or more categorical variates.
    Rectangle areas are joint probabilities, widths are always marginal (though possibly joint 
    margins, i.e. marginal joint distributions of two or more variates), and heights of rectangles
    are always conditional probabilities.
    Eikosograms embed the rules of probability and are useful for introducing elementary probability
    theory, including axioms, marginal, conditional, and joint probabilities, and their
    relationships (including Bayes theorem as a completely trivial consequence).
    They are markedly superior to Venn diagrams for this purpose, especially in distinguishing
    probabilistic independence, mutually exclusive events, coincident events, and associations.
    They also are useful for identifying and understanding conditional independence structure.
    As data analysis tools, eikosograms display categorical data in a manner similar
    to Mosaic plots, especially when only two variates are involved (the only case in which
    they are essentially identical, though eikosograms purposely disallow spacing between rectangles).
    Unlike Mosaic plots, eikosograms do not alternate axes as each new categorical variate 
    (beyond two) is introduced.  
    Instead, only one categorical variate, designated the ""response"", presents on the vertical axis 
    and all others, designated the ""conditioning"" variates, appear on the horizontal. 
    In this way, conditional probability appears only as height and marginal probabilities as widths. 
    The eikosogram is therefore much better suited to a response model analysis (e.g. logistic model)
    than is a Mosaic plot.  
    Mosaic plots are better suited to log-linear style modelling as in discrete multivariate analysis.
    Of course, eikosograms are also suited to discrete multivariate analysis with each variate in turn 
    appearing as the response. 
    This makes it better suited than Mosaic plots to discrete graphical models based on conditional 
    independence graphs (i.e. ""Bayesian Networks"" or ""BayesNets"").  
    The eikosogram and its superiority to Venn diagrams in teaching probability is described in
    W.H. Cherry and R.W. Oldford (2003) <https://math.uwaterloo.ca/~rwoldfor/papers/eikosograms/paper.pdf>, 
    its value in exploring conditional independence structure and relation to graphical and log-linear models
    is described in R.W. Oldford (2003) <https://math.uwaterloo.ca/~rwoldfor/papers/eikosograms/independence/paper.pdf>,
    and a number of problems, puzzles, and paradoxes that are easily explained with eikosograms are given in
    R.W. Oldford (2003) <https://math.uwaterloo.ca/~rwoldfor/papers/eikosograms/examples/paper.pdf>.",2018-08-22,Wayne Oldford,https://github.com/rwoldford/eikosograms,TRUE,https://github.com/rwoldford/eikosograms,7750,2,2019-07-20T15:30:05Z,3875
einet,"Methods and utilities for causal emergence.
    Used to explore and compute various information theory metrics for networks, such as effective information, effectiveness and causal emergence.",2020-04-23,Travis Byrum,https://github.com/travisbyrum/einet,TRUE,https://github.com/travisbyrum/einet,643,1,2020-05-17T21:07:59Z,643
EIX,"Structure mining from 'XGBoost' and 'LightGBM' models.
    Key functionalities of this package cover: visualisation of tree-based ensembles models,
    identification of interactions, measuring of variable importance,
    measuring of interaction importance, explanation of single prediction 
    with break down plots (based on 'xgboostExplainer' and 'iBreakDown' packages). 
    To download the 'LightGBM' use the following link: <https://github.com/Microsoft/LightGBM>.
    'EIX' is a part of the 'DrWhy.AI' universe.",2020-02-18,Ewelina Karbowiak,https://github.com/ModelOriented/EIX,TRUE,https://github.com/modeloriented/eix,6115,9,2020-02-18T12:21:23Z,679.4444444444445
eixport,"Emissions are the mass of pollutants released into the atmosphere. Air quality models need emissions data, with spatial and temporal distribution, to represent air pollutant concentrations. This package, eixport, creates inputs for the air quality models 'WRF-Chem' Grell et al (2005) <doi:10.1016/j.atmosenv.2005.04.027>, 'BRAMS-SPM' Freitas et al (2005) <doi:10.1016/j.atmosenv.2005.07.017> and 'RLINE' Snyder et al (2013) <doi:10.1016/j.atmosenv.2013.05.074>. See the eixport website (<https://atmoschem.github.io/eixport/>) for more information, documentations and examples. More details in Ibarra-Espinosa et al (2018) <doi.org/10.21105/joss.00607>.",2020-04-16,Sergio Ibarra-Espinosa,https://atmoschem.github.io/eixport,TRUE,https://github.com/atmoschem/eixport,11002,9,2020-04-07T18:54:26Z,1222.4444444444443
elastic,"Connect to 'Elasticsearch', a 'NoSQL' database built on the 'Java'
    Virtual Machine. Interacts with the 'Elasticsearch' 'HTTP' API
    (<https://www.elastic.co/products/elasticsearch>), including functions for
    setting connection details to 'Elasticsearch' instances, loading bulk data,
    searching for documents with both 'HTTP' query variables and 'JSON' based body
    requests. In addition, 'elastic' provides functions for interacting with API's
    for 'indices', documents, nodes, clusters, an interface to the cat API, and
    more.",2020-01-11,Scott Chamberlain,"https://docs.ropensci.org/elastic (website),
https://github.com/ropensci/elastic",TRUE,https://github.com/ropensci/elastic,70994,211,2020-06-01T19:15:47Z,336.46445497630333
elasticsearchr,"A lightweight R interface to 'Elasticsearch' - a NoSQL search-engine and 
    column store database (see <https://www.elastic.co/products/elasticsearch> for more 
    information). This package implements a simple Domain-Specific Language (DSL) for indexing, 
    deleting, querying, sorting and aggregating data using 'Elasticsearch'.",2019-07-30,Alex Ioannides,https://github.com/alexioannides/elasticsearchr,TRUE,https://github.com/alexioannides/elasticsearchr,22553,45,2019-07-30T20:36:01Z,501.1777777777778
electionsBR,"Offers a set of functions to easily download and clean 
    Brazilian electoral data from the Superior Electoral Court website. 
    Among others, the package retrieves data on local and
    federal elections for all positions (city councilor, mayor, state deputy,
    federal deputy, governor, and president) aggregated by
    state, city, and electoral zones. ",2019-07-09,Denisson Silva,http://electionsbr.com/,TRUE,https://github.com/silvadenisson/electionsbr,16637,34,2019-07-16T19:45:03Z,489.3235294117647
electivity,"Provides all electivity algorithms (including Vanderploeg and Scavia 
    electivity) that were examined in Lechowicz (1982) <doi:10.1007/BF00349007>, 
    plus the example data that were provided for moth resource utilisation.",2019-08-20,Desi Quintans,https://github.com/DesiQuintans/electivity,TRUE,https://github.com/desiquintans/electivity,3502,0,2019-08-21T22:03:54Z,NA
elementR,Aims to facilitate the reduction of elemental microchemistry data from solid-phase LAICPMS analysis (laser ablation inductive coupled plasma mass spectrometry). The 'elementR' package provides a reactive and user friendly interface (based on a 'shiny' application) and a set of 'R6' classes for conducting all steps needed for an optimal data reduction while leaving maximum control for user.,2018-05-03,Charlotte Sirot,https://github.com/charlottesirot/elementR,TRUE,https://github.com/charlottesirot/elementr,17187,7,2020-05-26T09:04:39Z,2455.285714285714
elevatr,"Several web services are available that provide access to elevation
             data. This package provides access to several of those services and 
             returns elevation data either as a SpatialPointsDataFrame from 
             point elevation services or as a raster object from raster 
             elevation services.  Currently, the package supports access to the
             Amazon Web Services Terrain Tiles <https://aws.amazon.com/public-datasets/terrain/> 
             and the USGS Elevation Point Query Service <http://ned.usgs.gov/epqs/>.",2018-11-28,Jeffrey Hollister,https://www.github.com/jhollist/elevatr,TRUE,https://github.com/jhollist/elevatr,24078,80,2020-05-21T20:44:40Z,300.975
elfDistr,"Density, distribution function, quantile function
    and random generation for the Kumaraswamy Complementary Weibull
    Geometric (Kw-CWG) lifetime probability distribution proposed
    in Afify, A.Z. et al (2017) <doi:10.1214/16-BJPS322>.",2019-10-07,Matheus H. J. Saldanha,https://github.com/matheushjs/elfDistr,TRUE,https://github.com/matheushjs/elfdistr,3024,0,2020-01-24T08:44:12Z,NA
ellipsis,"The ellipsis is a powerful tool for extending functions. Unfortunately 
    this power comes at a cost: misspelled arguments will be silently ignored. 
    The ellipsis package provides a collection of functions to catch problems
    and alert the user.",2020-05-15,Hadley Wickham,"https://ellipsis.r-lib.org, https://github.com/r-lib/ellipsis",TRUE,https://github.com/r-lib/ellipsis,12002228,114,2020-05-15T12:31:31Z,105282.70175438597
elliptic,"
 A suite of elliptic and related functions including Weierstrass and
 Jacobi forms.  Also includes various tools for manipulating and
 visualizing complex functions.",2019-03-14,Robin K. S. Hankin,https://github.com/RobinHankin/elliptic.git,TRUE,https://github.com/robinhankin/elliptic,489612,0,2020-02-16T04:43:51Z,NA
elo,"A flexible framework for calculating Elo ratings and resulting
    rankings of any two-team-per-matchup system (chess, sports leagues, 'Go',
    etc.). This implementation is capable of evaluating a variety of matchups,
    Elo rating updates, and win probabilities, all based on the basic Elo
    rating system. It also includes methods to benchmark performance,
    including logistic regression and Markov chain models.",2020-01-14,Ethan Heinzen,"https://github.com/eheinzen/elo,
https://cran.r-project.org/package=elo,
https://eheinzen.github.io/elo/",TRUE,https://github.com/eheinzen/elo,15081,16,2020-03-09T18:15:19Z,942.5625
EloChoice,"Allows calculating global scores for characteristics of visual stimuli as assessed by human raters. Stimuli are presented as sequence of pairwise comparisons ('contests'), during each of which a rater expresses preference for one stimulus over the other (forced choice). The algorithm for calculating global scores is based on Elo rating, which updates individual scores after each single pairwise contest. Elo rating is widely used to rank chess players according to their performance. Its core feature is that dyadic contests with expected outcomes lead to smaller changes of participants' scores than outcomes that were unexpected. As such, Elo rating is an efficient tool to rate individual stimuli when a large number of such stimuli are paired against each other in the context of experiments where the goal is to rank stimuli according to some characteristic of interest. Clark et al (2018) <doi:10.1371/journal.pone.0190393> provide details.",2019-07-04,Christof Neumann,https://github.com/gobbios/EloChoice,TRUE,https://github.com/gobbios/elochoice,13209,4,2019-07-02T10:12:48Z,3302.25
EloOptimized,"Provides an implementation of the maximum likelihood methods for deriving
    Elo scores as published in Foerster, Franz et al. (2016) <DOI:10.1038/srep35404>.",2018-09-17,Joseph Feldblum,https://github.com/jtfeld/EloOptimized,TRUE,https://github.com/jtfeld/elooptimized,6851,0,2020-05-02T21:59:45Z,NA
EloRating,"Provides functions to quantify animal dominance hierarchies. The major focus is on Elo rating and its ability to deal with temporal dynamics in dominance interaction sequences. For static data, David's score and de Vries' I&SI are also implemented. In addition, the package provides functions to assess transitivity, linearity and stability of dominance networks. See Neumann et al (2011) <doi:10.1016/j.anbehav.2011.07.016> for an introduction.",2020-03-12,Christof Neumann,https://github.com/gobbios/EloRating,TRUE,https://github.com/gobbios/elorating,18776,1,2020-01-14T22:17:10Z,18776
elsa,"A framework that provides the methods for quantifying entropy-based local indicator of spatial association (ELSA) that can be used for both continuous and categorical data. In addition, this package offers other methods to measure local indicators of spatial associations (LISA). Furthermore, global spatial structure can be measured using a variogram-like diagram, called entrogram. For more information, please check that paper: Naimi, B., Hamm, N. A., Groen, T. A., Skidmore, A. K., Toxopeus, A. G., & Alibakhshi, S. (2019) <doi:10.1016/j.spasta.2018.10.001>.",2020-03-19,Babak Naimi,http://r-gis.net,TRUE,https://github.com/babaknaimi/elsa,1460,3,2020-03-12T22:54:19Z,486.6666666666667
emayili,"A light, simple tool for sending emails with minimal dependencies.",2020-06-03,Andrew B. Collier,https://datawookie.github.io/emayili/,TRUE,https://github.com/datawookie/emayili,2992,48,2020-06-03T13:33:58Z,62.333333333333336
emba,"Analysis and visualization of an ensemble of boolean models for 
  biomarker discovery in cancer cell networks. The package allows to easily 
  import the data results of a software pipeline that predicts synergistic drug 
  combinations in cancer cell lines, developed by the DrugLogics research group 
  in NTNU. It has generic functions that can be used to split a boolean model 
  dataset to model groups with regards to the models predictive performance (number of true 
  positive predictions or Matthews correlation coefficient score) or synergy prediction based on a given set 
  of observed synergies and find the average activity difference per network 
  node between all group pairs. Thus, given user-specific thresholds,
  important nodes (biomarkers) can be accessed in the sense that they make the 
  models predict specific synergies (synergy biomarkers) or have better 
  performance in general (performance biomarkers). Lastly, if the 
  boolean models have a specific equation form and differ only in their link operator, 
  link operator biomarkers can also be assessed.",2020-04-14,John Zobolas,https://github.com/bblodfon/emba,TRUE,https://github.com/bblodfon/emba,2782,0,2020-06-07T19:07:35Z,NA
embed,Predictors can be converted to one or more numeric representations using simple generalized linear models <arXiv:1611.09477> or nonlinear models <arXiv:1604.06737>. Most encoding methods are supervised.,2020-05-25,Max Kuhn,"https://embed.tidymodels.org, https://github.com/tidymodels/embed",TRUE,https://github.com/tidymodels/embed,10962,61,2020-05-25T16:43:47Z,179.70491803278688
EMCluster,"EM algorithms and several efficient
        initialization methods for model-based clustering of finite
        mixture Gaussian distribution with unstructured dispersion
        in both of unsupervised and semi-supervised learning.",2019-03-22,Wei-Chen Chen,https://github.com/snoweye/EMCluster,TRUE,https://github.com/snoweye/emcluster,53271,13,2020-05-03T00:26:01Z,4097.7692307692305
emdi,"Functions that support estimating, assessing and mapping regional
    disaggregated indicators. So far, estimation methods comprise direct estimation
    and the model-based approach Empirical Best Prediction (see ""Small area
    estimation of poverty indicators"" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), 
    as well as their precision estimates. The assessment of the used model
    is supported by a summary and diagnostic plots. For a suitable presentation of
    estimates, map plots can be easily created. Furthermore, results can easily be
    exported to excel. For a detailed description of the package and the methods used
    see ""The {R} Package {emdi} for Estimating and Mapping Regionally Disaggregated Indicators""
    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07>.",2020-03-18,Soeren Pannier,https://github.com/SoerenPannier/emdi,TRUE,https://github.com/soerenpannier/emdi,18961,4,2020-05-07T08:35:05Z,4740.25
EmissV,"Creates emissions for use in air quality models. Vehicular emissions 
  are estimated by a top-down approach, total emissions are calculated using the 
  statistical description of the fleet of vehicles, the emission is spatially 
  distributed according to satellite images or openstreetmap data 
  <https://www.openstreetmap.org> and then distributed temporarily 
  (Vara-Vela et al., 2016, <doi:10.5194/acp-16-777-2016>).",2020-04-01,Daniel Schuch,https://atmoschem.github.io/EmissV,TRUE,https://github.com/atmoschem/emissv,9411,14,2020-04-01T17:21:04Z,672.2142857142857
EML,"Work with Ecological Metadata Language ('EML') files. 
    'EML' is a widely used metadata standard in the ecological and
    environmental sciences, described in Jones et al. (2006),
    <doi:10.1146/annurev.ecolsys.37.091305.110031>.",2020-02-08,Carl Boettiger,"https://docs.ropensci.org/EML, https://github.com/ropensci/EML",TRUE,https://github.com/ropensci/eml,23328,81,2020-02-20T17:00:46Z,288
emld,"This is a utility for transforming Ecological Metadata Language
        ('EML') files into 'JSON-LD' and back into 'EML.'  Doing so creates a
        list-based representation of 'EML' in R, so that 'EML' data can easily
        be manipulated using standard 'R' tools. This makes this package an
        effective backend for other 'R'-based tools  working with 'EML.' By
        abstracting away the complexity of 'XML' Schema, developers can
        build around native 'R' list objects and not have to worry about satisfying
        many of the additional constraints of set by the schema (such as element
        ordering, which is handled automatically). Additionally, the 'JSON-LD' 
        representation enables the use of developer-friendly 'JSON' parsing and
        serialization that may facilitate the use of 'EML' in contexts outside of 'R,'
        as well as the informatics-friendly serializations such as 'RDF' and
        'SPARQL' queries.",2020-02-05,Carl Boettiger,"https://docs.ropensci.org/emld, https://github.com/ropensci/emld",TRUE,https://github.com/ropensci/emld,12565,10,2020-06-05T00:15:01Z,1256.5
emmeans,"Obtain estimated marginal means (EMMs) for many linear, generalized 
  linear, and mixed models. Compute contrasts or linear functions of EMMs,
  trends, and comparisons of slopes. Plots and other displays.
  Least-squares means are discussed, and the term ""estimated marginal means""
  is suggested, in Searle, Speed, and Milliken (1980) Population marginal means 
  in the linear model: An alternative to least squares means, The American 
  Statistician 34(4), 216-221 <doi:10.1080/00031305.1980.10483031>.",2020-05-25,Russell Lenth,https://github.com/rvlenth/emmeans,TRUE,https://github.com/rvlenth/emmeans,922285,119,2020-06-08T19:45:17Z,7750.294117647059
emojifont,"An implementation of using emoji and fontawesome for using in both
    base and 'ggplot2' graphics.",2019-12-12,Guangchuang Yu,https://guangchuangyu.github.io/emojifont,TRUE,https://github.com/guangchuangyu/emojifont,44057,57,2019-12-12T03:20:46Z,772.9298245614035
EmpiricalCalibration,"Routines for performing empirical calibration of observational
  study estimates. By using a set of negative control hypotheses we can
  estimate the empirical null distribution of a particular observational
  study setup. This empirical null distribution can be used to compute a
  calibrated p-value, which reflects the probability of observing an
  estimated effect size when the null hypothesis is true taking both random
  and systematic error into account. A similar approach can be used to
  calibrate confidence intervals, using both negative and positive controls.",2020-04-07,Martijn Schuemie,"https://ohdsi.github.io/EmpiricalCalibration,
https://github.com/OHDSI/EmpiricalCalibration",TRUE,https://github.com/ohdsi/empiricalcalibration,20205,6,2020-06-08T06:42:43Z,3367.5
emstreeR,"Computes Euclidean Minimum Spanning Trees (EMST) using the fast 
    Dual-Tree Boruvka algorithm (March, Ram, Gray, 2010, 
    <doi:10.1145/1835804.1835882>) implemented in 'mlpack' - the C++ Machine 
    Learning library (Curtin et al., 2013). 'emstreeR' heavily relies on 
    'RcppMLPACK' and 'Rcpp', working as a wrapper to the C++ fast EMST 
    algorithm. Thus, R users do not have to deal with the R-'Rcpp'-C++ 
    integration. The package also provides functions and an S3 method for 
    readily plotting Minimum Spanning Trees (MST) using either 'base' R, 
    'scatterplot3d' or 'ggplot2' style.",2019-05-08,Allan Quadros,NA,TRUE,https://github.com/allanvc/emstreer,7929,3,2019-08-20T21:24:09Z,2643
emuR,"Provides the next iteration of the EMU Speech 
    Database Management System (EMU-SDMS) with database management, data 
    extraction, data preparation and data visualization facilities.",2019-11-06,Raphael Winkelmann,https://github.com/IPS-LMU/emuR,TRUE,https://github.com/ips-lmu/emur,28793,18,2020-06-08T15:55:02Z,1599.611111111111
enc,"
    Implements an S3 class for storing 'UTF-8' strings, based on regular character vectors.
    Also contains routines to portably read and write 'UTF-8' encoded text files,
    to convert all strings in an object to 'UTF-8',
    and to create character vectors with various encodings.",2019-12-19,Kirill Müller,https://github.com/krlmlr/enc,TRUE,https://github.com/krlmlr/enc,63654,11,2019-12-19T13:57:53Z,5786.727272727273
encryptr,"It is important to ensure that sensitive data is protected. 
    This straightforward package is aimed at the end-user. 
    Strong RSA encryption using a public/private key pair is used to encrypt data frame or tibble columns.
    A public key can be shared to allow others to encrypt data to be sent to you. 
    This is particularly aimed a healthcare settings so patient data can be pseudonymised. ",2019-04-25,Ewen Harrison,https://github.com/SurgicalInformatics/encryptr,TRUE,https://github.com/surgicalinformatics/encryptr,7133,78,2019-11-07T12:12:44Z,91.44871794871794
endoSwitch,Maximum likelihood estimation of endogenous switching regression models from Heckman (1979) <doi:10.2307/1912352> and estimation of treatment effects.  ,2020-02-21,Bowen Chen,https://github.com/cbw1243/endoSwitch,TRUE,https://github.com/cbw1243/endoswitch,1285,0,2020-01-17T15:35:22Z,NA
energy,"E-statistics (energy) tests and statistics for multivariate and univariate inference,
             including distance correlation, one-sample, two-sample, and multi-sample tests for
             comparing multivariate distributions, are implemented. Measuring and testing
             multivariate independence based on distance correlation, partial distance correlation,
             multivariate goodness-of-fit tests, k-groups and hierarchical clustering based on energy 
             distance, testing for multivariate normality, distance components (disco) for non-parametric 
             analysis of structured data, and other energy statistics/methods are implemented.",2019-12-07,Maria Rizzo,https://github.com/mariarizzo/energy,TRUE,https://github.com/mariarizzo/energy,315151,23,2019-12-08T08:48:48Z,13702.217391304348
enpls,"An algorithmic framework for measuring feature importance,
    outlier detection, model applicability domain evaluation,
    and ensemble predictive modeling with (sparse)
    partial least squares regressions.",2019-05-18,Nan Xiao,"https://nanx.me/enpls/, https://github.com/nanxstats/enpls",TRUE,https://github.com/nanxstats/enpls,46025,13,2020-04-23T23:02:01Z,3540.3846153846152
enrichwith,"Provides the ""enrich"" method to enrich list-like R objects with new, relevant components. The current version has methods for enriching objects of class 'family', 'link-glm', 'lm', 'glm' and 'betareg'. The resulting objects preserve their class, so all methods associated with them still apply. The package also provides the 'enriched_glm' function that has the same interface as 'glm' but results in objects of class 'enriched_glm'. In addition to the usual components in a `glm` object, 'enriched_glm' objects carry an object-specific simulate method and functions to compute the scores, the observed and expected information matrix, the first-order bias, as well as model densities, probabilities, and quantiles at arbitrary parameter values. The package can also be used to produce customizable source code templates for the structured implementation of methods to compute new components and enrich arbitrary objects.",2020-01-10,Ioannis Kosmidis,https://github.com/ikosmidis/enrichwith,TRUE,https://github.com/ikosmidis/enrichwith,27499,5,2019-12-27T15:47:42Z,5499.8
ensr,"Elastic net regression models are controlled by two parameters,
  lambda, a measure of shrinkage, and alpha, a metric defining the model's
  location on the spectrum between ridge and lasso regression.  
  glmnet provides tools for selecting lambda via cross
  validation but no automated methods for selection of alpha.  Elastic Net
  SearcheR automates the simultaneous selection of both lambda and alpha.
  Developed, in part, with support by NICHD R03 HD094912.",2019-01-21,Peter DeWitt,https://github.com/dewittpe/ensr,TRUE,https://github.com/dewittpe/ensr,5316,0,2020-03-02T20:50:34Z,NA
entropart,"Measurement and partitioning of diversity, based on Tsallis entropy, following Marcon and Herault (2015) <doi:10.18637/jss.v067.i08>.
             'entropart' provides functions to calculate alpha, beta and gamma diversity of communities, including phylogenetic and functional diversity.
             Estimation-bias corrections are available.",2020-01-22,Eric Marcon,https://github.com/EricMarcon/entropart,TRUE,https://github.com/ericmarcon/entropart,36765,3,2020-04-18T21:20:29Z,12255
envalysis,"Small toolbox for data analyses in environmental chemistry and
    ecotoxicology. Provides, for example, calibration() to calculate calibration
    curves and corresponding limits of detection (LODs) and quantification
    (LOQs) according to German DIN 32645:2008-11. texture() makes it easy to
    estimate soil particle size distributions from hydrometer measurements (ASTM
    D422-63(2007)e2).",2020-04-17,Zacharias Steinmetz,https://github.com/zsteinmetz/envalysis,TRUE,https://github.com/zsteinmetz/envalysis,8019,0,2020-04-17T16:59:31Z,NA
envDocument,"Prints out information about the R working environment
    (system, R version,loaded and attached packages and versions) from a single
    function ""env_doc()"".  Optionally adds information on git repository,
    tags, commits and remotes (if available).",2019-08-19,Donald Jackson,https://github.com/dgJacks0n/envDocument,TRUE,https://github.com/dgjacks0n/envdocument,16932,1,2019-09-04T12:47:34Z,16932
enviGCMS,"Gas/Liquid Chromatography-Mass Spectrometer(GC/LC-MS) Data Analysis for Environmental Science. This package covered topics such molecular isotope ratio, matrix effects and Short-Chain Chlorinated Paraffins analysis etc. in environmental analysis.",2020-06-04,Miao YU,https://github.com/yufree/enviGCMS,TRUE,https://github.com/yufree/envigcms,13602,6,2020-06-04T14:28:02Z,2267
envirem,Generation of bioclimatic rasters that are complementary to the typical 19 bioclim variables.  ,2020-06-04,Pascal O. Title,http://envirem.github.io,TRUE,https://github.com/ptitle/envirem,16788,5,2020-06-03T22:21:26Z,3357.6
envnames,"Set of functions to keep track of user-defined environment names
    (which cannot be retrieved with the built-in function environmentName()).
    The package also provides functionality to search for objects in environments,
    deal with function calling chains, and retrieve an object's
    memory address.",2019-01-04,Daniel Mastropietro,https://github.com/mastropi/envnames,TRUE,https://github.com/mastropi/envnames,7521,0,2019-08-05T08:57:31Z,NA
EPGMr,"Everglades Phosphorus Gradient Model predicts variations in water-column P concentration, peat accretion rate, and soil P concentration along a horizontal gradient imposed by an external phosphorus load and sheet-flow conditions. Potential biological responses are expressed in terms of marsh surface area exceeding threshold criteria for water-column and soil phosphorus concentrations. More information of the model can be found at <http://www.wwwalker.net/epgm/>.",2020-05-05,Paul Julian,https://github.com/swampthingpaul/EPGMr,TRUE,https://github.com/swampthingpaul/epgmr,495,0,2020-06-04T11:31:11Z,NA
eph,"Tools to download and manipulate the Permanent Household Survey from Argentina
    (EPH is the Spanish acronym for Permanent Household Survey).
    e.g: get_microdata() for downloading the datasets, get_poverty_lines() for downloading the official poverty baskets,
    calculate_poverty() for the calculation of stating if a household is in poverty or not, following the official methodology.
    organize_panels() is used to concatenate observations from different periods, and organize_labels()
    adds the official labels to the data. The implemented methods are based on INDEC (2016) <http://www.estadistica.ec.gba.gov.ar/dpe/images/SOCIEDAD/EPH_metodologia_22_pobreza.pdf>.
    As this package works with the argentinian Permanent Household Survey and its main audience is from this country,
    the documentation was written in Spanish.",2020-05-24,Diego Kozlowski,https://github.com/holatam/eph,TRUE,https://github.com/holatam/eph,5803,23,2020-05-24T08:39:38Z,252.30434782608697
epicontacts,"A collection of tools for representing epidemiological contact data, composed of case line lists and contacts between cases. Also contains procedures for data handling, interactive graphics, and statistics.",2017-11-21,VP Nagraj,http://www.repidemicsconsortium.org/epicontacts/,TRUE,https://github.com/reconhub/epicontacts,14109,8,2020-02-14T13:03:23Z,1763.625
EpiContactTrace,"Routines for epidemiological contact tracing
    and visualisation of network of contacts.",2020-03-15,Stefan Widgren,https://github.com/stewid/EpiContactTrace,TRUE,https://github.com/stewid/epicontacttrace,27680,3,2020-03-03T10:18:11Z,9226.666666666666
EpiILM,Provides tools for simulating from discrete-time individual level models for infectious disease data analysis. This epidemic model class contains spatial and contact-network based models with two disease types: Susceptible-Infectious (SI) and Susceptible-Infectious-Removed (SIR).,2020-03-12,Vineetha Warriyar. K. V.,https://github.com/vineetha-warriyar/EpiILM,TRUE,https://github.com/vineetha-warriyar/epiilm,15856,2,2020-05-21T22:38:27Z,7928
EpiILMCT,"Provides tools for simulating from continuous-time individual level models of disease transmission, and carrying out infectious disease data analyses with the same models. The epidemic models considered are distance-based and/or contact network-based models within Susceptible-Infectious-Removed (SIR) or Susceptible-Infectious-Notified-Removed (SINR) compartmental frameworks. An overview of the implemented continuous-time individual level models for epidemics is given by Almutiry and Deardon (2019) <doi:10.1515/ijb-2017-0092>.",2020-01-21,Waleed Almutiry,https://github.com/waleedalmutiry/EpiILMCT/,TRUE,https://github.com/waleedalmutiry/epiilmct,12776,2,2020-01-21T21:51:20Z,6388
epikit,"Contains tools for formatting inline code, renaming redundant
  columns, aggregating age categories, and calculating proportions with
  confidence intervals. This is part of the 'R4Epis' project
  <https://r4epis.netlify.com>.",2020-04-13,Zhian N. Kamvar,"https://github.com/R4EPI/epikit, https://r4epis.netlify.com,
https://r4epi.github.io/epikit",TRUE,https://github.com/r4epi/epikit,1860,1,2020-04-10T22:59:41Z,1860
epimdr,"Functions, data sets and shiny apps for ""Epidemics: Models and Data in R"" by Ottar N. Bjornstad (ISBN 978-3-319-97487-3) <https://www.springer.com/gp/book/9783319974866>. The package contains functions to study the S(E)IR model, spatial and age-structured SIR models; time-series SIR and chain-binomial stochastic models; catalytic disease models; coupled map lattice models of spatial transmission and network models for social spread of infection. The package is also an advanced quantitative companion to the coursera Epidemics Massive Online Open Course <https://www.coursera.org/learn/epidemics>.",2020-01-25,Ottar N. Bjornstad,"https://github.com/objornstad/epimdr,
https://www.springer.com/gp/book/9783319974866,
http://ento.psu.edu/directory/onb1",TRUE,https://github.com/objornstad/epimdr,9770,36,2020-02-13T21:29:42Z,271.3888888888889
EpiModel,"Tools for simulating mathematical models of infectious disease dynamics. 
    Epidemic model classes include deterministic compartmental models, stochastic 
    individual-contact models, and stochastic network models. Network models use the
    robust statistical methods of exponential-family random graph models (ERGMs) 
    from the Statnet suite of software packages in R. Standard templates for epidemic 
    modeling include SI, SIR, and SIS disease types. EpiModel features 
    an API for extending these templates to address novel scientific research aims.",2020-05-08,Samuel Jenness,"http://epimodel.org/, http://github.com/statnet/EpiModel",TRUE,https://github.com/statnet/epimodel,108537,127,2020-05-21T17:00:59Z,854.6220472440945
episensr,"Basic sensitivity analysis of the observed relative risks adjusting
    for unmeasured confounding and misclassification of the
    exposure/outcome, or both. It follows the bias analysis methods and
    examples from the book by Lash T.L, Fox M.P, and Fink A.K.
    ""Applying Quantitative Bias Analysis to Epidemiologic Data"",
    ('Springer', 2009).",2020-03-06,Denis Haine,NA,TRUE,https://github.com/dhaine/episensr,22722,5,2020-03-17T03:30:54Z,4544.4
episheet,"A collection of R functions supporting the text book
  Modern Epidemiology, Second Edition, by Kenneth J.Rothman and Sander Greenland.
  ISBN 13: 978-0781755641  See <http://www.krothman.org/> for more information.",2019-01-23,James Black,https://github.com/epijim/episheet,TRUE,https://github.com/epijim/episheet,13745,3,2020-05-14T14:25:58Z,4581.666666666667
epitrix,"A collection of small functions useful for epidemics analysis and infectious disease modelling. This includes computation of basic reproduction numbers from growth rates, generation of hashed labels to anonymise data, and fitting discretised Gamma distributions.",2019-01-15,Thibaut Jombart,http://www.repidemicsconsortium.org/epitrix,TRUE,https://github.com/reconhub/epitrix,25111,8,2019-09-23T06:51:19Z,3138.875
eplusr,"A rich toolkit of using the whole building
    simulation program 'EnergyPlus'(<https://energyplus.net>), which
    enables programmatic navigation, modification of 'EnergyPlus' models
    and makes it less painful to do parametric simulations and analysis.",2020-02-20,Hongyuan Jia,"https://hongyuanjia.github.io/eplusr,
https://github.com/hongyuanjia/eplusr",TRUE,https://github.com/hongyuanjia/eplusr,16234,24,2020-06-09T23:57:00Z,676.4166666666666
eponge,"Provides a set of functions, which facilitates removing objects from an environment. 
             It allows to delete objects specified with regular expression or with other conditions (e.g. if object is numeric),
             using one function call.    ",2020-03-24,Krzysztof Joachimiak,"https://github.com/krzjoa/eponge, https://krzjoa.github.io/eponge/",TRUE,https://github.com/krzjoa/eponge,1141,0,2020-03-26T19:21:30Z,NA
epsiwal,"Implements the conditional estimation procedure of
  Lee, Sun, Sun and Taylor (2016) <doi:10.1214/15-AOS1371>.
  This procedure allows hypothesis testing on the mean of
  a normal random vector subject to linear constraints.",2019-07-02,Steven E. Pav,https://github.com/shabbychef/epsiwal,TRUE,https://github.com/shabbychef/epsiwal,3907,0,2019-06-29T04:35:20Z,NA
epuR,"Provides functions to collect the economic policy uncertainty and related index data from the official 
 website <https://www.policyuncertainty.com/index.html> in real time. Deals with date format and returns an time series object to
 facilitate further data manipulation and analysis.",2020-04-10,Lingbing Feng,https://github.com/Lingbing/epuR,TRUE,https://github.com/lingbing/epur,930,1,2020-04-29T15:19:41Z,930
eq5d,"EQ-5D is a popular health related quality of life instrument used 
    in the clinical and economic evaluation of health care. Developed by the 
    EuroQol group <https://www.euroqol.org>, the instrument consists of two 
    components: health state description and evaluation. For the description 
    component a subject self-rates their health in terms of five dimensions; 
    mobility, self-care, usual activities, pain/discomfort, and 
    anxiety/depression using either a three-level (EQ-5D-3L,
    <https://www.euroqol.org/eq-5d-instruments/eq-5d-3l-about>) or a five-level
    (EQ-5D-5L, <https://www.euroqol.org/eq-5d-instruments/eq-5d-5l-about>) 
    scale. Frequently the scores on these five dimensions are converted to a 
    single utility index using country specific value sets, which can be used
    in the clinical and economic evaluation of health care as well as in 
    population health surveys. The eq5d package provides methods to calculate 
    index scores from a subject's dimension scores. 25 TTO and 11 VAS EQ-5D-3L value 
    sets including those for countries in Szende et al (2007) 
    <doi:10.1007/1-4020-5511-0> and Szende et al (2014) 
    <doi:10.1007/978-94-007-7596-1>, 21 EQ-5D-5L EQ-VT value sets from the EuroQol
    website, and the EQ-5D-5L crosswalk value sets developed by van Hout et al. (2012) 
    <doi:10.1016/j.jval.2012.02.008> are included. Additionally, a shiny web tool is 
    included to enable the calculation, visualisation and automated statistical 
    analysis of EQ-5D index values via a web browser using EQ-5D dimension scores 
    stored in CSV or Excel files. ",2020-06-07,Fraser Morton,https://github.com/fragla/eq5d,TRUE,https://github.com/fragla/eq5d,6166,6,2020-06-06T13:35:24Z,1027.6666666666667
equaltestMI,"Functions for examining measurement invariance via equivalence testing are included in this package. The traditionally used RMSEA (Root Mean Square Error of Approximation) cutoff values are adjusted based on simulation results. In addition, a projection-based method is implemented to test the equality of latent factor means across groups without assuming the equality of intercepts. For more information, see Yuan, K. H., & Chan, W. (2016) <doi:10.1037/met0000080>, Deng, L., & Yuan, K. H. (2016) <doi:10.1007/s11336-015-9491-8>, and Jiang, G., Mai, Y., & Yuan, K. H. (2017) < doi:10.3389/fpsyg.2017.01823>. ",2020-06-05,Ge Jiang,NA,TRUE,https://github.com/gabriellajg/equaltestmi,9918,1,2020-06-05T17:04:43Z,9918
equate,"Contains methods for observed-score linking
  and equating under the single-group, equivalent-groups,
  and nonequivalent-groups with anchor test(s) designs.
  Equating types include identity, mean, linear, general
  linear, equipercentile, circle-arc, and composites of
  these. Equating methods include synthetic, nominal
  weights, Tucker, Levine observed score, Levine true
  score, Braun/Holland, frequency estimation, and chained
  equating. Plotting and summary methods, and methods for
  multivariate presmoothing and bootstrap error estimation
  are also provided.",2018-04-08,Anthony Albano,https://github.com/talbano/equate,TRUE,https://github.com/talbano/equate,37968,2,2020-03-04T17:44:35Z,18984
ergm,An integrated set of tools to analyze and simulate networks based on exponential-family random graph models (ERGMs). 'ergm' is a part of the Statnet suite of packages for network analysis.,2019-06-10,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm,320683,44,2020-06-01T11:00:10Z,7288.25
ergm.ego,Utilities for managing egocentrically sampled network data and a wrapper around the 'ergm' package to facilitate ERGM inference and simulation from such data.,2019-05-31,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm.ego,31002,9,2020-04-13T09:40:48Z,3444.6666666666665
ergmito,"Simulation and estimation of Exponential Random Graph Models (ERGMs)
  for small networks using exact statistics. As a difference from the 'ergm'
  package, 'ergmito' circumvents using Markov-Chain Maximum Likelihood Estimator
  (MC-MLE) and instead uses Maximum Likelihood Estimator (MLE) to fit ERGMs
  for small networks. As exhaustive enumeration is computationally feasible for
  small networks, this R package takes advantage of this and provides tools for
  calculating likelihood functions, and other relevant functions, directly,
  meaning that in many cases both estimation and simulation of ERGMs for
  small networks can be faster and more accurate than simulation-based
  algorithms.",2020-02-12,George Vega Yon,https://muriteams.github.io/ergmito,TRUE,https://github.com/muriteams/ergmito,2324,5,2020-05-18T18:42:28Z,464.8
err,"Messages should provide users with readable information 
    about R objects without flooding their console. 
    'cc()' concatenates vector and data frame values 
    into a grammatically correct string using commas, an ellipsis and conjunction. 
    'cn()' allows the user to define a string which varies based on a count.
    'co()' combines the two to produce a customizable object aware string.
    The package further facilitates this process by providing five 'sprintf'-like 
    types such as '%n' for the length of an object and '%o' for its name as
    well as wrappers for pasting objects and issuing errors, warnings and messages.",2019-04-25,Joe Thorley,https://github.com/poissonconsulting/err,TRUE,https://github.com/poissonconsulting/err,14532,6,2020-05-08T01:12:39Z,2422
errorist,"Provides environment hooks that obtain errors and warnings which
    occur during the execution of code to automatically search for solutions.",2020-02-24,James Balamuta,https://github.com/r-assist/errorist,TRUE,https://github.com/r-assist/errorist,9099,18,2020-02-23T21:28:12Z,505.5
errorlocate,Errors in data can be located and removed using validation rules from package 'validate'.,2020-02-06,Edwin de Jonge,https://github.com/data-cleaning/errorlocate,TRUE,https://github.com/data-cleaning/errorlocate,15714,12,2020-02-18T09:01:59Z,1309.5
errors,"Support for measurement errors in R vectors, matrices and arrays:
    automatic uncertainty propagation and reporting.
    Documentation about 'errors' is provided in the paper by Ucar, Pebesma &
    Azcorra (2018, <doi:10.32614/RJ-2018-075>), included in this package as a
    vignette; see 'citation(""errors"")' for details.",2020-01-08,Iñaki Ucar,https://github.com/r-quantities/errors,TRUE,https://github.com/r-quantities/errors,18613,28,2020-06-08T17:59:43Z,664.75
errum,"Perform a Bayesian estimation of the exploratory reduced
    reparameterized unified model (ErRUM) described by Culpepper and Chen (2018)
    <doi:10.3102/1076998618791306>.",2020-03-20,James Joseph Balamuta,https://github.com/tmsalab/errum,TRUE,https://github.com/tmsalab/errum,1397,0,2020-03-20T02:39:55Z,NA
eRTG3D,"Creates realistic random trajectories in a 3-D space between two given fix points, so-called conditional empirical random walks (CERWs). The trajectory generation is based on empirical distribution functions extracted from observed trajectories (training data) and thus reflects the geometrical movement characteristics of the mover. A digital elevation model (DEM), representing the Earth's surface, and a background layer of probabilities (e.g. food sources, uplift potential, waterbodies, etc.) can be used to influence the trajectories.
    Unterfinger M (2018). ""3-D Trajectory Simulation in Movement Ecology: Conditional Empirical Random Walk"". Master's thesis, University of Zurich. <https://www.geo.uzh.ch/dam/jcr:6194e41e-055c-4635-9807-53c5a54a3be7/MasterThesis_Unterfinger_2018.pdf>.
    Technitis G, Weibel R, Kranstauber B, Safi K (2016). ""An algorithm for empirically informed random trajectory generation between two endpoints"". GIScience 2016: Ninth International Conference on Geographic Information Science, 9, online. <doi:10.5167/uzh-130652>.",2019-09-19,Merlin Unterfinger,"https://munterfinger.github.io/eRTG3D/,
https://github.com/munterfinger/eRTG3D",TRUE,https://github.com/munterfinger/ertg3d,3188,2,2019-12-21T13:01:36Z,1594
esaddle,Tools for fitting the Extended Empirical Saddlepoint (EES) density of Fasiolo et al. (2018) <doi:10.1214/18-EJS1433>.,2020-01-10,Matteo Fasiolo and Simon N. Wood,https://github.com/mfasiolo/esaddle,TRUE,https://github.com/mfasiolo/esaddle,11521,1,2020-01-10T16:13:51Z,11521
esaps,"It allows to construct two types of indicators used in the study of
    Electoral Systems and Party Systems starting from electoral results data.
    The Effective Number of Parties (Laakso and Taagepera (1979) <doi:10.1177/001041407901200101>)
    and Electoral Volatility in its three versions (Pedersen (1979) <doi:10.1111/j.1475-6765.1979.tb01267.x>,
    Powell and Tucker (2014) <doi:10.1017/S0007123412000531> and Torcal and Lago (2015, ISBN:9788415260356)).",2018-03-15,Nicolas Schmidt,https://github.com/Nicolas-Schmidt/esaps,TRUE,https://github.com/nicolas-schmidt/esaps,7803,3,2020-04-20T15:10:51Z,2601
esc,"Implementation of the web-based 'Practical Meta-Analysis Effect Size
    Calculator' from David B. Wilson (<http://www.campbellcollaboration.org/escalc/html/EffectSizeCalculator-Home.php>)
    in R. Based on the input, the effect size can be returned as standardized mean 
    difference, Cohen's f, Hedges' g, Pearson's r or Fisher's
    transformation z, odds ratio or log odds, or eta squared effect size.",2019-12-04,Daniel Lüdecke,https://strengejacke.github.io/esc,TRUE,https://github.com/strengejacke/esc,30315,12,2020-05-28T14:30:53Z,2526.25
eSDM,"A tool which allows users to create and evaluate ensembles 
    of species distribution model (SDM) predictions. 
    Functionality is offered through R functions or a GUI (R Shiny app). 
    This tool can assist users in identifying spatial uncertainties and 
    making informed conservation and management decisions. The package is 
    further described in Woodman et al (2019) <doi:10.1111/2041-210X.13283>.",2020-04-26,Sam Woodman,"https://smwoodman.github.io/eSDM,
https://github.com/smwoodman/eSDM",TRUE,https://github.com/smwoodman/esdm,4677,4,2020-04-26T21:18:00Z,1169.25
esmprep,"Support in preparing a raw ESM dataset for statistical analysis. Preparation includes the handling of errors (mostly due to technological reasons) and the generating of new variables that are necessary and/or helpful in meeting the conditions when statistically analyzing ESM data. The functions in 'esmprep' are meant to hierarchically lead from bottom, i.e. the raw (separated) ESM dataset(s), to top, i.e. a single ESM dataset ready for statistical analysis. This hierarchy evolved out of my personal experience in working with ESM data.",2019-07-05,Marcel Miché,https://github.com/mmiche/esmprep,TRUE,https://github.com/mmiche/esmprep,11702,1,2019-07-05T11:15:49Z,11702
esquisse,"A 'shiny' gadget to create 'ggplot2' charts interactively with drag-and-drop to map your variables.
    You can quickly visualize your data accordingly to their type, export to 'PNG' or 'PowerPoint',
    and retrieve the code to reproduce the chart.",2020-01-27,Victor Perrier,https://github.com/dreamRs/esquisse,TRUE,https://github.com/dreamrs/esquisse,100050,923,2020-05-29T12:13:44Z,108.39653304442037
ess,"An implementation of the ESS algorithm following Amol Deshpande, Minos Garofalakis,
	     Michael I Jordan (2013) <arXiv:1301.2267>. The ESS algorithm
	     is used for model selection in decomposable graphical models.",2020-05-24,Mads Lindskou,https://github.com/mlindsk/ess,TRUE,https://github.com/mlindsk/ess,2312,0,2020-05-24T16:04:31Z,NA
essurvey,Download data from the European Social Survey directly from their website <http://www.europeansocialsurvey.org/>. There are two families of functions that allow you to download and interactively check all countries and rounds available.,2019-12-11,Jorge Cimentada,"https://docs.ropensci.org/essurvey/,
https://github.com/ropensci/essurvey",TRUE,https://github.com/ropensci/essurvey,13053,33,2020-05-24T09:01:09Z,395.54545454545456
estatapi,"Provides an interface to e-Stat API, the one-stop service for official statistics of the Japanese government.",2020-04-12,Hiroaki Yutani,https://yutannihilation.github.io/estatapi/,TRUE,https://github.com/yutannihilation/estatapi,16755,14,2020-04-12T06:19:38Z,1196.7857142857142
EstimationTools,"A routine for parameter estimation for any probability density or
    mass function implemented in R via maximum likelihood (ML) given a data set. This
    routine is a wrapper function specifically developed for ML estimation. There are
    included optimization procedures such as 'nlminb' and 'optim' from base package,
    and 'DEoptim' Mullen (2011) <doi: 10.18637/jss.v040.i06>. Standard errors are
    estimated with 'numDeriv' Gilbert (2011) <http://CRAN.R-project.org/package=numDeriv>
    or the option 'Hessian = TRUE' of 'optim' function.",2019-10-24,Jaime Mosquera,"https://jaimemosg.github.io/EstimationTools/,
https://github.com/Jaimemosg/EstimationTools",TRUE,https://github.com/jaimemosg/estimationtools,5388,1,2020-04-14T18:04:50Z,5388
estimatr,"Fast procedures for small set of commonly-used, design-appropriate estimators with robust standard errors and confidence intervals. Includes estimators for linear regression, instrumental variables regression, difference-in-means, Horvitz-Thompson estimation, and regression improving precision of experimental estimates by interacting treatment with centered pre-treatment covariates introduced by Lin (2013) <doi:10.1214/12-AOAS583>.",2020-03-19,Graeme Blair,"https://declaredesign.org/r/estimatr/,
https://github.com/DeclareDesign/estimatr",TRUE,https://github.com/declaredesign/estimatr,62302,104,2020-06-09T17:39:14Z,599.0576923076923
estudy2,"An implementation of a most commonly used event study methodology,
    including both parametric and nonparametric tests. It contains variety
    aspects of the rate of return estimation (the core calculation is done in
    C++), as well as three classical for event study market models: mean
    adjusted returns, market adjusted returns and single-index market models.
    There are 6 parametric and 6 nonparametric tests provided, which examine
    cross-sectional daily abnormal return (see the documentation of the
    functions for more information). Parametric tests include tests proposed by 
    Brown and Warner (1980) <DOI:10.1016/0304-405X(80)90002-1>, Brown and Warner
    (1985) <DOI:10.1016/0304-405X(85)90042-X>, Boehmer et al. (1991)
    <DOI:10.1016/0304-405X(91)90032-F>, Patell (1976) <DOI:10.2307/2490543>, and
    Lamb (1995) <DOI:10.2307/253695>. Nonparametric tests covered in estudy2 are
    tests described in Corrado and Zivney (1992) <DOI:10.2307/2331331>,
    McConnell and Muscarella (1985) <DOI:10.1016/0304-405X(85)90006-6>,
    Boehmer et al. (1991) <DOI:10.1016/0304-405X(91)90032-F>, Cowan (1992)
    <DOI:10.1007/BF00939016>, Corrado (1989) <DOI:10.1016/0304-405X(89)90064-0>,
    Campbell and Wasley (1993) <DOI:10.1016/0304-405X(93)90025-7>, Savickas (2003)
    <DOI:10.1111/1475-6803.00052>, Kolari and Pynnonen (2010)
    <DOI:10.1093/rfs/hhq072>. Furthermore, tests for the cumulative
    abnormal returns proposed by Brown and Warner (1985)
    <DOI:10.1016/0304-405X(85)90042-X> and Lamb (1995) <DOI:10.2307/253695>
    are included.",2020-04-30,Iegor Rudnytskyi,"http://github.com/irudnyts/estudy2,
http://irudnyts.github.io/estudy2/",TRUE,https://github.com/irudnyts/estudy2,12639,1,2020-04-30T18:22:04Z,12639
esvis,"A variety of methods are provided to estimate and visualize
    distributional differences in terms of effect sizes. Particular emphasis
    is upon evaluating differences between two or more distributions across
    the entire scale, rather than at a single point (e.g., differences in
    means). For example, Probability-Probability (PP) plots display the
    difference between two or more distributions, matched by their empirical
    CDFs (see Ho and Reardon, 2012; <doi:10.3102/1076998611411918>), allowing
    for examinations of where on the scale distributional differences are
    largest or smallest. The area under the PP curve (AUC) is an effect-size
    metric, corresponding to the probability that a randomly selected
    observation from the x-axis distribution will have a higher value
    than a randomly selected observation from the y-axis distribution. 
    Binned effect size plots are also available, in which the distributions
    are split into bins (set by the user) and separate effect sizes (Cohen's
    d) are produced for each bin - again providing a means to evaluate the
    consistency (or lack thereof) of the difference between two or more 
    distributions at different points on the scale. Evaluation of empirical 
    CDFs is also provided, with  built-in arguments for providing annotations 
    to help evaluate distributional differences at specific points (e.g., 
    semi-transparent shading). All function take a consistent argument 
    structure. Calculation of specific effect sizes is also possible. The
    following effect sizes are estimable: (a) Cohen's d, (b) Hedges' g, 
    (c) percentage above a cut, (d) transformed (normalized) percentage above 
    a cut, (e)  area under the PP curve, and (f) the V statistic (see Ho, 
    2009; <doi:10.3102/1076998609332755>), which essentially transforms the 
    area under the curve to standard deviation units. By default, effect sizes 
    are calculated for all possible pairwise comparisons, but a reference 
    group (distribution) can be specified.",2020-04-30,Daniel Anderson,https://github.com/datalorax/esvis,TRUE,https://github.com/datalorax/esvis,10884,43,2020-04-30T20:03:53Z,253.11627906976744
ETAS,"Fits the space-time Epidemic Type Aftershock Sequence
    ('ETAS') model to earthquake catalogs using a stochastic 'declustering' 
    approach. The 'ETAS' model is a 'spatio-temporal' marked point process
    model and a special case of the 'Hawkes' process. The package is based 
    on a Fortran program by 'Jiancang Zhuang'
    (available at <http://bemlar.ism.ac.jp/zhuang/software.html>),
    which is modified and translated into C++ and C such that it 
    can be called from R. Parallel computing with 'OpenMP' is possible 
    on supported platforms.",2019-01-25,Abdollah Jalilian,https://github.com/jalilian/ETAS,TRUE,https://github.com/jalilian/etas,26345,6,2019-10-15T15:42:51Z,4390.833333333333
ethnobotanyR,"An implementation of the quantitative ethnobotany indices in R. The goal is to provide an easy-to-use platform for ethnobotanists to assess the cultural significance of plant species based on informant consensus. The package closely follows the paper by Tardio and Pardo-de-Santayana (2008). Tardio, J., and M. Pardo-de-Santayana, 2008. Cultural Importance Indices: A Comparative Analysis Based on the Useful Wild Plants of Southern Cantabria (Northern Spain) 1. Economic Botany, 62(1), 24-39. <doi:10.1007/s12231-007-9004-5>.",2020-01-30,Cory Whitney,https://CRAN.R-project.org/package=ethnobotanyR,TRUE,https://github.com/cwwhitney/ethnobotanyr,8489,3,2020-06-09T11:36:26Z,2829.6666666666665
etl,"A predictable and pipeable framework for performing ETL 
    (extract-transform-load) operations on publicly-accessible medium-sized data 
    set. This package sets up the method structure and implements generic 
    functions. Packages that depend on this package download specific data sets 
    from the Internet, clean them up, and import them into a local or remote 
    relational database management system.",2020-06-02,Ben Baumer,http://github.com/beanumber/etl,TRUE,https://github.com/beanumber/etl,22725,109,2020-06-04T19:35:30Z,208.4862385321101
ETLUtils,"Provides functions to facilitate the use of the 'ff' package
    in interaction with big data in 'SQL' databases (e.g. in 'Oracle', 'MySQL',
    'PostgreSQL', 'Hive') by allowing easy importing directly into 'ffdf' objects
    using 'DBI', 'RODBC' and 'RJDBC'. Also contains some basic utility functions to
    do fast left outer join merging based on 'match', factorisation of data and a
    basic function for re-coding vectors.",2018-01-25,Jan Wijffels,https://github.com/jwijffels/ETLUtils,TRUE,https://github.com/jwijffels/etlutils,31876,16,2020-04-28T21:29:12Z,1992.25
eudract,"The remit of the European Clinical Trials Data Base (EudraCT <https://eudract.ema.europa.eu/> ) is to provide open access to summaries of all registered clinical trial results; thus aiming to prevent non-reporting of negative results and provide open-access to results to inform future research. The amount of information required and the format of the results, however, imposes a large extra workload at the end of studies on clinical trial units. In particular, the adverse-event-reporting component requires entering: each unique combination of treatment group and safety event; for every such event above, a further 4 pieces of information (body system, number of occurrences, number of subjects, number exposed) for non-serious events, plus an extra three pieces of data for serious adverse events (numbers of causally related events, deaths, causally related deaths). This package prepares the required statistics needed by EudraCT and formats them into the precise requirements to directly upload an XML file into the web portal, with no further data entry by hand.",2020-04-06,Simon Bond,https://eudract-tool.medschl.cam.ac.uk/,TRUE,https://github.com/shug0131/eudract,3313,2,2020-04-03T08:09:19Z,1656.5
eulerr,"Generate area-proportional Euler diagrams
    using numerical optimization. An Euler diagram is a generalization of a Venn
    diagram, relaxing the criterion that all interactions need to be
    represented. Diagrams may be fit with ellipses and circles via
    a wide range of inputs and can be visualized in numerous ways.",2020-03-09,Johan Larsson,"https://github.com/jolars/eulerr, https://jolars.github.io/eulerr/",TRUE,https://github.com/jolars/eulerr,48085,69,2020-03-09T10:35:38Z,696.8840579710145
europepmc,"An R Client for the Europe PubMed Central RESTful Web Service
    (see <https://europepmc.org/RestfulWebService> for more information). It
    gives access to both metadata on life science literature and open access
    full texts. Europe PMC indexes all PubMed content and other literature
    sources including Agricola, a bibliographic database of citations to the
    agricultural literature, or Biological Patents. In addition to bibliographic
    metadata, the client allows users to fetch citations and reference lists.
    Links between life-science literature and other EBI databases, including
    ENA, PDB or ChEMBL are also accessible. No registration or API key is
    required. See the vignettes for usage examples.",2020-05-31,Najko Jahn,"https://docs.ropensci.org/europepmc,
http://github.com/ropensci/europepmc/",TRUE,https://github.com/ropensci/europepmc,107926,17,2020-06-05T13:03:51Z,6348.588235294118
eurostat,"Tools to download data from the Eurostat database
    <http://ec.europa.eu/eurostat> together with search and
    manipulation utilities.",2020-02-11,Leo Lahti,https://ropengov.github.io/eurostat,TRUE,https://github.com/ropengov/eurostat,82389,153,2020-05-12T12:15:33Z,538.4901960784314
evabic,"Evaluates the performance of binary classifiers.
    Computes confusion measures (TP, TN, FP, FN), derived measures (TPR,
    FDR, accuracy, F1, DOR, ..), and area under the curve.  Outputs are
    well suited for nested dataframes.",2020-03-08,Antoine Bichat,"https://abichat.github.io/evabic,
https://github.com/abichat/evabic",TRUE,https://github.com/abichat/evabic,1482,5,2020-04-04T09:49:51Z,296.4
evalITR,"A collection of statistical methods for evaluating individualized treatment rules under randomized data. The provided metrics include PAV (Population Average Value), PAPE (Population Average Prescription Effect), and AUPEC (Area Under Prescription Effect Curve). It also provides the tools to analyze individualized treatment rules under budget constraints. Imai and Li (2019) <arXiv:1905.05389>.",2020-02-20,Michael Lingzhi Li,https://github.com/MichaelLLi/evalITR,TRUE,https://github.com/michaellli/evalitr,1733,1,2020-05-24T16:11:44Z,1733
evaluate,"Parsing and evaluation tools that make it easy to recreate the
    command line behaviour of R.",2019-05-28,Yihui Xie,https://github.com/r-lib/evaluate,TRUE,https://github.com/r-lib/evaluate,17577584,85,2020-02-06T16:35:46Z,206795.10588235295
evaluator,"An open source risk analysis toolkit based on the OpenFAIR ontology 
  <https://www2.opengroup.org/ogsys/catalog/C13K> and risk assessment standard 
  <https://www2.opengroup.org/ogsys/catalog/C13G>. Empowers an organization to 
  perform a quantifiable, repeatable, and data-driven risk review.",2020-04-16,David Severski,https://evaluator.tidyrisk.org,TRUE,https://github.com/davidski/evaluator,18367,77,2020-04-15T22:41:15Z,238.53246753246754
EventDetectR,Detect events in time-series data. Combines multiple well-known R packages like 'forecast' and 'neuralnet' to deliver an easily configurable tool for multivariate event detection.,2020-01-23,Sowmya Chandrasekaran,https://github.com/frehbach/EventDetectR,TRUE,https://github.com/frehbach/eventdetectr,7771,9,2020-06-08T18:49:55Z,863.4444444444445
eventstudies,"A platform for conducting event studies (Fama, Fisher,
             Jensen, Roll (1969) <doi:10.2307/2525569>) and for
             methodological research on event studies. The package
             supports market model, augmented market model, and excess
             returns methods for data modelling along with Wilcox,
             classical t-test, and Bootstrap as inference procedures.",2020-06-02,Chirag Anand,https://github.com/nipfpmf/eventstudies,TRUE,https://github.com/nipfpmf/eventstudies,11304,14,2020-06-03T05:17:54Z,807.4285714285714
EventStudy,"Perform Event Studies from through our <http://EventStudyTools.com> Application Programming Interface, parse the results, visualize it, and / or use the results in further analysis.",2019-03-14,Dr. Simon Mueller,http://eventstudytools.com,TRUE,https://github.com/eventstudytools/api-wrapper.r,17171,8,2019-08-02T13:50:28Z,2146.375
EviewsR,It allows running 'EViews'(<https://eviews.com>) program from R Markdown. 'EViews' (Econometric Views) is a statistical software for Econometric analysis.  This package serves as an 'EViews' Knit-Engine for 'knitr' package. Write all your 'EViews' commands in R Markdown chunk.,2020-06-04,Sagiru Mati,https://smati.com.ng,TRUE,https://github.com/sagirumati/eviewsr,0,1,2020-06-08T08:32:28Z,0
evolqg,"Provides functions for covariance matrix comparisons, estimation
    of repeatabilities in measurements and matrices, and general evolutionary
    quantitative genetics tools.",2020-02-06,Ana Paula Assis,NA,TRUE,https://github.com/lem-usp/evolqg,22573,6,2020-02-13T16:25:14Z,3762.1666666666665
ewoc,"An implementation of a variety of escalation with overdose control designs introduced by Babb, Rogatko and Zacks (1998) <doi:10.1002/(SICI)1097-0258(19980530)17:10%3C1103::AID-SIM793%3E3.0.CO;2-9>. It calculates the next dose as a clinical trial proceeds and performs simulations to obtain operating characteristics.",2020-06-07,Marcio A. Diniz,https://github.com/dnzmarcio/ewoc/,TRUE,https://github.com/dnzmarcio/ewoc,10196,2,2020-06-07T06:46:48Z,5098
exactextractr,"Provides a replacement for the 'extract' function from the 'raster' package
    that is suitable for extracting raster values using 'sf' polygons.",2020-05-07,Daniel Baston,"https://isciences.gitlab.io/exactextractr/,
https://github.com/isciences/exactextractr",TRUE,https://github.com/isciences/exactextractr,11867,66,2020-05-26T23:32:29Z,179.8030303030303
exams.mylearn,"Randomized multiple-select and single-select
  question generation for the 'MyLearn' teaching and learning
  platform. Question templates
  in the form of the R/exams package (see <http://www.r-exams.org/>)
  are transformed into XML format required by 'MyLearn'.",2020-05-25,Darjus Hosszejni,https://github.com/hdarjus/WU-MyLearn-QGen,TRUE,https://github.com/hdarjus/wu-mylearn-qgen,152,1,2020-05-26T08:28:17Z,152
exceedProb,Computes confidence intervals for the exceedance probability of normally distributed estimators. Currently only supports general linear models. Please see Segal (2019) <arXiv:1803.03356> for more information.,2019-08-27,Brian D. Segal,https://github.com/bdsegal/exceedProb,TRUE,https://github.com/bdsegal/exceedprob,3598,0,2019-12-13T04:22:19Z,NA
excelR,An R interface to 'jExcel' library to create web-based interactive tables and spreadsheets compatible with 'Excel' or any other spreadsheet software.,2020-03-09,Swechhya Bista,https://github.com/Swechhya/excelR,TRUE,https://github.com/swechhya/excelr,11416,99,2020-05-08T12:26:18Z,115.31313131313131
exdex,"Performs frequentist inference for the extremal index of a 
    stationary time series.  Two types of methodology are used.  One type is
    based on a model that relates the distribution of block maxima to the 
    marginal distribution of series and leads to the semiparametric maxima 
    estimators described in Northrop (2015) <doi:10.1007/s10687-015-0221-5> and 
    Berghaus and Bucher (2018) <doi:10.1214/17-AOS1621>.  Sliding block maxima
    are used to increase precision of estimation. The other type of methodology
    uses a model for the distribution of threshold inter-exceedance times
    (Ferro and Segers (2003) <doi:10.1111/1467-9868.00401>). Two 
    versions of this type of approach are provided, following Suveges (2007) 
    <doi:10.1007/s10687-007-0034-2> and Suveges and Davison (2010)  
    <doi:10.1214/09-AOAS292>.",2019-08-06,Paul J. Northrop,http://github.com/paulnorthrop/exdex,TRUE,https://github.com/paulnorthrop/exdex,4185,0,2019-12-03T21:00:25Z,NA
ExPanDaR,"Provides a shiny-based front end (the 'ExPanD' app) and
    a set of functions for exploratory data analysis. Run as a web-based 
    app, 'ExPanD' enables users to assess the robustness of empirical evidence 
    without providing them access to the underlying data. You can export a 
    notebook containing the analysis of 'ExPanD' and/or use the functions of the 
    package to support your exploratory data analysis workflow. Refer to the 
    vignettes of the package for more information on how to use 'ExPanD' and/or 
    the functions of this package.",2020-01-29,Joachim Gassen,https://joachim-gassen.github.io/ExPanDaR,TRUE,https://github.com/joachim-gassen/expandar,14481,68,2020-06-09T19:28:12Z,212.9558823529412
experiment,"Provides various statistical methods for
  designing and analyzing randomized experiments. One functionality
  of the package is the implementation of randomized-block and
  matched-pair designs based on possibly multivariate pre-treatment
  covariates. The package also provides the tools to analyze various
  randomized experiments including cluster randomized experiments,
  two-stage randomized experiments, randomized experiments with 
  noncompliance, and randomized experiments with missing data.",2019-08-05,Kosuke Imai,https://github.com/kosukeimai/experiment,TRUE,https://github.com/kosukeimai/experiment,26441,7,2019-08-05T16:03:10Z,3777.285714285714
ExpertChoice,Supports designing efficient discrete choice experiments (DCEs). Experimental designs can be formed on the basis of orthogonal arrays or search methods for optimal designs (Federov or mixed integer programs). Various methods for converting these experimental designs into a discrete choice experiment. Many efficiency measures! Draws from literature of Kuhfeld (2010) and Street et. al (2005) <doi:10.1016/j.ijresmar.2005.09.003>.,2020-04-03,Jed Stephens,NA,TRUE,https://github.com/jedstephens/expertchoice,951,3,2020-04-07T17:18:11Z,317
explor,Shiny interfaces and graphical functions for multivariate analysis results exploration.,2020-05-02,Julien Barnier,https://juba.github.io/explor/,TRUE,https://github.com/juba/explor,42298,150,2020-05-26T12:58:54Z,281.9866666666667
explore,"Interactive data exploration with one line of code or use an easy to remember set of tidy functions for exploratory data analysis. Introduces three main verbs. explore() to graphically explore a variable or table, describe() to describe a variable or table and report() to create an automated report.",2020-04-06,Roland Krasser,http://github.com/rolkra/explore,TRUE,https://github.com/rolkra/explore,9097,33,2020-04-05T21:48:59Z,275.6666666666667
ExPosition,"A variety of descriptive multivariate analyses with the singular value decomposition,
    such as principal components analysis, correspondence analysis, and multidimensional scaling.
    See An ExPosition of the Singular Value Decomposition in R (Beaton et al 2014) <doi:10.1016/j.csda.2013.11.006>.",2019-01-07,Derek Beaton,NA,TRUE,https://github.com/derekbeaton/exposition-family_old,66239,2,2019-11-16T21:33:20Z,33119.5
expss,"Package computes and displays tables with support for 'SPSS'-style 
        labels, multiple and nested banners, weights, multiple-response variables 
        and significance testing. There are facilities for nice output of tables 
        in 'knitr', 'Shiny', '*.xlsx' files, R and 'Jupyter' notebooks. Methods 
        for labelled variables add value labels support to base R functions and to 
        some functions from other packages. Additionally, the package brings 
        popular data transformation functions from 'SPSS' Statistics and 'Excel': 
        'RECODE', 'COUNT', 'COMPUTE', 'DO IF', 'COUNTIF', 'VLOOKUP' and etc. 
        These functions are very useful for data processing in marketing research 
        surveys. Package intended to help people to move data 
        processing from 'Excel' and 'SPSS' to R.",2020-03-25,Gregory Demin,https://gdemin.github.io/expss/,TRUE,https://github.com/gdemin/expss,136199,48,2020-04-04T11:13:29Z,2837.4791666666665
extraDistr,"Density, distribution function, quantile function
    and random generation for a number of univariate
    and multivariate distributions. This package implements the
    following distributions: Bernoulli, beta-binomial, beta-negative
    binomial, beta prime, Bhattacharjee, Birnbaum-Saunders,
    bivariate normal, bivariate Poisson, categorical, Dirichlet,
    Dirichlet-multinomial, discrete gamma, discrete Laplace,
    discrete normal, discrete uniform, discrete Weibull, Frechet,
    gamma-Poisson, generalized extreme value, Gompertz,
    generalized Pareto, Gumbel, half-Cauchy, half-normal, half-t,
    Huber density, inverse chi-squared, inverse-gamma, Kumaraswamy,
    Laplace, location-scale t, logarithmic, Lomax, multivariate
    hypergeometric, multinomial, negative hypergeometric, 
    non-standard beta, normal mixture, Poisson mixture, Pareto,
    power, reparametrized beta, Rayleigh, shifted Gompertz, Skellam,
    slash, triangular, truncated binomial, truncated normal,
    truncated Poisson, Tukey lambda, Wald, zero-inflated binomial,
    zero-inflated negative binomial, zero-inflated Poisson.",2019-06-10,Tymoteusz Wolodzko,https://github.com/twolodzko/extraDistr,TRUE,https://github.com/twolodzko/extradistr,432331,22,2020-02-12T23:00:44Z,19651.409090909092
extrafont,"Tools to using fonts other than the standard PostScript fonts.
    This package makes it easy to use system TrueType fonts and with PDF or
    PostScript output files, and with bitmap output files in Windows. extrafont
    can also be used with fonts packaged specifically to be used with, such as
    the fontcm package, which has Computer Modern PostScript fonts with math
    symbols. See https://github.com/wch/extrafont for instructions and
    examples.",2014-12-08,Winston Chang,https://github.com/wch/extrafont,TRUE,https://github.com/wch/extrafont,930005,227,2020-01-20T18:17:21Z,4096.938325991189
extraoperators,"Speed up common tasks, particularly logical or
  relational comparisons and routine follow up tasks such as finding the
  indices and subsetting. Inspired by mathematics, where something like:
  3 < x < 6 is a standard, elegant and clear way to assert that
  x is both greater than 3 and less than 6
  (see for example <https://en.wikipedia.org/wiki/Relational_operator>),
  a chaining operator is implemented. The chaining operator, %c%,
  allows multiple relational operations to be used in quotes on the right
  hand side for the same object, on the left hand side.
  The %e% operator allows something like set-builder notation 
  (see for example <https://en.wikipedia.org/wiki/Set-builder_notation>) 
  to be used on the right hand side.
  All operators have built in prefixes defined for all, subset, and which
  to reduce the amount of code needed for common tasks, such as return those
  values that are true.",2019-11-04,Joshua F. Wiley,"http://joshuawiley.com/extraoperators,
https://github.com/JWiley/extraoperators",TRUE,https://github.com/jwiley/extraoperators,3773,3,2019-11-11T06:01:07Z,1257.6666666666667
extremeStat,"Code to fit, plot and compare several (extreme value)
    distribution functions. Can also compute (truncated) distribution quantile estimates and
    draw a plot with return periods on a linear scale.",2017-11-05,Berry Boessenkool,https://github.com/brry/extremeStat,TRUE,https://github.com/brry/extremestat,17590,7,2020-06-09T07:56:36Z,2512.8571428571427
exuber,"Testing for and dating periods of explosive
    dynamics (exuberance) in time series using the univariate and panel
    recursive unit root tests proposed by Phillips et al. (2015)
    <doi:10.1111/iere.12132> and Pavlidis et al. (2016)
    <doi:10.1007/s11146-015-9531-2>.  The recursive least-squares
    algorithm utilizes the matrix inversion lemma to avoid matrix
    inversion which results in significant speed improvements. Simulation
    of a variety of periodically-collapsing bubble processes.",2020-05-12,Kostas Vasilopoulos,https://github.com/kvasilopoulos/exuber,TRUE,https://github.com/kvasilopoulos/exuber,10022,9,2020-05-12T12:55:06Z,1113.5555555555557
eyelinker,"Imports plain-text ASC data files from EyeLink eye trackers 
    into (relatively) tidy data frames for analysis and visualization.",2019-09-22,Simon Barthelme,https://github.com/a-hurst/eyelinker,TRUE,https://github.com/a-hurst/eyelinker,13966,1,2019-12-01T18:02:45Z,13966
eyetrackingR,"A set of tools that address tasks along the pipeline from raw
    data to analysis and visualization for eye-tracking data. Offers several
    popular types of analyses, including linear and growth curve time analyses,
    onset-contingent reaction time analyses, as well as several non-parametric
    bootstrapping approaches.",2018-12-03,Jacob Dink,http://eyetracking-r.com,TRUE,https://github.com/jwdink/eyetrackingr,20220,57,2020-01-11T22:02:46Z,354.7368421052632
ezcox,"A tool to operate a batch of univariate or multivariate 
    Cox models and return tidy result.",2020-06-03,Shixiang Wang,https://github.com/ShixiangWang/ezcox,TRUE,https://github.com/shixiangwang/ezcox,3762,5,2020-06-04T13:32:33Z,752.4
ezknitr,"An extension of 'knitr' that adds flexibility in several
    ways. One common source of frustration with 'knitr' is that it assumes
    the directory where the source file lives should be the working directory,
    which is often not true. 'ezknitr' addresses this problem by giving you
    complete control over where all the inputs and outputs are, and adds several
    other convenient features to make rendering markdown/HTML documents easier.",2016-09-16,Dean Attali,https://github.com/ropenscilabs/ezknitr,TRUE,https://github.com/ropenscilabs/ezknitr,22077,86,2019-12-09T12:23:15Z,256.7093023255814
ezpickr,"Choosing any rectangular data file using interactive GUI dialog box, and seamlessly manipulating tidy data between an 'Excel' window and R session.",2019-11-17,JooYoung Seo,https://github.com/jooyoungseo/ezpickr,TRUE,https://github.com/jooyoungseo/ezpickr,12826,4,2020-05-16T14:58:16Z,3206.5
fable,"Provides a collection of commonly used univariate and multivariate
    time series forecasting models including automatically selected exponential 
    smoothing (ETS) and autoregressive integrated moving average (ARIMA) models.
    These models work within the 'fable' framework provided by the 'fabletools'
    package, which provides the tools to evaluate, visualise, and combine models 
    in a workflow consistent with the tidyverse.",2020-04-22,Mitchell OHara-Wild,"https://fable.tidyverts.org, https://github.com/tidyverts/fable",TRUE,https://github.com/tidyverts/fable,48174,296,2020-06-04T11:13:16Z,162.75
fabletools,"Provides tools, helpers and data structures for developing models and time series functions for 'fable' and extension packages. These tools support a consistent and tidy interface for time series modelling and analysis.",2020-03-24,Mitchell OHara-Wild,"http://fabletools.tidyverts.org/,
https://github.com/tidyverts/fabletools",TRUE,https://github.com/tidyverts/fabletools,56056,42,2020-06-08T10:11:10Z,1334.6666666666667
fabMix,"Model-based clustering of multivariate continuous data using Bayesian mixtures of factor analyzers (Papastamoulis (2019) <DOI:10.1007/s11222-019-09891-z> (2018) <DOI:10.1016/j.csda.2018.03.007>). The number of clusters is estimated using overfitting mixture models (Rousseau and Mengersen (2011) <DOI:10.1111/j.1467-9868.2011.00781.x>): suitable prior assumptions ensure that asymptotically the extra components will have zero posterior weight, therefore, the inference is based on the ``alive'' components. A Gibbs sampler is implemented in order to (approximately) sample from the posterior distribution of the overfitting mixture. A prior parallel tempering scheme is also available, which allows to run multiple parallel chains with different prior distributions on the mixture weights. These chains run in parallel and can swap states using a Metropolis-Hastings move. Eight different parameterizations give rise to parsimonious representations of the covariance per cluster (following Mc Nicholas and Murphy (2008) <DOI:10.1007/s11222-008-9056-0>). The model parameterization and number of factors is selected according to the Bayesian Information Criterion. Identifiability issues related to label switching are dealt by post-processing the simulated output with the Equivalence Classes Representatives algorithm (Papastamoulis and Iliopoulos (2010) <https://www.jstor.org/stable/25703571>, Papastamoulis (2016) <DOI:10.18637/jss.v069.c01>). ",2020-02-19,Panagiotis Papastamoulis,https://github.com/mqbssppe/overfittingFABMix,TRUE,https://github.com/mqbssppe/overfittingfabmix,8398,1,2020-02-20T07:01:43Z,8398
fabricatr,"Helps you imagine your data before you collect it. Hierarchical data structures
   and correlated data can be easily simulated, either from random number generators or
   by resampling from existing data sources. This package is faster with 'data.table' and
   'mvnfast' installed.",2019-09-04,Graeme Blair,"https://declaredesign.org/r/fabricatr,
https://github.com/DeclareDesign/fabricatr",TRUE,https://github.com/declaredesign/fabricatr,22867,64,2019-11-01T23:42:53Z,357.296875
facerec,"Provides an interface to the 'Kairos' Face Recognition API <https://kairos.com/face-recognition-api>. The API detects faces in images and returns estimates for demographics like gender, ethnicity and age.  ",2018-05-14,Carsten Schwemmer,https://github.com/methodds/facerec,TRUE,https://github.com/methodds/facerec,7902,30,2019-06-18T09:50:03Z,263.4
factoextra,"Provides some easy-to-use functions to extract and visualize the
    output of multivariate data analyses, including 'PCA' (Principal Component
    Analysis), 'CA' (Correspondence Analysis), 'MCA' (Multiple Correspondence
    Analysis), 'FAMD' (Factor Analysis of Mixed Data), 'MFA' (Multiple Factor Analysis) and 'HMFA' (Hierarchical Multiple
    Factor Analysis) functions from different R packages. It contains also functions
    for simplifying some clustering analysis steps and provides 'ggplot2' - based
    elegant data visualization.",2020-04-01,Alboukadel Kassambara,http://www.sthda.com/english/rpkgs/factoextra,TRUE,https://github.com/kassambara/factoextra,1262178,205,2020-04-01T21:19:20Z,6156.965853658537
FactorAssumptions,"Tests for Kaiser-Meyer-Olkin (KMO) and
    communalities in a dataset. It provides a final sample by removing
    variables in a iterable manner while keeping account of the variables
    that were removed in each step. It follows the best practices and assumptions according to
    Hair, Black, Babin & Anderson (2018, ISBN:9781473756540).",2020-03-06,Jose Storopoli,https://github.com/storopoli/FactorAssumptions,TRUE,https://github.com/storopoli/factorassumptions,1206,1,2020-02-29T15:31:18Z,1206
factorEx,"Provides design-based and model-based estimators for the population average marginal component effects in general factorial experiments, including conjoint analysis. The package also implements a series of recommendations offered in de la Cuesta, Egami, and Imai (2019+), and Egami and Imai (2019) <doi:10.1080/01621459.2018.1476246>.",2020-05-11,Naoki Egami,https://github.com/naoki-egami/factorEx,TRUE,https://github.com/naoki-egami/factorex,3969,0,2020-05-11T15:58:50Z,NA
factorMerger,"
    The Merging Path Plot is a methodology for adaptive fusing of k-groups 
    with likelihood-based model selection. This package contains tools for 
    exploration and visualization of k-group dissimilarities. 
    Comparison of k-groups is one of the most important issues
    in exploratory analyses and it has zillions of applications. 
    The traditional approach is to use pairwise post hoc tests
    in order to verify which groups differ significantly. However, 
    this approach fails with a large number of groups in both interpretation 
    and visualization layer.
    The Merging Path Plot solves this problem by using an easy-to-understand 
    description of dissimilarity among groups based on Likelihood Ratio Test (LRT) statistic (Sitko, Biecek 2017) <arXiv:1709.04412>.
    'factorMerger' is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.
    Work on this package was financially supported by the 'NCN Opus grant 2016/21/B/ST6/02176'.",2019-07-03,Tomasz Mikołajczyk,https://github.com/MI2DataLab/factorMerger,TRUE,https://github.com/mi2datalab/factormerger,24313,22,2019-11-18T10:04:39Z,1105.1363636363637
factory,"Function factories are functions that make functions. They can be 
    confusing to construct. Straightforward techniques can produce functions 
    that are fragile or hard to understand. While more robust techniques exist 
    to construct function factories, those techniques can be confusing. This 
    package is designed to make it easier to construct function factories.",2019-08-21,Jon Harmon,https://github.com/jonthegeek/factory,TRUE,https://github.com/jonthegeek/factory,3638,37,2020-06-03T19:23:20Z,98.32432432432432
factset.analyticsapi.engines,"Allow clients to fetch 'analytics' through API for Portfolio 
    'Analytics'('PA'), Style Performance Risk('SPAR') and 'Vault' products of 
    'FactSet'. Visit 
    <https://github.com/factset/analyticsapi-engines-r-sdk/tree/master/Engines>
    for more information on the usage of package. Visit 
    <https://developer.factset.com/> for more information on products.",2020-02-02,Akshay Sheth,https://github.com/factset/analyticsapi-engines-r-sdk,TRUE,https://github.com/factset/analyticsapi-engines-r-sdk,2051,1,2020-01-23T11:53:39Z,2051
factset.protobuf.stach,"Generates 'RProtobuf' classes for 'FactSet' 'STACH' tabular 
    format which represents complex multi-dimensional array of data. These 
    classes help in the 'serialization' and 'deserialization' of 'STACH' 
    formatted data. See 'GitHub' repository documentation for more 
    information.",2020-01-14,analytics-reporting,https://github.com/factset/stachschema,TRUE,https://github.com/factset/stachschema,2435,3,2020-04-27T10:05:18Z,811.6666666666666
fad,"Compute maximum likelihood estimators of parameters in a Gaussian factor model using
  the the matrix-free methodology described in Dai et al. (2019) <doi:10.1080/10618600.2019.1704296>.
  In contrast to the factanal() function from 'stats' package, fad() can handle high-dimensional datasets where
  number of variables exceed the sample size and is also substantially faster than the EM algorithms.",2020-01-24,Somak Dutta,https://github.com/somakd/fad,TRUE,https://github.com/somakd/fad,2180,2,2020-02-01T06:15:49Z,1090
FAdist,Probability distributions that are sometimes useful in hydrology.,2020-04-15,Francois Aucoin,https://github.com/tpetzoldt/FAdist,TRUE,https://github.com/tpetzoldt/fadist,35553,4,2020-04-15T05:45:10Z,8888.25
fairness,"Offers various metrics of algorithmic fairness. Fairness in machine learning is an emerging topic with the overarching aim to critically assess algorithms (predictive and classification models) whether their results reinforce existing social biases. While unfair algorithms can propagate such biases and offer prediction or classification results with a disparate impact on various sensitive subgroups of populations (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities), fair algorithms possess the underlying foundation that these groups should be treated similarly / should have similar outcomes. The fairness R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. These methods are described by Calders and Verwer (2010) <doi:10.1007/s10618-010-0190-x>, Chouldechova (2017) <doi:10.1089/big.2016.0047>, Feldman et al. (2015) <doi:10.1145/2783258.2783311> , Friedler et al. (2018) <doi:10.1145/3287560.3287589> and Zafar et al. (2017) <doi:10.1145/3038912.3052660>. The package also offers convenient visualizations to help understand fairness metrics.",2020-05-01,Nikita Kozodoi,NA,TRUE,https://github.com/kozodoi/fairness,3790,10,2020-05-15T16:48:45Z,379
fanplot,"Visualise sequential distributions using a range of plotting
    styles. Sequential distribution data can be input as either simulations or
    values corresponding to percentiles over time. Plots are added to
    existing graphic devices using the fan function. Users can choose from four
    different styles, including fan chart type plots, where a set of coloured
    polygon, with shadings corresponding to the percentile values are layered
    to represent different uncertainty levels. Full details in R Journal article; Abel (2015) <doi:10.32614/RJ-2015-002>.",2019-12-18,Guy J. Abel,https://github.com/gjabel/fanplot,TRUE,https://github.com/gjabel/fanplot,47034,0,2019-12-16T12:55:36Z,NA
fansi,"Counterparts to R string manipulation functions that account for
   the effects of ANSI text formatting control sequences.",2020-01-08,Brodie Gaslam,https://github.com/brodieG/fansi,TRUE,https://github.com/brodieg/fansi,14247072,37,2020-01-09T13:43:52Z,385056
faoutlier,"Tools for detecting and summarize influential cases that
    can affect exploratory and confirmatory factor analysis models as well as
    structural equation models more generally.",2017-07-22,Phil Chalmers,https://github.com/philchalmers/faoutlier,TRUE,https://github.com/philchalmers/faoutlier,25607,5,2020-06-08T18:42:43Z,5121.4
FarmTest,"Performs robust multiple testing for means in the presence of known and unknown latent factors presented in Fan et al.(2019) ""FarmTest: Factor-Adjusted Robust Multiple Testing With Approximate False Discovery Control"" <doi:10.1080/01621459.2018.1527700>.
             Implements a series of adaptive Huber methods combined with fast data-drive tuning schemes proposed in Ke et al.(2019) ""User-Friendly Covariance Estimation for Heavy-Tailed Distributions"" <doi:10.1214/19-STS711> to estimate model parameters and construct test statistics that are robust against heavy-tailed and/or asymmetric error distributions. 
             Extensions to two-sample simultaneous mean comparison problems are also included. 
             As by-products, this package contains functions that compute adaptive Huber mean, covariance and regression estimators that are of independent interest.",2020-04-28,Xiaoou Pan,https://github.com/XiaoouPan/FarmTest,TRUE,https://github.com/xiaooupan/farmtest,11649,2,2020-04-28T03:26:58Z,5824.5
farrell,"Allows the user to execute interactively radial data envelopment analysis models. The user has the ability to upload a data frame, 
    select the input/output variables, choose the technology assumption to adopt and decide whether to run an input or an output oriented model. 
    When the model is executed a set of results are displayed which include efficiency scores, peers' determination, scale efficiencies' evaluation 
    and slacks' calculation. Fore more information about the theoretical background of the package, 
    please refer to Bogetoft & Otto (2011) <doi:10.1007/978-1-4419-7961-2>.",2020-06-03,Mohamed El Fodil Ihaddaden,https://github.com/feddelegrand7/farrell,TRUE,https://github.com/feddelegrand7/farrell,0,3,2020-06-03T12:44:20Z,0
farver,"The encoding of colour can be handled in many different ways, using
    different colour spaces. As different colour spaces have different uses,
    efficient conversion between these representations are important. The 
    'farver' package provides a set of functions that gives access to very fast
    colour space conversion and comparisons implemented in C++, and offers 
    speed improvements over the 'convertColor' function in the 'grDevices' 
    package.",2020-01-16,Thomas Lin Pedersen,"https://farver.data-imaginist.com,
https://github.com/thomasp85/farver",TRUE,https://github.com/thomasp85/farver,4618709,58,2020-01-16T13:42:05Z,79632.91379310345
fasjem,"This is an R implementation of ""A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse Gaussian Graphical Models"" (FASJEM). The FASJEM algorithm can be used to estimate multiple related precision matrices. For instance, it can identify context-specific gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogonous data sets, this tool  can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(fasjem) to learn the basic functions provided by this package. For more details, please see <http://proceedings.mlr.press/v54/wang17e/wang17e.pdf>.",2017-08-01,Beilun Wang,https://github.com/QData/JEM,TRUE,https://github.com/qdata/jem,11736,0,2019-08-28T16:28:07Z,NA
fasstr,"The Flow Analysis Summary Statistics Tool for R, 'fasstr', provides various 
    functions to clean and screen daily stream discharge data; calculate and visualize various summary statistics
    and metrics; and compute annual trending (using 'zyp' package methods <https://CRAN.R-project.org/package=zyp>)
    and volume frequency analyses (using methods similar to HEC-SSP (2019) 
    <https://www.hec.usace.army.mil/software/hec-ssp/>). It features useful function arguments for filtering of and
    handling dates, customizing data and metrics, and the ability to pull daily data directly from the Water Survey
    of Canada hydrometric database (<https://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/>).",2020-01-09,Jon Goetz,"https://github.com/bcgov/fasstr,
https://www2.gov.bc.ca/gov/content/environment/air-land-water/water",TRUE,https://github.com/bcgov/fasstr,2602,29,2020-05-29T16:57:12Z,89.72413793103448
fastDummies,"Creates dummy columns from columns that have categorical variables (character or factor types). You can also specify which columns to make dummies out of, or which columns to ignore. Also creates dummy rows from character, factor, and Date columns. This package provides a significant speed increase from creating dummy variables through model.matrix().",2020-03-07,Jacob Kaplan,https://github.com/jacobkap/fastDummies,TRUE,https://github.com/jacobkap/fastdummies,170328,25,2020-03-07T18:05:37Z,6813.12
fasterize,"Provides a drop-in replacement for rasterize() from the 'raster'
   package that takes 'sf'-type objects, and is much faster. There is support
   for the main options provided by the rasterize() function, including
   setting the field used and background value, and options for 
   aggregating multi-layer rasters. Uses the scan line algorithm attributed to
   Wylie et al. (1967) <doi:10.1145/1465611.1465619>.",2020-03-25,Noam Ross,https://github.com/ecohealthalliance/fasterize,TRUE,https://github.com/ecohealthalliance/fasterize,58374,131,2020-03-24T12:36:47Z,445.60305343511453
fastLink,"Implements a Fellegi-Sunter probabilistic record linkage model that allows for missing data
    and the inclusion of auxiliary information. This includes functionalities to conduct a merge of two 
    datasets under the Fellegi-Sunter model using the Expectation-Maximization algorithm. In addition, 
    tools for preparing, adjusting, and summarizing data merges are included. The package implements methods 
    described in Enamorado, Fifield, and Imai (2019) ''Using a Probabilistic Model to Assist Merging of 
    Large-scale Administrative Records'', American Political Science Review and is available 
    at <http://imai.fas.harvard.edu/research/linkage.html>.",2020-04-29,Ted Enamorado,NA,TRUE,https://github.com/kosukeimai/fastlink,17405,143,2020-04-29T22:45:57Z,121.7132867132867
fastlogranktest,"A very fast Log-Rank-Test implementation that is several orders of magnitude faster than the implementation in the 'survival' package.
  Log-Rank-Tests can be computed individually or concurrently using threading.",2020-06-04,Andreas Stelzer,https://github.com/compsysmed/fastlogranktest.git,TRUE,https://github.com/compsysmed/fastlogranktest,3043,0,2020-04-03T14:36:55Z,NA
fastmap,"Fast implementation of a key-value store. Environments are commonly
    used as key-value stores, but every time a new key is used, it is added to
    R's global symbol table, causing a small amount of memory leakage. This can
    be problematic in cases where many different keys are used. Fastmap avoids
    this memory leak issue by implementing the map using data structures in C++.",2019-10-08,Winston Chang,"https://r-lib.github.io/fastmap/, https://github.com/r-lib/fastmap",TRUE,https://github.com/r-lib/fastmap,3136924,80,2019-12-16T05:24:27Z,39211.55
fastNaiveBayes,"This is an extremely fast implementation of a Naive Bayes classifier. This 
    package is currently the only package that supports a Bernoulli distribution, a Multinomial 
    distribution, and a Gaussian distribution, making it suitable for both binary features, 
    frequency counts, and numerical features. Another feature is the support of a mix of 
    different event models. Only numerical variables are allowed, however, categorical variables 
    can be transformed into dummies and used with the Bernoulli distribution. 
    The implementation is largely based on the paper 
    ""A comparison of event models for Naive Bayes anti-spam e-mail filtering"" 
    written by K.M. Schneider (2003) <doi:10.3115/1067807.1067848>. Any issues can be 
    submitted to: <https://github.com/mskogholt/fastNaiveBayes/issues>.",2020-05-04,Martin Skogholt,https://github.com/mskogholt/fastNaiveBayes,TRUE,https://github.com/mskogholt/fastnaivebayes,11623,40,2020-05-04T10:17:26Z,290.575
fastpos,"Finds the critical sample size (""critical point of stability"") for a 
    correlation to stabilize in Schoenbrodt and Perugini's definition of 
    sequential stability (see <doi:10.1016/j.jrp.2013.05.009>).",2020-02-17,Johannes Titz,https://github.com/johannes-titz/fastpos,TRUE,https://github.com/johannes-titz/fastpos,3158,0,2020-02-17T10:33:33Z,NA
fastshap,"Computes fast (relative to other implementations) approximate 
    Shapley values for any supervised learning model. Shapley values help to 
    explain the predictions from any black box model using ideas from game 
    theory; see Strumbel and Kononenko (2014) <doi:10.1007/s10115-013-0679-x> 
    for details.",2020-02-02,Brandon Greenwell,https://github.com/bgreenwell/fastshap,TRUE,https://github.com/bgreenwell/fastshap,8789,32,2020-02-02T00:24:15Z,274.65625
fastStat,"When we do statistic work, we need to see the structure of the data.
    list.str() function will help you see the structure of the data quickly. 
    list.plot() function can help you check every variable in your dataframe.
    table_one() function will make it easy to make a baseline table including 
    difference tests. uv_linear(), uv_logit(), uv_cox(), uv_logrank() will give
    you a hand to do univariable regression analysis, while mv_linear(), 
    mv_logit() and mv_cox() will carry out multivariable regression analysis.",2019-11-22,Jing Zhang,https://github.com/yikeshu0611/fastStat,TRUE,https://github.com/yikeshu0611/faststat,2832,0,2019-11-16T12:43:45Z,NA
fauxnaif,"Provides a replacement for dplyr::na_if().  Allows you to specify
    multiple values to be replaced with NA using a single function.",2020-03-01,Alexander Rossell Hayes,https://github.com/rossellhayes/fauxnaif,TRUE,https://github.com/rossellhayes/fauxnaif,1631,0,2020-05-13T05:19:24Z,NA
fauxpas,"HTTP error helpers. Methods included for general purpose HTTP 
    error handling, as well as individual methods for every HTTP status
    code, both via status code numbers as well as their descriptive names.
    Supports ability to adjust behavior to stop, message or warning.
    Includes ability to use custom whisker template to have any configuration
    of status code, short description, and verbose message. Currently 
    supports integration with 'crul', 'curl', and 'httr'.",2020-04-13,Scott Chamberlain,"https://docs.ropensci.org/fauxpas,
https://github.com/ropensci/fauxpas",TRUE,https://github.com/ropensci/fauxpas,38178,11,2020-04-13T15:49:57Z,3470.7272727272725
fbRads,"Wrapper functions around the Facebook Marketing 'API' to create, read, update and delete custom audiences, images, campaigns, ad sets, ads and related content.",2016-04-06,Ajaykumar Gopal,https://github.com/cardcorp/fbRads,TRUE,https://github.com/cardcorp/fbrads,19047,114,2020-03-31T17:45:28Z,167.07894736842104
fc,"Provides a streamlined, standard evaluation-based approach to multivariate function composition. Allows for chaining commands via a forward-pipe operator, %>%.",2018-08-14,Xiaofei (Susan) Wang,https://github.com/swang87/fc,TRUE,https://github.com/swang87/fc,6996,0,2019-10-20T22:53:12Z,NA
fcaR,"Provides tools to perform fuzzy formal concept analysis, presented in Wille (1982) <doi:10.1007/978-3-642-01815-2_23> and in Ganter and Obiedkov (2016) <doi:10.1007/978-3-662-49291-8>.
    It provides functions to load and save a formal context, extract its concept lattice and implications. 
    In addition, one can use the implications to compute semantic closures of fuzzy sets and, thus, build recommendation systems.",2020-01-19,Domingo Lopez Rodriguez,https://github.com/neuroimaginador/fcaR,TRUE,https://github.com/neuroimaginador/fcar,2604,4,2020-05-25T18:21:36Z,651
FcircSEC,"Extract full length circular RNA sequences and classify circular RNA
             using the output of circular RNA prediction tools, reference genome and the annotation file corresponding to the reference genome.
             This package uses the output of circular RNA prediction tools such as 'CIRI', 'CIRCExplorer' and the output of other state-of-the-art circular RNA prediction tools.
             Details about the circular RNA prediction procedure can be found in
             'Yuan Gao, Jinfeng Wang and Fangqing Zhao' (2015) <doi:10.1186/s13059-014-0571-3>
             and 'Zhang XO, Wang HB, Zhang Y, Lu X, Chen LL and Yang L' (2014) <doi:10.1016/j.cell.2014.09.001>.",2020-01-31,Md. Tofazzal Hossain,https://github.com/tofazzal4720/FcircSEC,TRUE,https://github.com/tofazzal4720/fcircsec,1726,0,2020-01-21T06:34:17Z,NA
FCPS,"Many conventional clustering algorithms are provided in this package with consistent input and output, which enables the user to try out algorithms swiftly. Additionally, 26 statistical approaches for the estimation of the number of clusters as well as the the mirrored density plot (MD-plot) of clusterability are implemented. Moreover, the fundamental clustering problems suite (FCPS) offers a variety of clustering challenges any algorithm should handle when facing real world data, see Thrun, M.C., Ultsch A.: ""Clustering Benchmark Datasets Exploiting the Fundamental Clustering Problems"" (2020), Data in Brief, <DOI:10.1016/j.dib.2020.105501>.",2020-06-07,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/fcps,2257,3,2020-06-07T14:35:58Z,752.3333333333334
fda.usc,"Routines for exploratory and descriptive analysis of functional data such as depth measurements, atypical curves detection, regression models, supervised classification, unsupervised classification and functional analysis of variance.",2020-02-17,Manuel Oviedo de la Fuente,"https://github.com/moviedo5/fda.usc,
http://www.jstatsoft.org/v51/i04/",TRUE,https://github.com/moviedo5/fda.usc,88248,1,2020-02-17T09:54:39Z,88248
fdaACF,"Quantify the serial correlation across lags of a given functional 
    time series using an autocorrelation function for functional time series.
    The autocorrelation function is based on the L2 norm of the lagged covariance 
    operators of the series. Functions are available for estimating the 
    distribution of the autocorrelation function under the assumption 
    of strong functional white noise.",2020-01-24,Guillermo Mestre Marcos,https://github.com/GMestreM/fdaACF,TRUE,https://github.com/gmestrem/fdaacf,2337,3,2020-03-24T10:15:56Z,779
fdapace,"A versatile package that provides implementation of various
    methods of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this
    package is Functional Principal Component Analysis (FPCA), a key technique for
    functional data analysis, for sparsely or densely sampled random trajectories
    and time courses, via the Principal Analysis by Conditional Estimation
    (PACE) algorithm. This core algorithm yields covariance and mean functions,
    eigenfunctions and principal component (scores), for both functional data and
    derivatives, for both dense (functional) and sparse (longitudinal) sampling designs.
    For sparse designs, it provides fitted continuous trajectories with confidence bands,
    even for subjects with very few longitudinal observations. PACE is a viable and
    flexible alternative to random effects modeling of longitudinal data. There is also a
    Matlab version (PACE) that contains some methods not available on fdapace and vice
    versa. Please cite our package if you use it (You may run the command
    citation(""fdapace"") to get the citation format and bibtex entry).
    References: Wang, J.L., Chiou, J., Müller, H.G. (2016) <doi:10.1146/annurev-statistics-041715-033624>;
    Chen, K., Zhang, X., Petersen, A., Müller, H.G. (2017) <doi:10.1007/s12561-015-9137-5>.",2020-05-15,Cody Carroll,https://github.com/functionaldata/tPACE,TRUE,https://github.com/functionaldata/tpace,23955,15,2020-06-01T20:30:50Z,1597
fdistr,"Provides functionality to generate a frequency 
    distribution table from a set of observations and plot the frequency
    distribution using a Pareto chart.",2019-12-02,Donnie Minnick,https://github.com/dtminnick/fdistr,TRUE,https://github.com/dtminnick/fdistr,1722,1,2019-12-24T14:58:02Z,1722
feasts,"Provides a collection of features, decomposition methods, 
    statistical summaries and graphics functions for the analysing tidy time
    series data. The package name 'feasts' is an acronym comprising of its key
    features: Feature Extraction And Statistics for Time Series.",2020-03-18,Mitchell OHara-Wild,"http://feasts.tidyverts.org/, https://github.com/tidyverts/feasts/",TRUE,https://github.com/tidyverts/feasts,44061,157,2020-06-05T11:32:21Z,280.64331210191085
FeatureHashing,"Feature hashing, also called as the hashing trick, is a method to transform 
  features of a instance to a vector. Thus, it is a method to transform a real dataset to a matrix. 
  Without looking up the indices in an associative array, 
  it applies a hash function to the features and uses their hash values as indices directly.
  The method of feature hashing in this package was proposed in Weinberger et al. (2009) <arXiv:0902.2206>. 
  The hashing algorithm is the murmurhash3 from the 'digest' package. 
  Please see the README in <https://github.com/wush978/FeatureHashing> for more information.",2019-11-24,Wush Wu,https://github.com/wush978/FeatureHashing,TRUE,https://github.com/wush978/featurehashing,27791,94,2019-11-25T02:33:29Z,295.6489361702128
featuretoolsR,"A 'reticulate'-based interface to the 'Python' module 'Featuretools'.
  The package grants functionality to interact with 'Pythons' 'Featuretools' module, which allows 
  for automated feature engineering on any data frame. Valid features and new data sets can, after
  feature synthesis, easily be extracted.",2020-04-25,Magnus Furugård,https://github.com/magnusfurugard/featuretoolsR,TRUE,https://github.com/magnusfurugard/featuretoolsr,4206,39,2020-04-25T10:06:25Z,107.84615384615384
febr,"
  Making the access to the Free Brazilian Repository for Open Soil Data <http://www.ufsm.br/febr/> as easy 
  as possible.",2020-03-17,Alessandro Samuel-Rosa,https://github.com/febr-team/febr-package/,TRUE,https://github.com/febr-team/febr-package,9861,3,2020-04-15T02:34:49Z,3287
FedData,"Functions to automate downloading geospatial data available from
    several federated data sources (mainly sources maintained by the US Federal
    government). Currently, the package enables extraction from seven datasets:
    The National Elevation Dataset digital elevation models (1 and 1/3 arc-second;
    USGS); The National Hydrography Dataset (USGS); The Soil Survey Geographic
    (SSURGO) database from the National Cooperative Soil Survey (NCSS), which is
    led by the Natural Resources Conservation Service (NRCS) under the USDA; the
    Global Historical Climatology Network (GHCN), coordinated by National Climatic
    Data Center at NOAA; the Daymet gridded estimates of daily weather parameters 
    for North America, version 3, available from the Oak Ridge National Laboratory's
    Distributed Active Archive Center (DAAC); the International Tree Ring Data Bank; 
    and the National Land Cover Database (NLCD).",2019-04-22,R. Kyle Bocinsky,https://github.com/ropensci/FedData,TRUE,https://github.com/ropensci/feddata,56667,65,2020-04-27T20:07:30Z,871.8
fedregs,"The Code of Federal Regulations (CFR) annual edition is the codification 
    of the general and permanent rules published in the Federal Register by the departments
    and agencies of the Federal Government of the United States of America. Simply, the 
    'fedregs' package facilitates word processing and sentiment analysis of the CFR using tidy 
    principles. Note: According to the Code of Federal Regulations XML Rendition User Guide Document: 
    ""In general, there are no restrictions on re-use of information in Code of Federal Regulations
    material because U.S. Government works are not subject to copyright. OFR and GPO do not
    restrict downstream uses of Code of Federal Regulations data, except that independent providers
    should be aware that only the OFR and GPO are entitled to represent that they are the providers
    of the official versions of the Code of Federal Regulations and related Federal Register
    publications.""",2019-09-16,Scott Large,NA,TRUE,https://github.com/slarge/fedregs,8310,1,2020-05-27T13:34:26Z,8310
feedeR,Retrieve data from RSS/Atom feeds.,2020-04-19,Andrew Collier,https://github.com/datawookie/feedeR,TRUE,https://github.com/datawookie/feeder,19985,19,2020-04-19T14:09:00Z,1051.842105263158
feisr,"Provides the function feis() to estimate fixed effects individual 
    slope (FEIS) models. The FEIS model constitutes a more general version of 
    the often-used fixed effects (FE) panel model, as implemented in the 
    package 'plm' by Croissant and Millo (2008) <doi:10.18637/jss.v027.i02>. 
    In FEIS models, data are not only person ""demeaned"" like in conventional 
    FE models, but ""detrended"" by the predicted individual slope of each 
    person or group. Estimation is performed by applying least squares lm() 
    to the transformed data. For more details on FEIS models see Bruederl and 
    Ludwig (2015, ISBN:1446252442); Frees (2001) <doi:10.2307/3316008>; 
    Polachek and Kim (1994) <doi:10.1016/0304-4076(94)90075-2>; 
    Wooldridge (2010, ISBN:0262294354). To test consistency of conventional FE 
    and random effects estimators against heterogeneous slopes, the package 
    also provides the functions feistest() for an artificial regression test 
    and bsfeistest() for a bootstrapped version of the Hausman test.",2019-03-01,Tobias Ruettenauer,https://github.com/ruettenauer/feisr,TRUE,https://github.com/ruettenauer/feisr,11388,4,2020-06-09T19:55:38Z,2847
felp,"
    Provides pseudo-postfix operators and more to enhance displaying documents.
    The `?.` pseudo-postfix operator and the `?` prefix operator displays documents and contents (source or structure) of objects simultaneously to help understanding the objects.
    The `?p` pseudo-postfix operator displays package documents, and is shorter than help(package = foo).",2019-12-06,Atsushi Yasumoto,https://github.com/atusy/felp,TRUE,https://github.com/atusy/felp,4195,11,2020-05-10T23:52:42Z,381.3636363636364
FEprovideR,"A structured profile likelihood algorithm for the logistic fixed effects model and an approximate expectation maximization (EM) algorithm for the logistic mixed effects model. Based on He, K., Kalbfleisch, J.D., Li, Y. and Li, Y. (2013) <doi:10.1007/s10985-013-9264-6>.",2019-07-30,Michael Kleinsasser,NA,TRUE,https://github.com/umich-biostatistics/feprovider,4690,1,2019-07-30T13:09:32Z,4690
ffbase,"Extends the out of memory vectors of 'ff' with
    statistical functions and other utilities to ease their usage.",2020-03-18,Edwin de Jonge,http://github.com/edwindj/ffbase,TRUE,https://github.com/edwindj/ffbase,421150,28,2020-02-29T11:34:53Z,15041.07142857143
FFTrees,"Create, visualize, and test fast-and-frugal decision trees (FFTs). FFTs are very simple decision trees for
    binary classification problems. FFTs can be preferable to more complex algorithms because they are easy to communicate, 
    require very little information, and are robust against overfitting.",2020-06-08,Nathaniel Phillips,NA,TRUE,https://github.com/ndphillips/fftrees,34922,108,2020-06-08T18:40:23Z,323.35185185185185
fgdr,"Read and Parse for Fundamental Geo-Spatial Data (FGD) which downloads XML file 
    from providing site (<https://fgd.gsi.go.jp/download/menu.php>). The JPGIS format file 
    provided by FGD so that it can be handled as an R spatial object such as 'sf' and 'raster' or 'stars'.
    Supports the FGD version 4.1, and accepts fundamental items and digital elevation models.",2020-05-06,Shinya Uryu,https://github.com/uribo/fgdr,TRUE,https://github.com/uribo/fgdr,3607,5,2020-06-01T09:04:31Z,721.4
fgeo,"To help you access, transform, analyze, and
    visualize ForestGEO data, we developed a collection of R packages
    (<https://forestgeo.github.io/fgeo/>). This package, in particular,
    helps you to install and load the entire package-collection with a
    single R command, and provides convenient ways to find relevant
    documentation. Most commonly, you should not worry about the
    individual packages that make up the package-collection as you can
    access all features via this package. To learn more about ForestGEO
    visit <http://www.forestgeo.si.edu/>.",2019-06-19,Mauro Lepore,"http://forestgeo.github.io/fgeo, https://github.com/forestgeo/fgeo",TRUE,https://github.com/forestgeo/fgeo,4859,16,2019-12-11T18:02:06Z,303.6875
fgeo.analyze,"To help you access, transform, analyze, and
    visualize ForestGEO data, we developed a collection of R packages
    (<https://forestgeo.github.io/fgeo/>). This package, in particular,
    helps you to implement analyses of plot species distributions,
    topography, demography, and biomass. It also includes a torus
    translation test to determine habitat associations of tree species as
    described by Zuleta et al. (2018) <doi:10.1007/s11104-018-3878-0>. To
    learn more about ForestGEO visit <http://www.forestgeo.si.edu/>.",2020-03-23,Mauro Lepore,https://github.com/forestgeo/fgeo.analyze,TRUE,https://github.com/forestgeo/fgeo.analyze,5653,1,2020-03-23T18:18:37Z,5653
fgeo.plot,"To help you access, transform, analyze, and
    visualize ForestGEO data, we developed a collection of R packages
    (<https://forestgeo.github.io/fgeo/>). This package, in particular,
    helps you to plot ForestGEO data. To learn more about ForestGEO visit
    <http://www.forestgeo.si.edu/>.",2019-06-18,Mauro Lepore,"https://github.com/forestgeo/fgeo.plot,
https://forestgeo.github.io/fgeo.plot/",TRUE,https://github.com/forestgeo/fgeo.plot,5348,2,2019-06-19T15:15:40Z,2674
fgeo.tool,"To help you access, transform, analyze, and
    visualize ForestGEO data, we developed a collection of R packages
    (<https://forestgeo.github.io/fgeo/>). This package, in particular,
    helps you to easily import, filter, and modify ForestGEO data. To
    learn more about ForestGEO visit <http://www.forestgeo.si.edu/>.",2020-03-23,Mauro Lepore,https://github.com/forestgeo/fgeo.tool,TRUE,https://github.com/forestgeo/fgeo.tool,6378,2,2020-03-23T18:04:26Z,3189
fgeo.x,"Access small example datasets from Luquillo, a
    ForestGEO site in Puerto Rico
    (<https://forestgeo.si.edu/sites/north-america/luquillo>).",2019-06-07,Mauro Lepore,https://github.com/forestgeo/fgeo.x,TRUE,https://github.com/forestgeo/fgeo.x,5511,1,2019-06-17T19:11:18Z,5511
fic,"Compares how well different models estimate a quantity of interest (the ""focus"") so that different models may be preferred for different purposes.  Comparisons within any class of models fitted by maximum likelihood are supported, with shortcuts for commonly-used classes such as generalised linear models and parametric survival models.  The methods originate from Claeskens and Hjort (2003) <doi:10.1198/016214503000000819> and Claeskens and Hjort (2008, ISBN:9780521852258).",2019-04-13,Christopher Jackson,https://github.com/chjackson/fic,TRUE,https://github.com/chjackson/fic,4840,5,2019-12-02T09:29:42Z,968
fieldRS,"In remote sensing, designing a field campaign to collect ground-truth data can be a challenging task. We need to collect representative samples while accounting for issues such as budget constraints and limited accessibility created by e.g. poor infrastructure. As suggested by Olofsson et al. (2014) <doi:10.1016/j.rse.2014.02.015>, this demands the establishment of best-practices to collect ground-truth data that avoid the waste of time and funds. 'fieldRS' addresses this issue by helping scientists and practitioners design field campaigns through the identification of priority sampling sites, the extraction of potential sampling plots and the conversion of plots into consistent training and validation samples that can be used in e.g. land cover classification.",2020-06-02,Ruben Remelgado,https://github.com/RRemelgado/fieldRS/,TRUE,https://github.com/rremelgado/fieldrs,7702,10,2020-06-02T13:27:19Z,770.2
fields,"For curve, surface and function fitting with an emphasis
 on splines, spatial data, geostatistics,  and spatial statistics. The major methods
 include cubic, and thin plate splines, Kriging, and compactly supported
 covariance functions for large data sets. The splines and Kriging methods are
 supported by functions that can determine the smoothing parameter
 (nugget and sill variance) and other covariance function parameters by cross
 validation and also by restricted maximum likelihood. For Kriging
 there is an easy to use function that also estimates the correlation
 scale (range parameter).  A major feature is that any covariance function
 implemented in R and following a simple format can be used for
 spatial prediction. There are also many useful functions for plotting
 and working with spatial data as images. This package also contains
 an implementation of sparse matrix methods for large spatial data
 sets and currently requires the sparse matrix (spam) package. Use
 help(fields) to get started and for an overview.  The fields source
 code is deliberately commented and provides useful explanations of
 numerical details as a companion to the manual pages. The commented
 source code can be viewed by expanding  source code version
 and looking in the R subdirectory. The reference for fields can be generated
 by the citation function in R and has DOI <doi:10.5065/D6W957CT>. Development
 of this package was supported in part by the National Science Foundation  Grant
 1417857 and the National Center for Atmospheric Research. See the Fields URL
 for a vignette on using this package and some background on spatial statistics.",2020-02-04,Douglas Nychka,https://github.com/NCAR/Fields,TRUE,https://github.com/ncar/fields,1456365,10,2020-02-03T18:12:51Z,145636.5
fiery,"A very flexible framework for building server side logic in R. The 
    framework is unopinionated when it comes to how HTTP requests and WebSocket
    messages are handled and supports all levels of app complexity; from serving
    static content to full-blown dynamic web-apps. Fiery does not hold your hand
    as much as e.g. the shiny package does, but instead sets you free to create
    your web app the way you want.",2019-09-27,Thomas Lin Pedersen,"https://fiery.data-imaginist.com,
https://github.com/thomasp85/fiery",TRUE,https://github.com/thomasp85/fiery,27268,185,2019-10-02T20:10:14Z,147.3945945945946
fillr,"Edit vectors to fill missing values, based on the vector itself.",2020-01-28,Jelger van Zaane,https://jelger12.github.io/fillr/,TRUE,https://github.com/jelger12/fillr,4071,1,2020-01-28T15:06:45Z,4071
finalfit,"Generate regression results tables and plots in final 
    format for publication. Explore models and export directly to PDF 
    and 'Word' using 'RMarkdown'. ",2020-04-21,Ewen Harrison,https://github.com/ewenharrison/finalfit,TRUE,https://github.com/ewenharrison/finalfit,41392,202,2020-05-22T17:03:25Z,204.9108910891089
finbif,"A programmatic interface to the 'Finnish Biodiversity Information
    Facility' ('FinBIF') API (<https://api.laji.fi>). 'FinBIF' aggregates
    Finnish biodiversity data from multiple sources in a single open access
    portal for researchers, citizen scientists, industry and government.
    'FinBIF' allows users of biodiversity information to find, access, combine
    and visualise data on Finnish plants, animals and microorganisms. The
    'finbif' package makes the publicly available data in 'FinBIF' easily
    accessible to programmers. Biodiversity information is available on taxonomy
    and taxon occurrence. Occurrence data can be filtered by taxon, time,
    location and other variables. The data accessed are conveniently
    preformatted for subsequent analyses.",2020-04-23,William Morris,"https://github.com/luomus/finbif, https://luomus.github.io/finbif",TRUE,https://github.com/luomus/finbif,3114,1,2020-04-30T08:19:00Z,3114
finch,"Parse and create Darwin Core (<http://rs.tdwg.org/dwc/>) Simple
    and Archives. Functionality includes reading and parsing all the
    files in a Darwin Core Archive, including the datasets and metadata;
    read and parse simple Darwin Core files; and validation of Darwin
    Core Archives.",2019-04-25,Scott Chamberlain,https://github.com/ropensci/finch,TRUE,https://github.com/ropensci/finch,15909,19,2019-12-09T13:08:56Z,837.3157894736842
findpython,Package designed to find an acceptable python binary.,2019-03-08,Trevor L Davis,https://github.com/trevorld/findpython,TRUE,https://github.com/trevorld/findpython,91805,5,2019-11-25T22:42:20Z,18361
findR,"Scans all directories and subdirectories of a path for code snippets, R scripts,
    R Markdown, PDF or text files containing a specific pattern.  Files found can be copied to a new folder.",2018-03-13,David Zumbach,NA,TRUE,https://github.com/zumbov2/findr,12256,1,2019-12-09T08:11:11Z,12256
fingerprint,"Functions to manipulate binary fingerprints
 of arbitrary length. A fingerprint is represented by an object of S4 class 'fingerprint'
 which is internally represented a vector of integers, such
 that each element represents the position in the fingerprint that is set to 1.
 The bitwise logical functions in R are overridden so that they can be used directly
 with 'fingerprint' objects. A number of distance metrics are also
 available (many contributed by Michael Fadock). Fingerprints 
 can be converted to Euclidean vectors (i.e., points on the unit hypersphere) and
 can also be folded using OR.  Arbitrary fingerprint formats can be handled via line
 handlers. Currently handlers are provided for CDK, MOE and BCI fingerprint data.",2018-01-07,Rajarshi Guha,NA,TRUE,https://github.com/rajarshi/cdkr,57277,30,2020-03-16T02:38:29Z,1909.2333333333333
fingertipscharts,"Use Fingertips charts to recreate the visualisations 
    that are displayed on the Fingertips website (<http://fingertips.phe.org.uk/>).",2020-06-05,Sebastian Fox,NA,TRUE,https://github.com/publichealthengland/fingertipscharts,13579,5,2020-06-04T20:03:34Z,2715.8
fingertipsR,Fingertips (<http://fingertips.phe.org.uk/>) contains data for many indicators of public health in England. The underlying data is now more easily accessible by making use of the API.,2020-06-06,Sebastian Fox,"https://fingertips.phe.org.uk,
https://github.com/ropensci/fingertipsR,
https://docs.ropensci.org/fingertipsR/",TRUE,https://github.com/ropensci/fingertipsr,33730,43,2020-06-05T08:35:38Z,784.4186046511628
fipe,"The Brazilian vehicle purchase pricing table is provided by 
  the Institute of Economic Research Foundation (Fipe) and used in purchase 
  negotiations according to region, vehicle’s conservation, color, accessories 
  or any other factor that might influence the demand and supply for a specific 
  vehicle. For more on the data themselves and web access, please see 
  <https://www.fipe.org.br/en-us/home/>.",2019-08-25,Italo Cegatta,https://italocegatta.github.io/fipe/,TRUE,https://github.com/italocegatta/fipe,3712,1,2019-09-03T00:51:14Z,3712
FiRE,"The algorithm assigns rareness/ outlierness score to every sample in voluminous datasets.
    The algorithm makes multiple estimations of the proximity between a pair of samples, in low-dimensional spaces. To compute proximity, FiRE uses Sketching, a variant of locality sensitive hashing. For more details: Jindal, A., Gupta, P., Jayadeva and Sengupta, D., 2018. Discovery of rare cells from voluminous single cell expression data. Nature Communications, 9(1), p.4719. <doi:10.1038/s41467-018-07234-6>.",2019-01-02,Prashant Gupta,https://github.com/princethewinner/FiRE,TRUE,https://github.com/princethewinner/fire,5638,15,2019-08-09T04:25:48Z,375.8666666666667
firebase,"Authenticate users in 'Shiny' applications using 'Google Firebase' 
    with any of the many methods provided; email and password, email link, or
    using a third-party provider such as 'Github', 'Twitter', or 'Google'.",2020-03-30,John Coene,"https://firebase.john-coene.com/,
https://github.com/JohnCoene/firebase",TRUE,https://github.com/johncoene/firebase,1082,47,2020-04-04T09:35:49Z,23.02127659574468
fishbc,"Provides raw and curated data on the codes,
    classification and conservation status of freshwater fishes in British
    Columbia. Marine fishes will be added in a future release.",2020-06-04,Evan Amies-Galonski,https://github.com/poissonconsulting/fishbc,TRUE,https://github.com/poissonconsulting/fishbc,0,2,2020-06-09T00:17:11Z,0
fishtree,"An interface to the Fish Tree of Life API to download taxonomies,
    phylogenies, fossil calibrations, and diversification rate information for
    ray-finned fishes.",2019-12-17,Jonathan Chang,https://fishtreeoflife.org/,TRUE,https://github.com/jonchang/fishtree,7961,3,2020-06-09T05:45:38Z,2653.6666666666665
fishualize,Implementation of color palettes based on fish species. ,2020-04-20,Nina M. D. Schiettekatte,https://github.com/nschiett/fishualize,TRUE,https://github.com/nschiett/fishualize,3965,101,2020-05-27T22:47:20Z,39.257425742574256
fitdistrplus,"Extends the fitdistr() function (of the MASS package) with several functions to help the fit of a parametric distribution to non-censored or censored data. Censored data may contain left censored, right censored and interval censored values, with several lower and upper bounds. In addition to maximum likelihood estimation (MLE), the package provides moment matching (MME), quantile matching (QME) and maximum goodness-of-fit estimation (MGE) methods (available only for non-censored data). Weighted versions of MLE, MME and QME are available. See e.g. Casella & Berger (2002). Statistical inference. Pacific Grove.",2020-05-19,Aurelie Siberchicot,"https://lbbe.univ-lyon1.fr/fitdistrplus.html,
https://github.com/aursiber/fitdistrplus",TRUE,https://github.com/aursiber/fitdistrplus,753470,3,2020-05-19T11:44:34Z,251156.66666666666
fitHeavyTail,"Robust estimation methods for the mean vector and covariance matrix 
    from data (possibly containing NAs) under multivariate heavy-tailed 
    distributions such as angular Gaussian (via Tyler's method), Cauchy, 
    and Student's t. 
    Additionally, a factor model structure can be specified for the covariance 
    matrix.
    The package is based on the papers: Sun, Babu, and Palomar (2014),
    Sun, Babu, and Palomar (2015), Liu and Rubin (1995), and 
    Zhou, Liu, Kumar, and Palomar (2019).",2020-01-07,Daniel P. Palomar,https://github.com/dppalomar/fitHeavyTail,TRUE,https://github.com/dppalomar/fitheavytail,2925,6,2020-04-16T05:39:11Z,487.5
fitODBOD,"Contains Probability Mass Functions, Cumulative Mass Functions, Negative Log Likelihood value, parameter estimation and modeling data using Binomial Mixture Distributions (BMD) (Manoj et al (2013) <doi:10.5539/ijsp.v2n2p24>) and Alternate Binomial Distributions (ABD) (Paul (1985) <doi:10.1080/03610928508828990>), also Journal article to use the package(<doi:10.21105/joss.01505>).",2020-01-16,Amalan Mahendran,"https://github.com/Amalan-ConStat/R-fitODBOD,https://amalan-constat.github.io/R-fitODBOD/index.html",TRUE,https://github.com/amalan-constat/r-fitodbod,8792,1,2019-07-02T15:22:47Z,8792
FitUltD,"Extends the fitdist() (from 'fitdistrplus') adding the Anderson-Darling ad.test() (from 'ADGofTest') and Kolmogorov Smirnov Test ks.test() inside, trying the distributions from 'stats' package by default and offering a second function which uses mixed distributions to fit, this distributions are split with unsupervised learning, with Mclust() function (from 'mclust').",2019-09-11,José Carlos Del Valle,https://github.com/jcval94/FitUltD,TRUE,https://github.com/jcval94/fitultd,4866,0,2020-03-24T04:32:33Z,NA
fitzRoy,"An easy package for scraping and processing Australia Rules Football (AFL)
    data. 'fitzRoy' provides a range of functions for accessing publicly available data 
    from 'AFL Tables' <https://afltables.com>, 'Footy Wire' <https://www.footywire.com> and
    'The Squiggle' <https://squiggle.com.au>. Further functions allow for easy processing, 
    cleaning and transformation of this data into formats that can be used for analysis. ",2020-05-23,James Day,"https://jimmyday12.github.io/fitzRoy/,
https://github.com/jimmyday12/fitzRoy",TRUE,https://github.com/jimmyday12/fitzroy,3618,67,2020-06-09T10:43:26Z,54
fivethirtyeight,"Datasets and code published by the data journalism website 
    'FiveThirtyEight' available at <https://github.com/fivethirtyeight/data>. 
    Note that while we received guidance from editors at 'FiveThirtyEight', this 
    package is not officially published by 'FiveThirtyEight'.",2019-07-31,Albert Y. Kim,https://github.com/rudeboybert/fivethirtyeight,TRUE,https://github.com/rudeboybert/fivethirtyeight,73520,396,2020-06-05T18:03:36Z,185.65656565656565
fixest,"Fast and user-friendly estimation of econometric models with multiple fixed-effects. Includes ordinary least squares (OLS), generalized linear models (GLM) and the negative binomial.
    The core of the package is based on optimized parallel C++ code, scaling especially well for large data sets. The method to obtain the fixed-effects coefficients is based on Berge (2018) <https://wwwen.uni.lu/content/download/110162/1299525/file/2018_13>.
    Further provides tools to export and view the results of several estimations with intuitive design to cluster the standard-errors.",2020-04-14,Laurent Berge,NA,TRUE,https://github.com/lrberge/fixest,10465,43,2020-06-09T20:43:13Z,243.37209302325581
FixSeqMTP,"Several generalized / directional Fixed Sequence Multiple Testing
    Procedures (FSMTPs) are developed for testing a sequence of pre-ordered
    hypotheses while controlling the FWER, FDR and Directional Error (mdFWER).
    All three FWER controlling generalized FSMTPs are designed under arbitrary
    dependence, which allow any number of acceptances. Two FDR controlling
    generalized FSMTPs are respectively designed under arbitrary dependence and
    independence, which allow more but a given number of acceptances. Two mdFWER
    controlling directional FSMTPs are respectively designed under arbitrary
    dependence and independence, which can also make directional decisions based
    on the signs of the test statistics. The main functions for each proposed
    generalized / directional FSMTPs are designed to calculate adjusted p-values
    and critical values, respectively. For users' convenience, the functions also
    provide the output option for printing decision rules.",2017-01-05,Yalin Zhu,NA,TRUE,https://github.com/allenzhuaz/fixseqmtp,12466,1,2019-08-06T19:11:38Z,12466
FKF,"This is a fast and flexible implementation of the Kalman
        filter, which can deal with NAs. It is entirely written in C
        and relies fully on linear algebra subroutines contained in
        BLAS and LAPACK. Due to the speed of the filter, the fitting of
        high-dimensional linear state space models to large datasets
        becomes possible. This package also contains a plot function
        for the visualization of the state vector and graphical
        diagnostics of the residuals.",2020-06-01,Paul Smith,"https://waternumbers.github.io/FKF/,
https://github.com/waternumbers/FKF",TRUE,https://github.com/waternumbers/fkf,47059,0,2020-06-04T22:05:10Z,NA
flacco,"Tools and features for ""Exploratory Landscape Analysis (ELA)"" of
	single-objective continuous optimization problems.
    Those features are able to quantify rather complex properties, such as the
    global structure, separability, etc., of the optimization problems.",2020-03-31,Pascal Kerschke,https://github.com/kerschke/flacco,TRUE,https://github.com/kerschke/flacco,19782,24,2020-03-31T18:14:14Z,824.25
flair,"Facilitates easier formatting and highlighting of R
    source code in a R Markdown-based presentation. The main goal of the
    package is to allow users to preserve their code creation process
    within code chunks, then to specify formatting details for the source
    code, such as highlighting of particular syntactical elements.",2020-04-23,Kelly Bodwin,"https://github.com/kbodwin/flair,
https://kbodwin.github.io/flair/index.html",TRUE,https://github.com/kbodwin/flair,807,96,2020-05-04T09:54:40Z,8.40625
FLAME,"Efficient implementations of the algorithms in the 
    Almost-Matching-Exactly framework for interpretable matching in causal
    inference. These algorithms match units via a learned, weighted Hamming
    distance that determines which covariates are more important to match on.
    For more information and examples, see the Almost-Matching-Exactly website. ",2020-04-15,Vittorio Orlandi,NA,TRUE,https://github.com/vittorioorlandi/flame,6135,3,2020-05-29T15:03:03Z,2045
flamingos,"Provides a variety of original and flexible user-friendly 
    statistical latent variable models for the simultaneous clustering and 
    segmentation of heterogeneous functional data (i.e time series, or more 
    generally longitudinal data, fitted by unsupervised algorithms, including 
    EM algorithms. Functional Latent Data Models for Clustering heterogeneous 
    curves ('FLaMingos') are originally introduced and written in 'Matlab' by
    Faicel Chamroukhi 
    <https://github.com/fchamroukhi?utf8=?&tab=repositories&q=mix&type=public&language=matlab>. 
    The references are mainly the following ones.
    Chamroukhi F. (2010) <https://chamroukhi.com/FChamroukhi-PhD.pdf>.
    Chamroukhi F., Same A., Govaert, G. and Aknin P. (2010) <doi:10.1016/j.neucom.2009.12.023>.
    Chamroukhi F., Same A., Aknin P. and Govaert G. (2011). <doi:10.1109/IJCNN.2011.6033590>.
    Same A., Chamroukhi F., Govaert G. and Aknin, P. (2011) <doi:10.1007/s11634-011-0096-5>.
    Chamroukhi F., and Glotin H. (2012) <doi:10.1109/IJCNN.2012.6252818>.
    Chamroukhi F., Glotin H. and Same A. (2013) <doi:10.1016/j.neucom.2012.10.030>.
    Chamroukhi F. (2015) <https://chamroukhi.com/FChamroukhi-HDR.pdf>.
    Chamroukhi F. and Nguyen H-D. (2019) <doi:10.1002/widm.1298>.",2019-08-06,Faicel Chamroukhi,https://github.com/fchamroukhi/FLaMingos,TRUE,https://github.com/fchamroukhi/flamingos,3486,0,2020-01-22T17:39:26Z,NA
flan,Tools for fluctuations analysis of mutant cells counts.,2020-04-29,Adrien Mazoyer,"https://www.r-project.org, https://github.com/AdriMaz/flan",TRUE,https://github.com/adrimaz/flan,12878,1,2020-05-04T12:27:43Z,12878
flashlight,"Shed light on black box machine learning models by
    the help of model performance, variable importance, global surrogate
    models, ICE profiles, partial dependence (Friedman J. H. (2001)
    <doi:10.1214/aos/1013203451>), accumulated local effects (Apley D. W.
    (2016) <arXiv:1612.08468>), further effects plots, scatter plots,
    interaction strength, and variable contribution breakdown (approximate
    SHAP) for single observations (Gosiewska and Biecek (2019)
    <arxiv:1903.11420>). All tools are implemented to work with case
    weights and allow for stratified analysis. Furthermore, multiple
    flashlights can be combined and analyzed together.",2020-04-14,Michael Mayer,https://github.com/mayer79/flashlight,TRUE,https://github.com/mayer79/flashlight,5885,7,2020-05-09T09:18:14Z,840.7142857142857
flexdashboard,"Format for converting an R Markdown document to a grid oriented
  dashboard. The dashboard flexibly adapts the size of it's components to the
  containing web page.",2018-06-29,Richard Iannone,http://rmarkdown.rstudio.com/flexdashboard,TRUE,https://github.com/rstudio/flexdashboard,354573,399,2020-05-27T19:08:08Z,888.6541353383459
flexsurv,"Flexible parametric models for time-to-event data,
    including the Royston-Parmar spline model, generalized gamma and
    generalized F distributions.  Any user-defined parametric
    distribution can be fitted, given at least an R function defining
    the probability density or hazard. There are also tools for
    fitting and predicting from fully parametric multi-state models.",2019-03-18,Christopher Jackson,https://github.com/chjackson/flexsurv-dev,TRUE,https://github.com/chjackson/flexsurv-dev,152129,20,2020-05-16T16:07:15Z,7606.45
flexsurvcure,Flexible parametric mixture and non-mixture cure models for time-to-event data.,2020-04-09,Jordan Amdahl,https://github.com/jrdnmdhl/flexsurvcure,TRUE,https://github.com/jrdnmdhl/flexsurvcure,13689,4,2020-04-09T18:50:15Z,3422.25
flextable,"Create pretty tables for 'HTML', 'Microsoft Word' and 'Microsoft PowerPoint' documents. 
  Functions are provided to let users create tables, modify and format their content. 
  It extends package 'officer' that does not contain any feature for customized tabular reporting 
  and can be used within R markdown documents.",2020-05-15,David Gohel,https://davidgohel.github.io/flextable,TRUE,https://github.com/davidgohel/flextable,267279,203,2020-05-25T16:51:06Z,1316.6453201970444
flightplanning,"Utility functions for creating flight plans for unmanned aerial vehicles (UAV), specially for the Litchi Hub platform. It calculates the flight and camera settings based on the camera specifications, exporting the flight plan CSV format ready to import into Litchi Hub.",2020-03-13,Caio Hamamura,https://github.com/caiohamamura/flightplanning-R.git,TRUE,https://github.com/caiohamamura/flightplanning-r,4219,0,2020-04-29T23:36:56Z,NA
FLightR,"Spatio-temporal locations of an animal are computed 
    from annotated data with a hidden Markov  model via particle
    filter algorithm. The package is relatively robust to varying
    degrees of shading.
    The hidden Markov model is described in Movement Ecology (Rakhimberdiev et al., 2015) <doi:10.1186/s40462-015-0062-5>,
    general package description is in the Methods in Ecology and Evolution (Rakhimberdiev et al., 2017) <doi:10.1111/2041-210X.12765>
    and package accuracy assessed in the Journal of Avian Biology (Rakhimberdiev et al. 2016) <doi:10.1111/jav.00891>.",2020-05-15,Eldar Rakhimberdiev,https://CRAN.R-project.org/package=FLightR,TRUE,https://github.com/eldarrak/flightr,15732,14,2020-05-15T07:55:58Z,1123.7142857142858
float,"R comes with a suite of utilities for linear algebra with ""numeric""
    (double precision) vectors/matrices. However, sometimes single precision (or
    less!) is more than enough for a particular task.  This package extends R's
    linear algebra facilities to include 32-bit float (single precision) data.
    Float vectors/matrices have half the precision of their ""numeric""-type
    counterparts but are generally faster to numerically operate on, for a
    performance vs accuracy trade-off.  The internal representation is an S4
    class, which allows us to keep the syntax identical to that of base R's.
    Interaction between floats and base types for binary operators is generally
    possible; in these cases, type promotion always defaults to the higher
    precision.  The package ships with copies of the single precision 'BLAS' and
    'LAPACK', which are automatically built in the event they are not available
    on the system.",2020-04-22,Drew Schmidt,https://github.com/wrathematics/float,TRUE,https://github.com/wrathematics/float,54243,35,2020-06-06T17:42:58Z,1549.8
flobr,"Converts files to and from flobs. 
    A flob is a file that was 
    read into binary in integer-mode as little endian, 
    saved as the single element of a named list (where the name is the name 
    of the original file) and then serialized before being coerced into a blob.
    Flobs are useful for writing and reading files to and from databases.",2020-05-15,Joe Thorley,https://github.com/poissonconsulting/flobr,TRUE,https://github.com/poissonconsulting/flobr,7170,6,2020-05-15T17:15:37Z,1195
flora,"Tools to quickly compile taxonomic and distribution data from
    the Brazilian Flora 2020.",2020-04-28,Gustavo Carvalho,http://www.github.com/gustavobio/flora,TRUE,https://github.com/gustavobio/flora,20271,14,2020-05-07T13:07:47Z,1447.9285714285713
fma,"All data sets from ""Forecasting: methods and applications"" by Makridakis, Wheelwright & Hyndman (Wiley, 3rd ed., 1998) <https://robjhyndman.com/forecasting/>.",2020-01-14,Rob Hyndman,"https://pkg.robjhyndman.com/fma/,
https://github.com/robjhyndman/fma",TRUE,https://github.com/robjhyndman/fma,1334997,5,2020-03-12T21:18:02Z,266999.4
fmbasics,"Implements basic financial market objects like currencies, currency
  pairs, interest rates and interest rate indices. You will be able to use
  Benchmark instances of these objects which have been defined using their most
  common conventions or those defined by International Swap Dealer Association
  (ISDA, <https://www.isda.org>) legal documentation. ",2018-01-06,Imanuel Costigan,"https://github.com/imanuelcostigan/fmbasics,
https://imanuelcostigan.github.io/fmbasics/",TRUE,https://github.com/imanuelcostigan/fmbasics,12377,7,2019-12-03T04:37:24Z,1768.142857142857
fmcmc,"Provides a friendly (flexible) Markov Chain Monte Carlo (MCMC)
         framework for implementing Metropolis-Hastings algorithm in a modular way
         allowing users to specify automatic convergence checker, personalized
         transition kernels, and out-of-the-box multiple MCMC chains using
         parallel computing. Most of the methods implemented in this package can
         be found in Brooks et al. (2011, ISBN 9781420079425). Among the methods
         included, we have: Haario (2001) <doi:10.1007/s11222-011-9269-5>
         Adaptive Metropolis, Vihola (2012) <doi:10.1007/s11222-011-9269-5>
         Robust Adaptive Metropolis, and Thawornwattana et
         al. (2018) <doi:10.1214/17-BA1084> Mirror transition kernels.",2020-04-23,George Vega Yon,https://github.com/USCbiostats/fmcmc,TRUE,https://github.com/uscbiostats/fmcmc,4049,9,2020-04-10T18:40:47Z,449.8888888888889
fmdates,"Implements common date calculations relevant for specifying
  the economic nature of financial market contracts that are typically defined
  by International Swap Dealer Association (ISDA, <http://www2.isda.org>) legal
  documentation. This includes methods to check whether dates are business
  days in certain locales, functions to adjust and shift dates and time length
  (or day counter) calculations.",2018-01-04,Imanuel Costigan,"https://github.com/imanuelcostigan/fmdates,
https://imanuelcostigan.github.io/fmdates/",TRUE,https://github.com/imanuelcostigan/fmdates,18542,6,2020-03-22T04:38:43Z,3090.3333333333335
FMradio,"Functions that support stable prediction and classification with radiomics data through factor-analytic modeling. For details, see Peeters et al. (2019) <arXiv:1903.11696>.",2019-12-16,Carel F.W. Peeters,https://github.com/CFWP/FMradio,TRUE,https://github.com/cfwp/fmradio,4791,3,2019-12-17T09:28:34Z,1597
fmriqa,"Methods for performing fMRI quality assurance (QA) measurements of
  test objects. Heavily  based on the fBIRN procedures detailed by Friedman and 
  Glover (2006) <doi:10.1002/jmri.20583>.",2018-02-19,Martin Wilson,NA,TRUE,https://github.com/martin3141/fmriqa,9779,0,2019-10-23T12:36:28Z,NA
foghorn,"The CRAN check results and where your package stands in the
    CRAN submission queue in your R terminal.",2020-05-05,Francois Michonneau,https://github.com/fmichonneau/foghorn,TRUE,https://github.com/fmichonneau/foghorn,362516,47,2020-05-05T09:14:46Z,7713.106382978724
foieGras,"Fits continuous-time random walk and correlated random walk state-space models to filter animal tracking data ('Argos', processed light-level 'geolocation', 'GPS'). Template Model Builder ('TMB') is used for fast estimation. The 'Argos' data can be: (older) least squares-based locations; (newer) Kalman filter-based locations with error ellipse information; or a mixture of both. The models estimate two sets of location states corresponding to: 1) each observation, which are (usually) irregularly timed; and 2) user-specified time intervals (regular or irregular). Latent variable models are provided to estimate move persistence along tracks as an index of behaviour. 'Jonsen I', 'McMahon CR', 'Patterson TA', 'Auger-Methe M', 'Harcourt R', 'Hindell MA', 'Bestley S' (2019) Movement responses to environment: fast inference of variation among southern elephant seals with a mixed effects model. Ecology 100:e02566 <doi:10.1002/ecy.2566>.",2019-10-07,Ian Jonsen,https://cran.r-project.org/package=foieGras,TRUE,https://github.com/ianjonsen/foiegras,6164,5,2020-06-08T11:00:01Z,1232.8
folderfun,"If you find yourself working on multiple different projects in R, you'll want a 
	series of folders pointing to raw data, processed data, plot results, intermediate table 
	outputs, etc. This package makes it easier to do that by providing a quick and easy way 
	to create and use functions for project-level directories.",2019-06-12,Nathan C. Sheffield,http://code.databio.org/folderfun,TRUE,https://github.com/databio/folderfun,6115,6,2019-06-12T11:38:19Z,1019.1666666666666
foodingraph,"Displays a weighted undirected food graph from an adjacency matrix.
    Can perform confidence-interval bootstrap inference with mutual information
    or maximal information coefficient.
    Based on my Master 1 internship at the Bordeaux Population Health center.
    References : Reshef et al. (2011) <doi:10.1126/science.1205438>,
    Meyer et al. (2008) <doi:10.1186/1471-2105-9-461>,
    Liu et al. (2016) <doi:10.1371/journal.pone.0158247>.",2019-10-06,Victor Gasque,https://github.com/vgasque/foodingraph/,TRUE,https://github.com/vgasque/foodingraph,3166,4,2019-10-01T16:12:05Z,791.5
forcats,"Helpers for reordering factor levels (including
    moving specified levels to front, ordering by first appearance,
    reversing, and randomly shuffling), and tools for modifying factor
    levels (including collapsing rare levels into other, 'anonymising',
    and manually 'recoding').",2020-03-01,Hadley Wickham,"http://forcats.tidyverse.org, https://github.com/tidyverse/forcats",TRUE,https://github.com/tidyverse/forcats,8233222,366,2020-05-28T13:10:03Z,22495.142076502732
foreach,"Support for the foreach looping construct.  Foreach is an
        idiom that allows for iterating over elements in a collection,
        without the use of an explicit loop counter.  This package in
        particular is intended to be used for its return value, rather
        than for its side effects.  In that sense, it is similar to the
        standard lapply function, but doesn't require the evaluation
        of a function.  Using foreach without side effects also
        facilitates executing the loop in parallel.",2020-03-30,Hong Ooi,https://github.com/RevolutionAnalytics/foreach,TRUE,https://github.com/revolutionanalytics/foreach,7031329,18,2020-05-07T10:48:24Z,390629.3888888889
forecast,"Methods and tools for displaying and analysing
             univariate time series forecasts including exponential smoothing
             via state space models and automatic ARIMA modelling.",2020-03-31,Rob Hyndman,"http://pkg.robjhyndman.com/forecast,
https://github.com/robjhyndman/forecast",TRUE,https://github.com/robjhyndman/forecast,6427355,823,2020-05-26T04:44:45Z,7809.665856622114
forecastHybrid,"Convenient functions for ensemble forecasts in R combining
    approaches from the 'forecast' package. Forecasts generated from auto.arima(), ets(),
    thetaf(), nnetar(), stlm(), tbats(), and snaive() can be combined with equal weights, weights
    based on in-sample errors (introduced by Bates & Granger (1969) <doi:10.1057/jors.1969.103>),
    or cross-validated weights. Cross validation for time series data with user-supplied models
    and forecasting functions is also supported to evaluate model accuracy.",2020-04-02,David Shaub,"https://gitlab.com/dashaub/forecastHybrid,
https://github.com/ellisp/forecastHybrid",TRUE,https://github.com/ellisp/forecasthybrid,94217,65,2020-04-01T16:41:20Z,1449.4923076923078
forecastML,"The purpose of 'forecastML' is to simplify the process of multi-step-ahead forecasting with standard machine learning algorithms. 'forecastML' supports lagged, dynamic, static, and grouping features for modeling single and grouped numeric or factor/sequence time series. In addition, simple wrapper functions are used to support model-building with most R packages. This approach to forecasting is inspired by Bergmeir, Hyndman, and Koo's (2018) paper ""A note on the validity of cross-validation for evaluating autoregressive time series prediction"" <doi:10.1016/j.csda.2017.11.003>.",2020-05-07,Nickalus Redell,https://github.com/nredell/forecastML/,TRUE,https://github.com/nredell/forecastml,6311,73,2020-06-06T21:52:56Z,86.45205479452055
foreSIGHT,"A tool to create hydroclimate scenarios, stress test systems and visualize system performance in scenario-neutral climate change impact assessments. Scenario-neutral approaches 'stress-test' the performance of a modelled system by applying a wide range of plausible hydroclimate conditions (see Brown & Wilby (2012) <doi:10.1029/2012EO410001> and Prudhomme et al. (2010) <doi:10.1016/j.jhydrol.2010.06.043>). These approaches allow the identification of hydroclimatic variables that affect the vulnerability of a system to hydroclimate variation and change. This tool enables the generation of perturbed time series using a range of approaches including simple scaling of observed time series (e.g. Culley et al. (2016) <doi:10.1002/2015WR018253>) and stochastic simulation of perturbed time series via an inverse approach (see Guo et al. (2018) <doi:10.1016/j.jhydrol.2016.03.025>). It incorporates a number of stochastic weather models to generate hydroclimate variables on a daily basis (e.g. precipitation, temperature, potential evapotranspiration) and allows a variety of different hydroclimate variable properties, herein called attributes, to be perturbed. Options are included for the easy integration of existing system models both internally in R and externally for seamless 'stress-testing'. A suite of visualization options for the results of a scenario-neutral analysis (e.g. plotting performance spaces and overlaying climate projection information) are also included. As further developments in scenario-neutral approaches occur the tool will be updated to incorporate these advances.",2019-12-04,Bree Bennett,NA,TRUE,https://github.com/bsbennett/foresight,9253,0,2019-12-05T03:41:52Z,NA
forestControl,"Approximate false positive rate control in selection frequency for
    random forest using the methods described by Ender Konukoglu and Melanie Ganz (2014) <arXiv:1410.2838>.
    Methods for calculating the selection frequency threshold at false positive rates
    and selection frequency false positive rate feature selection.",2019-11-18,Tom Wilson,https://github.com/aberHRML/forestControl,TRUE,https://github.com/aberhrml/forestcontrol,10625,2,2019-11-18T09:51:17Z,5312.5
forestplot,"A forest plot that allows for
    multiple confidence intervals per row,
    custom fonts for each text element,
    custom confidence intervals,
    text mixed with expressions, and more.
    The aim is to extend the use of forest plots beyond meta-analyses.
    This is a more general version of the original 'rmeta' package's forestplot()
    function and relies heavily on the 'grid' package.",2019-06-24,Max Gordon,http://gforge.se/packages/,TRUE,https://github.com/gforge/forestplot,136102,20,2020-03-07T08:56:43Z,6805.1
forestr,"Provides a toolkit for calculating forest and canopy structural complexity metrics from
    terrestrial LiDAR (light detection and ranging). References:  Atkins et al. 2018 <doi:10.1111/2041-210X.13061>; Hardiman et al. 2013 <doi:10.3390/f4030537>;
    Parker et al. 2004 <doi:10.1111/j.0021-8901.2004.00925.x>.",2020-04-14,Jeff Atkins,https://github.com/atkinsjeff/forestr,TRUE,https://github.com/atkinsjeff/forestr,7988,13,2020-06-05T01:38:13Z,614.4615384615385
ForestTools,"Provides tools for analyzing remotely sensed forest data, including functions for detecting treetops from canopy models (Popescu & Wynne, 2004), outlining tree crowns (Meyer & Beucher, 1990) and generating spatial statistics.",2020-05-06,Andrew Plowright,https://github.com/andrew-plowright/ForestTools,TRUE,https://github.com/andrew-plowright/foresttools,17164,15,2020-05-06T22:29:55Z,1144.2666666666667
formatR,"Provides a function tidy_source() to format R source code. Spaces
    and indent will be added to the code automatically, and comments will be
    preserved under certain conditions, so that R code will be more
    human-readable and tidy. There is also a Shiny app as a user interface in
    this package (see tidy_app()).",2019-06-11,Yihui Xie,https://github.com/yihui/formatR,TRUE,https://github.com/yihui/formatr,4172836,174,2019-11-18T05:14:50Z,23981.816091954024
formattable,"Provides functions to create formattable vectors and data frames.
    'Formattable' vectors are printed with text formatting, and formattable
    data frames are printed with multiple types of formatting in HTML
    to improve the readability of data presented in tabular form rendered in
    web pages.",2016-08-05,Kun Ren,"https://renkun.me/formattable,
https://github.com/renkun-ken/formattable",TRUE,https://github.com/renkun-ken/formattable,415201,547,2020-04-25T12:18:12Z,759.0511882998172
formulaic,"Many statistical models and analyses in R are implemented through formula objects. The formulaic package creates a unified approach for programmatically and dynamically generating formula objects. Users may specify the outcome and inputs of a model directly, search for variables to include based upon naming patterns, incorporate interactions, and identify variables to exclude. A wide range of quality checks are implemented to identify issues such as misspecified variables, duplication, a lack of contrast in the inputs, and a large number of levels in categorical data.  Variables that do not meet these quality checks can be automatically excluded from the model.  These issues are documented and reported in a manner that provides greater accountability and useful information to guide an investigation of the data.",2020-05-04,David Shilane,https://dachosen1.github.io/formulaic/index.html,TRUE,https://github.com/dachosen1/formulaic,5092,3,2020-05-07T19:51:27Z,1697.3333333333333
formulops,"Perform mathematical operations on R formula (add, subtract, multiply, etc.) and substitute parts of formula.",2020-02-22,Bill Denney,https://github.com/billdenney/formulops,TRUE,https://github.com/billdenney/formulops,1377,0,2020-02-15T19:52:17Z,NA
forrel,"Forensic applications of pedigree analysis, including likelihood ratios 
    for relationship testing, general relatedness inference, marker simulation, and 
    power analysis. General computation of exclusion powers is based on Egeland et 
    al. (2014) <doi:10.1016/j.fsigen.2013.05.001>. Several functions deal 
    specifically with family reunion cases, implementing and developing ideas from 
    Kling et al. (2017) <doi:10.1016/j.fsigen.2017.08.006>. A novelty of 'forrel' 
    is the ability to model background inbreeding in forensic pedigree computations.
    This can have significant impact in applications, as exemplified in Vigeland 
    and Egeland (2019) <doi:10.1016/j.fsigss.2019.10.175>. 'forrel' is part of the
    ped suite, a collection of packages for pedigree analysis. In particular, 
    'forrel' imports 'pedtools' for creating and manipulating pedigrees and markers,
    'pedprobr' for likelihood computations, and 'pedmut' for mutation modelling. 
    Pedigree data may be created from scratch, or loaded from text files. Data 
    import from the 'Familias' software (Egeland et al. (2000) 
    <doi:10.1016/S0379-0738(00)00147-X>) is supported. ",2020-03-22,Magnus Dehli Vigeland,https://github.com/magnusdv/forrel,TRUE,https://github.com/magnusdv/forrel,2213,5,2020-06-05T11:47:55Z,442.6
forwards,"Anonymized data from surveys conducted by Forwards <https://forwards.github.io/>, the R Foundation task force on women and other under-represented groups. Currently, a single data set of responses to a survey of attendees at useR! 2016 <https://www.r-project.org/useR-2016/>, the R user conference held at Stanford University, Stanford, California, USA, June 27 - June 30 2016.",2019-07-30,Heather Turner,https://github.com/forwards/forwards,TRUE,https://github.com/forwards/forwards,11127,1,2019-07-30T20:42:17Z,11127
foto,"The Fourier Transform Textural Ordination method 
  uses a principal component analysis on radially averaged
  two dimensional Fourier spectra to characterize image texture.",2019-01-17,Koen Hufkens,https://github.com/khufkens/foto,TRUE,https://github.com/khufkens/foto,5406,3,2019-07-16T10:22:31Z,1802
fourPNO,"Estimate Barton & Lord's (1981) <doi:10.1002/j.2333-8504.1981.tb01255.x> 
    four parameter IRT model with lower and upper asymptotes using Bayesian
    formulation described by Culpepper (2016) <doi:10.1007/s11336-015-9477-6>.",2019-09-24,Steven Andrew Culpepper,https://github.com/tmsalab/fourPNO,TRUE,https://github.com/tmsalab/fourpno,19800,1,2019-11-05T22:49:31Z,19800
fpCompare,"Comparisons of floating point numbers are problematic due to errors
    associated with the binary representation of decimal numbers.
    Despite being aware of these problems, people still use numerical methods
    that fail to account for these and other rounding errors (this pitfall is
    the first to be highlighted in Circle 1 of Burns (2012)
    'The R Inferno' <http://www.burns-stat.com/pages/Tutor/R_inferno.pdf>).
    This package provides new relational operators useful for performing
    floating point number comparisons with a set tolerance.",2019-09-10,Alex M Chubaty,https://github.com/PredictiveEcology/fpCompare,TRUE,https://github.com/predictiveecology/fpcompare,64644,4,2019-09-06T19:24:26Z,16161
fplyr,"Read and process a large delimited file block by
    block. A block consists of all the contiguous rows that have the same value
    in the first field. The result can be returned as a list or a data.table,
    or even directly printed to an output file.",2020-05-06,Federico Marotta,https://github.com/fmarotta/fplyr,TRUE,https://github.com/fmarotta/fplyr,1581,0,2020-05-06T20:15:20Z,NA
fpp3,"
    All data sets required for the examples and exercises in the book
    ""Forecasting: principles and practice"" by Rob J Hyndman and George Athanasopoulos
    <http://OTexts.org/fpp3/>.  All packages required to run the examples are also
    loaded.",2020-06-07,Rob Hyndman,"https://github.com/robjhyndman/fpp3-package,
https://OTexts.org/fpp3/",TRUE,https://github.com/robjhyndman/fpp3-package,12704,30,2020-06-07T05:06:49Z,423.46666666666664
fracdiff,"Maximum likelihood estimation of the parameters of a fractionally
   differenced ARIMA(p,d,q) model (Haslett and Raftery, Appl.Statistics, 1989);
   including inference and basic methods.  Some alternative algorithms to estimate ""H"".",2020-01-24,Martin Maechler,https://github.com/mmaechler/fracdiff,TRUE,https://github.com/mmaechler/fracdiff,3239007,5,2020-01-20T17:01:51Z,647801.4
FractalParameterEstimation,"The parameters p and q are estimated with the aid of a randomized Sierpinski Carpet which is built on a [p-p-p-q]-model. Thereby, for three times a simulation with a p-value and once with a q-value is assumed. Hence, these parameters are estimated and displayed. Moreover, functions for simulating random Sierpinski-Carpets with constant and variable probabilities are included. For more details on the method please see Hermann et al. (2015) <doi:10.1002/sim.6497>. ",2019-07-10,Philipp Hermann,NA,TRUE,https://github.com/phhermann/fractalparameterestimation,19845,0,2019-07-10T12:50:04Z,NA
frailtyEM,"Contains functions for fitting shared frailty models with a semi-parametric
    baseline hazard with the Expectation-Maximization algorithm. Supported data formats 
    include clustered failures with left truncation and recurrent events in gap-time
    or Andersen-Gill format. Several frailty distributions, such as the the gamma, positive stable
    and the Power Variance Family are supported. ",2019-09-22,Theodor Adrian Balan,https://github.com/tbalan/frailtyEM,TRUE,https://github.com/tbalan/frailtyem,21304,1,2019-09-19T20:04:47Z,21304
freealg,The free algebra in R; multivariate polynomials with non-commuting indeterminates.,2019-09-23,Robin K. S. Hankin,https://github.com/RobinHankin/freealg.git,TRUE,https://github.com/robinhankin/freealg,3189,1,2020-03-14T22:16:53Z,3189
freegroup,"Provides functionality for manipulating elements of the free group (juxtaposition is represented by a plus) including inversion, multiplication by a scalar, group-theoretic power operation, and Tietze forms.  The package is fully vectorized.",2018-09-25,Robin K. S. Hankin,https://github.com/RobinHankin/freegroup.git,TRUE,https://github.com/robinhankin/freegroup,9187,0,2020-05-01T22:46:49Z,NA
freesurfer,"Wrapper functions that interface with 'Freesurfer' 
    <https://surfer.nmr.mgh.harvard.edu/>, a powerful and 
    commonly-used 'neuroimaging'
    software, using system commands. The goal is to be able to interface with
    'Freesurfer' completely in R, where you pass R objects of class 'nifti',
    implemented by package 'oro.nifti', and the function executes an 'Freesurfer'
    command and returns an R object of class 'nifti' or necessary output.",2020-03-30,John Muschelli,NA,TRUE,https://github.com/muschellij2/freesurfer,13431,5,2020-04-29T23:35:53Z,2686.2
freesurferformats,"Provides functions to read and write data from neuroimaging files in 'FreeSurfer' <http://freesurfer.net/> binary formats. This includes, but is not limited to, the following file formats: 1) MGH/MGZ format files, which can contain multi-dimensional images or other data. Typically they contain time-series of three-dimensional brain scans acquired by magnetic resonance imaging (MRI). They can also contain vertex-wise measures of surface morphometry data. The MGH format is named after the Massachusetts General Hospital, and the MGZ format is a compressed version of the same format. 2) 'FreeSurfer' morphometry data files in binary 'curv' format. These contain vertex-wise surface measures, i.e., one scalar value for each vertex of a brain surface mesh. These are typically values like the cortical thickness or brain surface area at each vertex. 3) Annotation file format. This contains a brain surface parcellation derived from a cortical atlas. 4) Surface file format. Contains a brain surface mesh, given by a list of vertices and a list of faces.",2020-05-13,Tim Schäfer,https://github.com/dfsp-spirit/freesurferformats,TRUE,https://github.com/dfsp-spirit/freesurferformats,8488,6,2020-06-09T07:51:52Z,1414.6666666666667
frequency,"Generate 'SPSS'/'SAS' styled frequency tables. Frequency tables are 
    generated with variable and value label attributes where applicable with optional
    html output to quickly examine datasets.",2020-04-05,Alistair Wilcox,https://github.com/wilcoxa/frequency,TRUE,https://github.com/wilcoxa/frequency,13974,2,2020-04-05T09:26:16Z,6987
frequencyConnectedness,"Accompanies a paper (Barunik, Krehlik (2018) <doi:10.1093/jjfinec/nby001>) dedicated to spectral decomposition of connectedness measures and their interpretation. We implement all the developed estimators as well as the historical counterparts. For more information, see the help or GitHub page (<https://github.com/tomaskrehlik/frequencyConnectedness>) for relevant information.",2020-02-16,Tomas Krehlik,https://github.com/tomaskrehlik/frequencyConnectedness,TRUE,https://github.com/tomaskrehlik/frequencyconnectedness,14161,24,2020-02-04T21:58:32Z,590.0416666666666
fresh,"Customize 'Bootstrap' and 'Bootswatch' themes, like colors, fonts, grid layout, 
  to use in 'Shiny' applications, 'rmarkdown' documents and 'flexdashboard'.",2020-05-29,Victor Perrier,https://github.com/dreamRs/fresh,TRUE,https://github.com/dreamrs/fresh,3773,130,2020-05-29T14:20:54Z,29.023076923076925
FRK,"Fixed Rank Kriging is a tool for spatial/spatio-temporal modelling
    and prediction with large datasets. The approach, discussed in Cressie and
    Johannesson (2008) <DOI:10.1111/j.1467-9868.2007.00633.x>, decomposes the field, 
    and hence the covariance function, using a fixed set of n basis functions, 
    where n is typically much smaller than the number of data points (or polygons) m. 
    The method naturally allows for non-stationary, anisotropic covariance functions 
    and the use of observations with varying support (with known error variance). The 
    projected field is a key building block of the Spatial Random Effects (SRE) model, 
    on which this package is based. The package FRK provides helper functions to model, 
    fit, and predict using an SRE with relative ease.",2020-04-01,Andrew Zammit-Mangion,NA,TRUE,https://github.com/andrewzm/frk,27033,24,2020-05-22T05:20:07Z,1126.375
frost,"A compilation of empirical methods used by farmers and agronomic engineers to predict the minimum temperature to detect a frost night. These functions use variables such as environmental temperature, relative humidity, and dew point. See <http://sedici.unlp.edu.ar/handle/10915/72102> <http://www.fao.org/docrep/008/y7223e/y7223e0b.htm#bm11.8> for details.",2019-04-12,Ana Laura Diedrichs,https://github.com/anadiedrichs/frost,TRUE,https://github.com/anadiedrichs/frost,4911,2,2019-10-15T20:10:12Z,2455.5
fs,"A cross-platform interface to file system operations, built on
  top of the 'libuv' C library.",2020-04-04,Jim Hester,"http://fs.r-lib.org, https://github.com/r-lib/fs",TRUE,https://github.com/r-lib/fs,10063013,247,2020-04-28T12:59:42Z,40740.94331983806
FSA,"A variety of simple fish stock assessment methods.
    Detailed vignettes are available on the fishR website <http://derekogle.com/fishR/>.",2020-03-09,Derek Ogle,https://github.com/droglenc/FSA,TRUE,https://github.com/droglenc/fsa,225619,29,2020-06-01T00:54:07Z,7779.9655172413795
FSAdata,The datasets to support the Fish Stock Assessment ('FSA') package.,2019-05-18,Derek Ogle,"http://derekogle.com/fishR/, https://github.com/droglenc/FSAdata",TRUE,https://github.com/droglenc/fsadata,39700,4,2020-03-17T22:55:17Z,9925
fsbrain,"Provides high-level access to 'FreeSurfer' <http://freesurfer.net/> neuroimaging data on the level of subjects and groups. Load morphometry data, surfaces and brain parcellations based on atlases. Mask data using labels, load data for specific atlas regions only, and visualize data and results directly in 'R'.",2020-05-27,Tim Schäfer,https://github.com/dfsp-spirit/fsbrain,TRUE,https://github.com/dfsp-spirit/fsbrain,2723,6,2020-06-04T07:05:54Z,453.8333333333333
FSelectorRcpp,"'Rcpp' (free of 'Java'/'Weka') implementation of 'FSelector' entropy-based feature selection 
 algorithms based on an MDL discretization (Fayyad U. M., Irani K. B.: Multi-Interval Discretization of Continuous-Valued Attributes for Classification Learning.
 In 13'th International Joint Conference on Uncertainly in Artificial Intelligence (IJCAI93), pages 1022-1029, Chambery, France, 1993.) <https://www.ijcai.org/Proceedings/93-2/Papers/022.pdf>
 with a sparse matrix support.",2020-01-24,Zygmunt Zawadzki,http://mi2-warsaw.github.io/FSelectorRcpp/,TRUE,https://github.com/mi2-warsaw/fselectorrcpp,43607,28,2020-02-25T17:37:53Z,1557.392857142857
fslr,"Wrapper functions that interface with 'FSL' 
    <http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/>, a powerful and commonly-used 'neuroimaging'
    software, using system commands. The goal is to be able to interface with 'FSL'
    completely in R, where you pass R objects of class 'nifti', implemented by
    package 'oro.nifti', and the function executes an 'FSL' command and returns an R
    object of class 'nifti' if desired.",2019-08-05,John Muschelli,NA,TRUE,https://github.com/muschellij2/fslr,30912,30,2020-03-28T15:10:19Z,1030.4
fssemR,"An optimizer of Fused-Sparse Structural Equation Models, which is 
 the state of the art jointly fused sparse maximum likelihood function 
 for structural equation models proposed by Xin Zhou and Xiaodong Cai (2018 
 <doi:10.1101/466623>).",2019-12-04,Xin Zhou,https://github.com/Ivis4ml/fssemR,TRUE,https://github.com/ivis4ml/fssemr,6013,2,2020-01-10T20:27:01Z,3006.5
fst,"Multithreaded serialization of compressed data frames using the
    'fst' format. The 'fst' format allows for random access of stored data and
    compression with the LZ4 and ZSTD compressors created by Yann Collet. The ZSTD
    compression library is owned by Facebook Inc.",2020-04-01,Mark Klik,https://fstpackage.github.io,TRUE,https://github.com/fstpackage/fst,298522,459,2020-06-02T21:47:31Z,650.3747276688454
fstcore,"The 'fstlib' library provides multithreaded serialization of compressed data frames using the
    'fst' format. The 'fst' format allows for random access of stored data and compression with the 'LZ4' and 'ZSTD'
    compressors.",2020-05-04,Mark Klik,https://fstpackage.github.io/fstcore,TRUE,https://github.com/fstpackage/fst,594,459,2020-06-02T21:47:31Z,1.2941176470588236
ftExtra,"Build display tables easily by extending the
    functionality of the 'flextable' package. Features include spanning
    headers, grouping rows, parsing markdown texts and so on.",2020-03-20,Atsushi Yasumoto,https://github.com/atusy/ftExtra,TRUE,https://github.com/atusy/ftextra,1392,24,2020-04-05T23:36:35Z,58
fueleconomy,"Fuel economy data from the EPA, 1985-2015,
    conveniently packaged for consumption by R users.",2020-03-23,Hadley Wickham,https://github.com/hadley/fueleconomy,TRUE,https://github.com/hadley/fueleconomy,35759,16,2020-03-23T16:04:06Z,2234.9375
fun,"This is a collection of R games and other funny stuff, such as the
    classic Mine sweeper and sliding puzzles.",2018-12-05,Yihui Xie,https://github.com/yihui/fun,TRUE,https://github.com/yihui/fun,48780,36,2020-02-06T16:36:45Z,1355
funchir,YACFP (Yet Another Convenience Function Package). get_age() is a fast & accurate tool for measuring fractional years between two dates. abbr_to_colClass() is a much more concise way of feeding many types to a colClass argument in a data reader. stale_package_check() tries to identify any library() calls to unused packages.,2020-04-13,Michael Chirico,https://github.com/MichaelChirico/funchir,TRUE,https://github.com/michaelchirico/funchir,10934,3,2020-04-12T15:45:08Z,3644.6666666666665
funData,"S4 classes for univariate and multivariate functional data with
    utility functions. See <doi:10.18637/jss.v093.i05> for a detailed description 
    of the package functionalities and its interplay with the MFPCA package for 
    multivariate functional principal component analysis 
    <https://CRAN.R-project.org/package=MFPCA>. ",2020-04-25,Clara Happ-Kurz,https://github.com/ClaraHapp/funData,TRUE,https://github.com/clarahapp/fundata,20477,5,2020-04-25T11:21:37Z,4095.4
funModeling,"Around 10% of almost any predictive modeling project is spent in predictive modeling, 'funModeling' and the book Data Science Live Book (<https://livebook.datascienceheroes.com/>) are intended to cover remaining 90%: data preparation, profiling, selecting best variables 'dataViz', assessing model performance and other functions.",2019-10-09,Pablo Casas,https://livebook.datascienceheroes.com,TRUE,https://github.com/pablo14/funmodeling,97672,69,2020-04-06T21:00:49Z,1415.536231884058
FunnelPlotR,"An implementation of the Spiegelhalter (2005) <doi:10.1002/sim.1970> Funnel plots  for reporting standardised ratios, with overdispersion adjustment.",2020-02-25,Chris Mainey,"https://chrismainey.github.io/FunnelPlotR,
https://github.com/chrismainey/FunnelPlotR",TRUE,https://github.com/chrismainey/funnelplotr,5038,16,2020-05-18T13:56:24Z,314.875
funrar,"Computes functional rarity indices as proposed by Violle et al.
    (2017) <doi:10.1016/j.tree.2017.02.002>. Various indices can be computed
    using both regional and local information. Functional Rarity combines both
    the functional aspect of rarity as well as the extent aspect of rarity.
    'funrar' is presented in Grenié et al. (2017) <doi:10.1111/ddi.12629>.",2020-04-20,Matthias Grenié,https://rekyt.github.io/funrar/,TRUE,https://github.com/rekyt/funrar,23052,12,2020-04-20T14:52:53Z,1921
future,"The purpose of this package is to provide a lightweight and
    unified Future API for sequential and parallel processing of R
    expression via futures.  The simplest way to evaluate an expression
    in parallel is to use `x %<-% { expression }` with `plan(multiprocess)`.
    This package implements sequential, multicore, multisession, and
    cluster futures.  With these, R expressions can be evaluated on the
    local machine, in parallel a set of local machines, or distributed
    on a mix of local and remote machines.
    Extensions to this package implement additional backends for
    processing futures via compute cluster schedulers etc.
    Because of its unified API, there is no need to modify any code in order
    switch from sequential on the local machine to, say, distributed
    processing on a remote compute cluster.
    Another strength of this package is that global variables and functions
    are automatically identified and exported as needed, making it
    straightforward to tweak existing code to make use of futures.",2020-04-18,Henrik Bengtsson,https://github.com/HenrikBengtsson/future,TRUE,https://github.com/henrikbengtsson/future,1089535,648,2020-06-03T15:43:56Z,1681.3811728395062
future.apply,"Implementations of apply(), by(), eapply(), lapply(), Map(), mapply(), replicate(), sapply(), tapply(), and vapply() that can be resolved using any future-supported backend, e.g. parallel on the local machine or distributed on a compute cluster.  These future_*apply() functions come with the same pros and cons as the corresponding base-R *apply() functions but with the additional feature of being able to be processed via the future framework.",2020-04-17,Henrik Bengtsson,https://github.com/HenrikBengtsson/future.apply,TRUE,https://github.com/henrikbengtsson/future.apply,329703,139,2020-05-13T01:15:51Z,2371.9640287769785
future.BatchJobs,"Implementation of the Future API on top of the 'BatchJobs' package.
    This allows you to process futures, as defined by the 'future' package,
    in parallel out of the box, not only on your local machine or ad-hoc
    cluster of machines, but also via high-performance compute ('HPC') job
    schedulers such as 'LSF', 'OpenLava', 'Slurm', 'SGE', and 'TORQUE' / 'PBS',
    e.g. 'y <- future.apply::future_lapply(files, FUN = process)'.
    NOTE: The 'BatchJobs' package is deprecated in favor of the 'batchtools'
    package. Because of this, it is recommended to use the 'future.batchtools'
    package instead of this package.",2019-09-29,Henrik Bengtsson,https://github.com/HenrikBengtsson/future.BatchJobs,TRUE,https://github.com/henrikbengtsson/future.batchjobs,23305,8,2020-03-21T03:03:26Z,2913.125
future.batchtools,"Implementation of the Future API on top of the 'batchtools' package.
    This allows you to process futures, as defined by the 'future' package,
    in parallel out of the box, not only on your local machine or ad-hoc
    cluster of machines, but also via high-performance compute ('HPC') job
    schedulers such as 'LSF', 'OpenLava', 'Slurm', 'SGE', and 'TORQUE' / 'PBS',
    e.g. 'y <- future.apply::future_lapply(files, FUN = process)'.",2020-04-14,Henrik Bengtsson,https://github.com/HenrikBengtsson/future.batchtools,TRUE,https://github.com/henrikbengtsson/future.batchtools,49975,64,2020-05-06T00:29:17Z,780.859375
future.callr,"Implementation of the Future API on top of the 'callr' package.  This allows you to process futures, as defined by the 'future' package, in parallel out of the box, on your local (Linux, macOS, Windows, ...) machine.  Contrary to backends relying on the 'parallel' package (e.g. 'future::multisession'), the 'callr' backend provided here can run more than 125 parallel R processes.",2019-09-28,Henrik Bengtsson,https://github.com/HenrikBengtsson/future.callr,TRUE,https://github.com/henrikbengtsson/future.callr,22883,35,2020-03-28T02:58:39Z,653.8
future.tests,"Backends implementing the 'Future' API, as defined by the 'future' package, should use the tests provided by this package to validate that they meet the minimal requirements of the 'Future' API.  The tests can be performed easily from within R or from outside of R from the command line making it easy to include them package tests and in Continuous Integration (CI) pipelines.",2020-03-20,Henrik Bengtsson,https://github.com/HenrikBengtsson/future.tests,TRUE,https://github.com/henrikbengtsson/future.tests,1401,9,2020-05-02T22:32:54Z,155.66666666666666
FuzzyAHP,"Calculation of AHP (Analytic Hierarchy Process -
    <http://en.wikipedia.org/wiki/Analytic_hierarchy_process>)
    with classic and fuzzy weights based on Saaty's pairwise
    comparison method for determination of weights.",2019-12-06,Jan Caha,http://github.com/JanCaha/FuzzyAHP/,TRUE,https://github.com/jancaha/fuzzyahp,17281,3,2019-12-10T07:09:58Z,5760.333333333333
fuzzyjoin,"Join tables together based not on whether columns
  match exactly, but whether they are similar by some comparison.
  Implementations include string distance and regular expression
  matching.",2020-05-15,David Robinson,https://github.com/dgrtwo/fuzzyjoin,TRUE,https://github.com/dgrtwo/fuzzyjoin,89734,487,2020-05-16T02:20:43Z,184.258726899384
fxtract,"An R6 implementation for calculating features from grouped data.
    The output will be one row for each group.
    This functionality is often needed in the feature extraction process of machine learning problems.
    Very large datasets are supported, since data is only read into RAM when needed.
    Calculation can be done in parallel and the process can be monitored. 
    Global error handling is supported.
    Results are available in one final dataframe.",2020-06-05,Quay Au,https://github.com/QuayAu/fxtract,TRUE,https://github.com/quayau/fxtract,6016,16,2020-06-05T13:49:28Z,376
GADMTools,"Manipulate, assemble, export <https://gadm.org/> maps. Create 'choropleth', 'isopleth', dots plot, proportional dots,
   dot-density and more.",2020-03-05,Jean Pierre Decorps,https://github.com/IamKDO/GADMTools,TRUE,https://github.com/iamkdo/gadmtools,22900,1,2020-03-06T17:43:13Z,22900
gambin,"Fits unimodal and multimodal gambin distributions to species-abundance distributions
    from ecological data, as in in Matthews et al. (2014) <DOI:10.1111/ecog.00861>. 
    'gambin' is short for 'gamma-binomial'. The main function is fit_abundances(), which estimates 
    the 'alpha' parameter(s) of the gambin distribution using maximum likelihood. Functions are 
    also provided to generate the gambin distribution and for calculating likelihood statistics.",2020-06-02,Thomas Matthews,https://github.com/txm676/gambin/,TRUE,https://github.com/txm676/gambin,26957,4,2020-06-02T11:38:07Z,6739.25
gamCopula,"Implementation of various inference and simulation tools to
    apply generalized additive models to bivariate dependence structures and
    non-simplified vine copulas.",2020-02-05,Thibault Vatter,https://github.com/tvatter/gamCopula,TRUE,https://github.com/tvatter/gamcopula,13060,4,2019-12-04T20:44:20Z,3265
gameofthrones,Implementation of the characteristic palettes from the TV show 'Game of Thrones'.,2020-02-23,Alejandro Jimenez Rico,https://github.com/aljrico/gameofthrones,TRUE,https://github.com/aljrico/gameofthrones,46822,53,2020-02-23T09:26:17Z,883.433962264151
gamesGA,"Finds adaptive strategies for sequential symmetric 
    games using a genetic algorithm. Currently, any symmetric two by two matrix
    is allowed, and strategies can remember the history of an opponent's play
    from the previous three rounds of moves in iterated interactions between
    players. The genetic algorithm returns a list of adaptive strategies given
    payoffs, and the mean fitness of strategies in each generation.",2020-03-01,A. Bradley Duthie,https://bradduthie.github.io/gamesGA/,TRUE,https://github.com/bradduthie/gamesga,9470,1,2020-03-01T19:37:27Z,9470
gamlr,"The gamma lasso algorithm provides regularization paths corresponding to a range of non-convex cost functions between L0 and L1 norms.  As much as possible, usage for this package is analogous to that for the glmnet package (which does the same thing for penalization between L1 and L2 norms).  For details see: Taddy (2017 JCGS), 'One-Step Estimator Paths for Concave Regularization', <arXiv:1308.5623>.",2020-06-08,Matt Taddy,http://github.com/TaddyLab/gamlr,TRUE,https://github.com/taddylab/gamlr,50094,14,2020-06-02T22:29:18Z,3578.1428571428573
gap,"It is designed as an integrated package for genetic data
        analysis of both population and family data. Currently, it
        contains functions for sample size calculations of both
        population-based and family-based designs, probability of
        familial disease aggregation, kinship calculation, statistics
        in linkage analysis, and association analysis involving genetic
        markers including haplotype analysis with or without environmental
        covariates.",2020-02-02,"Jing Hua Zhao and colleagues with inputs from Kurt Hornik and
        Brian Ripley",https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,131042,5,2020-04-28T11:28:17Z,26208.4
GAparsimony,"Methodology that combines feature selection, model tuning, and parsimonious model selection with Genetic Algorithms (GA) proposed in {Martinez-de-Pison} (2015) <DOI:10.1016/j.asoc.2015.06.012>. To this objective, a novel GA selection procedure is introduced based on separate cost and complexity evaluations.",2019-12-03,F.J. Martinez-de-Pison,https://github.com/jpison/GAparsimony,TRUE,https://github.com/jpison/gaparsimony,10398,3,2020-01-28T12:24:17Z,3466
garchx,"Flexible and robust estimation and inference of generalised autoregressive conditional heteroscedasticity (GARCH) models with covariates based on the results by Francq and Thieu (2018) <doi:10.1017/S0266466617000512>. Coefficients can straightforwardly be set to zero by omission, and quasi maximum likelihood methods ensure estimates are generally consistent and inference valid, even when the standardised innovations are non-normal and/or dependent over time.",2020-05-10,Genaro Sucarrat,"https://CRAN.R-project.org/package=garchx,
http://www.sucarrat.net/",TRUE,https://github.com/gsucarrat/garchx,1465,0,2020-05-10T14:08:02Z,NA
gargle,"Provides utilities for working with Google APIs
    <https://developers.google.com/apis-explorer>.  This includes
    functions and classes for handling common credential types and for
    preparing, executing, and processing HTTP requests.",2020-05-06,Jennifer Bryan,"https://gargle.r-lib.org, https://github.com/r-lib/gargle",TRUE,https://github.com/r-lib/gargle,1981912,76,2020-05-28T15:28:28Z,26077.78947368421
GAS,"Simulate, estimate and forecast using univariate and multivariate GAS models 
  as described in Ardia et al. (2019) <doi:10.18637/jss.v088.i06>.",2020-04-27,Leopoldo Catania,https://github.com/LeopoldoCatania/GAS,TRUE,https://github.com/leopoldocatania/gas,40027,18,2020-04-26T18:30:24Z,2223.722222222222
gaselect,"Provides a genetic algorithm for finding variable
    subsets in high dimensional data with high prediction performance. The
    genetic algorithm can use ordinary least squares (OLS) regression models or
    partial least squares (PLS) regression models to evaluate the prediction
    power of variable subsets. By supporting different cross-validation
    schemes, the user can fine-tune the tradeoff between speed and quality of
    the solution.",2020-02-06,David Kepplinger,https://github.com/dakep/gaselect,TRUE,https://github.com/dakep/gaselect,16500,1,2020-02-07T15:48:54Z,16500
gastempt,"Fits gastric emptying time series from MRI or scintigraphic measurements
   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with 
   Stan; computes derived parameters such as t50 and AUC.",2020-05-01,Dieter Menne,http://github.com/dmenne/gastempt,TRUE,https://github.com/dmenne/gastempt,9327,2,2020-05-01T09:38:47Z,4663.5
gaussfacts,"Display a random fact about Carl Friedrich Gauss
 based the on collection curated by Mike Cavers via the
 <http://gaussfacts.com> site.",2016-08-03,Dirk Eddelbuettel,NA,TRUE,https://github.com/eddelbuettel/gaussfacts,13696,2,2020-05-03T23:12:04Z,6848
gbfs,"Supplies a set of functions to interface with bikeshare data
    following the General Bikeshare Feed Specification, allowing users to query
    and accumulate tidy datasets for specified cities/bikeshare programs.",2020-06-07,Simon P. Couch,https://github.com/simonpcouch/gbfs,TRUE,https://github.com/simonpcouch/gbfs,10253,13,2020-06-07T19:34:37Z,788.6923076923077
GCalignR,"Aligns peak based on peak retention times and matches homologous peaks
    across samples. The underlying alignment procedure comprises three sequential steps.
    (1) Full alignment of samples by linear transformation of retention times to 
    maximise similarity among homologous peaks (2) Partial alignment of peaks within 
    a user-defined retention time window to cluster homologous peaks (3) Merging rows
    that are likely representing homologous substances (i.e. no sample shows peaks in 
    both rows and the rows have similar retention time means). The algorithm is described in detail
    in Ottensmann et al., 2018 <doi:10.1371/journal.pone.0198311>. ",2018-07-16,Meinolf Ottensmann,https://github.com/mottensmann/GCalignR,TRUE,https://github.com/mottensmann/gcalignr,13455,1,2019-12-18T14:34:59Z,13455
gclm,"Estimation of covariance matrices as solutions of 
             continuous time Lyapunov equations. 
             Sparse coefficient matrix and diagonal noise are estimated 
             with a proximal gradient 
             method for an l1-penalized loss minimization problem.
             Varando G, Hansen NR (2020) <arXiv:2005.10483>.",2020-06-04,Gherardo Varando,https://github.com/gherardovarando/gclm,TRUE,https://github.com/gherardovarando/gclm,0,0,2020-05-25T06:55:06Z,NA
gdalcubes,"Processing collections of Earth observation images as on-demand multispectral, multitemporal raster data cubes. Users
    define cubes by spatiotemporal extent, resolution, and spatial reference system and let 'gdalcubes' automatically apply cropping, reprojection, and 
    resampling using the 'Geospatial Data Abstraction Library' ('GDAL'). Implemented functions on data cubes include reduction over space and time, 
    applying arithmetic expressions on pixel band values, moving window aggregates over time, filtering by space, time, bands, and predicates on pixel values, 
    exporting data cubes as 'netCDF' or 'GeoTIFF' files, and plotting.  The package implements lazy evaluation and 
    multithreading. All computational parts are implemented in C++, linking to the 'GDAL', 'netCDF', 'CURL', and 'SQLite' libraries. 
    See Appel and Pebesma (2019) <doi:10.3390/data4030092> for further details.",2020-05-17,Marius Appel,https://github.com/appelmar/gdalcubes_R,TRUE,https://github.com/appelmar/gdalcubes_r,6821,52,2020-05-18T11:39:25Z,131.17307692307693
gdalUtilities,"R's 'sf' package ships with self-contained 'GDAL'
    executables, including a bare bones interface to several of the
    'GDAL'-related utility programs collectively known as the 'GDAL'
    utilities. For each of those utilities, this package provides an R
    wrapper whose formal arguments closely mirror those of the 'GDAL'
    command line interface. All of the utilities operate on data
    stored in files and typically write their output to other
    files. As a result, processing data stored in any of R's more
    common spatial formats (i.e. those supported by the 'sp', 'sf',
    and 'raster' packages) will require first writing to disk, then
    processing with the package's wrapper functions before reading
    back into R.",2020-04-29,Joshua OBrien,https://github.com/JoshOBrien/gdalUtilities/,TRUE,https://github.com/joshobrien/gdalutilities,6127,16,2020-04-29T16:06:50Z,382.9375
gdalUtils,"Wrappers for the Geospatial Data Abstraction Library (GDAL)
    Utilities.",2020-02-13,Jonathan Asher Greenberg and Matteo Mattiuzzi,NA,TRUE,https://github.com/gearslaboratory/gdalutils,359922,9,2020-02-13T19:25:43Z,39991.333333333336
GDINA,"A set of psychometric tools for cognitive diagnosis modeling based on the generalized deterministic inputs, noisy and gate (G-DINA) model by de la Torre (2011) <DOI:10.1007/s11336-011-9207-7> and its extensions, including the sequential G-DINA model by Ma and de la Torre (2016) <DOI:10.1111/bmsp.12070> for polytomous responses, and the polytomous G-DINA model by Chen and de la Torre <DOI:10.1177/0146621613479818> for polytomous attributes. Joint attribute distribution can be independent, saturated, higher-order, loglinear smoothed or structured. Q-matrix validation, item and model fit statistics, model comparison at test and item level and differential item functioning can also be conducted. A graphical user interface is also provided. For tutorials, please check Ma and de la Torre (2020) <DOI:10.18637/jss.v093.i14>, Ma and de la Torre (2019) <DOI:10.1111/emip.12262>, Ma (2019) <DOI:10.1007/978-3-030-05584-4_29> and de la Torre and Akbay (2019) <DOI:10.14689/ejer.2019.80.9>. ",2020-05-24,Wenchao Ma,"https://github.com/Wenchao-Ma/GDINA,
https://wenchao-ma.github.io/GDINA",TRUE,https://github.com/wenchao-ma/gdina,55094,12,2020-06-04T16:21:47Z,4591.166666666667
gdistance,Calculate distances and routes on geographic grids.,2020-02-29,Jacob van Etten,https://agrobioinfoservices.github.io/gdistance/,TRUE,https://github.com/agrobioinfoservices/gdistance,108502,0,2020-02-28T19:30:15Z,NA
gdtools,Useful tools for writing vector graphics devices.,2020-04-03,David Gohel,NA,TRUE,https://github.com/davidgohel/gdtools,1538739,23,2020-04-03T11:41:58Z,66901.69565217392
GE,"Some tools for developing general equilibrium models and some general equilibrium models. These models can be used for teaching economic theory and are built by the methods of new structural economics (see <https://www.nse.pku.edu.cn/> and LI Wu, 2019, General Equilibrium and Structural Dynamics: Perspectives of New Structural Economics. Beijing: Economic Science Press).",2020-06-02,LI Wu,NA,TRUE,https://github.com/liwur/cge,1638,0,2020-01-31T02:42:46Z,NA
GEEmediate,"Causal mediation analysis for a single exposure/treatment and a
    single mediator, both allowed to be either continuous or binary. The package
    implements the difference method and provide point and interval estimates as
    well as testing for the natural direct and indirect effects and the mediation
    proportion. Nevo, Xiao and Spiegelman (2019) <doi:10.1515/ijb-2017-0006>.",2019-07-18,Daniel Nevo,NA,TRUE,https://github.com/daniel258/geemediate,12234,0,2019-07-16T11:29:08Z,NA
geex,"Provides a general, flexible framework for estimating parameters
    and empirical sandwich variance estimator from a set of unbiased estimating
    equations (i.e., M-estimation in the vein of Stefanski & Boos (2002)
    <doi:10.1198/000313002753631330>). All examples from Stefanski & Boos (2002)
    are published in the corresponding Journal of Statistical Software paper 
    <doi:10.18637/jss.v092.i02>. Also provides an API to compute finite-sample 
    variance corrections.",2020-02-17,Bradley Saul,"https://github.com/bsaul/geex, https://bsaul.github.io/geex/",TRUE,https://github.com/bsaul/geex,10297,4,2020-02-17T14:08:37Z,2574.25
geiger,"Methods for fitting macroevolutionary models to phylogenetic trees 
	Pennell (2014) <doi:10.1093/bioinformatics/btu181>.",2020-06-02,Luke Harmon,https://github.com/mwpennell/geiger-v2,TRUE,https://github.com/mwpennell/geiger-v2,158324,14,2020-06-01T20:38:01Z,11308.857142857143
gemma2,"Fits a multivariate linear mixed effects model that uses a polygenic term, after Zhou & Stephens (2014) (<https://www.nature.com/articles/nmeth.2848>). Of particular interest is the estimation of variance components with restricted maximum likelihood (REML) methods. Genome-wide efficient mixed-model association (GEMMA), as implemented in the package 'gemma2', uses an expectation-maximization algorithm for variance components inference for use in quantitative trait locus studies.",2019-10-01,Frederick Boehm,https://github.com/fboehm/gemma2,TRUE,https://github.com/fboehm/gemma2,3384,0,2019-10-01T19:22:18Z,NA
genalg,"R based genetic algorithm for binary and floating point
        chromosomes.",2015-03-16,Egon Willighagen and Michel Ballings,https://github.com/egonw/genalg,TRUE,https://github.com/egonw/genalg,98635,15,2019-07-15T08:15:37Z,6575.666666666667
gender,"Infers state-recorded gender categories from first names and dates of birth using historical
    datasets. By using these datasets instead of lists of male and female names,
    this package is able to more accurately infer the gender of a name, and it
    is able to report the probability that a name was male or female. GUIDELINES:
    This method must be used cautiously and responsibly. Please be sure to see the
    guidelines and warnings about usage in the 'README' or the package documentation.
    See Blevins and Mullen (2015) <http://www.digitalhumanities.org/dhq/vol/9/3/000223/000223.html>.",2020-05-15,Lincoln Mullen,"https://docs.ropensci.org/gender/,
https://github.com/ropensci/gender",TRUE,https://github.com/ropensci/gender,334276,134,2020-05-14T21:51:04Z,2494.597014925373
geneHummus,"A pipeline with high specificity and sensitivity in extracting 
  proteins from the RefSeq database (National Center for Biotechnology 
  Information). Manual identification of gene families is highly 
  time-consuming and laborious, requiring an iterative process of manual and 
  computational analysis to identify members of a given family. The pipelines 
  implements an automatic approach for the identification of gene families 
  based on the conserved domains that specifically define that family. See 
  Die et al. (2018) <doi:10.1101/436659> for more information and examples.",2019-04-04,Jose V. Die,https://github.com/NCBI-Hackathons/GeneHummus,TRUE,https://github.com/ncbi-hackathons/genehummus,5168,5,2020-02-01T16:34:03Z,1033.6
GeneralizedUmatrix,"Projections are common dimensionality reduction methods, which represent high-dimensional data in a two-dimensional space. However, when restricting the output space to two dimensions, which results in a two dimensional scatter plot (projection) of the data, low dimensional similarities do not represent high dimensional distances coercively [Thrun, 2018]. This could lead to a misleading interpretation of the underlying structures [Thrun, 2018]. By means of the 3D topographic map the generalized Umatrix is able to depict errors of these two-dimensional scatter plots. The package is based on the book of Thrun, M.C.: ""Projection Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <DOI:10.1007/978-3-658-20540-9>.",2020-03-23,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/generalizedumatrix,16574,0,2020-06-02T12:21:23Z,NA
genero,"Estimate gender from names in Spanish and Portuguese. 
    Works with vectors and dataframes. The estimation works not only
    for first names but also full names. The package relies on a
    compilation of common names with it's most frequent associated 
    gender in both languages which are used as look up tables for gender
    inference.",2020-03-09,Juan Pablo Marin Diaz,https://github.com/datasketch/genero,TRUE,https://github.com/datasketch/genero,1461,1,2020-06-01T00:43:42Z,1461
GeNetIt,"Implementation of spatial graph-theoretic genetic gravity models.
    The model framework is applicable for other types of spatial flow questions.
    Includes functions for constructing spatial graphs, sampling and summarizing
    associated raster variables and building unconstrained and singly constrained
    gravity models.",2020-04-01,Jeffrey S. Evans,https://github.com/jeffreyevans/GeNetIt,TRUE,https://github.com/jeffreyevans/genetit,15390,0,2020-04-01T13:58:31Z,NA
genie,"A new hierarchical clustering linkage criterion:
    the Genie algorithm links two clusters in such a way that a chosen
    economic inequity measure (e.g., the Gini index) of the cluster
    sizes does not increase drastically above a given threshold. Benchmarks
    indicate a high practical usefulness of the introduced method:
    it most often outperforms the Ward or average linkage in terms of
    the clustering quality while retaining the single linkage speed,
    see (Gagolewski et al. 2016a <DOI:10.1016/j.ins.2016.05.003>,
    2016b <DOI:10.1007/978-3-319-45656-0_16>)
    for more details.",2017-04-27,Marek Gagolewski,http://www.gagolewski.com/software/genie/,TRUE,https://github.com/gagolews/genie,16606,19,2020-01-16T05:54:19Z,874
genio,"Implements readers and writers for file formats associated with genetics data.  Reading and writing plink BED/BIM/FAM formats is fully supported, including a lightning-fast BED reader and writer implementations.  Other functions are 'readr' wrappers that are more constrained, user-friendly, and efficient for these particular applications; handles plink and eigenstrat tables (FAM, BIM, IND, and SNP files).  There are also ""make"" functions for FAM and BIM tables with default values to go with simulated genotype data.",2019-12-17,Alejandro Ochoa,https://github.com/OchoaLab/genio,TRUE,https://github.com/ochoalab/genio,4925,6,2020-05-22T02:10:23Z,820.8333333333334
genius,Easily access song lyrics in a tidy way.,2020-05-28,Josiah Parry,https://github.com/josiahparry/genius,TRUE,https://github.com/josiahparry/genius,13058,92,2020-05-09T21:01:04Z,141.93478260869566
geniusr,"Provides tools to interact nicely with the 'Genius' API 
    <https://docs.genius.com/>. 
    Search hosted content, extract associated metadata and retrieve lyrics with ease.",2020-04-13,Ewen Henderson,"https://ewenme.github.io/geniusr/,
https://github.com/ewenme/geniusr",TRUE,https://github.com/ewenme/geniusr,11460,30,2020-04-13T16:34:16Z,382
genlasso,"Provides fast algorithms for computing the solution path for generalized lasso problems. Important use cases are the fused lasso over an arbitrary graph, and trend fitting of any given polynomial order. Specialized implementations for the latter two problems are given to improve stability and speed.",2019-07-11,Taylor B. Arnold and Ryan J. Tibshirani,https://github.com/statsmaths/genlasso,TRUE,https://github.com/statsmaths/genlasso,41457,20,2019-06-20T15:45:36Z,2072.85
genridge,"
	The genridge package introduces generalizations of the standard univariate
	ridge trace plot used in ridge regression and related methods.  These graphical methods
	show both bias (actually, shrinkage) and precision, by plotting the covariance ellipsoids of the estimated
	coefficients, rather than just the estimates themselves.  2D and 3D plotting methods are provided,
	both in the space of the predictor variables and in the transformed space of the PCA/SVD of the
	predictors.  ",2020-01-29,Michael Friendly,NA,TRUE,https://github.com/friendly/genridge,22874,0,2020-01-29T14:38:27Z,NA
genscore,"Implementation of the Generalized Score Matching estimator in Yu et al. (2019) <http://jmlr.org/papers/v20/18-278.html> for non-negative graphical models (truncated Gaussian, exponential square-root, gamma, a-b models) and univariate truncated Gaussian distributions. Also includes the original estimator for untruncated Gaussian graphical models from Lin et al. (2016) <doi:10.1214/16-EJS1126>, with the addition of a diagonal multiplier.",2020-04-27,Shiqing Yu,https://github.com/sqyu/genscore,TRUE,https://github.com/sqyu/genscore,627,0,2020-04-24T19:19:49Z,NA
genvar,"Implements tools for manipulating data sets and performing regressions in a way that is familiar to users of a popular, but proprietary, statistical package commonly used in the social sciences. Loads a single dataset into memory and implements a set of imperative commands to modify that data and perform regressions and other analysis on the dataset. Offers an alternative to standard R's function-based approach to data manipulation.",2020-01-21,Zach Flynn,NA,TRUE,https://github.com/flynnzac/genvar,3486,4,2020-04-09T01:29:51Z,871.5
geoaxe,"Split 'geospatial' objects into pieces. Includes
    support for some spatial object inputs, 'Well-Known Text', and
    'GeoJSON'.",2016-02-19,Scott Chamberlain,https://github.com/ropenscilabs/geoaxe,TRUE,https://github.com/ropenscilabs/geoaxe,73540,14,2019-12-09T13:12:05Z,5252.857142857143
geobr,"Easy access to official spatial data sets of Brazil as 'sf' objects in R.
	     The package includes a wide range of geospatial data available at various 
             geographic scales and for various years with harmonized attributes, projection and topology.",2020-03-29,Rafael H. M. Pereira,https://github.com/ipeaGIT/geobr,TRUE,https://github.com/ipeagit/geobr,8679,313,2020-06-05T20:24:01Z,27.728434504792332
geodaData,"Stores small spatial datasets used to teach basic spatial analysis
    concepts. Datasets are based off of the 'GeoDa' software workbook and data
    site <https://geodacenter.github.io/data-and-lab/> developed by Luc Anselin
    and team at the University of Chicago. Datasets are stored as 'sf' objects.",2020-05-27,Angela Li,https://github.com/spatialanalysis/geodaData,TRUE,https://github.com/spatialanalysis/geodadata,111,11,2020-05-20T01:06:43Z,10.090909090909092
geodist,"Dependency-free, ultra fast calculation of geodesic distances.
    Includes the reference nanometre-accuracy geodesic distances of Karney
    (2013) <doi:10.1007/s00190-012-0578-z>, as used by the 'sf' package, as well
    as Haversine and Vincenty distances. Default distance measure is the ""Mapbox
    cheap ruler"" which is generally more accurate than Haversine or Vincenty for
    distances out to a few hundred kilometres, and is considerably faster. The
    main function accepts one or two inputs in almost any generic rectangular
    form, and returns either matrices of pairwise distances, or vectors of
    sequential distances.",2020-05-18,Mark Padgham,https://github.com/hypertidy/geodist,TRUE,https://github.com/hypertidy/geodist,16348,55,2020-05-19T09:59:21Z,297.23636363636365
geofacet,Provides geofaceting functionality for 'ggplot2'. Geofaceting arranges a sequence of plots of data for different geographical entities into a grid that preserves some of the geographical orientation.,2020-05-26,Ryan Hafen,https://github.com/hafen/geofacet,TRUE,https://github.com/hafen/geofacet,23093,244,2020-05-25T22:45:17Z,94.64344262295081
geohashTools,"Tools for working with Gustavo Niemeyer's geohash coordinate system, including API for interacting with other common R GIS libraries.",2020-05-26,Michael Chirico,https://github.com/MichaelChirico/geohashTools,TRUE,https://github.com/michaelchirico/geohashtools,6461,39,2020-05-26T10:43:28Z,165.66666666666666
geojson,"Classes for 'GeoJSON' to make working with 'GeoJSON' easier.
    Includes S3 classes for 'GeoJSON' classes with brief summary output,
    and a few methods such as extracting and adding bounding boxes,
    properties, and coordinate reference systems; working with 
    newline delimited 'GeoJSON'; linting through the 'geojsonlint' 
    package; and serializing to/from 'Geobuf' binary 'GeoJSON' 
    format.",2019-01-31,Scott Chamberlain,https://github.com/ropensci/geojson,TRUE,https://github.com/ropensci/geojson,221000,30,2019-12-09T13:12:23Z,7366.666666666667
geojsonio,"Convert data to 'GeoJSON' or 'TopoJSON' from various R classes,
    including vectors, lists, data frames, shape files, and spatial classes.
    'geojsonio' does not aim to replace packages like 'sp', 'rgdal', 'rgeos',
    but rather aims to be a high level client to simplify conversions of data
    from and to 'GeoJSON' and 'TopoJSON'.",2020-04-07,Scott Chamberlain,"https://github.com/ropensci/geojsonio (devel),
https://docs.ropensci.org/geojsonio (docs)",TRUE,https://github.com/ropensci/geojsonio,325128,128,2020-04-08T15:31:48Z,2540.0625
geojsonlint,"Tools for linting 'GeoJSON'. Includes tools for interacting with the
    online tool <http://geojsonlint.com>, the 'Javascript' library 'geojsonhint'
    (<https://www.npmjs.com/package/geojsonhint>), and validating against a
    'GeoJSON' schema via the 'Javascript' library
    (<https://www.npmjs.com/package/is-my-json-valid>). Some tools work locally
    while others require an internet connection.",2020-02-13,Scott Chamberlain,"https://github.com/ropensci/geojsonlint (devel)
https://docs.ropensci.org/geojsonlint (docs)",TRUE,https://github.com/ropensci/geojsonlint,151169,9,2020-02-13T16:04:02Z,16796.555555555555
geojsonR,"Includes functions for processing GeoJson objects <https://en.wikipedia.org/wiki/GeoJSON> relying on 'RFC 7946' <https://tools.ietf.org/pdf/rfc7946.pdf>. The geojson encoding is based on 'json11', a tiny JSON library for 'C++11' <https://github.com/dropbox/json11>. Furthermore, the source code is exported in R through the 'Rcpp' and 'RcppArmadillo' packages.",2020-03-18,Lampros Mouselimis,https://github.com/mlampros/geojsonR,TRUE,https://github.com/mlampros/geojsonr,29809,9,2020-03-18T16:47:27Z,3312.1111111111113
geojsonsf,Converts Between GeoJSON and simple feature objects. ,2020-03-18,David Cooley,https://github.com/SymbolixAU/geojsonsf,TRUE,https://github.com/symbolixau/geojsonsf,76359,54,2020-06-07T00:19:48Z,1414.0555555555557
geoknife,"Processes gridded datasets found on the U.S. Geological Survey
    Geo Data Portal web application or elsewhere, using a web-enabled workflow
    that eliminates the need to download and store large datasets that are reliably
    hosted on the Internet. The package provides access to several data subset and
    summarization algorithms that are available on remote web processing servers (Read et al. (2015) <doi:10.1111/ecog.01880>).",2020-06-02,Jordan Read,https://github.com/USGS-R/geoknife,TRUE,https://github.com/usgs-r/geoknife,36963,51,2020-05-30T10:21:23Z,724.7647058823529
geometr,"Provides tools that generate and process fully accessible and tidy
    geometric shapes. The package improves interoperability of spatial and 
    other geometric classes by providing getters and setters that produce 
    identical output from various classes.",2020-03-30,Steffen Ehrmann,https://github.com/EhrmannS/geometr,TRUE,https://github.com/ehrmanns/geometr,2237,13,2020-05-15T13:03:55Z,172.07692307692307
geometry,"Makes the 'Qhull' library <http://www.qhull.org>
    available in R, in a similar manner as in Octave and MATLAB. Qhull
    computes convex hulls, Delaunay triangulations, halfspace
    intersections about a point, Voronoi diagrams, furthest-site
    Delaunay triangulations, and furthest-site Voronoi diagrams. It
    runs in 2D, 3D, 4D, and higher dimensions. It implements the
    Quickhull algorithm for computing the convex hull. Qhull does not
    support constrained Delaunay triangulations, or mesh generation of
    non-convex objects, but the package does include some R functions
    that allow for this.",2019-12-04,Jean-Romain Roussel [cph,https://davidcsterratt.github.io/geometry,TRUE,https://github.com/davidcsterratt/geometry,945355,12,2019-12-03T18:20:44Z,78779.58333333333
geomorph,"Read, manipulate, and digitize landmark data, generate shape
    variables via Procrustes analysis for points, curves and surfaces, perform
    shape analyses, and provide graphical depictions of shapes and patterns of
    shape variation.",2020-06-03,Dean Adams,https://github.com/geomorphR/geomorph,TRUE,https://github.com/geomorphr/geomorph,103997,42,2020-04-21T12:55:45Z,2476.1190476190477
geonetwork,"Provides classes and methods for handling networks or 
  graphs whose nodes are geographical (i.e. locations in the globe).
  The functionality includes the creation of objects of class geonetwork
  as a graph with node coordinates, the computation of network measures,
  the support of spatial operations (projection to different Coordinate
  Reference Systems, handling of bounding boxes, etc.) and the plotting of
  the geonetwork object combined with supplementary cartography for spatial 
  representation.",2019-04-05,Facundo Muñoz,https://github.com/Cirad-ASTRE/geonetwork,TRUE,https://github.com/cirad-astre/geonetwork,5115,1,2019-08-23T15:29:20Z,5115
geoops,"Tools for doing calculations and manipulations on 'GeoJSON',
    a 'geospatial' data interchange format (<https://tools.ietf.org/html/rfc7946>).
    'GeoJSON' is also valid 'JSON'.",2020-05-17,Scott Chamberlain,"https://docs.ropensci.org/geoops,
https://github.com/ropensci/geoops",TRUE,https://github.com/ropensci/geoops,10190,18,2020-05-18T14:17:59Z,566.1111111111111
geospark,"R binds 'GeoSpark' <http://geospark.datasyslab.org/> extending 'sparklyr' 
    <https://spark.rstudio.com/> R package to make distributed 'geocomputing' easier. Sf is a
    package that provides [simple features] <https://en.wikipedia.org/wiki/Simple_Features> access
    for R and which is a leading 'geospatial' data processing tool. 'Geospark' R package bring 
    the same simple features access like sf but running on Spark distributed system.",2020-03-02,Harry Zhu,NA,TRUE,https://github.com/harryprince/geospark,5346,38,2020-03-02T03:26:49Z,140.68421052631578
geoSpectral,"Provides S4 classes and data import, preprocessing, graphing, 
    manipulation and export methods for geo-Spectral datasets (datasets with space/time/spectral 
    dimensions). These type of data are frequently collected within earth observation projects 
    (remote sensing, spectroscopy, bio-optical oceanography, mining, agricultural, atmospheric, 
    environmental or similar branch of science).",2020-02-20,Servet Ahmet Cizmeli,https://github.com/PranaGeo/geoSpectral,TRUE,https://github.com/pranageo/geospectral,11461,2,2020-02-21T08:06:27Z,5730.5
geotopbricks,"It analyzes raster maps and other information as input/output
    files from the Hydrological Distributed Model GEOtop. It contains functions
    and methods to import maps and other keywords from geotop.inpts file. Some
    examples with simulation cases of GEOtop 2.x/3.x are presented in the package.
    Any information about the GEOtop Distributed Hydrological Model source code
    is available on www.geotop.org. Technical details about the model are
    available in Endrizzi et al, 2014
    (<http://www.geosci-model-dev.net/7/2831/2014/gmd-7-2831-2014.html>).",2020-02-11,Emanuele Cordano,"http://www.geotop.org, https://github.com/ecor/geotopbricks",TRUE,https://github.com/ecor/geotopbricks,19197,3,2020-05-05T01:00:45Z,6399
geouy,"The toolbox have functions to load and process geographic information for Uruguay. 
        And extra-function to get address coordinates and orthophotos through the uruguayan 'IDE' API <https://www.gub.uy/infraestructura-datos-espaciales/tramites-y-servicios/servicios/servicio-direcciones-geograficas>.",2020-06-03,Richard Detomasi,NA,TRUE,https://github.com/richdeto/geouy,1976,2,2020-06-09T23:59:50Z,988
geoviz,Simpler processing of digital elevation model and GPS trace data for use with the 'rayshader' package.,2020-01-12,Neil Charles,https://github.com/neilcharles/geoviz/,TRUE,https://github.com/neilcharles/geoviz,6086,83,2020-04-28T15:43:45Z,73.32530120481928
GermaParl,"Data package to disseminate the  'GermaParl' corpus of parliamentary debates of 
  the German Bundestag prepared in the 'PolMine Project'. The package includes a small subset of
  the corpus for demonstration and testing purposes. The package includes functionality to load 
  the full corpus from the open science repository 'Zenodo' and some auxiliary functions to
  enhance the corpus.",2020-05-25,Andreas Blaette,https://github.com/polmine/GermaParl,TRUE,https://github.com/polmine/germaparl,185,1,2020-04-09T20:05:07Z,185
GerminaR,A collection of different indices and visualization techniques for evaluate the seed germination process in ecophysiological studies (Lozano-Isla et al. 2019) <doi:10.1111/1440-1703.1275>.,2020-03-28,Flavio Lozano Isla,https://flavjack.github.io/germinaquant/,TRUE,https://github.com/flavjack/germinar,15301,2,2020-06-02T17:47:08Z,7650.5
germinationmetrics,"Provides functions to compute various germination indices such as
    germinability, median germination time, mean germination time, mean
    germination rate, speed of germination, Timson's index, germination value,
    coefficient of uniformity of germination, uncertainty of germination
    process, synchrony of germination etc. from germination count data. Includes
    functions for fitting cumulative seed germination curves using
    four-parameter hill function and computation of associated parameters. See
    the vignette for more, including full list of citations for the methods
    implemented.",2019-01-19,J. Aravind,"https://github.com/aravind-j/germinationmetrics,
https://aravind-j.github.io/germinationmetrics/
https://CRAN.R-project.org/package=germinationmetrics
https://doi.org/10.5281/zenodo.1219630",TRUE,https://github.com/aravind-j/germinationmetrics,12302,1,2020-02-27T18:32:47Z,12302
gert,"Simple git client based on 'libgit2' with user-friendly authentication
    and support for both SSH and HTTPS remotes on all platforms. User credentials
    are shared with command line 'git' through the git-credential store and ssh keys
    stored on disk or ssh-agent. On Linux, a somewhat recent  version of 'libgit2' is
    required.",2019-10-29,Jeroen Ooms,"https://jeroen.cran.dev/gert (website),
httsp://github.com/r-lib/gert (devel), https://libgit2.org
(upstream)",TRUE,https://github.com/r-lib/gert,7637,58,2020-06-09T14:29:42Z,131.67241379310346
gestalt,"Provides a suite of function-building tools centered around a
  (forward) composition operator, %>>>%, which extends the semantics of the
  'magrittr' %>% operator and supports 'tidyverse' quasiquotation. It enables
  you to construct composite functions that can be inspected and transformed as
  list-like objects. In conjunction with %>>>%, a compact function constructor,
  fn(), and a function that performs partial application, partial(), are also
  provided. Both support quasiquotation.",2019-06-27,Eugene Ha,https://github.com/egnha/gestalt,TRUE,https://github.com/egnha/gestalt,9842,33,2019-06-27T06:32:44Z,298.24242424242425
GetBCBData,"Downloads and organizes datasets using BCB's API <https://www.bcb.gov.br/>. Offers options for caching with the 'memoise' package and
    , multicore/multisession with 'furrr' and format of output data (long/wide). ",2019-04-23,Marcelo Perlin,https://github.com/msperlin/GetBCBData/,TRUE,https://github.com/msperlin/getbcbdata,5174,4,2019-11-20T11:36:19Z,1293.5
getCRUCLdata,"Provides functions that automate downloading and importing
    University of East Anglia Climate Research Unit ('CRU') 'CL' v. 2.0
    climatology data, facilitates the calculation of minimum temperature and
    maximum temperature and formats the data into a tidy data frame as a
    'tibble' or a list of 'raster' 'stack' objects for use.  'CRU' 'CL' v. 2.0
    data are a gridded climatology of 1961-1990 monthly means released in 2002
    and cover all land areas (excluding Antarctica) at 10 arcminutes
    (0.1666667 degree) resolution.  For more information see the description of
    the data provided by the University of East Anglia Climate Research Unit,
    <https://crudata.uea.ac.uk/cru/data/hrg/tmc/readme.txt>.",2019-08-29,Adam Sparks,https://docs.ropensci.org/getCRUCLdata/,TRUE,https://github.com/ropensci/getcrucldata,34859,11,2020-03-22T08:32:58Z,3169
GetDFPData,"Reads annual financial reports including assets, liabilities, dividends history, stockholder composition and much more from Bovespa's DFP, FRE and FCA systems <http://www.bmfbovespa.com.br/en_us/products/listed-equities-and-derivatives/equities/listed-companies.htm>.
 These are web based interfaces for all financial reports of companies traded at Bovespa. The package is specially designed for large scale data importation, keeping a tabular (long) structure for easier processing.  ",2020-05-18,Marcelo Perlin,https://github.com/msperlin/GetDFPData/,TRUE,https://github.com/msperlin/getdfpdata,21345,29,2020-05-18T15:58:23Z,736.0344827586207
GetHFData,Downloads and aggregates high frequency trading data for Brazilian instruments directly from Bovespa ftp site <ftp://ftp.bmf.com.br/MarketData/>.,2019-04-08,Marcelo Perlin,https://github.com/msperlin/GetHFData/,TRUE,https://github.com/msperlin/gethfdata,30243,30,2020-06-09T19:03:09Z,1008.1
getlandsat,"Get Landsat 8 Data from Amazon Web Services ('AWS')
    public data sets (<https://registry.opendata.aws/landsat-8/>).
    Includes functions for listing images and fetching them, and handles
    caching to prevent unnecessary additional requests.",2018-04-30,Scott Chamberlain,https://github.com/ropensci/getlandsat,TRUE,https://github.com/ropensci/getlandsat,12915,47,2019-12-09T13:16:22Z,274.78723404255317
GetLattesData,A simple API for downloading and reading xml data directly from Lattes <http://lattes.cnpq.br/>.,2020-03-07,Marcelo Perlin,https://github.com/msperlin/GetLattesData/,TRUE,https://github.com/msperlin/getlattesdata,15697,6,2020-03-07T15:22:09Z,2616.1666666666665
getmstatistic,"Quantifying systematic heterogeneity in meta-analysis using R.
    The M statistic aggregates heterogeneity information across multiple
    variants to, identify systematic heterogeneity patterns and their direction
    of effect in meta-analysis. It's primary use is to identify outlier studies,
    which either show ""null"" effects or consistently show stronger or weaker
    genetic effects than average across, the panel of variants examined in a
    GWAS meta-analysis. In contrast to conventional heterogeneity metrics
    (Q-statistic, I-squared and tau-squared) which measure random heterogeneity
    at individual variants, M measures systematic (non-random)
    heterogeneity across multiple independently associated variants. Systematic
    heterogeneity can arise in a meta-analysis due to differences in the study
    characteristics of participating studies. Some of the differences may
    include: ancestry, allele frequencies, phenotype definition, age-of-disease
    onset, family-history, gender, linkage disequilibrium and quality control
    thresholds. See <https://magosil86.github.io/getmstatistic/> for statistical
    statistical theory, documentation and examples.",2020-03-30,Lerato E Magosi,https://magosil86.github.io/getmstatistic/,TRUE,https://github.com/magosil86/getmstatistic,11430,2,2020-03-29T22:43:47Z,5715
getopt,"Package designed to be used with Rscript to write
    ``#!'' shebang scripts that accept short and long flags/options.
    Many users will prefer using instead the packages optparse or argparse
    which add extra features like automatically generated help option and usage,
    support for default values, positional argument support, etc.",2019-03-22,Trevor L Davis,https://github.com/trevorld/r-getopt,TRUE,https://github.com/trevorld/r-getopt,442998,10,2019-11-26T01:09:33Z,44299.8
GetoptLong,"This is yet another command-line argument parser which wraps the 
    powerful Perl module Getopt::Long and with some adaptation for easier use
	in R. It also provides a simple way for variable interpolation in R.",2020-01-08,Zuguang Gu,https://github.com/jokergoo/GetoptLong,TRUE,https://github.com/jokergoo/getoptlong,228934,7,2020-06-06T17:32:31Z,32704.85714285714
getProxy,"Allows get address and port 
	of the free proxy server, from one of two services
	<http://gimmeproxy.com/> or <https://getproxylist.com/>. 
	And it's easy to redirect your Internet connection through
	a proxy server.",2018-08-20,Alexey Seleznev,http://selesnow.github.io/getProxy,TRUE,https://github.com/selesnow/getproxy,7163,6,2020-05-08T14:58:59Z,1193.8333333333333
GetQuandlData,"Imports time series data from the 'Quandl' database <https://www.quandl.com>. The package uses the  'json api' at <https://www.quandl.com/tools/api>, local caching ('memoise' package) and the tidy format by default. 
   Also allows queries of databases, allowing the user to see which time series are available for each database id. In short, it is an alternative to package 'Quandl', with faster data importation in the tidy/long format.",2019-10-20,Marcelo S. Perlin,https://github.com/msperlin/GetQuandlData/,TRUE,https://github.com/msperlin/getquandldata,3038,7,2019-10-16T19:04:52Z,434
gets,"Automated General-to-Specific (GETS) modelling of the mean and variance of a regression, and indicator saturation methods for detecting and testing for structural breaks in the mean.",2020-05-04,Genaro Sucarrat,"https://CRAN.R-project.org/package=gets,
http://www.sucarrat.net/R/gets",TRUE,https://github.com/gsucarrat/gets,60468,3,2020-04-30T13:02:55Z,20156
getspres,"An implementation of SPRE (standardised predicted random-effects)
    statistics in R to explore heterogeneity in genetic association meta-
    analyses, as described by Magosi et al. (2019) 
    <doi:10.1093/bioinformatics/btz590>. SPRE statistics are precision 
    weighted residuals that indicate the direction and extent with which 
    individual study-effects in a meta-analysis deviate from the average 
    genetic effect. Overly influential positive outliers have the potential 
    to inflate average genetic effects in a meta-analysis whilst negative 
    outliers might lower or change the direction of effect. See the 'getspres' 
    website for documentation and examples 
    <https://magosil86.github.io/getspres/>.",2020-03-31,Lerato E Magosi,https://magosil86.github.io/getspres/,TRUE,https://github.com/magosil86/getspres,3678,0,2020-03-31T12:38:39Z,NA
getTBinR,"Quickly and easily import analysis ready
    Tuberculosis (TB) burden data, from the World Health Organisation
    (WHO), into R. The aim of getTBinR is to allow researchers, and other
    interested individuals, to quickly and easily gain access to a
    detailed TB data set and to start using it to derive key insights. It
    provides a consistent set of tools that can be used to rapidly
    evaluate hypotheses on a widely used data set before they are explored
    further using more complex methods or more detailed data. These tools
    include: generic plotting and mapping functions; a data dictionary
    search tool; an interactive shiny dashboard; and an automated, country
    level, TB report. For newer R users, this package reduces the barrier
    to entry by handling data import, munging, and visualisation. All
    plotting and mapping functions are built with ggplot2 so can be
    readily extended.",2019-09-03,Sam Abbott,"https://www.samabbott.co.uk/getTBinR,
https://github.com/seabbs/getTBinR",TRUE,https://github.com/seabbs/gettbinr,15627,13,2020-02-23T17:24:33Z,1202.076923076923
GetTDData,Downloads and aggregates data for Brazilian government issued bonds directly from the website of Tesouro Direto <http://www.tesouro.fazenda.gov.br/tesouro-direto-balanco-e-estatisticas>.,2019-10-01,Marcelo Perlin,https://github.com/msperlin/GetTDData/,TRUE,https://github.com/msperlin/gettddata,31329,6,2019-10-01T19:22:18Z,5221.5
gettz,"A function to retrieve the system timezone on Unix systems
 which has been found to find an answer when 'Sys.timezone()' has failed.
 It is based on an answer by Duane McCully posted on 'StackOverflow', and
 adapted to be callable from R. The package also builds on Windows, but
 just returns NULL.",2020-04-14,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/gettz.html,TRUE,https://github.com/eddelbuettel/gettz,17968,1,2020-05-16T13:39:24Z,17968
gexp,"Generates experiments - simulating structured or experimental data as: 
             completely randomized design, randomized block design, latin square design, 
             factorial and split-plot experiments (Ferreira, 2008, ISBN:8587692526; 
             Naes et al., 2007 <doi:10.1002/qre.841>; Rencher et al., 2007, ISBN:9780471754985; 
             Montgomery, 2001, ISBN:0471316490).",2020-04-02,Ivan Bezerra Allaman,https://github.com/ivanalaman/gexp,TRUE,https://github.com/ivanalaman/gexp,5117,1,2020-04-01T22:33:18Z,5117
gfcanalysis,"Supports analyses using the Global Forest Change dataset released
    by Hansen et al. gfcanalysis was originally written for the Tropical Ecology 
    Assessment and Monitoring (TEAM) Network. For additional details on the 
    Global Forest Change dataset, see: Hansen, M. et al. 2013. ""High-Resolution 
    Global Maps of 21st-Century Forest Cover Change."" Science 342 (15 
    November): 850-53. The forest change data and more information on the 
    product is available at <http://earthenginepartners.appspot.com>.",2019-03-12,Matthew Cooper,https://github.com/azvoleff/gfcanalysis,TRUE,https://github.com/azvoleff/gfcanalysis,18776,10,2020-02-05T03:20:56Z,1877.6
gfonts,"Download 'Google' fonts and generate CSS to use in 'rmarkdown' documents and 
  'shiny' applications. Some popular fonts are included and ready to use.",2020-05-09,Victor Perrier,https://github.com/dreamRs/gfonts,TRUE,https://github.com/dreamrs/gfonts,488,78,2020-05-09T17:51:52Z,6.256410256410256
gfoRmula,"Implements the parametric g-formula algorithm of Robins (1986) 
    <doi:10.1016/0270-0255(86)90088-6>. The g-formula can be used to estimate 
    the causal effects of hypothetical time-varying treatment interventions on 
    the mean or risk of an outcome from longitudinal data with time-varying 
    confounding. This package allows: 1) binary or continuous/multi-level 
    time-varying treatments; 2) different types of outcomes (survival or 
    continuous/binary end of follow-up); 3) data with competing events or 
    truncation by death and loss to follow-up and other types of censoring 
    events; 4) different options for handling competing events in the case of 
    survival outcomes; 5) a random measurement/visit process; 6) joint 
    interventions on multiple treatments; and 7) general incorporation of a 
    priori knowledge of the data structure.",2020-03-23,Victoria Lin,"https://github.com/CausalInference/gfoRmula,
https://arxiv.org/abs/1908.07072",TRUE,https://github.com/causalinference/gformula,4675,25,2020-03-22T15:36:43Z,187
gg.gap,It is not very easy to define segments for y-axis in a 'ggplot2' plot. gg.gap() function in this package can carry it out.,2019-09-30,Jiacheng Lou,https://github.com/ChrisLou-bioinfo/gg.gap,TRUE,https://github.com/chrislou-bioinfo/gg.gap,3723,8,2019-10-06T09:26:22Z,465.375
ggallin,"Extra geoms and scales for 'ggplot2', including geom_cloud(),
  a Normal density cloud replacement for errorbars;
  transforms ssqrt_trans and pseudolog10_trans, which are loglike but 
  appropriate for negative data; interp_trans() and warp_trans() which
  provide scale transforms based on interpolation;
  and an infix compose operator for scale transforms.",2017-10-02,Steven E. Pav,https://github.com/shabbychef/ggallin,TRUE,https://github.com/shabbychef/ggallin,9880,4,2019-10-04T05:22:41Z,2470
ggalluvial,"Alluvial plots use variable-width ribbons and stacked bar plots to
    represent multi-dimensional or repeated-measures data with categorical or
    ordinal variables; see Riehmann, Hanfler, and Froehlich (2005)
    <doi:10.1109/INFVIS.2005.1532152> and Rosvall and Bergstrom (2010)
    <doi:10.1371/journal.pone.0008694>.
    Alluvial plots are statistical graphics in the sense of Wilkinson (2006)
    <doi:10.1007/0-387-28695-0>; they share elements with Sankey diagrams and
    parallel sets plots but are uniquely determined from the data and a small
    set of parameters. This package extends Wickham's (2010)
    <doi:10.1198/jcgs.2009.07098> layered grammar of graphics to generate
    alluvial plots from tidy data.",2020-04-16,Jason Cory Brunson,http://corybrunson.github.io/ggalluvial/,TRUE,https://github.com/corybrunson/ggalluvial,58607,229,2020-05-29T01:49:43Z,255.92576419213975
GGally,"
    The R package 'ggplot2' is a plotting system based on the grammar of graphics.
    'GGally' extends 'ggplot2' by adding several functions
    to reduce the complexity of combining geometric objects with transformed data.
    Some of these functions include a pairwise plot matrix, a two group pairwise plot
    matrix, a parallel coordinates plot, a survival plot, and several functions to
    plot networks.",2020-06-06,Barret Schloerke,"https://ggobi.github.io/ggally, https://github.com/ggobi/ggally",TRUE,https://github.com/ggobi/ggally,1995490,351,2020-06-08T14:45:47Z,5685.156695156696
ggalt,"A compendium of new geometries, coordinate systems, statistical 
    transformations, scales and fonts for 'ggplot2', including splines, 1d and 2d densities, 
    univariate average shifted histograms, a new map coordinate system based on the 
    'PROJ.4'-library along with geom_cartogram() that mimics the original functionality of 
    geom_map(), formatters for ""bytes"", a stat_stepribbon() function, increased 'plotly'
    compatibility and the 'StateFace' open source font 'ProPublica'. Further new 
    functionality includes lollipop charts, dumbbell charts, the ability to encircle
    points and coordinate-system-based text annotations.",2017-02-15,Bob Rudis,https://github.com/hrbrmstr/ggalt,TRUE,https://github.com/hrbrmstr/ggalt,112335,512,2019-07-30T10:46:36Z,219.404296875
ggamma,"Density, distribution function, quantile function and random generation for the Generalized Gamma proposed in Stacy, E. W. (1962) <doi:10.1214/aoms/1177704481>.",2019-12-15,Matheus H. J. Saldanha,https://mjsaldanha.com/posts/ggamma,TRUE,https://github.com/matheushjs/ggamma,2661,0,2019-12-15T08:24:18Z,NA
gganimate,"The grammar of graphics as implemented in the 'ggplot2' package has
    been successful in providing a powerful API for creating static 
    visualisation. In order to extend the API for animated graphics this package
    provides a completely new set of grammar, fully compatible with 'ggplot2' 
    for specifying transitions and animations in a flexible and extensible way.",2020-02-09,Thomas Lin Pedersen,"https://gganimate.com, https://github.com/thomasp85/gganimate",TRUE,https://github.com/thomasp85/gganimate,198098,1548,2020-05-13T18:37:47Z,127.9702842377261
ggbeeswarm,"Provides two methods of plotting categorical scatter plots such
    that the arrangement of points within a category reflects the density of
    data at that region, and avoids over-plotting.",2017-08-07,Erik Clarke,https://github.com/eclarke/ggbeeswarm,TRUE,https://github.com/eclarke/ggbeeswarm,183110,326,2019-08-14T20:39:38Z,561.6871165644171
ggcharts,"Streamline the creation of common charts by taking care of a lot of
    data preprocessing and plot customization for the user. Provides a
    high-level interface to create plots using 'ggplot2'.",2020-05-20,Thomas Neitmann,https://github.com/thomas-neitmann/ggcharts,TRUE,https://github.com/thomas-neitmann/ggcharts,2701,121,2020-06-01T17:30:02Z,22.322314049586776
ggcorrplot,"The 'ggcorrplot' package can be used to visualize easily a
    correlation matrix using 'ggplot2'. It provides a solution for reordering the
    correlation matrix and displays the significance level on the plot. It also
    includes a function for computing a matrix of correlation p-values.",2019-05-19,Alboukadel Kassambara,http://www.sthda.com/english/wiki/ggcorrplot,TRUE,https://github.com/kassambara/ggcorrplot,300513,119,2019-10-02T17:42:09Z,2525.3193277310925
ggdag,"Tidy, analyze, and plot directed acyclic graphs
    (DAGs). 'ggdag' is built on top of 'dagitty', an R package that uses
    the 'DAGitty' web tool (<http://dagitty.net>) for creating and
    analyzing DAGs. 'ggdag' makes it easy to tidy and plot 'dagitty'
    objects using 'ggplot2' and 'ggraph', as well as common analytic and
    graphical functions, such as determining adjustment sets and node
    relationships.",2020-02-13,Malcolm Barrett,https://github.com/malcolmbarrett/ggdag,TRUE,https://github.com/malcolmbarrett/ggdag,24217,280,2020-06-05T18:11:00Z,86.48928571428571
ggdemetra,"Provides 'ggplot2' functions to return the results of seasonal and trading day adjustment 
    made by 'RJDemetra'. 'RJDemetra' is an 'R' interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>),
    the seasonal adjustment software officially recommended to the members of the European Statistical System and
    the European System of Central Banks.",2019-09-12,Alain Quartier-la-Tente,https://github.com/AQLT/ggdemetra,TRUE,https://github.com/aqlt/ggdemetra,6436,9,2019-09-12T21:16:50Z,715.1111111111111
ggdmc,"Hierarchical Bayesian models. The package provides tools to fit two response time models, using the population-based Markov Chain Monte Carlo. ",2019-04-29,Yi-Shin Lin,https://github.com/yxlin/ggdmc,TRUE,https://github.com/yxlin/ggdmc,13619,4,2020-06-01T12:15:52Z,3404.75
gge,"Create biplots for GGE (genotype plus genotype-by-environment) and
    GGB (genotype plus genotype-by-block-of-environments) models.",2018-05-15,Kevin Wright,https://github.com/kwstat/gge,TRUE,https://github.com/kwstat/gge,23299,5,2020-01-20T15:31:51Z,4659.8
ggeasy,"Provides a series of aliases to commonly used but difficult 
    to remember 'ggplot2' sequences.",2020-03-19,Jonathan Carroll,https://github.com/jonocarroll/ggeasy,TRUE,https://github.com/jonocarroll/ggeasy,3318,156,2020-05-21T12:53:33Z,21.26923076923077
ggedit,Interactively edit 'ggplot2' layer and theme aesthetics definitions.,2020-06-02,Jonathan Sidi,https://github.com/yonicd/ggedit,TRUE,https://github.com/yonicd/ggedit,28629,207,2020-06-02T01:51:11Z,138.30434782608697
ggeffects,"Compute marginal effects from statistical models and returns the 
    result as tidy data frames. These data frames are ready to use with the 
    'ggplot2'-package. Marginal effects can be calculated for many different 
    models. Interaction terms, splines and polynomial terms are also supported. 
    The main functions are ggpredict(), ggemmeans() and ggeffect(). There is a 
    generic plot()-method to plot the results using 'ggplot2'.",2020-04-20,Daniel Lüdecke,https://strengejacke.github.io/ggeffects,TRUE,https://github.com/strengejacke/ggeffects,365148,264,2020-06-09T20:17:45Z,1383.1363636363637
ggetho,"Extension of 'ggplot2' providing layers, scales and preprocessing functions
    useful to represent behavioural variables that are recorded over multiple animals and days.
    This package is part of the 'rethomics' framework <http://rethomics.github.io/>.",2020-04-29,Quentin Geissmann,https://github.com/rethomics/ggetho,TRUE,https://github.com/rethomics/ggetho,11914,6,2020-06-09T01:42:23Z,1985.6666666666667
ggExtra,"Collection of functions and layers to enhance 'ggplot2'. The 
    flagship function is 'ggMarginal()', which can be used to add marginal
    histograms/boxplots/density plots to 'ggplot2' scatterplots.",2019-08-27,Dean Attali,https://github.com/daattali/ggExtra,TRUE,https://github.com/daattali/ggextra,242853,275,2020-06-09T04:14:23Z,883.1018181818182
ggfittext,"Provides 'ggplot2' geoms to fit text into a box by growing, shrinking
    or wrapping the text.",2019-07-18,David Wilkins,https://wilkox.org/ggfittext,TRUE,https://github.com/wilkox/ggfittext,111726,176,2020-05-28T10:30:51Z,634.8068181818181
ggfocus,"A 'ggplot2' extension that provides tools for automatically
    creating scales to focus on subgroups of the data plotted 
    without losing other information.",2020-01-23,Victor Freguglia,https://github.com/Freguglia/ggfocus,TRUE,https://github.com/freguglia/ggfocus,8050,13,2020-01-27T20:23:04Z,619.2307692307693
ggforce,"The aim of 'ggplot2' is to aid in visual data investigations. This
    focus has led to a lack of facilities for composing specialised plots.
    'ggforce' aims to be a collection of mainly new stats and geoms that fills
    this gap. All additional functionality is aimed to come through the official
    extension system so using 'ggforce' should be a stable experience.",2019-08-20,Thomas Lin Pedersen,https://ggforce.data-imaginist.com,TRUE,https://github.com/thomasp85/ggforce,867324,542,2020-01-06T10:08:01Z,1600.228782287823
ggformula,Provides a formula interface to 'ggplot2' graphics.,2020-03-04,Randall Pruim,https://github.com/ProjectMOSAIC/ggformula,TRUE,https://github.com/projectmosaic/ggformula,441587,29,2020-03-04T07:21:38Z,15227.137931034482
ggfortify,"Unified plotting tools for statistics commonly used, such as GLM,
    time series, PCA families, clustering and survival analysis. The package offers
    a single plotting interface for these analysis results and plots in a unified
    style using 'ggplot2'.",2020-04-26,Yuan Tang,https://github.com/sinhrks/ggfortify,TRUE,https://github.com/sinhrks/ggfortify,857992,433,2020-05-12T16:20:31Z,1981.5057736720555
gggenes,"Provides a 'ggplot2' geom and helper functions for drawing gene
  arrow maps.",2019-06-24,David Wilkins,https://wilkox.org/gggenes,TRUE,https://github.com/wilkox/gggenes,15751,160,2020-04-25T08:17:44Z,98.44375
gggibbous,"Moon charts are like pie charts except that the proportions are
    shown as crescent or gibbous portions of a circle, like the lit and unlit
    portions of the moon. As such, they work best with only one or two groups.
    'gggibbous' extends 'ggplot2' to allow for plotting multiple moon charts in
    a single panel and does not require a square coordinate system.",2019-12-02,Michael Bramson,https://github.com/mnbram/gggibbous,TRUE,https://github.com/mnbram/gggibbous,2058,42,2019-11-23T21:31:50Z,49
gghalves,"A 'ggplot2' extension for easy plotting of half-half geom combinations. Think half boxplot and half jitterplot, or half violinplot and half dotplot.",2020-03-28,Frederik Tiedemann,https://github.com/erocoar/gghalves,TRUE,https://github.com/erocoar/gghalves,4939,149,2020-03-28T12:12:37Z,33.147651006711406
gghighlight,Make it easier to explore data with highlights.,2020-03-29,Hiroaki Yutani,https://github.com/yutannihilation/gghighlight/,TRUE,https://github.com/yutannihilation/gghighlight,41805,393,2020-06-06T13:33:39Z,106.37404580152672
ggimage,"Supports image files and graphic objects to be visualized in
    'ggplot2' graphic system.",2020-04-02,Guangchuang Yu,"https://github.com/GuangchuangYu/ggimage (devel),
https://guangchuangyu.github.io/pkgdocs/ggimage.html (vignette)",TRUE,https://github.com/guangchuangyu/ggimage,73156,102,2020-04-20T07:27:31Z,717.2156862745098
ggimg,"Provides two new layer types for displaying image data as layers
  within the Grammar of Graphics framework. Displays images using either a
  rectangle interface, with a fixed bounding box, or a point interface using a
  central point and general size parameter. Images can be given as local
  JPEG or PNG files, external resources, or as a list column containing
  raster image data.",2020-03-20,Taylor B. Arnold,https://github.com/statsmaths/ggimg,TRUE,https://github.com/statsmaths/ggimg,1386,25,2020-03-23T14:17:40Z,55.44
gginference,"Visualise the results of F test to compare two variances, Student's t-test, test of equal or given proportions, Pearson's chi-squared test for count data and test for association/correlation between paired samples.",2020-03-21,Kleanthis Koupidis,https://github.com/okgreece/gginference,TRUE,https://github.com/okgreece/gginference,8165,5,2020-04-30T22:49:47Z,1633
GGIR,"A tool to process and analyse data collected with wearable raw acceleration sensors as described in Migueles and colleagues (2019) <doi: 10.1123/jmpb.2018-0063>, van Hees and colleagues (2014) <doi: 10.1152/japplphysiol.00421.2014>, and (2015) <doi: 10.1371/journal.pone.0142533>. The package has been developed and tested for binary data from 'GENEActiv' <https://www.activinsights.com/> and GENEA devices (not for sale), .csv-export data from  'Actigraph' <http://actigraphcorp.com> devices, and .cwa and .wav-format data from 'Axivity' <https://axivity.com>. These devices are currently widely used in research on human daily physical activity. Further, the package can handle accelerometer data file from any other sensor brand providing that the data is stored in csv format and has either no header or a two column header. Also the package allows for external function embedding.",2020-05-01,Vincent T van Hees,"https://github.com/wadpac/GGIR/,
https://groups.google.com/forum/#!forum/RpackageGGIR",TRUE,https://github.com/wadpac/ggir,79870,31,2020-06-04T17:21:19Z,2576.451612903226
ggiraph,Create interactive 'ggplot2' graphics using 'htmlwidgets'.,2019-10-31,David Gohel,https://davidgohel.github.io/ggiraph,TRUE,https://github.com/davidgohel/ggiraph,158050,400,2020-04-09T09:53:54Z,395.125
gglasso,"A unified algorithm, blockwise-majorization-descent (BMD), for efficiently computing the solution paths of the group-lasso penalized least squares, logistic regression, Huberized SVM and squared SVM. The package is an implementation of Yang, Y. and Zou, H. (2015) DOI: <doi:10.1007/s11222-014-9498-5>.",2020-03-18,Yi Yang,https://github.com/emeryyi/gglasso,TRUE,https://github.com/emeryyi/gglasso,39181,1,2020-02-17T18:56:58Z,39181
gglogo,"Visualize sequences in (modified) logo plots. The design choices
    used by these logo plots allow sequencing data to be more easily analyzed.
    Because it is integrated into the 'ggplot2' geom framework, these logo plots
    support native features such as faceting.",2020-01-28,Eric Hare,https://github.com/heike/gglogo,TRUE,https://github.com/heike/gglogo,13671,14,2020-01-28T20:41:46Z,976.5
gglorenz,"Provides statistical transformations for plotting empirical 
    ordinary Lorenz curve (Lorenz 1905) <doi:10.2307/2276207> and 
    generalized Lorenz curve (Shorrocks 1983) <doi:10.2307/2554117>.",2020-05-27,JJ Chen,https://github.com/jjchern/gglorenz,TRUE,https://github.com/jjchern/gglorenz,8782,12,2020-05-31T21:33:05Z,731.8333333333334
ggmap,"A collection of functions to visualize spatial data and models
    on top of static maps from various online sources (e.g Google Maps and Stamen
    Maps). It includes tools common to those tasks, including functions for
    geolocation and routing.",2019-02-05,David Kahle,https://github.com/dkahle/ggmap,TRUE,https://github.com/dkahle/ggmap,2143211,594,2020-05-26T03:26:15Z,3608.0993265993266
ggmcmc,"Tools for assessing and diagnosing convergence of
    Markov Chain Monte Carlo simulations, as well as for graphically display
    results from full MCMC analysis. The package also facilitates the graphical
    interpretation of models by providing flexible functions to plot the
    results against observed variables.",2020-04-02,Xavier Fernández i Marín,"http://xavier-fim.net/packages/ggmcmc,
https://github.com/xfim/ggmcmc",TRUE,https://github.com/xfim/ggmcmc,78004,92,2020-04-22T04:50:07Z,847.8695652173913
ggmix,"Fit penalized multivariable linear mixed models with a single 
    random effect to control for population structure in genetic association 
    studies. The goal is to simultaneously fit many genetic variants at the 
    same time, in order to select markers that are independently associated 
    with the response. Can also handle prior annotation information, 
    for example, rare variants, in the form of variable weights. For more 
    information, see the website below and the accompanying paper: 
    Bhatnagar et al., ""Simultaneous SNP selection and adjustment for 
    population structure in high dimensional prediction models"", 2020, 
    <DOI:10.1101/408484>.",2020-03-20,Sahir Bhatnagar,https://github.com/sahirbhatnagar/ggmix,TRUE,https://github.com/sahirbhatnagar/ggmix,1147,6,2020-05-14T15:59:28Z,191.16666666666666
ggmosaic,"Mosaic plots in the 'ggplot2' framework. Mosaic
    plot functionality is provided in a single 'ggplot2' layer by calling
    the geom 'mosaic'.",2018-09-12,Haley Jeppson,http://github.com/haleyjeppson/ggmosaic,TRUE,https://github.com/haleyjeppson/ggmosaic,93876,102,2020-05-06T15:04:17Z,920.3529411764706
ggnetwork,Geometries to plot network objects with 'ggplot2'.,2020-02-12,François Briatte,https://github.com/briatte/ggnetwork,TRUE,https://github.com/briatte/ggnetwork,56818,95,2020-02-12T15:54:09Z,598.0842105263158
ggnuplot,"Provides a theme, a discrete color palette, and continuous scales
    to make 'ggplot2' look like 'gnuplot'. This may be helpful if you use both
    'ggplot2' and 'gnuplot' in one project.",2020-06-04,Hannes Riebl,https://github.com/hriebl/ggnuplot,TRUE,https://github.com/hriebl/ggnuplot,0,0,2020-06-01T14:48:58Z,NA
ggpacman,"A funny coding challenge to reproduce the game Pac-Man using 'ggplot2' and 'gganimate'.
    It provides a pre-defined moves set for Pac-Man and the ghosts for the first level of the
    game Pac-Man as well as polygon datasets to draw ghosts in 'ggplot2'.",2020-05-16,Mickaël Canouil,https://github.com/mcanouil/pacman,TRUE,https://github.com/mcanouil/pacman,356,40,2020-05-12T10:30:44Z,8.9
ggpage,"Facilitates the creation of page layout
    visualizations in which words are represented as rectangles with sizes
    relating to the length of the words. Which then is divided in lines
    and pages for easy overview of up to quite large texts.",2019-06-13,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/ggpage,TRUE,https://github.com/emilhvitfeldt/ggpage,8082,296,2019-06-13T23:41:07Z,27.304054054054053
ggparty,Extends 'ggplot2' functionality to the 'partykit' package. 'ggparty' provides the necessary tools to create clearly structured and highly customizable visualizations for tree-objects of the class 'party'.,2019-07-18,Martin Borkovec,https://github.com/martin-borkovec/ggparty,TRUE,https://github.com/martin-borkovec/ggparty,5416,109,2019-07-15T15:02:29Z,49.68807339449541
ggplot.multistats,"
    Provides the ggplot binning layer stat_summaries_hex(),
    which functions similar to its singular form,
    but allows the use of multiple statistics per bin.
    Those statistics can be mapped to multiple bin aesthetics.",2019-10-28,Philipp Angerer,https://github.com/flying-sheep/ggplot.multistats,TRUE,https://github.com/flying-sheep/ggplot.multistats,19496,8,2019-12-07T11:02:11Z,2437
ggplot2,"A system for 'declaratively' creating graphics,
    based on ""The Grammar of Graphics"". You provide the data, tell 'ggplot2'
    how to map variables to aesthetics, what graphical primitives to use,
    and it takes care of the details.",2020-05-28,Hadley Wickham,"http://ggplot2.tidyverse.org, https://github.com/tidyverse/ggplot2",TRUE,https://github.com/tidyverse/ggplot2,32768488,4465,2020-06-09T11:35:16Z,7338.967077267637
ggplotgui,Easily explore data by creating ggplots through a (shiny-)GUI. R-code to recreate graph provided.   ,2017-07-08,Gert Stulp,https://github.com/gertstulp/ggplotgui/,TRUE,https://github.com/gertstulp/ggplotgui,31486,105,2020-05-06T12:24:24Z,299.8666666666667
ggplotify,"Convert plot function call (using expression or formula) to 'grob' or 'ggplot' object that compatible to the 'grid' and 'ggplot2' ecosystem. With this package, we are able to e.g. using 'cowplot' to align plots produced by 'base' graphics, 'ComplexHeatmap', 'eulerr', 'grid', 'lattice', 'magick', 'pheatmap', 'vcd' etc. by converting them to 'ggplot' objects.",2020-03-12,Guangchuang Yu,https://github.com/GuangchuangYu/ggplotify,TRUE,https://github.com/guangchuangyu/ggplotify,198953,54,2020-03-27T08:47:33Z,3684.314814814815
ggPMX,"At Novartis, we aimed at standardizing the set of diagnostic plots used for modeling 
  activities in order to reduce the overall effort required for generating such plots. 
  For this, we developed a guidance that proposes an adequate set of diagnostics and a toolbox, 
  called 'ggPMX' to execute them. 'ggPMX' is a toolbox that can generate all diagnostic plots at a quality sufficient 
  for publication and submissions using few lines of code. ",2020-05-14,Amine Gassem,https://github.com/ggPMXdevelopment/ggPMX,TRUE,https://github.com/ggpmxdevelopment/ggpmx,6860,17,2020-06-05T02:43:32Z,403.52941176470586
ggpointdensity,"A cross between a 2D density plot and a scatter plot,
    implemented as a 'ggplot2' geom. Points in the scatter plot are 
    colored by the number of neighboring points. This is useful to
    visualize the 2D-distribution of points in case of overplotting.",2019-08-28,Lukas P. M. Kremer,https://github.com/LKremer/ggpointdensity,TRUE,https://github.com/lkremer/ggpointdensity,6148,255,2020-02-21T11:01:51Z,24.109803921568627
ggpol,A 'ggplot2' extension for implementing parliament charts and several other useful visualizations. ,2020-03-28,Frederik Tiedemann,https://github.com/erocoar/ggpol,TRUE,https://github.com/erocoar/ggpol,22838,62,2020-03-28T13:16:12Z,368.35483870967744
ggpubr,"The 'ggplot2' package is excellent and flexible for elegant data
    visualization in R. However the default generated plots requires some formatting
    before we can send them for publication. Furthermore, to customize a 'ggplot',
    the syntax is opaque and this raises the level of difficulty for researchers
    with no advanced R programming skills. 'ggpubr' provides some easy-to-use
    functions for creating and customizing 'ggplot2'- based publication ready plots.",2020-05-04,Alboukadel Kassambara,https://rpkgs.datanovia.com/ggpubr/,TRUE,https://github.com/kassambara/ggpubr,3097124,593,2020-06-09T18:37:03Z,5222.8060708263065
ggpval,"Automatically performs desired statistical tests (e.g. wilcox.test(), t.test()) to compare between groups, 
    and adds the resulting p-values to the plot with an annotation bar.
    Visualizing group differences are frequently performed by boxplots, bar plots, etc.
    Statistical test results are often needed to be annotated on these plots. 
    This package provides a convenient function that works on 'ggplot2' objects, 
    performs the desired statistical test between groups of interest and annotates the test results on the plot.",2019-09-10,Jun Cheng,https://github.com/s6juncheng/ggpval,TRUE,https://github.com/s6juncheng/ggpval,14689,24,2019-09-10T18:39:06Z,612.0416666666666
ggquickeda,"Quickly and easily perform exploratory data analysis by uploading your
     data as a 'csv' file. Start generating insights using 'ggplot2' plots and
     'table1' tables with descriptive stats, all using an easy-to-use point and click 
     'Shiny' interface.",2020-04-17,Samer Mouksassi,https://github.com/smouksassi/ggquickeda,TRUE,https://github.com/smouksassi/ggquickeda,12155,33,2020-06-08T21:46:59Z,368.3333333333333
ggRandomForests,"Graphic elements for exploring Random Forests using the 'randomForest' or
    'randomForestSRC' package for survival, regression and classification forests and
    'ggplot2' package plotting.",2016-09-07,John Ehrlinger,https://github.com/ehrlinger/ggRandomForests,TRUE,https://github.com/ehrlinger/ggrandomforests,47811,117,2020-04-27T01:03:41Z,408.64102564102564
ggraph,"The grammar of graphics as implemented in ggplot2 is a poor fit for
    graph and network visualizations due to its reliance on tabular data input.
    ggraph is an extension of the ggplot2 API tailored to graph visualizations
    and provides the same flexible approach to building up plots layer by layer.",2020-05-20,Thomas Lin Pedersen,"https://ggraph.data-imaginist.com,
https://github.com/thomasp85/ggraph",TRUE,https://github.com/thomasp85/ggraph,659712,727,2020-05-20T19:07:27Z,907.4442916093535
ggraptR,"Intended for both technical and non-technical users to create
    interactive data visualizations through a web browser GUI without writing any
    code.",2019-09-04,Eugene Dubossarsky,NA,TRUE,https://github.com/cargomoose/raptr,48925,61,2020-05-01T20:35:45Z,802.0491803278688
ggrepel,"Provides text and label geoms for 'ggplot2' that help to avoid
    overlapping text labels. Labels repel away from each other and away from the
    data points.",2020-03-08,Kamil Slowikowski,http://github.com/slowkow/ggrepel,TRUE,https://github.com/slowkow/ggrepel,4328914,743,2020-04-07T17:03:26Z,5826.263795423957
ggridges,Ridgeline plots provide a convenient way of visualizing changes in distributions over time or space. This package enables the creation of such plots in 'ggplot2'.,2020-01-12,Claus O. Wilke,https://wilkelab.org/ggridges,TRUE,https://github.com/wilkelab/ggridges,903726,303,2020-01-12T06:17:51Z,2982.5940594059407
ggrisk,"The risk plot may be one of the most commonly used figures in 
    tumor genetic data analysis. We can conclude the following two points: 
    Comparing the prediction results of the model with the real survival situation 
    to see whether the survival rate of the high-risk group is lower than that of the 
    low-level group, and whether the survival time of the high-risk group is 
    shorter than that of the low-risk group. The other is to compare the heat 
    map and scatter plot to see the correlation between the predictors and the 
    outcome.",2020-02-09,Jing Zhang,https://github.com/yikeshu0611/ggrisk,TRUE,https://github.com/yikeshu0611/ggrisk,2003,1,2020-02-11T14:13:49Z,2003
ggroups,"Calculates additive and dominance genetic relationship matrices and their inverses, in matrix and tabular-sparse formats. It includes functions for checking and processing pedigree, as well as functions to calculate the matrix of genetic group contributions (Q), and adding those contributions to the genetic merit of animals (Quaas (1988) <doi:10.3168/jds.S0022-0302(88)79691-5>). Calculation of Q is computationally extensive. There are computationally optimized functions to calculate Q.",2020-03-19,Mohammad Ali Nilforooshan,https://github.com/nilforooshan/ggroups,TRUE,https://github.com/nilforooshan/ggroups,6371,0,2020-03-19T06:45:40Z,NA
ggsci,"A collection of 'ggplot2' color palettes inspired by
    plots in scientific journals, data visualization libraries,
    science fiction movies, and TV shows.",2018-05-14,Nan Xiao,"https://nanx.me/ggsci/, https://github.com/road2stat/ggsci",TRUE,https://github.com/road2stat/ggsci,2255906,335,2020-04-23T15:30:54Z,6734.04776119403
ggsignif,"Enrich your 'ggplots' with group-wise comparisons.
  This package provides an easy way to indicate if two groups are significantly different.
  Commonly this is shown by a bracket on top connecting the groups of interest which itself is annotated with the level of significance (NS, *, **, ***).
  The package provides a single layer (geom_signif()) that takes the groups for comparison and the test (t.test(), wilcox.text() etc.) as arguments and adds the annotation
  to the plot.",2019-08-08,Constantin Ahlmann-Eltze,https://github.com/const-ae/ggsignif,TRUE,https://github.com/const-ae/ggsignif,2266810,232,2020-05-10T12:49:01Z,9770.73275862069
ggsn,"Adds north symbols (18 options) and scale bars in kilometers,
    meters, nautical miles, or statue miles, to maps in geographic
    or metric coordinates created with 'ggplot2' or 'ggmap'.",2019-02-18,Oswaldo Santos Baquero,https://github.com/oswaldosantos/ggsn,TRUE,https://github.com/oswaldosantos/ggsn,55885,137,2019-08-29T13:54:12Z,407.91970802919707
ggsoccer,"The 'ggplot2' package provides a powerful set of tools 
  for visualising and investigating data. The 'ggsoccer' package provides a 
  set of functions for elegantly displaying and exploring soccer event data
  with 'ggplot2'. Providing extensible layers and themes, it is designed to
  work smoothly with a variety of popular sports data providers.",2019-05-14,Ben Torvaney,"ggsoccer.statsandsnakeoil.com, github.com/Torvaney/ggsoccer",TRUE,https://github.com/torvaney/ggsoccer,10950,92,2020-04-12T11:45:39Z,119.02173913043478
ggsom,The aim of this package is to offer more variability of graphics based on the self-organizing maps.,2020-01-15,Felipe Carvalho,https://github.com/oldlipe/ggsom,TRUE,https://github.com/oldlipe/ggsom,8111,4,2020-01-15T16:24:11Z,2027.75
ggspatial,"Spatial data plus the power of the ggplot2 framework means easier mapping when input 
  data are already in the form of spatial objects.",2020-06-09,Dewey Dunnington,"https://paleolimbot.github.io/ggspatial,
https://github.com/paleolimbot/ggspatial",TRUE,https://github.com/paleolimbot/ggspatial,68663,233,2020-06-05T19:17:52Z,294.6909871244635
ggstar,"To create the regular polygon layer for easily discernible shapes, 
             we developed the package, it can be easily used if you know the 'ggplot2'.",2020-05-15,Shuangbin Xu,https://github.com/xiangpin/ggstar/,TRUE,https://github.com/xiangpin/ggstar,1626,8,2020-06-09T07:34:36Z,203.25
ggstatsplot,"Extension of 'ggplot2', 'ggstatsplot' creates
    graphics with details from statistical tests included in the plots
    themselves. It is targeted primarily at behavioral sciences community
    to provide a one-line code to generate information-rich plots for
    statistical analysis of continuous (violin plots, scatterplots,
    histograms, dot plots, dot-and-whisker plots) or categorical (pie and
    bar charts) data. Currently, it supports only the most common types of
    statistical tests: parametric, nonparametric, robust, and bayesian
    versions of t-test/anova, correlation analyses, contingency table
    analysis, meta-analysis, and regression analyses.",2020-05-30,Indrajeet Patil,"https://indrajeetpatil.github.io/ggstatsplot/,
https://github.com/IndrajeetPatil/ggstatsplot",TRUE,https://github.com/indrajeetpatil/ggstatsplot,60399,869,2020-06-09T12:42:32Z,69.50402761795166
ggswissmaps,"Offers various swiss maps as data frames and 'ggplot2' objects and gives the
    possibility to add layers of data on the maps. Data are publicly available
    from the swiss federal statistical office.",2016-10-29,Sandro Petrillo Burri,https://github.com/gibonet/ggswissmaps,TRUE,https://github.com/gibonet/ggswissmaps,19274,4,2020-01-29T16:11:20Z,4818.5
ggtext,"A 'ggplot2' extension that enables the rendering of
    complex formatted plot labels (titles, subtitles, facet labels,
    axis labels, etc.). Text boxes with automatic word wrap are also
    supported.",2020-06-04,Claus O. Wilke,https://wilkelab.org/ggtext,TRUE,https://github.com/wilkelab/ggtext,0,376,2020-06-04T15:16:00Z,0
ggThemeAssist,Rstudio add-in that delivers a graphical interface for editing 'ggplot2' theme elements.,2016-08-13,Calli Gross,https://github.com/calligross/ggthemeassist,TRUE,https://github.com/calligross/ggthemeassist,56648,333,2019-06-15T06:26:12Z,170.1141141141141
ggTimeSeries,"Provides additional display mediums for time series visualisations, such as calendar heat map, steamgraph, marimekko, etc.",2018-09-03,Aditya Kothari,https://github.com/Ather-Energy/ggTimeSeries,TRUE,https://github.com/ather-energy/ggtimeseries,14616,195,2019-06-21T05:57:32Z,74.95384615384616
GGUM,"An implementation of the generalized graded unfolding model (GGUM) in R, see Roberts, Donoghue, and Laughlin (2000) <doi:10.1177/01466216000241001>). It allows to simulate data sets based on the GGUM. It fits the GGUM and the GUM, and it retrieves item and person parameter estimates. Several plotting functions are available (item and test information functions; item and test characteristic curves; item category response curves). Additionally, there are some functions that facilitate the communication between R and 'GGUM2004'. Finally, a model-fit checking utility, MODFIT(), is also available.",2020-05-18,Jorge N. Tendeiro,http://github.com/jorgetendeiro/GGUM,TRUE,https://github.com/jorgetendeiro/ggum,11390,1,2020-05-18T16:13:03Z,11390
ggupset,"Replace the standard x-axis in 'ggplots' with a combination matrix
  to visualize complex set overlaps. 'UpSet' has introduced a new way to visualize
  the overlap of sets as an alternative to Venn diagrams. 
  This package provides a simple way to produce such plots using 'ggplot2'. 
  In addition it can convert any categorical axis into a combination
  matrix axis.",2020-05-05,Constantin Ahlmann-Eltze,https://github.com/const-ae/ggupset,TRUE,https://github.com/const-ae/ggupset,9314,141,2020-05-08T16:31:16Z,66.05673758865248
ggVennDiagram,"Easy-to-use functions to generate 2-4 sets Venn plot in publication quality. 
  'ggVennDiagram' is the first software that can automatically fill different colors to each part of a Venn diagram.",2019-10-09,Chun-Hui Gao,https://github.com/gaospecial/ggVennDiagram,TRUE,https://github.com/gaospecial/ggvenndiagram,5018,65,2019-12-25T08:36:31Z,77.2
ggwordcloud,"Provides a word cloud text geom for 'ggplot2'. Texts
    are placed so that they do not overlap as in 'ggrepel'.  The algorithm
    used is a variation around the one of 'wordcloud2.js'.",2019-06-02,Erwan Le Pennec,"https://github.com/lepennec/ggwordcloud,
https://lepennec.github.io/ggwordcloud/",TRUE,https://github.com/lepennec/ggwordcloud,22002,126,2020-03-03T08:45:18Z,174.61904761904762
Ghat,"Functions are provided for quantifying evolution and selection on complex traits. 
              The package implements effective handling and analysis algorithms scaled for 
              genome-wide data and calculates a composite statistic, denoted Ghat, which is used 
              to test for selection on a trait. The package provides a number of simple examples 
              for handling and analysing the genome data and visualising the output and results. 
              Beissinger et al., (2018) <doi:10.1534/genetics.118.300857>.",2019-08-02,Medhat Mahmoud,https://www.genetics.org/content/209/1/321,TRUE,https://github.com/medhat86/ghat,3473,0,2019-07-18T07:14:45Z,NA
ghibli,"Colour palettes inspired by Studio Ghibli <https://en.wikipedia.org/wiki/Studio_Ghibli> 
    films, ported to R for your enjoyment.",2020-04-16,Ewen Henderson,"https://ewenme.github.io/ghibli/, https://github.com/ewenme/ghibli",TRUE,https://github.com/ewenme/ghibli,12669,188,2020-04-16T11:56:45Z,67.38829787234043
ghql,"A 'GraphQL' client, with an R6 interface for initializing
    a connection to a 'GraphQL' instance, and methods for constructing
    queries, including fragments and parameterized queries. Queries
    are checked with the 'libgraphqlparser' C++ parser via the
    'gaphql' package.",2020-03-04,Scott Chamberlain,"https://github.com/ropensci/ghql (devel)
https://docs.ropensci.org/ghql (docs)",TRUE,https://github.com/ropensci/ghql,1870,66,2020-03-04T18:21:28Z,28.333333333333332
gibble,"Build a map of path-based geometry, this is a simple description of the number
 of parts in an object and their basic structure. Translation and restructuring operations for 
 planar shapes and other hierarchical types require a data model with a record of the underlying
 relationships between elements. The gibble() function creates a geometry map, a simple record of 
 the underlying structure in path-based hierarchical types. There are methods for the planar shape 
 types in the 'sf' and 'sp' packages and for types in the 'trip' and 'silicate' packages. ",2020-05-09,Michael Sumner,https://github.com/mdsumner/gibble,TRUE,https://github.com/mdsumner/gibble,18295,5,2020-05-18T13:09:32Z,3659
gifski,"Multi-threaded GIF encoder written in Rust: <https://gif.ski/>. 
    Converts images to GIF animations using pngquant's efficient cross-frame 
    palettes and temporal dithering with thousands of colors per frame.",2018-09-28,Jeroen Ooms,"https://gif.ski/ (upstream), https://github.com/r-rust/gifski
(devel)",TRUE,https://github.com/r-rust/gifski,321963,41,2019-10-05T11:38:08Z,7852.756097560976
gifti,"Functions to read in the geometry format under the 
    'Neuroimaging' 'Informatics' Technology Initiative ('NIfTI'), called 
    'GIFTI' <https://www.nitrc.org/projects/gifti/>. 
    These files contain surfaces of brain imaging data.",2018-02-01,John Muschelli,NA,TRUE,https://github.com/muschellij2/gifti,13234,3,2020-05-08T15:44:51Z,4411.333333333333
GIFTr,"A framework and functions to create 'MOODLE' quizzes. 'GIFTr' takes dataframe of questions of
    four types: multiple choices, numerical, true or false and short answer questions, and exports a text 
    file formatted in 'MOODLE' GIFT format. You can prepare a spreadsheet in any software and import 
    it into R to generate any number of questions with 'HTML', 'markdown' and 'LaTeX' support.",2019-10-20,Omar I. Elashkar,https://github.com/omarelashkar/GIFTr,TRUE,https://github.com/omarelashkar/giftr,2791,1,2019-10-21T16:46:53Z,2791
GillespieSSA2,"A fast, scalable, and versatile framework for simulating large 
  systems with Gillespie's Stochastic Simulation Algorithm ('SSA'). 
  This package is the spiritual successor to the 'GillespieSSA' package 
  originally written by Mario Pineda-Krch. Benefits of this package
  include major speed improvements (>100x), easier to understand documentation,
  and many unit tests that try to ensure the package works as intended.",2020-03-14,Robrecht Cannoodt,http://github.com/rcannood/GillespieSSA2,TRUE,https://github.com/rcannood/gillespiessa2,4357,4,2020-03-16T09:33:26Z,1089.25
gim,"Implements the generalized integration model, which integrates individual-level data and summary statistics under a generalized linear model framework. It supports continuous and binary outcomes to be modeled by the linear and logistic regression models. For binary outcome, data can be sampled in prospective cohort studies or case-control studies. ",2019-11-04,Han Zhang,https://github.com/zhangh12/gim,TRUE,https://github.com/zhangh12/gim,8771,0,2020-05-20T06:04:57Z,NA
gimme,"Automated identification and estimation of group- and
    individual-level relations in time series data from within a structural
    equation modeling framework.",2020-02-15,Kathleen Gates,https://github.com/GatesLab/gimme/,TRUE,https://github.com/gateslab/gimme,40077,10,2020-05-19T22:23:04Z,4007.7
gimms,"This is a set of functions to retrieve information about GIMMS
    NDVI3g files currently available online; download (and re-arrange, in the 
    case of NDVI3g.v0) the half-monthly data sets from NASA Ames Ecological 
    Forecasting Lab (ECOCAST); import downloaded files from ENVI binary 
    (NDVI3g.v0) or NetCDF format (NDVI3g.v1) directly into R based on the 
    widespread 'raster' package; conduct quality control; and generate monthly 
    composites (e.g., maximum values) from the half-monthly input data. As a 
    special gimmick, a method is included to conveniently apply the Mann-Kendall 
    trend test upon 'Raster*' images, optionally featuring trend-free 
    pre-whitening to account for lag-1 autocorrelation.",2020-03-19,Florian Detsch,https://github.com/environmentalinformatics-marburg/gimms,TRUE,https://github.com/environmentalinformatics-marburg/gimms,24061,13,2020-03-19T13:15:32Z,1850.8461538461538
gistr,"Work with 'GitHub' 'gists' from 'R' (e.g., 
    <http://en.wikipedia.org/wiki/GitHub#Gist>, 
    <https://help.github.com/articles/about-gists/>). A 'gist'
    is simply one or more files with code/text/images/etc. This package allows
    the user to create new 'gists', update 'gists' with new files, rename files,
    delete files, get and delete 'gists', star and 'un-star' 'gists', fork 'gists',
    open a 'gist' in your default browser, get embed code for a 'gist', list
    'gist' 'commits', and get rate limit information when 'authenticated'. Some
    requests require authentication and some do not. 'Gists' website: 
    <https://gist.github.com/>.",2020-01-09,Scott Chamberlain,"https://github.com/ropensci/gistr (devel),
https://docs.ropensci.org/gistr (website)",TRUE,https://github.com/ropensci/gistr,135580,90,2020-02-11T00:16:55Z,1506.4444444444443
git2r,"Interface to the 'libgit2' library, which is a pure C
    implementation of the 'Git' core methods. Provides access to 'Git'
    repositories to extract data and running some basic 'Git'
    commands.",2020-05-03,See AUTHORS file.,"https://docs.ropensci.org/git2r (website),
https://github.com/ropensci/git2r",TRUE,https://github.com/ropensci/git2r,7971170,163,2020-05-08T15:05:51Z,48902.88343558282
git2rdata,Make versioning of data.frame easy and efficient using git repositories.,2020-03-02,Thierry Onkelinx,"https://github.com/ropensci/git2rdata,
https://doi.org/10.5281/zenodo.1485309",TRUE,https://github.com/ropensci/git2rdata,5001,78,2020-03-02T12:25:56Z,64.11538461538461
gitgadget,"An Rstudio addin for version control that allows users to clone
    repositories, create and delete branches, and sync forks on GitHub, GitLab, etc.
    Furthermore, the addin uses the GitLab API to allow instructors to create
    forks and merge requests for all students/teams with one click of a button.",2019-10-10,Vincent Nijs,URL: https://github.com/vnijs/gitgadget,TRUE,https://github.com/vnijs/gitgadget,14171,15,2020-05-17T22:16:31Z,944.7333333333333
gitignore,"Simple interface to query gitignore.io to fetch
    gitignore templates that can be included in the .gitignore file. More
    than 450 templates are currently available.",2019-07-29,Philippe Massicotte,https://github.com/ropensci/gitignore,TRUE,https://github.com/ropensci/gitignore,4545,29,2020-04-12T22:04:47Z,156.72413793103448
gitlink,"Provides helpers to add 'Git' links to 'shiny'
    applications, 'rmarkdown' documents, and other 'HTML' based resources.
    This is most commonly used for 'GitHub' ribbons.",2019-07-23,Cole Arendt,https://github.com/colearendt/gitlink,TRUE,https://github.com/colearendt/gitlink,3984,14,2019-11-28T05:32:55Z,284.57142857142856
glcm,"Enables calculation of image textures (Haralick 1973) 
    <doi:10.1109/TSMC.1973.4309314> from grey-level co-occurrence matrices 
    (GLCMs). Supports processing images that cannot fit in memory.",2020-02-26,Alex Zvoleff,http://www.azvoleff.com/glcm,TRUE,https://github.com/azvoleff/glcm,23494,11,2020-02-26T21:44:22Z,2135.818181818182
gllvm,"Analysis of multivariate data using generalized linear latent variable models (gllvm). 
      Estimation is performed using either Laplace approximation method or variational approximation method implemented via TMB (Kristensen et al., (2016), <doi:10.18637/jss.v070.i05>). 
      For details see Niku et al. (2019a) <doi:10.1371/journal.pone.0216129> and Niku et al. (2019b) <doi:10.1111/2041-210X.13303>.",2020-05-11,Jenni Niku,https://github.com/JenniNiku/gllvm.git,TRUE,https://github.com/jenniniku/gllvm,13901,16,2020-05-27T15:45:45Z,868.8125
glmbb,"Find all hierarchical models of specified generalized linear
    model with information criterion (AIC, BIC, or AICc) within specified
    cutoff of minimum value.  Alternatively, find all such graphical models.
    Use branch and bound algorithm so we do not have to fit all models.",2017-06-02,Charles J. Geyer <charlie@stat.umn.edu>.,https://github.com/cjgeyer/glmbb,TRUE,https://github.com/cjgeyer/glmbb,15856,0,2020-05-28T19:44:36Z,NA
glmdisc,"A Stochastic-Expectation-Maximization (SEM) algorithm (Celeux et al. (1995) <https://hal.inria.fr/inria-00074164>) associated with a Gibbs sampler which purpose is to learn a constrained representation for logistic regression that is called quantization (Ehrhardt et al. (2019) <arXiv:1903.08920>). Continuous features are discretized and categorical features' values are grouped to produce a better logistic regression model. Pairwise interactions between quantized features are dynamically added to the model through a Metropolis-Hastings algorithm (Hastings, W. K. (1970) <doi:10.1093/biomet/57.1.97>).",2020-03-22,Adrien Ehrhardt,https://adimajo.github.io,TRUE,https://github.com/adimajo/glmdisc,6237,3,2020-04-14T15:43:43Z,2079
GLMMadaptive,"Fits generalized linear mixed models for a single grouping factor under
    maximum likelihood approximating the integrals over the random effects with an 
    adaptive Gaussian quadrature rule; Jose C. Pinheiro and Douglas M. Bates (1995) 
    <doi:10.1080/10618600.1995.10474663>.  ",2020-01-24,Dimitris Rizopoulos,"https://drizopoulos.github.io/GLMMadaptive/,
https://github.com/drizopoulos/GLMMadaptive",TRUE,https://github.com/drizopoulos/glmmadaptive,31810,28,2020-02-02T20:30:21Z,1136.0714285714287
glmmboot,"Performs bootstrap resampling for most models that update() works for. There
    are two primary functions: bootstrap_model() performs block resampling if random effects
    are present, and case resampling if not; bootstrap_ci() converts output from
    bootstrap model runs into confidence intervals and p-values. By default,
    bootstrap_model() calls bootstrap_ci().
    Package motivated by Humphrey and Swingley (2018) <arXiv:1805.08670>.",2020-03-30,Colman Humphrey,https://github.com/ColmanHumphrey/glmmboot,TRUE,https://github.com/colmanhumphrey/glmmboot,12080,3,2020-03-29T19:22:08Z,4026.6666666666665
glmmfields,"Implements Bayesian spatial and spatiotemporal models that
    optionally allow for extreme spatial deviations through time. 'glmmfields'
    uses a predictive process approach with random fields implemented through
    a multivariate-t distribution instead of the usual multivariate normal.
    Sampling is conducted with 'Stan'. References: Anderson and Ward (2019)
    <doi:10.1002/ecy.2403>.",2019-05-18,Sean C. Anderson,https://github.com/seananderson/glmmfields,TRUE,https://github.com/seananderson/glmmfields,9609,24,2020-05-28T05:54:30Z,400.375
glmmsr,"Conduct inference about generalized linear mixed models, with a
    choice about which method to use to approximate the likelihood. In addition
    to the Laplace and adaptive Gaussian quadrature approximations, which are
    borrowed from 'lme4', the likelihood may be approximated by the sequential
    reduction approximation, or an importance sampling approximation. These
    methods provide an accurate approximation to the likelihood in some
    situations where it is not possible to use adaptive Gaussian quadrature.",2019-02-04,Helen Ogden,http://github.com/heogden/glmmsr,TRUE,https://github.com/heogden/glmmsr,23992,13,2019-06-20T13:34:54Z,1845.5384615384614
glmnetUtils,"Provides a formula interface for the 'glmnet' package for
    elasticnet regression, a method for cross-validating the alpha parameter,
    and other quality-of-life tools.",2020-03-12,Hong Ooi,https://github.com/Hong-Revo/glmnetUtils,TRUE,https://github.com/hong-revo/glmnetutils,88976,46,2020-03-07T12:25:27Z,1934.2608695652175
glmpca,"Implements a generalized version of principal components analysis
    (GLM-PCA) for dimension reduction of non-normally distributed data such as
    counts or binary matrices.
    Townes FW, Hicks SC, Aryee MJ, Irizarry RA (2019) <doi:10.1101/574574>.
    Townes FW (2019) <arXiv:1907.02647>.",2019-09-27,F. William Townes,https://github.com/willtownes/glmpca,TRUE,https://github.com/willtownes/glmpca,4863,37,2020-04-01T13:06:42Z,131.43243243243242
glmtree,"A logistic regression tree is a decision tree with logistic regressions at its leaves. A particular stochastic expectation maximization algorithm is used to draw a few good trees, that are then assessed via the user's criterion of choice among BIC / AIC / test set Gini. The formal development is given in a PhD chapter, see Ehrhardt (2019) <https://github.com/adimajo/manuscrit_these/releases/>.",2019-10-06,Adrien Ehrhardt,https://adimajo.github.io,TRUE,https://github.com/adimajo/glmtree,3318,1,2019-09-26T13:37:00Z,3318
GlobalOptions,"It provides more configurations on the option values such as validation
    and filtering on the values, making options invisible or private.",2019-09-30,Zuguang Gu,https://github.com/jokergoo/GlobalOptions,TRUE,https://github.com/jokergoo/globaloptions,428816,3,2020-06-06T20:11:10Z,142938.66666666666
globals,"Identifies global (""unknown"" or ""free"") objects in R expressions
    by code inspection using various strategies, e.g. conservative or liberal.
    The objective of this package is to make it as simple as possible to
    identify global objects for the purpose of exporting them in distributed
    compute environments.",2019-12-07,Henrik Bengtsson,https://github.com/HenrikBengtsson/globals,TRUE,https://github.com/henrikbengtsson/globals,1252822,17,2020-05-02T21:51:11Z,73695.41176470589
glue,"An implementation of interpreted string literals, inspired by
  Python's Literal String Interpolation <https://www.python.org/dev/peps/pep-0498/> and Docstrings
  <https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted String Literals
  <https://docs.julialang.org/en/v1.3/manual/strings/#Triple-Quoted-String-Literals-1>.",2020-05-13,Jim Hester,"https://github.com/tidyverse/glue, https://glue.tidyverse.org/",TRUE,https://github.com/tidyverse/glue,20314140,455,2020-06-04T19:29:54Z,44646.46153846154
gluedown,"Ease the transition between R vectors and markdown
    text. With 'gluedown' and 'rmarkdown', users can create traditional
    vectors in R, glue those strings together with the markdown syntax,
    and print those formatted vectors directly to the document. This
    package primarily uses GitHub Flavored Markdown (GFM), an offshoot of
    the unambiguous CommonMark specification by John MacFarlane (2019)
    <https://spec.commonmark.org/>.",2020-01-14,Kiernan Nicholls,"https://kiernann.com/gluedown/,
https://github.com/kiernann/gluedown/",TRUE,https://github.com/kiernann/gluedown,3534,74,2020-01-29T16:30:00Z,47.75675675675676
gmailr,"An interface to the 'Gmail' 'RESTful' API.  Allows
    access to your 'Gmail' messages, threads, drafts and labels.",2019-08-23,Jim Hester,https://github.com/r-lib/gmailr,TRUE,https://github.com/r-lib/gmailr,2079070,196,2020-02-03T16:31:03Z,10607.5
gmapsdistance,"Get distance and travel time between two points from Google Maps.
    Four possible modes of transportation (bicycling, walking, driving and
    public transportation).",2018-08-28,Rodrigo Azuero Melo & & Demetrio Rodriguez T & David Zarruk,https://github.com/rodazuero/gmapsdistance,TRUE,https://github.com/rodazuero/gmapsdistance,41473,62,2020-02-17T22:41:48Z,668.9193548387096
gmat,"Simulation of correlation matrices possibly constrained by a given undirected or acyclic directed graph. In particular, the package provides functions that implement the simulation methods described in Córdoba et al. (2018a) <doi:10.1007/978-3-030-03493-1_13>, Córdoba et al. (2018b) <doi:10.1145/2695664.2695717> and Córdoba et al. (2019) <arXiv:1909.01062>.",2019-09-13,Irene Córdoba,https://github.com/irenecrsn/gmat,TRUE,https://github.com/irenecrsn/gmat,7651,0,2019-10-08T10:20:56Z,NA
GMCM,"Unsupervised Clustering and Meta-analysis using Gaussian Mixture
    Copula Models.",2019-11-05,Anders Ellern Bilgrau,https://github.com/AEBilgrau/GMCM,TRUE,https://github.com/aebilgrau/gmcm,27222,6,2020-01-28T19:37:54Z,4537
gMCP,"Functions and a graphical user interface for graphical described
    multiple test procedures.",2020-03-23,Kornelius Rohmeyer,http://gsrmtp.r-forge.r-project.org/,TRUE,https://github.com/kornl/gmcp,38935,5,2020-03-22T20:44:36Z,7787
Gmisc,"Tools for making the descriptive ""Table 1"" used in medical
    articles, a transition plot for showing changes between categories 
    (also known as a Sankey diagram), flow charts by extending the grid package, 
    a method for variable selection based on the SVD, Bézier lines with arrows complementing the
    ones in the 'grid' package, and more.",2020-05-06,Max Gordon,http://gforge.se,TRUE,https://github.com/gforge/gmisc,72781,37,2020-05-05T12:13:00Z,1967.054054054054
gMOIP,"Make 2D and 3D plots of linear programming (LP), 
    integer linear programming (ILP), or mixed integer linear programming (MILP) models 
    with up to three objectives. Plots of both the solution and criterion space are possible.
    For instance the non-dominated (Pareto) set for bi-objective LP/ILP/MILP programming models 
    (see vignettes for an overview).",2020-02-20,Lars Relund Nielsen,https://github.com/relund/gMOIP/,TRUE,https://github.com/relund/gmoip,11518,0,2020-05-20T13:25:02Z,NA
GMSE,"Integrates game theory and ecological theory to construct 
    social-ecological models that simulate the management of populations and 
    stakeholder actions. These models build off of a previously developed 
    management strategy evaluation (MSE) framework to simulate all aspects of 
    management: population dynamics, manager observation of populations, manager
    decision making, and stakeholder responses to management decisions. The 
    newly developed generalised management strategy evaluation (GMSE) 
    framework uses genetic algorithms to mimic the decision-making process of 
    managers and stakeholders under conditions of change, uncertainty, and 
    conflict. Simulations can be run using gmse(), gmse_apply(), and
    gmse_gui() functions.",2020-05-31,A. Bradley Duthie,https://confoobio.github.io/gmse/,TRUE,https://github.com/confoobio/gmse,14827,6,2020-06-05T11:43:15Z,2471.1666666666665
gnm,"Functions to specify and fit generalized nonlinear models, including models with multiplicative interaction terms such as the UNIDIFF model from sociology and the AMMI model from crop science, and many others.  Over-parameterized representations of models are used throughout; functions are provided for inference on estimable parameter combinations, as well as standard methods for diagnostics etc.",2020-02-03,Heather Turner,https://github.com/hturner/gnm,TRUE,https://github.com/hturner/gnm,243906,3,2020-02-03T09:21:22Z,81302
goffda,"Implementation of several goodness-of-fit tests for functional
     data. Currently, mostly related with the functional linear model with
     functional/scalar response and functional/scalar predictor. The package
     allows for the replication of the data applications considered in
     García-Portugués, Álvarez-Liébana, Álvarez-Pérez and González-Manteiga
     (2019) <arXiv:1909.07686>.",2019-12-17,Eduardo García-Portugués,https://github.com/egarpor/goffda,TRUE,https://github.com/egarpor/goffda,3342,5,2019-12-16T23:16:28Z,668.4
goftest,"Cramer-Von Mises and Anderson-Darling tests of goodness-of-fit
	     for continuous univariate distributions, using
	     efficient algorithms.",2019-12-02,Adrian Baddeley,https://github.com/baddstats/goftest,TRUE,https://github.com/baddstats/goftest,683087,1,2019-11-27T01:55:16Z,683087
golem,"An opinionated framework for building a
    production-ready 'Shiny' application. This package contains a series
    of tools for building a robust 'Shiny' application from start to
    finish.",2020-03-05,Vincent Guyader,https://github.com/ThinkR-open/golem,TRUE,https://github.com/thinkr-open/golem,21530,369,2020-05-28T12:47:07Z,58.34688346883469
goodpractice,"Give advice about good practices when building R packages.
    Advice includes functions and syntax to avoid, package structure,
    code complexity, code formatting, etc.",2018-05-02,Hannah Frick,https://github.com/mangothecat/goodpractice,TRUE,https://github.com/mangothecat/goodpractice,15188,312,2019-11-14T11:22:44Z,48.67948717948718
googleAnalyticsR,"Interact with the Google Analytics 
  APIs <https://developers.google.com/analytics/>, including 
  the Core Reporting API (v3 and v4), Management API, User Activity API
  and Multi-Channel Funnel API.",2019-11-04,Mark Edmondson,http://code.markedmondson.me/googleAnalyticsR/,TRUE,https://github.com/markedmondson1234/googleanalyticsr,117273,192,2020-06-02T19:03:14Z,610.796875
googleAuthR,"Create R functions that interact with OAuth2 Google APIs 
    <https://developers.google.com/apis-explorer/> easily,
    with auto-refresh and Shiny compatibility.",2020-04-26,Mark Edmondson,http://code.markedmondson.me/googleAuthR/,TRUE,https://github.com/markedmondson1234/googleauthr,251177,139,2020-05-24T16:38:36Z,1807.0287769784172
googleCloudRunner,"Tools to easily enable R scripts in the Google Cloud Platform.
  Utilise cloud services such as Cloud Run <https://cloud.run> for R over HTTP, 
  Cloud Build <https://cloud.google.com/cloud-build/> for Continuous Delivery 
  and Integration services and 
  Cloud Scheduler <https://cloud.google.com/scheduler/> for scheduled scripts.",2020-05-02,Mark Edmondson,https://code.markedmondson.me/googleCloudRunner,TRUE,https://github.com/markedmondson1234/googlecloudrunner,2274,30,2020-06-08T21:11:35Z,75.8
googleCloudStorageR,"Interact with Google Cloud Storage <https://cloud.google.com/storage/> 
  API in R. Part of the 'cloudyr' <https://cloudyr.github.io/> project.",2019-08-31,Mark Edmondson,http://code.markedmondson.me/googleCloudStorageR/,TRUE,https://github.com/cloudyr/googlecloudstorager,86202,65,2020-06-06T10:30:55Z,1326.1846153846154
googleCloudVisionR,"Interact with the 'Google Cloud Vision' <https://cloud.google.com/vision/>
  API in R. Part of the 'cloudyr' <https://cloudyr.github.io/> project.",2020-02-07,Jeno Pal,NA,TRUE,https://github.com/cloudyr/googlecloudvisionr,4367,4,2020-04-02T09:18:55Z,1091.75
googleComputeEngineR,"Interact with the 'Google Compute Engine' API in R. Lets you create, 
  start and stop instances in the 'Google Cloud'.  Support for preconfigured instances, 
  with templates for common R needs. ",2019-05-04,Mark Edmondson,https://cloudyr.github.io/googleComputeEngineR/,TRUE,https://github.com/cloudyr/googlecomputeenginer,29968,124,2020-05-26T07:00:33Z,241.67741935483872
googledrive,Manage Google Drive files from R.,2020-05-05,Jennifer Bryan,"https://googledrive.tidyverse.org,
https://github.com/tidyverse/googledrive",TRUE,https://github.com/tidyverse/googledrive,224268,188,2020-05-28T15:31:53Z,1192.9148936170213
googleLanguageR,"Call 'Google Cloud' machine learning APIs for text and speech tasks.
  Call the 'Cloud Translation' API <https://cloud.google.com/translate/> for detection 
  and translation of text, the 'Natural Language' API <https://cloud.google.com/natural-language/> to 
  analyse text for sentiment, entities or syntax, the 'Cloud Speech' API 
  <https://cloud.google.com/speech/> to transcribe sound files to text and 
  the 'Cloud Text-to-Speech' API <https://cloud.google.com/text-to-speech/> to turn text 
  into sound files.",2020-04-19,Mark Edmondson,"http://code.markedmondson.me/googleLanguageR/,
https://github.com/ropensci/googleLanguageR,
https://docs.ropensci.org/googleLanguageR/",TRUE,https://github.com/ropensci/googlelanguager,25903,129,2020-04-20T13:36:52Z,200.7984496124031
googler,"This is a wrapper for the command line tool 'googler', which can be
    found at the following URL: <https://github.com/jarun/googler>.",2019-09-04,Michael W. Kearney,https://github.com/mkearney/googler,TRUE,https://github.com/mkearney/googler,3520,9,2019-09-03T14:13:00Z,391.1111111111111
googlesheets,Interact with Google Sheets from R.,2018-06-29,Jennifer Bryan,https://github.com/jennybc/googlesheets,TRUE,https://github.com/jennybc/googlesheets,431130,753,2020-04-21T19:00:30Z,572.5498007968127
googlesheets4,"Interact with Google Sheets through the Sheets API
    v4 <https://developers.google.com/sheets/api>. ""API"" is an acronym for
    ""application programming interface""; the Sheets API allows users to
    interact with Google Sheets programmatically, instead of via a web
    browser. The ""v4"" refers to the fact that the Sheets API is currently
    at version 4. This package can read and write both the metadata and
    the cell data in a Sheet.",2020-05-08,Jennifer Bryan,https://github.com/tidyverse/googlesheets4,TRUE,https://github.com/tidyverse/googlesheets4,36479,174,2020-05-28T15:30:30Z,209.6494252873563
googleway,"Provides a mechanism to plot a 'Google Map' from 'R' and overlay
    it with shapes and markers. Also provides access to 'Google Maps' APIs,
    including places, directions, roads, distances, geocoding, elevation and
    timezone.",2018-09-17,David Cooley,NA,TRUE,https://github.com/symbolixau/googleway,84124,171,2020-02-17T03:10:49Z,491.953216374269
gotop,Add a scroll back to top 'Font Awesome' icon in R Markdown documents and Shiny apps using 'jQuery GoTop'.,2020-04-25,Félix Luginbuhl,"https://felixluginbuhl.com/gotop, https://github.com/lgnbhl/gotop",TRUE,https://github.com/lgnbhl/gotop,1022,0,2020-04-25T15:56:04Z,NA
govdown,"A suite of custom R Markdown formats and templates
    for authoring web pages styled with the GOV.UK Design System.",2020-05-13,Duncan Garmonsway,https://ukgovdatascience.github.io/govdown,TRUE,https://github.com/ukgovdatascience/govdown,3573,32,2020-05-13T20:17:18Z,111.65625
GPareto,"Gaussian process regression models, a.k.a. Kriging models, are
    applied to global multi-objective optimization of black-box functions.
    Multi-objective Expected Improvement and Step-wise Uncertainty Reduction
    sequential infill criteria are available. A quantification of uncertainty
    on Pareto fronts is provided using conditional simulations.",2020-04-01,Mickael Binois,http://github.com/mbinois/GPareto,TRUE,https://github.com/mbinois/gpareto,54031,7,2020-04-01T10:56:49Z,7718.714285714285
gpclib,General polygon clipping routines for R based on Alan Murta's C library.,2020-02-28,Roger D. Peng <rpeng@jhsph.edu> with contributions from Duncan Murdoch and Barry Rowlingson; GPC library by Alan Murta,"http://www.cs.man.ac.uk/~toby/gpc/,
http://github.com/rdpeng/gpclib",TRUE,https://github.com/rdpeng/gpclib,108351,8,2020-02-28T16:18:57Z,13543.875
gpg,"Bindings to GnuPG for working with OpenGPG (RFC4880) cryptographic methods.
    Includes utilities for public key encryption, creating and verifying digital signatures,
    and managing your local keyring. Note that some functionality depends on the version of 
    GnuPG that is installed on the system. On Windows this package can be used together with
    'GPG4Win' which provides a GUI for managing keys and entering passphrases.",2019-12-02,Jeroen Ooms,"https://jeroen.cran.dev/gpg/ (docs) https://github.com/jeroen/gpg
(dev)",TRUE,https://github.com/jeroen/gpg,16818,14,2019-12-02T13:09:17Z,1201.2857142857142
gplots,"Various R programming tools for plotting data, including:
  - calculating and plotting locally smoothed summary function as
    ('bandplot', 'wapply'),
  - enhanced versions of standard plots ('barplot2', 'boxplot2',
    'heatmap.2', 'smartlegend'),
  - manipulating colors ('col2hex', 'colorpanel', 'redgreen',
    'greenred', 'bluered', 'redblue', 'rich.colors'),
  - calculating and plotting two-dimensional data summaries ('ci2d',
    'hist2d'),
  - enhanced regression diagnostic plots ('lmplot2', 'residplot'),
  - formula-enabled interface to 'stats::lowess' function ('lowess'),
  - displaying textual data in plots ('textplot', 'sinkplot'),
  - plotting a matrix where each cell contains a dot whose size
    reflects the relative magnitude of the elements ('balloonplot'),
  - plotting ""Venn"" diagrams ('venn'),
  - displaying Open-Office style plots ('ooplot'),
  - plotting multiple data on same region, with separate axes
    ('overplot'),
  - plotting means and confidence intervals ('plotCI', 'plotmeans'),
  - spacing points in an x-y plot so they don't overlap ('space').",2020-02-25,Gregory R. Warnes,https://github.com/talgalili/gplots,TRUE,https://github.com/talgalili/gplots,4595210,4,2020-02-24T06:28:44Z,1148802.5
gqlr,"Server implementation of 'GraphQL' <http://graphql.github.io/graphql-spec/>,
    a query language originally created by Facebook for describing data requirements on complex application
    data models.  Visit <http://graphql.org> to learn more about 'GraphQL'.",2019-12-02,Barret Schloerke,"https://github.com/schloerke/gqlr,
http://graphql.github.io/graphql-spec/, http://graphql.org",TRUE,https://github.com/schloerke/gqlr,9298,36,2019-12-02T16:09:40Z,258.27777777777777
grabsampling,"Functions for obtaining the probability of detection, for grab samples selection by using two different methods such as systematic or random based on two-state Markov chain model. For detection probability calculation, we used results from Bhat, U. and Lal, R. (1988) <doi:10.2307/1427041>.",2020-03-04,Mayooran Thevaraja,https://github.com/Mayooran1987/grabsampling,TRUE,https://github.com/mayooran1987/grabsampling,1529,0,2020-03-12T20:57:01Z,NA
grainscape,"Given a landscape resistance surface, creates grains of connectivity
    (Galpern et al. (2012) <doi:10.1111/j.1365-294X.2012.05677.x>) and minimum planar graph
    (Fall et al. (2007) <doi:10.1007/s10021-007-9038-7>) models that can be used to calculate
    effective distances for landscape connectivity at multiple scales.",2019-12-06,Alex M Chubaty,"https://alexchubaty.com/grainscape,
https://github.com/achubaty/grainscape",TRUE,https://github.com/achubaty/grainscape,4936,9,2019-12-06T17:07:18Z,548.4444444444445
GRANBase,"Repository based tools for department and analysis level
    reproducibility. 'GRANBase' allows creation of custom branched, continuous
    integration-ready R repositories, including incremental testing of only packages
    which have changed versions since the last repository build.",2020-02-05,Cory Barr,https://github.com/gmbecker/gRAN,TRUE,https://github.com/gmbecker/gran,19826,24,2020-05-07T18:21:54Z,826.0833333333334
GRANCore,"Provides the classes and methods for GRANRepository
    objects that are used within the 'GRAN' build framework for R packages.
    This is primarily used by the 'GRANBase' package and repositories
    that are created by it.",2020-02-04,Gabriel Becker[aut,https://github.com/gmbecker/GRANCore,TRUE,https://github.com/gmbecker/grancore,9679,1,2019-10-31T00:35:24Z,9679
grangers,"Contains five functions performing the calculation of unconditional and conditional Granger-causality spectra, bootstrap inference on both, and inference on the difference between them via the bootstrap approach of Farne' and Montanari, 2018 <arXiv:1803.00374>.",2019-06-03,Matteo Farne,https://github.com/MatFar88/grangers,TRUE,https://github.com/matfar88/grangers,4444,1,2019-07-29T22:13:21Z,4444
grapherator,"Set of functions for step-wise generation of (weighted) graphs. Aimed for research in the field of single- and multi-objective combinatorial optimization. Graphs are generated adding nodes, edges and weights. Each step may be repeated multiple times with different predefined and custom generators resulting in high flexibility regarding the graph topology and structure of edge weights.",2017-12-21,Jakob Bossek,https://github.com/jakobbossek/grapherator,TRUE,https://github.com/jakobbossek/grapherator,8875,5,2019-09-17T10:56:43Z,1775
graphlayouts,"Several new layout algorithms to visualize networks are provided which are not part of 'igraph'. 
    Most are based on the concept of stress majorization by Gansner et al. (2004) <doi:10.1007/978-3-540-31843-9_25>. 
    Some more specific algorithms allow to emphasize hidden group structures in networks or focus on specific nodes.",2020-04-25,David Schoch,"http://graphlayouts.schochastics.net/,
https://github.com/schochastics/graphlayouts",TRUE,https://github.com/schochastics/graphlayouts,346297,145,2020-04-25T21:09:25Z,2388.255172413793
graphql,"Bindings to the 'libgraphqlparser' C++ library. Parses GraphQL syntax
    and exports the AST in JSON format.",2018-12-01,Jeroen Ooms,"http://graphql.org (upstream) https://github.com/ropensci/graphql
(devel)",TRUE,https://github.com/ropensci/graphql,17465,26,2019-12-08T22:41:42Z,671.7307692307693
graphTweets,"Allows building an edge table from data frame of tweets, 
  also provides function to build nodes and another create a temporal graph.",2020-01-08,John Coene,http://graphTweets.john-coene.com,TRUE,https://github.com/johncoene/graphtweets,31168,42,2020-01-07T12:45:54Z,742.0952380952381
gratia,"Graceful 'ggplot'-based graphics and utility functions for working with generalized additive models (GAMs) fitted using the 'mgcv' package. Provides a reimplementation of the plot() method for GAMs that 'mgcv' provides, as well as 'tidyverse' compatible representations of estimated smooths.",2020-05-31,Gavin L. Simpson,https://gavinsimpson.github.io/gratia,TRUE,https://github.com/gavinsimpson/gratia,8472,83,2020-06-05T21:10:50Z,102.07228915662651
graticule,"Create graticule lines and labels for maps. Control the creation
    of lines by setting their placement (at particular meridians and parallels)
    and extent (along parallels and meridians). Labels are created independently of
    lines.",2016-02-02,Michael D. Sumner,https://github.com/mdsumner/graticule,TRUE,https://github.com/mdsumner/graticule,17044,17,2019-10-14T05:54:02Z,1002.5882352941177
grattan,"Utilities for costing and evaluating Australian tax policy, including high-performance tax and transfer calculators, a fast method of projecting tax collections, and an interface to common indices from the Australian Bureau of Statistics.  Written to support Grattan Institute's Australian Perspectives program. For access to the 'taxstats' package, please run
 install.packages(""taxstats"", repos = ""https://hughparsonage.github.io/tax-drat/"", type = ""source""). 
 N.B. The 'taxstats' package is approximately 50 MB.",2020-03-16,Hugh Parsonage,"https://github.com/HughParsonage/grattan,
https://hughparsonage.github.io/grattan/",TRUE,https://github.com/hughparsonage/grattan,27992,15,2020-03-24T00:32:11Z,1866.1333333333334
gravitas,"Provides tools for systematically exploring large quantities of 
             temporal data across nonlinear temporal granularities
             (deconstructions of time) by visualizing probability distributions.
             Nonlinear time granularities can be circular, quasi-circular or 
             aperiodic. 'gravitas' computes nonlinear
             single-order-up or multiple-order-up granularities, check the
             feasibility of creating plots for any two nonlinear granularities
             and recommend probability distributions plots for exploring
             periodicity in the data.",2020-02-17,Sayani Gupta,https://github.com/Sayani07/gravitas/,TRUE,https://github.com/sayani07/gravitas,3491,11,2020-06-01T06:00:06Z,317.3636363636364
grec,Provides algorithms for detection of spatial patterns from oceanographic data using image processing methods based on Gradient Recognition.,2020-02-19,Wencheng Lau-Medrano,https://github.com/LuisLauM/grec,TRUE,https://github.com/luislaum/grec,12943,1,2020-02-06T14:38:41Z,12943
greenclust,"Implements a method of iteratively collapsing the rows of a
    contingency table, two at a time, by selecting the pair of categories whose
    combination yields a new table with the smallest loss of chi-squared, as
    described by Greenacre, M.J. (1988) <doi:10.1007/BF01901670>. The result is
    compatible with the class of object returned by the 'stats' package's
    hclust() function and can be used similarly (plotted as a dendrogram,
    cut, etc.). Additional functions are provided for automatic cutting and
    diagnostic plotting.",2020-01-10,Jeff Jetton,https://github.com/JeffJetton/greenclust,TRUE,https://github.com/jeffjetton/greenclust,4223,3,2020-02-13T04:00:03Z,1407.6666666666667
gremlin,"Fit linear mixed-effects models using restricted (or residual)
    maximum likelihood (REML) and with generalized inverse matrices to specify
    covariance structures for random effects. In particular, the package is suited
    to fit quantitative genetic mixed models, often referred to as 'animal models' 
    (Kruuk. 2004 <DOI: 10.1098/rstb.2003.1437>). Implements the average
    information algorithm as the main tool to maximize the restricted likelihood,
    but with other algorithms available (Meyer. 1997. Genet Sel Evol 29:97; Meyer
    and Smith. 1998. Genet Sel Evol 28:23.).",2019-04-09,Matthew Wolak,http://github.com/matthewwolak/gremlin,TRUE,https://github.com/matthewwolak/gremlin,6028,2,2019-10-12T11:29:02Z,3014
gren,"Allows the user to incorporate multiple sources of co-data 	
	(e.g., 	previously obtained p-values, published gene lists, and annotation) in the	estimation of a logistic regression model to enhance predictive performance and 	feature selection, as described in Münch, Peeters, van der Vaart, and van de Wiel 	(2018) <arXiv:1805.00389>.",2018-07-30,Magnus M. Münch,https://github.com/magnusmunch/gren/,TRUE,https://github.com/magnusmunch/gren,6483,0,2019-12-02T09:39:02Z,NA
greta,"Write statistical models in R and fit them by MCMC and optimisation on CPUs and GPUs, using Google 'TensorFlow'.
  greta lets you write your own model like in BUGS, JAGS and Stan, except that you write models right in R, it scales well to massive datasets, and it’s easy to extend and build on.
  See the website for more information, including tutorials, examples, package documentation, and the greta forum.",2019-08-09,Nick Golding,https://greta-stats.org,TRUE,https://github.com/greta-dev/greta,21058,419,2020-04-13T07:39:10Z,50.25775656324582
gretel,"The social network literature features numerous methods for assigning
    value to paths as a function of their ties. 'gretel' systemizes these approaches,
    casting them as instances of a generalized path value function indexed by 
    a penalty parameter. The package also calculates probabilistic path value and
    identifies optimal paths in either value framework. Finally, proximity 
    matrices can be generated in these frameworks that capture high-order connections 
    overlooked in primitive adjacency sociomatrices. Novel methods are described
    in Buch (2019) <https://davidbuch.github.io/analyzing-networks-with-gretel.html>. 
    More traditional methods are also implemented, as described in Yang, Knoke (2001) 
    <doi:10.1016/S0378-8733(01)00043-0>.",2019-08-22,David Buch,https://github.com/davidbuch/gretel,TRUE,https://github.com/davidbuch/gretel,3433,0,2019-10-14T16:35:51Z,NA
grex,"Convert 'Ensembl' gene identifiers from Genotype-Tissue
    Expression (GTEx) data to identifiers in other annotation systems,
    including 'Entrez', 'HGNC', and 'UniProt'.",2019-05-17,Nan Xiao,"https://nanx.me/grex/, https://github.com/nanxstats/grex",TRUE,https://github.com/nanxstats/grex,16799,4,2020-04-23T22:58:16Z,4199.75
greybox,"Implements functions and instruments for regression model building and its
             application to forecasting. The main scope of the package is in variables selection
             and models specification for cases of time series data. This includes promotional
             modelling, selection between different dynamic regressions with non-standard
             distributions of errors, selection based on cross validation, solutions to the fat
             regression model problem and more. Models developed in the package are tailored
             specifically for forecasting purposes. So as a results there are several methods
             that allow producing forecasts from these models and visualising them.",2020-05-20,"Ivan Svetunkov  (Lecturer at Centre for Marketing Analytics
    and Forecasting",https://github.com/config-i1/greybox,TRUE,https://github.com/config-i1/greybox,208137,15,2020-06-06T14:48:52Z,13875.8
grf,"A pluggable package for forest-based statistical estimation and inference.
    GRF currently provides methods for non-parametric least-squares regression,
    quantile regression, survival regression and treatment effect estimation (optionally using instrumental
    variables), with support for missing values.",2020-06-04,Julie Tibshirani,https://github.com/grf-labs/grf,TRUE,https://github.com/grf-labs/grf,75628,417,2020-06-09T21:04:24Z,181.3621103117506
gridGraphics,"Functions to convert a page of plots drawn with the 
  'graphics' package into identical output drawn with the 'grid' package.
  The result looks like the original 'graphics'-based plot, but consists
  of 'grid' grobs and viewports that can then be manipulated with 
  'grid' functions (e.g., edit grobs and revisit viewports).",2020-02-25,Paul Murrell,https://github.com/pmur002/gridgraphics,TRUE,https://github.com/pmur002/gridgraphics,297494,28,2020-02-25T00:30:17Z,10624.785714285714
gridsampler,"Simulation tool to facilitate determination of
    required sample size to achieve category saturation
    for studies using multiple repertory grids in conjunction with
    content analysis.",2016-11-23,Mark Heckmann,https://github.com/markheckmann/gridsampler,TRUE,https://github.com/markheckmann/gridsampler,11652,4,2020-02-06T19:45:55Z,2913
gridtext,"Provides support for rendering of formatted text using 'grid' graphics. Text can be
    formatted via a minimal subset of 'Markdown', 'HTML', and inline 'CSS' directives, and it can be
    rendered both with and without word wrap.",2020-02-24,Claus O. Wilke,https://wilkelab.org/gridtext,TRUE,https://github.com/wilkelab/gridtext,6848,75,2020-05-03T19:08:59Z,91.30666666666667
groupdata2,"Methods for dividing data into groups. 
    Create balanced partitions and cross-validation folds. 
    Perform time series windowing and general grouping and splitting of data. 
    Balance existing groups with up- and downsampling.",2020-06-06,Ludvig Renbo Olsen,https://github.com/ludvigolsen/groupdata2,TRUE,https://github.com/ludvigolsen/groupdata2,17044,14,2020-06-07T22:52:08Z,1217.4285714285713
groupedstats,"Collection of functions to run statistical tests
    across all combinations of multiple grouping variables.",2020-05-29,Indrajeet Patil,"https://indrajeetpatil.github.io/groupedstats/,
https://github.com/IndrajeetPatil/groupedstats/",TRUE,https://github.com/indrajeetpatil/groupedstats,48753,46,2020-05-31T11:22:10Z,1059.8478260869565
groupICA,"Contains an implementation of an independent component analysis (ICA) for grouped data. The main function groupICA() performs a blind source separation, by maximizing an independence across sources and allows to adjust for varying confounding for user-specified groups. Additionally, the package contains the function uwedge() which can be used to approximately jointly diagonalize a list of matrices. For more details see the project website <https://sweichwald.de/groupICA/>.",2018-06-19,Niklas Pfister and Sebastian Weichwald,https://github.com/sweichwald/groupICA-R,TRUE,https://github.com/sweichwald/groupica-r,6701,1,2020-05-15T08:05:37Z,6701
growthrates,"A collection of methods to determine growth rates from
    experimental data, in particular from batch experiments and
    plate reader trials.",2019-12-18,Thomas Petzoldt,https://github.com/tpetzoldt/growthrates,TRUE,https://github.com/tpetzoldt/growthrates,20623,13,2020-01-25T20:03:01Z,1586.3846153846155
grpreg,"Efficient algorithms for fitting the regularization path of linear
  regression, GLM, and Cox regression models with grouped penalties.  This
  includes group selection methods such as group lasso, group MCP, and
  group SCAD as well as bi-level selection methods such as the group
  exponential lasso, the composite MCP, and the group bridge.",2020-02-19,Patrick Breheny,"http://pbreheny.github.io/grpreg,
https://github.com/pbreheny/grpreg",TRUE,https://github.com/pbreheny/grpreg,332933,21,2020-06-09T21:42:53Z,15853.952380952382
grpSLOPE,"Group SLOPE is a penalized linear regression method that is used
    for adaptive selection of groups of significant predictors in a
    high-dimensional linear model.
    The Group SLOPE method can control the (group) false discovery rate at a
    user-specified level (i.e., control the expected proportion of irrelevant
    among all selected groups of predictors).",2020-04-07,Alexej Gossmann,https://github.com/agisga/grpSLOPE.git,TRUE,https://github.com/agisga/grpslope,13466,3,2020-04-13T20:10:39Z,4488.666666666667
gscaLCA,"
    Execute Latent Class Analysis (LCA) and Latent Class Regression (LCR) by using Generalized Structured Component Analysis (GSCA). This is explained in Ryoo, Park, and Kim (2019) <doi:10.1007/s41237-019-00084-6>.
    It estimates the parameters of latent class prevalence and item response probability in LCA with a single line comment. It also provides graphs of item response probabilities. In addition, the package enables to estimate the relationship between the prevalence and covariates. ",2020-06-08,Seohee Park,https://github.com/hee6904/gscaLCA,TRUE,https://github.com/hee6904/gscalca,3209,0,2020-06-08T17:48:42Z,NA
gsheet,"Simple package to download Google Sheets using just the sharing
    link. Spreadsheets can be downloaded as a data frame, or as plain text to parse
    manually. Google Sheets is the new name for Google Docs Spreadsheets <https://www.google.com/sheets/about>.",2020-04-07,Max Conway,https://github.com/maxconway/gsheet,TRUE,https://github.com/maxconway/gsheet,129150,37,2020-04-07T13:35:14Z,3490.5405405405404
gsl,"
 An R wrapper for some of the functionality of the
 Gnu Scientific Library.",2019-03-25,Robin K. S. Hankin,https://github.com/RobinHankin/gsl.git,TRUE,https://github.com/robinhankin/gsl,580566,6,2020-05-01T23:37:17Z,96761
GSODR,"Provides automated downloading, parsing, cleaning, unit conversion
    and formatting of Global Surface Summary of the Day ('GSOD') weather data
    from the from the USA National Centers for Environmental Information
    ('NCEI').  Units are converted from from United States Customary System
    ('USCS') units to International System of Units ('SI').  Stations may be
    individually checked for number of missing days defined by the user, where
    stations with too many missing observations are omitted.  Only stations with
    valid reported latitude and longitude values are permitted in the final
    data.  Additional useful elements, saturation vapour pressure ('es'), actual
    vapour pressure ('ea') and relative humidity ('RH') are calculated from the
    original data using the improved August-Roche-Magnus approximation (Alduchov
    & Eskridge 1996) and included in the final data set.  The resulting metadata
    include station identification information, country, state, latitude,
    longitude, elevation, weather observations and associated flags.  For
    information on the 'GSOD' data from 'NCEI', please see the 'GSOD'
    'readme.txt' file available from,
    <http://www1.ncdc.noaa.gov/pub/data/gsod/readme.txt>.",2020-04-17,Adam Sparks,https://docs.ropensci.org/GSODR/,TRUE,https://github.com/ropensci/gsodr,55097,69,2020-06-01T13:01:39Z,798.5072463768116
gstat,"Variogram modelling; simple, ordinary and universal point or block (co)kriging; spatio-temporal kriging; sequential Gaussian or indicator (co)simulation; variogram and variogram map plotting utility functions; supports sf and stars.",2020-05-18,Edzer Pebesma,https://github.com/r-spatial/gstat/,TRUE,https://github.com/r-spatial/gstat,797248,110,2020-05-18T11:15:51Z,7247.709090909091
gt,"Build display tables from tabular data with an easy-to-use set of
    functions. With its progressive approach, we can construct display tables
    with a cohesive set of table parts. Table values can be formatted using any
    of the included formatting functions. Footnotes and cell styles can be 
    precisely added through a location targeting system. The way in which 'gt'
    handles things for you means that you don't often have to worry about the
    fine details.",2020-05-23,Richard Iannone,https://github.com/rstudio/gt,TRUE,https://github.com/rstudio/gt,19156,1095,2020-05-29T19:26:03Z,17.49406392694064
gtable,"Tools to make it easier to work with ""tables"" of
    'grobs'. The 'gtable' package defines a 'gtable' grob class that specifies a
    grid along with a list of grobs and their placement in the grid. Further the
    package makes it easy to manipulate and combine 'gtable' objects so that 
    complex compositions can be build up sequentially.",2019-03-25,Hadley Wickham,https://github.com/r-lib/gtable,TRUE,https://github.com/r-lib/gtable,16404790,63,2019-06-26T07:57:33Z,260393.49206349207
gtfs2gps,Convert general transit feed specification (GTFS) data to global positioning system (GPS) records in 'data.table' format. It also has some functions to subset GTFS data in time and space and to convert both representations to simple feature format.,2020-05-28,Rafael H. M. Pereira,https://github.com/ipeaGIT/gtfs2gps,TRUE,https://github.com/ipeagit/gtfs2gps,1653,37,2020-06-04T11:14:49Z,44.67567567567568
gtfsrouter,"Use GTFS (General Transit Feed Specification) data for routing from
    nominated start and end stations, and for extracting isochrones from
    nominated start station.",2019-03-22,Mark Padgham,https://github.com/ATFutures/gtfs-router,TRUE,https://github.com/atfutures/gtfs-router,4964,30,2020-06-04T13:54:54Z,165.46666666666667
gtrendsR,"An interface for retrieving and displaying the information
        returned online by Google Trends is provided. Trends (number of
        hits) over the time as well as geographic representation of the
        results can be displayed.",2020-05-17,Philippe Massicotte,https://github.com/PMassicotte/gtrendsR,TRUE,https://github.com/pmassicotte/gtrendsr,118835,234,2020-05-17T17:19:56Z,507.84188034188037
gtsummary,"Creates presentation-ready tables summarizing data
    sets, regression models, and more. The code to create the tables is
    concise and highly customizable. Data frames can be summarized with
    any function, e.g. mean(), median(), even user-written functions.
    Regression models are summarized and include the reference rows for
    categorical variables. Common regression models, such as logistic
    regression and Cox proportional hazards regression, are automatically
    identified and the tables are pre-filled with appropriate column
    headers. ",2020-06-02,Daniel D. Sjoberg,"https://github.com/ddsjoberg/gtsummary,
http://www.danieldsjoberg.com/gtsummary/",TRUE,https://github.com/ddsjoberg/gtsummary,14940,231,2020-06-09T23:40:48Z,64.67532467532467
guardianapi,"Access to 'The Guardian' newspaper's open API
  <https://open-platform.theguardian.com/>, containing all articles published 
  in 'The Guardian' from 1999 to the present, including article text, metadata,
  tags and contributor information. An API key and registration is required.",2019-06-23,Evan Odell,https://docs.evanodell.com/guardianapi,TRUE,https://github.com/evanodell/guardianapi,6170,4,2019-06-23T21:09:38Z,1542.5
Guerry,"Maps of France in 1830, multivariate datasets from A.-M. Guerry and others, and statistical and 
	graphic methods related to Guerry's ""Moral Statistics of France"". The goal is to facilitate the exploration and
	development of statistical and graphic methods for multivariate data in a geo-spatial context of historical interest.",2020-01-29,Michael Friendly,https://github.com/friendly/Guerry,TRUE,https://github.com/friendly/guerry,55443,0,2020-01-29T15:11:04Z,NA
GuessCompx,"Make an empirical guess on the time and memory complexities of an algorithm or a function.
    Tests multiple, increasing size random samples of your data and tries to fit various complexity functions o(n), o(n2), o(log(n)), etc.
    Based on best fit, it predicts the full computation time on your whole dataset. Results are plotted with 'ggplot2'.",2019-06-03,Marc Agenis,https://github.com/agenis/GuessCompx,TRUE,https://github.com/agenis/guesscompx,4296,9,2019-06-17T22:36:49Z,477.3333333333333
gustave,"Provides a toolkit for analytical variance estimation in survey sampling. Apart from the implementation of standard variance estimators, its main feature is to help the sampling expert produce easy-to-use variance estimation ""wrappers"", where systematic operations (linearization, domain estimation) are handled in a consistent and transparent way.",2019-12-16,Martin Chevalier,https://github.com/martinchevalier/gustave,TRUE,https://github.com/martinchevalier/gustave,7919,4,2019-12-16T22:03:37Z,1979.75
gutenbergr,"Download and process public domain works in the Project
    Gutenberg collection <http://www.gutenberg.org/>. Includes metadata for
    all Project Gutenberg works, so that they can be searched and retrieved.",2019-09-10,David Robinson,http://github.com/ropensci/gutenbergr,TRUE,https://github.com/ropensci/gutenbergr,155395,70,2019-12-09T21:12:11Z,2219.9285714285716
gvc,"Several tools for Global Value Chain ('GVC') analysis are
    implemented.",2020-04-23,Bastiaan Quast,"https://qua.st/gvc, https://github.com/bquast/gvc",TRUE,https://github.com/bquast/gvc,23285,6,2020-04-25T09:54:55Z,3880.8333333333335
gWidgets2RGtk2,Implements the 'gWidgets2' API for 'RGtk2.',2018-01-04,John Verzani,https://github.com/jverzani/gWidgets2RGtk2,TRUE,https://github.com/jverzani/gwidgets2rgtk2,40477,4,2019-10-28T14:01:25Z,10119.25
gwsem,"Melds genome-wide association tests with structural
    equation modeling (SEM) using 'OpenMx'. This package contains
    low-level C/C++ code to rapidly read genetic data encoded in U.K.
    Biobank or 'plink' formats. Prebuilt modeling options include one and
    two factor models. Alternately, analyses may utilize arbitrary,
    user-provided SEMs.  See Verhulst, Maes, & Neale (2017)
    <doi:10.1007/s10519-017-9842-6> for details. An updated manuscript is
    in preparation.",2020-03-27,Joshua N. Pritikin,https://github.com/jpritikin/gwsem,TRUE,https://github.com/jpritikin/gwsem,2752,1,2020-05-29T13:28:15Z,2752
h2o4gpu,"Interface to 'H2O4GPU' <https://github.com/h2oai/h2o4gpu>, a collection of 'GPU' solvers for machine learning algorithms.",2018-03-23,Yuan Tang,https://github.com/h2oai/h2o4gpu,TRUE,https://github.com/h2oai/h2o4gpu,10710,377,2020-06-03T13:54:04Z,28.408488063660478
hablar,Simple tools for converting columns to new data types. Intuitive functions for columns with missing values. ,2020-03-19,David Sjoberg,https://davidsjoberg.github.io/,TRUE,https://github.com/davidsjoberg/hablar,21996,23,2020-05-17T06:42:22Z,956.3478260869565
hackeRnews,"Use the <https://hacker-news.firebaseio.com/v0/> API through R. Retrieve
    posts, articles and other items in form of convenient R objects.",2019-12-13,Ryszard Szymanski,https://github.com/szymanskir/hackeRnews,TRUE,https://github.com/szymanskir/hackernews,2562,19,2020-01-22T19:51:32Z,134.8421052631579
hagis,"Analysis of plant pathogen pathotype survey data.  Functions
  provided calculate distribution of susceptibilities, distribution of
  complexities with statistics, pathotype frequency distribution, as well as
  diversity indices for pathotypes.  This package is meant to be a direct
  replacement for Herrmann, Löwer, Schachtel's (1999)
  <doi:10.1046/j.1365-3059.1999.00325.x> Habgood-Gilmour Spreadsheet, 'HaGiS',
  previously used for pathotype analysis.",2019-11-18,Austin G. McCoy,"https://github.com/openplantpathology/hagis,
https://openplantpathology.github.io/hagis/",TRUE,https://github.com/openplantpathology/hagis,4266,2,2020-04-11T10:12:49Z,2133
hal9001,"A scalable implementation of the highly adaptive lasso algorithm,
  including routines for constructing sparse matrices of basis functions of the
  observed data, as well as a custom implementation of Lasso regression tailored
  to enhance efficiency when the matrix of predictors is composed exclusively of
  indicator functions. For ease of use and increased flexibility, the Lasso
  fitting routines invoke code from the 'glmnet' package by default. The highly
  adaptive lasso was first formulated and described by MJ van der Laan (2017)
  <doi:10.1515/ijb-2015-0097>, with practical demonstrations of its performance
  given by Benkeser and van der Laan (2016) <doi:10.1109/DSAA.2016.93>.",2020-03-05,Jeremy Coyle,https://github.com/tlverse/hal9001,TRUE,https://github.com/tlverse/hal9001,1725,13,2020-03-06T00:56:08Z,132.69230769230768
haldensify,"Conditional density estimation is a longstanding and challenging
    problem in statistical theory, and numerous proposals exist for optimally
    estimating such complex functions. Algorithms for nonparametric estimation
    of conditional densities based on a pooled hazard regression formulation and
    semiparametric estimation via conditional hazards modeling are implemented
    based on the highly adaptive lasso, a nonparametric regression function for
    efficient estimation with fast convergence under mild assumptions. The
    pooled hazards formulation implemented was first described by Díaz and
    van der Laan (2011) <doi:10.2202/1557-4679.1356>.",2020-03-14,Nima Hejazi,https://github.com/nhejazi/haldensify,TRUE,https://github.com/nhejazi/haldensify,1461,3,2020-05-27T20:46:01Z,487
handlr,"Converts among many citation formats, including 'BibTeX',
    'Citeproc', 'Codemeta', 'RDF XML', 'RIS', and 'Schema.org'. A low
    level 'R6' class is provided, as well as stand-alone functions
    for each citation format for both read and write.",2019-08-19,Scott Chamberlain,https://github.com/ropensci/handlr,TRUE,https://github.com/ropensci/handlr,5872,29,2020-04-14T23:24:55Z,202.48275862068965
hansard,"Provides functions to download data from the 
  <http://www.data.parliament.uk/> APIs. Because of the structure of the API, 
  there is a named function for each type of available data for ease of use, 
  as well as some functions designed to retrieve specific pieces of commonly 
  used data. Functions for each new API will be added as and when they become
  available.",2019-11-13,Evan Odell,https://docs.evanodell.com/hansard,TRUE,https://github.com/evanodell/hansard,22711,20,2020-03-13T13:11:00Z,1135.55
hardhat,"Building modeling packages is hard. A large amount of effort
    generally goes into providing an implementation for a new method that is
    efficient, fast, and correct, but often less emphasis is put on the user
    interface. A good interface requires specialized knowledge about S3 methods
    and formulas, which the average package developer might not have.
    The goal of 'hardhat' is to reduce the burden around building new modeling
    packages by providing functionality for preprocessing, predicting, and
    validating input.",2020-05-20,Davis Vaughan,https://github.com/tidymodels/hardhat,TRUE,https://github.com/tidymodels/hardhat,29586,67,2020-05-20T21:38:58Z,441.5820895522388
HARModel,"Estimation, simulation, and forecasting using the HAR model from Corsi(2009) <DOI:10.1093/jjfinec/nbp001> and extensions.",2019-08-31,Emil Sjoerup,https://github.com/emilsjoerup/HARModel,TRUE,https://github.com/emilsjoerup/harmodel,7554,3,2019-09-04T18:01:35Z,2518
harrypotter,Implementation of characteristic palettes inspired in the Wizarding World and the Harry Potter movie franchise.,2020-03-05,Alejandro Jimenez Rico,https://github.com/aljrico/harrypotter,TRUE,https://github.com/aljrico/harrypotter,53006,54,2020-03-05T19:25:02Z,981.5925925925926
hashr,"Apply the SuperFastHash algorithm to any R object. Hash whole R objects or, 
     for vectors or lists, hash R objects to obtain a set of hash values that is stored 
     in a structure equivalent to the input. ",2015-08-06,Mark van der Loo,https://github.com/markvanderloo/hashr,TRUE,https://github.com/markvanderloo/hashr,15381,7,2019-06-24T21:22:32Z,2197.285714285714
hasseDiagram,Drawing Hasse diagram - visualization of transitive reduction of a finite partially ordered set.,2017-02-24,Krzysztof Ciomek,https://github.com/kciomek/hasseDiagram,TRUE,https://github.com/kciomek/hassediagram,20377,4,2020-03-17T21:02:08Z,5094.25
haven,"Import foreign statistical formats into R via the
    embedded 'ReadStat' C library,
    <https://github.com/WizardMac/ReadStat>.",2020-06-01,Hadley Wickham,"http://haven.tidyverse.org, https://github.com/tidyverse/haven,
https://github.com/WizardMac/ReadStat",TRUE,https://github.com/tidyverse/haven,10508617,309,2020-06-01T16:07:43Z,34008.46925566343
hBayesDM,"
    Fit an array of decision-making tasks with computational models in
    a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of
    various computational models with a single line of coding
    (Ahn et al., 2017) <doi:10.1162/CPSY_a_00002>.",2019-11-13,Woo-Young Ahn,https://github.com/CCS-Lab/hBayesDM,TRUE,https://github.com/ccs-lab/hbayesdm,25819,96,2019-11-15T05:00:17Z,268.9479166666667
hcandersenr,"Texts for H.C. Andersens fairy tales, ready for
    text analysis. Fairy tales in German, Danish, English, Spanish and
    French.",2019-01-19,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/hcandersenr,TRUE,https://github.com/emilhvitfeldt/hcandersenr,6764,7,2020-03-11T22:54:04Z,966.2857142857143
hchinamap,"By binding R functions and the 'Highmaps' <https://www.highcharts.com.cn/products/highmaps> chart library, 'hchinamap' package provides a simple way to map China and its provinces. The map of China drawn by this package contains complete Chinese territory, especially the Nine-dotted line, South Tibet, Hong Kong, Macao and Taiwan.",2019-08-23,Zhenxing Cheng,https://github.com/czxa/hchinamap,TRUE,https://github.com/czxa/hchinamap,4715,14,2019-10-19T13:25:03Z,336.7857142857143
HCmodelSets,"Software for performing the reduction, exploratory and model selection phases of the procedure proposed by Cox, D.R. and Battey, H.S. (2017) <doi:10.1073/pnas.1703764114> for sparse regression when the number of potential explanatory variables far exceeds the sample size. The software supports linear regression, likelihood-based fitting of generalized linear regression models and the proportional hazards model fitted by partial likelihood.",2020-04-20,H. H. Hoeltgebaum,NA,TRUE,https://github.com/hhhelfer/hcmodelsets,9393,0,2020-04-20T15:41:39Z,NA
hddtools,"Tools to discover hydrological data, accessing catalogues and databases from various data providers.",2020-05-25,Claudia Vitolo,"http://docs.ropensci.org/hddtools,
https://github.com/ropensci/hddtools",TRUE,https://github.com/ropensci/hddtools,19969,33,2020-05-25T10:10:12Z,605.1212121212121
hdf5r,"'HDF5' is a data model, library and file format for storing 
    and managing large amounts of data. This package provides a nearly
    feature complete, object oriented  wrapper for the 'HDF5' API
    <https://support.hdfgroup.org/HDF5/doc/RM/RM_H5Front.html> using R6 classes. 
    Additionally, functionality is added so that 'HDF5' objects behave very 
    similar to their corresponding R counterparts.",2020-03-25,Holger Hoefling,"https://hhoeflin.github.io/hdf5r,
https://github.com/hhoeflin/hdf5r",TRUE,https://github.com/hhoeflin/hdf5r,155016,37,2020-03-24T12:10:55Z,4189.621621621622
hdme,"Penalized regression for generalized linear models for
  measurement error problems (aka. errors-in-variables). The package
  contains a version of the lasso (L1-penalization) which corrects
  for measurement error (Sorensen et al. (2015) <doi:10.5705/ss.2013.180>). 
  It also contains an implementation of the Generalized Matrix Uncertainty 
  Selector, which is a version the (Generalized) Dantzig Selector for the 
  case of measurement error (Sorensen et al. (2018) <doi:10.1080/10618600.2018.1425626>).",2020-05-18,Oystein Sorensen,https://github.com/osorensen/hdme,TRUE,https://github.com/osorensen/hdme,12694,4,2020-05-18T12:09:12Z,3173.5
hdnom,"Creates nomogram visualizations for penalized Cox regression
    models, with the support of reproducible survival model building,
    validation, calibration, and comparison for high-dimensional data.",2019-06-23,Nan Xiao,"https://nanx.me/hdnom/, https://github.com/nanxstats/hdnom,
http://hdnom.io",TRUE,https://github.com/nanxstats/hdnom,36225,28,2020-04-23T23:03:02Z,1293.75
healthcareai,A machine learning toolbox tailored to healthcare data.,2020-02-28,Mike Mastanduno,http://docs.healthcare.ai,TRUE,https://github.com/healthcatalyst/healthcareai-r,29057,177,2020-02-28T18:44:20Z,164.1638418079096
heatmaply,"Create interactive cluster 'heatmaps' that can be saved as a stand-
    alone HTML file, embedded in 'R Markdown' documents or in a 'Shiny' app, and
    available in the 'RStudio' viewer pane. Hover the mouse pointer over a cell to
    show details or drag a rectangle to zoom. A 'heatmap' is a popular graphical
    method for visualizing high-dimensional data, in which a table of numbers
    are encoded as a grid of colored cells. The rows and columns of the matrix
    are ordered to highlight patterns and are often accompanied by 'dendrograms'.
    'Heatmaps' are used in many fields for visualizing observations, correlations,
    missing values patterns, and more. Interactive 'heatmaps' allow the inspection
    of specific value by hovering the mouse over a cell, as well as zooming into
    a region of the 'heatmap' by dragging a rectangle around the relevant area.
    This work is based on the 'ggplot2' and 'plotly.js' engine. It produces
    similar 'heatmaps' as 'heatmap.2' or 'd3heatmap', with the advantage of speed
    ('plotly.js' is able to handle larger size matrix), the ability to zoom from
    the 'dendrogram' panes, and the placing of factor variables in the sides of the
    'heatmap'.",2020-03-28,Tal Galili,"https://talgalili.github.io/heatmaply/,
https://cran.r-project.org/package=heatmaply,
https://github.com/talgalili/heatmaply/,
https://www.r-statistics.com/tag/heatmaply/",TRUE,https://github.com/talgalili/heatmaply,184732,243,2020-05-26T13:33:08Z,760.2139917695473
heatwaveR,"The different methods of defining and detecting extreme events, known as heatwaves or cold-spells in both air and water temperature data are encompassed within this package. These detection algorithms may be used on non-temperature data as well however, this is not catered for explicitly here as no use of this technique in the literature currently exists.",2019-12-01,Robert W. Schlegel,"https://robwschlegel.github.io/heatwaveR/index.html,
https://github.com/robwschlegel/heatwaveR",TRUE,https://github.com/robwschlegel/heatwaver,10565,13,2020-06-06T21:34:24Z,812.6923076923077
heddlr,"Helper functions designed to make
    dynamically generating R Markdown documents easier by providing a
    simple and tidy way to create report pieces, shape them to your data,
    and combine them for exporting into a single R Markdown document.",2020-03-24,Michael Mahoney,"https://github.com/mikemahoney218/heddlr,
https://mikemahoney218.github.io/heddlr/",TRUE,https://github.com/mikemahoney218/heddlr,2277,10,2020-05-24T23:25:57Z,227.7
hedgehog,"Hedgehog will eat all your bugs.
  'Hedgehog' is a property-based testing package in the spirit
  of 'QuickCheck'. With 'Hedgehog', one can test properties
  of their programs against randomly generated input, providing
  far superior test coverage compared to unit testing. One of the
  key benefits of 'Hedgehog' is integrated shrinking of
  counterexamples, which allows one to quickly find the cause of
  bugs, given salient examples when incorrect behaviour occurs.",2018-08-22,Huw Campbell,https://hedgehog.qa,TRUE,https://github.com/hedgehogqa/r-hedgehog,6511,35,2020-05-03T12:12:32Z,186.02857142857144
heemod,"An implementation of the modelling and reporting features described 
    in reference textbook and guidelines (Briggs, Andrew, et al. Decision 
    Modelling for Health Economic Evaluation. Oxford Univ. Press, 2011;
    Siebert, U. et al. State-Transition Modeling. Medical Decision Making 
    32, 690-700 (2012).): deterministic and probabilistic sensitivity analysis, 
    heterogeneity analysis, time dependency on state-time and model-time 
    (semi-Markov and non-homogeneous Markov models), etc.",2020-05-11,Kevin Zarca,NA,TRUE,https://github.com/pierucci/heemod,32183,28,2020-04-20T13:07:01Z,1149.392857142857
helda,"The main focus is on preprocessing and data visualization of machine learning models performances. 
  Some functions allow to fill in gaps in time series using linear interpolation on panel data, some functions 
  permit to draw lift effect and lift curve in order to benchmark machine learning models or you can even find 
  the optimal number of clusters in agglomerative clustering algorithm.",2020-06-07,Simon Corde,https://www.github.com/Redcart/helda,TRUE,https://github.com/redcart/helda,2815,0,2020-06-07T10:34:50Z,NA
helminthR,"Access to large host-parasite data is often hampered by the 
  availability of data and difficulty in obtaining it in a programmatic way
  to encourage analyses. 'helminthR' provides a programmatic interface to the 
  London Natural History Museum's host-parasite database, one of the largest 
  host-parasite databases existing currently <http://www.nhm.ac.uk/research-curation/scientific-resources/taxonomy-systematics/host-parasites/>. The package allows the user
  to query by host species, parasite species, and geographic location.",2019-02-03,Tad Dallas,https://github.com/rOpenSci/helminthR,TRUE,https://github.com/ropensci/helminthr,7858,6,2019-12-09T21:13:00Z,1309.6666666666667
heplots,"Provides HE plot and other functions for visualizing hypothesis
    tests in multivariate linear models. HE plots represent sums-of-squares-and-
    products matrices for linear hypotheses and for error using ellipses (in two
    dimensions) and ellipsoids (in three dimensions). The related 'candisc' package
    provides visualizations in a reduced-rank canonical discriminant space when
    there are more than a few response variables.",2018-04-03,Michael Friendly,http://datavis.ca/R/index.php#heplots,TRUE,https://github.com/friendly/heplots,245238,3,2020-04-28T14:45:59Z,81746
hereR,"Interface to the 'HERE' REST APIs <https://developer.here.com/develop/rest-apis>:
  (1) geocode and autocomplete addresses or reverse geocode POIs using the 'Geocoder' API;
  (2) route directions, travel distance or time matrices and isolines using the 'Routing' API;
  (3) request real-time traffic flow and incident information from the 'Traffic' API;
  (4) find request public transport connections and nearby stations from the 'Public Transit' API;
  (5) get weather forecasts, reports on current weather conditions, astronomical
  information and alerts at a specific location from the 'Destination Weather' API.
  Locations, routes and isolines are returned as 'sf' objects.",2020-04-18,Merlin Unterfinger,"https://munterfinger.github.io/hereR/,
https://github.com/munterfinger/hereR/",TRUE,https://github.com/munterfinger/herer,5370,33,2020-06-02T10:05:56Z,162.72727272727272
hesim,"A modular and computationally efficient R package for  
  parameterizing, simulating, and analyzing health-economic simulation 
  models. The package supports cohort discrete time state transition models 
  (Briggs et al. 1998) <doi:10.2165/00019053-199813040-00003>,
  N-state partitioned survival models (Glasziou et al. 1990)
  <doi:10.1002/sim.4780091106>, and individual-level continuous 
  time state transition models (Siebert et al. 2012) <doi:10.1016/j.jval.2012.06.014>,
  encompassing both Markov (time-homogeneous and time-inhomogeneous) and 
  semi-Markov processes. Decision uncertainty from a cost-effectiveness analysis is 
  quantified with standard graphical and tabular summaries of a probabilistic 
  sensitivity analysis (Claxton et al. 2005, Barton et al. 2008) <doi:10.1002/hec.985>, 
  <doi:10.1111/j.1524-4733.2008.00358.x>. Use of C++ and data.table
  make individual-patient simulation, probabilistic sensitivity analysis, 
  and incorporation of patient heterogeneity fast.",2020-06-02,Devin Incerti,https://github.com/hesim-dev/hesim,TRUE,https://github.com/hesim-dev/hesim,10920,23,2020-06-09T03:36:20Z,474.7826086956522
hettreatreg,"Computes diagnostics for linear regression when treatment effects are heterogeneous.
    The output of 'hettreatreg' represents ordinary least squares (OLS) 
    estimates of the effect of a binary treatment as a weighted average of the average treatment effect 
    on the treated (ATT) and the average treatment effect on the untreated (ATU). 
    The program estimates the OLS weights on these parameters, computes the associated model diagnostics, 
    and reports the implicit OLS estimate of the average treatment effect (ATE). 
    See Sloczynski (2019), <http://people.brandeis.edu/~tslocz/Sloczynski_paper_regression.pdf>.",2020-05-13,Mark McAvoy,https://github.com/tslocz/hettreatreg,TRUE,https://github.com/tslocz/hettreatreg,368,1,2020-04-30T01:39:07Z,368
hettx,"Implements methods developed by Ding, Feller, and Miratrix (2016) <doi:10.1111/rssb.12124> <arXiv:1412.5000>,
    and Ding, Feller, and Miratrix (2018) <doi:10.1080/01621459.2017.1407322> <arXiv:1605.06566>
    for testing whether there is unexplained variation in treatment effects across observations, and for characterizing
    the extent of the explained and unexplained variation in treatment effects. The package includes wrapper functions
    implementing the proposed methods, as well as helper functions for analyzing and visualizing the results of the test.",2019-03-06,Ben Fifield,NA,TRUE,https://github.com/bfifield/detect_heteffects,4983,5,2020-02-08T19:56:51Z,996.6
heuristica,"Implements various heuristics like Take The Best and
    unit-weight linear, which do two-alternative choice: which of
    two objects will have a higher criterion?  Also offers functions
    to assess performance, e.g. percent correct across all row pairs
    in a data set and finding row pairs where models disagree.
    New models can be added by implementing a fit and predict function--
    see vignette.",2019-08-21,Jean Whitmore,https://github.com/jeanimal/heuristica,TRUE,https://github.com/jeanimal/heuristica,16105,4,2019-08-21T12:49:44Z,4026.25
heuristicsmineR,"Provides the heuristics miner algorithm for process discovery 
   as proposed by Weijters et al. (2011) <doi:10.1109/CIDM.2011.5949453>. The
   algorithm builds a causal net from an event log created with the 'bupaR' 
   package. Event logs are a set of ordered sequences of events for which 
   'bupaR' provides the S3 class eventlog(). The discovered causal nets 
   can be visualised as 'htmlwidgets' and it is possible to annotate them with
   the occurrence frequency or processing and waiting time of process 
   activities.  ",2020-03-29,Felix Mannhardt,https://github.com/bupaverse/heuristicsmineR,TRUE,https://github.com/bupaverse/heuristicsminer,6030,8,2020-03-29T19:02:16Z,753.75
hexbin,Binning and plotting functions for hexagonal bins.,2020-02-03,Dan Carr,http://github.com/edzer/hexbin,TRUE,https://github.com/edzer/hexbin,4751457,23,2020-02-03T13:36:16Z,206585.08695652173
hexSticker,Helper functions for creating reproducible hexagon sticker purely in R.,2020-06-01,Guangchuang Yu,https://github.com/GuangchuangYu/hexSticker,TRUE,https://github.com/guangchuangyu/hexsticker,21124,362,2020-06-01T13:25:09Z,58.353591160220994
HGNChelper,"Contains functions for
 identifying and correcting HGNC human gene symbols and MGI mouse gene symbols 
 which have been converted to date format by Excel, withdrawn, or aliased.
 Also contains functions for reversibly converting between HGNC
 symbols and valid R names.",2019-10-24,Levi Waldron and Markus Riester,https://github.com/waldronlab/HGNChelper,TRUE,https://github.com/waldronlab/hgnchelper,37420,11,2020-04-28T17:51:15Z,3401.818181818182
hgutils,"
    A handy collection of utility functions designed to aid in package development, plotting and scientific research.
    Package development functionalities includes among others tools such as cross-referencing package imports with the description file,
    analysis of redundant package imports, editing of the description file and the creation of package badges for GitHub.
    Some of the other functionalities include automatic package installation and loading, plotting points without overlap,
    creating nice breaks for plots, overview tables and many more handy utility functions.",2019-09-07,H.G. van den Boorn,https://github.com/hvdboorn/hgutils,TRUE,https://github.com/hvdboorn/hgutils,7088,0,2019-09-07T13:11:05Z,NA
HiClimR,"A tool for Hierarchical Climate Regionalization applicable to any correlation-based clustering.
             It adds several features and a new clustering method (called, 'regional' linkage) to hierarchical
             clustering in R ('hclust' function in 'stats' library): data regridding, coarsening spatial resolution,
             geographic masking, contiguity-constrained clustering, data filtering by mean and/or variance
             thresholds, data preprocessing (detrending, standardization, and PCA), faster correlation function
             with preliminary big data support, different clustering methods, hybrid hierarchical clustering,
             multivariate clustering (MVC), cluster validation, visualization of regionalization results, and
             exporting region map and mean timeseries into NetCDF-4 file.",2020-02-22,Hamada S. Badr,https://github.com/hsbadr/HiClimR,TRUE,https://github.com/hsbadr/hiclimr,27911,8,2020-02-23T08:05:29Z,3488.875
hier.part,"Partitioning of the independent and joint contributions of each
    variable in a multivariate data set, to a linear regression by hierarchical
    decomposition of goodness-of-fit measures of regressions using all subsets 
    of predictors in the data set. (i.e., model (1), (2), ..., (N), (1,2), ...,
    (1,N), ..., (1,2,3,...,N)). A Z-score based estimate of the 'importance' of
    each predictor is provided by using a randomisation test.",2020-03-03,Chris Walsh,NA,TRUE,https://github.com/cjbwalsh/hier.part,34951,0,2020-03-03T08:46:58Z,NA
hierfstat,"Allows the estimation of hierarchical F-statistics from haploid or diploid genetic data 
    with any numbers  of levels in the hierarchy, following the algorithm of Yang (Evolution, 1998, 52(4):950-956; 
    <DOI:10.2307/2411227>. Functions are also given to test via randomisations the significance of each F and variance components,  
	using the likelihood-ratio statistics G.",2015-12-04,Jerome Goudet,"http://www.r-project.org, http://github.com/jgx65/hierfstat",TRUE,https://github.com/jgx65/hierfstat,79733,11,2019-09-24T22:05:33Z,7248.454545454545
highcharter,"A wrapper for the 'Highcharts' library including
    shortcut functions to plot R objects. 'Highcharts'
    <http://www.highcharts.com/> is a charting library offering
    numerous chart types with a simple configuration syntax.",2019-01-15,Joshua Kunst,http://jkunst.com/highcharter,TRUE,https://github.com/jbkunst/highcharter,293806,530,2020-05-06T00:12:46Z,554.3509433962264
highfrequency,"Provide functionality to manage, clean and match highfrequency
    trades and quotes data, calculate various liquidity measures, estimate and
    forecast volatility, detect price jumps and investigate microstructure noise and intraday
    periodicity.",2020-04-15,Kris Boudt,https://github.com/jonathancornelissen/highfrequency,TRUE,https://github.com/jonathancornelissen/highfrequency,47840,51,2020-04-14T17:17:51Z,938.0392156862745
highlight,"Syntax highlighter for R code based on the results
    of the R parser. Rendering in HTML and latex markup. Custom Sweave
    driver performing syntax highlighting of R code chunks.",2019-12-15,Hadley Wickham,https://github.com/hadley/highlight,TRUE,https://github.com/hadley/highlight,423828,1,2019-12-16T00:28:58Z,423828
highlightHTML,"A tool to format R markdown with CSS ids for HTML output. 
    The tool may be most helpful for those using markdown to create reproducible
    documents. The biggest limitations in formatting is the knowledge of CSS
    by the document authors.",2020-04-21,Brandon LeBeau,https://github.com/lebebr01/highlightHTML,TRUE,https://github.com/lebebr01/highlighthtml,11301,4,2020-04-21T03:03:43Z,2825.25
highr,"Provides syntax highlighting for R source code. Currently it
    supports LaTeX and HTML output. Source code of other languages is supported
    via Andre Simon's highlight package (<http://www.andre-simon.de>).",2019-03-20,Yihui Xie,https://github.com/yihui/highr,TRUE,https://github.com/yihui/highr,15684850,35,2020-02-06T16:37:56Z,448138.5714285714
hilbertSimilarity,"Quantifying similarity between high-dimensional single cell samples is challenging, and usually requires
    some simplifying hypothesis to be made. By transforming the high dimensional space into a high dimensional grid,
    the number of cells in each sub-space of the grid is characteristic of a given sample. Using a Hilbert curve
    each sample can be visualized as a simple density plot, and the distance between samples can be calculated from
    the distribution of cells using the Jensen-Shannon distance. Bins that correspond to significant differences
    between samples can identified using a simple bootstrap procedure.",2019-11-11,Yann Abraham,http://github.com/yannabraham/hilbertSimilarity,TRUE,https://github.com/yannabraham/hilbertsimilarity,3022,5,2019-11-29T11:20:32Z,604.4
hilldiv,"Tools for analysing, comparing, visualising and partitioning diversity based on Hill numbers.
  'hilldiv' is an R package that provides a set of functions to assist analysis of diversity for
  diet reconstruction, microbial community profiling or more general ecosystem characterisation
  analyses based on Hill numbers, using OTU/ASV tables and associated phylogenetic trees as
  inputs. The package includes functions for (phylo)diversity measurement, (phylo)diversity
  profile plotting, (phylo)diversity comparison between samples and groups, (phylo)diversity
  partitioning and (dis)similarity measurement. All of these grounded in abundance-based and
  incidence-based Hill numbers.
  The statistical framework developed around Hill numbers encompasses many of the most
  broadly employed diversity (e.g. richness, Shannon index, Simpson index),
  phylogenetic diversity (e.g. Faith's PD, Allen's H, Rao's quadratic entropy) and
  dissimilarity (e.g. Sorensen index, Unifrac distances) metrics. This enables the most
  common analyses of diversity to be performed while grounded in a single statistical
  framework. The methods are described in Jost et al. (2007) <DOI:10.1890/06-1736.1>,
  Chao et al. (2010) <DOI:10.1098/rstb.2010.0272> and Chiu et al. (2014)
  <DOI:10.1890/12-0960.1>; and reviewed in the framework of molecularly characterised
  biological systems in Alberdi & Gilbert (2019) <DOI:10.1111/1755-0998.13014>.",2019-10-01,Antton Alberdi,https://github.com/anttonalberdi/hilldiv,TRUE,https://github.com/anttonalberdi/hilldiv,3399,1,2020-05-10T08:11:36Z,3399
hillR,"Calculate taxonomic, functional and phylogenetic diversity measures 
    through Hill Numbers proposed by Chao, Chiu and Jost (2014) 
    <doi:10.1146/annurev-ecolsys-120213-091540>.",2018-11-19,Daijiang Li,https://github.com/daijiang/hillR,TRUE,https://github.com/daijiang/hillr,7206,13,2020-05-22T15:40:45Z,554.3076923076923
hIRT,"Implementation of a class of hierarchical item response
  theory (IRT) models where both the mean and the variance of latent preferences
  (ability parameters) may depend on observed covariates. The current
  implementation includes both the two-parameter latent trait model for binary data and the
  graded response model for ordinal data. Both are fitted via the Expectation-Maximization (EM)
  algorithm. Asymptotic standard errors are derived from the observed information
  matrix.",2020-03-26,Xiang Zhou,http://github.com/xiangzhou09/hIRT,TRUE,https://github.com/xiangzhou09/hirt,11139,2,2020-04-01T19:00:51Z,5569.5
historydata,"These sample data sets are intended for historians
    learning R. They include population, institutional, religious,
    military, and prosopographical data suitable for mapping,
    quantitative analysis, and network analysis.",2014-12-24,Lincoln Mullen,https://github.com/ropensci/historydata,TRUE,https://github.com/ropensci/historydata,21698,65,2019-12-09T13:21:09Z,333.81538461538463
HiveR,"Creates and plots 2D and 3D hive plots. Hive plots are a unique method of displaying networks of many types in which node properties are mapped to axes using meaningful properties rather than being arbitrarily positioned.  The hive plot concept was invented by Martin Krzywinski at the Genome Science Center (www.hiveplot.net/).  Keywords: networks, food webs, linnet, systems biology, bioinformatics.",2020-06-09,Bryan A. Hanson,https://github.com/bryanhanson/HiveR,TRUE,https://github.com/bryanhanson/hiver,30972,62,2020-06-09T14:22:28Z,499.5483870967742
hJAM,"Provides functions to implement a hierarchical approach which is designed to perform joint analysis of summary statistics using the framework of Mendelian Randomization or transcriptome analysis. Reference: Lai Jiang, Shujing Xu, Nicholas Mancuso, Paul J. Newcombe, David V. Conti (2020). ""A Hierarchical Approach Using Marginal Summary Statistics for Multiple Intermediates in a Mendelian Randomization or Transcriptome Analysis."" <bioRxiv><doi:10.1101/2020.02.03.924241>.",2020-02-20,Lai Jiang,https://github.com/lailylajiang/hJAM,TRUE,https://github.com/lailylajiang/hjam,1781,5,2020-05-18T05:03:51Z,356.2
HLMdiag,"A suite of diagnostic tools for hierarchical
    (multilevel) linear models. The tools include
    not only leverage and traditional deletion diagnostics (Cook's
    distance, covratio, covtrace, and MDFFITS) but also 
    convenience functions and graphics for residual analysis. Models
    can be fit using either lmer in the 'lme4' package or lme in the 'nlme' package,
    but only two-level models fit using lme are currently supported.",2015-12-12,Adam Loy,https://github.com/aloy/HLMdiag,TRUE,https://github.com/aloy/hlmdiag,34893,9,2020-02-19T17:02:21Z,3877
HMDHFDplus,"Utilities for reading data from the Human Mortality Database (<https://www.mortality.org>), Human Fertility Database (<https://www.humanfertility.org>), and similar databases from the web or locally into an R session as data.frame objects. These are the two most widely used sources of demographic data to study basic demographic change, trends, and develop new demographic methods. Other supported databases at this time include the Human Fertility Collection (<http://www.fertilitydata.org/>), The Japanese Mortality Database (<http://www.ipss.go.jp/p-toukei/JMD>), and the Canadian Human Mortality Database (<http://www.bdlc.umontreal.ca/chmd/>). Arguments and data are standardized.",2020-02-20,Tim Riffe,https://github.com/timriffe/TR1,TRUE,https://github.com/timriffe/tr1,18658,1,2020-02-20T08:04:31Z,18658
hmi,"Runs single level and multilevel imputation models. The user just has to pass the data to the main function and, optionally, his analysis model. Basically the package then translates this analysis model into commands to impute the data according to it with functions from 'mice', 'MCMCglmm' or routines build for this package.",2020-05-03,Matthias Speidel  (Munich,http://github.com/matthiasspeidel/hmi,TRUE,https://github.com/matthiasspeidel/hmi,22451,3,2020-05-03T16:00:04Z,7483.666666666667
Hmisc,"Contains many functions useful for data
	analysis, high-level graphics, utility operations, functions for
	computing sample size and power, importing and annotating datasets,
	imputing missing values, advanced table making, variable clustering,
	character string manipulation, conversion of R objects to LaTeX and html code,
	and recoding variables.",2020-03-23,Frank E Harrell Jr,"http://biostat.mc.vanderbilt.edu/Hmisc,
https://github.com/harrelfe/Hmisc",TRUE,https://github.com/harrelfe/hmisc,9408907,151,2020-05-28T19:12:43Z,62310.64238410596
hms,"Implements an S3 class for storing and formatting time-of-day
    values, based on the 'difftime' class.",2020-01-08,Kirill Müller,"https://hms.tidyverse.org/, https://github.com/tidyverse/hms",TRUE,https://github.com/tidyverse/hms,14635755,111,2020-01-07T16:19:41Z,131853.64864864864
Hmsc,"Hierarchical Modelling of Species Communities (HMSC) is
   a model-based approach for analyzing community ecological data. 
   This package implements it in the Bayesian framework with Gibbs
   Markov chain Monte Carlo (MCMC) sampling.",2020-03-19,Otso Ovaskainen,https://www.helsinki.fi/en/researchgroups/statistical-ecology/hmsc,TRUE,https://github.com/hmsc-r/hmsc,5572,38,2020-06-09T13:21:43Z,146.6315789473684
hoardr,"Suite of tools for managing cached files, targeting
    use in other R packages. Uses 'rappdirs' for cross-platform paths.
    Provides utilities to manage cache directories, including targeting
    files by path or by key; cached directories can be compressed and
    uncompressed easily to save disk space.",2018-12-02,Scott Chamberlain,https://github.com/ropensci/hoardr,TRUE,https://github.com/ropensci/hoardr,63438,17,2020-03-10T18:39:49Z,3731.6470588235293
holodeck,"Provides pipe-friendly (%>%) wrapper functions for MASS::mvrnorm() to create simulated multivariate data sets
    with groups of variables with different degrees of variance, covariance, and effect size. ",2020-05-26,Eric Scott,https://github.com/Aariq/holodeck,TRUE,https://github.com/aariq/holodeck,4568,7,2020-05-25T22:59:44Z,652.5714285714286
homologene,"A wrapper for the homologene database by the National Center for
    Biotechnology Information ('NCBI'). It allows searching for gene homologs across 
    species. Data in this package can be found at <ftp://ftp.ncbi.nih.gov/pub/HomoloGene/build68/>.
    The package also includes an updated version of the homologene database where 
    gene identifiers and symbols are replaced with their latest (at the time of
    submission) version and functions to fetch latest annotation data to keep updated.",2019-03-28,Ogan Mancarci,https://github.com/oganm/homologene,TRUE,https://github.com/oganm/homologene,8594,15,2020-06-07T13:48:53Z,572.9333333333333
homomorpheR,"Homomorphic computations in R for privacy-preserving applications. Currently only
             the Paillier Scheme is implemented.",2019-01-23,Balasubramanian Narasimhan,http://github.com/bnaras/homomorpheR,TRUE,https://github.com/bnaras/homomorpher,14208,4,2019-10-24T16:04:42Z,3552
hpackedbubble,"By binding R functions and the 'Highcharts' <http://www.highcharts.com/> charting library, 'hpackedbubble' package provides a simple way to draw split packed bubble charts.",2019-08-19,Zhenxing Cheng,https://github.com/czxa/hpackedbubble,TRUE,https://github.com/czxa/hpackedbubble,4753,30,2020-05-14T08:24:56Z,158.43333333333334
hR,Transform and analyze workforce data in meaningful ways for human resources (HR) analytics.,2019-11-10,Dale Kube,NA,TRUE,https://github.com/dalekube/hr,12622,4,2020-02-13T16:18:01Z,3155.5
hrbrthemes,"A compilation of extra 'ggplot2' themes, scales and utilities, including a 
    spell check function for plot label fields and an overall emphasis on typography. 
    A copy of the 'Google' font 'Roboto Condensed' <https://github.com/google/roboto/> 
    is also included along with a copy of the 'IBM' 'Plex Sans' <https://github.com/IBM/type>,
    'Titillium Web' <https://fonts.google.com/specimen/Titillium+Web>, and
    'Public Sans' <https://github.com/uswds/public-sans/> fonts
    are also included to support their respective typography-oriented themes.",2020-03-06,Bob Rudis,http://github.com/hrbrmstr/hrbrthemes,TRUE,https://github.com/hrbrmstr/hrbrthemes,221631,739,2020-03-05T19:54:04Z,299.9066305818674
hrcomprisk,Nonparametric cumulative-incidence based estimation of the ratios of sub-hazard ratios to cause-specific hazard ratios using the approach from Ng et al. (2020).,2020-01-21,Daniel Antiporta,https://github.com/AntiportaD/hrcomprisk,TRUE,https://github.com/antiportad/hrcomprisk,2373,0,2020-01-23T14:35:03Z,NA
HRM,"Methods for testing main and interaction effects in possibly
    high-dimensional parametric or nonparametric repeated measures in factorial designs for univariate or multivariate data.
    The observations of the subjects are assumed to be multivariate normal if using the parametric test.
    The nonparametric version tests with regard to nonparametric relative effects (based on pseudo-ranks).
    It is possible to use up to 2 whole- and 3 subplot factors.",2020-02-06,Martin Happ,http://github.com/happma/HRM,TRUE,https://github.com/happma/hrm,22747,0,2020-02-06T09:24:58Z,NA
hSDM,"User-friendly and fast set of functions for estimating parameters of hierarchical Bayesian species distribution models (Latimer et al. 2006 <doi:10.1890/04-0609>). Such models allow interpreting the observations (occurrence and abundance of a species) as a result of several hierarchical processes including ecological processes (habitat suitability, spatial dependence and anthropogenic disturbance) and observation processes (species detectability). Hierarchical species distribution models are essential for accurately characterizing the environmental response of species, predicting their probability of occurrence, and assessing uncertainty in the model results.",2019-05-12,Ghislain Vieilledent,"https://ecology.ghislainv.fr/hSDM,
https://github.com/ghislainv/hSDM",TRUE,https://github.com/ghislainv/hsdm,17924,4,2020-04-19T08:55:58Z,4481
hsstan,"Linear and logistic regression models penalized with hierarchical
  shrinkage priors for selection of biomarkers (or more general variable
  selection), which can be fitted using Stan (Carpenter et al. (2017)
  <doi:10.18637/jss.v076.i01>). It implements the horseshoe and regularized
  horseshoe priors (Piironen and Vehtari (2017) <doi:10.1214/17-EJS1337SI>),
  as well as the projection predictive selection approach to recover a sparse
  set of predictive biomarkers (Piironen, Paasiniemi and Vehtari (2018)
  <arXiv:1810.02406>).",2020-05-01,Marco Colombo,https://github.com/mcol/hsstan,TRUE,https://github.com/mcol/hsstan,2692,2,2020-05-01T14:28:42Z,1346
HTLR,"Efficient Bayesian multinomial logistic regression based on heavy-tailed
  (hyper-LASSO, non-convex) priors. The posterior of coefficients and hyper-parameters
  is sampled with restricted Gibbs sampling for leveraging the high-dimensionality and
  Hamiltonian Monte Carlo for handling the high-correlation among coefficients. A detailed
  description of the method: Li and Yao (2018), 
  Journal of Statistical Computation and Simulation, 88:14, 2827-2851, <arXiv:1405.3319>.",2020-01-17,Longhai Li,https://longhaisk.github.io/HTLR/,TRUE,https://github.com/longhaisk/htlr,3792,4,2020-03-22T04:45:45Z,948
htmlTable,"Tables with state-of-the-art layout elements such as row spanners,
    column spanners, table spanners, zebra striping, and more. While allowing
    advanced layout, the underlying css-structure is simple in order to maximize
    compatibility with word processors such as 'MS Word' or 'LibreOffice'. The package
    also contains a few text formatting functions that help outputting text
    compatible with HTML/LaTeX.",2019-12-04,Max Gordon,http://gforge.se/packages/,TRUE,https://github.com/gforge/htmltable,5254877,62,2019-12-05T21:20:46Z,84756.08064516129
htmltools,Tools for HTML generation and output.,2019-10-04,RStudio,https://github.com/rstudio/htmltools,TRUE,https://github.com/rstudio/htmltools,18420721,81,2020-04-21T19:06:18Z,227416.3086419753
htmlwidgets,"A framework for creating HTML widgets that render in various
    contexts including the R console, 'R Markdown' documents, and 'Shiny'
    web applications.",2019-10-08,Joe Cheng,https://github.com/ramnathv/htmlwidgets,TRUE,https://github.com/ramnathv/htmlwidgets,11398929,656,2020-05-23T18:46:25Z,17376.416158536584
hts,"Provides methods for analysing and forecasting hierarchical and 
    grouped time series. The available forecast methods include bottom-up,
    top-down, optimal combination reconciliation (Hyndman et al. 2011) 
    <doi:10.1016/j.csda.2011.03.006>, and trace minimization reconciliation
    (Wickramasuriya et al. 2018) <doi:10.1080/01621459.2018.1448825>.",2020-04-03,Rob Hyndman,http://pkg.earo.me/hts,TRUE,https://github.com/earowang/hts,195744,90,2020-04-03T22:49:57Z,2174.9333333333334
httk,"Functions and data tables for simulation and statistical analysis 
             of chemical toxicokinetics (""TK"") as in Pearce et al. (2017) 
             <doi:10.18637/jss.v079.i04>. Chemical-specific in vitro 
             data have been obtained from relatively high throughput 
             experiments. Both physiologically-based (""PBTK"") and empirical 
             (e.g., one compartment) ""TK"" models can be parameterized for 
             several hundred chemicals and multiple species. These models are 
             solved efficiently, often using compiled (C-based) code. A Monte 
             Carlo sampler is included for simulating biological variability 
             (Ring et al., 2017 <doi:10.1016/j.envint.2017.06.004>) 
             and measurement limitations. Calibrated methods are included for 
             predicting tissue:plasma partition coefficients and volume of 
             distribution 
             (Pearce et al., 2017 <doi:10.1007/s10928-017-9548-7>). 
             These functions and data provide a set of tools for 
             in vitro-in vivo extrapolation (""IVIVE"") of high throughput 
             screening data (e.g., Tox21, ToxCast) to real-world exposures via 
             reverse dosimetry (also known as ""RTK"") 
             (Wetmore et al., 2015 <doi:10.1093/toxsci/kfv171>).",2020-03-02,John Wambaugh,https://www.epa.gov/chemical-research/rapid-chemical-exposure-and-dose-research,TRUE,https://github.com/usepa/comptox-expocast-httk,29376,6,2020-03-01T20:15:58Z,4896
httpcode,"Find and explain the meaning of 'HTTP' status codes.
    Functions included for searching for codes by full or partial number,
    by message, and get appropriate dog and cat images for many
    status codes.",2020-04-10,Scott Chamberlain,https://github.com/sckott/httpcode,TRUE,https://github.com/sckott/httpcode,279420,7,2020-04-10T15:52:07Z,39917.142857142855
httptest,"Testing and documenting code that communicates with remote servers
    can be painful. Dealing with authentication, server state,
    and other complications can make testing seem too costly to
    bother with. But it doesn't need to be that hard. This package enables one
    to test all of the logic on the R sides of the API in your package without
    requiring access to the remote service. Importantly, it provides three
    contexts that mock the network connection in different ways, as well as
    testing functions to assert that HTTP requests were---or were
    not---made. It also allows one to safely record real API responses to use as
    test fixtures. The ability to save responses and load them offline also
    enables one to write vignettes and other dynamic documents that can be
    distributed without access to a live server.",2020-01-28,Neal Richardson,"https://enpiar.com/r/httptest,
https://github.com/nealrichardson/httptest",TRUE,https://github.com/nealrichardson/httptest,51485,61,2020-01-28T21:57:11Z,844.016393442623
httpuv,"Provides low-level socket and protocol support for handling
    HTTP and WebSocket requests directly from within R. It is primarily
    intended as a building block for other packages, rather than making it
    particularly easy to create complete web applications using httpuv alone.
    httpuv is built on top of the libuv and http-parser C libraries, both of
    which were developed by Joyent, Inc. (See LICENSE file for libuv and
    http-parser license information.)",2020-06-06,Winston Chang,https://github.com/rstudio/httpuv,TRUE,https://github.com/rstudio/httpuv,12374948,160,2020-06-08T17:20:48Z,77343.425
httr,"Useful tools for working with HTTP organised by
    HTTP verbs (GET(), POST(), etc). Configuration functions make it easy
    to control additional request components (authenticate(),
    add_headers() and so on).",2019-08-05,Hadley Wickham,"https://httr.r-lib.org/, https://github.com/r-lib/httr",TRUE,https://github.com/r-lib/httr,17350875,846,2020-05-28T15:28:45Z,20509.308510638297
hues,"Creating effective colour palettes for figures is 
    challenging. This package generates and plot palettes of optimally 
    distinct colours in perceptually uniform colour space, based on 
    'iwanthue' <http://tools.medialab.sciences-po.fr/iwanthue/>. 
    This is done through k-means clustering of CIE Lab colour space, 
    according to user-selected constraints on hue, chroma, and 
    lightness.",2019-12-01,John Baumgartner,https://github.com/johnbaums/hues,TRUE,https://github.com/johnbaums/hues,10063,19,2019-12-01T20:48:21Z,529.6315789473684
humidity,"Vapor pressure, relative humidity, absolute humidity, specific humidity, and mixing ratio are commonly used water vapor measures in meteorology. This R package provides functions for calculating saturation vapor pressure (hPa), partial water vapor pressure (Pa), relative humidity (%), absolute humidity (kg/m^3), specific humidity (kg/kg), and mixing ratio (kg/kg) from temperature (K) and dew point (K). Conversion functions between humidity measures are also provided.",2019-11-10,Jun Cai,https://github.com/caijun/humidity,TRUE,https://github.com/caijun/humidity,13549,0,2019-11-10T07:04:14Z,NA
HURDAT,"Scraped dataset of the Hurricane Research Division's Hurricane 
    Re-Analysis Project known as HURDAT. Storm details are available for most 
    known hurricanes and tropical storms for the Atlantic and northeastern 
    Pacific ocean (northwestern hemisphere). See <http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html> 
    for more information.",2020-01-28,Tim Trice,https://github.com/timtrice/HURDAT,TRUE,https://github.com/timtrice/hurdat,11419,7,2019-07-17T19:31:28Z,1631.2857142857142
hurricaneexposure,"Allows users to create time series of tropical storm
    exposure histories for chosen counties for a number of hazard metrics
    (wind, rain, distance from the storm, etc.). This package interacts
    with data available through the 'hurricaneexposuredata' package, which
    is available in a 'drat' repository. To access this data package, see the 
    instructions at <https://github.com/geanders/hurricaneexposure>. 
    The size of the 'hurricaneexposuredata' package is
    approximately 20 MB. This work was supported in part by grants from the National
    Institute of Environmental Health Sciences (R00ES022631), the National Science
    Foundation (1331399), and a NASA Applied Sciences Program/Public Health Program
    Grant (NNX09AV81G).",2020-02-13,Brooke Anderson,https://github.com/geanders/hurricaneexposure,TRUE,https://github.com/geanders/hurricaneexposure,10811,19,2020-02-12T16:49:05Z,569
hutils,"Provides utility functions for, and drawing on, the 'data.table' package. The package also collates useful miscellaneous functions extending base R not available elsewhere. The name is a portmanteau of 'utils' and the author.",2019-10-05,Hugh Parsonage,"https://github.com/hughparsonage/hutils,
https://hughparsonage.github.io/hutils/",TRUE,https://github.com/hughparsonage/hutils,33416,3,2019-10-05T13:09:09Z,11138.666666666666
hutilscpp,"Provides utility functions that are simply, frequently used, 
    but may require higher performance that what can be obtained from base R.
    Incidentally provides support for 'reverse geocoding', such as matching a point
    with its nearest neighbour in another array. Used as a complement to package
    'hutils' by sacrificing compilation or installation time for higher running 
    speeds. The name is a portmanteau of the author and 'Rcpp'.",2019-10-16,Hugh Parsonage,https://github.com/hughparsonage/hutilscpp,TRUE,https://github.com/hughparsonage/hutilscpp,6543,4,2020-05-02T05:04:09Z,1635.75
huxtable,"Like 'xtable', creates styled tables. Export to HTML, LaTeX, 'Word', 
  'Excel', 'PowerPoint' and RTF. Simple, modern interface to manipulate 
  borders, size, position, captions, colours, text styles and number formatting.
  Table cells can span multiple rows and/or columns.
  Includes  a 'huxreg' function for creation of regression tables, and 'quick_*' 
  one-liners to print data to a new document.",2020-01-08,David Hugh-Jones,https://hughjonesd.github.io/huxtable,TRUE,https://github.com/hughjonesd/huxtable,91547,242,2020-06-05T12:29:33Z,378.29338842975204
hwig,"The half-weight index gregariousness (HWIG) is an association 
             index used in social network analyses. It extends the half-weight 
             association index (HWI), correcting for level of gregariousness 
             in individuals. It is calculated using group by individual 
             data according to methods described in Godde et al. (2013) 
             <doi:10.1016/j.anbehav.2012.12.010>. ",2020-04-16,Alec L. Robitaille,"https://gitlab.com/robit.a/hwig, https://github.com/robitalec/hwig",TRUE,https://github.com/robitalec/hwig,792,0,2020-05-12T17:07:17Z,NA
hwordcloud,"Provides a way to display word clouds in R. The word cloud is a html widget, so you can use it in interactive documents and 'shiny' applications.",2019-08-07,Zhenxing Cheng,https://github.com/czxa/hwordcloud,TRUE,https://github.com/czxa/hwordcloud,4468,12,2019-12-20T09:00:16Z,372.3333333333333
hybridModels,"Simulates stochastic hybrid models for transmission of infectious
    diseases in dynamic networks. It is a metapopulation model in which each
    node in the network is a sub-population and disease spreads within nodes
    and among them, combining two approaches: stochastic simulation algorithm
    or its approximations (Gillespie DT (2007)
    <doi:10.1146/annurev.physchem.58.032806.104637>) and individual-based
    approach, respectively. Movement among nodes are data based and can be
    irregular. Equations that models spread within nodes are customizable and
    there are two link types among nodes: migration and influence (commuting).",2020-04-16,Fernando S. Marques,https://github.com/fernandosm/hybridModels,TRUE,https://github.com/fernandosm/hybridmodels,14113,0,2020-04-16T02:44:06Z,NA
HydeNet,"Facilities for easy implementation of hybrid Bayesian networks
    using R. Bayesian networks are directed acyclic graphs representing joint
    probability distributions, where each node represents a random variable and
    each edge represents conditionality. The full joint distribution is therefore
    factorized as a product of conditional densities, where each node is assumed
    to be independent of its non-descendents given information on its parent nodes.
    Since exact, closed-form algorithms are computationally burdensome for inference
    within hybrid networks that contain a combination of continuous and discrete
    nodes, particle-based approximation techniques like Markov Chain Monte Carlo
    are popular. We provide a user-friendly interface to constructing these networks
    and running inference using the 'rjags' package. Econometric analyses (maximum
    expected utility under competing policies, value of information) involving
    decision and utility nodes are also supported.",2020-05-15,Jarrod E. Dalton,"https://github.com/nutterb/HydeNet,",TRUE,https://github.com/nutterb/hydenet,21275,15,2020-05-15T12:42:35Z,1418.3333333333333
hydroGOF,"S3 functions implementing both statistical and graphical goodness-of-fit measures between observed and simulated values, mainly oriented to be used during the calibration, validation, and application of hydrological models. Missing values in observed and/or simulated values can be removed before computations. Comments / questions / collaboration of any kind are very welcomed.",2020-03-12,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/hydroGOF,TRUE,https://github.com/hzambran/hydrogof,120094,15,2020-05-01T16:43:50Z,8006.266666666666
hydroPSO,"State-of-the-art version of the Particle Swarm Optimisation (PSO) algorithm (SPSO-2011 and SPSO-2007 capable). hydroPSO can be used as a replacement of the 'optim' R function for (global) optimization of non-smooth and non-linear functions. However, the main focus of hydroPSO is the calibration of environmental and other real-world models that need to be executed from the system console. hydroPSO is model-independent, allowing the user to easily interface any computer simulation model with the calibration engine (PSO). hydroPSO  communicates with the model through the model's own input and output files, without requiring access to the model's source code. Several PSO variants and controlling options are included to fine-tune the performance of the calibration engine to different calibration problems. An advanced sensitivity analysis function together with user-friendly plotting summaries facilitate the interpretation and assessment of the calibration results. hydroPSO is parallel-capable, to alleviate the computational burden of complex models with ""long"" execution time. Bugs reports/comments/questions are very welcomed (in English, Spanish or Italian). See Zambrano-Bigiarini and Rojas (2013) <doi:10.1016/j.envsoft.2013.01.004> for more details.",2020-04-29,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/hydroPSO,TRUE,https://github.com/hzambran/hydropso,28438,15,2020-05-02T18:23:58Z,1895.8666666666666
hydroscoper,"R interface to the Greek National Data Bank for Hydrological and 
    Meteorological Information <http://www.hydroscope.gr/>. It covers 
    Hydroscope's data sources and provides functions to transliterate, 
    translate and download them into tidy dataframes.",2020-03-07,Konstantinos Vantas,"https://github.com/ropensci/hydroscoper,
https://docs.ropensci.org/hydroscoper/",TRUE,https://github.com/ropensci/hydroscoper,11425,10,2020-03-07T17:30:09Z,1142.5
hydrostats,Calculates a suite of hydrologic indices for daily time series data that are widely used in hydrology and stream ecology.,2019-05-05,Nick Bond,https://github.com/nickbond/hydrostats,TRUE,https://github.com/nickbond/hydrostats,24248,12,2019-11-30T06:14:44Z,2020.6666666666667
hydroTSM,"S3 functions for management, analysis, interpolation and plotting of time series used in hydrology and related environmental sciences. In particular, this package is highly oriented to hydrological modelling tasks. The focus of this package has been put in providing a collection of tools useful for the daily work of hydrologists (although an effort was made to optimise each function as much as possible, functionality has had priority over speed). Bugs / comments / questions / collaboration of any kind are very welcomed, and in particular, datasets that can be included in this package for academic purposes.",2020-03-11,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/hydroTSM,TRUE,https://github.com/hzambran/hydrotsm,127237,13,2020-03-14T00:07:41Z,9787.461538461539
hyfo,"Focuses on data processing and visualization in hydrology and
    climate forecasting. Main function includes data extraction, data downscaling,
    data resampling, gap filler of precipitation, bias correction of forecasting
    data, flexible time series plot, and spatial map generation. It is a good pre-
    processing and post-processing tool for hydrological and hydraulic modellers.",2020-04-04,Yuanchao Xu,https://yuanchao-xu.github.io/hyfo/,TRUE,https://github.com/yuanchao-xu/hyfo,17133,9,2020-04-03T18:14:04Z,1903.6666666666667
hyper2,A suite of routines for the hyperdirichlet distribution; supersedes the 'hyperdirichlet' package.,2019-05-16,Robin K. S. Hankin,https://github.com/RobinHankin/hyper2.git,TRUE,https://github.com/robinhankin/hyper2,13406,1,2020-06-09T02:29:38Z,13406
HypergeoMat,"Evaluates the hypergeometric functions of a matrix argument, which appear in random matrix theory. This is an implementation of Koev & Edelman's algorithm (2006) <doi:10.1090/S0025-5718-06-01824-2>. ",2019-10-26,Stéphane Laurent,https://github.com/stla/HypergeoMat,TRUE,https://github.com/stla/hypergeomat,3518,0,2019-10-26T12:38:17Z,NA
hyperSpec,"Comfortable ways to work with hyperspectral data sets.
    I.e. spatially or time-resolved spectra, or spectra with any other kind
    of information associated with each of the spectra. The spectra can be data
    as obtained in XRF, UV/VIS, Fluorescence, AES, NIR, IR, Raman, NMR, MS,
    etc. More generally, any data that is recorded over a discretized variable,
    e.g. absorbance = f (wavelength), stored as a vector of absorbance values
    for discrete wavelengths is suitable.",2020-05-29,Claudia Beleites,https://github.com/cbeleites/hyperSpec,TRUE,https://github.com/cbeleites/hyperspec,45324,14,2020-06-09T15:27:10Z,3237.4285714285716
hypothesisr,"Interact with the application programming interface for the web
    annotation service 'Hypothes.is' (See <http://hypothes.is> for more
    information.) Allows users to download data about public annotations, and
    create, retrieve, update, and delete their own annotations.",2016-07-01,Matthew Lincoln,https://github.com/mdlincoln/hypothesisr,TRUE,https://github.com/mdlincoln/hypothesisr,11637,14,2019-08-29T20:13:08Z,831.2142857142857
hypr,"Translation between experimental null hypotheses, hypothesis matrices, and contrast matrices as used in linear regression models. The package is based on the method described in Schad, Vasishth, Hohenstein, and Kliegl (2019) <doi:10.1016/j.jml.2019.104038> and Rabe, Vasishth, Hohenstein, Kliegl, and Schad (2020) <doi:10.21105/joss.02134>.",2020-05-27,Maximilian M. Rabe,https://maxrabe.com/hypr,TRUE,https://github.com/mmrabe/hypr,3917,1,2020-05-27T15:07:53Z,3917
hystReet,An R API wrapper for the 'Hystreet' project <https://hystreet.com>. 'Hystreet' provides pedestrian counts in different cities in Germany.,2020-04-01,Johannes Friedrich,https://github.com/JohannesFriedrich/hystReet,TRUE,https://github.com/johannesfriedrich/hystreet,1073,5,2020-04-23T21:08:48Z,214.6
ibb,Call wrappers for Istanbul Metropolitan Municipality's Open Data Portal (Turkish: İstanbul Büyükşehir Belediyesi Açık Veri Portalı) at <https://data.ibb.gov.tr/en/>.,2020-05-11,Berk Orbay,https://github.com/berkorbay/ibb,TRUE,https://github.com/berkorbay/ibb,421,0,2020-05-10T20:42:45Z,NA
ibmsunburst,"Generates Personality Insights sunburst diagrams
    based on 'IBM Watson' Personality Insights service output.",2019-01-14,Steph Locke,"https://github.com/lockedata/ibmsunburst,
https://lockedata.github.io/ibmsunburst/",TRUE,https://github.com/lockedata/ibmsunburst,6423,4,2019-10-18T21:28:04Z,1605.75
iBreakDown,"Model agnostic tool for decomposition of predictions from black boxes.
    Supports additive attributions and attributions with interactions.
    The Break Down Table shows contributions of every variable to a final prediction. 
    The Break Down Plot presents variable contributions in a concise graphical way. 
    This package works for classification and regression models. 
    It is an extension of the 'breakDown' package (Staniak and Biecek 2018) <doi:10.32614/RJ-2018-072>,
    with new and faster strategies for orderings. 
    It supports interactions in explanations and has interactive visuals (implemented with 'D3.js' library). 
    The methodology behind is described in the 'iBreakDown' article (Gosiewska and Biecek 2019) <arXiv:1903.11420>
    This package is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.",2020-04-20,Przemyslaw Biecek,"https://ModelOriented.github.io/iBreakDown/,
https://github.com/ModelOriented/iBreakDown",TRUE,https://github.com/modeloriented/ibreakdown,17738,48,2020-05-14T09:35:26Z,369.5416666666667
ICAMS,"Analysis and visualization of experimentally elucidated mutational
    signatures -- the kind of analysis and visualization in Boot et al.,
    ""In-depth characterization of the cisplatin mutational signature in 
    human cell lines and in esophageal and liver tumors"", Genome Research 2018, 
    <doi:10.1101/gr.230219.117>. 'ICAMS' stands for In-depth Characterization 
    and Analysis of Mutational Signatures. 'ICAMS' has functions to read in 
    variant call files (VCFs) and to collate the corresponding catalogs of 
    mutational spectra and to analyze and plot catalogs of mutational spectra
    and signatures. Handles both ""counts-based"" and ""density-based"" catalogs
    of mutational spectra or signatures.",2020-04-21,Steve Rozen,https://github.com/steverozen/ICAMS,TRUE,https://github.com/steverozen/icams,3997,3,2020-06-03T04:07:20Z,1332.3333333333333
iccbeta,"A function and vignettes for computing an intraclass correlation
    described in Aguinis & Culpepper (2015) <doi:10.1177/1094428114563618>.
    This package quantifies the share of variance in a dependent variable that
    is attributed to group heterogeneity in slopes.",2019-01-28,Steven Andrew Culpepper,https://github.com/tmsalab/iccbeta,TRUE,https://github.com/tmsalab/iccbeta,18408,1,2019-11-06T01:18:38Z,18408
icd,"Calculate comorbidities, medical risk scores, and
    work very quickly and precisely with ICD-9 and ICD-10 codes. This
    package enables a work flow from raw tables of ICD codes in hospital
    databases to comorbidities. ICD-9 and ICD-10 comorbidity mappings from
    Quan (Deyo and Elixhauser versions), Elixhauser and AHRQ included.
    Common ambiguities and code formats are handled. Comorbidity
    computation includes Hierarchical Condition Codes, and an
    implementation of AHRQ Clinical Classifications. Risk scores include
    those of Charlson and van Walraven.  US Clinical Modification, Word
    Health Organization, Belgian and French ICD-10 codes are supported,
    most of which are downloaded on demand.",2020-05-31,Jack O. Wasey,https://jackwasey.github.io/icd/,TRUE,https://github.com/jackwasey/icd,32754,165,2020-05-30T18:49:48Z,198.5090909090909
ICD10gm,"Provides convenient access to the German modification of the International Classification of Diagnoses, 10th revision (ICD-10-GM). It provides functionality to aid in the identification, specification and historisation of ICD-10 codes. Its intended use is the analysis of routinely collected data in the context of epidemiology, medical research and health services research. The underlying metadata are released by the German Institute for Medical Documentation and Information <https://www.dimdi.de>, and are redistributed in accordance with their license.",2020-04-14,Ewan Donnachie,"https://edonnachie.github.io/ICD10gm,
https://doi.org/10.5281/zenodo.2542833",TRUE,https://github.com/edonnachie/icd10gm,5583,1,2020-04-14T13:06:02Z,5583
iCellR,"A toolkit that allows scientists to work with data from single cell sequencing technologies such as scRNA-seq, scVDJ-seq and CITE-Seq. Single (i) Cell R package ('iCellR') provides unprecedented flexibility at every step of the analysis pipeline, including normalization, clustering, dimensionality reduction, imputation, visualization, and so on. Users can design both unsupervised and supervised models to best suit their research. In addition, the toolkit provides 2D and 3D interactive visualizations, differential expression analysis, filters based on cells, genes and clusters, data merging, normalizing for dropouts, data imputation methods, correcting for batch differences, pathway analysis, tools to find marker genes for clusters and conditions, predict cell types and pseudotime analysis. See Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.05.05.078550>  and Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.03.31.019109> for more details.",2020-05-08,Alireza Khodadadi-Jamayran,https://github.com/rezakj/iCellR,TRUE,https://github.com/rezakj/icellr,7124,48,2020-06-09T18:32:05Z,148.41666666666666
icesVocab,"R interface to access the RECO POX web services of the ICES 
  (International Council for the Exploration of the Sea) Vocabularies database 
  <https://vocab.ices.dk/services/POX.aspx>.",2019-03-12,Colin Millar,https://vocab.ices.dk/services/POX.aspx,TRUE,https://github.com/ices-tools-prod/icesvocab,12119,3,2020-05-25T21:23:50Z,4039.6666666666665
iCiteR,"A minimal wrapper around the NIH's 'iCite' API (<https://icite.od.nih.gov/api>). 
  Given a vector of pubmed IDs, this package returns a dataframe of the information yielded by
  the 'iCite' API. The primary metrics yielded by 'iCite' are measurements of a paper's 
  scientific influence and translational potential, but the API also returns other meta-data 
  from the paper, including author names, publication journal, publication year, paper title, 
  doi, and a number of other citation metrics.",2019-11-18,Travis Riddle,NA,TRUE,https://github.com/riddlet/iciter,4225,0,2019-11-05T18:31:52Z,NA
ICON,"Provides easy-to-use and easy-to-access datasets from the
    Index of COmplex Networks (ICON) database available on the University
    of Colorado website. All datasets can be loaded with a single function
    call and new datasets are being slowly added from ICON at
    <https://icon.colorado.edu>. Specific ICON datasets of interest can
    be requested at the BugReports URL <https://github.com/rrrlw/ICON/issues>.",2020-05-20,Raoul Wadhwa,https://github.com/rrrlw/ICON,TRUE,https://github.com/rrrlw/icon,4241,0,2020-05-20T02:45:14Z,NA
icr,"Provides functions to compute and plot Krippendorff's inter-coder 
    reliability coefficient alpha and bootstrapped uncertainty estimates 
    (Krippendorff 2004, ISBN:0761915443). The bootstrap routines are set up to
    make use of parallel threads where supported.",2020-03-20,Alexander Staudt,https://github.com/staudtlex/icr,TRUE,https://github.com/staudtlex/icr,16737,1,2020-03-20T17:04:49Z,16737
IDE,"The Integro-Difference Equation model is a linear, dynamical model used to model
   phenomena that evolve in space and in time; see, for example, Cressie and Wikle (2011,
   ISBN:978-0-471-69274-4) or Dewar et al. (2009) <doi:10.1109/TSP.2008.2005091>. At the
   heart of the model is the kernel, which dictates how the process evolves from one time
   point to the next. Both process and parameter reduction are used to facilitate computation,
   and spatially-varying kernels are allowed. Data used to estimate the parameters are assumed
   to be readings of the process corrupted by Gaussian measurement error. Parameters are fitted
   by maximum likelihood, and estimation is carried out using an evolution algorithm. ",2019-06-24,Andrew Zammit-Mangion,NA,TRUE,https://github.com/andrewzm/ide,8952,0,2019-06-24T04:47:24Z,NA
idefix,"Generates efficient designs for discrete choice experiments based on the multinomial logit model, and individually adapted designs for the mixed multinomial logit model. The generated designs can be presented on screen and choice data can be gathered using a shiny application. Crabbe M, Akinc D and Vandebroek M (2014) <doi:10.1016/j.trb.2013.11.008>.",2020-04-07,Frits Traets,https://github.com/traets/idefix,TRUE,https://github.com/traets/idefix,14790,7,2020-04-07T11:45:02Z,2112.8571428571427
ideq,"In contrast to other methods of modeling spatio-temporal data,
  dynamic spatio-temporal models (DSTMs) directly model the dynamic
  data-generating process.
  'ideq' supports two main classes of DSTMs:
  (1) empirical orthogonal function (EOF) models and
  (2) integrodifference equation (IDE) models.
  EOF models do not directly use any spatial information;
  instead, they make use of observed relationships in the data
  (the principal components) to model the underlying process.
  In contrast, IDE models are based on diffusion dynamics and the process
  evolution is governed by a (typically Gaussian) redistribution kernel.
  Both types have a variety of options for specifying the model components,
  including the process matrix, process error, and observation error.
  The classic reference for DSTMs is
  Noel Cressie and Christopher K. Wikle (2011, ISBN:978-0471692744).
  For IDE models specifically, see
  Christopher K. Wikle and Noel Cressie (1999, <https://www.jstor.org/stable/2673587>)
  and 
  Christopher K. Wikle (2002, <doi:10.1191/1471082x02st036oa>).",2019-12-19,Easton Huch,NA,TRUE,https://github.com/eastonhuch/ideq,4722,2,2019-12-17T02:55:47Z,2361
idmodelr,"Explore a range of infectious disease models in a consistent framework. 
    The primary aim of 'idmodelr' is to provide a library of infectious disease models
    for researchers, students, and other interested individuals. These models can be 
    used to understand the underlying dynamics and as a reference point when developing
    models for research. 'idmodelr' also provides a range of utilities. These include: plotting 
    functionality; a simulation wrapper; scenario analysis tooling; an interactive 
    dashboard; tools for handling mult-dimensional models; and both model and parameter
    look up tables. Unlike other modelling packages such as 'pomp' (<https://kingaa.github.io/pomp/>), 'libbi' (<http://libbi.org>)
    and 'EpiModel' (<http://www.epimodel.or>), 'idmodelr' serves primarily as an educational 
    resource. It is most comparable to epirecipes (<http://epirecip.es/epicookbook/chapters/simple>)
    but provides a more consistent framework, an R based workflow, and additional utility tooling. 
    After users have explored model dynamics with 'idmodelr' they may then 
    implement their model using one of these packages in order to utilise the model
    fitting tools they provide.  For newer modellers, this package reduces the barrier
    to entry by containing multiple infectious disease models, providing a consistent
    framework for simulation and visualisation, and signposting towards other, more 
    research focussed, resources. ",2019-09-10,Sam Abbott,"http://www.samabbott.co.uk/idmodelr,
https://github.com/seabbs/idmodelr",TRUE,https://github.com/seabbs/idmodelr,4112,8,2020-01-21T14:57:42Z,514
ids,Generate random or human readable and pronounceable identifiers.,2017-05-31,Rich FitzJohn,https://github.com/richfitz/ids,TRUE,https://github.com/richfitz/ids,33699,73,2020-05-29T09:08:34Z,461.63013698630135
ifaTools,"Tools, tutorials, and demos of Item Factor Analysis using 'OpenMx'.",2020-02-04,Joshua N. Pritikin,https://github.com/jpritikin/ifaTools,TRUE,https://github.com/jpritikin/ifatools,22571,1,2019-12-10T15:32:28Z,22571
igate,"An implementation of the initial guided analytics for parameter testing and
    controlband extraction framework. Functions are available for continuous and 
    categorical target variables as well as for generating standardized reports of the
    conducted analysis. See <https://github.com/stefan-stein/igate> for more information
    on the technology.",2019-09-10,Stefan Stein,https://github.com/stefan-stein/igate,TRUE,https://github.com/stefan-stein/igate,3499,0,2019-09-13T11:07:33Z,NA
IGP,"Creates a Gaussian process model using the specified package. 
    Makes it easy to try different packages in same code, only the
    package argument needs to be changed.
    It is essentially a wrapper for the other Gaussian process
    software packages.",2017-09-19,Collin Erickson,https://github.com/CollinErickson/IGP,TRUE,https://github.com/collinerickson/igp,9298,1,2020-03-29T01:42:11Z,9298
igraph,"Routines for simple graphs and network analysis. It can
  handle large graphs very well and provides functions for generating random
  and regular graphs, graph visualization, centrality methods and much more.",2020-03-19,See AUTHORS file.,http://igraph.org,TRUE,https://github.com/igraph/igraph,7331578,1005,2020-06-09T17:52:31Z,7295.102487562189
ihpdr,"Web scraping the <https://www.dallasfed.org> for
    up-to-date data on international house prices and exuberance
    indicators. Download data in tidy format.",2020-04-25,Kostas Vasilopoulos,https://github.com/kvasilopoulos/ihpdr,TRUE,https://github.com/kvasilopoulos/ihpdr,3859,0,2020-04-24T16:57:52Z,NA
IMAGE,"Performs mQTL (methylation quantitative-trait locus) mapping in 
    bisulfite sequencing studies by fitting a binomial mixed model and then 
    incorporating the allelic-specific methylation pattern. Based on Fan, Yue; 
    Vilgalys, Tauras P.; Sun, Shiquan; Peng, Qinke; Tung, Jenny; Zhou, Xiang 
    (2019) <doi:10.1101/615039>.",2019-07-28,Michael Kleinsasser,NA,TRUE,https://github.com/umich-biostatistics/image,4348,0,2019-07-23T14:22:20Z,NA
imagefluency,"Get image statistics based on processing fluency theory. The
    functions provide scores for several basic aesthetic principles that
    facilitate fluent cognitive processing of images: contrast,
    complexity / simplicity, self-similarity, symmetry, and typicality.
    See Mayer & Landwehr (2018) <doi:10.1037/aca0000187> and Mayer & Landwehr
    (2018) <doi:10.31219/osf.io/gtbhw> for the theoretical background of the methods.",2020-01-09,Stefan Mayer,https://stm.github.io/imagefluency,TRUE,https://github.com/stm/imagefluency,3747,2,2020-01-09T16:21:58Z,1873.5
imager,"Fast image processing for images in up to 4 dimensions (two spatial
    dimensions, one time/depth dimension, one colour dimension). Provides most
    traditional image processing tools (filtering, morphology, transformations,
    etc.) as well as various functions for easily analysing image data using R. The
    package wraps 'CImg', <http://cimg.eu>, a simple, modern C++ library for image
    processing.",2020-05-11,Shota Ochi,"http://dahtah.github.io/imager, https://github.com/dahtah/imager",TRUE,https://github.com/dahtah/imager,320551,158,2020-05-25T08:40:07Z,2028.8037974683543
imagerExtra,Provides advanced functions for image processing based on the package 'imager'.,2019-01-25,Shota Ochi,https://github.com/ShotaOchi/imagerExtra,TRUE,https://github.com/shotaochi/imagerextra,11997,8,2020-02-06T12:03:27Z,1499.625
imagine,"Provides fast application of image filters to data matrices,
    using R and C++ algorithms.",2020-02-06,Wencheng Lau-Medrano,https://github.com/LuisLauM/imagine,TRUE,https://github.com/luislaum/imagine,15314,1,2020-02-06T14:47:00Z,15314
ImaginR,"The pearl oyster, Pinctada margaritifera (Linnaeus, 1758), represents the second economic resource of French Polynesia. It is one of the only bivalves expressing a large varied range of inner shell color, & by correlation, of pearl color. This phenotypic variability is partly under genetic control, but also under environmental influence. With ImaginR, it's now possible to delimit the color phenotype of the pearl oyster's inner shell and to characterize their color variations (by the HSV color code system) with pictures.",2017-05-31,Pierre-Louis Stenger,NA,TRUE,https://github.com/plstenger/imaginr,9620,0,2019-08-08T08:47:59Z,NA
imbalance,"Class imbalance usually damages the performance of classifiers. Thus, it is
             important to treat data before applying a classifier algorithm. This package
             includes recent resampling algorithms in the literature: (Barua et al. 2014)
             <doi:10.1109/tkde.2012.232>; (Das et al. 2015) <doi:10.1109/tkde.2014.2324567>,
             (Zhang et al. 2014) <doi:10.1016/j.inffus.2013.12.003>; (Gao et al. 2014)
             <doi:10.1016/j.neucom.2014.02.006>; (Almogahed et al. 2014)
             <doi:10.1007/s00500-014-1484-5>. It also includes an useful interface to
             perform oversampling.",2020-04-07,Ignacio Cordón,http://github.com/ncordon/imbalance,TRUE,https://github.com/ncordon/imbalance,30042,30,2019-12-17T22:57:31Z,1001.4
imfr,"Explore and download data from the International Monetary Fund's
    data API <http://data.imf.org/>.",2019-11-30,Christopher Gandrud,https://CRAN.R-project.org/package=imfr,TRUE,https://github.com/christophergandrud/imfr,18440,20,2019-11-30T17:25:59Z,922
imgpalr,"Provides ability to create color palettes from image files. 
    It offers control over the type of color palette to derive from an image (qualitative, sequential or divergent) and other palette properties.
    Quantiles of an image color distribution can be trimmed. 
    Near-black or near-white colors can be trimmed in RGB color space independent of trimming brightness or saturation distributions in HSV color space.
    Creating sequential palettes also offers control over the order of HSV color dimensions to sort by.
    This package differs from other related packages like 'RImagePalette' in approaches to quantizing and extracting colors in images to assemble color palettes 
    and the level of user control over palettes construction.",2019-11-28,Matthew Leonawicz,https://github.com/leonawicz/imgpalr,TRUE,https://github.com/leonawicz/imgpalr,3995,20,2019-11-27T22:38:27Z,199.75
imgrec,Provides an interface for image recognition using the 'Google Vision API' <https://cloud.google.com/vision/> .  Converts API data for features such as object detection and optical character recognition to data frames. The package also includes functions for analyzing image annotations.,2019-07-12,Carsten Schwemmer,https://github.com/cschwem2er/imgrec,TRUE,https://github.com/cschwem2er/imgrec,3779,11,2019-12-09T14:04:42Z,343.54545454545456
IMIFA,"Provides flexible Bayesian estimation of Infinite Mixtures of Infinite Factor Analysers and related models, for nonparametrically clustering high-dimensional data, introduced by Murphy et al. (2019) <doi:10.1214/19-BA1179>. The IMIFA model conducts Bayesian nonparametric model-based clustering with factor analytic covariance structures without recourse to model selection criteria to choose the number of clusters or cluster-specific latent factors, mostly via efficient Gibbs updates. Model-specific diagnostic tools are also provided, as well as many options for plotting results, conducting posterior inference on parameters of interest, posterior predictive checking, and quantifying uncertainty.",2020-05-12,Keefe Murphy,https://cran.r-project.org/package=IMIFA,TRUE,https://github.com/keefe-murphy/imifa,16060,4,2020-05-12T19:03:01Z,4015
iml,"Interpretability methods to analyze the behavior
    and predictions of any machine learning model.  Implemented methods
    are: Feature importance described by Fisher et al. (2018)
    <arXiv:1801.01489>, accumulated local effects plots described by Apley
    (2018) <arXiv:1612.08468>, partial dependence plots described by
    Friedman (2001) <http://www.jstor.org/stable/2699986>, individual
    conditional expectation ('ice') plots described by Goldstein et al.
    (2013) <doi:10.1080/10618600.2014.907095>, local models (variant of
    'lime') described by Ribeiro et. al (2016) <arXiv:1602.04938>, the
    Shapley Value described by Strumbelj et. al (2014)
    <doi:10.1007/s10115-013-0679-x>, feature interactions described by
    Friedman et. al <doi:10.1214/07-AOAS148> and tree surrogate models.",2020-03-26,Christoph Molnar,https://github.com/christophM/iml,TRUE,https://github.com/christophm/iml,69028,320,2020-05-27T08:27:13Z,215.7125
immcp,"The pathway fingerprint is a method to indicate the profile of significant pathways being influenced by drugs, which may hint drug functions. Through the similarity of pathway fingerprints, the potential relationship between disease and prescription can be found. Ye (2012) <doi: 10.1007/s13238-012-2011-z>.",2020-06-09,Yuanlong Hu,https://github.com/YuanlongHu/immcp,TRUE,https://github.com/yuanlonghu/immcp,0,0,2020-06-05T03:01:33Z,NA
immer,"
    Implements some item response models for multiple
    ratings, including the hierarchical rater model, 
    conditional maximum likelihood estimation of linear 
    logistic partial credit model and a wrapper function
    to the commercial FACETS program. See Robitzsch and
    Steinfeld (2018) for a description of the functionality
    of the package. 
    See Wang, Su & Qiu (2014; <doi:10.1111/jedm.12045>)
    for an overview of modeling alternatives.",2018-12-10,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/immer,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/immer,21583,2,2020-03-02T17:16:51Z,10791.5
Immigrate,"Based on large margin principle, this package performs feature selection methods: ""IM4E""(Iterative Margin-Maximization under Max-Min Entropy Algorithm); ""Immigrate""(Iterative Max-Min Entropy Margin-Maximization with Interaction Terms Algorithm); ""BIM""(Boosted version of IMMIGRATE algorithm); ""Simba""(Iterative Search Margin Based Algorithm); ""LFE""(Local Feature Extraction Algorithm). This package also performs prediction for the above feature selection methods.",2020-05-22,Ruzhang Zhao,"https://cran.r-project.org/package=Immigrate,
https://arxiv.org/abs/1810.02658,
https://github.com/RuzhangZhao/Immigrate/",TRUE,https://github.com/ruzhangzhao/immigrate,6785,4,2020-05-22T18:29:43Z,1696.25
immunarch,"A comprehensive framework for bioinformatics analysis of bulk and single-cell 
    T-cell receptor and antibody repertoires. It provides seamless data loading, analysis and 
    visualisation for AIRR (Adaptive Immune Receptor Repertoire) data, both bulk immunosequencing (RepSeq)
    and single-cell sequencing (scRNAseq). It implements most of the widely used AIRR analysis methods, 
    such as: clonality analysis, estimation of repertoire similarities in distribution of clonotypes 
    and gene segments, repertoire diversity analysis, annotation of clonotypes using external immune receptor 
    databases and clonotype tracking in vaccination and cancer studies. A successor to our
    previously published 'tcR' immunoinformatics package (Nazarov 2015) <doi:10.1186/s12859-015-0613-1>.",2020-05-13,Vadim I. Nazarov,"https://immunarch.com/, https://github.com/immunomind/immunarch",TRUE,https://github.com/immunomind/immunarch,475,53,2020-05-13T10:03:22Z,8.962264150943396
immuneSIM,"Simulate full B-cell and T-cell receptor repertoires using an in silico 
    recombination process that includes a wide variety of tunable parameters to introduce noise and biases. 
    Additional post-simulation modification functions allow the user to implant motifs or codon biases as 
    well as remodeling sequence similarity architecture. The output repertoires contain records of all 
    relevant repertoire dimensions and can be analyzed using provided repertoire analysis functions.
    Preprint is available at bioRxiv (Weber et al., 2019 <doi:10.1101/759795>).",2019-09-27,Cédric R. Weber,https://immuneSIM.readthedocs.io,TRUE,https://github.com/greifflab/immunesim,3030,16,2020-05-18T16:44:56Z,189.375
implyr,"'SQL' back-end to 'dplyr' for Apache Impala, the massively
    parallel processing query engine for Apache 'Hadoop'. Impala enables
    low-latency 'SQL' queries on data stored in the 'Hadoop' Distributed
    File System '(HDFS)', Apache 'HBase', Apache 'Kudu', Amazon Simple 
    Storage Service '(S3)', Microsoft Azure Data Lake Store '(ADLS)', 
    and Dell 'EMC' 'Isilon'. See <https://impala.apache.org> for more
    information about Impala.",2019-07-21,Ian Cook,https://github.com/ianmcook/implyr,TRUE,https://github.com/ianmcook/implyr,22150,65,2020-02-26T14:52:54Z,340.7692307692308
importinegi,Download and manage data sets of statistical projects and geographic data created by Instituto Nacional de Estadistica y Geografia (INEGI). See <https://www.inegi.org.mx/>.,2020-05-04,Cesar Renteria,NA,TRUE,https://github.com/crenteriam/importinegi,4473,0,2020-05-07T00:33:31Z,NA
imputeFin,"Missing values often occur in financial data due to a variety 
    of reasons (errors in the collection process or in the processing stage, 
    lack of asset liquidity, lack of reporting of funds, etc.). However, 
    most data analysis methods expect complete data and cannot be employed 
    with missing values. One convenient way to deal with this issue without 
    having to redesign the data analysis method is to impute the missing 
    values. This package provides an efficient way to impute the missing 
    values based on modeling the time series with a random walk or an 
    autoregressive (AR) model, convenient to model log-prices and log-volumes 
    in financial data. In the current version, the imputation is 
    univariate-based (so no asset correlation is used). 
    The package is based on the paper:
    J. Liu, S. Kumar, and D. P. Palomar (2019). Parameter Estimation of 
    Heavy-Tailed AR Model With Missing Data Via Stochastic EM. IEEE Trans. on 
    Signal Processing, vol. 67, no. 8, pp. 2159-2172. <doi:10.1109/TSP.2019.2899816>.",2019-12-13,Daniel P. Palomar,"https://CRAN.R-project.org/package=imputeFin,
https://github.com/dppalomar/imputeFin",TRUE,https://github.com/dppalomar/imputefin,2613,7,2020-02-07T03:54:47Z,373.2857142857143
imputeR,"Multivariate Expectation-Maximization (EM) based imputation framework that offers several different algorithms. These include regularisation methods like Lasso and Ridge regression, tree-based models and dimensionality reduction methods like PCA and PLS.",2020-01-20,Steffen Moritz,http://github.com/SteffenMoritz/imputeR,TRUE,https://github.com/steffenmoritz/imputer,20534,5,2020-03-20T16:13:25Z,4106.8
imputeTS,"Imputation (replacement) of missing values 
             in univariate time series. 
             Offers several imputation functions
             and missing data plots. 
             Available imputation algorithms include: 
            'Mean', 'LOCF', 'Interpolation', 
            'Moving Average', 'Seasonal Decomposition', 
            'Kalman Smoothing on Structural Time Series models',
            'Kalman Smoothing on ARIMA models'. Published in Moritz and Bartz-Beielstein (2017) 
            <doi: 10.32614/RJ-2017-009>.",2019-07-01,Steffen Moritz,"https://github.com/SteffenMoritz/imputeTS,
https://steffenmoritz.github.io/imputeTS/",TRUE,https://github.com/steffenmoritz/imputets,300397,85,2020-06-03T03:38:10Z,3534.0823529411764
incgraph,"An efficient and incremental approach for calculating 
    the differences in orbit counts when performing single edge modifications 
    in a network. Calculating the differences in orbit counts is much more efficient than
    recalculating all orbit counts from scratch for each time point.",2017-10-12,Robrecht Cannoodt,http://www.github.com/rcannood/incgraph,TRUE,https://github.com/rcannood/incgraph,9165,2,2019-12-08T19:46:44Z,4582.5
incidence,"Provides functions and classes to compute, handle and visualise incidence from dated events for a defined time interval. Dates can be provided in various standard formats. The class 'incidence' is used to store computed incidence and can be easily manipulated, subsetted, and plotted. In addition, log-linear models can be fitted to 'incidence' objects using 'fit'. This package is part of the RECON (<http://www.repidemicsconsortium.org/>) toolkit for outbreak analysis.",2020-03-25,Zhian N. Kamvar,http://www.repidemicsconsortium.org/incidence/,TRUE,https://github.com/reconhub/incidence,47558,44,2020-03-16T23:16:14Z,1080.8636363636363
inctools,"Tools for estimating incidence from biomarker data in cross-
    sectional surveys, and for calibrating tests for recent infection. 
    Implements and extends the method of Kassanjee et al. (2012)
    <doi:10.1097/EDE.0b013e3182576c07>.",2019-11-07,Eduard Grebe,http://www.incidence-estimation.org/page/inctools,TRUE,https://github.com/sacema/inctools,14592,5,2020-03-11T08:04:00Z,2918.4
iNEXT,"Provides simple functions to compute and plot two
    types (sample-size- and coverage-based) rarefaction and extrapolation of species
    diversity (Hill numbers) for individual-based (abundance) data or sampling-unit-
    based (incidence) data. (Hsieh, Ma and Chao 2014) <doi: 10.1111/2041-210X.12613>.",2020-01-28,T. C. Hsieh,http://chao.stat.nthu.edu.tw/wordpress/software_download/,TRUE,https://github.com/johnsonhsieh/inext,51249,35,2020-01-28T13:18:02Z,1464.2571428571428
infer,The objective of this package is to perform inference using an expressive statistical grammar that coheres with the tidy design framework. ,2019-11-19,Andrew Bray,"https://github.com/tidymodels/infer, https://infer.netlify.com/",TRUE,https://github.com/tidymodels/infer,156127,467,2019-12-19T12:46:28Z,334.31905781584584
inferr,"Select set of parametric and non-parametric statistical tests. 'inferr' builds upon the solid set of
    statistical tests provided in 'stats' package by including additional data types as inputs, expanding and
    restructuring the test results. The tests included are t tests, variance tests, proportion tests, chi square tests, Levene's test, McNemar Test, Cochran's Q test and Runs test.",2018-02-13,Aravind Hebbali,"https://rsquaredacademy.github.io/inferr/,
https://github.com/rsquaredacademy/inferr",TRUE,https://github.com/rsquaredacademy/inferr,14939,27,2019-08-27T09:43:55Z,553.2962962962963
infix,Contains a number of infix binary operators that may be useful in day to day practices.,2018-12-25,Ernest Benedito,http://github.com/ebeneditos/infix,TRUE,https://github.com/ebeneditos/infix,6711,0,2020-01-15T20:37:12Z,NA
influenceAUC,"Ke, B. S., Chiang, A. J., & Chang, Y. C. I. (2018) <doi:10.1080/10543406.2017.1377728> provide two theoretical methods (influence function and local influence) based on the area under the receiver operating characteristic curve (AUC) to quantify the numerical impact of each observation to the overall AUC. Alternative graphical tools, cumulative lift charts, are proposed to reveal the existences and approximate locations of those influential observations through data visualization.",2020-05-30,Bo-Shiang Ke,NA,TRUE,https://github.com/boshiangke/influenceauc,2258,0,2020-05-30T13:47:52Z,NA
influential,"Contains functions for reconstruction of networks from
    adjacency matrices and data frames, analysis of the topology of the network 
    and calculation of centrality measures, and identification of the most
    influential nodes. Also, some functions have been provided for the assessment 
    of dependence and correlation of two network centrality measures as well as 
    the conditional probability of deviation from their corresponding means in opposite direction.
    Fred Viole and David Nawrocki (2013, ISBN:1490523995).
    Csardi G, Nepusz T (2006). ""The igraph software package for complex network research."" InterJournal, Complex Systems, 1695.
    Adopted algorithms and sources are referenced in function document.",2020-04-25,Adrian (Abbas) Salavaty,http://github.com/asalavaty/influential,TRUE,https://github.com/asalavaty/influential,2014,2,2020-05-21T03:05:33Z,1007
influxdbr,"An R interface to the InfluxDB time series database <https://www.influxdata.com>. This package allows you to fetch and write time series data from/to an InfluxDB server. Additionally, handy wrappers for the Influx Query Language (IQL) to manage and explore a remote database are provided. ",2018-01-10,Dominik Leutnant,https://github.com/dleutnant/influxdbr,TRUE,https://github.com/dleutnant/influxdbr,27635,70,2020-05-02T05:51:47Z,394.7857142857143
infoDecompuTE,"The main purpose of this package is to generate the structure of the analysis of variance 
            (ANOVA) table of the two-phase experiments. The user only need to input the design and the 
              relationships of the random and fixed factors using the Wilkinson-Rogers' syntax, 
              this package can then quickly generate the structure of the ANOVA table with the 
              coefficients of the variance components for the expected mean squares.
              Thus, the balanced incomplete block design and provides the efficiency
              factors of the fixed effects can also be studied and compared much easily.",2020-03-28,Kevin Chang,https://github.com/kcha193/infoDecompuTE,TRUE,https://github.com/kcha193/infodecompute,18921,0,2020-03-28T03:51:24Z,NA
ingredients,"Collection of tools for assessment of feature importance and feature effects.
    Key functions are:
    feature_importance() for assessment of global level feature importance,
    ceteris_paribus() for calculation of the what-if plots,
    partial_dependence() for partial dependence plots,
    conditional_dependence() for conditional dependence plots,
    accumulated_dependence() for accumulated local effects plots,
    aggregate_profiles() and cluster_profiles() for aggregation of ceteris paribus profiles,
    generic print() and plot() for better usability of selected explainers,
    generic plotD3() for interactive, D3 based explanations, and
    generic describe() for explanations in natural language.
    The package 'ingredients' is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.",2020-04-20,Przemyslaw Biecek,"https://ModelOriented.github.io/ingredients/,
https://github.com/ModelOriented/ingredients",TRUE,https://github.com/modeloriented/ingredients,19466,23,2020-06-06T21:28:55Z,846.3478260869565
inlabru,"Facilitates spatial modeling using integrated nested Laplace approximation via the 
  INLA package (<http://www.r-inla.org>). Additionally, implements a log Gaussian Cox process likelihood for 
  modeling univariate and spatial point processes based on ecological survey data. See Yuan Yuan, 
  Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Havard Rue, 
  Tim Gerrodette (2017), <arXiv:1604.06013>.",2020-02-16,Fabian E. Bachl,"http://www.inlabru.org,",TRUE,https://github.com/fbachl/inlabru,13135,23,2020-06-05T11:13:10Z,571.0869565217391
inline,"Functionality to dynamically define R functions and S4 methods
 with 'inlined' C, C++ or Fortran code supporting the .C and .Call calling
 conventions.",2018-05-18,Oleg Sklyar,NA,TRUE,https://github.com/eddelbuettel/inline,1164682,30,2020-01-23T23:31:34Z,38822.73333333333
inlinedocs,"Generates Rd files from R source code with comments.
 The main features of the default syntax are that
 (1) docs are defined in comments near the relevant code,
 (2) function argument names are not repeated in comments, and
 (3) examples are defined in R code, not comments.
 It is also easy to define a new syntax.",2019-12-05,Toby Dylan Hocking,http://github.com/tdhock/inlinedocs,TRUE,https://github.com/tdhock/inlinedocs,45218,1,2019-12-09T16:44:36Z,45218
inlmisc,"A collection of functions for creating high-level graphics,
    performing raster-based analysis, processing MODFLOW-based models,
    selecting subsets using a genetic algorithm, creating interactive web maps,
    accessing color palettes, etc. Used to support packages and scripts written
    by researchers at the United States Geological Survey (USGS)
    Idaho National Laboratory (INL) Project Office.",2020-01-15,Jason C. Fisher,https://github.com/USGS-R/inlmisc,TRUE,https://github.com/usgs-r/inlmisc,45876,12,2020-01-15T07:14:20Z,3823
inops,"Infix operators to detect, subset, and replace the elements matched by a given condition.
  The functions have several variants of operator types, including subsets, ranges, regular expressions and others.
  Implemented operators work on vectors, matrices, and lists.",2019-11-19,Antoine Fabri,https://github.com/moodymudskipper/inops,TRUE,https://github.com/moodymudskipper/inops,2728,33,2019-11-19T13:56:51Z,82.66666666666667
inpdfr,"A set of functions to analyse and compare texts, using classical 
  text mining	functions, as well as those from theoretical ecology.",2020-01-16,Rebaudo Francois (IRD,https://github.com/frareb/inpdfr/,TRUE,https://github.com/frareb/inpdfr,16327,2,2020-01-16T11:22:08Z,8163.5
insect,Provides tools for probabilistic taxon assignment with informatic sequence classification trees. See Wilkinson et al (2018) <doi:10.7287/peerj.preprints.26812v1>.,2018-11-25,Shaun Wilkinson,http://github.com/shaunpwilkinson/insect,TRUE,https://github.com/shaunpwilkinson/insect,9230,9,2019-10-25T00:16:50Z,1025.5555555555557
insight,"A tool to provide an easy, intuitive and consistent access to 
   information contained in various R models, like model formulas, model terms, 
   information about random effects, data that was used to fit the model or 
   data from response variables. 'insight' mainly revolves around two types 
   of functions: Functions that find (the names of) information, starting with 
   'find_', and functions that get the underlying data, starting with 'get_'. 
   The package has a consistent syntax and works with many different model 
   objects, where otherwise functions to access these information are missing.",2020-06-08,Daniel Lüdecke,https://easystats.github.io/insight/,TRUE,https://github.com/easystats/insight,452044,120,2020-06-09T13:32:14Z,3767.0333333333333
InSilicoVA,"Computes individual causes of death and population cause-specific mortality fractions using the 'InSilicoVA' algorithm from McCormick et al. (2016) <DOI:10.1080/01621459.2016.1152191>. It uses data derived from verbal autopsy (VA) interviews, in a format similar to the input of the widely used 'InterVA4' method. This package provides general model fitting and customization for 'InSilicoVA' algorithm and basic graphical visualization of the output.",2020-05-10,Zehang Richard Li,https://github.com/verbal-autopsy-software/InSilicoVA,TRUE,https://github.com/verbal-autopsy-software/insilicova,27490,2,2020-05-08T15:10:28Z,13745
inspectdf,"A collection of utilities for columnwise summary, comparison and visualisation of data frames.  Functions report missingness, categorical levels, numeric distribution, correlation, column types and memory usage.",2019-11-05,Alastair Rushworth,https://alastairrushworth.github.io/inspectdf/,TRUE,https://github.com/alastairrushworth/inspectdf,21200,174,2019-12-06T17:20:49Z,121.83908045977012
installr,"R is great for installing software.  Through the 'installr'
    package you can automate the updating of R (on Windows, using updateR())
    and install new software. Software installation is initiated through a
    GUI (just run installr()), or through functions such as: install.Rtools(),
    install.pandoc(), install.git(), and many more. The updateR() command
    performs the following: finding the latest R version, downloading it,
    running the installer, deleting the installation file, copy and updating
    old packages to the new R installation.",2019-08-02,Tal Galili,"http://talgalili.github.io/installr/,
https://github.com/talgalili/installr/,
http://www.r-statistics.com/tag/installr/",TRUE,https://github.com/talgalili/installr,1422998,193,2020-06-02T14:44:10Z,7373.046632124352
insurancerating,"Methods for insurance rating. It helps actuaries to implement GLMs within all relevant steps needed to construct 
    a risk premium from raw data. It provides a data driven strategy for the construction of insurance tariff classes. 
    This strategy is based on the work by Antonio and Valdez (2012) <doi:10.1007/s10182-011-0152-7>. It also provides recipes 
    on how to easily perform one-way, or univariate, analyses on an insurance portfolio. In addition it adds functionality 
    to include reference categories in the levels of the coefficients in the output of a generalized linear regression analysis.",2020-06-08,Martin Haringa,"https://github.com/mharinga/insurancerating,
https://mharinga.github.io/insurancerating/",TRUE,https://github.com/mharinga/insurancerating,7035,6,2020-06-08T10:51:58Z,1172.5
interactionR,"Produces a publication-ready table that includes all effect estimates necessary for full reporting effect modification and interaction analysis as recommended by Knol and Vanderweele (2012) [<doi:10.1093/ije/dyr218>].
    It also estimates confidence interval for the trio of additive interaction measures using the delta method (see Hosmer and Lemeshow (1992), [<doi:10.1097/00001648-199209000-00012>]), variance recovery method (see Zou (2008), [<doi:10.1093/aje/kwn104>]), or percentile bootstrapping (see Assmann et al. (1996), [<doi:10.1097/00001648-199605000-00012>]). ",2020-04-07,Babatunde Alli,https://github.com/epi-zen/interactionR,TRUE,https://github.com/epi-zen/interactionr,1029,3,2020-04-07T17:41:12Z,343
interactions,"A suite of functions for conducting and interpreting analysis 
  of statistical interaction in regression models that was formerly part of the 
  'jtools' package. Functionality includes visualization of two- and three-way
  interactions among continuous and/or categorical variables as well as 
  calculation of ""simple slopes"" and Johnson-Neyman intervals (see e.g., 
  Bauer & Curran, 2005 <doi:10.1207/s15327906mbr4003_5>). These
  capabilities are implemented for generalized linear models in addition to the 
  standard linear regression context.",2020-04-04,Jacob A. Long,https://interactions.jacob-long.com,TRUE,https://github.com/jacob-long/interactions,34528,78,2020-04-02T15:27:25Z,442.6666666666667
interep,"Extensive penalized variable selection methods have been developed in the past two decades for analyzing high dimensional omics data, such as gene expressions, single nucleotide polymorphisms (SNPs), copy number variations (CNVs) and others. However, lipidomics data have been rarely investigated by using high dimensional variable selection methods. This package incorporates our recently developed penalization procedures to conduct interaction analysis for high dimensional lipidomics data with repeated measurements. The core module of this package is developed in C++. The development of this software package and the associated statistical methods have been partially supported by an Innovative Research Award from Johnson Cancer Research Center, Kansas State University.",2020-04-20,Fei Zhou,https://github.com/feizhoustat/interep,TRUE,https://github.com/feizhoustat/interep,8961,1,2020-04-19T05:27:47Z,8961
internetarchive,"Search the Internet Archive, retrieve metadata, and download
    files.",2016-12-08,Lincoln Mullen,https://github.com/ropensci/internetarchive,TRUE,https://github.com/ropensci/internetarchive,17505,39,2020-05-20T02:48:26Z,448.84615384615387
interplot,"Plots the conditional coefficients (""marginal effects"") of
    variables included in multiplicative interaction terms.",2019-11-18,Yue Hu,NA,TRUE,https://github.com/sammo3182/interplot,81892,10,2019-11-17T12:55:52Z,8189.2
intervals,Tools for working with and comparing sets of points and intervals.,2020-04-04,Richard Bourgon,http://github.com/edzer/intervals,TRUE,https://github.com/edzer/intervals,551107,7,2020-04-04T09:26:33Z,78729.57142857143
IntrinioStockAPI,"Download financial data from the free 'Intrinio Stock API' (<https://intrinio.com/>).
    'Intrinio' offers a REST API which provides financial markets data 
    including intra-day stock prices, historical stock prices, technical indicators, company fundamentals, and more. 
    Complete documentation for the 'Intrinio Stock API' is available here: 
    <https://intrinio.com/documentation/api/>. To access the 'Intrinio Stock API',
    simply create a free account <https://intrinio.com/>.",2018-10-08,Intrinio,https://github.com/intrinio/r-sdk,TRUE,https://github.com/intrinio/r-sdk,6125,2,2020-05-19T19:17:17Z,3062.5
intrval,"Evaluating if values 
  of vectors are within different open/closed intervals
  (`x %[]% c(a, b)`), or if two closed
  intervals overlap (`c(a1, b1) %[]o[]% c(a2, b2)`).
  Operators for negation and directional relations also implemented.",2017-01-22,Peter Solymos,https://github.com/psolymos/intrval,TRUE,https://github.com/psolymos/intrval,13939,42,2020-03-10T19:21:24Z,331.8809523809524
intsurv,"Contains implementations of
    integrative survival analysis routines, including
    regular Cox cure rate model proposed by
    Kuk and Chen (1992) <doi:10.1093/biomet/79.3.531>
    via an EM algorithm proposed by
    Sy and Taylor (2000) <doi:10.1111/j.0006-341X.2000.00227.x>,
    regularized Cox cure rate model with elastic net penalty following
    Masud et al. (2018) <doi:10.1177/0962280216677748>, and
    Zou and Hastie (2005) <doi:10.1111/j.1467-9868.2005.00503.x>, and
    weighted concordance index for cure models proposed by
    Asano and Hirakawa (2017) <doi:10.1080/10543406.2017.1293082>.",2019-12-18,Wenjie Wang,https://github.com/wenjie2wang/intsurv,TRUE,https://github.com/wenjie2wang/intsurv,3970,3,2020-02-22T02:23:16Z,1323.3333333333333
intsvy,"
  Provides tools for importing, merging, and analysing data from 
  international assessment studies (TIMSS, PIRLS, PISA, ICILS, and PIAAC).",2019-05-10,Daniel Caro,"http://danielcaro.net/r-intsvy/,
https://github.com/eldafani/intsvy",TRUE,https://github.com/eldafani/intsvy,57237,11,2020-02-04T17:02:16Z,5203.363636363636
inverseRegex,"Reverse engineer a regular expression pattern for the characters
    contained in an R object. Individual characters can be categorised into
    digits, letters, punctuation or spaces and encoded into run-lengths. This
    can be used to summarise the structure of a dataset or identify non-standard
    entries. Many non-character inputs such as numeric vectors and data frames
    are supported.",2019-09-23,Jasper Watson,NA,TRUE,https://github.com/rntq472/inverseregex,2961,0,2019-09-24T03:03:31Z,NA
iNZightMR,"Interaction and analysis of multiple response data,
    along with other tools for analysing these types of data including
    missing value analysis and calculation of standard errors for
    a range of covariance matrix results (proportions, multinomial,
    independent samples, and multiple response).",2020-05-05,Tom Elliott,https://www.stat.auckland.ac.nz/~wild/iNZight/,TRUE,https://github.com/inzightvit/inzightmr,529,0,2020-05-19T03:55:54Z,NA
iNZightTools,"Provides a collection of wrapper functions for common variable and dataset manipulation workflows primarily used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions. Additionally, many of the functions return the 'tidyverse' code used to obtain the result in an effort to bridge the gap between GUI and coding.",2020-05-20,Tom Elliott,http://inzight.nz,TRUE,https://github.com/inzightvit/inzighttools,2167,1,2020-05-19T03:57:35Z,2167
iNZightTS,"Provides a collection of functions for working with time series data, including functions for drawing, decomposing, and forecasting. Includes capabilities to compare multiple series and fit both additive and multiplicative models. Used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions. Holt (1957) <doi:10.1016/j.ijforecast.2003.09.015>, Winters (1960) <doi:10.1287/mnsc.6.3.324>, Cleveland, Cleveland, & Terpenning (1990) ""STL: A Seasonal-Trend Decomposition Procedure Based on Loess"".",2020-05-12,Tom Elliott,https://www.stat.auckland.ac.nz/~wild/iNZight/,TRUE,https://github.com/inzightvit/inzightts,389,0,2020-05-19T03:54:53Z,NA
IOHanalyzer,"The data analysis module for the Iterative Optimization Heuristics
    Profiler ('IOHprofiler'). This module provides statistical analysis methods for the 
    benchmark data generated by optimization heuristics, which can be visualized through a 
    web-based interface. The benchmark data is usually generated by the 
    experimentation module, called 'IOHexperimenter'. 'IOHanalyzer' also supports
    the widely used 'COCO' (Comparing Continuous Optimisers) data format for benchmarking.",2020-01-10,Hao Wang,"http://iohprofiler.liacs.nl,
https://github.com/IOHprofiler/IOHAnalyzer",TRUE,https://github.com/iohprofiler/iohanalyzer,4880,9,2020-06-07T18:11:08Z,542.2222222222222
iotables,"Pre-processing and basic analytical tasks related to working with Eurostat's symmetric input-output
    tables and provide basic input-output economics calculations. The package is 
    a part of rOpenGov <http://ropengov.github.io/> to open source open government initiatives.",2020-05-19,Daniel Antal,http://iotables.ceemid.eu/,TRUE,https://github.com/ropengov/iotables,14292,3,2020-05-26T20:52:53Z,4764
ip2location,"Enables the user to find the country, region, city, coordinates, zip code, time zone, ISP, domain name, connection type, area code, weather station code, weather station name, mobile, usage types, etc that any IP address or hostname originates from. Supported IPv4 and IPv6.
        Please visit <https://www.ip2location.com> to learn more. You may also want to visit <https://lite.ip2location.com> for free database download.
        This package requires 'IP2Location Python' module. At the terminal, please run 'pip install IP2Location' to install the module.",2019-11-15,Chris Lim,https://github.com/ip2location/ip2location-r,TRUE,https://github.com/ip2location/ip2location-r,2735,2,2019-11-12T03:09:03Z,1367.5
ipa,"Converts character vectors between phonetic
    representations.  Supports IPA (International Phonetic Alphabet),
    X-SAMPA (Extended Speech Assessment Methods Phonetic Alphabet), and
    ARPABET (used by the CMU Pronouncing Dictionary).",2020-06-04,Alexander Rossell Hayes,https://github.com/rossellhayes/ipa,TRUE,https://github.com/rossellhayes/ipa,0,0,2020-06-04T18:21:30Z,NA
ipaddress,"Classes and functions for working with IP (Internet
    Protocol) addresses and networks, inspired by the Python 'ipaddress'
    module.  Offers full support for both IPv4 and IPv6 (Internet Protocol
    versions 4 and 6) address spaces. It is specifically designed to work
    well with the 'tidyverse'.",2020-05-12,David Hall,"https://davidchall.github.io/ipaddress,
https://github.com/davidchall/ipaddress",TRUE,https://github.com/davidchall/ipaddress,2085,11,2020-05-12T19:00:49Z,189.54545454545453
ipADMIXTURE,"A data clustering package based on admixture ratios (Q matrix) of population structure. The framework is based on iterative Pruning procedure that performs data clustering by splitting a given population into subclusters until meeting the condition of stopping criteria the same as ipPCA, iNJclust, and IPCAPS frameworks. The package also provides a function to retrieve phylogeny tree that construct a neighbor-joining tree based on a similar matrix between clusters. By given multiple Q matrices with varying a number of ancestors (K), the framework define a similar value between clusters i,j as a minimum number K* that makes majority of members of two clusters are in the different clusters. This K* reflexes a minimum number of ancestors we need to splitting cluster i,j into different clusters if we assign K* clusters based on maximum admixture ratio of individuals. The publication of this package is at Chainarong Amornbunchornvej, Pongsakorn Wangkumhang, and Sissades Tongsima (2020) <doi:10.1101/2020.03.21.001206>.",2020-03-26,Chainarong Amornbunchornvej,https://github.com/DarkEyes/ipADMIXTURE,TRUE,https://github.com/darkeyes/ipadmixture,1086,2,2020-04-21T03:52:50Z,543
ipc,"Provides tools for passing messages between R processes. 
    Shiny Examples are provided showing how to perform useful tasks such as: 
    updating reactive values from within a future, progress bars for long running 
    async tasks, and interrupting async tasks based on user input.",2019-06-23,Ian E. Fellows,https://github.com/fellstat/ipc,TRUE,https://github.com/fellstat/ipc,9034,33,2019-06-12T02:34:23Z,273.75757575757575
ipeadatar,"Allows direct access to the macroeconomic, 
             financial and regional database maintained by 
             Brazilian Institute for Applied Economic Research ('Ipea').
             This R package uses the 'Ipeadata' API. For more information, 
             see <http://www.ipeadata.gov.br/>.",2020-05-14,Luiz Eduardo S. Gomes,http://github.com/gomesleduardo/ipeadatar,TRUE,https://github.com/gomesleduardo/ipeadatar,24792,13,2020-05-14T17:28:03Z,1907.076923076923
ipfr,"Performs iterative proportional updating given a seed table and
  an arbitrary number of marginal distributions. This is commonly used in
  population synthesis, survey raking, matrix rebalancing, and other
  applications. For example, a household survey may be weighted to match the
  known distribution of households by size from the census. An origin/
  destination trip matrix might be balanced to match traffic counts.
  The approach used by this package is based on a paper from
  Arizona State University (Ye, Xin, et. al. (2009)
  <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.537.723&rep=rep1&type=pdf>).
  Some enhancements have been made to their work including primary and 
  secondary target balance/importance, general marginal agreement, and weight 
  restriction.",2020-04-01,Kyle Ward,https://github.com/dkyleward/ipfr,TRUE,https://github.com/dkyleward/ipfr,3708,1,2020-04-02T13:02:12Z,3708
ipmisc,"Provides functions needed for data cleaning and
    formatting and forms data cleaning and wrangling backend for the
    following packages: 'broomExtra', 'ggstatsplot', 'groupedstats',
    'pairwiseComparisons', 'statsExpressions', and 'tidyBF'.",2020-05-31,Indrajeet Patil,"https://indrajeetpatil.github.io/ipmisc/,
https://github.com/IndrajeetPatil/ipmisc",TRUE,https://github.com/indrajeetpatil/ipmisc,16764,1,2020-05-30T20:36:35Z,16764
iptmnetr,"Provides an R interface to the 'iPTMnet' database REST API, which can be used to retrieve 
    Post Translational Modification (PTM) data in systems biology context. This package handles all the aspects
    of communicating with the API, which involve sending the request, checking the error codes and parsing the
    response in a format that is ready to integrate into existing workflows.",2019-12-05,Sachin Gavali,"https://research.bioinformatics.udel.edu/iptmnet/,
https://github.com/udel-cbcb/iptmnetr",TRUE,https://github.com/udel-cbcb/iptmnetr,8003,1,2019-12-05T14:45:37Z,8003
ipumsr,"An easy way to import census, survey and geographic data provided by 'IPUMS'
    into R plus tools to help use the associated metadata to make analysis easier. 'IPUMS'
    data describing 1.4 billion individuals drawn from over 750 censuses and surveys is
    available free of charge from our website <https://ipums.org>.",2020-06-03,Derek Burk,"https://www.ipums.org, https://github.com/mnpopcenter/ipumsr",TRUE,https://github.com/mnpopcenter/ipumsr,49716,66,2020-06-03T14:50:23Z,753.2727272727273
IPV,"Generate plots based on the Item Pool Visualization concept for
    latent constructs. Item Pool Visualizations are used to display the
    conceptual structure of a set of items (self-report or psychometric).
    Dantlgraber, Stieger, & Reips (2019) <doi:10.1177/2059799119884283>.",2020-03-04,Nils Petras,https://github.com/NilsPetras/IPV,TRUE,https://github.com/nilspetras/ipv,2005,1,2020-03-04T15:55:07Z,2005
irace,"Iterated race is an extension of the Iterated F-race method for
             the automatic configuration of optimization algorithms, that is,
             (offline) tuning their parameters by finding the most appropriate
             settings given a set of instances of an optimization problem.
             M. López-Ibáñez, J. Dubois-Lacoste, L. Pérez Cáceres, T. Stützle,
             and M. Birattari (2016) <doi:10.1016/j.orp.2016.09.002>.",2020-03-31,Manuel López-Ibáñez,"http://iridia.ulb.ac.be/irace,
https://github.com/MLopez-Ibanez/irace",TRUE,https://github.com/mlopez-ibanez/irace,71137,4,2020-06-04T17:39:02Z,17784.25
ircor,"Provides implementation of various correlation coefficients of common use in
  Information Retrieval. In particular, it includes Kendall (1970, isbn:0852641990) tau coefficient
  as well as tau_a and tau_b for the treatment of ties. It also includes Yilmaz et al. (2008)
  <doi:10.1145/1390334.1390435> tauAP correlation coefficient, and versions tauAP_a and tauAP_b
  developed by Urbano and Marrero (2017) <doi:10.1145/3121050.3121106> to cope with ties.",2017-08-21,Julián Urbano,https://github.com/julian-urbano/ircor/,TRUE,https://github.com/julian-urbano/ircor,8683,3,2019-12-10T15:54:29Z,2894.3333333333335
IRkernel,"
    The R kernel for the 'Jupyter' environment executes R code which the front-end
    ('Jupyter Notebook' or other front-ends) submits to the kernel via the network.",2019-12-06,Thomas Kluyver,https://irkernel.github.io,TRUE,https://github.com/irkernel/irkernel,215633,1285,2020-04-11T13:10:53Z,167.8077821011673
isoband,"A fast C++ implementation to generate contour lines (isolines) and
  contour polygons (isobands) from regularly spaced grids containing elevation data.",2020-04-12,Claus O. Wilke,https://github.com/wilkelab/isoband,TRUE,https://github.com/wilkelab/isoband,2698282,90,2020-04-27T16:16:25Z,29980.911111111112
IsoriX,"Building isoscapes using mixed models and inferring the geographic
  origin of samples based on their isotopic ratios. This package is essentially a
  simplified interface to several other packages which implements a new
  statistical framework based on mixed models. It uses 'spaMM' for fitting and
  predicting isoscapes, and assigning an organism's origin depending on its
  isotopic ratio. 'IsoriX' also relies heavily on the package 'rasterVis' for
  plotting the maps produced with 'raster' using 'lattice'.",2018-08-29,Alexandre Courtiol,https://github.com/courtiol/IsoriX/,TRUE,https://github.com/courtiol/isorix,19165,5,2020-05-26T07:42:06Z,3833
isotree,"Fast and multi-threaded implementation of
	isolation forest (Liu, Ting, Zhou (2008) <doi:10.1109/ICDM.2008.17>),
	extended isolation forest (Hariri, Kind, Brunner (2018) <arXiv:1811.02141>),
	SCiForest (Liu, Ting, Zhou (2010) <doi:10.1007/978-3-642-15883-4_18>),
	and fair-cut forest (Cortes (2019) <arXiv:1911.06646>),
	for isolation-based outlier detection, clustered outlier detection, distance or similarity
	approximation (Cortes (2019) <arXiv:1910.12362>),
	and imputation of missing values (Cortes (2019) <arXiv:1911.06646>),
	based on random or guided decision tree splitting. Provides simple heuristics for fitting the model to
	categorical columns and handling missing data, and offers options for varying between random and guided
	splits, and for using different splitting criteria.",2020-04-27,David Cortes,https://github.com/david-cortes/isotree,TRUE,https://github.com/david-cortes/isotree,3069,21,2020-06-09T20:09:32Z,146.14285714285714
ItemResponseTrees,"Item response tree (IR-tree) models are a class of item response
    theory (IRT) models that assume that the responses to polytomous items can
    best be explained by multiple psychological processes; see Böckenholt
    (2012) <doi:10.1037/a0028111> for details. The package 
    'ItemResponseTrees' allows to fit such IR-tree models in 'mirt', 'Mplus', or
    'TAM'. The package automates some of the hassle of IR-tree modeling by means
    of a consistent syntax. This allows new users to quickly adopt this model
    class, and this allows experienced users to fit many complex models
    effortlessly.",2020-05-06,Hansjörg Plieninger,https://github.com/hplieninger/ItemResponseTrees,TRUE,https://github.com/hplieninger/itemresponsetrees,607,1,2020-06-03T16:29:27Z,607
ivx,"Drawing statistical inference on the coefficients
    of a short- or long-horizon predictive regression with persistent
    regressors by using the IVX method of Magdalinos and Phillips (2009)
    and <doi:10.1017/S0266466608090154> Kostakis, Magdalinos and
    Stamatogiannis (2015) <doi:10.1093/rfs/hhu139>.",2019-05-04,Kostas Vasilopoulos,https://github.com/kvasilopoulos/ivx,TRUE,https://github.com/kvasilopoulos/ivx,4319,3,2019-08-19T14:40:19Z,1439.6666666666667
jaatha,"An estimation method that can use computer simulations to
    approximate maximum-likelihood estimates even when the likelihood function can not
    be evaluated directly. It can be applied whenever it is feasible to conduct many
    simulations, but works best when the data is approximately Poisson distributed.
    It was originally designed for demographic inference in evolutionary
    biology. It has optional support for conducting coalescent simulation using
    the 'coala' package.",2019-07-10,Paul Staab,https://github.com/statgenlmu/jaatha,TRUE,https://github.com/statgenlmu/jaatha,27682,3,2019-11-02T10:51:58Z,9227.333333333334
jabr,"Interface to browse, list, and fetch data about West Java.",2020-01-13,Muhammad Aswan Syahputra,https://github.com/aswansyahputra/jabr,TRUE,https://github.com/aswansyahputra/jabr,3133,3,2019-12-25T06:35:09Z,1044.3333333333333
jack,"Symbolic calculation and evaluation of the Jack polynomials, zonal polynomials, and Schur polynomials. Mainly based on Demmel & Koev's paper (2006) <doi:10.1090/S0025-5718-05-01780-1>. Zonal polynomials and Schur polynomials are particular cases of Jack polynomials. Zonal polynomials appear in random matrix theory. Schur polynomials appear in the field of combinatorics.",2019-09-16,Stéphane Laurent,https://github.com/stla/jackR,TRUE,https://github.com/stla/jackr,4105,0,2019-09-17T14:00:49Z,NA
jackalope,"Simply and efficiently
    simulates (i) variants from reference genomes and (ii) reads from both Illumina 
    <https://www.illumina.com/>
    and Pacific Biosciences (PacBio) <https://www.pacb.com/> platforms. 
    It can either read reference genomes from FASTA files or simulate new ones.
    Genomic variants can be simulated using summary statistics, phylogenies, 
    Variant Call Format (VCF) files, and coalescent simulations—the latter of which
    can include selection, recombination, and demographic fluctuations.
    'jackalope' can simulate single, paired-end, or mate-pair Illumina reads, 
    as well as PacBio reads.
    These simulations include sequencing errors, mapping qualities, multiplexing,
    and optical/polymerase chain reaction (PCR) duplicates.
    Simulating Illumina sequencing is based on ART
    by Huang et al. (2012) <doi:10.1093/bioinformatics/btr708>.
    PacBio sequencing simulation is based on 
    SimLoRD  by Stöcker et al. (2016) <doi:10.1093/bioinformatics/btw286>.
    All outputs can be written to standard file formats.",2020-02-28,Lucas A. Nell [cph,https://github.com/lucasnell/jackalope,TRUE,https://github.com/lucasnell/jackalope,5656,6,2020-06-09T16:34:11Z,942.6666666666666
jagsUI,"A set of wrappers around 'rjags' functions to run Bayesian analyses in 'JAGS' (specifically, via 'libjags').  A single function call can control adaptive, burn-in, and sampling MCMC phases, with MCMC chains run in sequence or in parallel. Posterior distributions are automatically summarized (with the ability to exclude some monitored nodes if desired) and functions are available to generate figures based on the posteriors (e.g., predictive check plots, traceplots). Function inputs, argument syntax, and output format are nearly identical to the 'R2WinBUGS'/'R2OpenBUGS' packages to allow easy switching between MCMC samplers. ",2019-07-30,Ken Kellner,https://github.com/kenkellner/jagsUI,TRUE,https://github.com/kenkellner/jagsui,86760,20,2020-03-09T20:35:15Z,4338
JamendoR,"Provides an interface to 'Jamendo' API <https://developer.jamendo.com/v3.0>.
              Pull audio, features and other information for a given 
              'Jamendo' user (including yourself!) or enter an artist's -, album's -, 
              or track's name and retrieve the available information in seconds.",2019-04-15,Maximilian Greil,http://github.com/MaxGreil/JamendoR,TRUE,https://github.com/maxgreil/jamendor,4530,2,2019-09-11T11:46:54Z,2265
janitor,"The main janitor functions can: perfectly format data.frame column
    names; provide quick counts of variable combinations (i.e., frequency
    tables and crosstabs); and isolate duplicate records. Other janitor functions
    nicely format the tabulation results. These tabulate-and-report functions
    approximate popular features of SPSS and Microsoft Excel. This package
    follows the principles of the ""tidyverse"" and works well with the pipe function
    %>%. janitor was built with beginning-to-intermediate R users in mind and is
    optimized for user-friendliness. Advanced R users can already do everything
    covered here, but with janitor they can do it faster and save their thinking for
    the fun stuff.",2020-04-12,Sam Firke,https://github.com/sfirke/janitor,TRUE,https://github.com/sfirke/janitor,458531,826,2020-06-03T20:56:36Z,555.1222760290557
jaod,"Client for the Directory of Open Access Journals ('DOAJ')
    (<https://doaj.org/>). API documentation at
    <https://doaj.org/api/v1/docs>. Methods included for working with
    all 'DOAJ' API routes: fetch article information by identifier,
    search for articles, fetch journal information by identifier,
    and search for journals.",2019-09-04,Scott Chamberlain,https://github.com/ropensci/jaod,TRUE,https://github.com/ropensci/jaod,9757,10,2019-12-09T13:23:13Z,975.7
jdx,Simplifies and extends data exchange between 'R' and 'Java'.,2020-06-04,Floid R. Gilbert,https://github.com/floidgilbert/jdx,TRUE,https://github.com/floidgilbert/jdx,9874,6,2020-06-04T20:20:28Z,1645.6666666666667
jeek,"Provides a fast and scalable joint estimator for integrating additional knowledge in learning multiple related sparse Gaussian Graphical Models (JEEK). The JEEK algorithm can be used to fast estimate multiple related precision matrices in a large-scale. For instance, it can identify multiple gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogeneous data sets, this tool can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(jeek) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Arshdeep Sekhon, Yanjun Qi ""A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models"" (ICML 2018) <arXiv:1806.00548>.",2018-07-07,Beilun Wang,https://github.com/QData/jeek,TRUE,https://github.com/qdata/jeek,7532,1,2019-08-28T16:30:45Z,7532
jetpack,"Manage project dependencies from your DESCRIPTION file. Create a reproducible virtual environment with minimal additional files in your project. Provides tools to add, remove, and update dependencies as well as install existing dependencies with a single function.",2019-07-01,Andrew Kane,https://github.com/ankane/jetpack,TRUE,https://github.com/ankane/jetpack,10875,196,2020-05-25T18:05:42Z,55.484693877551024
jiebaR,"Chinese text segmentation, keyword extraction and speech tagging
    For R.",2019-12-13,Qin Wenfeng,https://github.com/qinwf/jiebaR/,TRUE,https://github.com/qinwf/jiebar,117358,280,2019-12-13T15:16:53Z,419.1357142857143
jjb,"Set of common functions used for manipulating colors,
    detecting and interacting with 'RStudio', modeling, formatting, determining
    users' operating system, feature scaling, and more!",2020-01-08,James Balamuta,https://github.com/coatless/jjb,TRUE,https://github.com/coatless/jjb,8041,1,2020-01-07T19:47:51Z,8041
JMbayes,Shared parameter models for the joint modeling of longitudinal and time-to-event data using MCMC; Dimitris Rizopoulos (2016) <doi:10.18637/jss.v072.i07>. ,2020-01-09,Dimitris Rizopoulos,https://github.com/drizopoulos/JMbayes,TRUE,https://github.com/drizopoulos/jmbayes,45377,27,2020-01-16T19:06:46Z,1680.6296296296296
jmotif,"Implements time series z-normalization, SAX, HOT-SAX, VSM, SAX-VSM, RePair, and RRA
    algorithms facilitating time series motif (i.e., recurrent pattern), discord (i.e., anomaly),
    and characteristic pattern discovery along with interpretable time series classification.",2020-02-13,Pavel Senin,https://github.com/jMotif/jmotif-R,TRUE,https://github.com/jmotif/jmotif-r,21098,49,2020-02-13T20:42:43Z,430.57142857142856
jmvcore,"A framework for creating rich interactive analyses for the jamovi
    platform (see <https://www.jamovi.org> for more information).",2020-06-02,Jonathon Love,https://www.jamovi.org,TRUE,https://github.com/jamovi/jmvcore,113038,2,2020-06-02T05:19:28Z,56519
joineR,"Analysis of repeated measurements and time-to-event data via random
    effects joint models. Fits the joint models proposed by Henderson and colleagues
    <doi:10.1093/biostatistics/1.4.465> (single event time) and by Williamson and
    colleagues (2008) <doi:10.1002/sim.3451> (competing risks events time) to a
    single continuous repeated measure. The time-to-event data is modelled using a 
    (cause-specific) Cox proportional hazards regression model with time-varying 
    covariates. The longitudinal outcome is modelled using a linear mixed effects
    model. The association is captured by a latent Gaussian process. The model is 
    estimated using am Expectation Maximization algorithm. Some plotting functions 
    and the variogram are also included. This project is funded by the Medical 
    Research Council (Grant numbers G0400615 and MR/M013227/1).",2020-02-08,Pete Philipson,https://github.com/petephilipson/joineR/,TRUE,https://github.com/petephilipson/joiner,42731,2,2020-02-08T21:50:19Z,21365.5
joineRmeta,"Fits joint models of the type proposed by Henderson and colleagues 
    (2000) <doi:10.1093/biostatistics/1.4.465>, but extends to the multi-study, 
    meta-analytic case. Functions for meta-analysis of a single longitudinal and 
    a single  time-to-event outcome from multiple studies using joint models.  
    Options to produce plots for multi study joint data, to pool joint model 
    fits from 'JM' and 'joineR' packages in a two stage meta-analysis, and to 
    model multi-study joint data in a one stage meta-analysis.",2020-01-24,Maria Sudell,https://github.com/mesudell/joineRmeta/,TRUE,https://github.com/mesudell/joinermeta,8252,1,2020-01-24T13:49:21Z,8252
joinet,"Implements high-dimensional multivariate regression by stacked generalisation (Wolpert 1992 <doi:10.1016/S0893-6080(05)80023-1>). For positively correlated outcomes, a single multivariate regression is typically more predictive than multiple univariate regressions. Includes functions for model fitting, extracting coefficients, outcome prediction, and performance measurement.",2019-11-13,Armin Rauschenberger,https://github.com/rauschenberger/joinet,TRUE,https://github.com/rauschenberger/joinet,4191,2,2020-06-08T15:58:21Z,2095.5
JointAI,"Provides joint analysis and imputation of (generalized) 
    linear and cumulative logit regression models, (generalized) linear and 
    cumulative logit mixed models and parametric (Weibull) as well as Cox
    proportional hazards survival models with incomplete (covariate) data in 
    the Bayesian framework.
    The package performs some preprocessing of the data and creates a 'JAGS'
    model, which will then automatically be passed to 'JAGS' 
    <http://mcmc-jags.sourceforge.net> with the help of 
    the package 'rjags'.
    It also provides summary and plotting functions for the output and allows 
    the user to export imputed values.",2020-02-12,Nicole S. Erler,https://nerler.github.io/JointAI,TRUE,https://github.com/nerler/jointai,12257,8,2020-02-22T07:04:30Z,1532.125
JointNets,"An end-to-end package for learning multiple sparse Gaussian graphical models and nonparanormal models from Heterogeneous Data with Additional Knowledge. It is able to simulate multiple related graphs as well as produce samples drawn from them. Multiple state-of-the-art sparse Gaussian graphical model estimators are included to both multiple and difference estimation. Graph visualization is available in 2D as well as 3D, designed specifically for brain. Moreover, a set of evaluation metrics are integrated for easy exploration with model validity. Finally, classification using graphical model is achieved with Quadratic Discriminant Analysis. The package comes with multiple demos with datasets from various fields. Methods references: SIMULE (Wang B et al. (2017) <doi:10.1007/s10994-017-5635-7>), WSIMULE (Singh C et al. (2017) <arXiv:1709.04090v2>), DIFFEE (Wang B et al. (2018) <arXiv:1710.11223>), JEEK (Wang B et al. (2018) <arXiv:1806.00548>), JGL(Danaher P et al. (2012) <arXiv:1111.0324>) and kdiffnet (Sekhon A et al, preprint for publication).",2019-07-29,Arshdeep Sekhon,https://github.com/QData/JointNets,TRUE,https://github.com/qdata/jointnets,6709,2,2019-11-14T10:27:41Z,3354.5
josaplay,"Josa in Korean is often determined by judging the previous word. 
            When writing reports using Rmd, a function that prints the 
            appropriate investigation for each case is helpful. 
            The 'josaplay' package then evaluates the previous word 
            to determine which josa is appropriate.",2019-05-16,Chanyub Park,https://github.com/mrchypark/josaplay,TRUE,https://github.com/mrchypark/josaplay,4039,2,2019-07-29T05:47:14Z,2019.5
jpmesh,"Helpful functions for using mesh code (80km to 125m) data in Japan. Visualize mesh code using 'ggplot2' and 'leaflet', etc.",2020-05-06,Shinya Uryu,https://uribo.github.io/jpmesh,TRUE,https://github.com/uribo/jpmesh,19909,29,2020-06-02T23:08:08Z,686.5172413793103
jpndistrict,"Utilizing the data that Japanese administration area provided 
    by the National Land Numerical Information download service (<http://nlftp.mlit.go.jp/ksj/index.html>). 
    This package provide map data is based on the Digital Map 25000 (Map Image) published 
    by Geospatial Information Authority of Japan (Approval No.603FY2017 information usage <http://www.gsi.go.jp>).",2020-04-20,Shinya Uryu,https://uribo.github.io/jpndistrict,TRUE,https://github.com/uribo/jpndistrict,15508,13,2020-06-09T23:52:40Z,1192.923076923077
jqr,"Client for 'jq', a 'JSON' processor (<https://stedolan.github.io/jq/>), 
    written in C. 'jq' allows the following with 'JSON' data: index into, parse, 
    do calculations, cut up and filter, change key names and values, perform 
    conditionals and comparisons, and more.",2018-10-22,Scott Chamberlain,https://github.com/ropensci/jqr,TRUE,https://github.com/ropensci/jqr,269831,113,2020-04-27T16:57:45Z,2387.8849557522126
jrc,An 'httpuv' based bridge between R and 'JavaScript'. Provides an easy way to exchange commands and data between a web page and a currently running R session. ,2020-02-07,Svetlana Ovchinnikova,https://github.com/anders-biostat/jrc,TRUE,https://github.com/anders-biostat/jrc,7031,9,2020-02-07T10:42:33Z,781.2222222222222
js,"A set of utilities for working with JavaScript syntax in R.
    Includes tools to parse, tokenize, compile, validate, reformat, optimize 
    and analyze JavaScript code.",2020-06-03,Jeroen Ooms,https://github.com/jeroen/js,TRUE,https://github.com/jeroen/js,23482,54,2020-06-03T17:41:20Z,434.85185185185185
jSDM,"Fits joint species distribution models ('jSDM')
    in a hierarchical Bayesian framework (Warton et al. 2015
    <doi:10.1016/j.tree.2015.09.007>). The Gibbs sampler is written
    in C++. It uses 'Rcpp', 'Armadillo' and 'GSL' to maximize computation
    efficiency.",2019-07-02,Ghislain Vieilledent,"https://ecology.ghislainv.fr/jSDM,
https://github.com/ghislainv/jSDM",TRUE,https://github.com/ghislainv/jsdm,3806,4,2019-08-14T00:32:48Z,951.5
jskm,The function 'jskm()' creates publication quality Kaplan-Meier plot with at risk tables below. 'svyjskm()' provides plot for weighted Kaplan-Meier estimator. ,2020-05-17,Jinseob Kim,https://github.com/jinseob2kim/jskm,TRUE,https://github.com/jinseob2kim/jskm,7949,2,2020-05-17T14:27:39Z,3974.5
JSmediation,"A set of helper functions to conduct joint-significance tests for 
  mediation analysis, as recommended by 
  Yzerbyt, Muller, Batailler, & Judd. (2018) <doi:10.1037/pspa0000132>.",2020-01-30,Cédric Batailler,https://github.com/cedricbatailler/JSmediation,TRUE,https://github.com/cedricbatailler/jsmediation,4677,5,2020-01-30T14:09:46Z,935.4
jsmodule,"'RStudio' addins and 'Shiny' modules for descriptive statistics, regression and survival analysis.",2020-06-04,Jinseob Kim,https://github.com/jinseob2kim/jsmodule,TRUE,https://github.com/jinseob2kim/jsmodule,8403,6,2020-06-04T16:31:30Z,1400.5
jsonlite,"A fast JSON parser and generator optimized for statistical data
    and the web. Started out as a fork of 'RJSONIO', but has been completely
    rewritten in recent versions. The package offers flexible, robust, high
    performance tools for working with JSON in R and is particularly powerful
    for building pipelines and interacting with a web API. The implementation is
    based on the mapping described in the vignette (Ooms, 2014). In addition to
    converting JSON data from/to R objects, 'jsonlite' contains functions to
    stream, validate, and prettify JSON data. The unit tests included with the
    package verify that all edge cases are encoded and decoded consistently for
    use with dynamic data in systems and applications.",2020-02-02,Jeroen Ooms,"https://arxiv.org/abs/1403.2805 (paper)
https://jeroen.cran.dev/jsonlite (docs)",TRUE,https://github.com/jeroen/jsonlite,23614745,256,2020-05-25T22:11:28Z,92245.09765625
jsonvalidate,"Uses the node library 'is-my-json-valid' or 'ajv' to
    validate 'JSON' against a 'JSON' schema.  Drafts 04, 06 and 07 of
    'JSON' schema are supported.",2019-06-25,Rich FitzJohn,https://github.com/ropensci/jsonvalidate,TRUE,https://github.com/ropensci/jsonvalidate,161697,34,2020-04-05T15:02:24Z,4755.794117647059
jsr223,"Provides a high-level integration for the 'Java' platform that makes 'Java' objects easy to use from within 'R'; provides a unified interface to integrate 'R' with several programming languages; and features extensive data exchange between 'R' and 'Java'. The 'jsr223'-supported programming languages include 'Groovy', 'JavaScript', 'JRuby' ('Ruby'), 'Jython' ('Python'), and 'Kotlin'. Any of these languages can use and extend 'Java' classes in natural syntax. Furthermore, solutions developed in any of the 'jsr223'-supported languages are also accessible to 'R' developers. The 'jsr223' package also features callbacks, script compiling, and string interpolation. In all, 'jsr223' significantly extends the computing capabilities of the 'R' software environment.",2020-06-04,Floid R. Gilbert,https://github.com/floidgilbert/jsr223,TRUE,https://github.com/floidgilbert/jsr223,8397,7,2020-06-04T20:19:56Z,1199.5714285714287
jstable,"Create regression tables from generalized linear model(GLM), generalized estimating equation(GEE), generalized linear mixed-effects model(GLMM), Cox proportional hazards model, survey-weighted generalized linear model(svyglm) and survey-weighted Cox model results for publication.",2020-06-02,Jinseob Kim,https://github.com/jinseob2kim/jstable,TRUE,https://github.com/jinseob2kim/jstable,10903,2,2020-05-05T18:00:58Z,5451.5
jstor,"Functions and helpers to import metadata, ngrams and full-texts 
    delivered by Data for Research by JSTOR. ",2020-06-04,Thomas Klebel,"https://github.com/ropensci/jstor, https://docs.ropensci.org/jstor",TRUE,https://github.com/ropensci/jstor,11078,35,2020-06-03T22:54:52Z,316.51428571428573
jsTree,"Create and customize interactive trees using the 'jQuery' 'jsTree' <https://www.jstree.com/>
    plugin library and the 'htmlwidgets' package. These trees can be used
    directly from the R console, from 'RStudio', in Shiny apps and R Markdown documents.",2017-10-24,Jonathan Sidi,https://github.com/metrumresearchgroup/jsTree,TRUE,https://github.com/metrumresearchgroup/jstree,9616,22,2019-10-14T23:58:27Z,437.09090909090907
jtools,"This is a collection of tools that the author (Jacob) has written
  for the purpose of more efficiently understanding and sharing the results of
  (primarily) regression analyses. There are also a number of miscellaneous
  functions for statistical and programming purposes. Just about everything 
  supports models from the survey package.",2020-04-21,Jacob A. Long,https://jtools.jacob-long.com,TRUE,https://github.com/jacob-long/jtools,170416,88,2020-04-21T13:14:58Z,1936.5454545454545
JuliaCall,"Provides an R interface to 'Julia',
    which is a high-level, high-performance dynamic programming language
    for numerical computing, see <https://julialang.org/> for more information.
    It provides a high-level interface as well as a low-level interface.
    Using the high level interface, you could call any 'Julia' function just like
    any R function with automatic type conversion. Using the low level interface,
    you could deal with C-level SEXP directly while enjoying the convenience of
    using a high-level programming language like 'Julia'.",2019-11-27,Changcheng Li,https://github.com/Non-Contradiction/JuliaCall,TRUE,https://github.com/non-contradiction/juliacall,129965,125,2020-03-30T20:40:48Z,1039.72
JWileymisc,"Miscellaneous tools and functions,
    including: generate descriptive statistics tables,
    format output, visualize relations among variables or check
    distributions, and generic functions for residual and
    model diagnostics. ",2020-04-28,Joshua F. Wiley,"http://joshuawiley.com/JWileymisc,
https://github.com/JWiley/JWileymisc",TRUE,https://github.com/jwiley/jwileymisc,15172,2,2020-05-25T13:14:20Z,7586
jwutil,"This is a set of simple utilities for various data
    manipulation and testing tasks.  The goal is to use core R tools well,
    without bringing in many dependencies. Main areas of interest are
    semi-automated data frame manipulation, such as converting factors in
    multiple binary indicator columns. There are testing functions which
    provide 'testthat' expectations to permute arguments to function
    calls. There are functions and data to test extreme numbers, dates,
    and bad input of various kinds which should allow testing failure and
    corner cases, which can be used for fuzzing your functions. The test
    suite has many examples of usage.",2019-05-06,Jack O. Wasey,https://github.com/jackwasey/jwutil,TRUE,https://github.com/jackwasey/jwutil,11342,0,2020-01-18T19:58:17Z,NA
kableExtra,"Build complex HTML or 'LaTeX' tables using 'kable()' from 'knitr' 
    and the piping syntax from 'magrittr'. Function 'kable()' is a light weight 
    table generator coming from 'knitr'. This package simplifies the way to 
    manipulate the HTML or 'LaTeX' codes generated by 'kable()' and allows 
    users to construct complex tables and customize styles using a readable 
    syntax. ",2019-03-16,Hao Zhu,"http://haozhu233.github.io/kableExtra/,
https://github.com/haozhu233/kableExtra",TRUE,https://github.com/haozhu233/kableextra,1137675,389,2019-12-17T03:23:55Z,2924.6143958868893
kamila,"Implements methods for clustering mixed-type data,
  specifically combinations of continuous and nominal data. Special attention
  is paid to the often-overlooked problem of equitably balancing the
  contribution of the continuous and categorical variables. This package
  implements KAMILA clustering, a novel method for clustering
  mixed-type data in the spirit of k-means clustering. It does not require
  dummy coding of variables, and is efficient enough to scale to rather large
  data sets. Also implemented is Modha-Spangler clustering, which uses a
  brute-force strategy to maximize the cluster separation simultaneously in the
  continuous and categorical variables. For more information, see Foss, Markatou,
  Ray, & Heching (2016) <doi:10.1007/s10994-016-5575-7> and Foss & Markatou
  (2018) <doi:10.18637/jss.v083.i13>.",2020-03-13,Alexander Foss,https://github.com/ahfoss/kamila,TRUE,https://github.com/ahfoss/kamila,14668,10,2020-03-13T04:36:13Z,1466.8
kayadata,"Provides data for Kaya identity variables (population, gross 
             domestic product, primary energy consumption, and energy-related 
             CO2 emissions) for the world and for individual nations, and 
             utility functions for looking up data,  plotting trends of 
             Kaya variables, and plotting the fuel mix for a given country
             or region. The Kaya identity (Yoichi Kaya and Keiichi Yokobori, 
             ""Environment, Energy, and Economy: Strategies for Sustainability"" 
             (United Nations University Press, 1998) and 
             <https://en.wikipedia.org/wiki/Kaya_identity>) expresses a nation's 
             or region's greenhouse gas emissions in terms of its population, 
             per-capita Gross Domestic Product, the energy intensity of its 
             economy, and the carbon-intensity of its energy supply.",2020-01-08,Jonathan Gilligan,"https://jonathan-g.github.io/kayadata/,
https://github.com/jonathan-g/kayadata",TRUE,https://github.com/jonathan-g/kayadata,5159,0,2020-03-27T07:07:35Z,NA
kcopula,"Provides the density and distribution function of the bivariate 
    K-copula by Wollschläger and Schäfer (2016) <doi:10.21314/JOR.2016.342>.",2020-04-07,Marcel Kremer,https://github.com/mlkremer/kcopula,TRUE,https://github.com/mlkremer/kcopula,908,0,2020-02-12T16:12:48Z,NA
kde1d,"Provides an efficient implementation of univariate local polynomial
    kernel density estimators that can handle bounded and discrete data. See 
    Geenens (2014) <arXiv:1303.4121>, 
    Geenens and Wang (2018) <arXiv:1602.04862>, 
    Nagler (2018a) <arXiv:1704.07457>, 
    Nagler (2018b) <arXiv:1705.05431>.",2019-11-18,Thomas Nagler,https://github.com/tnagler/kde1d,TRUE,https://github.com/tnagler/kde1d,14045,6,2019-11-15T17:56:21Z,2340.8333333333335
kdtools,"Provides various tools for working with multidimensional
  data in R and C++, including extremely fast nearest-neighbor- and range-
  queries without the overhead of linked tree nodes.",2019-04-23,Timothy Keitt,https://github.com/thk686/kdtools,TRUE,https://github.com/thk686/kdtools,8007,6,2020-05-26T01:27:57Z,1334.5
keras,"Interface to 'Keras' <https://keras.io>, a high-level neural
  networks 'API'. 'Keras' was developed with a focus on enabling fast experimentation,
  supports both convolution based networks and recurrent networks (as well as
  combinations of the two), and runs seamlessly on both 'CPU' and 'GPU' devices.",2020-05-19,Daniel Falbel [ctb,https://keras.rstudio.com,TRUE,https://github.com/rstudio/keras,531246,634,2020-05-25T11:32:03Z,837.9274447949526
kerastuneR,"'Keras Tuner' <https://keras-team.github.io/keras-tuner/> is a hypertuning framework made for humans. 
             It aims at making the life of AI practitioners, hypertuner 
             algorithm creators and model designers as simple as possible by 
             providing them with a clean and easy to use API for hypertuning. 
             'Keras Tuner' makes moving from a base model to a hypertuned one quick and 
             easy by only requiring you to change a few lines of code.",2020-05-14,Turgut Abdullayev,https://github.com/henry090/kerastuneR,TRUE,https://github.com/henry090/kerastuner,1578,24,2020-06-08T17:26:23Z,65.75
kernelboot,"Smoothed bootstrap and functions for random generation from
             univariate and multivariate kernel densities. It does not
             estimate kernel densities.",2020-02-13,Tymoteusz Wolodzko,https://github.com/twolodzko/kernelboot,TRUE,https://github.com/twolodzko/kernelboot,16251,0,2020-02-13T21:26:27Z,NA
KernelKnn,Extends the simple k-nearest neighbors algorithm by incorporating numerous kernel functions and a variety of distance metrics. The package takes advantage of 'RcppArmadillo' to speed up the calculation of distances between observations.,2019-11-29,Lampros Mouselimis,https://github.com/mlampros/KernelKnn,TRUE,https://github.com/mlampros/kernelknn,40909,10,2019-12-04T15:08:46Z,4090.9
kernscr,"Kernel Machine Score Test for Pathway Analysis in the Presence of 
    Semi-Competing Risks. Method is detailed in: Neykov, Hejblum & Sinnott (2018) 
    <doi: 10.1177/0962280216653427>.",2019-08-20,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/kernscr,12016,0,2019-08-20T17:00:06Z,NA
keyATM,"Fits keyword assisted topic models (keyATM) using collapsed Gibbs samplers. The keyATM combines the latent dirichlet allocation (LDA) models with a small number of keywords selected by researchers in order to improve the interpretability and topic classification of the LDA. The keyATM can also incorporate covariates and directly model time trends. The keyATM is proposed in Eshima, Imai, and Sasaki (2020) <arXiv:2004.05964>.",2020-06-02,Shusei Eshima,https://keyatm.github.io/keyATM/,TRUE,https://github.com/keyatm/keyatm,948,21,2020-06-03T01:24:45Z,45.142857142857146
KeyboardSimulator,Control your keyboard and mouse with R code by simulating key presses and mouse clicks. The input simulation is implemented with the Windows API.,2020-04-14,Jim Chen,https://github.com/ChiHangChen/KeyboardSimulator,TRUE,https://github.com/chihangchen/keyboardsimulator,13886,12,2020-04-12T13:31:45Z,1157.1666666666667
keyholder,"Tools for keeping track of information, named
    ""keys"", about rows of data frame like objects. This is done by
    creating special attribute ""keys"" which is updated after every change
    in rows (subsetting, ordering, etc.).  This package is designed to
    work tightly with 'dplyr' package.",2020-05-09,Evgeni Chasnovski,"https://echasnovski.github.io/keyholder/,
https://github.com/echasnovski/keyholder/",TRUE,https://github.com/echasnovski/keyholder,10596,6,2020-05-31T19:00:24Z,1766
KFAS,"State space modelling is an efficient and flexible framework for 
    statistical inference of a broad class of time series and other data. KFAS 
    includes computationally efficient functions for Kalman filtering, smoothing, 
    forecasting, and simulation of multivariate exponential family state space models, 
    with observations from Gaussian, Poisson, binomial, negative binomial, and gamma 
    distributions. See the paper by Helske (2017) <doi:10.18637/jss.v078.i10> for details.",2019-06-10,Jouni Helske,NA,TRUE,https://github.com/helske/kfas,188309,37,2020-05-28T04:50:15Z,5089.4324324324325
kfda,"Kernel Fisher Discriminant Analysis (KFDA) is performed using Kernel Principal Component Analysis (KPCA) and Fisher Discriminant Analysis (FDA).
    There are some similar packages. First, 'lfda' is a package that performs Local Fisher Discriminant Analysis (LFDA) and performs other functions.
    In particular, 'lfda' seems to be impossible to test because it needs the label information of the data in the function argument. Also, the 'ks' package has a limited dimension, which makes it difficult to analyze properly.
    This package is a simple and practical package for KFDA based on the paper of Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) <DOI:10.1016/j.patcog.2003.10.015>.",2017-09-27,Donghwan Kim,https://github.com/ainsuotain/kfda,TRUE,https://github.com/ainsuotain/kfda,8758,1,2020-05-13T04:28:30Z,8758
khroma,"An implementation of Paul Tol's colour schemes for
    use with 'graphics' or 'ggplot2'. These schemes are ready for each
    type of data (qualitative, diverging or sequential), with colours that
    are distinct for all people, including colour-blind readers. This
    package provides tools to simulate colour-blindness and to test how
    well the colours of any palette are identifiable. Several scientific
    thematic schemes (geologic timescale, land cover, FAO soils, etc.) are
    also implemented.",2019-10-26,Nicolas Frerebeau,"http://khroma.archaeo.science,
http://github.com/nfrerebeau/khroma,
https://cran.r-project.org/package=khroma",TRUE,https://github.com/nfrerebeau/khroma,8644,18,2020-05-24T22:02:11Z,480.22222222222223
kit,"Basic functions, implemented in C, for large data manipulation. Fast vectorised ifelse()/nested if()/switch() functions, psum()/pprod() functions equivalent to pmin()/pmax() plus others which are missing from base R. Most of these functions are callable at C level.",2020-05-24,Morgan Jacob,NA,TRUE,https://github.com/2005m/kit,533,12,2020-05-24T15:38:36Z,44.416666666666664
kitagawa,"Provides tools to calculate the theoretical hydrodynamic response
    of an aquifer undergoing harmonic straining or pressurization, or analyze
    measured responses. There are
    two classes of models here: (1) for sealed wells, based on the model of 
    Kitagawa et al (2011, <doi:10.1029/2010JB007794>), 
    and (2) for open wells, based on the models of
    Cooper et al (1965, <doi:10.1029/JZ070i016p03915>), 
    Hsieh et al (1987, <doi:10.1029/WR023i010p01824>), 
    Rojstaczer (1988, <doi:10.1029/JB093iB11p13619>), and 
    Liu et al (1989, <doi:10.1029/JB094iB07p09453>). These models treat 
    strain (or aquifer head) as an input to the
    physical system, and fluid-pressure (or water height) as the output. The
    applicable frequency band of these models is characteristic of seismic
    waves, atmospheric pressure fluctuations, and solid earth tides.",2018-09-14,Andrew J Barbour,https://github.com/abarbour/kitagawa,TRUE,https://github.com/abarbour/kitagawa,16684,2,2020-01-13T22:09:04Z,8342
kiwisR,"A wrapper for querying 'WISKI' databases via the 'KiWIS' 'REST' API. 'WISKI' is an 'SQL' relational database 
  used for the collection and storage of water data developed by KISTERS and 'KiWIS' is a 'REST' service that provides
  access to 'WISKI' databases via HTTP requests (<https://water.kisters.de/en/technology-trends/kisters-and-open-data/>). 
  Contains a list of default databases (called 'hubs') and also allows users to provide their own 'KiWIS' URL. 
  Supports the entire query process- from metadata to specific time series values. All data is returned as tidy tibbles.",2019-12-15,Ryan Whaley,https://github.com/rywhale/kiwisR,TRUE,https://github.com/rywhale/kiwisr,6501,3,2019-12-15T15:35:50Z,2167
kknn,"Weighted k-Nearest Neighbors for Classification, Regression and Clustering.",2016-03-26,Klaus Schliep,https://github.com/KlausVigo/kknn,TRUE,https://github.com/klausvigo/kknn,286443,20,2020-02-21T15:04:47Z,14322.15
klassR,"Functions to search, retrieve and apply classifications 
  and codelists using Statistics Norway's API <https://www.ssb.no/klass> 
  from the system 'KLASS'. Retrieves classifications by date with options 
  to choose language, hierarchical level and formatting.",2019-10-09,Susie Jentoft,NA,TRUE,https://github.com/statisticsnorway/klassr,3007,0,2019-06-13T05:23:16Z,NA
klexdatr,"Six relational 'tibbles' from the Kootenay Lake Large Trout Exploitation study.
  The study which ran from 2008 to 2014 caught, tagged and released large Rainbow Trout and Bull Trout
  in Kootenay Lake by boat angling. 
  The fish were tagged with internal acoustic tags and/or high reward external tags
  and subsequently detected by an acoustic receiver array as well as reported by anglers.
  The data are analysed by Thorley and Andrusak (1994) <doi:10.7717/peerj.2874>
  to estimate the natural and fishing mortality of both species.",2020-05-04,Joe Thorley,https://github.com/poissonconsulting/klexdatr,TRUE,https://github.com/poissonconsulting/klexdatr,526,0,2020-05-08T01:14:29Z,NA
klic,"Kernel Learning Integrative Clustering (KLIC) is an algorithm that allows to combine multiple kernels, each representing a different measure of the similarity between a set of observations. The contribution of each kernel on the final clustering is weighted according to the amount of information carried by it. As well as providing the functions required to perform the kernel-based clustering, this package also allows the user to simply give the data as input: the kernels are then built using consensus clustering. Different strategies to choose the best number of clusters are also available. For further details please see Cabassi and Kirk (2019) <arXiv:1904.07701>.",2020-04-03,Alessandra Cabassi,http://github.com/acabassi/klic,TRUE,https://github.com/acabassi/klic,1000,2,2020-05-15T15:36:31Z,500
klustR,"Used to create dynamic, interactive 'D3.js' 
  based parallel coordinates and principal component plots in 'R'.
  The plots make visualizing k-means or other clusters simple and informative.",2019-06-19,McKay Davis,"https://mckaymdavis.github.io/klustR/,
https://github.com/McKayMDavis/klustR",TRUE,https://github.com/mckaymdavis/klustr,3133,2,2019-07-04T10:59:27Z,1566.5
kmc,"Given constraints for right censored data, we use a recursive computational algorithm to calculate the the ""constrained"" Kaplan-Meier estimator. The constraint is assumed given in linear estimating equations or mean functions. We also illustrate how this leads to the empirical likelihood ratio test with right censored data and accelerated failure time model with given coefficients. EM algorithm from emplik package is used to get the initial value. The properties and performance of the EM algorithm is discussed in Mai Zhou and Yifan Yang (2015)<doi: 10.1007/s00180-015-0567-9> and Mai Zhou and Yifan Yang (2017) <10.1002/wics.1400>. More applications could be found in Mai Zhou (2015) <doi: 10.1201/b18598>.",2020-03-16,Yifan Yang,http://github.com/yfyang86/kmc,TRUE,https://github.com/yfyang86/kmc,14419,1,2020-05-12T05:44:28Z,14419
kmeRs,"Contains tools to calculate similarity score matrix for DNA k-mers. The pairwise
            similarity score is calculated using PAM or BLOSUM substitution matrix. The 
            results are evaluated by similarity score calculated by Needleman-Wunsch 
            (1970) <doi:10.1016/0022-2836(70)90057-4> global or Smith-Waterman 
            (1981) <doi:10.1016/0022-2836(81)90087-5> local alignment. Higher similarity
            score indicates more similar sequences for BLOSUM and less similar sequences
            for PAM matrix; 30, 40, 70, 120, 250 and 62, 45, 50, 62, 80, 100 matrix 
            versions are available for PAM and BLOSUM, respectively. ",2018-11-03,Rafal Urniaz,https://rafalurniaz.github.io/kmeRs/,TRUE,https://github.com/rafalurniaz/kmers,5894,1,2019-09-14T11:51:04Z,5894
knitcitations,"Provides the ability to create dynamic citations
    in which the bibliographic information is pulled from the web rather
    than having to be entered into a local database such as 'bibtex' ahead of
    time. The package is primarily aimed at authoring in the R 'markdown'
    format, and can provide outputs for web-based authoring such as linked
    text for inline citations.  Cite using a 'DOI', URL, or
    'bibtex' file key.  See the package URL for details.",2019-09-15,Carl Boettiger,https://github.com/cboettig/knitcitations,TRUE,https://github.com/cboettig/knitcitations,131733,185,2019-09-13T23:13:30Z,712.0702702702703
knitr,"Provides a general-purpose tool for dynamic report generation in R
    using Literate Programming techniques.",2020-02-06,Yihui Xie,https://yihui.org/knitr/,TRUE,https://github.com/yihui/knitr,20246849,1926,2020-06-03T03:56:41Z,10512.382658359295
knn.covertree,"
    Similarly to the 'FNN' package, this package allows calculation of the k nearest neighbors (kNN) of a data matrix.
    The implementation is based on cover trees introduced by
    Alina Beygelzimer, Sham Kakade, and John Langford (2006) <doi:10.1145/1143844.1143857>.",2019-10-28,Philipp Angerer,https://github.com/flying-sheep/knn.covertree,TRUE,https://github.com/flying-sheep/knn.covertree,6540,1,2019-11-09T13:40:04Z,6540
knnp,"Two main functionalities are provided. One of them is predicting values with 
    k-nearest neighbors algorithm and the other is optimizing the parameters k and d of the algorithm.
    These are carried out in parallel using multiple threads.",2020-01-10,Daniel Bastarrica Lacalle,https://github.com/Grasia/knnp,TRUE,https://github.com/grasia/knnp,7456,1,2020-01-15T12:38:14Z,7456
kntnr,"Retrieve data from 'kintone' (<https://www.kintone.com/>) via its API.
    'kintone' is an enterprise application platform.",2020-04-08,Hiroaki Yutani,https://yutannihilation.github.io/kntnr/,TRUE,https://github.com/yutannihilation/kntnr,13748,3,2020-04-08T13:07:47Z,4582.666666666667
kofdata,"Read Swiss time series data from the 'KOF Datenservice' API, <https://datenservice.kof.ethz.ch>. The API provides macroeconomic survey data, business cycle and further macro economic time series about Switzerland. The package itself is a set of wrappers around the 'KOF Datenservice' API. The 'kofdata' package is able to consume public information as well as data that requires an API token. ",2020-03-28,Matthias Bannert,https://github.com/KOF-ch/kofdata,TRUE,https://github.com/kof-ch/kofdata,8737,2,2020-03-28T13:50:34Z,4368.5
komaletter,"An R Markdown template for writing beautiful yet versatile letters,
  using the 'KOMA-Script' letter class 'scrlttr2' and an adaptation of the
  'pandoc-letter' template. 'scrlttr2' provides layouts for many different
  window envelope types and the possibility to define your own.",2019-12-07,Robert Nuske,https://github.com/rnuske/komaletter,TRUE,https://github.com/rnuske/komaletter,9190,20,2020-02-23T10:32:43Z,459.5
konfound,"Statistical methods that quantify the conditions necessary to alter
    inferences, also known as sensitivity analysis, are becoming increasingly
    important to a variety of quantitative sciences. A series of recent works,
    including Frank (2000) <doi:10.1177/0049124100029002001> and Frank et al.
    (2013) <doi:10.3102/0162373713493129> extend previous sensitivity analyses
    by considering the characteristics of omitted variables or unobserved cases
    that would change an inference if such variables or cases were observed. These
    analyses generate statements such as ""an omitted variable would have to be
    correlated at xx with the predictor of interest (e.g., treatment) and outcome
    to invalidate an inference of a treatment effect"". Or ""one would have to replace
    pp percent of the observed data with null hypothesis cases to invalidate the
    inference"". We implement these recent developments of sensitivity analysis and
    provide modules to calculate these two robustness indices and generate such
    statements in R. In particular, the functions konfound(), pkonfound() and 
    mkonfound() allow users to calculate the robustness of inferences for a user's 
    own model, a single published study and multiple studies respectively.",2020-02-26,Joshua M Rosenberg,https://github.com/jrosen48/konfound,TRUE,https://github.com/jrosen48/konfound,9387,3,2020-05-19T15:58:09Z,3129
KScorrect,"Implements the Lilliefors-corrected Kolmogorov-Smirnov test for use
    in goodness-of-fit tests, suitable when population parameters are unknown and
    must be estimated by sample statistics. P-values are estimated by simulation.
    Can be used with a variety of continuous distributions, including normal,
    lognormal, univariate mixtures of normals, uniform, loguniform, exponential,
    gamma, and Weibull distributions. Functions to generate random numbers and
    calculate density, distribution, and quantile functions are provided for use
    with the log uniform and mixture distributions.",2019-07-03,Phil Novack-Gottshall,https://github.com/pnovack-gottshall/KScorrect,TRUE,https://github.com/pnovack-gottshall/kscorrect,18108,2,2019-07-05T16:24:33Z,9054
ksharp,"Clustering typically assigns data points into discrete groups, but the clusters can sometimes be indistinct. Cluster sharpening adjusts an existing clustering to create contrast between groups. This package provides a general interface for cluster sharpening along with several implementations based on different excision criteria.",2020-01-26,Tomasz Konopka,https://github.com/tkonopka/ksharp,TRUE,https://github.com/tkonopka/ksharp,2027,3,2020-01-27T18:09:11Z,675.6666666666666
kuniezu,"Data set on Japan's national geography. 
    Provides tools for efficient processing and visualization of 
    unique coordinate systems.",2020-05-23,Shinya Uryu,"https://uribo.github.io/kuniezu/, https://github.com/uribo/kuniezu",TRUE,https://github.com/uribo/kuniezu,618,11,2020-05-28T03:39:26Z,56.18181818181818
kwb.hantush,"Calculation groundwater mounding beneath an
    infiltration basin based on the Hantush (1967) equation
    (<doi:10.1029/WR003i001p00227>). The correct implementation is shown
    with a verification example based on a USGS report (page 25,
    <https://pubs.usgs.gov/sir/2010/5102/support/sir2010-5102.pdf#page=35>).",2019-09-17,Michael Rustler,"https://kwb-r.github.io/kwb.hantush,
https://github.com/KWB-R/kwb.hantush",TRUE,https://github.com/kwb-r/kwb.hantush,15224,0,2019-10-01T09:16:15Z,NA
labelled,"Work with labelled data imported from 'SPSS'
    or 'Stata' with 'haven' or 'foreign'. This package
    provides useful functions to deal with ""haven_labelled"" and
    ""haven_labelled_spss"" classes introduced by 'haven' package.",2020-05-25,Joseph Larmarange,http://larmarange.github.io/labelled/,TRUE,https://github.com/larmarange/labelled,1323950,35,2020-06-03T12:05:57Z,37827.142857142855
labelmachine,"Assign meaningful labels to data frame columns.
    'labelmachine' manages your label assignment rules in 'yaml' files
    and makes it easy to use the same labels in multiple projects.",2019-10-11,Adrian Maldet,"https://a-maldet.github.io/labelmachine,
https://github.com/a-maldet/labelmachine",TRUE,https://github.com/a-maldet/labelmachine,3055,6,2019-10-08T08:58:09Z,509.1666666666667
lacunaritycovariance,"Functions for estimating the gliding box
    lacunarity (GBL), covariance, and pair-correlation of a random closed
    set (RACS) in 2D from a binary coverage map (e.g. presence-absence
    land cover maps).  Contains a number of newly-developed
    covariance-based estimators of GBL (Hingee et al., 2019)
    <doi:10.1007/s13253-019-00351-9> and balanced estimators, proposed by
    Picka (2000) <http://www.jstor.org/stable/1428408>, for covariance,
    centred covariance, and pair-correlation.  Also contains methods for
    estimating contagion-like properties of RACS and simulating 2D Boolean
    models.  Binary coverage maps are usually represented as raster images
    with pixel values of TRUE, FALSE or NA, with NA representing
    unobserved pixels.  A demo for extracting such a binary map from a
    geospatial data format is provided.  Binary maps may also be
    represented using polygonal sets as the foreground, however for most
    computations such maps are converted into raster images.  The package
    is based on research conducted during the author's PhD studies.",2020-01-31,Kassel Liam Hingee,https://github.com/kasselhingee/lacunaritycovariance,TRUE,https://github.com/kasselhingee/lacunaritycovariance,4152,1,2020-01-31T01:08:05Z,4152
LaF,"Methods for fast access to large ASCII files.  Currently the
    following file formats are supported: comma separated format (CSV) and fixed
    width format. It is assumed that the files are too large to fit into memory,
    although the package can also be used to efficiently access files that do
    fit into memory. Methods are provided to access and process files blockwise.
    Furthermore, an opened file can be accessed as one would an ordinary
    data.frame. The LaF vignette gives an overview of the functionality
    provided.",2020-03-23,Jan van der Laan,https://github.com/djvanderlaan/LaF,TRUE,https://github.com/djvanderlaan/laf,104999,49,2020-03-31T19:31:34Z,2142.8367346938776
LAGOSNE,"Client for programmatic access to the Lake
    Multi-scaled Geospatial and Temporal database <https://lagoslakes.org>, with functions
    for accessing lake water quality and ecological context data for the US.",2019-07-29,Joseph Stachelek,https://github.com/cont-limno/LAGOSNE,TRUE,https://github.com/cont-limno/lagosne,11303,5,2020-06-08T14:59:26Z,2260.6
Lahman,"Provides the tables from the 'Sean Lahman Baseball Database' as
    a set of R data.frames. It uses the data on pitching, hitting and fielding
    performance and other tables from 1871 through 2018, as recorded in the 2019
    version of the database. Documentation examples show how many baseball
    questions can be investigated.",2020-06-08,Chris Dalzell,https://CRAN.R-project.org/package=Lahman,TRUE,https://github.com/cdalzell/lahman,886833,27,2020-06-09T23:43:20Z,32845.666666666664
lakemorpho,"Lake morphometry metrics are used by limnologists to understand,
    among other things, the ecological processes in a lake. Traditionally, these
    metrics are calculated by hand, with planimeters, and increasingly with
    commercial GIS products. All of these methods work; however, they are either
    outdated, difficult to reproduce, or require expensive licenses to use. The
    'lakemorpho' package provides the tools to calculate a typical suite
    of these metrics from an input elevation model and lake polygon. The metrics
    currently supported are: fetch, major axis, minor axis, major/minor axis 
    ratio, maximum length, maximum width, mean width, maximum depth, mean depth, 
    shoreline development, shoreline length, surface area, and volume.",2018-02-11,Jeffrey W. Hollister,http://www.github.com/jhollist/lakemorpho,TRUE,https://github.com/jhollist/lakemorpho,16764,5,2020-05-30T00:24:57Z,3352.8
LAM,"
    Includes some procedures for latent variable modeling with a 
    particular focus on multilevel data.
    The 'LAM' package contains mean and covariance structure modelling
    for multivariate normally distributed data (mlnormal(); Longford, 1987;
    <doi:10.1093/biomet/74.4.817>), a general Metropolis-Hastings algorithm 
    (amh(); Roberts & Rosenthal, 2001, <doi:10.1214/ss/1015346320>) and 
    penalized maximum likelihood estimation (pmle(); Cole, Chu & Greenland, 
    2014; <doi:10.1093/aje/kwt245>).",2020-05-09,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/LAM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/lam,13126,2,2020-05-09T10:31:25Z,6563
LambertW,"Lambert W x F distributions are a generalized framework to analyze
    skewed, heavy-tailed data. It is based on an input/output system, where the
    output random variable (RV) Y is a non-linearly transformed version of an input
    RV X ~ F with similar properties as X, but slightly skewed (heavy-tailed).
    The transformed RV Y has a Lambert W x F distribution. This package contains
    functions to model and analyze skewed, heavy-tailed data the Lambert Way:
    simulate random samples, estimate parameters, compute quantiles, and plot/
    print results nicely. Probably the most important function is 'Gaussianize',
    which works similarly to 'scale', but actually makes the data Gaussian.
    A do-it-yourself toolkit allows users to define their own Lambert W x
    'MyFavoriteDistribution' and use it in their analysis right away.",2020-06-08,Georg M. Goerg,"https://github.com/gmgeorg/LambertW http://arxiv.org/abs/0912.4554
http://arxiv.org/abs/1010.2265 http://arxiv.org/abs/1602.02200",TRUE,https://github.com/gmgeorg/lambertw,104665,0,2020-06-09T01:44:08Z,NA
landscapemetrics,"Calculates landscape metrics for categorical landscape patterns in 
    a tidy workflow. 'landscapemetrics' reimplements the most common metrics from
    'FRAGSTATS' (<https://www.umass.edu/landeco/research/fragstats/fragstats.html>) 
    and new ones from the current literature on landscape metrics.
    This package supports 'raster' spatial objects and takes 
    RasterLayer, RasterStacks, RasterBricks or lists of RasterLayer from the
    'raster' package as input arguments. It further provides utility functions
    to visualize patches, select metrics and building blocks to develop new 
    metrics.",2020-05-15,Maximillian H.K. Hesselbarth,https://r-spatialecology.github.io/landscapemetrics/,TRUE,https://github.com/r-spatialecology/landscapemetrics,25205,135,2020-06-02T06:50:44Z,186.7037037037037
landscapeR,"Simulates categorical maps on actual geographical realms, starting from either empty landscapes or landscapes provided by the user (e.g. land use maps). Allows to tweak or create landscapes while retaining a high degree of control on its features, without the hassle of specifying each location attribute. In this it differs from other tools which generate null or neutral landscapes in a theoretical space. The basic algorithm currently implemented uses a simple agent style/cellular automata growth model, with no rules (apart from areas of exclusion) and von Neumann neighbourhood (four cells, aka Rook case). Outputs are raster dataset exportable to any common GIS format.",2017-07-05,Dario Masante,https://github.com/dariomasante/landscapeR,TRUE,https://github.com/dariomasante/landscaper,13721,0,2020-02-04T11:36:38Z,NA
landscapetools,"Provides utility functions for some of the less-glamorous tasks involved
    in landscape analysis. It includes functions to coerce raster data to the
    common tibble format and vice versa, it helps with flexible reclassification
    tasks of raster data and it provides a function to merge multiple raster.
    Furthermore, 'landscapetools' helps landscape scientists to visualize their
    data by providing optional themes and utility functions to plot single
    landscapes, rasterstacks, -bricks and lists of raster.",2019-02-25,Marco Sciaini,https://ropensci.github.io/landscapetools/,TRUE,https://github.com/ropensci/landscapetools,12094,40,2020-01-28T13:44:49Z,302.35
languageserver,"An implementation of the Language Server Protocol
    for R. The Language Server protocol is used by an editor client to
    integrate features like auto completion. See
    <https://microsoft.github.io/language-server-protocol> for details.",2020-05-25,Randy Lai,https://github.com/REditorSupport/languageserver,TRUE,https://github.com/reditorsupport/languageserver,58912,244,2020-06-02T23:40:29Z,241.44262295081967
languageserversetup,"Allows to install the R 'languageserver' with all dependencies
    into a separate library and use that independent installation
    automatically when R is instantiated as a language server process.
    Useful for making language server seamless to use without
    running into package version conflicts.",2020-04-10,Jozef Hajnala,https://github.com/jozefhajnala/languageserversetup,TRUE,https://github.com/jozefhajnala/languageserversetup,2545,8,2020-04-08T08:45:02Z,318.125
LaplacesDemon,Provides a complete environment for Bayesian inference using a variety of different samplers (see ?LaplacesDemon for an overview). The README describes the history of the package development process.,2020-02-06,Henrik Singmann,https://github.com/LaplacesDemonR/LaplacesDemon,TRUE,https://github.com/laplacesdemonr/laplacesdemon,146228,56,2020-02-09T12:37:18Z,2611.214285714286
lassopv,"Estimate the p-values for predictors x against target variable y in lasso regression, using the regularization strength when each predictor enters the active set of regularization path for the first time as the statistic. This is based on the assumption that predictors (of the same variance) that (first) become active earlier tend to be more significant. Three null distributions are supported: normal and spherical, which are computed separately for each predictor and analytically under approximation, which aims at efficiency and accuracy for small p-values.",2018-02-22,Lingfei Wang,https://github.com/lingfeiwang/lassopv,TRUE,https://github.com/lingfeiwang/lassopv,13222,0,2019-12-03T21:24:25Z,NA
latentnet,"Fit and simulate latent position and cluster models for statistical networks. See Krivitsky and Handcock (2008) <10.18637/jss.v024.i05> and Krivitsky, Handcock, Raftery, and Hoff (2009) <10.1016/j.socnet.2009.04.001>.",2020-03-22,Pavel N. Krivitsky,http://www.statnet.org,TRUE,https://github.com/statnet/latentnet,125817,10,2020-03-21T07:46:35Z,12581.7
later,"Executes arbitrary R or C functions some time after the current
    time, after the R execution stack has emptied. The functions are scheduled
    in an event loop.",2020-06-05,Joe Cheng,https://github.com/r-lib/later,TRUE,https://github.com/r-lib/later,9354988,99,2020-06-05T17:56:33Z,94494.82828282828
latte,"Back-end connections to 'LattE' (<https://www.math.ucdavis.edu/~latte>) 
	for counting lattice points and integration inside convex polytopes and 
	'4ti2' (<http://www.4ti2.de/>) for algebraic, geometric, and combinatorial 
	problems on linear spaces and front-end tools facilitating their use in the 
	'R' ecosystem.",2019-03-25,David Kahle,https://github.com/dkahle/latte,TRUE,https://github.com/dkahle/latte,5023,1,2020-05-03T22:24:53Z,5023
lattice,"A powerful and elegant high-level data visualization
  system inspired by Trellis graphics, with an emphasis on
  multivariate data. Lattice is sufficient for typical graphics needs,
  and is also flexible enough to handle most nonstandard requirements.
  See ?Lattice for an introduction.",2020-04-02,Deepayan Sarkar,http://lattice.r-forge.r-project.org/,TRUE,https://github.com/deepayan/lattice,3671621,34,2020-05-14T12:10:17Z,107988.85294117648
lava,"A general implementation of Structural Equation Models
	with latent variables (MLE, 2SLS, and composite likelihood
	estimators) with both continuous, censored, and ordinal
	outcomes (Holst and Budtz-Joergensen (2013) <doi:10.1007/s00180-012-0344-y>).
	Mixture latent variable models and non-linear latent variable models
	(Holst and Budtz-Joergensen (2019) <doi:10.1093/biostatistics/kxy082>).
	The package also provides methods for graph exploration (d-separation,
	back-door criterion), simulation of general non-linear latent variable
	models, and estimation of influence functions for a broad range of
	statistical models. ",2020-03-05,Klaus K. Holst,https://github.com/kkholst/lava,TRUE,https://github.com/kkholst/lava,2702681,28,2020-06-05T07:54:26Z,96524.32142857143
lavaanPlot,"Plots path diagrams from models in lavaan using the plotting
    functionality from the DiagrammeR package. DiagrammeR provides nice path diagrams 
    via Graphviz, and these functions make it easy to generate these diagrams from a
    lavaan path model without having to write the DOT language graph specification.",2018-04-25,Alex Lishinski,https://github.com/alishinski/lavaanPlot,TRUE,https://github.com/alishinski/lavaanplot,22259,19,2020-02-26T18:35:32Z,1171.5263157894738
lavaSearch2,"Tools for model specification in the latent variable framework
    (add-on to the 'lava' package). The package contains three main functionalities:
    Wald tests/F-tests with improved control of the type 1 error in small samples,
    adjustment for multiple comparisons when searching for local dependencies,
    and adjustment for multiple comparisons when doing inference for multiple latent variable models. ",2020-03-18,Brice Ozenne,https://github.com/bozenne/lavaSearch2,TRUE,https://github.com/bozenne/lavasearch2,13796,0,2019-07-25T08:14:34Z,NA
lawn,"Client for 'Turfjs' (<http://turfjs.org>) for
    'geospatial' analysis. The package revolves around using 'GeoJSON'
    data. Functions are included for creating 'GeoJSON' data objects,
    measuring aspects of 'GeoJSON', and combining, transforming,
    and creating random 'GeoJSON' data objects.",2019-02-01,Scott Chamberlain,https://github.com/ropensci/lawn,TRUE,https://github.com/ropensci/lawn,28333,56,2020-04-27T17:02:01Z,505.94642857142856
lax,"Performs adjusted inferences based on model objects fitted, using 
    maximum likelihood estimation, by the extreme value analysis packages
    'evd' <https://cran.r-project.org/package=evd>, 
    'evir' <https://cran.r-project.org/package=evir>, 
    'extRemes' <https://cran.r-project.org/package=extRemes>, 
    'fExtremes' <https://cran.r-project.org/package=fExtremes>, 
    'ismev' <https://cran.r-project.org/package=ismev>, 
    'mev' <https://cran.r-project.org/package=mev>, 
    'POT' <https://cran.r-project.org/package=POT> and
    'texmex' <https://cran.r-project.org/package=texmex>. 
    Adjusted standard errors and an adjusted loglikelihood are provided, using    
    the 'chandwich' package <https://cran.r-project.org/package=chandwich>
    and the object-oriented features of the 'sandwich' package 
    <https://cran.r-project.org/package=sandwich>. The adjustment is based on a 
    robust sandwich estimator of the parameter covariance matrix, based on the 
    methodology in Chandler and Bate (2007) <doi:10.1093/biomet/asm015>. This 
    can be used for cluster correlated data when interest lies in the 
    parameters of the marginal distributions, or for performing inferences that 
    are robust to certain types of model misspecification.  Univariate extreme 
    value models, including regression models, are supported.  ",2019-12-05,Paul J. Northrop,"https://paulnorthrop.github.io/lax/,
http://github.com/paulnorthrop/lax",TRUE,https://github.com/paulnorthrop/lax,3528,0,2020-02-05T20:11:08Z,NA
lazybar,"A simple progress bar showing estimated remaining time. 
    Multiple forecast methods and user defined forecast method for 
    the remaining time are supported.",2020-04-28,Yangzhuoran Yang,"https://pkg.yangzhuoranyang.com/lazybar/,
https://github.com/FinYang/lazybar/",TRUE,https://github.com/finyang/lazybar,635,0,2020-04-29T06:01:12Z,NA
lazyraster,"Read raster data at a specified resolution on-demand via 'GDAL' 
 (the Geospatial Data Abstraction Library <https://gdal.org/>). Augments the 
 'raster' package by never reading data from a raster source until necessary for 
 generating an in-memory 'raster' object. A 'lazyraster' object may be cropped 
 and converted to 'raster' object, and by default will only read a small amount 
 of data sufficient for an overall summary. The amount of data read can be 
 controlled by specifying the output dimensions. ",2019-10-09,Michael Sumner,https://github.com/hypertidy/lazyraster,TRUE,https://github.com/hypertidy/lazyraster,2916,18,2019-11-11T11:27:47Z,162
lazytrade,"Provide sets of functions and methods to learn and practice data science using idea of algorithmic trading.
    Main goal is to process information within ""Decision Support System"" to come up with analysis or predictions.
    There are several utilities such as dynamic and adaptive risk management using reinforcement learning
    and even functions to generate predictions of price changes using pattern recognition deep regression learning.",2020-03-23,Vladimir Zhbanko,"https://vladdsm.github.io/myblog_attempt/topics/lazy%20trading/,
https://github.com/vzhomeexperiments/lazytrade",TRUE,https://github.com/vzhomeexperiments/lazytrade,5357,11,2020-03-22T12:20:27Z,487
LBSPR,"Simulate expected equilibrium length composition, yield-per-recruit, and
    the spawning potential ratio (SPR) using the length-based SPR (LBSPR) model. Fit the LBSPR
    model to length data to estimate  selectivity, relative apical fishing mortality, and
    the spawning potential ratio for data-limited fisheries.
    See Hordyk et al (2016) <doi:10.1139/cjfas-2015-0422> for more information about the
    LBSPR assessment method.",2019-12-05,Adrian Hordyk,https://github.com/AdrianHordyk/LBSPR,TRUE,https://github.com/adrianhordyk/lbspr,15899,2,2020-05-25T16:48:17Z,7949.5
lcars,"Provides Shiny widgets and theme that support a 'Library Computer Access/Retrieval System' (LCARS) aesthetic for Shiny apps. 
    The package also includes functions for adding a minimal LCARS theme to static 'ggplot2' graphs. 
    More details about LCARS can be found at <https://en.wikipedia.org/wiki/LCARS>.",2020-02-06,Matthew Leonawicz,https://github.com/leonawicz/lcars,TRUE,https://github.com/leonawicz/lcars,1907,39,2020-02-21T14:32:29Z,48.8974358974359
lchemix,"A joint latent class model where a hierarchical structure exists, with an interaction between female and male partners of a couple. A Bayesian perspective to inference and Markov chain Monte Carlo algorithms to obtain posterior estimates of model parameters. The reference paper is: Beom Seuk Hwang, Zhen Chen, Germaine M.Buck Louis, Paul S. Albert, (2018) ""A Bayesian multi-dimensional couple-based latent risk model with an application to infertility"". Biometrics, 75, 315-325. <doi:10.1111/biom.12972>.",2020-02-28,Weimin Zhang,"http://github.com/wzhang17/lchemix.git,
https://doi.org/10.1111/biom.12972",TRUE,https://github.com/wzhang17/lchemix,1580,0,2020-02-20T20:53:14Z,NA
lcmm,"Estimation of various extensions of the mixed models including latent class mixed models, joint latent latent class mixed models and mixed models for curvilinear univariate or multivariate longitudinal outcomes using a maximum likelihood estimation method (Proust-Lima, Philipps, Liquet (2017) <doi:10.18637/jss.v078.i02>).",2020-06-03,Cecile Proust-Lima,NA,TRUE,https://github.com/cecileproust-lima/lcmm,53866,5,2020-06-03T11:15:43Z,10773.2
lcopula,"Collections of functions allowing random number generations and
    estimation of 'Liouville' copulas, as described in Belzile and Neslehova (2017) <doi:10.1016/j.jmva.2017.05.008>.",2019-07-06,Leo Belzile,NA,TRUE,https://github.com/lbelzile/lcopula,49751,0,2019-07-06T14:36:12Z,NA
lcsm,"Helper functions to implement univariate and bivariate latent change score models in R using the 'lavaan' package.
  For details about Latent Change Score Modeling (LCSM) see McArdle (2009) <doi:10.1146/annurev.psych.60.110707.163612> and Grimm, An, McArdle, Zonderman and Resnick (2012) <doi:10.1080/10705511.2012.659627>.
  The package automatically generates 'lavaan' syntax for different model specifications and varying timepoints.
  The 'lavaan' syntax generated by this package can be returned and further specifications can be added manually.
  Longitudinal plots as well as simplified path diagrams can be created to visualise data and model specifications.
  Estimated model parameters and fit statistics can be extracted as data frames.
  Data for different univariate and bivariate LCSM can be simulated by specifying estimates for model parameters to explore their effects.
  This package combines the strengths of other R packages like 'lavaan', 'broom', and 'semPlot' by generating 'lavaan' syntax that helps these packages work together.",2020-06-05,Milan Wiedemann,https://milanwiedemann.github.io/lcsm/,TRUE,https://github.com/milanwiedemann/lcsm,0,2,2020-06-07T20:05:49Z,0
ldaPrototype,"Determine a Prototype from a number of runs of Latent Dirichlet Allocation (LDA) measuring its similarities with S-CLOP: A procedure to select the LDA run with highest mean pairwise similarity, which is measured by S-CLOP (Similarity of multiple sets by Clustering with Local Pruning), to all other runs. LDA runs are specified by its assignments leading to estimators for distribution parameters. Repeated runs lead to different results, which we encounter by choosing the most representative LDA run as prototype.",2020-01-10,Jonas Rieger,"https://github.com/JonasRieger/ldaPrototype,
https://doi.org/10.5281/zenodo.3597978",TRUE,https://github.com/jonasrieger/ldaprototype,2146,3,2020-05-15T14:08:42Z,715.3333333333334
ldat,"Tools for working with vectors and data sets that are too large
    to keep in memory. Extends the basic functionality provided in the 'lvec'
    package. Provides basis statistical functionality of 'lvec' objects, such
    as arithmetic operations and calculating means and sums. Also implements
    'data.frame'-like objects storing its data in 'lvec' objects.",2020-03-13,Jan van der Laan,https://github.com/djvanderlaan/ldat,TRUE,https://github.com/djvanderlaan/ldat,9906,4,2020-03-11T06:35:50Z,2476.5
LDATS,"Combines Latent Dirichlet Allocation (LDA) and Bayesian multinomial
    time series methods in a two-stage analysis to quantify dynamics in
	high-dimensional temporal data. LDA decomposes multivariate data into 
    lower-dimension latent groupings, whose relative proportions are modeled
    using generalized Bayesian time series models that include abrupt 
    changepoints and smooth dynamics. The methods are described in Blei
    et al. (2003) <doi:10.1162/jmlr.2003.3.4-5.993>, Western and Kleykamp
   (2004) <doi:10.1093/pan/mph023>, Venables and Ripley 
   (2002, ISBN-13:978-0387954578), and Christensen et al. 
   (2018) <doi:10.1002/ecy.2373>.",2020-03-19,Juniper L. Simonis,"https://weecology.github.io/LDATS,
https://github.com/weecology/LDATS",TRUE,https://github.com/weecology/ldats,4035,18,2020-03-19T08:56:46Z,224.16666666666666
ldatuning,"For this first version only metrics to estimate the best fitting
    number of topics are implemented.",2020-04-21,Murzintcev Nikita,https://github.com/nikita-moor/ldatuning,TRUE,https://github.com/nikita-moor/ldatuning,41750,40,2020-04-21T14:28:00Z,1043.75
LDlinkR,"Provides access to the LDlink API (<https://ldlink.nci.nih.gov/?tab=apiaccess>)
    using the R console.  This programmatic access facilitates researchers who are interested
    in performing batch queries in 1000 Genomes Project data using LDlink.",2020-03-02,Timothy A. Myers,https://ldlink.nci.nih.gov,TRUE,https://github.com/cbiit/ldlinkr,4732,4,2020-03-02T21:11:07Z,1183
ldsr,"Streamflow (and climate) reconstruction using Linear Dynamical Systems. 
    The advantage of this method is the additional state trajectory which can reveal more information 
    about the catchment or climate system. For details of the method please refer to Nguyen and Galelli 
    (2018) <doi:10.1002/2017WR022114>.",2020-05-04,Hung Nguyen,https://github.com/ntthung/ldsr,TRUE,https://github.com/ntthung/ldsr,520,1,2020-05-05T02:09:02Z,520
LeafArea,"An interface for the image processing program 'ImageJ', which
    allows a rapid digital image analysis for particle sizes. This package includes
    function to write an 'ImageJ' macro which is optimized for a leaf area analysis by
    default.",2019-07-03,Masatoshi Katabuchi,https://github.com/mattocci27/LeafArea,TRUE,https://github.com/mattocci27/leafarea,19693,15,2019-07-04T00:07:56Z,1312.8666666666666
leafem,"Provides extensions for packages 'leaflet' & 'mapdeck', 
    many of which are used by package 'mapview'. 
    Focus is on functionality readily available in 
    Geographic Information Systems such as 'Quantum GIS'. Includes functions
    to display coordinates of mouse pointer position, query image values via 
    mouse pointer and zoom-to-layer buttons. Additionally, provides a feature 
    type agnostic function to add points, lines, polygons to a map.",2020-04-05,Tim Appelhans,https://github.com/r-spatial/leafem,TRUE,https://github.com/r-spatial/leafem,225576,48,2020-06-09T14:45:26Z,4699.5
leaflet,"Create and customize interactive maps using the 'Leaflet'
    JavaScript library and the 'htmlwidgets' package. These maps can be used
    directly from the R console, from 'RStudio', in Shiny applications and R Markdown
    documents.",2019-11-16,Joe Cheng,http://rstudio.github.io/leaflet/,TRUE,https://github.com/rstudio/leaflet,1639280,602,2020-04-06T13:59:11Z,2723.056478405316
leaflet.extras2,"Several 'leaflet' plugins are integrated, which are available as extension to the 'leaflet' package.",2020-05-18,Gatscha Sebastian,"https://trafficonese.github.io/leaflet.extras2,
https://github.com/trafficonese/leaflet.extras2",TRUE,https://github.com/trafficonese/leaflet.extras2,306,19,2020-05-19T09:06:28Z,16.105263157894736
leaflet.providers,"Contains third-party map tile provider information from
    'Leaflet.js', <https://github.com/leaflet-extras/leaflet-providers>, to be
    used with the 'leaflet' R package. Additionally, 'leaflet.providers'
    enables users to retrieve up-to-date provider information between package
    updates.",2019-11-09,Leslie Huang,https://github.com/rstudio/leaflet.providers,TRUE,https://github.com/rstudio/leaflet.providers,315883,6,2019-11-12T16:22:13Z,52647.166666666664
leafR,"A set of functions for analyzing the structure 
  of forests based on the leaf area density (LAD) and leaf area index (LAI) measures 
  calculated from Airborne Laser Scanning (ALS), i.e., scanning lidar (Light Detection 
  and Ranging) data. The methodology is discussed and described in 
  Almeida et al. (2019) <doi:10.3390/rs11010092> and 
  Stark et al. (2012) <doi:10.1111/j.1461-0248.2012.01864.x>.",2019-08-02,Danilo Roberti Alves de Almeida,https://github.com/DRAAlmeida/leafR,TRUE,https://github.com/draalmeida/leafr,4450,2,2019-08-01T23:28:02Z,2225
leaftime,"Use the 'leaflet-timeline' plugin with a leaflet widget to add an
    interactive slider with play, pause, and step buttons to explore temporal
    geographic spatial data changes.",2020-01-26,Jonathan Skeate (leaflet-timeline library,https://github.com/timelyportfolio/leaftime,TRUE,https://github.com/timelyportfolio/leaftime,3598,44,2020-01-26T16:02:04Z,81.77272727272727
learnPopGen,"Conducts various numerical analyses and simulations in population genetics and evolutionary theory, primarily for the purpose of teaching (and learning about) key concepts in population & quantitative genetics, and evolutionary theory.",2019-05-20,Liam J. Revell,http://github.com/liamrevell/learnPopGen,TRUE,https://github.com/liamrevell/learnpopgen,9613,15,2019-06-10T14:37:24Z,640.8666666666667
learnr,"Create interactive tutorials using R Markdown. Use a combination
  of narrative, figures, videos, exercises, and quizzes to create self-paced
  tutorials for learning about R and R packages.",2020-02-13,Barret Schloerke,"https://rstudio.github.io/learnr/,
https://github.com/rstudio/learnr",TRUE,https://github.com/rstudio/learnr,80690,334,2020-06-08T18:22:38Z,241.5868263473054
ledger,"Utilities for querying plain text accounting files from 'Ledger', 'HLedger', and 'Beancount'.",2020-05-18,Trevor L Davis,"https://github.com/trevorld/r-ledger,
https://trevorldavis.com/R/ledger",TRUE,https://github.com/trevorld/r-ledger,8321,22,2020-05-18T17:31:32Z,378.22727272727275
legco,"Fetching data from Hong Kong Legislative Council's open data API in R. 
    Functions correspond to the data endpoints of the API. 
    Documentations of supported API databases:
    <https://www.legco.gov.hk/odata/english/billsdb.html>, 
    <https://www.legco.gov.hk/odata/english/hansard-db.html>,
    <https://www.legco.gov.hk/odata/english/attendance-db.html>,
    <https://www.legco.gov.hk/odata/english/schedule-db.html> and
    <https://www.legco.gov.hk/odata/english/vrdb.html>.",2020-03-31,Elgar Teo,https://github.com/elgarteo/legco,TRUE,https://github.com/elgarteo/legco,1019,0,2020-06-07T07:28:50Z,NA
legislatoR,"Facilitates access to the Comparative Legislators Database (CLD). The CLD includes political, sociodemographic, career, online presence, public attention, and visual information for over 45,000 contemporary and historical politicians from ten countries.",2020-04-24,Sascha Goebel,https://github.com/saschagobel/legislatoR,TRUE,https://github.com/saschagobel/legislator,651,51,2020-06-03T12:39:34Z,12.764705882352942
legocolors,"Provides a dataset containing several color naming conventions established by multiple sources, along with associated color metadata.
    The package also provides related helper functions for mapping among the different Lego color naming conventions and between Lego colors, hex colors, and 'R' color names, 
    making it easy to convert any color palette to one based on existing Lego colors while keeping as close to the original color palette as possible.
    The functions use nearest color matching based on Euclidean distance in RGB space. 
    Naming conventions for color mapping include those from 'BrickLink' (<https://www.bricklink.com>), 'The Lego Group' (<https://www.lego.com>), 'LDraw' (<https://www.ldraw.org/>), and 'Peeron' (<http://www.peeron.com/>).",2019-04-28,Matthew Leonawicz,https://github.com/leonawicz/legocolors,TRUE,https://github.com/leonawicz/legocolors,5261,2,2020-03-31T02:43:17Z,2630.5
leiden,"Implements the 'Python leidenalg' module to be called in R.
    Enables clustering using the leiden algorithm for partition a graph into communities.
    See the 'Python' repository for more details: <https://github.com/vtraag/leidenalg>
    Traag et al (2018) From Louvain to Leiden: guaranteeing well-connected communities. <arXiv:1810.08473>.",2020-02-04,S. Thomas Kelly,https://github.com/TomKellyGenetics/leiden,TRUE,https://github.com/tomkellygenetics/leiden,92030,9,2020-05-01T08:45:29Z,10225.555555555555
leri,"Finds and downloads Landscape Evaporative Response
    Index (LERI) data, then reads the data into 'R' using the 'raster'
    package. The LERI product measures anomalies in actual
    evapotranspiration, to support drought monitoring and early warning
    systems. More info on LERI is available at
    <https://www.esrl.noaa.gov/psd/leri/>.",2019-09-09,Max Joseph,https://github.com/earthlab/leri,TRUE,https://github.com/earthlab/leri,3304,2,2019-09-09T16:47:54Z,1652
letsR,"Handling, processing, and analyzing geographic
    data on species' distributions and environmental variables. 
    Read Vilela & Villalobos (2015) <doi: 10.1111/2041-210X.12401> for details.",2020-04-14,Bruno Vilela & Fabricio Villalobos,"http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12401/abstract,
https://github.com/macroecology/letsR",TRUE,https://github.com/macroecology/letsr,22713,14,2020-05-13T21:32:21Z,1622.357142857143
LexisNexisTools,"My PhD supervisor once told me that everyone doing newspaper
    analysis starts by writing code to read in files from the 'LexisNexis' newspaper
    archive (retrieved e.g., from <http://www.nexis.com/> or any of the partner
    sites). However, while this is a nice exercise I do recommend, not everyone has
    the time. This package takes files downloaded from the newspaper archive of
    'LexisNexis', reads them into R and offers functions for further processing.",2020-06-03,Johannes Gruber,https://github.com/JBGruber/LexisNexisTools,TRUE,https://github.com/jbgruber/lexisnexistools,10317,48,2020-06-04T08:19:57Z,214.9375
LexisPlotR,"Plots empty Lexis grids, adds lifelines and highlights certain areas of the grid, like cohorts and age groups.",2020-01-12,Philipp Ottolinger,https://github.com/ottlngr/LexisPlotR,TRUE,https://github.com/ottlngr/lexisplotr,16860,9,2020-01-12T14:22:12Z,1873.3333333333333
lfda,"Functions for performing and visualizing Local Fisher Discriminant
    Analysis(LFDA), Kernel Fisher Discriminant Analysis(KLFDA), and Semi-supervised
    Local Fisher Discriminant Analysis(SELF).",2019-07-31,Yuan Tang,https://github.com/terrytangyuan/lfda,TRUE,https://github.com/terrytangyuan/lfda,49218,72,2019-12-19T03:33:07Z,683.5833333333334
lfe,"Transforms away factors with many levels prior to doing an OLS.
  Useful for estimating linear models with multiple group fixed effects, and for
  estimating linear models which uses factors with many levels as pure control variables.
  Includes support for instrumental variables, conditional F statistics for weak instruments,
  robust and multi-way clustered standard errors, as well as limited mobility bias correction.",2019-12-17,Simen Gaure,https://github.com/sgaure/lfe,TRUE,https://github.com/sgaure/lfe,218041,38,2019-12-13T12:05:34Z,5737.921052631579
lgr,"A flexible, feature-rich yet light-weight logging
    framework based on 'R6' classes. It supports hierarchical loggers,
    custom log levels, arbitrary data fields in log events, logging to
    plaintext, 'JSON', (rotating) files, memory buffers, and databases, as
    well as email and push notifications. For a full list of features with
    examples please refer to the package vignette.",2020-03-20,Stefan Fleck,https://s-fleck.github.io/lgr,TRUE,https://github.com/s-fleck/lgr,67257,50,2020-05-01T09:25:36Z,1345.14
lhs,Provides a number of methods for creating and augmenting Latin Hypercube Samples and Orthogonal Array Latin Hypercube Samples.,2020-04-13,Rob Carnell,https://github.com/bertcarnell/lhs,TRUE,https://github.com/bertcarnell/lhs,264521,8,2020-04-13T11:35:19Z,33065.125
liayson,"Given an RNA-seq derived cell-by-gene matrix and an DNA-seq derived copy number segmentation, LIAYSON predicts the number of clones present in a tumor, their size, the copy number profile of each clone and the clone membership of each single cell (Andor, N. & Lau, B., et al. (2018) <doi:10.1101/445932>).",2020-04-30,Noemi Andor,"https://github.com/noemiandor/liayson,
https://groups.google.com/d/forum/liayson",TRUE,https://github.com/noemiandor/liayson,5558,2,2020-04-07T01:01:59Z,2779
LibOPF,"The 'LibOPF' is a framework to develop pattern recognition techniques based on optimum-path forests (OPF), João P. Papa and Alexandre X. Falcão (2008) <doi:10.1007/978-3-540-89639-5_89>, with methods for supervised learning and data clustering.",2020-04-12,Rafael Junqueira Martarelli,"https://github.com/RafaelJM/LibOPF-in-R,
https://github.com/jppbsi/LibOPF/wiki,
http://www.ic.unicamp.br/~afalcao/libopf/",TRUE,https://github.com/rafaeljm/libopf-in-r,1596,1,2020-04-11T20:34:10Z,1596
lidR,"Airborne LiDAR (Light Detection and Ranging) interface for data
    manipulation and visualization. Read/write 'las' and 'laz' files, computation
    of metrics in area based approach, point filtering, artificial point reduction,
    classification from geographic data, normalization, individual tree segmentation
    and other manipulations.",2020-06-08,Jean-Romain Roussel,https://github.com/Jean-Romain/lidR,TRUE,https://github.com/jean-romain/lidr,55841,229,2020-06-04T12:15:33Z,243.84716157205241
lifecontingencies,"Classes and methods that allow the user to manage life table,
    actuarial tables (also multiple decrements tables). Moreover, functions to easily
    perform demographic, financial and actuarial mathematics on life contingencies
    insurances calculations are contained therein.",2019-03-05,Giorgio Alfredo Spedicato,http://github.com/spedygiorgio/lifecontingencies,TRUE,https://github.com/spedygiorgio/lifecontingencies,65593,33,2020-05-15T20:16:32Z,1987.6666666666667
lifecycle,"Manage the life cycle of your exported functions with
    shared conventions, documentation badges, and non-invasive
    deprecation warnings. The 'lifecycle' package defines four
    development stages (experimental, maturing, stable, and
    questioning) and three deprecation stages (soft-deprecated,
    deprecated, and defunct). It makes it easy to insert badges
    corresponding to these stages in your documentation. Usage of
    deprecated functions are signalled with increasing levels of
    non-invasive verbosity.",2020-03-06,Lionel Henry,"https://lifecycle.r-lib.org/, https://github.com/r-lib/lifecycle",TRUE,https://github.com/r-lib/lifecycle,7430789,34,2020-03-16T07:34:14Z,218552.61764705883
liftr,Persistent reproducible reporting by containerization of R Markdown documents.,2019-06-19,Nan Xiao,"https://nanx.me/liftr/, https://github.com/nanxstats/liftr",TRUE,https://github.com/nanxstats/liftr,25331,146,2020-04-23T16:14:24Z,173.5
liger,"Gene Set Enrichment Analysis (GSEA) is a computational method that determines whether an a priori defined set of genes shows statistically significant, concordant differences between two biological states. The original algorithm is detailed in Subramanian et al. with 'Java' implementations available through the Broad Institute (Subramanian et al. 2005 <doi:10.1073/pnas.0506580102>). The 'liger' package provides a lightweight R implementation of this enrichment test on a list of values (Fan et al., 2017 <doi:10.5281/zenodo.887386>). Given a list of values, such as p-values or log-fold changes derived from differential expression analysis or other analyses comparing biological states, this package enables you to test a priori defined set of genes for enrichment to enable interpretability of highly significant or high fold-change genes.",2019-01-03,Jean Fan,https://github.com/JEFworks/liger,TRUE,https://github.com/jefworks/liger,8785,40,2019-08-20T15:05:17Z,219.625
lightr,"Parse various reflectance/transmittance/absorbance spectra file
    formats to extract spectral data and metadata, as described in Gruson, White
    & Maia (2019) <doi:10.21105/joss.01857>. Among other formats, it can import
    files from 'Avantes' <https://www.avantes.com/>, 'CRAIC' 
    <http://www.microspectra.com/>, and 'OceanInsight' (formerly 'OceanOptics') 
    <https://www.oceaninsight.com/> brands.
    This package has been peer-reviewed by rOpenSci (v. 0.1).",2020-04-01,Hugo Gruson,"https://docs.ropensci.org/lightr,
https://github.com/ropensci/lightr",TRUE,https://github.com/ropensci/lightr,4160,3,2020-05-13T07:42:56Z,1386.6666666666667
lightsout,"Lights Out is a puzzle game consisting of a grid of lights
    that are either on or off. Pressing any light will toggle it and its
    adjacent lights. The goal of the game is to switch all the lights off. This
    package provides an interface to play the game on different board sizes,
    both through the command line or with a visual application. Puzzles can
    also be solved using the automatic solver included. View a demo
    online at http://daattali.com/shiny/lightsout/.",2016-07-26,Dean Attali,https://github.com/daattali/lightsout,TRUE,https://github.com/daattali/lightsout,13381,31,2020-01-12T07:01:37Z,431.64516129032256
lime,"When building complex models, it is often difficult to explain why
    the model should be trusted. While global measures such as accuracy are
    useful, they cannot be used for explaining why a model made a specific
    prediction. 'lime' (a port of the 'lime' 'Python' package) is a method for
    explaining the outcome of black box models by fitting a local model around
    the point in question an perturbations of this point. The approach is
    described in more detail in the article by Ribeiro et al. (2016) 
    <arXiv:1602.04938>.",2019-11-12,Thomas Lin Pedersen,"https://lime.data-imaginist.com, https://github.com/thomasp85/lime",TRUE,https://github.com/thomasp85/lime,81216,419,2019-11-12T07:32:04Z,193.8329355608592
linearOrdering,"Provides various methods of linear ordering of data. Supports weights and positive/negative impacts.
    Currently included methods:
    * Sum of ranks
    * Standardized sums
    * Hellwig's (Hellwig, 1968, <https://unesdoc.unesco.org/ark:/48223/pf0000158559.locale=en>)
    * TOPSIS (Yoon & Hwang, 1981, ISBN:978-3-642-48318-9).",2019-10-11,Antoni Baum,https://github.com/Yard1/linearOrdering,TRUE,https://github.com/yard1/linearordering,4386,1,2019-10-11T21:51:12Z,4386
lineup,"Tools for detecting and correcting sample mix-ups between two sets
    of measurements, such as between gene expression data on two tissues.",2019-03-06,Karl W Broman,https://github.com/kbroman/lineup,TRUE,https://github.com/kbroman/lineup,17729,1,2020-05-28T12:27:47Z,17729
lingtypology,"Provides R with the Glottolog database <http://glottolog.org> and some more abilities for purposes of linguistic mapping. The Glottolog database contains the catalogue of languages of the world. This package helps researchers to make a linguistic maps, using philosophy of the Cross-Linguistic Linked Data project <http://clld.org/>, which allows for while at the same time facilitating uniform access to the data across publications. A tutorial for this package is available on GitHub pages <https://docs.ropensci.org/lingtypology/> and package vignette. Maps created by this package can be used both for the investigation and linguistic teaching. In addition, package provides an ability to download data from typological databases such as WALS, AUTOTYP and some others and to create your own database website.",2020-04-26,George Moroz,"https://CRAN.R-project.org/package=lingtypology,
https://github.com/ropensci/lingtypology/,
https://ropensci.github.io/lingtypology/",TRUE,https://github.com/ropensci/lingtypology,24275,33,2020-04-26T15:22:27Z,735.6060606060606
link2GI,Functions to simplify the linking of open source GIS and remote sensing related command line interfaces.,2020-02-28,Chris Reudenbach,"https://github.com/r-spatial/link2GI/,
https://r-spatial.github.io/link2GI/",TRUE,https://github.com/r-spatial/link2gi,25654,19,2020-05-18T14:05:02Z,1350.2105263157894
LinkageMapView,"Produces high resolution, publication ready linkage maps
    and quantitative trait loci maps. Input can be output from 'R/qtl',
    simple text or comma delimited files. Output is currently
    a portable document file.",2018-01-21,Lisa Ouellette,https://github.com/louellette/LinkageMapView,TRUE,https://github.com/louellette/linkagemapview,13183,6,2019-11-18T19:52:15Z,2197.1666666666665
LinkedMatrix,"A class that links matrix-like objects (nodes) by rows or by
    columns while behaving similarly to a base R matrix. Very large matrices
    are supported if the nodes are file-backed matrices.",2020-05-22,Alexander Grueneberg,https://github.com/QuantGen/LinkedMatrix,TRUE,https://github.com/quantgen/linkedmatrix,17039,2,2020-05-22T21:15:14Z,8519.5
linl,"A 'LaTeX' Letter class for 'rmarkdown', using the
 'pandoc-letter' template adapted for use with 'markdown'.",2019-10-23,Dirk Eddelbuettel and Aaron Wolen,http://dirk.eddelbuettel.com/code/linl.html,TRUE,https://github.com/eddelbuettel/linl,11994,84,2020-04-09T22:07:54Z,142.78571428571428
lintools,"Variable elimination (Gaussian elimination, Fourier-Motzkin elimination), 
    Moore-Penrose pseudoinverse, reduction to reduced row echelon form, value substitution,  
    projecting a vector on the convex polytope described by a system of (in)equations, 
    simplify systems by removing spurious columns and rows and collapse implied equalities, 
    test if a matrix is totally unimodular, compute variable ranges implied by linear
    (in)equalities.",2019-12-05,Mark van der Loo,https://github.com/data-cleaning/lintools,TRUE,https://github.com/data-cleaning/lintools,18334,1,2019-12-04T12:09:42Z,18334
lintr,"Checks adherence to a given style, syntax errors and possible
    semantic issues.  Supports on the fly checking of R code edited with 'RStudio IDE', 'Emacs',
    'Vim', 'Sublime Text' and 'Atom'.",2020-02-19,Jim Hester,https://github.com/jimhester/lintr,TRUE,https://github.com/jimhester/lintr,947658,732,2020-05-25T20:36:47Z,1294.6147540983607
liquidSVM,"Support vector machines (SVMs) and related kernel-based learning
    algorithms are a well-known class of machine learning algorithms, for
    non-parametric classification and regression.
    liquidSVM is an implementation of SVMs whose key features are:
    fully integrated hyper-parameter selection,
    extreme speed on both small and large data sets,
    full flexibility for experts, and
    inclusion of a variety of different learning scenarios:
    multi-class classification, ROC, and Neyman-Pearson learning, and
    least-squares, quantile, and expectile regression.",2019-09-14,Ingo Steinwart,https://github.com/liquidSVM/liquidSVM,TRUE,https://github.com/liquidsvm/liquidsvm,16580,44,2019-09-03T12:15:48Z,376.8181818181818
lisa,"Contains 128 palettes from Color Lisa. All palettes are based on masterpieces from the worlds greatest artists. For more information, see <http://colorlisa.com/>.",2019-11-03,Tyler Littlefield,https://github.com/tyluRp/lisa,TRUE,https://github.com/tylurp/lisa,5088,23,2019-11-03T15:14:01Z,221.2173913043478
listarrays,"A toolbox for R arrays. Flexibly split, bind, reshape, modify, 
    subset and name arrays.",2020-03-08,Tomasz Kalinowski,"https://github.com/t-kalinowski/listarrays,
https://t-kalinowski.github.io/listarrays/",TRUE,https://github.com/t-kalinowski/listarrays,8567,10,2020-06-02T03:23:19Z,856.7
listcomp,"An implementation of list comprehensions as purely syntactic
  sugar with a minor runtime overhead. It constructs nested for-loops and
  executes the byte-compiled loops to collect the results.",2020-05-24,Dirk Schumacher,https://github.com/dirkschumacher/listcomp,TRUE,https://github.com/dirkschumacher/listcomp,534,12,2020-05-24T07:33:31Z,44.5
listenv,"List environments are environments that have list-like properties.  For instance, the elements of a list environment are ordered and can be accessed and iterated over using index subsetting, e.g. 'x <- listenv(a = 1, b = 2); for (i in seq_along(x)) x[[i]] <- x[[i]] ^ 2; y <- as.list(x)'.",2019-12-05,Henrik Bengtsson,https://github.com/HenrikBengtsson/listenv,TRUE,https://github.com/henrikbengtsson/listenv,861242,15,2020-04-15T00:12:03Z,57416.13333333333
listviewer,"R lists, especially nested lists, can be very difficult to
    visualize or represent. Sometimes 'str()' is not enough, so this suite of
    htmlwidgets is designed to help see, understand, and maybe even modify your R
    lists.  The function 'reactjson()' requires a package
    'reactR' that can be installed from CRAN or <https://github.com/timelyportfolio/reactR>.",2019-11-02,Jos de Jong,https://github.com/timelyportfolio/listviewer,TRUE,https://github.com/timelyportfolio/listviewer,226791,138,2019-11-02T18:02:08Z,1643.4130434782608
littler,"A scripting and command-line front-end
 is provided by 'r' (aka 'littler') as a lightweight binary wrapper around
 the GNU R language and environment for statistical computing and graphics.
 While R can be used in batch mode, the r binary adds full support for
 both 'shebang'-style scripting (i.e. using a  hash-mark-exclamation-path
 expression as the first line in scripts) as well as command-line use in
 standard Unix pipelines. In other words, r provides the R language without
 the environment.",2020-06-03,Dirk Eddelbuettel and Jeff Horner,http://dirk.eddelbuettel.com/code/littler.html,TRUE,https://github.com/eddelbuettel/littler,71069,212,2020-06-03T13:01:27Z,335.2311320754717
live,"Interpretability of complex machine learning models is a growing concern.
    This package helps to understand key factors that drive the 
    decision made by complicated predictive model (so called black box model). 
    This is achieved through local approximations that are either based on 
    additive regression like model or CART like model that allows for 
    higher interactions. The methodology is based on Tulio Ribeiro, Singh, Guestrin (2016) <doi:10.1145/2939672.2939778>.
    More details can be found in Staniak, Biecek (2018) <doi:10.32614/RJ-2018-072>.",2020-01-15,Mateusz Staniak,https://github.com/ModelOriented/live,TRUE,https://github.com/modeloriented/live,12417,35,2019-08-21T18:02:19Z,354.77142857142854
LLSR,"Originally design to characterise Aqueous Two Phase Systems, LLSR provide a simple way to analyse experimental data and obtain phase diagram parameters, among other properties, systematically. The package will include (every other update) new functions in order to comprise useful tools in liquid-liquid extraction research.",2019-03-05,Diego F Coelho,https://CRAN.R-project.org/package=LLSR,TRUE,https://github.com/diegofcoelho/llsr,20153,0,2019-10-30T14:58:02Z,NA
lmds,"
  A fast dimensionality reduction method scaleable to large numbers of samples.
  Landmark Multi-Dimensional Scaling (LMDS) is an extension of classical Torgerson MDS,
  but rather than calculating a complete distance matrix between all pairs of samples,
  only the distances between a set of landmarks and the samples are calculated.",2019-09-27,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,http://github.com/dynverse/lmds,TRUE,https://github.com/dynverse/lmds,4125,2,2019-09-08T10:48:00Z,2062.5
lme4,"Fit linear and generalized linear mixed-effects models.
    The models and their components are represented using S4 classes and
    methods.  The core computational algorithms are implemented using the
    'Eigen' C++ library for numerical linear algebra and 'RcppEigen' ""glue"".",2020-04-07,Douglas Bates,https://github.com/lme4/lme4/,TRUE,https://github.com/lme4/lme4,9585494,384,2020-05-09T23:07:11Z,24962.223958333332
lmeInfo,"Provides analytic derivatives and information matrices for
    fitted linear mixed effects (lme) models and generalized least squares (gls) models
    estimated using lme() (from package 'nlme') and gls() (from package 'nlme'), respectively.
    The package includes functions for estimating the sampling variance-covariance of variance
    component parameters using the inverse Fisher information. The variance components include
    the parameters of the random effects structure (for lme models), the variance structure,
    and the correlation structure. The expected and average forms of the Fisher information matrix
    are used in the calculations, and models estimated by full maximum likelihood or
    restricted maximum likelihood are supported. The package also includes a function for estimating
    standardized mean difference effect sizes (Pustejovsky, Hedges, and Shadish (2014) <DOI:10.3102/1076998614547577>)
    based on fitted lme or gls models.",2020-05-10,James Pustejovsky,https://jepusto.github.io/lmeInfo,TRUE,https://github.com/jepusto/lmeinfo,825,0,2020-06-07T20:29:03Z,NA
lmeresampler,"Bootstrap routines for nested linear mixed effects models fit using
    either 'lme4' or 'nlme'. The provided 'bootstrap()' function implements the
    parametric, residual, cases, semi-parametric (i.e., CGR),  and random effect
    block (REB) bootstrap procedures. An overview of these procedures can be found 
    in Van der Leeden et al. (2008) <doi: 10.1007/978-0-387-73186-5_11>, 
    Carpenter, Goldstein & Rasbash (2003) <doi: 10.1111/1467-9876.00415>,
    and Chambers & Chandra (2013) <doi: 10.1080/10618600.2012.681216>.",2020-01-31,Adam Loy,https://github.com/aloy/lmeresampler,TRUE,https://github.com/aloy/lmeresampler,8851,16,2020-02-19T16:48:08Z,553.1875
lmerTest,"Provides p-values in type I, II or III anova and summary tables
    for lmer model fits (cf. lme4) via Satterthwaite's degrees of freedom method. A
    Kenward-Roger method is also available via the pbkrtest package. Model selection
    methods include step, drop1 and anova-like tables for random effects (ranova).
    Methods for Least-Square means (LS-means) and tests of linear contrasts of fixed
    effects are also available.",2020-04-08,Alexandra Kuznetsova,https://github.com/runehaubo/lmerTestR,TRUE,https://github.com/runehaubo/lmertestr,890884,24,2020-04-15T07:33:07Z,37120.166666666664
lmm,"It implements Expectation/Conditional Maximization Either (ECME)
             and rapidly converging algorithms as well as
             Bayesian inference for linear mixed models, 
             which is described in Schafer, J.L. (1998)
             ""Some improved procedures for linear mixed models"".
             Dept. of Statistics, The Pennsylvania State University.",2018-06-30,Original by Joseph L. Schafer,https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,28643,5,2020-04-28T11:28:17Z,5728.6
lmPerm,Linear model functions using permutation tests.,2016-08-02,Bob Wheeler,https://github.com/mtorchiano/lmPerm,TRUE,https://github.com/mtorchiano/lmperm,39014,8,2020-02-25T18:05:44Z,4876.75
lmQCM,"Implementation based on Zhang, Jie & Huang, Kun (2014) <doi:10.4137/CIN.S14021> Normalized ImQCM: An Algorithm for Detecting Weak Quasi-Cliques in Weighted Graph with Applications in Gene Co-Expression Module Discovery in Cancers. Cancer informatics, 13, CIN-S14021.",2019-03-12,Zhi Huang,http://github.com/huangzhii/lmQCM,TRUE,https://github.com/huangzhii/lmqcm,8642,1,2019-10-02T22:48:54Z,8642
lmSubsets,"Exact and approximation algorithms for variable-subset
  selection in ordinary linear regression models.  Either compute all
  submodels with the lowest residual sum of squares, or determine the
  single-best submodel according to a pre-determined statistical
  criterion.  Hofmann et al. (2020) <10.18637/jss.v093.i03>.",2020-05-23,Marc Hofmann,https://github.com/marc-hofmann/lmSubsets.R,TRUE,https://github.com/marc-hofmann/lmsubsets.r,9435,3,2020-05-24T12:12:24Z,3145
lobstr,"A set of tools for inspecting and understanding R data
    structures inspired by str(). Includes ast() for visualizing abstract 
    syntax trees, ref() for showing shared references, cst() for showing 
    call stack trees, and obj_size() for computing object sizes.",2019-07-02,Hadley Wickham,https://github.com/r-lib/lobstr,TRUE,https://github.com/r-lib/lobstr,69622,227,2019-07-02T17:00:36Z,306.704845814978
localICE,"Local Individual Conditional Expectation ('localICE') is a local explanation approach from the field of eXplainable Artificial Intelligence (XAI). localICE is a model-agnostic XAI approach which provides three-dimensional local explanations for particular data instances. The approach is proposed in the master thesis of Martin Walter as an extension to ICE (see Reference). The three dimensions are the two features at the horizontal and vertical axes as well as the target represented by different colors. The approach is applicable for classification and regression problems to explain interactions of two features towards the target. For classification models, the number of classes can be more than two and each class is added as a different color to the plot. The given instance is added to the plot as two dotted lines according to the feature values. The localICE-package can explain features of type factor and numeric of any machine learning model. Automatically supported machine learning packages are 'mlr', 'randomForest', 'caret' or all other with an S3 predict function. For further model types from other libraries, a predict function has to be provided as an argument in order to get access to the model. Reference to the ICE approach: Alex Goldstein, Adam Kapelner, Justin Bleich, Emil Pitkin (2013) <arXiv:1309.6392>. ",2020-02-07,Martin Walter,https://github.com/viadee/localICE,TRUE,https://github.com/viadee/localice,5496,7,2020-02-07T23:40:22Z,785.1428571428571
localIV,"In the generalized Roy model, the marginal treatment effect (MTE) can be used as
  a building block for constructing conventional causal parameters such as the average treatment
  effect (ATE) and the average treatment effect on the treated (ATT). Given a treatment selection
  equation and an outcome equation, the function mte() estimates the MTE via the semiparametric
  local instrumental variables method or the normal selection model. The function mte_at() evaluates
  MTE at different values of the latent resistance u with a given X = x, and the function mte_tilde_at()
  evaluates MTE projected onto the estimated propensity score. The function ace() estimates
  population-level average causal effects such as ATE, ATT, or the marginal policy relevant
  treatment effect.",2020-04-01,Xiang Zhou,https://github.com/xiangzhou09/localIV,TRUE,https://github.com/xiangzhou09/localiv,8047,1,2020-04-01T14:30:25Z,8047
localModel,"Local explanations of machine learning models describe, how features contributed to a single prediction. 
    This package implements an explanation method based on LIME 
    (Local Interpretable Model-agnostic Explanations, 
    see Tulio Ribeiro, Singh, Guestrin (2016) <doi:10.1145/2939672.2939778>) in which interpretable
    inputs are created based on local rather than global behaviour of each original feature.",2019-12-18,Mateusz Staniak,https://github.com/ModelOriented/localModel,TRUE,https://github.com/modeloriented/localmodel,5257,10,2019-08-26T17:52:46Z,525.7
lodi,"Impute observed values below the limit of detection (LOD) via
    censored likelihood multiple imputation (CLMI) in single-pollutant
    models, developed by Boss et al (2019) <doi:10.1097/EDE.0000000000001052>.
    CLMI handles exposure detection limits that may change throughout the course
    of exposure assessment. 'lodi' provides functions for imputing and
    pooling for this method.",2020-02-07,Alexander Rix,https://github.com/umich-cphds/lodi,TRUE,https://github.com/umich-cphds/lodi,4045,0,2020-02-18T19:27:10Z,NA
log4r,"The log4r package is meant to provide a fast, lightweight,
  object-oriented approach to logging in R based on the widely-emulated
  'log4j' system and etymology.",2020-01-18,Aaron Jacobs,https://github.com/johnmyleswhite/log4r,TRUE,https://github.com/johnmyleswhite/log4r,61180,61,2020-01-17T19:54:03Z,1002.9508196721312
logbin,"Methods for fitting log-link GLMs and GAMs to binomial data,
    including EM-type algorithms with more stable convergence properties than standard methods.",2018-08-31,Mark W. Donoghoe,https://github.com/mdonoghoe/logbin,TRUE,https://github.com/mdonoghoe/logbin,19509,9,2019-07-05T05:32:32Z,2167.6666666666665
logger,"Inspired by the the 'futile.logger' R package and 'logging' Python module, this utility provides a flexible and extensible way of formatting and delivering log messages with low overhead.",2019-01-02,Gergely Daróczi,https://github.com/daroczig/logger,TRUE,https://github.com/daroczig/logger,22316,122,2019-12-05T22:07:58Z,182.91803278688525
logging,"Pure R implementation of the ubiquitous log4j package. It offers hierarchic 
  loggers, multiple handlers per logger, level based filtering, space handling in messages 
  and custom formatting.",2019-07-14,Walerian Sokolowski,https://github.com/WLOGSolutions/r-logging,TRUE,https://github.com/wlogsolutions/r-logging,549600,44,2019-08-11T15:41:01Z,12490.90909090909
loggit,"
    An effortless 'ndjson' (newline-delimited 'JSON') logger, with two primary
    log-writing interfaces. It provides a set of wrappings for base R's
    message(), warning(), and stop() functions that maintain identical
    functionality, but also log the handler message to an 'ndjson' log file.
    'loggit' also exports its internal 'loggit()' function for powerful and
    configurable custom logging. No change in existing code is necessary to use
    this package, and should only require additions to fully leverage the power
    of the logging system. 'loggit' also provides a log reader for reading an
    'ndjson' log file into a data frame, log rotation, and live echo of the
    'ndjson' log messages to terminal 'stdout' for log capture by external
    systems (like containers). 'loggit' is ideal for Shiny apps, data pipelines,
    modeling work flows, and more. Please see the vignettes for detailed example
    use cases.",2020-06-06,Ryan Price,https://github.com/ryapric/loggit,TRUE,https://github.com/ryapric/loggit,12614,29,2020-06-06T21:30:02Z,434.9655172413793
logisticRR,"Adjusted odds ratio conditional on potential confounders can be directly obtained from logistic regression. However, those adjusted odds ratios have been widely incorrectly interpreted as a relative risk. As relative risk is often of interest in public health, we provide a simple code to return adjusted relative risks from logistic regression model under potential confounders. ",2020-04-03,Youjin Lee,https://github.com/youjin1207/logisticRR,TRUE,https://github.com/youjin1207/logisticrr,7721,0,2020-03-14T19:37:44Z,NA
lognorm,"The lognormal distribution  
  (Limpert et al. (2001) <doi:10.1641/0006-3568(2001)051%5B0341:lndats%5D2.0.co;2>)
  can characterize uncertainty that is bounded by zero.
  This package provides estimation of distribution parameters, computation of
  moments and other basic statistics, and an approximation of the distribution
  of the sum of several correlated lognormally distributed variables 
  (Lo 2013 <doi:10.12988/ams.2013.39511>).",2019-08-02,Thomas Wutzler,https://github.com/bgctw/lognorm,TRUE,https://github.com/bgctw/lognorm,9183,3,2020-04-14T20:41:33Z,3061
LongCART,"Constructs tree for continuous longitudinal data and survival data using baseline covariates as partitioning variables according to the 'LongCART' and 'SurvCART' algorithm, respectively.",2020-04-24,Madan G Kundu,https://www.r-project.org,TRUE,https://github.com/madanstat/longcart,3425,0,2019-09-15T07:01:56Z,NA
longpower,"Compute power and sample size for linear models of longitudinal
    data. Supported models include mixed-effects models and models fit by
    generalized least squares and generalized estimating equations. Relevant
    formulas are derived by Liu and Liang (1997) <DOI:10.2307/2533554>, 
    Diggle et al (2002) <ISBN:9780199676750>, and Lu, Luo, and Chen (2008)
    <DOI:10.2202/1557-4679.1098>.",2020-04-21,Michael C. Donohue,https://github.com/mcdonohue/longpower,TRUE,https://github.com/mcdonohue/longpower,27176,0,2020-04-21T14:32:33Z,NA
loo,"Efficient approximate leave-one-out cross-validation (LOO)
    for Bayesian models fit using Markov chain Monte Carlo, as 
    described in Vehtari, Gelman, and Gabry (2017) 
    <doi:10.1007/s11222-016-9696-4>. 
    The approximation uses Pareto smoothed importance sampling (PSIS), 
    a new procedure for regularizing importance weights. 
    As a byproduct of the calculations, we also obtain approximate 
    standard errors for estimated predictive errors and for the comparison 
    of predictive errors between models. The package also provides methods 
    for using stacking and other model weighting techniques to average 
    Bayesian predictive distributions.",2019-12-19,Jonah Gabry,"https://mc-stan.org/loo, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/loo,969000,85,2020-06-09T15:23:06Z,11400
loon,An extendable toolkit for interactive data visualization and exploration.,2020-05-24,R. Wayne Oldford,http://great-northern-diver.github.io/loon/,TRUE,https://github.com/great-northern-diver/loon,14521,30,2020-05-22T18:45:15Z,484.03333333333336
lorentz,"The Lorentz transform in special relativity; also the gyrogroup structure of three-velocities following Ungar (2006)
  <doi:10.1088/0143-0807/27/3/L02>.  For general relativity, see the
  'schwarzschild' package.",2019-03-21,Robin K. S. Hankin,https://github.com/RobinHankin/lorentz.git,TRUE,https://github.com/robinhankin/lorentz,6687,2,2020-05-01T10:48:27Z,3343.5
lotri,"Provides a simple mechanism to specify a symmetric block diagonal matrices (often 
  used for covariance matrices).  This is based on the domain specific language implemented
  in 'nlmixr' but expanded to create matrices in R generally instead of specifying parts of matrices
  to estimate.",2020-05-29,Matthew L. Fidler,https://github.com/nlmixrdevelopment/lotri,TRUE,https://github.com/nlmixrdevelopment/lotri,10894,0,2020-04-24T20:25:40Z,NA
lpirfs,"Provides functions to estimate and plot linear as well as nonlinear impulse 
             responses based on local projections by Jordà (2005) <doi:10.1257/0002828053828518>.",2020-06-05,Philipp Adämmer,NA,TRUE,https://github.com/adaemmerp/lpirfs,12461,8,2020-06-03T09:11:36Z,1557.625
LPS,"An implementation of the Linear Predictor Score approach, as initiated by Radmacher et al. (J Comput Biol 2001) and enhanced by Wright et al. (PNAS 2003) for gene expression signatures. Several tools for unsupervised clustering of gene expression data are also provided.",2015-02-16,Sylvain Mareschal,http://bioinformatics.ovsa.fr/LPS,TRUE,https://github.com/maressyl/r.lps,16956,0,2020-05-03T10:35:28Z,NA
lpSolve,"Lp_solve is freely available (under LGPL 2) software for
        solving linear, integer and mixed integer programs. In this
        implementation we supply a ""wrapper"" function in C and some R
        functions that solve general linear/integer problems,
        assignment problems, and transportation problems. This version
        calls lp_solve version 5.5.",2020-01-24,Michel Berkelaar and others,https://github.com/gaborcsardi/lpSolve,TRUE,https://github.com/gaborcsardi/lpsolve,1302821,3,2020-01-24T12:19:57Z,434273.6666666667
LPWC,"Computes a time series distance measure for clustering based on weighted correlation and introduction of lags. The lags capture delayed responses in a time series dataset. The timepoints must be specified. T. Chandereng, A. Gitter (2020) <doi:10.1186/s12859-019-3324-1>.",2020-01-23,Thevaa Chandereng,https://github.com/gitter-lab/LPWC,TRUE,https://github.com/gitter-lab/lpwc,10198,11,2020-04-25T19:52:47Z,927.0909090909091
lsasim,"Provides functions to simulate data from large-scale educational
  assessments, including background questionnaire data and cognitive item
  responses that adhere to a multiple-matrix sampled design.",2019-12-05,Waldir Leoncio,NA,TRUE,https://github.com/tmatta/lsasim,10791,5,2019-12-05T19:59:13Z,2158.2
ltmle,"Targeted Maximum Likelihood Estimation (TMLE) of
    treatment/censoring specific mean outcome or marginal structural model for
    point-treatment and longitudinal data.",2020-03-13,Joshua Schwab,https://github.com/joshuaschwab/ltmle,TRUE,https://github.com/joshuaschwab/ltmle,23584,12,2020-03-13T21:07:37Z,1965.3333333333333
lubridate,"Functions to work with date-times and time-spans:
    fast and user friendly parsing of date-time data, extraction and
    updating of components of a date-time (years, months, days, hours,
    minutes, and seconds), algebraic manipulation on date-time and
    time-span objects. The 'lubridate' package has a consistent and
    memorable syntax that makes working with dates easy and fun.  Parts of
    the 'CCTZ' source code, released under the Apache 2.0 License, are
    included in this package. See <https://github.com/google/cctz> for
    more details.",2020-06-08,Vitalie Spinu,"http://lubridate.tidyverse.org,
https://github.com/tidyverse/lubridate",TRUE,https://github.com/tidyverse/lubridate,13775281,489,2020-06-01T17:19:07Z,28170.30879345603
lucid,"Print vectors (and data frames) of floating point numbers
    using a non-scientific format optimized for human readers.  Vectors
    of numbers are rounded using significant digits, aligned at the
    decimal point, and all zeros trailing the decimal point are dropped.
    See: Wright (2016). Lucid: An R Package for Pretty-Printing Floating Point
    Numbers. In JSM Proceedings, Statistical Computing Section. Alexandria,
    VA: American Statistical Association. 2270-2279.",2019-02-06,Kevin Wright,https://github.com/kwstat/lucid,TRUE,https://github.com/kwstat/lucid,21365,24,2019-09-13T15:16:48Z,890.2083333333334
LUCIDus,"An implementation for the 'LUCID' model (Peng (2019) <doi:10.1093/bioinformatics/btz667>) to jointly estimate latent unknown clusters/subgroups with integrated data. 
  An EM algorithm is used to obtain the latent cluster assignment and model parameter estimates. 
  Feature selection is achieved by applying the L1 regularization method.",2020-05-18,Yinqi Zhao,https://github.com/Yinqi93/LUCIDus,TRUE,https://github.com/yinqi93/lucidus,5931,0,2020-06-09T01:45:34Z,NA
ludic,"Probabilistic record linkage without direct identifiers using only 
    diagnosis codes. Method is detailed in: Hejblum, Weber, Liao, Palmer, 
    Churchill, Szolovits, Murphy, Kohane & Cai (2019) <doi: 10.1038/sdata.2018.298>.",2019-12-04,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/ludic,11319,0,2020-04-04T07:19:36Z,NA
lumberjack,"A framework that allows for easy logging of changes in data.
    Main features: start tracking changes by adding a single line of code to 
    an existing script. Track changes in multiple datasets, using multiple 
    loggers. Add custom-built loggers or use loggers offered by other 
    packages.",2020-05-08,Mark van der Loo,https://github.com/markvanderloo/lumberjack,TRUE,https://github.com/markvanderloo/lumberjack,11641,34,2020-05-08T18:16:32Z,342.38235294117646
Luminescence,"A collection of various R functions for the purpose of Luminescence
    dating data analysis. This includes, amongst others, data import, export,
    application of age models, curve deconvolution, sequence analysis and
    plotting of equivalent dose distributions.",2020-01-08,Sebastian Kreutzer,https://CRAN.R-project.org/package=Luminescence,TRUE,https://github.com/r-lum/luminescence,56142,7,2020-01-04T20:31:05Z,8020.285714285715
lutz,"Input latitude and longitude values or an 'sf/sfc' POINT 
    object and get back the time zone in which they exist. Two methods are implemented. 
    One is very fast and uses 'Rcpp' in conjunction with data from the 'Javascript' library
    (<https://github.com/darkskyapp/tz-lookup/>). This method also works outside of countries' 
    borders and in international waters, however speed comes at the cost of accuracy - near time 
    zone borders away from populated centres there is a chance that it will return the incorrect
    time zone. The other method is slower but more accurate - it uses the 'sf' package to intersect 
    points with a detailed map of time zones from here: 
    <https://github.com/evansiroky/timezone-boundary-builder/>. The package also 
    contains several utility functions for helping to understand and visualize 
    time zones, such as listing of world time zones, including information about 
    daylight savings times and their offsets from UTC. You can also plot a 
    time zone to visualize the UTC offset over a year and when daylight savings 
    times are in effect.",2019-07-19,Andy Teucher,https://andyteucher.ca/lutz,TRUE,https://github.com/ateucher/lutz,65739,49,2020-05-11T19:43:18Z,1341.6122448979593
lvm4net,"Latent variable models for network data using fast inferential
    procedures. For more information please visit: <http://igollini.github.io/lvm4net/>.",2019-06-13,Isabella Gollini,http://github.com/igollini/lvm4net,TRUE,https://github.com/igollini/lvm4net,16401,7,2019-06-19T10:01:11Z,2343
lvmcomp,"Provides stochastic EM algorithms for latent variable models
    with a high-dimensional latent space. So far, we provide functions for confirmatory item
    factor analysis based on the multidimensional two parameter logistic (M2PL) model and the 
    generalized multidimensional partial credit model. These functions scale well for problems
    with many latent traits (e.g., thirty or even more) and are virtually tuning-free.
    The computation is facilitated by multiprocessing 'OpenMP' API.
    For more information, please refer to:
    Zhang, S., Chen, Y., & Liu, Y. (2018). An Improved Stochastic EM Algorithm for Large-scale
    Full-information Item Factor Analysis. British Journal of Mathematical and Statistical
    Psychology. <doi:10.1111/bmsp.12153>.",2018-12-30,Siliang Zhang,https://github.com/slzhang-fd/lvmcomp,TRUE,https://github.com/slzhang-fd/lvmcomp,6894,2,2020-06-04T02:50:42Z,3447
lwgeom,"Access to selected functions found in 'liblwgeom' <https://github.com/postgis/postgis/tree/master/liblwgeom>, the light-weight geometry library used by 'PostGIS' <http://postgis.net/>.",2020-05-20,Edzer Pebesma,https://github.com/r-spatial/lwgeom/,TRUE,https://github.com/r-spatial/lwgeom,456635,39,2020-06-02T06:55:59Z,11708.589743589744
m2r,"Persistent interface to 'Macaulay2' <http://www.math.uiuc.edu/Macaulay2/>
    and front-end tools facilitating its use in the 'R' ecosystem. For details see 
    Kahle et. al. (2020) <doi:10.18637/jss.v093.i09>.",2020-05-28,David Kahle,https://github.com/coneill-math/m2r,TRUE,https://github.com/coneill-math/m2r,10076,4,2020-05-28T03:24:26Z,2519
MachineShop,"Meta-package for statistical and machine learning with a unified
    interface for model fitting, prediction, performance assessment, and
    presentation of results.  Approaches for model fitting and prediction of
    numerical, categorical, or censored time-to-event outcomes include
    traditional regression models, regularization methods, tree-based methods,
    support vector machines, neural networks, ensembles, data preprocessing,
    filtering, and model tuning and selection.  Performance metrics are provided
    for model assessment and can be estimated with independent test sets, split
    sampling, cross-validation, or bootstrap resampling.  Resample estimation
    can be executed in parallel for faster processing and nested in cases of
    model tuning and selection.  Modeling results can be summarized with
    descriptive statistics; calibration curves; variable importance; partial
    dependence plots; confusion matrices; and ROC, lift, and other performance
    curves.",2020-06-04,Brian J Smith,https://brian-j-smith.github.io/MachineShop/,TRUE,https://github.com/brian-j-smith/machineshop,15324,51,2020-06-08T13:21:01Z,300.47058823529414
macleish,"Download data from the Ada and Archibald MacLeish Field 
    Station in Whately, MA. The Ada 
    and Archibald MacLeish Field Station is a 260-acre patchwork of 
    forest and farmland located in West Whately, MA that provides opportunities 
    for faculty and students to pursue environmental research, outdoor 
    education, and low-impact recreation 
    (see <http://www.smith.edu/ceeds/macleish.php> for more information). 
    This package contains 
    weather data over several years, and spatial data on various man-made and 
    natural structures.",2020-06-03,Benjamin S. Baumer,http://github.com/beanumber/macleish,TRUE,https://github.com/beanumber/macleish,15621,2,2020-06-02T17:18:26Z,7810.5
maditr,"Package provides pipe-style interface for 'data.table'. It preserves all 'data.table' features without
              significant impact on performance. 'let' and 'take' functions are simplified interfaces for most common data
              manipulation tasks. For example, you can write 'take(mtcars, mean(mpg), by = am)' for aggregation or 
              'let(mtcars, hp_wt = hp/wt, hp_wt_mpg = hp_wt/mpg)' for modification. Use 'take_if/let_if' for conditional
              aggregation/modification. 'query_if' function translates its arguments one-to-one to '[.data.table' method.
              Additionally there are some conveniences such as automatic 'data.frame' conversion to 'data.table'.",2020-04-27,Gregory Demin,https://github.com/gdemin/maditr,TRUE,https://github.com/gdemin/maditr,14312,43,2020-04-27T12:14:49Z,332.83720930232556
madness,"An object that supports automatic differentiation
    of matrix- and multidimensional-valued functions with 
    respect to multidimensional independent variables. 
    Automatic differentiation is via 'forward accumulation'.",2020-02-08,Steven E. Pav,https://github.com/shabbychef/madness,TRUE,https://github.com/shabbychef/madness,20076,18,2020-02-08T05:51:55Z,1115.3333333333333
madrat,"Provides a framework which should improve reproducibility and transparency in data processing. It provides functionality such as automatic meta data creation and management, rudimentary quality management, data caching, work-flow management and data aggregation.
    * The title is a wish not a promise. By no means we expect this package to deliver everything what is needed to achieve full reproducibility and transparency, but we believe that it supports efforts in this direction.",2019-12-17,Jan Philipp Dietrich,"https://github.com/pik-piam/madrat,
https://doi.org/10.5281/zenodo.1115490",TRUE,https://github.com/pik-piam/madrat,11546,5,2020-06-08T11:18:50Z,2309.2
mads,"Performs distance sampling analyses on a number of species 
    at once and can account for unidentified sightings, model uncertainty 
    and covariate uncertainty. Unidentified sightings refer to sightings 
    which cannot be allocated to a single species but may instead be 
    allocated to a group of species. The abundance of each unidentified 
    group is estimated and then prorated to the species estimates. Model 
    uncertainty should be incorporated when multiple models give equally
    good fit to the data but lead to large differences in estimated
    density / abundance. Covariate uncertainty should be incorporated
    when covariates cannot be measured accurately, for example this is 
    often the case for group size in marine mammal surveys. Variance 
    estimation for these methods is via a non parametric bootstrap. 
    The methods implemented are described in Gerodette T. and Forcada 
    J. (2005) <doi:10.3354/meps291001> Non-recovery of two spotted and 
    spinner dolphin populations in the eastern tropical Pacific Ocean.",2020-05-27,Laura Marshall,NA,TRUE,https://github.com/distancedevelopment/mads,17446,2,2020-05-18T23:14:38Z,8723
magclass,"Data class for increased interoperability working with spatial-
    temporal data together with corresponding functions and methods (conversions,
    basic calculations and basic data manipulation). The class distinguishes
    between spatial, temporal and other dimensions to facilitate the development
    and interoperability of tools build for it. Additional features are name-based
    addressing of data and internal consistency checks (e.g. checking for the right
    data order in calculations).",2020-03-02,Jan Philipp Dietrich,"https://github.com/pik-piam/magclass,
https://doi.org/10.5281/zenodo.1158580",TRUE,https://github.com/pik-piam/magclass,22914,1,2020-06-08T11:23:23Z,22914
magickGUI,Enables us to use the functions of the package 'magick' interactively.,2019-08-28,Shota Ochi,https://github.com/ShotaOchi/magickGUI,TRUE,https://github.com/shotaochi/magickgui,7106,6,2020-05-09T00:50:34Z,1184.3333333333333
magicLamp,"Set of utility functions to interact with 'WeMo Switch', a smart 
    plug that can be remotely controlled via wifi. The provided functions make 
    it possible to turn one or more 'WeMo Switch' plugs on and off in a 
    scriptable fashion. More information about 'WeMo Switch' can be found at 
    <http://www.belkin.com/us/p/P-F7C027/>. ",2017-09-21,Simon Garnier,https://github.com/swarm-lab/magicLamp,TRUE,https://github.com/swarm-lab/magiclamp,8699,2,2019-12-09T19:25:34Z,4349.5
maic,"A generalised workflow for generation of subject weights to be 
    used in Matching-Adjusted Indirect Comparison (MAIC) per Signorovitch et 
    al (2012) <doi:10.1016/j.jval.2012.05.004>, Signorovitch et al (2010) 
    <doi:10.2165/11538370-000000000-00000>. In MAIC, unbiased 
    comparison between outcomes of two trials is facilitated by weighting the
    subject-level outcomes of one trial with weights derived such that the 
    weighted aggregate measures of the prognostic or effect modifying variables 
    are equal to those of the sample in the comparator trial. The functions and
    classes included in this package wrap and abstract the process demonstrated
    in the UK National Institute for Health and Care Excellence Decision 
    Support Unit (NICE DSU)'s example (Phillippo et al, (2016) [see URL]),
    providing a repeatable and easily specifiable workflow for producing 
    multiple comparison variable sets against a variety of target studies, with
    preprocessing for a number of aggregate target forms (e.g. mean, median, 
    domain limits).",2020-04-30,Rob Young,"https://github.com/heorltd/maic,
http://nicedsu.org.uk/technical-support-documents/population-adjusted-indirect-comparisons-maic-and-stc/",TRUE,https://github.com/heorltd/maic,620,0,2020-05-02T20:18:42Z,NA
makedummies,"Create dummy variables from categorical data.
    This package can convert categorical data (factor and ordered) into
    dummy variables and handle multiple columns simultaneously.
    This package enables to select whether a dummy variable for base group
    is included (for principal component analysis/factor analysis) or
    excluded (for regression analysis) by an option.
    'makedummies' function accepts 'data.frame', 'matrix', and
    'tbl' (tibble) class (by 'tibble' package).
    'matrix' class data is automatically converted to 'data.frame' class.",2019-08-04,Toshiaki Ara,https://github.com/toshi-ara/makedummies,TRUE,https://github.com/toshi-ara/makedummies,17882,6,2019-08-04T10:52:31Z,2980.3333333333335
malariaAtlas,"A suite of tools to allow you to download all 
  publicly available parasite rate survey points, mosquito occurrence points and raster surfaces from 
  the 'Malaria Atlas Project' <https://malariaatlas.org/> servers as well as utility functions for plotting
  the downloaded data.",2020-06-01,Daniel Pfeffer,https://github.com/malaria-atlas-project/malariaAtlas,TRUE,https://github.com/malaria-atlas-project/malariaatlas,10130,23,2020-06-01T07:48:19Z,440.4347826086956
mangoTraining,"Datasets to be used primarily in conjunction with Mango Solutions
    training materials but also for the book 'SAMS Teach Yourself R in 24 Hours' (ISBN: 978-0-672-33848-9).
    Version 1.0-7 is largely for use with the book; however, version 1.1 has a much greater focus on use with
    training materials, whilst retaining compatibility with the book.",2020-06-03,Mango Solutions,http://www.mango-solutions.com,TRUE,https://github.com/mangothecat/mangotraining,21853,6,2020-05-18T08:48:00Z,3642.1666666666665
manhplot,"This plot integrates annotation into a manhattan plot. The plot is implemented as a heatmap, which is binned using -log10(p-value) and chromosome position. Annotation currently supported is minor allele frequency and gene function high impact variants.",2019-11-25,Chris Grace,https://github.com/cgrace1978/manhplot/,TRUE,https://github.com/cgrace1978/manhplot,4062,5,2020-01-28T12:28:46Z,812.4
manipulateWidget,"Like package 'manipulate' does for static graphics, this package
    helps to easily add controls like sliders, pickers, checkboxes, etc. that 
    can be used to modify the input data or the parameters of an interactive 
    chart created with package 'htmlwidgets'.",2020-02-24,Veronique Bachelier,https://github.com/rte-antares-rpackage/manipulateWidget,TRUE,https://github.com/rte-antares-rpackage/manipulatewidget,1369754,109,2020-03-23T16:02:43Z,12566.550458715596
MANOVA.RM,"Implemented are various tests for semi-parametric repeated measures
    and general MANOVA designs that do neither assume multivariate normality nor
    covariance homogeneity, i.e., the procedures are applicable for a wide range
    of general multivariate factorial designs. In addition to asymptotic inference
    methods, novel bootstrap and permutation approaches are implemented as well. These provide more
    accurate results in case of small to moderate sample sizes. Furthermore, post-hoc 
    comparisons are provided for the multivariate analyses.
    Friedrich, S., Konietschke, F. and Pauly, M. (2018) <arXiv:1801.08002>.",2019-08-28,Sarah Friedrich,http://github.com/smn74/MANOVA.RM,TRUE,https://github.com/smn74/manova.rm,20958,3,2020-03-25T09:45:58Z,6986
manymodelr,"Frequently one needs a convenient way to build and tune
             several models in one go.The goal is to provide a number of convenience functions useful in machine learning 
             applications. It provides the ability to build, tune and obtain predictions of 
             several models in one function. The models are built using 'caret' functions with
             easier to read syntax.
             Kuhn(2014) <arXiv:1405.6974>.
             Kuhn(2008) <doi10.18637/jss.v028.i05>.
             Chambers,J.M.(1992) <doi:10.1007/978-3-642-50096-1_48>.
             Wilkinson,G.N. and Rogers, C. E. (1973) <doi:10.2307/2346786>.",2020-02-12,Nelson Gonzabato,https://github.com/Nelson-Gon/manymodelr,TRUE,https://github.com/nelson-gon/manymodelr,6215,2,2020-06-09T15:53:09Z,3107.5
maotai,"Matrix is an universal and sometimes primary object/unit in applied mathematics and statistics. We provide a number of algorithms for selected problems in optimization and statistical inference. For general exposition to the topic with focus on statistical context, see the book by Banerjee and Roy (2014, ISBN:9781420095388).",2020-05-17,Kisung You,http://github.com/kyoustat/maotai,TRUE,https://github.com/kyoustat/maotai,4702,4,2020-05-16T18:26:56Z,1175.5
mapdeck,"Provides a mechanism to plot an interactive map using 'Mapbox GL' 
		(<https://www.mapbox.com/mapbox-gl-js/api/>), a javascript library for interactive maps,
		and 'Deck.gl' (<http://deck.gl/#/>), a javascript library which uses 'WebGL' for 
		visualising large data sets.",2020-05-14,David Cooley,https://symbolixau.github.io/mapdeck/articles/mapdeck.html,TRUE,https://github.com/symbolixau/mapdeck,68066,251,2020-05-26T06:40:59Z,271.1792828685259
mapedit,"Suite of interactive functions and helpers for selecting and editing
    geospatial data.",2020-02-02,Tim Appelhans,https://github.com/r-spatial/mapedit,TRUE,https://github.com/r-spatial/mapedit,67686,161,2020-04-14T01:55:03Z,420.4099378881988
Mapinguari,"Facilitates the incorporation of biological processes in biogeographical analyses. It offers conveniences in fitting, comparing and extrapolating models of biological processes such as physiology and phenology. These spatial extrapolations can be informative by themselves, but also complement traditional correlative species distribution models, by mixing environmental and process-based predictors. ",2019-09-30,Gabriel Caetano,http://github.com/gabrielhoc/Mapinguari,TRUE,https://github.com/gabrielhoc/mapinguari,3075,3,2019-09-16T19:56:56Z,1025
mapr,"Utilities for visualizing species occurrence data. Includes
    functions to visualize occurrence data from 'spocc', 'rgbif',
    and other packages. Mapping options included for base R plots, 'ggplot2',
    'ggmap', 'leaflet' and 'GitHub' 'gists'.",2018-03-21,Scott Chamberlain,https://github.com/ropensci/mapr,TRUE,https://github.com/ropensci/mapr,19831,34,2019-12-09T13:32:01Z,583.2647058823529
mapsapi,"Interface to the 'Google Maps' APIs: (1) routing directions based on the 'Directions' API, returned as 'sf' objects, either as single feature per alternative route, or a single feature per segment per alternative route; (2) travel distance or time matrices based on the 'Distance Matrix' API; (3) geocoded locations based on the 'Geocode' API, returned as 'sf' objects, either points or bounds; (4) map images using the 'Maps Static' API, returned as 'stars' objects.",2020-04-14,Michael Dorman,https://github.com/michaeldorman/mapsapi/,TRUE,https://github.com/michaeldorman/mapsapi,24909,26,2020-05-26T07:38:16Z,958.0384615384615
mapview,"Quickly and conveniently create interactive
    visualisations of spatial data with or without background maps.
    Attributes of displayed features are fully queryable via pop-up
    windows. Additional functionality includes methods to visualise true-
    and false-color raster images and bounding boxes.",2020-04-07,Tim Appelhans,https://github.com/r-spatial/mapview,TRUE,https://github.com/r-spatial/mapview,550206,290,2020-06-09T17:59:12Z,1897.2620689655173
marcher,"A set of tools for likelihood-based estimation, model selection and testing of two- and three-range shift and migration models for animal movement data as described in Gurarie et al. (2017) <doi: 10.1111/1365-2656.12674>.  Provided movement data (X, Y and Time), including irregularly sampled data, functions estimate the time, duration and location of one or two range shifts, as well as the ranging area and auto-correlation structure of the movment.  Tests assess, for example, whether the shift was ""significant"", and whether a two-shift migration was a true return migration.",2017-04-12,Eliezer Gurarie,NA,TRUE,https://github.com/eligurarie/marcher,9435,2,2020-04-28T04:51:08Z,4717.5
MareyMap,Local recombination rates are graphically estimated across a genome using Marey maps.,2020-05-21,Aurélie Siberchicot,"https://lbbe.univ-lyon1.fr/-MareyMap-.html ;
http://lbbe-shiny.univ-lyon1.fr/MareyMapOnline/",TRUE,https://github.com/aursiber/mareymap,19050,0,2020-05-21T08:27:17Z,NA
margins,"An R port of Stata's 'margins' command, which can be used to
    calculate marginal (or partial) effects from model objects.",2018-05-22,Thomas J. Leeper,https://github.com/leeper/margins,TRUE,https://github.com/leeper/margins,104686,208,2019-12-25T08:58:29Z,503.2980769230769
markdown,"Provides R bindings to the 'Sundown' Markdown rendering library
    (<https://github.com/vmg/sundown>). Markdown is a plain-text formatting
    syntax that can be converted to 'XHTML' or other formats. See
    <http://en.wikipedia.org/wiki/Markdown> for more information about Markdown.",2019-08-07,Yihui Xie,https://github.com/rstudio/markdown,TRUE,https://github.com/rstudio/markdown,18653245,56,2020-02-06T16:40:30Z,333093.66071428574
markdownInput,"An R-Shiny module containing a ""markdownInput"". This input allows
    the user to write some markdown code and to preview the result. This input
    has been inspired by the ""comment"" window of <https://github.com/>.",2020-01-31,Julien Diot,https://github.com/juliendiot42/markdownInput,TRUE,https://github.com/juliendiot42/markdowninput,2192,2,2020-02-03T02:14:12Z,1096
markovchain,"Functions and S4 methods to create and manage discrete time Markov
    chains more easily. In addition functions to perform statistical (fitting
    and drawing random variates) and probabilistic (analysis of their structural
    proprieties) analysis are provided.",2020-05-21,Giorgio Alfredo Spedicato,http://github.com/spedygiorgio/markovchain/,TRUE,https://github.com/spedygiorgio/markovchain,208197,77,2020-05-20T21:23:57Z,2703.8571428571427
MarkowitzR,"A collection of tools for analyzing significance of 
    Markowitz portfolios.",2020-01-08,Steven E. Pav,https://github.com/shabbychef/MarkowitzR,TRUE,https://github.com/shabbychef/markowitzr,26152,3,2020-01-07T15:57:32Z,8717.333333333334
marmap,"Import xyz data from the NOAA (National Oceanic and Atmospheric Administration, <http://www.noaa.gov>), GEBCO (General Bathymetric Chart of the Oceans, <http://www.gebco.net>) and other sources, plot xyz data to prepare publication-ready figures, analyze xyz data to extract transects, get depth / altitude based on geographical coordinates, or calculate z-constrained least-cost paths.",2020-05-19,Eric Pante,https://github.com/ericpante/marmap,TRUE,https://github.com/ericpante/marmap,69271,13,2020-05-27T09:37:21Z,5328.538461538462
marqLevAlg,"This algorithm provides a numerical solution to the
        problem of minimizing (or maximizing) a function. It is particularly suited for complex problems and more efficient than
        the Gauss-Newton-like algorithm when starting from points very
        far from the final minimum (or maximum). Each iteration is parallelized and convergence relies on a stringent stopping criterion based on the first and second derivatives. ",2020-03-30,Viviane Philipps,NA,TRUE,https://github.com/vivianephilipps/marqlevalgparallel,16473,0,2020-03-26T17:23:28Z,NA
MARSS,"The MARSS package provides maximum-likelihood parameter estimation for constrained and unconstrained linear multivariate autoregressive state-space (MARSS) models fit to multivariate time-series data.  Fitting is primarily via an Expectation-Maximization (EM) algorithm, although fitting via the BFGS algorithm (using the optim function) is also provided.  MARSS models are a class of dynamic linear model (DLM) and vector autoregressive model (VAR) model.  Functions are provided for parametric and innovations bootstrapping, Kalman filtering and smoothing, bootstrap model selection criteria (AICb), confidences intervals via the Hessian approximation and via bootstrapping and calculation of auxiliary residuals for detecting outliers and shocks.  The user guide shows examples of using MARSS for parameter estimation for a variety of applications, model selection, dynamic factor analysis, outlier and shock detection, and addition of covariates.  Type RShowDoc(""UserGuide"", package=""MARSS"") at the R command line to open the MARSS user guide.  Online workshops (lectures and computer labs) at <https://nwfsc-timeseries.github.io/>  See the NEWS file for update information.",2020-02-04,Eli Holmes,https://nwfsc-timeseries.github.io/MARSS,TRUE,https://github.com/nwfsc-timeseries/marss,49148,23,2020-05-20T18:02:38Z,2136.8695652173915
mashr,"Implements the multivariate adaptive shrinkage (mash)
    method of Urbut et al (2019) <DOI:10.1038/s41588-018-0268-8> for
    estimating and testing large numbers of effects in many conditions
    (or many outcomes). Mash takes an empirical Bayes approach to
    testing and effect estimation; it estimates patterns of similarity
    among conditions, then exploits these patterns to improve accuracy
    of the effect estimates. The core linear algebra is implemented in
    C++ for fast model fitting and posterior computation.",2020-06-09,Peter Carbonetto,http://github.com/stephenslab/mashr,TRUE,https://github.com/stephenslab/mashr,0,32,2020-05-22T20:37:10Z,0
mason,"Use a consistent syntax to create data structures
    of common statistical techniques that can be continued in a pipe
    chain.  Design the analysis, add settings and variables, construct the
    results, and polish the final structure. Rinse and repeat for any
    number of statistical techniques.",2020-06-04,Luke Johnston,https://github.com/lwjohnst86/mason,TRUE,https://github.com/lwjohnst86/mason,11338,1,2020-06-04T17:01:07Z,11338
matahari,"Conveniently log everything you type into the R console. Logs are
    are stored as tidy data frames which can then be analyzed using 'tidyverse'
    style tools.",2020-02-06,Sean Kross,https://github.com/jhudsl/matahari,TRUE,https://github.com/jhudsl/matahari,5656,34,2020-02-08T00:32:24Z,166.35294117647058
matchingMarkets,"Implements structural estimators to correct for
    the sample selection bias from observed outcomes in matching
    markets. This includes one-sided matching of agents into
    groups as well as two-sided matching of students to schools.
    The package also contains algorithms to find stable matchings
    in the three most common matching problems: the stable roommates
    problem, the college admissions problem, and the house
    allocation problem.",2020-01-12,Thilo Klein,"http://matchingMarkets.org, http://klein.uk",TRUE,https://github.com/thiloklein/matchingmarkets,53893,28,2019-12-15T09:22:24Z,1924.75
matchmaker,"Provides flexible dictionary-based
    cleaning that allows users to specify implicit and explicit missing data,
    regular expressions for both data and columns, and global matches, while
    respecting ordering of factors. This package is part of the 'RECON'
    (<https://www.repidemicsconsortium.org/>) toolkit for outbreak analysis.",2020-02-21,Zhian N. Kamvar,"https://www.repidemicsconsortium.org/matchmaker,
https://github.com/reconhub/matchmaker",TRUE,https://github.com/reconhub/matchmaker,3216,4,2020-02-21T20:44:05Z,804
MatchThem,"Provides the necessary tools for the pre-processing techniques of matching and weighting multiply imputed datasets to control for effects of confounders and to reduce the degree of dependence on certain modeling assumptions in studying the causal associations between an exposure and an outcome. This package includes functions to perform matching within and across the multiply imputed datasets using several matching methods, to estimate weights of units in the imputed datasets using several weighting methods, to calculate the causal effect estimate in each matched or weighted dataset using parametric or non-parametric statistical models, and to pool the obtained estimates from these models according to Rubin's rules (please see <https://github.com/FarhadPishgar/MatchThem> for details).",2020-03-23,Farhad Pishgar,https://github.com/FarhadPishgar/MatchThem,TRUE,https://github.com/farhadpishgar/matchthem,4327,2,2020-03-22T18:06:14Z,2163.5
mathjaxr,Provides 'MathJax' and macros to enable its use within Rd files for rendering equations in the HTML help files.,2020-05-08,Wolfgang Viechtbauer,https://github.com/wviechtb/mathjaxr,TRUE,https://github.com/wviechtb/mathjaxr,1128,20,2020-06-05T15:52:29Z,56.4
matlib,"A collection of matrix functions for teaching and learning matrix
    linear algebra as used in multivariate statistical methods. These functions are
    mainly for tutorial purposes in learning matrix algebra ideas using R. In some
    cases, functions are provided for concepts available elsewhere in R, but where
    the function call or name is not obvious. In other cases, functions are provided
    to show or demonstrate an algorithm. In addition, a collection of functions are
    provided for drawing vector diagrams in 2D and 3D.",2020-04-02,Michael Friendly,https://github.com/friendly/matlib,TRUE,https://github.com/friendly/matlib,138668,38,2020-05-05T14:12:19Z,3649.157894736842
matricks,"Provides functions, which make matrix creation conciser 
             (such as the core package's function m() for rowwise matrix definition or 
             runifm() for random value matrices).
             Allows to set multiple matrix values at once, by using list of formulae. 
             Provides additional matrix operators and dedicated plotting function.",2020-02-23,Krzysztof Joachimiak,"https://github.com/krzjoa/matricks,
https://krzjoa.github.io/matricks/",TRUE,https://github.com/krzjoa/matricks,1458,2,2020-03-03T22:15:06Z,729
MatrixEQTL,"Matrix eQTL is designed for fast eQTL analysis on large datasets.
        Matrix eQTL can test for association between genotype 
        and gene expression using linear regression 
        with either additive or ANOVA genotype effects.
        The models can include covariates to account for factors 
        as population stratification, gender, and clinical variables. 
        It also supports models with heteroscedastic and/or correlated errors,
        false discovery rate estimation and 
        separate treatment of local (cis) and distant (trans) eQTLs.
        For more details see Shabalin (2012) <doi:10.1093/bioinformatics/bts163>.",2019-12-22,Andrey A Shabalin,http://www.bios.unc.edu/research/genomic_software/Matrix_eQTL/,TRUE,https://github.com/andreyshabalin/matrixeqtl,36919,22,2019-12-05T00:27:46Z,1678.1363636363637
matrixProfile,"A simple and the early stage package for matrix profile based on the paper of Chin-Chia Michael Yeh, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Hoang Anh Dau, Diego Furtado Silva, Abdullah Mueen, and Eamonn Keogh (2016) <DOI:10.1109/ICDM.2016.0179>. This package calculates all-pairs-similarity for a given window size for time series data.",2018-08-17,Donghwan Kim,https://github.com/ainsuotain/matrixprofile,TRUE,https://github.com/ainsuotain/matrixprofile,6468,1,2020-05-13T04:29:53Z,6468
matrixsampling,"Provides samplers for various matrix variate distributions: Wishart, inverse-Wishart, normal, t, inverted-t, Beta type I, Beta type II, Gamma, confluent hypergeometric. Allows to simulate the noncentral Wishart distribution without the integer restriction on the degrees of freedom.",2019-08-24,Stéphane Laurent,https://github.com/stla/matrixsampling,TRUE,https://github.com/stla/matrixsampling,10929,1,2019-08-26T06:33:03Z,10929
matrixStats,"High-performing functions operating on rows and columns of matrices, e.g. col / rowMedians(), col / rowRanks(), and col / rowSds().  Functions optimized per data type and for subsetted calculations such that both memory usage and processing time is minimized.  There are also optimized vector-based methods, e.g. binMeans(), madDiff() and weightedMedian().",2020-03-13,Henrik Bengtsson,https://github.com/HenrikBengtsson/matrixStats,TRUE,https://github.com/henrikbengtsson/matrixstats,3728504,136,2020-05-26T17:25:34Z,27415.470588235294
matrixStrucTest,"Tests for block-diagonal structure in symmetric matrices (e.g. correlation matrices) under the null hypothesis of exchangeable off-diagonal elements. As described in Segal et al. (2019), these tests can be useful for construct validation either by themselves or as a complement to confirmatory factor analysis. Monte Carlo methods are used to approximate the permutation p-value with Hubert's Gamma (Hubert, 1976) and a t-statistic. This package also implements the chi-squared statistic described by Steiger (1980). Please see Segal, et al. (2019) <doi:10.1007/s11336-018-9647-4> for more information.",2019-07-18,Brian D. Segal,https://github.com/bdsegal/matrixStrucTest,TRUE,https://github.com/bdsegal/matrixstructest,3518,0,2019-07-19T19:18:09Z,NA
matrixTests,"Functions to perform fast statistical hypothesis tests on rows/columns of matrices.
  The main goals are: 1) speed via vectorization, 2) output that is detailed and easy to use,
  3) compatibility with tests implemented in R (like those available in the 'stats' package).",2020-05-01,Karolis Koncevičius,https://github.com/KKPMW/matrixTests,TRUE,https://github.com/kkpmw/matrixtests,13803,17,2020-05-02T17:13:33Z,811.9411764705883
matsbyname,"An implementation of matrix mathematics wherein operations are performed ""by name.""",2020-05-29,Matthew Heun,https://github.com/MatthewHeun/matsbyname,TRUE,https://github.com/matthewheun/matsbyname,7805,0,2020-05-29T17:03:02Z,NA
matsindf,"Provides functions to collapse a tidy data frame into matrices in a data frame
    and expand a data frame of matrices into a tidy data frame.",2020-03-22,Matthew Heun,https://github.com/MatthewHeun/matsindf,TRUE,https://github.com/matthewheun/matsindf,6436,3,2020-04-19T22:34:00Z,2145.3333333333335
mauricer,"'BEAST2' (<http://www.beast2.org>) is a widely used
    Bayesian phylogenetic tool, that uses DNA/RNA/protein data
    and many model priors to create a posterior of jointly estimated 
    phylogenies and parameters.
    'BEAST2' is commonly accompanied by 'BEAUti 2' (<http://www.beast2.org>),
    which, among others, allows one to install 'BEAST2' package. 
    This package allows to install 'BEAST2' packages from 'R'.",2019-12-02,Richèl J.C. Bilderbeek,https://github.com/ropensci/mauricer,TRUE,https://github.com/ropensci/mauricer,3796,1,2020-04-22T10:38:19Z,3796
maxnet,"Procedures to fit species distributions models from occurrence records and environmental variables, using 'glmnet' for model fitting. Model structure is the same as for the 'Maxent' Java package, version 3.4.0, with the same feature types and regularization options.  See the 'Maxent' website <http://biodiversityinformatics.amnh.org/open_source/maxent> for more details.",2017-02-11,Steven Phillips,https://github.com/mrmaxent/maxnet,TRUE,https://github.com/mrmaxent/maxnet,32198,44,2020-02-27T20:34:31Z,731.7727272727273
MazamaCoreUtils,"A suite of utility functions providing functionality commonly
    needed for production level projects such as logging, error handling,
    and cache management.",2020-04-08,Jonathan Callahan,https://github.com/MazamaScience/MazamaCoreUtils,TRUE,https://github.com/mazamascience/mazamacoreutils,10717,2,2020-04-08T18:26:02Z,5358.5
MazamaLocationUtils,"A suite of utility functions for discovering and managing metadata 
    associated with sets of spatially unique ""known locations"".",2019-11-20,Jonathan Callahan,https://github.com/MazamaScience/MazamaCoreUtils,TRUE,https://github.com/mazamascience/mazamacoreutils,2791,2,2020-04-08T18:26:02Z,1395.5
MazamaSpatialUtils,"A suite of conversion scripts to create internally standardized
    spatial polygons data frames. Utility scripts use these data sets to return
    values such as country, state, timezone, watershed, etc. associated with a
    set of longitude/latitude pairs. (They also make cool maps.)",2019-09-28,Jonathan Callahan,https://github.com/MazamaScience/MazamaSpatialUtils,TRUE,https://github.com/mazamascience/mazamaspatialutils,28248,0,2020-05-18T22:59:18Z,NA
mbbefd,"Distributions that are typically used for exposure rating in
             general insurance, in particular to price reinsurance contracts.
             The vignettes show code snippets to fit the distribution to
             empirical data.",2019-01-02,Giorgio Spedicato,http://github.com/spedygiorgio/mbbefd,TRUE,https://github.com/spedygiorgio/mbbefd,24839,9,2020-04-26T19:54:04Z,2759.8888888888887
mbend,"Bending non-positive-definite (symmetric) matrices to positive-definite, using weighted and unweighted methods.
   Jorjani, H., et al. (2003) <doi:10.3168/jds.S0022-0302(03)73646-7>.
   Schaeffer, L. R. (2014) <http://animalbiosciences.uoguelph.ca/~lrs/ELARES/PDforce.pdf>.",2020-06-05,Mohammad Ali Nilforooshan,https://github.com/nilforooshan/mbend,TRUE,https://github.com/nilforooshan/mbend,3490,1,2020-06-04T23:33:37Z,3490
mboost,"Functional gradient descent algorithm
  (boosting) for optimizing general risk functions utilizing
  component-wise (penalised) least squares estimates or regression
  trees as base-learners for fitting generalized linear, additive
  and interaction models to potentially high-dimensional data.",2020-02-18,Benjamin Hofner,https://github.com/boost-R/mboost,TRUE,https://github.com/boost-r/mboost,276009,52,2020-02-17T13:10:05Z,5307.865384615385
mboxr,Importing and converting an mbox file into a tibble object.,2019-10-28,JooYoung Seo,https://github.com/jooyoungseo/mboxr,TRUE,https://github.com/jooyoungseo/mboxr,9028,7,2020-05-16T15:04:56Z,1289.7142857142858
MCDA,"Support for the analyst in a Multicriteria Decision Aiding (MCDA) process with algorithms, 
    preference elicitation and data visualisation functions. Sébastien Bigaret, Richard Hodgett, Patrick Meyer, 
    Tatyana Mironova, Alexandru Olteanu (2017) Supporting the multi-criteria decision aiding process : 
    R and the MCDA package, Euro Journal On Decision Processes, Volume 5, Issue 1 - 4, 
    pages 169 - 194 <doi:10.1007/s40070-017-0064-1>.",2019-05-29,Patrick Meyer,https://github.com/paterijk/MCDA,TRUE,https://github.com/paterijk/mcda,24889,15,2020-05-28T09:23:04Z,1659.2666666666667
mclogit,"Specification and estimation of conditional logit models of binary
    responses and multinomial counts is provided, with or without
    random effects. The current implementation of the estimator for random
    effects variances uses a Laplace approximation (or PQL) approach and thus should
    be used only if groups sizes are large.",2018-09-27,Martin Elff,"http://www.elff.eu/software/mclogit/,http://github.com/melff/mclogit/",TRUE,https://github.com/melff/mclogit,29397,13,2020-05-28T21:39:29Z,2261.3076923076924
mcmc,"Simulates continuous distributions of random vectors using
    Markov chain Monte Carlo (MCMC).  Users specify the distribution by an
    R function that evaluates the log unnormalized density.  Algorithms
    are random walk Metropolis algorithm (function metrop), simulated
    tempering (function temper), and morphometric random walk Metropolis
    (Johnson and Geyer, 2012, <doi:10.1214/12-AOS1048>,
    function morph.metrop),
    which achieves geometric ergodicity by change of variable.",2020-03-21,Charles J. Geyer,"http://www.stat.umn.edu/geyer/mcmc/,
https://github.com/cjgeyer/mcmc",TRUE,https://github.com/cjgeyer/mcmc,461156,13,2020-03-24T05:38:57Z,35473.53846153846
mcmcderive,"Generates derived parameter(s) from Monte Carlo Markov Chain (MCMC) 
    samples using R code. This allows Bayesian models to be fitted without the 
    inclusion of derived parameters which add unnecessary clutter and 
    slow model fitting. For more information on MCMC samples see 
    Brooks et al. (2011) <isbn:978-1-4200-7941-8>.",2019-07-02,Joe Thorley,https://github.com/poissonconsulting/mcmcderive,TRUE,https://github.com/poissonconsulting/mcmcderive,3732,0,2020-05-13T00:38:50Z,NA
mcmcOutput,"Implements a class ('mcmcOutput') for efficiently storing and handling Markov chain Monte Carlo (MCMC) output, intended as an aid for those writing customized MCMC samplers. A range of constructor methods are provided covering common output formats. Functions are provided to generate summary and diagnostic statistics and to display histograms or density plots of posterior distributions, for the entire output, or subsets of draws, nodes, or parameters.",2020-06-04,Mike Meredith,https://github.com/mikemeredith/mcmcOutput,TRUE,https://github.com/mikemeredith/mcmcoutput,0,0,2020-06-07T02:10:51Z,NA
MCMCprecision,"Estimates the precision of transdimensional Markov chain Monte Carlo 
    (MCMC) output, which is often used for Bayesian analysis of models with different 
    dimensionality (e.g., model selection). Transdimensional MCMC (e.g., reversible 
    jump MCMC) relies on sampling a discrete model-indicator variable to estimate 
    the posterior model probabilities. If only few switches occur between the models, 
    precision may be low and assessment based on the assumption of independent 
    samples misleading. Based on the observed transition matrix of the indicator 
    variable, the method of Heck, Overstall, Gronau, & Wagenmakers (2019, 
    Statistics & Computing, 29, 631-643) <doi:10.1007/s11222-018-9828-0> draws 
    posterior samples of the stationary distribution to (a) assess the uncertainty 
    in the estimated posterior model probabilities and (b) estimate the effective 
    sample size of the MCMC output.",2019-12-05,Daniel W. Heck,https://github.com/danheck/MCMCprecision,TRUE,https://github.com/danheck/mcmcprecision,13246,0,2020-01-23T10:02:44Z,NA
mcmcr,"Functions and classes to store, manipulate and summarise 
   Monte Carlo Markov Chain (MCMC) samples. For more information see 
   Brooks et al. (2011) <isbn:978-1-4200-7941-8>.",2019-06-27,Joe Thorley,https://github.com/poissonconsulting/mcmcr,TRUE,https://github.com/poissonconsulting/mcmcr,9007,5,2020-06-09T23:11:44Z,1801.4
MCMCvis,"Performs key functions for MCMC analysis using minimal code - visualizes, manipulates, and summarizes MCMC output. Functions support simple and straightforward subsetting of model parameters within the calls, and produce presentable and 'publication-ready' output. MCMC output may be derived from Bayesian model output fit with JAGS, Stan, or other MCMC samplers.",2020-03-25,Casey Youngflesh,http://github.com/caseyyoungflesh/MCMCvis,TRUE,https://github.com/caseyyoungflesh/mcmcvis,27813,27,2020-03-25T02:32:38Z,1030.111111111111
mcp,"Flexible and informed regression with Multiple Change Points (MCP). 'mcp' can infer change points in means, variances, autocorrelation structure, and any combination of these, as well as the parameters of the segments in between. All parameters are estimated with uncertainty and prediction intervals are supported - also near the change points. 'mcp' supports hypothesis testing via Savage-Dickey density ratio, posterior contrasts, and cross-validation. 'mcp' provides a generalization of the approach described in Carlin, Gelfand, & Smith (1992) <doi:10.2307/2347570> and Stephens (1994) <doi:10.2307/2986119>.",2020-01-09,Jonas Kristoffer Lindeløv,"http://lindeloev.github.io/mcp/, https://github.com/lindeloev/mcp",TRUE,https://github.com/lindeloev/mcp,3026,40,2020-01-10T08:22:06Z,75.65
MCPModPack,"An efficient implementation of the MCPMod (Multiple Comparisons and Modeling) method to support a simulation-based design and analysis of dose-finding trials with normally distributed, binary and count endpoints (Bretz et al. (2005) <doi:10.1111/j.1541-0420.2005.00344.x>).",2020-03-19,Alex Dmitrienko,https://github.com/medianainc/MCPModPack,TRUE,https://github.com/medianainc/mcpmodpack,1305,2,2020-04-21T02:18:40Z,652.5
mde,"Correct identification and handling of missing data is one of the most important steps in any analysis. To aid this process, 'mde' provides a very easy to use yet robust framework to quickly get an idea of where the missing data
             lies and therefore find the most appropriate action to take.
             Graham WJ (2009) <doi:10.1146/annurev.psych.58.110405.085530>. ",2020-02-29,Nelson Gonzabato,https://github.com/Nelson-Gon/mde,TRUE,https://github.com/nelson-gon/mde,1601,0,2020-06-01T15:34:56Z,NA
mdmb,"
    Contains model-based treatment of missing data for regression 
    models with missing values in covariates or the dependent 
    variable using maximum likelihood or Bayesian estimation 
    (Ibrahim et al., 2005; <doi:10.1198/016214504000001844>;
    Luedtke, Robitzsch, & West, 2019a, 2019b, <doi:10.1037/met0000233>; 
    <doi:10.1080/00273171.2019.1640104>).
    The regression model can be nonlinear (e.g., interaction 
    effects, quadratic effects or B-spline functions). 
    Multilevel models with missing data in predictors are
    available for Bayesian estimation. Substantive-model compatible 
    multiple imputation can be also conducted.",2020-05-12,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/mdmb,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/mdmb,38683,2,2020-05-12T20:30:14Z,19341.5
MDplot,"Provides automatization for plot generation succeeding common molecular dynamics analyses.
             This includes straightforward plots, such as RMSD (Root-Mean-Square-Deviation) and
             RMSF (Root-Mean-Square-Fluctuation) but also more sophisticated ones such as
             dihedral angle maps, hydrogen bonds, cluster bar plots and
             DSSP (Definition of Secondary Structure of Proteins) analysis. Currently able to load
             GROMOS, GROMACS and AMBER formats, respectively.",2017-07-04,Christian Margreitter,https://github.com/MDplot/MDplot,TRUE,https://github.com/mdplot/mdplot,13897,8,2019-08-25T17:55:39Z,1737.125
mdsr,"A complement to *Modern Data
    Science with R* (ISBN: 978-1498724487, publisher URL: 
    <https://www.crcpress.com/Modern-Data-Science-with-R/Baumer-Kaplan-Horton/p/book/9781498724487>). 
    This package contains all of the data and code necessary to
    complete exercises and reproduce examples from the text. It also 
    facilitates connections to the SQL database server used in the book.",2019-05-20,Ben Baumer,http://github.com/beanumber/mdsr,TRUE,https://github.com/beanumber/mdsr,33303,24,2020-06-01T16:37:19Z,1387.625
meanr,"Sentiment analysis is a popular technique in text mining that
    attempts to determine the emotional state of some text. We provide a new
    implementation of a common method for computing sentiment, whereby words are
    scored as positive or negative according to a dictionary lookup. Then the
    sum of those scores is returned for the document. We use the 'Hu' and 'Liu'
    sentiment dictionary ('Hu' and 'Liu', 2004) <doi:10.1145/1014052.1014073>
    for determining sentiment. The scoring function is 'vectorized' by document,
    and scores for multiple documents are computed in parallel via 'OpenMP'.",2019-07-19,Drew Schmidt,https://github.com/wrathematics/meanr,TRUE,https://github.com/wrathematics/meanr,13151,20,2019-07-19T19:18:40Z,657.55
Mediana,"Provides a general framework for clinical trial simulations based
    on the Clinical Scenario Evaluation (CSE) approach. The package supports a
    broad class of data models (including clinical trials with continuous, binary,
    survival-type and count-type endpoints as well as multivariate outcomes that are
    based on combinations of different endpoints), analysis strategies and commonly
    used evaluation criteria.",2019-05-08,Gautier Paux,http://gpaux.github.io/Mediana/,TRUE,https://github.com/gpaux/mediana,20572,12,2020-04-18T18:41:48Z,1714.3333333333333
medicalrisk,"Generates risk estimates and comorbidity flags from ICD-9-CM
    codes available in administrative medical datasets. The package supports
    the Charlson Comorbidity Index, the Elixhauser Comorbidity
    classification, the Revised Cardiac Risk Index, and the Risk Stratification
    Index.  Methods are table-based, fast, and use the 'plyr' package, so
    parallelization is possible for large jobs. Also includes a sample of
    real ICD-9 data for 100 patients from a publicly available dataset.",2020-02-29,Patrick McCormick,https://github.com/patrickmdnet/medicalrisk,TRUE,https://github.com/patrickmdnet/medicalrisk,16714,4,2020-02-29T03:02:57Z,4178.5
meditate,A simple meditation timer that logs session information.,2020-01-15,Jason C. Fisher,https://github.com/jfisher-usgs/meditate,TRUE,https://github.com/jfisher-usgs/meditate,2710,0,2020-01-15T16:58:36Z,NA
meditations,Prints a random quote from Marcus Aurelius' book Meditations.,2019-01-16,Jacob Kaplan,https://github.com/jacobkap/meditations,TRUE,https://github.com/jacobkap/meditations,5899,1,2019-12-01T01:37:37Z,5899
medmod,"This toolbox allows you to do simple mediation and moderation 
    analysis. It is also available as a module for 'jamovi' 
    (see <https://www.jamovi.org> for more information). 'Medmod' is based 
    on the 'lavaan' package by Yves Rosseel. You can find an in depth tutorial 
    on the 'lavaan' model syntax used for this package on 
    <http://lavaan.ugent.be/tutorial/index.html>.",2017-09-12,Ravi Selker,https://github.com/raviselker/medmod,TRUE,https://github.com/raviselker/medmod,9724,3,2019-11-07T14:08:28Z,3241.3333333333335
MEDseq,"Implements a model-based clustering method for categorical life-course sequences relying on mixtures of exponential-distance models introduced by Murphy et al. (2019) <arXiv:1908.07963>. A range of flexible precision parameter settings corresponding to weighted generalisations of the Hamming distance metric are considered, along with the potential inclusion of a noise component. Gating covariates can be supplied in order to relate sequences to baseline characteristics. Sampling weights are also accommodated. The models are fitted using the EM algorithm and tools for visualising the results are also provided.",2020-05-12,Keefe Murphy,https://cran.r-project.org/package=MEDseq,TRUE,https://github.com/keefe-murphy/medseq,3963,1,2020-05-12T22:16:48Z,3963
mefa4,"An S4 update of the 'mefa' package
  using sparse matrices for enhanced efficiency.
  Sparse array-like objects are supported via
  lists of sparse matrices.",2020-02-28,Peter Solymos,https://github.com/psolymos/mefa4,TRUE,https://github.com/psolymos/mefa4,30442,0,2020-02-28T03:02:03Z,NA
MEGENA,"Co-Expression Network Analysis by adopting network embedding technique. Song W.-M., Zhang B. (2015) Multiscale Embedded Gene Co-expression Network Analysis. PLoS Comput Biol 11(11): e1004574. <doi: 10.1371/journal.pcbi.1004574>.",2018-09-10,Won-Min Song,https://github.com/songw01/MEGENA,TRUE,https://github.com/songw01/megena,12478,5,2020-05-21T14:58:09Z,2495.6
mem,"The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week.",2019-05-28,Jose E. Lozano,https://github.com/lozalojo/mem,TRUE,https://github.com/lozalojo/mem,25581,4,2020-01-24T09:10:15Z,6395.25
memapp,"The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week. 'memapp' is a web application created in the Shiny framework for the 'mem' R package.",2019-06-04,Jose E. Lozano,https://github.com/lozalojo/memapp,TRUE,https://github.com/lozalojo/memapp,20883,2,2019-06-19T06:21:17Z,10441.5
meme,"The word 'Meme' was originated from the book, 'The Selfish Gene', authored by Richard Dawkins (1976).
             It is a unit of culture that is passed from one generation to another and correlates to the gene, the unit of physical heredity.
             The internet memes are captioned photos that are intended to be funny, ridiculous.
             Memes behave like infectious viruses and travel from person to person quickly through social media.
             The 'meme' package allows users to make custom memes.",2019-08-05,Guangchuang Yu,https://github.com/GuangchuangYu/meme/,TRUE,https://github.com/guangchuangyu/meme,15788,30,2019-08-05T08:24:11Z,526.2666666666667
memery,"Generates internet memes that optionally include a superimposed inset plot and other atypical features, 
    combining the visual impact of an attention-grabbing meme with graphic results of data analysis.
    The package differs from related packages that focus on imitating and reproducing standard memes.
    Some packages do this by interfacing with online meme generators whereas others achieve this natively.
    This package takes the latter approach. It does not interface with online meme generators or require any authentication with external websites.
    It reads images directly from local files or via URL and meme generation is done by the package.
    While this is similar to the 'meme' package available on CRAN, it differs in that the focus is on 
    allowing for non-standard meme layouts and hybrids of memes mixed with graphs.
    While this package can be used to make basic memes like an online meme generator would produce, 
    it caters primarily to hybrid graph-meme plots where the meme presentation can be seen as a backdrop highlighting 
    foreground graphs of data analysis results.
    The package also provides support for an arbitrary number of meme text labels with arbitrary size, position and other attributes 
    rather than restricting to the standard top and/or bottom text placement. 
    This is useful for proper aesthetic interleaving of plots of data between meme image backgrounds and overlain text labels.
    The package offers a selection of templates for graph placement and appearance with respect to the underlying meme.
    Graph templates also permit additional template-specific customization.
    Animated gif support is provided but this is optional and functional only if the 'magick' package is installed. 
    'magick' is not required unless gif functionality is desired.",2019-04-19,Matthew Leonawicz,https://github.com/leonawicz/memery,TRUE,https://github.com/leonawicz/memery,13040,12,2020-01-18T19:06:06Z,1086.6666666666667
memisc,"An infrastructure for the management of survey data including
        value labels, definable missing values, recoding of variables,
        production of code books, and import of (subsets of) 'SPSS' and
        'Stata' files is provided. Further, the package allows to produce
        tables and data frames of arbitrary descriptive statistics and
        (almost) publication-ready tables of regression model
        estimates, which can be exported to 'LaTeX' and HTML.",2020-02-14,Martin Elff (with contributions from Christopher N. Lawrence,"http://www.elff.eu/software/memisc/,http://github.com/melff/memisc/",TRUE,https://github.com/melff/memisc,412328,32,2020-06-09T19:46:46Z,12885.25
memoise,"Cache the results of a function so that when you call it
    again with the same arguments it returns the pre-computed value.",2017-04-21,Jim Hester,https://github.com/hadley/memoise,TRUE,https://github.com/hadley/memoise,8224443,218,2020-04-03T15:19:36Z,37726.80275229358
memor,"A 'rmarkdown' template that supports company logo, contact info, 
    watermarks and more. Currently restricted to 'Latex'/'Markdown'; a similar 
    'HTML' theme will be added in the future. ",2020-05-10,Hao Zhu,https://github.com/hebrewseniorlife/memor,TRUE,https://github.com/hebrewseniorlife/memor,7944,59,2020-05-10T02:44:47Z,134.64406779661016
memuse,"How much ram do you need to store a 100,000 by 100,000 matrix?
    How much ram is your current R session using? How much ram do you even have?
    Learn the scintillating answer to these and many more such questions with
    the 'memuse' package.",2020-02-17,Drew Schmidt,https://github.com/shinra-dev/memuse,TRUE,https://github.com/shinra-dev/memuse,76454,32,2020-02-11T01:57:14Z,2389.1875
MESS,"A mixed collection of useful and semi-useful diverse
    statistical functions, some of which may even be referenced in
    The R Primer book.",2019-09-15,Claus Thorn Ekstrøm,https://github.com/ekstroem/MESS,TRUE,https://github.com/ekstroem/mess,67641,2,2020-05-29T17:57:29Z,33820.5
meta,"User-friendly general package providing standard methods for meta-analysis and supporting Schwarzer, Carpenter, and Rücker <DOI:10.1007/978-3-319-21416-0>, ""Meta-Analysis with R"" (2015):
 - fixed effect and random effects meta-analysis;
 - several plots (forest, funnel, Galbraith / radial, L'Abbe, Baujat, bubble);
 - statistical tests and trim-and-fill method to evaluate bias in meta-analysis;
 - import data from 'RevMan 5';
 - prediction interval, Hartung-Knapp method for random effects model;
 - cumulative meta-analysis and leave-one-out meta-analysis;
 - meta-regression;
 - generalised linear mixed models;
 - produce forest plot summarising several (subgroup) meta-analyses.",2020-05-04,Guido Schwarzer,https://github.com/guido-s/meta http://meta-analysis-with-r.org,TRUE,https://github.com/guido-s/meta,263982,28,2020-05-04T18:10:27Z,9427.92857142857
metaBMA,"Computes the posterior model probabilities for standard meta-analysis models 
    (null model vs. alternative model assuming either fixed- or random-effects, respectively).
    These posterior probabilities are used to estimate the overall mean effect size 
    as the weighted average of the mean effect size estimates of the random- and 
    fixed-effect model as proposed by Gronau, Van Erp, Heck, Cesario, Jonas, & 
    Wagenmakers (2017, <doi:10.1080/23743603.2017.1326760>). The user can define 
    a wide range of non-informative or informative priors for the mean effect size 
    and the heterogeneity coefficient. Moreover, using pre-compiled Stan models, 
    meta-analysis with continuous and discrete moderators with Jeffreys-Zellner-Siow (JZS) 
    priors can be fitted and tested. This allows to compute Bayes factors and 
    perform Bayesian model averaging across random- and fixed-effects meta-analysis 
    with and without moderators. For a primer on Bayesian model-averaged meta-analysis, 
    see Gronau, Heck, Berkhout, Haaf, & Wagenmakers (2020, <doi:10.31234/osf.io/97qup>).",2020-06-02,Daniel W. Heck,https://github.com/danheck/metaBMA,TRUE,https://github.com/danheck/metabma,38568,11,2020-01-23T10:06:26Z,3506.181818181818
MetabolicSurv,"An approach to identifies metabolic biomarker signature for metabolic data by discovering predictive metabolite for predicting survival and classifying patients into risk groups. 
 Classifiers are constructed as a linear combination of predictive/important metabolites, prognostic factors and treatment effects if necessary. 
 Several methods were implemented to reduce the metabolomics matrix such as the  principle component analysis of Wold Svante et al. (1987) <doi:10.1016/0169-7439(87)80084-9> , 
 the LASSO method by Robert Tibshirani (1998) <doi:10.1002/(SICI)1097-0258(19970228)16:4%3C385::AID-SIM380%3E3.0.CO;2-3>, the 
 elastic net approach by Hui Zou and Trevor Hastie (2005) <doi:10.1111/j.1467-9868.2005.00503.x>. 
 Sensitivity analysis on the quantile used for the classification can also be accessed to check the deviation of the classification group based on the quantile specified. 
 Large scale cross validation can be performed in  order to investigate the mostly selected predictive metabolites and for internal validation. During the evaluation process, validation is accessed using the hazard ratios (HR) distribution of the test set and inference is mainly based on resampling and permutations technique.",2019-08-05,Olajumoke Evangelina Owokotomo,https://github.com/OlajumokeEvangelina/MetabolicSurv,TRUE,https://github.com/olajumokeevangelina/metabolicsurv,5514,0,2019-08-06T11:06:08Z,NA
metacoder,"A set of tools for parsing, manipulating, and graphing data
    classified by a hierarchy (e.g. a taxonomy).",2020-04-29,Zachary Foster,https://grunwaldlab.github.io/metacoder_documentation/,TRUE,https://github.com/grunwaldlab/metacoder,27226,80,2020-05-07T22:18:45Z,340.325
metacom,"Functions to analyze coherence, boundary clumping, and turnover
    following the pattern-based metacommunity analysis of Leibold and Mikkelson
    2002  <doi:10.1034/j.1600-0706.2002.970210.x>. The package also includes 
		functions to visualize ecological networks, and to calculate modularity 
		as a replacement to boundary clumping.",2020-03-23,Tad Dallas,https://cran.r-project.org/package=metacom,TRUE,https://github.com/taddallas/metacom,30959,8,2020-03-22T23:52:06Z,3869.875
metaDigitise,"High-throughput, flexible and reproducible extraction of data from figures in primary research papers. metaDigitise() can extract data and / or automatically calculate summary statistics for users from box plots, bar plots (e.g., mean and errors), scatter plots and histograms.",2020-03-13,Daniel Noble,NA,TRUE,https://github.com/daniel1noble/metadigitise,7684,48,2020-05-26T04:12:43Z,160.08333333333334
metagam,"Meta-analysis of generalized additive
    models and generalized additive mixed models. A typical use case is
    when data cannot be shared across locations, and an overall meta-analytic
    fit is sought. 'metagam' provides functionality for removing individual
    participant data from models computed using the 'mgcv' and 'gamm4' packages such
    that the model objects can be shared without exposing individual data.
    Furthermore, methods for meta-analysing these fits are provided. The implemented
    methods are described in Sorensen et al. (2020), <arXiv:2002.02627>,
    extending previous works by Schwartz and Zanobetti (2000)
    and Crippa et al. (2018) <doi:10.6000/1929-6029.2018.07.02.1>.",2020-05-11,Oystein Sorensen,"https://lifebrain.github.io/metagam/,
https://github.com/Lifebrain/metagam",TRUE,https://github.com/lifebrain/metagam,2168,1,2020-05-28T10:05:26Z,2168
MetaLonDA,"Identify time intervals of differentially abundant metagenomic features in longitudinal studies (Metwally AA, et al., Microbiome, 2018 <doi:10.1186/s40168-018-0402-y>).",2019-12-18,Ahmed A. Metwally,https://github.com/aametwally/MetaLonDA,TRUE,https://github.com/aametwally/metalonda,13034,3,2019-12-17T20:21:27Z,4344.666666666667
metamedian,"Implements several methods to meta-analyze studies that report the 
    sample median of the outcome. When the primary studies are one-group 
    studies, the methods of McGrath et al. (2019) <doi:10.1002/sim.8013> can 
    be applied to estimate the pooled median. In the two-group context, the 
    methods of McGrath et al. (2020) <doi:10.1002/bimj.201900036> can be 
    applied to estimate the pooled raw difference of medians across groups.",2020-01-28,Sean McGrath,https://github.com/stmcg/metamedian,TRUE,https://github.com/stmcg/metamedian,9332,1,2020-01-28T00:18:58Z,9332
metamer,"Creates data with identical statistics (metamers) using an iterative 
   algorithm proposed by Matejka & Fitzmaurice (2017) <DOI:10.1145/3025453.3025912>.",2019-09-18,Elio Campitelli,https://github.com/eliocamp/metamer,TRUE,https://github.com/eliocamp/metamer,5643,6,2019-09-19T18:38:15Z,940.5
metamicrobiomeR,"Generalized Additive Model for Location, Scale and Shape (GAMLSS) 
    with zero inflated beta (BEZI) family for analysis of microbiome relative abundance data 
    (with various options for data transformation/normalization to address compositional effects) and 
    random effects meta-analysis models for meta-analysis pooling estimates across microbiome studies 
    are implemented.
    Random Forest model to predict microbiome age based on relative abundances of  
    shared bacterial genera with the Bangladesh data (Subramanian et al 2014), 
    comparison of multiple diversity indexes using linear/linear mixed effect models 
    and some data display/visualization are also implemented.
    The reference paper is published by 
    Ho NT, Li F, Wang S, Kuhn L (2019) <doi:10.1186/s12859-019-2744-2> . ",2019-09-03,Nhan Ho,https://github.com/nhanhocu/metamicrobiomeR,TRUE,https://github.com/nhanhocu/metamicrobiomer,2745,10,2020-02-28T01:40:19Z,274.5
metan,"Performs stability analysis of multi-environment
    trial data using parametric and non-parametric methods. Parametric
    methods includes Additive Main Effects and Multiplicative Interaction
    (AMMI) analysis by Gauch (2013) <doi:10.2135/cropsci2013.04.0241>,
    Genotype plus Genotype-Environment (GGE) biplot analysis by Yan & Kang
    (2003) <doi:10.1201/9781420040371>, joint Regression Analysis by
    Eberhart & Russel (1966)
    (<doi:10.2135/cropsci1966.0011183X000600010011x>), ecovalence by
    Wricke (1965), genotypic confidence index by Annicchiarico (1992),
    Murakami & Cruz's (2004) method <doi:10.12702/1984-7033.v04n01a02>,
    stability variance by Shukla (1972) <doi:10.1038/hdy.1972.87>,
    weighted average of absolute scores by Olivoto et al. (2019a)
    <doi:10.2134/agronj2019.03.0220>, and multi-trait stability index by
    Olivoto et al. (2019b) <doi:10.2134/agronj2019.03.0221>.
    Non-parametric methods includes superiority index by Lin & Binns
    (1988) <doi:10.4141/cjps88-018>, nonparametric measures of phenotypic
    stability by Huehn (1990)
    <https://link.springer.com/article/10.1007/BF00024241>, TOP third
    statistic by Fox et al. (1990) <doi:10.1007/BF00040364>, geometric
    adaptability index described by Shahbazi (2019)
    <doi:10.1016/j.scienta.2019.04.047>. Functions for computing
    biometrical analysis such as path analysis, canonical correlation,
    partial correlation, clustering analysis, and tools for inspecting,
    manipulating, summarizing and plotting typical multi-environment
    trial data are also provided.",2020-06-07,Tiago Olivoto,https://github.com/TiagoOlivoto/metan,TRUE,https://github.com/tiagoolivoto/metan,5162,6,2020-06-09T02:59:58Z,860.3333333333334
metapost,"Provides an interface to 'MetaPost' (Hobby, 1998) 
    <http://www.tug.org/docs/metapost/mpman.pdf>.
    There are functions to generate an R description of a 'MetaPost'
    curve, functions to generate 'MetaPost' code from an R description,
    functions to process 'MetaPost' code, and functions to read
    solved 'MetaPost' paths back into R.",2019-06-24,Paul Murrell,"https://github.com/pmur002/metapost,
https://stattech.wordpress.fos.auckland.ac.nz/2018/12/03/2018-12-metapost-three-ways/",TRUE,https://github.com/pmur002/metapost,3583,1,2020-04-29T22:06:26Z,3583
metapro,"The meta-analysis is performed to increase the statistical power by integrating the results from several experiments. The p-values are often combined in meta-analysis when the effect sizes are not available. The 'metapro' R package provides not only traditional methods (Becker BJ (1994, ISBN:0-87154-226-9), Mosteller, F. & Bush, R.R. (1954, ISBN:0201048523) and Lancaster HO (1949, ISSN:00063444)), but also new methods such as weighted Fisher’s method and ordmeta we developed. While the (weighted) Z-method is suitable for finding features effective in most experiments, (weighted) Fisher’s method and ordmeta are useful for detecting partially associated features. Thus, the users can choose the function based on their purpose. ",2019-06-14,Sora Yoon,https://github.com/unistbig/metapro,TRUE,https://github.com/unistbig/metapro,4282,0,2019-06-17T08:34:27Z,NA
metarep,"User-friendly package for reporting replicability-analysis methods, affixed to meta-analyses summary. The replicability-analysis output provides an assessment of the investigated intervention, where it offers quantification of effect replicability and assessment of the consistency of findings.
 - Replicability-analysis for fixed-effects and random-effect meta analysis: 
 - r(u)-value;
 - lower bounds on the number of studies with replicated positive and\or negative effect;
 - Allows detecting inconsistency of signals;
 - forest plots with the summary of replicability analysis results;
 - Allows Replicability-analysis with or without the common-effect assumption. ",2020-04-06,Iman Jaljuli,https://github.com/IJaljuli/metarep,TRUE,https://github.com/ijaljuli/metarep,986,1,2020-04-01T22:35:09Z,986
metaRMST,"R implementation of a multivariate meta-analysis of randomized controlled trials (RCT) with the difference in restricted mean survival times (RMSTD). Use this package with individual patient level data from an RCT for a time-to-event outcome to determine combined effect estimates according to 4 methods: 1)  a univariate meta-analysis using observed treatment effects, 2) a univariate meta-analysis using effects predicted by fitted Royston-Parmar flexible parametric models, 3) multivariate meta-analysis with analytically derived covariance, 4) multivariate meta-analysis with bootstrap derived covariance. This package computes all combined effects and provides an RMSTD curve with combined effect estimates and their confidence intervals.",2018-12-18,Isabelle Weir,https://github.com/iweir/metaRMST,TRUE,https://github.com/iweir/metarmst,5667,0,2019-07-09T15:58:30Z,NA
metaSEM,"A collection of functions for conducting meta-analysis using a
             structural equation modeling (SEM) approach via the 'OpenMx' and
             'lavaan' packages. It also implements various procedures to
			 perform meta-analytic structural equation modeling on the
             correlation and covariance matrices.",2019-12-08,Mike Cheung,https://github.com/mikewlcheung/metasem,TRUE,https://github.com/mikewlcheung/metasem,37637,15,2020-06-01T10:28:47Z,2509.133333333333
MetaStan,"Performs Bayesian meta-analysis and model-based meta-analysis using 'Stan'. 
             Includes binomial-normal hierarchical models and option to use weakly informative priors for the
             heterogeneity parameter and the treatment effect parameter which are described in 
             Guenhan, Roever, and Friede (2020) <doi:10.1002/jrsm.1370>.",2020-04-09,Burak Kuersad Guenhan,https://github.com/gunhanb/MetaStan,TRUE,https://github.com/gunhanb/metastan,9185,3,2020-04-09T13:47:08Z,3061.6666666666665
metathis,"Create meta tags for 'R Markdown' HTML documents
    and 'Shiny' apps for customized social media cards, for accessibility, and 
    quality search engine indexing. 'metathis' currently supports HTML documents
    created with 'rmarkdown', 'shiny', 'xaringan', 'pagedown', 'bookdown', and 
    'flexdashboard'.",2020-03-02,Garrick Aden-Buie,https://github.com/gadenbuie/metathis,TRUE,https://github.com/gadenbuie/metathis,2013,35,2020-05-27T14:07:01Z,57.51428571428571
metaviz,"A compilation of functions to create visually appealing and information-rich 
    plots of meta-analytic data using 'ggplot2'. Currently allows to create forest plots, 
    funnel plots, and many of their variants, such as rainforest plots, thick forest plots, 
    additional evidence contour funnel plots, and sunset funnel plots. In addition, functionalities 
    for visual inference with the funnel plot in the context of meta-analysis are provided.",2020-04-09,Michael Kossmeier,https://github.com/Mkossmeier/metaviz,TRUE,https://github.com/mkossmeier/metaviz,15913,5,2020-04-07T17:42:00Z,3182.6
metawho,"A tool for implementing so called 'deft' approach
    (see Fisher, David J., et al. (2017) <DOI:10.1136/bmj.j573>) and model
    visualization.",2019-12-06,Shixiang Wang,https://github.com/ShixiangWang/metawho,TRUE,https://github.com/shixiangwang/metawho,4247,3,2019-12-06T14:56:53Z,1415.6666666666667
meteor,"A set of functions for weather and climate data manipulation, and other helper functions, to support dynamic ecological modelling, particularly crop and crop disease modeling.",2019-08-08,Robert J. Hijmans,NA,TRUE,https://github.com/cropmodels/meteor,3491,1,2020-02-19T04:59:14Z,3491
meteorits,"Provides a unified mixture-of-experts (ME) modeling and 
    estimation framework with several original and flexible ME models to 
    model, cluster and classify heterogeneous data in many complex 
    situations where the data are distributed according to non-normal, 
    possibly skewed distributions, and when they might be corrupted by 
    atypical observations. Mixtures-of-Experts models for complex and 
    non-normal distributions ('meteorits') are originally introduced and 
    written in 'Matlab' by Faicel Chamroukhi. The references are mainly the 
    following ones. The references are mainly the following ones.
    Chamroukhi F., Same A., Govaert, G. and Aknin P. (2009) <doi:10.1016/j.neunet.2009.06.040>.
    Chamroukhi F. (2010) <https://chamroukhi.com/FChamroukhi-PhD.pdf>.
    Chamroukhi F. (2015) <arXiv:1506.06707>.
    Chamroukhi F. (2015) <https://chamroukhi.com/FChamroukhi-HDR.pdf>.
    Chamroukhi F. (2016) <doi:10.1109/IJCNN.2016.7727580>.
    Chamroukhi F. (2016) <doi:10.1016/j.neunet.2016.03.002>.
    Chamroukhi F. (2017) <doi:10.1016/j.neucom.2017.05.044>.",2020-01-10,Faicel Chamroukhi,https://github.com/fchamroukhi/MEteorits,TRUE,https://github.com/fchamroukhi/meteorits,3092,0,2020-02-13T14:30:19Z,NA
MethComp,"Methods (standard and advanced) for analysis of agreement between measurement methods. These cover Bland-Altman plots, Deming regression, Lin's Total deviation index, and difference-on-average regression. See Carstensen B. (2010) ""Comparing Clinical Measurement Methods: A Practical Guide (Statistics in Practice)"" <doi:10.1002/9780470683019> for more information.",2020-01-19,Claus Thorn Ekstrøm,http://BendixCarstensen.com/MethComp/,TRUE,https://github.com/ekstroem/methcomp,19128,0,2020-01-20T14:47:29Z,NA
methcon5,"Identify and rank CpG DNA methylation conservation along the human 
    genome. Specifically it includes bootstrapping methods to provide ranking 
    which should adjust for the differences in length as without it short 
    regions tend to get higher conservation scores.",2019-12-20,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/methcon5,TRUE,https://github.com/emilhvitfeldt/methcon5,2465,0,2019-12-20T18:57:46Z,NA
metR,"Many useful functions and extensions for dealing
    with meteorological data in the tidy data framework. Extends 'ggplot2'
    for better plotting of scalar and vector fields and provides commonly
    used analysis methods in the atmospheric sciences.",2020-04-10,Elio Campitelli,https://github.com/eliocamp/metR,TRUE,https://github.com/eliocamp/metr,15036,80,2020-04-10T15:27:08Z,187.95
MetricsWeighted,"Provides weighted versions of several metrics,
    scoring functions and performance measures used in machine learning,
    including average unit deviances of the Bernoulli, Tweedie, Poisson,
    and Gamma distributions, see Jorgensen B. (1997, ISBN:
    978-0412997112). The package also contains a weighted version of
    generalized R-squared, see e.g. Cohen, J. et al. (2002, ISBN:
    978-0805822236). Furthermore, 'dplyr' chains are supported.",2020-04-18,Michael Mayer,https://github.com/mayer79/MetricsWeighted,TRUE,https://github.com/mayer79/metricsweighted,5731,4,2020-04-18T13:57:44Z,1432.75
mets,"Implementation of various statistical models for multivariate
    event history data <doi:10.1007/s10985-013-9244-x>. Including multivariate
    cumulative incidence models <doi:10.1002/sim.6016>, and  bivariate random
    effects probit models (Liability models) <doi:10.1016/j.csda.2015.01.014>.
    Also contains two-stage binomial modelling that can do pairwise odds-ratio
    dependence modelling based marginal logistic regression models. This is an
    alternative to the alternating logistic regression approach (ALR).",2020-03-04,Klaus K. Holst and Thomas Scheike,https://github.com/kkholst/mets,TRUE,https://github.com/kkholst/mets,118076,4,2020-06-05T07:55:14Z,29519
mev,"Various tools for the analysis of univariate, multivariate and functional extremes. Exact simulation from max-stable processes [Dombry, Engelke and Oesting (2016) <doi:10.1093/biomet/asw008>, R-Pareto processes for various parametric models, including Brown-Resnick (Wadsworth and Tawn, 2014, <doi:10.1093/biomet/ast042>) and Extremal Student (Thibaud and Opitz, 2015, <doi:10.1093/biomet/asv045>). Threshold selection methods, including Wadsworth (2016) <doi:10.1080/00401706.2014.998345>, and Northrop and Coleman (2014) <doi:10.1007/s10687-014-0183-z>. Multivariate extreme diagnostics. Estimation and likelihoods for univariate extremes, e.g., Coles (2001) <doi:10.1007/978-1-4471-3675-0>.",2020-01-27,Leo Belzile,https://github.com/lbelzile/mev/,TRUE,https://github.com/lbelzile/mev,44419,0,2020-06-04T17:49:43Z,NA
mfbvar,Estimation of mixed-frequency Bayesian vector autoregressive (VAR) models. The package implements a state space-based VAR model that handles mixed frequencies of the data. The model is estimated using Markov Chain Monte Carlo to numerically approximate the posterior distribution. Prior distributions that can be used include normal-inverse Wishart and normal-diffuse priors as well as steady-state priors. Stochastic volatility can be handled by common or factor stochastic volatility models.,2020-05-28,Sebastian Ankargren,https://github.com/ankargren/mfbvar,TRUE,https://github.com/ankargren/mfbvar,6431,14,2020-05-05T19:55:43Z,459.35714285714283
mfe,"Extracts meta-features from datasets to support the design of 
  recommendation systems based on Meta-Learning. The meta-features, also called 
  characterization measures, are able to characterize the complexity of datasets
  and to provide estimates of algorithm performance. The package contains not 
  only the standard characterization measures, but also more recent 
  characterization measures. By making available a large set of meta-feature 
  extraction functions, tasks like comprehensive data characterization, deep 
  data exploration and large number of Meta-Learning based data analysis can be
  performed. These concepts are described in the paper: Rivolli A., Garcia L., 
  Soares c., Vanschoren J. and Carvalho A. (2018) <arXiv:1808.10406>.",2020-05-05,Adriano Rivolli,https://github.com/rivolli/mfe,TRUE,https://github.com/rivolli/mfe,11332,20,2020-05-04T18:54:27Z,566.6
mfGARCH,"Estimating GARCH-MIDAS (MIxed-DAta-Sampling) models (Engle, Ghysels, Sohn, 2013, <doi:10.1162/REST_a_00300>) and related statistical inference, accompanying the paper ""Two are better than one: Volatility forecasting using multiplicative component GARCH models"" by Conrad and Kleen (2020, <doi:10.1002/jae.2742>). The GARCH-MIDAS model decomposes the conditional variance of (daily) stock returns into a short- and long-term component, where the latter may depend on an exogenous covariate sampled at a lower frequency. ",2020-05-12,Onno Kleen,https://github.com/onnokleen/mfGARCH/,TRUE,https://github.com/onnokleen/mfgarch,10165,19,2020-05-12T16:07:44Z,535
mFLICA,"A leadership-inference framework for multivariate time series. The framework for multiple-faction-leadership inference from coordinated activities or 'mFLICA' uses a notion of a leader as an individual who initiates collective patterns that everyone in a group follows. Given a set of time series of individual activities, our goal is to identify periods of coordinated activity, find factions of coordination if more than one exist, as well as identify leaders of each faction. For each time step, the framework infers following relations between individual time series, then identifying a leader of each faction whom many individuals follow but it follows no one. A faction is defined as a group of individuals that everyone follows the same leader. 'mFLICA' reports following relations, leaders of factions, and members of each faction for each time step. Please see Chainarong Amornbunchornvej and Tanya Berger-Wolf (2018) <doi:10.1137/1.9781611975321.62> when referring to this package in publications.",2020-04-03,Chainarong Amornbunchornvej,https://github.com/DarkEyes/mFLICA,TRUE,https://github.com/darkeyes/mflica,1927,0,2020-04-14T01:49:31Z,NA
MFPCA,"Calculate a multivariate functional principal component analysis
    for data observed on different dimensional domains. The estimation algorithm
    relies on univariate basis expansions for each element of the multivariate
    functional data  (Happ & Greven, 2018) <doi:10.1080/01621459.2016.1273115>. 
    Multivariate and univariate functional data objects are
    represented by S4 classes for this type of data implemented in the package
    'funData'. For more details on the general concepts of both packages and a case 
    study, see Happ-Kurz (2020) <doi:10.18637/jss.v093.i05>.",2020-04-25,Clara Happ-Kurz,https://github.com/ClaraHapp/MFPCA,TRUE,https://github.com/clarahapp/mfpca,15509,12,2020-04-25T11:24:24Z,1292.4166666666667
mgcViz,"Extension of the 'mgcv' package, providing visual tools for Generalized Additive Models that exploit the additive structure of such models, scale to large data sets and can be used in conjunction with a wide range of response distributions. The focus is providing visual methods for better understanding the model output and for aiding model checking and development beyond simple exponential family regression. The graphical framework is based on the layering system provided by 'ggplot2'.",2020-03-04,Matteo Fasiolo,https://github.com/mfasiolo/mgcViz,TRUE,https://github.com/mfasiolo/mgcviz,18138,62,2020-05-25T13:31:44Z,292.5483870967742
MGDrivE,"Provides a model designed to be a reliable testbed where various gene 
    drive interventions for mosquito-borne diseases control. It is being developed to 
    accommodate the use of various mosquito-specific gene drive systems within a 
    population dynamics framework that allows migration of individuals between patches 
    in landscape. Previous work developing the population dynamics can be found in Deredec et al. 
    (2001) <doi:10.1073/pnas.1110717108> and Hancock & Godfray (2007) <doi:10.1186/1475-2875-6-98>, 
    and extensions to accommodate basic CRISPR homing dynamics in Marshall et al. (2017) 
    <doi:10.1038/s41598-017-02744-7>.",2020-01-29,Héctor Manuel Sánchez Castellanos,"https://marshalllab.github.io/MGDrivE/,
https://www.marshalllab.com/",TRUE,https://github.com/marshalllab/mgdrive,4111,1,2020-01-24T20:17:30Z,4111
mgm,Estimation of k-Order time-varying Mixed Graphical Models and mixed VAR(p) models via elastic-net regularized neighborhood regression. For details see Haslbeck & Waldorp (2020) <doi:10.18637/jss.v093.i08>.,2020-04-20,Jonas Haslbeck,https://arxiv.org/abs/1510.06871,TRUE,https://github.com/jmbh/mgm,43637,20,2020-04-25T07:14:47Z,2181.85
mHMMbayes,"An implementation of the multilevel (also known as mixed or random 
    effects) hidden Markov model using Bayesian estimation in R. The multilevel 
    hidden Markov model (HMM) is a generalization of the well-known hidden
    Markov model, for the latter see Rabiner (1989) <doi:10.1109/5.18626>. The 
    multilevel HMM is tailored to accommodate (intense) longitudinal data of 
    multiple individuals simultaneously, see e.g., de Haan-Rietdijk et al. 
    <doi:10.1080/00273171.2017.1370364>. Using a multilevel framework, we allow 
    for heterogeneity in the model parameters (transition probability matrix and 
    conditional distribution), while estimating one overall HMM. The model can 
    be fitted on multivariate data with a categorical distribution, and include 
    individual level covariates (allowing for e.g., group comparisons on model 
    parameters). Parameters are estimated using Bayesian estimation utilizing 
    the forward-backward recursion within a hybrid Metropolis within Gibbs 
    sampler. The package also includes various visualization options, a function 
    to simulate data, and a function to obtain the most likely hidden state 
    sequence for each individual using the Viterbi algorithm.",2019-10-30,Emmeke Aarts,https://github.com/emmekeaarts/mHMMbayes,TRUE,https://github.com/emmekeaarts/mhmmbayes,2836,2,2019-11-12T15:26:32Z,1418
mhsmm,"Parameter estimation and prediction for hidden Markov and semi-Markov models for data with multiple observation sequences.  Suitable for equidistant time series data, with multivariate and/or missing data. Allows user defined emission distributions.",2017-01-15,Jared OConnell,https://github.com/jaredo/mhsmm,TRUE,https://github.com/jaredo/mhsmm,36252,7,2019-12-02T04:54:00Z,5178.857142857143
MHTdiscrete,"A comprehensive tool for almost all existing multiple testing
    methods for discrete data. The package also provides some novel multiple testing
    procedures controlling FWER/FDR for discrete data. Given discrete p-values
    and their domains, the [method].p.adjust function returns adjusted p-values,
    which can be used to compare with the nominal significant level alpha and make
    decisions. For users' convenience, the functions also provide the output option 
    for printing decision rules.",2018-12-15,Yalin Zhu,https://allen.shinyapps.io/MTPs/,TRUE,https://github.com/allenzhuaz/mhtdiscrete,14025,0,2019-07-09T19:10:25Z,NA
MIAmaxent,"Tools for training, selecting, and evaluating maximum entropy
    (and standard logistic regression) distribution models. This package 
    provides tools for user-controlled transformation of explanatory variables, 
    selection of variables by nested model comparison, and flexible model 
    evaluation and projection. It follows principles based on the maximum-
    likelihood interpretation of maximum entropy modeling, and uses infinitely-
    weighted logistic regression for model fitting.",2020-04-14,Julien Vollering,https://github.com/julienvollering/MIAmaxent,TRUE,https://github.com/julienvollering/miamaxent,13744,10,2020-05-12T12:19:40Z,1374.4
mice,"Multiple imputation using Fully Conditional Specification (FCS)
    implemented by the MICE algorithm as described in Van Buuren and
    Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>. Each variable has
    its own imputation model. Built-in imputation models are provided for
    continuous data (predictive mean matching, normal), binary data (logistic
    regression), unordered categorical data (polytomous logistic regression)
    and ordered categorical data (proportional odds). MICE can also impute
    continuous two-level data (normal model, pan, second-level variables).
    Passive imputation can be used to maintain consistency between variables.
    Various diagnostic plots are available to inspect the quality of the
    imputations.",2020-05-14,Stef van Buuren,"https://github.com/stefvanbuuren/mice,
https://stefvanbuuren.name/mice/,
https://stefvanbuuren.name/fimd/",TRUE,https://github.com/stefvanbuuren/mice,1953301,154,2020-06-04T19:32:39Z,12683.772727272728
miceadds,"
    Contains functions for multiple imputation which
    complements existing functionality in R.
    In particular, several imputation methods for the
    mice package (van Buuren & Groothuis-Oudshoorn, 2011,
    <doi:10.18637/jss.v045.i03>) are included.
    Main features of the miceadds package include
    plausible value imputation (Mislevy, 1991,
    <doi:10.1007/BF02294457>), multilevel imputation for
    variables at any level or with any number of hierarchical
    and non-hierarchical levels (Grund, Luedtke & Robitzsch,
    2018, <doi:10.1177/1094428117703686>; van Buuren, 2018, 
    Ch.7, <doi:10.1201/9780429492259>), imputation using 
    partial least squares (PLS) for high dimensional 
    predictors (Robitzsch, Pham & Yanagida, 2016), 
    nested multiple imputation (Rubin, 2003, 
    <doi:10.1111/1467-9574.00217>) and substantive model
    compatible imputation (Bartlett et al., 2015,
    <doi:10.1177/0962280214521348>).",2020-05-09,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/miceadds,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/miceadds,440511,10,2020-05-12T11:29:29Z,44051.1
miceFast,"
  Fast imputations under the object-oriented programming paradigm.
	There was used quantitative models with a closed-form solution. Thus package is based on linear algebra operations.
	The biggest improvement in time performance could be achieve for a calculation where a grouping variable have to be used.
	A single evaluation of a quantitative model for the multiple imputations is another major enhancement.
	Moreover there are offered a few functions built to work with popular R packages such as 'data.table' or 'dplyr'.",2019-08-19,Maciej Nasinski,https://github.com/Polkas/miceFast,TRUE,https://github.com/polkas/micefast,8643,6,2020-06-09T18:49:22Z,1440.5
miceRanger,"Multiple Imputation has been shown to 
  be a flexible method to impute missing values by 
  Van Buuren (2007) <doi:10.1177/0962280206074463>. 
  Expanding on this, random forests have been shown 
  to be an accurate model by Stekhoven and Buhlmann 
  <arXiv:1105.0828> to impute missing values in datasets. 
  They have the added benefits of returning out of bag 
  error and variable importance estimates, as well as 
  being simple to run in parallel.",2020-04-03,Sam Wilson,https://github.com/FarrellDay/miceRanger,TRUE,https://github.com/farrellday/miceranger,3218,25,2020-04-03T15:40:41Z,128.72
microbenchmark,"Provides infrastructure to accurately measure and compare
        the execution time of R expressions.",2019-09-24,Joshua M. Ulrich,https://github.com/joshuaulrich/microbenchmark/,TRUE,https://github.com/joshuaulrich/microbenchmark,933801,46,2020-05-28T21:58:28Z,20300.021739130436
microdemic,"The 'Microsoft Academic Knowledge' API provides programmatic access
	to scholarly articles in the 'Microsoft Academic Graph'
	(<https://academic.microsoft.com/>). Includes methods matching all 'Microsoft
	Academic' API routes, including search, graph search, text similarity, and
	interpret natural language query string.",2020-01-27,Scott Chamberlain,"https://github.com/ropensci/microdemic (devel),
https://docs.ropensci.org/microdemic (website)",TRUE,https://github.com/ropensci/microdemic,20121,12,2020-01-28T16:14:14Z,1676.75
microhaplot,"A downstream bioinformatics tool to construct and assist 
    curation of microhaplotypes from short read sequences.",2019-10-03,Thomas Ng,https://github.com/ngthomas/microhaplot,TRUE,https://github.com/ngthomas/microhaplot,3091,8,2019-09-28T00:52:49Z,386.375
MIDASwrappeR,"This is a wrapper around the C++ implementation of 'MIDAS' (Bhatia et al., 2020) <https://www.comp.nus.edu.sg/~sbhatia/assets/pdf/midas.pdf> by Siddharth Bhatia for graph like data.",2020-04-10,Tobias Heidler,https://github.com/pteridin/MIDASwrappeR,TRUE,https://github.com/pteridin/midaswrapper,877,7,2020-04-09T10:35:36Z,125.28571428571429
migest,"Indirect methods for estimating bilateral migration flows in the presence of partial or missing data, including the estimation of bilateral migration flows from changes in bilateral migrant stock tables (e.g. Abel (2013) <doi:10.4054/DemRes.2013.28.18>).",2019-10-05,Guy J. Abel,https://github.com/gjabel/migest/,TRUE,https://github.com/gjabel/migest,30803,13,2020-04-10T07:45:53Z,2369.4615384615386
migrbc,"Provides mechanisms for classifying border crossings using a rules-based methodology. The goal of performing this type of classification is to identify any potential long-term migrants.  A long-term migration is defined as a border crossing involving a change in residence status. A border crossing counts as a long-term migration to/from a country if it entails a change from non-residence to residence / residence to non-residence.  The rules-based classification that used to determine a long-term migration is defined by a threshold duration and a test duration, alternatively named window size. Under a 12/16 rule, for instance, the threshold duration is 12 months and the test duration (window size) is 16 months. With a 9/12 rule, the threshold duration is 9 months and the test duration (window size)  is 12 months. For more information about the methodology applied, please visit Stats NZ (2020) <https://www.stats.govt.nz/methods/defining-migrants-using-travel-histories-and-the-1216-month-rule>.",2020-05-15,Leshi Chen,"https://github.com/statisticsnz/migrbc,
https://statisticsnz.github.io/migrbc",TRUE,https://github.com/statisticsnz/migrbc,478,2,2020-05-17T21:29:27Z,239
mime,"Guesses the MIME type from a filename extension using the data
    derived from /etc/mime.types in UNIX-type systems.",2020-02-04,Yihui Xie,https://github.com/yihui/mime,TRUE,https://github.com/yihui/mime,18873306,21,2020-02-04T18:21:00Z,898728.8571428572
mimsy,"Calculate dissolved gas concentrations from raw MIMS 
	(Membrane Inlet Mass Spectrometer) signal data. Use mimsy() on 
	a formatted CSV file to return dissolved gas concentrations 
	(mg and microMole) of N2, O2, Ar based on 
	gas solubility at temperature, pressure, and salinity. See references 
	Benson and Krause (1984) <DOI:10.4319/lo.1992.37.6.1307>, Garcia and 
	Gordon (1992) <DOI:10.4319/lo.1984.29.3.0620>, Stull (1947) 
	<DOI:10.1021/ie50448a022>, and Hamme and Emerson (2004) 
	<DOI:10.1016/j.dsr.2004.06.009> for more information. Easily save the 
	output to a nicely-formatted multi-tab 'Excel' workbook with mimsy.save(). 
	Supports dual-temperature standard calibration for dual-bath MIMS setups.",2020-05-13,Michelle Catherine Kelly,"https://github.com/michelleckelly/mimsy,
https://michelleckelly.github.io/mimsy/",TRUE,https://github.com/michelleckelly/mimsy,5392,0,2020-06-09T18:09:53Z,NA
mindicador,"Importa datos de la API de <https://mindicador.cl> en formato de cuadro de datos o serie de tiempo.
    El objetivo es facilitar el uso de algunos datos economicos a periodistas y profesionales que requieren
    informacion desplegada de forma clara y concisa.
    (Imports data from <https://mindicador.cl> API in data frame or time series format. The goal
    is to ease using certain economic data with different R packages, having in mind journalists and professionals
    that require information displayed in a clear and concise way.)",2020-06-02,Mauricio Vargas,https://github.com/pachamaltese/mindicador,TRUE,https://github.com/pachamaltese/mindicador,0,0,2020-06-02T16:34:26Z,NA
mindr,"Convert Markdown ('.md') or R markdown ('.Rmd') files into mind map widgets or files ('.mm'), and vice versa. ""FreeMind"" mind map ('.mm') files can be opened by or imported to common mindmap software such as 'FreeMind' (<http://freemind.sourceforge.net/wiki/index.php/Main_Page>) and 'XMind' (<http://www.xmind.net>).",2020-02-29,Peng Zhao,https://github.com/pzhaonet/mindr,TRUE,https://github.com/pzhaonet/mindr,16233,483,2019-12-31T15:32:04Z,33.608695652173914
miniCRAN,"Makes it possible to create an internally consistent
    repository consisting of selected packages from CRAN-like repositories.
    The user specifies a set of desired packages, and 'miniCRAN' recursively
    reads the dependency tree for these packages, then downloads only this
    subset. The user can then install packages from this repository directly,
    rather than from CRAN.  This is useful in production settings, e.g. server
    behind a firewall, or remote locations with slow (or zero) Internet access.",2019-07-06,Andrie de Vries,https://github.com/andrie/miniCRAN,TRUE,https://github.com/andrie/minicran,99678,108,2019-12-18T16:02:25Z,922.9444444444445
minidown,"Create minimal, responsive, and style-agnostic HTML documents with
    the lightweight CSS frameworks such as 'sakura', 'Water.css', and 'mini.css'.
    Powerful features include floating table of contents as a sidebar,
    code folding of source, output, message, warning, and error, and accordion
    menus. They work without JavaScript.",2020-05-04,Atsushi Yasumoto,"https://minidown.atusy.net, https://github.com/atusy/minidown",TRUE,https://github.com/atusy/minidown,552,25,2020-06-07T22:51:21Z,22.08
mipfp,"An implementation of the iterative proportional fitting (IPFP), 
    maximum likelihood, minimum chi-square and weighted least squares procedures
    for updating a N-dimensional array with respect to given target marginal 
    distributions (which, in turn can be multidimensional). The package also
    provides an application of the IPFP to simulate multivariate Bernoulli
    distributions.",2018-08-29,Johan Barthelemy,https://github.com/jojo-/mipfp,TRUE,https://github.com/jojo-/mipfp,33800,10,2019-09-04T01:56:24Z,3380
mipred,"Calibration of generalized linear models and Cox regression models for prediction using 
    multiple imputation to account for missing values in the predictors as described in the paper by 
    ""Mertens, Banzato and de Wreede"" (2018) <arXiv:1810.05099>. The methodology and calculations 
    described in this paper are fully implemented in this package. The vignette describes all data analytic steps 
    which allow users to replicate results using the package functions on the data analyzed in the paper or 
    on their own data. 
    Imputations are generated using the package 'mice' without using the outcomes of observations for which the
    predictions are generated. Two options are provided to generate predictions. The first is prediction-averaging of 
    predictions calibrated from single models fitted on single imputed 
    datasets within a set of multiple imputations. The second is application of the Rubin's rules pooled model.
    For both implementations, unobserved values in the predictor data of new observations for 
    which the predictions are derived are automatically imputed. The package contains two basic functions.  
    The first, mipred() generates predictions of outcome on new observations. The second, mipred.cv() generates 
    cross-validated predictions with the methodology on existing data for which outcomes
    have already been observed. The present version is still in development and should support continuous, 
    binary and counting outcomes, but we have only thoroughly checked performance for binary outcome 
    logistic regression modeling. We will include the Cox regression extension later.",2019-07-12,Bart J. A. Mertens,"https://github.com/BartJAMertens/mipred,
https://arxiv.org/abs/1810.05099,
https://www.researchgate.net/project/Prediction-calibration-using-multiple-imputations-to-account-for-missing-predictor-values",TRUE,https://github.com/bartjamertens/mipred,3534,3,2019-09-04T16:29:09Z,1178
mirt,"Analysis of dichotomous and polytomous response data using
    unidimensional and multidimensional latent trait models under the Item
    Response Theory paradigm (Chalmers (2012) <doi:10.18637/jss.v048.i06>). 
    Exploratory and confirmatory models can be estimated with quadrature (EM) 
    or stochastic (MHRM) methods. Confirmatory
    bi-factor and two-tier analyses are available for modeling item testlets.
    Multiple group analysis and mixed effects designs also are available for
    detecting differential item and test functioning as well as modeling
    item and person covariates. Finally, latent class models such as the DINA,
    DINO, multidimensional latent class, and several other discrete latent
    variable models, including mixture and zero-inflated response models, 
    are supported.",2020-04-25,Phil Chalmers,"https://github.com/philchalmers/mirt,
https://github.com/philchalmers/mirt/wiki,
https://groups.google.com/forum/#!forum/mirt-package",TRUE,https://github.com/philchalmers/mirt,254514,115,2020-06-08T19:17:31Z,2213.1652173913044
mirtCAT,"Provides tools to generate an HTML interface for creating adaptive
    and non-adaptive educational and psychological tests using the shiny
    package (Chalmers (2016) <doi:10.18637/jss.v071.i05>). 
    Suitable for applying unidimensional and multidimensional
    computerized adaptive tests (CAT) using item response theory methodology and for
    creating simple questionnaires forms to collect response data directly in R.
    Additionally, optimal test designs (e.g., ""shadow testing"") are supported
    for tests which contain a large number of item selection constraints.
    Finally, package contains tools useful for performing Monte Carlo simulations 
    for studying the behavior of computerized adaptive test banks.",2019-06-28,Phil Chalmers,"https://github.com/philchalmers/mirtCAT,
https://github.com/philchalmers/mirtCAT/wiki,
https://groups.google.com/forum/#!forum/mirt-package",TRUE,https://github.com/philchalmers/mirtcat,85830,51,2020-05-07T19:22:42Z,1682.9411764705883
mirtjml,"Provides constrained joint maximum likelihood estimation
    algorithms for item factor analysis (IFA) based on multidimensional item response theory
    models. So far, we provide functions for exploratory and confirmatory IFA based on the 
    multidimensional two parameter logistic (M2PL) model for binary response data. Comparing 
    with traditional estimation methods for IFA, the methods implemented in this package scale
    better to data with large numbers of respondents, items, and latent factors. The computation
    is facilitated by multiprocessing 'OpenMP' API. For more information, please refer to:
    1. Chen, Y., Li, X., & Zhang, S. (2018). Joint Maximum Likelihood Estimation for 
    High-Dimensional Exploratory Item Factor Analysis. Psychometrika, 1-23. 
    <doi:10.1007/s11336-018-9646-5>;
    2. Chen, Y., Li, X., & Zhang, S. (2019). Structured Latent Factor Analysis for Large-scale Data: 
    Identifiability, Estimability, and Their Implications. Journal of the American Statistical 
    Association, <doi: 10.1080/01621459.2019.1635485>.",2020-06-08,Siliang Zhang,https://github.com/slzhang-fd/mirtjml,TRUE,https://github.com/slzhang-fd/mirtjml,5738,1,2020-06-02T21:56:16Z,5738
missCompare,"Offers a convenient pipeline to test and compare various missing data
  imputation algorithms on simulated and real data. The central assumption behind missCompare is that structurally
  different datasets (e.g. larger datasets with a large number of correlated variables vs. smaller datasets
  with non correlated variables) will benefit differently from different missing data imputation algorithms.
  missCompare takes measurements of your dataset and sets up a sandbox to try a curated list of standard and 
  sophisticated missing data imputation algorithms and compares them assuming custom missingness patterns.
  missCompare will also impute your real-life dataset for you after the selection of the best performing algorithm
  in the simulations. The package also provides various post-imputation diagnostics and visualizations to help you 
  assess imputation performance.    ",2019-02-05,Tibor V. Varga,NA,TRUE,https://github.com/tirgit/misscompare,5285,12,2020-05-13T15:01:52Z,440.4166666666667
missForest,"The function 'missForest' in this package is used to
        impute missing values particularly in the case of mixed-type
        data. It uses a random forest trained on the observed values of
        a data matrix to predict the missing values. It can be used to
        impute continuous and/or categorical data including complex
        interactions and non-linear relations. It yields an out-of-bag
        (OOB) imputation error estimate without the need of a test set
        or elaborate cross-validation. It can be run in parallel to 
        save computation time.",2013-12-31,Daniel J. Stekhoven,"http://www.r-project.org, https://github.com/stekhoven/missForest",TRUE,https://github.com/stekhoven/missforest,270573,43,2019-08-27T09:10:44Z,6292.395348837209
missMethods,"Supply functions for the creation and handling of missing data 
    as well as tools to evaluate missing data methods. Nearly all possibilities
    of generating missing data discussed by Santos et. al (2019) 
    <doi:10.1109/ACCESS.2019.2891360> and some additional are implemented. 
    Functions are supplied to compare parameter estimates and imputed values to 
    true values to evaluate missing data methods. Evaluations of these types 
    are done, for example, by Cetin-Berber et al. (2019) 
    <doi:10.1177/0013164418805532>  and Kim et al. (2005) 
    <doi:10.1093/bioinformatics/bth499>.",2020-04-01,Tobias Rockel,https://github.com/torockel/missMethods,TRUE,https://github.com/torockel/missmethods,1048,0,2020-04-03T15:01:29Z,NA
missSBM,"When a network is partially observed (here, NAs in the adjacency matrix rather than 1 or 0 
  due to missing information between node pairs), it is possible to account for the underlying process
  that generates those NAs. 'missSBM' adjusts the popular stochastic block model from network data 
  sampled under various missing data conditions, as described in Tabouy, Barbillon and Chiquet (2019) <doi:10.1080/01621459.2018.1562934>.",2019-09-16,Julien Chiquet,https://jchiquet.github.io/missSBM,TRUE,https://github.com/jchiquet/misssbm,3417,5,2019-09-17T20:01:32Z,683.4
MittagLeffleR,"Implements the Mittag-Leffler function, distribution,
  random variate generation, and estimation. Based on the Laplace-Inversion
  algorithm by Garrappa, R. (2015) <doi:10.1137/140971191>.",2018-04-25,Peter Straka,https://strakaps.github.io/MittagLeffleR/,TRUE,https://github.com/strakaps/mittagleffler,12214,3,2020-05-10T09:04:02Z,4071.3333333333335
miWQS,"The `miWQS` package handles the uncertainty due to below the detection limit in a correlated component mixture problem.  Researchers want to determine if a set/mixture of continuous and correlated components/chemicals is associated with an outcome and if so, which components are important in that mixture. These components share a common outcome but are interval-censored between zero and low thresholds, or detection limits, that may be different across the components. The `miWQS` package applies the multiple imputation (MI) procedure to the weighted quantile sum regression (WQS) methodology for continuous, binary, or count outcomes.  The imputation models are: bootstrapping imputation (Lubin et.al (2004) <doi:10.1289/ehp.7199>) and Bayesian imputation.  ",2019-12-12,Paul M. Hargarten,NA,TRUE,https://github.com/phargarten2/miwqs,7119,1,2019-06-28T21:26:00Z,7119
mixchar,"Deconvolution of thermal decay curves allows you to quantify proportions 
    of biomass components in plant litter. Thermal decay curves derived from 
    thermogravimetric analysis (TGA) are imported, modified, and then modelled in a 
    three- or four- part  mixture model using the Fraser-Suzuki function. The output 
    is estimates for weights of pseudo-components corresponding to hemicellulose, 
    cellulose, and lignin. For more information see: Müller-Hagedorn, M. and Bockhorn, 
    H. (2007) <doi:10.1016/j.jaap.2006.12.008>, Órfão, J. J. M. and Figueiredo, J. L. 
    (2001) <doi:10.1016/S0040-6031(01)00634-7>, and Yang, H. and Yan, R. and 
    Chen, H. and Zheng, C. and Lee, D. H. and Liang, D. T. (2006) <doi:10.1021/ef0580117>.",2018-08-16,Saras Windecker,http://github.com/smwindecker/mixchar,TRUE,https://github.com/smwindecker/mixchar,6181,6,2019-07-04T06:33:27Z,1030.1666666666667
mixdir,"Scalable Bayesian clustering of categorical datasets. The package implements a hierarchical Dirichlet 
    (Process) mixture  of multinomial distributions. It is thus a probabilistic latent class model (LCM) and can be used
    to reduce the  dimensionality of hierarchical data and cluster individuals into latent classes. It can automatically
    infer an appropriate number of latent classes or find k classes, as defined by the user.  The model is based on a
    paper by Dunson and Xing (2009) <doi:10.1198/jasa.2009.tm08439>, but implements a scalable variational inference algorithm so that it is
    applicable to large datasets. It is described and tested in the accompanying paper by 
    Ahlmann-Eltze and Yau (2018) <doi:10.1109/DSAA.2018.00068>.",2019-09-20,Constantin Ahlmann-Eltze,https://github.com/const-ae/mixdir,TRUE,https://github.com/const-ae/mixdir,7176,8,2019-09-20T14:50:53Z,897
MixedPsy,"Tools for the analysis of psychophysical data. This package allows to estimate the Point of Subjective Equivalence (PSE) 
    and the Just Noticeable Difference (JND), either from a psychometric function or from a Generalized Linear Mixed Model (GLMM). 
    Additionally, the package allows plotting the fitted models and the response data, simulating psychometric functions of different shapes, and simulating data sets.
    For a description of the use of GLMMs applied to psychophysical data, refer to Moscatelli et al. (2012), <doi:10.1167/12.11.26>.",2017-11-16,Alessandro Moscatelli,https://mixedpsychophysics.wordpress.com,TRUE,https://github.com/moskante/mixedpsy,8363,0,2020-05-18T17:42:36Z,NA
mixggm,"Mixtures of Gaussian graphical models for model-based clustering with sparse covariance and concentration matrices. See Fop, Murphy, and Scrucca (2018) <doi:10.1007/s11222-018-9838-y>.",2018-11-14,Michael Fop,https://github.com/michaelfop/mixggm,TRUE,https://github.com/michaelfop/mixggm,5656,1,2019-07-25T15:33:54Z,5656
MixMatrix,"Provides sampling and density functions for matrix
    variate normal, t, and inverted t distributions;  ML estimation for matrix
    variate normal and t distributions using the EM algorithm,
    including some restrictions on the parameters; and classification by linear and
    quadratic discriminant analysis for matrix variate normal and t
    distributions described in Thompson et al. (2019) <arXiv:1907.09565>.
    Performs clustering with matrix variate normal and t mixture models.",2019-11-14,Geoffrey Thompson,"http://github.com/gzt/MixMatrix/, https://gzt.github.io/MixMatrix/",TRUE,https://github.com/gzt/mixmatrix,3853,0,2020-04-07T06:05:25Z,NA
mixmeta,"A collection of functions to perform various meta-analytical models
  through a unified mixed-effects framework, including standard univariate
  fixed and random-effects meta-analysis and meta-regression, and non-standard
  extensions such as multivariate, multilevel, longitudinal, and dose-response
  models.",2020-03-09,Antonio Gasparrini,"https://github.com/gasparrini/mixmeta,
http://www.ag-myresearch.com/package-mixmeta",TRUE,https://github.com/gasparrini/mixmeta,12082,1,2020-05-27T15:17:35Z,12082
MixSIAR,"Creates and runs Bayesian mixing models to analyze
    biological tracer data (i.e. stable isotopes, fatty acids), which estimate the
    proportions of source (prey) contributions to a mixture (consumer). 'MixSIAR'
    is not one model, but a framework that allows a user to create a mixing model
    based on their data structure and research questions, via options for fixed/
    random effects, source data types, priors, and error terms. 'MixSIAR' incorporates
    several years of advances since 'MixSIR' and 'SIAR'.",2020-05-13,Brian Stock,https://github.com/brianstock/MixSIAR,TRUE,https://github.com/brianstock/mixsiar,20620,36,2020-05-14T00:34:51Z,572.7777777777778
mixsqp,"Provides an optimization method based on sequential
    quadratic programming (SQP) for maximum likelihood estimation of
    the mixture proportions in a finite mixture model where the
    component densities are known. The algorithm is expected to obtain
    solutions that are at least as accurate as the state-of-the-art
    MOSEK interior-point solver (called by function ""KWDual"" in the
    'REBayes' package), and they are expected to arrive at solutions
    more quickly when the number of samples is large and the number of
    mixture components is not too large. This implements the ""mix-SQP""
    algorithm, with some improvements, described in Y. Kim,
    P. Carbonetto, M. Stephens & M. Anitescu (2020)
    <DOI:10.1080/10618600.2019.1689985>.",2020-05-14,Peter Carbonetto,https://github.com/stephenslab/mixsqp,TRUE,https://github.com/stephenslab/mixsqp,21047,6,2020-05-14T12:22:25Z,3507.8333333333335
mize,"Optimization algorithms implemented in R, including
    conjugate gradient (CG), Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the
    limited memory BFGS (L-BFGS) methods. Most internal parameters can be set 
    through the call interface. The solvers hold up quite well for 
    higher-dimensional problems.",2019-12-05,James Melville,http://github.com/jlmelville/mize,TRUE,https://github.com/jlmelville/mize,14505,3,2020-06-02T17:28:10Z,4835
mizer,"A set of classes and methods to set up and run multi-species, trait
    based and community size spectrum ecological models, focused on the marine
    environment.",2020-06-08,Gustav Delius,"https://sizespectrum.org/mizer,
https://github.com/sizespectrum/mizer",TRUE,https://github.com/sizespectrum/mizer,18331,14,2020-06-08T16:43:32Z,1309.357142857143
mkin,"Calculation routines based on the FOCUS Kinetics Report (2006,
  2014).  Includes a function for conveniently defining differential equation
  models, model solution based on eigenvalues if possible or using numerical
  solvers.  If a C compiler (on windows: 'Rtools') is installed, differential
  equation models are solved using automatically generated C functions.  Please
  note that no warranty is implied for correctness of results or fitness for a
  particular purpose.",2020-05-12,Johannes Ranke,https://pkgdown.jrwb.de/mkin,TRUE,https://github.com/jranke/mkin,46831,6,2020-05-29T14:05:11Z,7805.166666666667
mknapsack,"Package solves multiple knapsack optimisation problem. 
    Given a set of items, each with volume and value, 
    it will allocate them to knapsacks of a given size in a way that
    value of top N knapsacks is as large as possible.",2018-04-10,Bulat Yapparov,https://github.com/madedotcom/mknapsack,TRUE,https://github.com/madedotcom/mknapsack,7669,0,2020-01-17T09:56:58Z,NA
mldr,"Exploratory data analysis and manipulation functions for multi-
    label data sets along with an interactive Shiny application to ease their use.",2019-12-19,David Charte,https://github.com/fcharte/mldr,TRUE,https://github.com/fcharte/mldr,63334,17,2019-12-10T17:34:17Z,3725.529411764706
mleap,"A 'sparklyr' <https://spark.rstudio.com> extension that provides
  an interface to 'MLeap' <https://github.com/combust/mleap>, an open source library
  that enables exporting and serving of 'Apache Spark' pipelines.",2020-01-10,Kevin Kuo,https://github.com/rstudio/mleap,TRUE,https://github.com/rstudio/mleap,11106,20,2020-01-11T06:25:28Z,555.3
MLML2R,"Maximum likelihood estimates (MLE) of the proportions
    of 5-mC and 5-hmC in the DNA using information from BS-conversion,
    TAB-conversion, and oxBS-conversion methods. One can use information from all three methods 
    or any combination of two of them. Estimates are based on Binomial model by
    Qu et al. (2013) <doi:10.1093/bioinformatics/btt459> and
    Kiihl et al. (2019) <doi:10.1515/sagmb-2018-0031>.",2019-10-17,Samara Kiihl,https://github.com/samarafk/MLML2R,TRUE,https://github.com/samarafk/mlml2r,9261,2,2019-10-17T10:17:39Z,4630.5
MLPA,"Functions to import Applied Biosystems data files of multiplex ligation-dependent probe amplification (MLPA) analysis and process them. Gene-expression profiling methods are described in Mareschal, Ruminy et al (2015) <doi:10.1016/j.jmoldx.2015.01.007>. Gene-fusion detection methods are described in Mareschal, Palau et al (under review).",2020-05-01,Sylvain Mareschal,http://bioinformatics.ovsa.fr/MLPA,TRUE,https://github.com/maressyl/r.mlpa,692,0,2020-06-09T16:04:10Z,NA
MLPUGS,"An implementation of classifier chains (CC's) for multi-label
    prediction. Users can employ an external package (e.g. 'randomForest',
    'C50'), or supply their own. The package can train a single set of CC's or
    train an ensemble of CC's -- in parallel if running in a multi-core
    environment. New observations are classified using a Gibbs sampler since
    each unobserved label is conditioned on the others. The package includes
    methods for evaluating the predictions for accuracy and aggregating across
    iterations and models to produce binary or probabilistic classifications.",2016-07-06,Mikhail Popov,https://github.com/bearloga/MLPUGS,TRUE,https://github.com/bearloga/mlpugs,10937,11,2020-03-06T17:45:11Z,994.2727272727273
mlr3,"Efficient, object-oriented programming on the
    building blocks of machine learning. Provides 'R6' objects for tasks,
    learners, resamplings, and measures. The package is geared towards
    scalability and larger datasets by supporting parallelization and
    out-of-memory data-backends like databases. While 'mlr3' focuses on
    the core computational operations, add-on packages provide additional
    functionality.",2020-06-02,Michel Lang,"https://mlr3.mlr-org.com, https://github.com/mlr-org/mlr3",TRUE,https://github.com/mlr-org/mlr3,35827,289,2020-06-08T10:53:31Z,123.96885813148789
mlr3data,"A small collection of interesting and educational
    machine learning data sets which are used as examples in the 'mlr3'
    book (<https://mlr3book.mlr-org.com>), the use case gallery
    (<https://mlr3gallery.mlr-org.com>), or in other examples.  All data
    sets are properly preprocessed and ready to be analyzed by most
    machine learning algorithms. Currently contains the following data
    sets: (1) housing prices in Kings County, and (2) Titanic passenger
    survival data.",2020-02-10,Michel Lang,https://github.com/mlr-org/mlr3data,TRUE,https://github.com/mlr-org/mlr3data,4978,0,2020-05-04T08:59:11Z,NA
mlr3db,"Extends the 'mlr3' package with a backend to
    transparently work with data bases. Internally relies on the
    abstraction of package 'dbplyr' to interact with one of the many
    supported data base management systems (DBMS).",2020-02-19,Michel Lang,"https:///mlr3db.mlr-org.com, https://github.com/mlr-org/mlr3db",TRUE,https://github.com/mlr-org/mlr3db,5764,9,2020-06-08T10:53:50Z,640.4444444444445
mlr3filters,"Extends 'mlr3' with filter methods for feature
    selection. Besides standalone filter methods built-in methods of any
    machine-learning algorithm are supported.  Partial scoring of
    multivariate filter methods is supported.",2020-03-12,Patrick Schratz,"https://mlr3filters.mlr-org.com,
https://github.com/mlr-org/mlr3filters",TRUE,https://github.com/mlr-org/mlr3filters,7292,4,2020-05-24T07:59:33Z,1823
mlr3learners,"Recommended Learners for 'mlr3'. Extends 'mlr3'
    with interfaces to essential machine learning packages on CRAN.  This
    includes, but is not limited to: (penalized) linear and logistic
    regression, linear and quadratic discriminant analysis, k-nearest
    neighbors, naive Bayes, support vector machines, and gradient
    boosting.",2020-04-22,Michel Lang,"https://mlr3learners.mlr-org.com,
https://github.com/mlr-org/mlr3learners",TRUE,https://github.com/mlr-org/mlr3learners,12014,20,2020-06-07T09:01:37Z,600.7
mlr3measures,"Implements multiple performance measures for
    supervised learning.  Includes over 40 measures for regression and
    classification. Additionally, meta information about the performance
    measures can be queried, e.g. what the best and worst possible
    performances scores are.",2020-04-01,Michel Lang,"https:///mlr3measures.mlr-org.com,
https://github.com/mlr-org/mlr3measures",TRUE,https://github.com/mlr-org/mlr3measures,37573,1,2020-05-24T07:59:20Z,37573
mlr3misc,"Frequently used helper functions and assertions
    used in 'mlr3' and its companion packages. Comes with helper functions
    for functional programming, for printing, to work with 'data.table',
    as well as some generally useful 'R6' classes. This package also
    supersedes the package 'BBmisc'.",2020-06-03,Michel Lang,"https://mlr3misc.mlr-org.com, https://github.com/mlr-org/mlr3misc",TRUE,https://github.com/mlr-org/mlr3misc,47541,4,2020-06-03T10:09:54Z,11885.25
mlr3pipelines,"Dataflow programming toolkit that enriches 'mlr3' with a diverse
  set of pipelining operators ('PipeOps') that can be composed into graphs.
  Operations exist for data preprocessing, model fitting, and ensemble
  learning. Graphs can themselves be treated as 'mlr3' 'Learners' and can
  therefore be resampled, benchmarked, and tuned.",2020-04-06,Martin Binder,"https://mlr3pipelines.mlr-org.com,
https://github.com/mlr-org/mlr3pipelines",TRUE,https://github.com/mlr-org/mlr3pipelines,15210,52,2020-06-05T16:09:38Z,292.5
mlr3proba,"Provides extensions for probabilistic supervised
    learning for 'mlr3'.  This includes extending the regression task to
    probabilistic and interval regression, adding a survival task, and
    other specialized models, predictions, and measures.",2020-06-05,Raphael Sonabend,"https://mlr3proba.mlr-org.com,
https://github.com/mlr-org/mlr3proba",TRUE,https://github.com/mlr-org/mlr3proba,5485,24,2020-06-08T15:28:21Z,228.54166666666666
mlr3tuning,"Implements methods for hyperparameter tuning with
    'mlr3', e.g. Grid Search, Random Search, or Simulated Annealing.
    Various termination criteria can be set and combined.  The class
    'AutoTuner' provides a convenient way to perform nested resampling in
    combination with 'mlr3'.",2020-01-31,Michel Lang,"https://mlr3tuning.mlr-org.com,
https://github.com/mlr-org/mlr3tuning",TRUE,https://github.com/mlr-org/mlr3tuning,7264,15,2020-05-24T22:26:44Z,484.26666666666665
mlr3verse,"The 'mlr3' package family is a set of packages for
    machine-learning purposes built in a modular fashion. This wrapper
    package is aimed to simplify the installation and loading of the core
    'mlr3' packages. Get more information about the 'mlr3' project at
    <https://mlr3book.mlr-org.com/>.",2020-01-19,Patrick Schratz,"https://mlr3verse.mlr-org.com,
https://github.com/mlr-org/mlr3verse",TRUE,https://github.com/mlr-org/mlr3verse,3448,7,2020-05-24T08:00:02Z,492.57142857142856
mlr3viz,"Provides visualizations for 'mlr3' objects such as tasks,
    predictions, resample results or benchmark results via the autoplot()
    generic of 'ggplot2'. The returned 'ggplot' objects are intended to provide
    sensible defaults, yet can easily be customized to create camera-ready
    figures. Visualizations include barplots, boxplots, histograms, ROC curves,
    and Precision-Recall curves.",2020-02-19,Michel Lang,"https://mlr3viz.mlr-org.com, https://github.com/mlr-org/mlr3viz",TRUE,https://github.com/mlr-org/mlr3viz,5099,15,2020-05-24T22:27:31Z,339.93333333333334
mlrCPO,"Toolset that enriches 'mlr' with a diverse set of preprocessing
    operators. Composable Preprocessing Operators (""CPO""s) are first-class
    R objects that can be applied to data.frames and 'mlr' ""Task""s to modify
    data, can be attached to 'mlr' ""Learner""s to add preprocessing to machine
    learning algorithms, and can be composed to form preprocessing pipelines.",2020-04-06,Martin Binder,https://github.com/mlr-org/mlrCPO,TRUE,https://github.com/mlr-org/mlrcpo,11522,36,2020-04-06T01:51:42Z,320.05555555555554
mlrMBO,"Flexible and comprehensive R toolbox for model-based optimization
    ('MBO'), also known as Bayesian optimization. It implements the Efficient
    Global Optimization Algorithm and is designed for both single- and multi-
    objective optimization with mixed continuous, categorical and conditional
    parameters. The machine learning toolbox 'mlr' provide dozens of regression
    learners to model the performance of the target algorithm with respect to
    the parameter settings. It provides many different infill criteria to guide
    the search process. Additional features include multi-point batch proposal,
    parallel execution as well as visualization and sophisticated logging
    mechanisms, which is especially useful for teaching and understanding of
    algorithm behavior. 'mlrMBO' is implemented in a modular fashion, such that
    single components can be easily replaced or adapted by the user for specific
    use cases.",2020-02-28,Bernd Bischl,https://github.com/mlr-org/mlrMBO,TRUE,https://github.com/mlr-org/mlrmbo,67292,158,2020-05-25T07:55:09Z,425.8987341772152
mltools,"A collection of machine learning helper functions, particularly assisting in the Exploratory Data Analysis phase. Makes heavy use of the 'data.table' package for optimal speed and memory efficiency. Highlights include a versatile bin_data() function, sparsify() for converting a data.table to sparse matrix format with one-hot encoding, fast evaluation metrics, and empirical_cdf() for calculating empirical Multivariate Cumulative Distribution Functions.",2018-05-12,Ben Gorman,https://github.com/ben519/mltools,TRUE,https://github.com/ben519/mltools,63694,58,2019-07-07T20:25:20Z,1098.1724137931035
mlxR,"Simulation and visualization of complex
    models for longitudinal data. The models are encoded using the model coding
    language 'Mlxtran' and automatically converted into C++ codes. 
    That allows one to implement very easily complex ODE-based models and complex 
    statistical models, including mixed effects models, for continuous, count, 
    categorical, and time-to-event data.",2020-06-02,Marc Lavielle,http://simulx.webpopix.org,TRUE,https://github.com/marclavielle/mlxr,27811,11,2020-05-22T14:07:43Z,2528.2727272727275
mmand,"Provides tools for performing mathematical morphology operations,
    such as erosion and dilation, on data of arbitrary dimensionality. Can also
    be used for finding connected components, resampling, filtering, smoothing
    and other image processing-style operations.",2020-03-03,Jon Clayden,https://github.com/jonclayden/mmand,TRUE,https://github.com/jonclayden/mmand,37864,23,2020-05-07T11:01:58Z,1646.2608695652175
mmetrics,"Provides a mechanism for easy computation of marketing metrics.
  By default in this package, metrics for digital marketing (e.g. CTR (Click Through Rate), CVR (Conversion Rate), CPC (Cost Per Click) etc) are calculated but you can define your own metrics easily.
  In addition to that, you can change an analysis axis to calculate these metrics.",2019-07-26,Shinichi Takayanagi,https://github.com/y-bar/mmetrics,TRUE,https://github.com/y-bar/mmetrics,4190,20,2019-08-09T15:04:59Z,209.5
MMRcaseselection,"Researchers doing a mixed-methods analysis (nested analysis as
    developed by Lieberman (2005) <doi:10.1017/S0003055405051762>) can
    use the package for the classification of cases and case selection using
    results of a linear regression. One can designate cases 
    as typical, deviant, extreme and pathway case and use different case 
    selection strategies for the choice of a case belonging to one of
    these types.",2020-06-03,Ingo Rohlfing,https://github.com/ingorohlfing/MMRcaseselection,TRUE,https://github.com/ingorohlfing/mmrcaseselection,0,1,2020-05-27T19:32:42Z,0
mniw,"Density evaluation and random number generation for the Matrix-Normal Inverse-Wishart (MNIW) distribution, as well as the the Matrix-Normal, Matrix-T, Wishart, and Inverse-Wishart distributions.  Core calculations are implemented in a portable (header-only) C++ library, with matrix manipulations using the 'Eigen' library for linear algebra.  Also provided is a Gibbs sampler for Bayesian inference on a random-effects model with multivariate normal observations.",2019-10-09,Martin Lysy,https://github.com/mlysy/mniw/,TRUE,https://github.com/mlysy/mniw,3035,0,2019-10-10T01:06:59Z,NA
mob,"Generate the monotonic binning and
    perform the woe (weight of evidence) transformation for the logistic regression
    used in the consumer credit scorecard development. The woe transformation is a piecewise
    transformation that is linear to the log odds. For a numeric variable, all of its monotonic 
    functional transformations will converge to the same woe transformation. ",2020-02-29,WenSui Liu,https://github.com/statcompute/mob,TRUE,https://github.com/statcompute/mob,1144,39,2020-02-03T03:06:45Z,29.333333333333332
mockery,"
    The two main functionalities of this package are creating mock
    objects (functions) and selectively intercepting calls to a given
    function that originate in some other function. It can be used
    with any testing framework available for R. Mock objects can
    be injected with either this package's own stub() function or a
    similar with_mock() facility present in the 'testthat' package.",2019-09-03,Jim Hester,https://github.com/jfiksel/mockery,TRUE,https://github.com/jfiksel/mockery,484450,55,2020-04-03T13:21:25Z,8808.181818181818
mod,"Creates modules inline or from a file. Modules can contain any R object and be nested. Each module have their own scope and package ""search path"" that does not interfere with one another or the user's working environment.",2019-08-23,Siqi Zhang,https://github.com/iqis/mod,TRUE,https://github.com/iqis/mod,4360,4,2019-12-05T02:18:12Z,1090
modeest,"Provides estimators of the mode of univariate
    data or univariate distributions. ",2019-11-18,Paul Poncet,https://github.com/paulponcet/modeest,TRUE,https://github.com/paulponcet/modeest,262292,5,2019-11-18T14:38:24Z,52458.4
modelbased,"Implements a general interface for model-based estimations for a wide variety of models (see support list of insight; Lüdecke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), used in the computation of marginal means, contrast analysis and predictions.",2020-03-12,Dominique Makowski,https://github.com/easystats/modelbased,TRUE,https://github.com/easystats/modelbased,4922,52,2020-05-21T02:40:56Z,94.65384615384616
modeldata,Data sets used for demonstrating or testing model-related packages are contained in this package.,2019-12-06,Max Kuhn,https://github.com/tidymodels/modeldata,TRUE,https://github.com/tidymodels/modeldata,18475,8,2020-04-23T19:51:35Z,2309.375
modeldb,Uses 'dplyr' and 'tidyeval' to fit statistical models inside the database. It currently supports KMeans and linear regression models.,2020-02-10,Max Kuhn,https://github.com/tidymodels/modeldb,TRUE,https://github.com/tidymodels/modeldb,9828,62,2020-05-13T14:20:49Z,158.51612903225808
modelDown,"Website generator with HTML summaries for predictive models.
    This package uses 'DALEX' explainers to describe global model behavior. 
    We can see how well models behave (tabs: Model Performance, Auditor),
    how much each variable contributes to predictions (tabs: Variable Response) 
    and which variables are the most important for a given model (tabs: Variable Importance).
    We can also compare Concept Drift for pairs of models (tabs: Drifter).
    Additionally, data available on the website can be easily recreated in current R session.
    Work on this package was financially supported by the NCN Opus grant 2017/27/B/ST6/01307 
    at Warsaw University of Technology, Faculty of Mathematics and Information Science.",2020-04-15,Kamil Romaszko,https://github.com/ModelOriented/modelDown,TRUE,https://github.com/modeloriented/modeldown,4650,97,2020-04-11T16:08:06Z,47.93814432989691
modeLLtest,"An implementation of the cross-validated difference in means (CVDM) test by Desmarais and Harden (2014) <doi:10.1007/s11135-013-9884-7> (see also Harden and Desmarais, 2011 <doi:10.1177/1532440011408929>) and the cross-validated median fit (CVMF) test by Desmarais and Harden (2012) <doi:10.1093/pan/mpr042>. These tests use leave-one-out cross-validated log-likelihoods to assist in selecting among model estimations. You can also utilize data from Golder (2010) <doi:10.1177/0010414009341714> and Joshi & Mason (2008) <doi:10.1177/0022343308096155> that are included to facilitate examples from real-world analysis.",2019-07-03,Shana Scogin,https://github.com/ShanaScogin/modeLLtest,TRUE,https://github.com/shanascogin/modelltest,3645,11,2019-10-04T22:16:20Z,331.3636363636364
modelr,"Functions for modelling that help you seamlessly
    integrate modelling into a pipeline of data manipulation and
    visualisation.",2020-05-19,Hadley Wickham,"https://modelr.tidyverse.org, https://github.com/tidyverse/modelr",TRUE,https://github.com/tidyverse/modelr,8039554,360,2020-05-19T20:12:53Z,22332.094444444443
modelStudio,"Automate the explanatory analysis of machine learning predictive models.
    Generate advanced interactive and animated model explanations in the form of
    a serverless HTML site with only one line of code. This tool is model agnostic,
    therefore compatible with most of the black box predictive models and frameworks.
    The main function computes various (instance and dataset level) model explanations
    and produces an interactive, customisable dashboard. It consists
    of multiple panels for plots with their short descriptions. Easily save and share 
    the dashboard with others. Tools for model exploration unite with tools for EDA 
    (Exploratory Data Analysis) to give a broad overview of the model behavior.",2020-05-08,Hubert Baniecki,"https://modelstudio.drwhy.ai,
https://github.com/ModelOriented/modelStudio",TRUE,https://github.com/modeloriented/modelstudio,7007,117,2020-06-04T16:48:20Z,59.888888888888886
modelsummary,"Create beautiful and customizable summary tables for statistical
    models. 'modelsummary' leverages the power of the 'gt', 'kableExtra' and
    'broom' packages. It supports dozens of model types, and can produce tables
    in HTML, LaTeX, RTF, Text/Markdown, JPG, PNG, and LaTeX formats. The tables
    can also be integrated in 'Rmarkdown', 'knitr', or 'Sweave' dynamic
    documents.",2020-05-26,Vincent Arel-Bundock,https://vincentarelbundock.github.io/modelsummary,TRUE,https://github.com/vincentarelbundock/modelsummary,6397,281,2020-06-09T16:04:25Z,22.765124555160142
modeltests,"Provides a number of testthat tests that can be
    used to verify that tidy(), glance() and augment() methods meet
    consistent specifications. This allows methods for the same generic to
    be spread across multiple packages, since all of those packages can
    make the same guarantees to users about returned objects.",2020-06-03,Alex Hayes,https://github.com/alexpghayes/modeltests,TRUE,https://github.com/alexpghayes/modeltests,2217,4,2020-06-02T22:45:53Z,554.25
moderndive,"Datasets and wrapper functions for tidyverse-friendly introductory linear regression, used in ""Statistical Inference via Data Science: A ModernDive into R and the Tidyverse"" available at <https://moderndive.com/>.",2019-11-04,Albert Y. Kim,https://github.com/ModernDive/moderndive_package,TRUE,https://github.com/moderndive/moderndive_package,32223,56,2020-05-18T12:52:20Z,575.4107142857143
modi,"Algorithms for multivariate outlier detection when missing values occur.
    Algorithms are based on Mahalanobis distance or data depth. Imputation is based
    on the multivariate normal model or uses nearest neighbour donors. The algorithms 
    take sample designs, in particular weighting, into account. The methods are 
    described in Bill and Hulliger (2016) <doi:10.17713/ajs.v45i1.86>.",2018-11-20,Martin Sterchi,https://github.com/martinSter/modi,TRUE,https://github.com/martinster/modi,5645,3,2019-07-30T13:29:13Z,1881.6666666666667
MODIS,"Download and processing functionalities for the Moderate Resolution
    Imaging Spectroradiometer (MODIS). The package provides automated access to the
    global online data archives LP DAAC (<https://lpdaac.usgs.gov/>), LAADS 
    (<https://ladsweb.modaps.eosdis.nasa.gov/>) and NSIDC (<https://nsidc.org/>) 
    as well as processing capabilities such as file conversion, mosaicking, 
    subsetting and time series filtering.",2020-03-30,Florian Detsch,https://github.com/MatMatt/MODIS,TRUE,https://github.com/matmatt/modis,30734,34,2020-03-30T13:52:22Z,903.9411764705883
MODISTools,"Programmatic interface to the Oak Ridge National Laboratories
    'MODIS Land Products Subsets' web services 
    (<https://modis.ornl.gov/data/modis_webservice.html>). Allows for easy
    downloads of 'MODIS' time series directly to your R workspace or
    your computer.",2020-03-05,Hufkens Koen,"https://docs.ropensci.org/MODISTools,
https://github.com/ropensci/MODISTools",TRUE,https://github.com/ropensci/modistools,28885,26,2020-04-20T11:11:38Z,1110.9615384615386
MODIStsp,"Allows automating the creation of time series of rasters derived
    from MODIS Satellite Land Products data. It performs several typical
    preprocessing steps such as download, mosaicking, reprojection and resize
    of data acquired on a specified time period. All processing parameters
    can be set using a user-friendly GUI. Users can select which layers of
    the original MODIS HDF files they want to process, which additional
    Quality Indicators should be extracted from aggregated MODIS Quality
    Assurance layers and, in the case of Surface Reflectance products
    , which Spectral Indexes should be computed from the original reflectance
    bands. For each output layer, outputs are saved as single-band raster
    files corresponding to each available acquisition date. Virtual files
    allowing access to the entire time series as a single file are also created.
    Command-line execution exploiting a previously saved processing options
    file is also possible, allowing to automatically update time series
    related to a MODIS product whenever a new image is available.",2020-05-10,Lorenzo Busetto,"https://github.com/ropensci/MODIStsp,
https://docs.ropensci.org/MODIStsp",TRUE,https://github.com/ropensci/modistsp,24912,98,2020-05-11T13:01:30Z,254.20408163265307
ModStatR,"Datasets and functions for the book ""Modélisation statistique par la pratique avec R"", F. Bertrand, E. Claeys and M. Maumy-Bertrand (2019, ISBN:9782100793525, Dunod, Paris). The first chapter of the book is dedicated to an introduction to the R statistical software. The second chapter deals with correlation analysis: Pearson, Spearman and Kendall simple, multiple and partial correlation coefficients. New wrapper functions for permutation tests or bootstrap of matrices of correlation are provided with the package. The third chapter is dedicated to data exploration with factorial analyses (PCA, CA, MCA, MDA) and clustering. The fourth chapter is dedicated to regression analysis: fitting and model diagnostics are detailed. The exercises focus on covariance analysis, logistic regression, Poisson regression, two-way analysis of variance for fixed or random factors. Various example datasets are shipped with the package: for instance on pokemon, world of warcraft, house tasks or food nutrition analyses.",2019-09-30,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/ModStatR",TRUE,https://github.com/fbertran/modstatr,2728,4,2019-10-01T10:37:09Z,682
modules,"Provides modules as an organizational unit for source code. Modules
    enforce to be more rigorous when defining dependencies and have
    a local search path. They can be used as a sub unit within packages
    or in scripts.",2019-02-10,Sebastian Warnholz,http://wahani.github.io/modules,TRUE,https://github.com/wahani/modules,24323,45,2020-03-02T13:18:05Z,540.5111111111111
MOEADr,"Modular implementation of Multiobjective Evolutionary Algorithms 
              based on Decomposition (MOEA/D) [Zhang and Li (2007), 
              <DOI:10.1109/TEVC.2007.892759>] for quick assembling and 
              testing of new algorithmic components, as well as easy 
              replication of published MOEA/D proposals. The full framework is
              documented in a paper published in the Journal of Statistical 
              Software [<doi:10.18637/jss.v092.i06>].",2020-02-17,Felipe Campelo,https://fcampelo.github.io/MOEADr/,TRUE,https://github.com/fcampelo/moeadr,10495,11,2020-02-17T17:06:59Z,954.0909090909091
MoEClust,"Clustering via parsimonious Gaussian Mixtures of Experts using the MoEClust models introduced by Murphy and Murphy (2019) <doi:10.1007/s11634-019-00373-8>. This package fits finite Gaussian mixture models with a formula interface for supplying gating and/or expert network covariates using a range of parsimonious covariance parameterisations from the GPCM family via the EM/CEM algorithm. Visualisation of the results of such models using generalised pairs plots and the inclusion of an additional noise component is also facilitated. A greedy forward stepwise search algorithm is provided for identifying the optimal model in terms of the number of components, the GPCM covariance parameterisation, and the subsets of gating/expert network covariates.",2020-05-12,Keefe Murphy,https://cran.r-project.org/package=MoEClust,TRUE,https://github.com/keefe-murphy/moeclust,12081,2,2020-05-12T22:52:33Z,6040.5
mombf,Bayesian model selection and averaging for regression and mixtures for non-local and selected local priors.,2019-12-06,David Rossell,https://github.com/davidrusi/mombf,TRUE,https://github.com/davidrusi/mombf,43643,1,2020-06-02T00:56:21Z,43643
momentuHMM,"Extended tools for analyzing telemetry data using generalized hidden Markov models. Features of momentuHMM (pronounced ``momentum'') include data pre-processing and visualization, fitting HMMs to location and auxiliary biotelemetry or environmental data, biased and correlated random walk movement models, hierarchical HMMs, multiple imputation for incorporating location measurement error and missing data, user-specified design matrices and constraints for covariate modelling of parameters, random effects, decoding of the state process, visualization of fitted models, model checking and selection, and simulation. See McClintock and Michelot (2018) <doi:10.1111/2041-210X.12995>.",2020-03-06,Brett McClintock,https://github.com/bmcclintock/momentuHMM,TRUE,https://github.com/bmcclintock/momentuhmm,19004,9,2020-03-05T05:45:43Z,2111.5555555555557
Momocs,"The development of this package 
       is now over, it is superseded by Momocs2 and more generally MomX ecosystem.
       The goal of Momocs is to provide a complete, convenient, 
       reproducible and open-source toolkit for 2D morphometrics.
       It includes most common 2D morphometrics approaches on outlines, open outlines, 
       configurations of landmarks, traditional morphometrics, and facilities for data preparation, 
       manipulation and visualization with a consistent grammar throughout.
       It allows reproducible, complex morphometrics analyses and other morphometrics approaches 
       should be easy to plug in, or develop from, on top of this canvas. ",2020-04-15,Vincent Bonhomme,https://github.com/MomX/Momocs/,TRUE,https://github.com/momx/momocs,30461,39,2020-05-01T12:51:51Z,781.0512820512821
Mondrian,"The unique function of this package allows representing in a single graph the relative occurrence and co-occurrence of events measured in a sample. 
  As examples, the package was applied to describe the occurrence and co-occurrence of different species of bacterial or viral symbionts infecting arthropods at the individual level. The graphics allows determining the prevalence of each symbiont and the patterns of multiple infections (i.e. how different symbionts share or not the same individual hosts). 
  We named the package after the famous painter as the graphical output recalls Mondrian’s paintings.",2020-05-22,Aurélie Siberchicot,"https://github.com/aursiber/Mondrian ;
http://lbbe-shiny.univ-lyon1.fr/MondrianShiny/",TRUE,https://github.com/aursiber/mondrian,13016,1,2020-05-22T12:35:03Z,13016
mongolite,"High-performance MongoDB client based on 'mongo-c-driver' and 'jsonlite'.
    Includes support for aggregation, indexing, map-reduce, streaming, encryption,
    enterprise authentication, and GridFS. The online user manual provides an overview 
    of the available methods in the package: <https://jeroen.github.io/mongolite/>.",2020-03-17,Jeroen Ooms,"https://github.com/jeroen/mongolite/ (devel)
https://jeroen.github.io/mongolite/ (user manual)
http://mongoc.org/ (upstream)",TRUE,https://github.com/jeroen/mongolite,259037,244,2020-03-23T15:51:17Z,1061.627049180328
monkeylearn,"Allows using some services of Monkeylearn <http://monkeylearn.com/> which is
    a Machine Learning platform on the cloud for text analysis (classification and extraction).",2018-04-13,Maëlle Salmon,"http://github.com/ropensci/monkeylearn,
http://ropensci.github.io/monkeylearn/",TRUE,https://github.com/ropensci/monkeylearn,16616,92,2019-12-05T19:32:32Z,180.6086956521739
monotonicity,"Test for monotonicity in financial variables sorted by portfolios. It is conventional practice in empirical research to form portfolios of assets ranked by a certain sort variable. A t-test is then used to consider the mean return spread between the portfolios with the highest and lowest values of the sort variable. Yet comparing only the average returns on the top and bottom portfolios does not provide a sufficient way to test for a monotonic relation between expected returns and the sort variable. This package provides nonparametric tests for the full set of monotonic patterns by Patton, A. and Timmermann, A. (2010) <doi:10.1016/j.jfineco.2010.06.006> and compares the proposed results with extant alternatives such as t-tests, Bonferroni bounds, and multivariate inequality tests through empirical applications and simulations.",2019-12-05,Siegfried Köstlmeier,https://github.com/skoestlmeier/monotonicity,TRUE,https://github.com/skoestlmeier/monotonicity,8952,1,2019-12-10T09:43:23Z,8952
morpheus,"Mixture of logistic regressions parameters (H)estimation with
    (U)spectral methods. The main methods take d-dimensional inputs and a vector
    of binary outputs, and return parameters according to the GLMs mixture model
    (General Linear Model). For more details see chapter 3 in the PhD thesis of
		Mor-Absa Loum: <http://www.theses.fr/s156435>, available here
		<https://tel.archives-ouvertes.fr/tel-01877796/document>.",2020-01-12,Benjamin Auder,https://github.com/yagu0/morpheus,TRUE,https://github.com/yagu0/morpheus,7556,0,2020-04-30T11:49:20Z,NA
Morpho,"A toolset for Geometric Morphometrics and mesh processing. This
    includes (among other stuff) mesh deformations based on reference points,
    permutation tests, detection of outliers, processing of sliding
    semi-landmarks and semi-automated surface landmark placement.",2020-03-09,Stefan Schlager,https://github.com/zarquon42b/Morpho,TRUE,https://github.com/zarquon42b/morpho,45072,29,2020-06-02T13:16:10Z,1554.2068965517242
MortalityLaws,"Fit the most popular human mortality 'laws', and construct 
  full and abridge life tables given various input indices. A mortality
  law is a parametric function that describes the dying-out process of 
  individuals in a population during a significant portion of their 
  life spans. For a comprehensive review of the most important mortality 
  laws see Tabeau (2001) <doi:10.1007/0-306-47562-6_1>. 
  Practical functions for downloading data from various human mortality 
  databases are provided as well.  ",2020-03-16,Marius D. Pascariu,https://github.com/mpascariu/MortalityLaws,TRUE,https://github.com/mpascariu/mortalitylaws,19526,9,2020-03-16T18:25:08Z,2169.5555555555557
mosaic,"Data sets and utilities from Project MOSAIC (<http://mosaic-web.org>) used
    to teach mathematics, statistics, computation and modeling.  Funded by the
    NSF, Project MOSAIC is a community of educators working to tie together
    aspects of quantitative work that students in science, technology,
    engineering and mathematics will need in their professional lives, but
    which are usually taught in isolation, if at all.",2020-05-18,Randall Pruim,"https://github.com/ProjectMOSAIC/mosaic,
https://projectmosaic.github.io/mosaic/",TRUE,https://github.com/projectmosaic/mosaic,809230,81,2020-05-18T01:16:03Z,9990.493827160493
mosaic.find,"Provides a function (mosaic_find()) designed to find rhythmic 
    and non-rhythmic trends in multi-omics time course data using model 
    selection and joint modeling, a method called MOSAIC (Multi-Omics 
    Selection with Amplitude Independent Criteria). For more information,
    see H. De los Santos et al. (2020) <doi:10.1101/2020.04.27.064147>.",2020-05-13,Hannah De los Santos,https://github.com/delosh653/MOSAIC,TRUE,https://github.com/delosh653/mosaic,342,0,2020-05-13T20:10:43Z,NA
mosaicCalc,"Part of the Project MOSAIC (<http://mosaic-web.org/>)
    suite that provides utility functions for doing calculus 
    (differentiation and integration) in R. The main differentiation and 
    antidifferentiation operators are described using formulas and return functions 
    rather than numerical values. Numerical values can be obtained by evaluating
    these functions.",2020-05-07,Daniel T. Kaplan,https://github.com/ProjectMOSAIC/mosaicCalc,TRUE,https://github.com/projectmosaic/mosaiccalc,67506,4,2020-05-06T19:03:49Z,16876.5
mosaicData,"Data sets from Project MOSAIC (<http://mosaic-web.org>) used
    to teach mathematics, statistics, computation and modeling.  Funded by the
    NSF, Project MOSAIC is a community of educators working to tie together
    aspects of quantitative work that students in science, technology,
    engineering and mathematics will need in their professional lives, but
    which are usually taught in isolation, if at all.",2020-05-15,Randall Pruim,https://github.com/ProjectMOSAIC/mosaicData,TRUE,https://github.com/projectmosaic/mosaicdata,532767,1,2020-05-15T03:09:50Z,532767
mosmafs,"Performs simultaneous hyperparameter tuning and
  feature selection through both single-objective and multi-objective
  optimization as described in Binder, Moosbauer et al. (2019) <arXiv:1912.12912>.
  Uses the 'ecr'-package as basis but adds mixed integer
  evolutionary strategies and multi-fidelity functionality as well as operators
  specific for the problem of feature selection.",2020-04-05,Martin Binder,https://github.com/compstat-lmu/mosmafs,TRUE,https://github.com/compstat-lmu/mosmafs,2659,1,2020-06-02T20:27:28Z,2659
motifcluster,"
    Tools for spectral clustering of weighted directed networks using motif
    adjacency matrices. Methods perform well on large and sparse networks, and
    random sampling methods for generating weighted directed networks are also
    provided. Based on methodology detailed in Underwood, Elliott and Cucuringu
    (2020) <arXiv:2004.01293>.",2020-05-18,William George Underwood,https://github.com/wgunderwood/motifcluster,TRUE,https://github.com/wgunderwood/motifcluster,258,2,2020-05-28T02:02:23Z,129
motoRneuron,"The temporal relationship between motor neurons can offer 
    explanations for neural strategies. We combined functions to reduce neuron 
    action potential discharge data and analyze it for short-term, time-domain 
    synchronization. Even more so, motoRneuron combines most available methods 
    for the determining cross correlation histogram peaks and most available 
    indices for calculating synchronization into simple functions. See 
    Nordstrom, Fuglevand, and Enoka (1992) <doi:10.1113/jphysiol.1992.sp019244> 
    for a more thorough introduction.",2019-02-26,Andrew Tweedell,http://github.com/tweedell/motoRneuron,TRUE,https://github.com/tweedell/motorneuron,4930,0,2019-06-21T17:18:35Z,NA
mountainplot,"Lattice functions for drawing folded empirical cumulative
    distribution plots, or mountain plots. A mountain plot is similar
    to an empirical CDF plot, except that the curve increases from
    0 to 0.5, then decreases from 0.5 to 1 using an inverted scale at
    the right side.",2017-07-13,Kevin Wright,https://github.com/kwstat/mountainplot,TRUE,https://github.com/kwstat/mountainplot,15579,1,2019-09-13T15:27:37Z,15579
mousetrap,"Mouse-tracking, the analysis of mouse movements in computerized
    experiments, is a method that is becoming increasingly popular in the
    cognitive sciences. The mousetrap package offers functions for importing,
    preprocessing, analyzing, aggregating, and visualizing mouse-tracking data.",2019-12-05,Pascal J. Kieslich,https://github.com/pascalkieslich/mousetrap,TRUE,https://github.com/pascalkieslich/mousetrap,20118,21,2020-02-22T17:23:22Z,958
moveHMM,"Provides tools for animal movement modelling using hidden Markov
    models. These include processing of tracking data, fitting hidden Markov models
    to movement data, visualization of data and fitted model, decoding of the state
    process...",2019-05-19,Theo Michelot,"https://github.com/TheoMichelot/moveHMM,
https://cran.r-project.org/package=moveHMM",TRUE,https://github.com/theomichelot/movehmm,28518,18,2020-05-16T17:37:12Z,1584.3333333333333
moveVis,Tools to visualize movement data (e.g. from GPS tracking) and temporal changes of environmental data (e.g. from remote sensing) by creating video animations.,2020-03-28,Jakob Schwalb-Willmann,http://movevis.org,TRUE,https://github.com/16eagle/movevis,21755,81,2020-05-12T14:03:50Z,268.58024691358025
mpath,"Algorithms optimize penalized models. Currently the models include penalized Poisson, negative binomial, zero-inflated Poisson, zero-inflated negative binomial regression models and robust models. The penalties include least absolute shrinkage and selection operator (LASSO), smoothly clipped absolute deviation (SCAD), minimax concave penalty (MCP), and each possibly combining with L_2 penalty. 
      See Wang et al. (2014) <doi:10.1002/sim.6314>, Wang et al. (2015) <doi:10.1002/bimj.201400143>,
      Wang et al. (2016) <doi:10.1177/0962280214530608>, Wang (2019) <arXiv:1912.11119>.",2020-06-01,Zhu Wang,https://github.com/zhuwang46/mpath,TRUE,https://github.com/zhuwang46/mpath,39043,0,2020-04-23T17:07:15Z,NA
mpcmp,"A collection of functions for estimation, testing and diagnostic checking for the mean-parametrized Conway-Maxwell Poisson (COM-Poisson) regression model of Huang (2017) <doi:10.1177/1471082X17697749>.",2019-03-04,Thomas Fung,https://github.com/thomas-fung/mpcmp,TRUE,https://github.com/thomas-fung/mpcmp,4921,2,2020-03-31T00:15:14Z,2460.5
mplot,"Model stability and variable inclusion plots [Mueller and Welsh
    (2010, <doi:10.1111/j.1751-5823.2010.00108.x>); Murray, Heritier and Mueller
    (2013, <doi:10.1002/sim.5855>)] as well as the adaptive fence [Jiang et al.
    (2008, <doi:10.1214/07-AOS517>); Jiang et al. 
    (2009, <doi:10.1016/j.spl.2008.10.014>)] for linear and generalised linear models.",2020-02-15,Garth Tarr,"http://garthtarr.github.io/mplot,
https://github.com/garthtarr/mplot",TRUE,https://github.com/garthtarr/mplot,169522,8,2020-03-02T06:24:11Z,21190.25
MplusAutomation,"Leverages the R language to automate latent variable model estimation
	and interpretation using 'Mplus', a powerful latent variable modeling program
	developed by Muthen and Muthen (<http://www.statmodel.com>). Specifically, this package
    provides routines for creating related groups of models, running batches of
    models, and extracting and tabulating model parameters and fit statistics.",2018-11-25,Michael Hallquist,https://github.com/michaelhallquist/MplusAutomation,TRUE,https://github.com/michaelhallquist/mplusautomation,87338,41,2020-05-23T03:50:26Z,2130.1951219512193
mpoly,Symbolic computing with multivariate polynomials in R.,2020-02-20,David Kahle,https://github.com/dkahle/mpoly,TRUE,https://github.com/dkahle/mpoly,30825,6,2020-05-23T17:02:53Z,5137.5
mppR,"Analysis of experimental multi-parent populations to detect
             regions of the genome (called quantitative trait loci, QTLs)
             influencing phenotypic traits. The population must be composed of crosses
             between a set of at least three parents (e.g. factorial design,
             'diallel', or nested association mapping). The functions cover data
             processing, QTL detection, and results visualization. The implemented
             methodology is described by Garin, Wimmer, Mezmouk, Malosetti and
             van Eeuwijk (2017) <doi:10.1007/s00122-017-2923-3>.",2020-02-11,Vincent Garin,https://github.com/vincentgarin/mppR,TRUE,https://github.com/vincentgarin/mppr,7118,1,2020-02-09T08:33:10Z,7118
MPTmultiverse,"
    Statistical or cognitive modeling usually requires a number of more or less 
    arbitrary choices creating one specific path through a 'garden of forking paths'. 
    The multiverse approach (Steegen, Tuerlinckx, Gelman, & Vanpaemel, 2016, 
    <doi:10.1177/1745691616658637>) offers a principled alternative in which results 
    for all possible combinations of reasonable modeling choices are reported. 
    MPTmultiverse performs a multiverse analysis for multinomial processing tree 
    (MPT, Riefer & Batchelder, 1988, <doi:10.1037/0033-295X.95.3.318>) models combining 
    maximum-likelihood/frequentist and Bayesian estimation approaches with 
    different levels of pooling (i.e., data aggregation). For the 
    frequentist approaches, no pooling (with and without parametric or nonparametric 
    bootstrap) and complete pooling are implemented using 
    MPTinR <https://cran.r-project.org/package=MPTinR>. 
    For the Bayesian approaches, no pooling, complete pooling, and three different 
    variants of partial pooling are implemented using 
    TreeBUGS <https://cran.r-project.org/package=TreeBUGS>. The main function is 
    fit_mpt() who performs the multiverse analysis in one call.",2020-05-18,Henrik Singmann,https://github.com/mpt-network/MPTmultiverse,TRUE,https://github.com/mpt-network/mptmultiverse,6677,1,2020-05-12T08:36:08Z,6677
MQMF,"Complements the book ""Using R for Modelling and  
    Quantitative Methods in Fisheries"" ISBN: 9780367469894, being 
    published in June 2020 by Chapman & Hall in their ""Using R series"". 
    There are numerous functions and data-sets that are used in the 
    book's many practical examples. ",2020-03-19,Malcolm Haddon,https://github.com/haddonm/MQMF,TRUE,https://github.com/haddonm/mqmf,1289,0,2020-05-06T00:13:34Z,NA
mrbayes,"Bayesian estimation of inverse variance weighted (IVW), Burgess 
    et al. (2013) <doi:10.1002/gepi.21758>, and MR-Egger, Bowden et 
    al. (2015) <doi:10.1093/ije/dyv080>, summary data models for Mendelian 
    randomization analyses.",2020-05-28,Okezie Uche-Ikonne,https://github.com/okezie94/mrbayes,TRUE,https://github.com/okezie94/mrbayes,3311,1,2020-05-29T10:21:29Z,3311
mrbsizeR,"A method for the multiresolution analysis of spatial fields and images to capture scale-dependent features.
    mrbsizeR is based on scale space smoothing and uses differences of smooths at neighbouring scales for finding features on different scales.
    To infer which of the captured features are credible, Bayesian analysis is used.
    The scale space multiresolution analysis has three steps: (1) Bayesian signal reconstruction.
    (2) Using differences of smooths, scale-dependent features of the reconstructed signal can be found.
    (3) Posterior credibility analysis of the differences of smooths created.
    The method has first been proposed by Holmstrom, Pasanen, Furrer, Sain (2011) <DOI:10.1016/j.csda.2011.04.011>.
    Matlab code is available under <http://cc.oulu.fi/~lpasanen/MRBSiZer/>.",2020-04-01,Roman Flury,"https://github.com/romanflury/mrbsizeR,
https://romanflury.github.io/mrbsizeR/",TRUE,https://github.com/romanflury/mrbsizer,10760,0,2019-12-10T12:37:18Z,NA
mrds,"Animal abundance estimation via conventional, multiple covariate
    and mark-recapture distance sampling (CDS/MCDS/MRDS). Detection function
    fitting is performed via maximum likelihood. Also included are diagnostics
    and plotting for fitted detection functions. Abundance estimation is via a
    Horvitz-Thompson-like estimator.",2020-05-12,Jeff Laake,NA,TRUE,https://github.com/distancedevelopment/mrds,44026,0,2020-06-08T13:38:17Z,NA
mregions,"Tools to get marine regions data from
    <http://www.marineregions.org/>. Includes tools to get region metadata,
    as well as data in 'GeoJSON' format, as well as Shape files. Use cases
    include using data downstream to visualize 'geospatial' data by marine
    region, mapping variation among different regions, and more.",2017-10-17,Scott Chamberlain,https://github.com/ropenscilabs/mregions,TRUE,https://github.com/ropenscilabs/mregions,13319,13,2019-12-09T13:33:24Z,1024.5384615384614
mrf2d,"Model fitting, sampling and visualization
    for the (Hidden) Markov Random Field model with pairwise interactions and 
    general interaction structure from 
    Freguglia, Garcia & Bicas (2020) <doi:10.1002/env.2613>,
    which has many popular models used in 2-dimensional lattices
    as particular cases, like the Ising Model and Potts Model.",2020-06-02,Victor Freguglia,"https://github.com/Freguglia/mrf2d,
https://arxiv.org/abs/2006.00383",TRUE,https://github.com/freguglia/mrf2d,1766,2,2020-06-02T23:03:44Z,883
MRFcov,"Approximate node interaction parameters of Markov Random Fields 
    graphical networks. Models can incorporate additional covariates, allowing users to estimate
    how interactions between nodes in the graph are predicted to change across
    covariate gradients. The general methods implemented in this package are described 
    in Clark et al. (2018) <doi:10.1002/ecy.2221>.",2019-04-10,Nicholas J Clark,https://github.com/nicholasjclark/MRFcov,TRUE,https://github.com/nicholasjclark/mrfcov,7127,16,2020-04-23T01:00:13Z,445.4375
mrgsolve,"Fast simulation from ordinary differential equation
    (ODE) based models typically employed in quantitative pharmacology and
    systems biology.",2020-02-21,Kyle T Baron,https://github.com/metrumresearchgroup/mrgsolve,TRUE,https://github.com/metrumresearchgroup/mrgsolve,23106,59,2020-06-09T13:39:22Z,391.6271186440678
mRpostman,"IMAP4rev1 (Internet Message Access Protocol, Version 4rev1) 
    functionalities based on the RFC 3501 manual (Crispin, 2003, 
    <doi:10.17487/RFC3501>), its updates, and other related documents. 
    'mRpostman' makes extensive use of 'curl' and 'libcurl' capabilities, 
    providing functions for mailboxes and electronic messages manipulation.",2020-04-20,Allan Quadros,NA,TRUE,https://github.com/allanvc/mrpostman,3762,15,2020-04-20T13:42:48Z,250.8
MRReg,"We provide the framework to analyze multiresolution partitions (e.g. country, provinces, subdistrict) where each individual data point belongs to only one partition in each layer (e.g. i belongs to subdistrict A, province P, and country Q).   We assume that a partition in a higher layer subsumes lower-layer partitions (e.g. a nation is at the 1st layer subsumes all provinces at the 2nd layer). Given N individuals that have a pair of real values (x,y) that generated from  independent variable X and dependent variable Y. Each individual i belongs to one partition per layer. Our goal is to find which partitions at which highest level that all individuals  in the these partitions share the same linear model Y=f(X) where f is a linear function. The framework deploys the Minimum Description Length principle (MDL) to infer solutions. The publication of this package is at Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok, and Suttipong Thajchayapong (2019) <arXiv:1907.05234>.",2020-05-12,Chainarong Amornbunchornvej,https://github.com/DarkEyes/MRReg,TRUE,https://github.com/darkeyes/mrreg,348,1,2020-05-13T10:28:15Z,348
MrSGUIDE,"An R implementation of 'GUIDE' style algorithm focusing on subgroup identification problem 
            under multiple responses of Loh et al. (2019) <doi:10.1002/widm.1326>. This package is intended for use 
            for randomized trials and observational studies.",2020-05-30,Peigen Zhou,"http://www.stat.wisc.edu/~loh/guide.html,
https://baconzhou.github.io/MrSGUIDE/,
http://pages.stat.wisc.edu/~loh/treeprogs/guide/LZ19.pdf,
http://pages.stat.wisc.edu/~loh/treeprogs/guide/sm19.pdf",TRUE,https://github.com/baconzhou/mrsguide,56,2,2020-05-30T16:31:29Z,28
msaenet,"Multi-step adaptive elastic-net (MSAENet) algorithm for
    feature selection in high-dimensional regressions proposed in
    Xiao and Xu (2015) <DOI:10.1080/00949655.2015.1016944>,
    with support for multi-step adaptive MCP-net (MSAMNet) and
    multi-step adaptive SCAD-net (MSASNet) methods.",2019-05-17,Nan Xiao,"https://nanx.me/msaenet/, https://github.com/nanxstats/msaenet",TRUE,https://github.com/nanxstats/msaenet,24391,9,2020-04-23T15:24:53Z,2710.1111111111113
MSbox,"Common mass spectrometry tools described in John Roboz (2013) <doi:10.1201/b15436>. It allows checking element
 isotopes, calculating (isotope labelled) exact monoisitopic mass, m/z values and mass accuracy, and inspecting possible contaminant mass peaks,
 examining possible adducts in electrospray ionization (ESI) and matrix-assisted laser desorption ionization (MALDI)
 ion sources. ",2019-07-18,Yonghui Dong,https://github.com/YonghuiDong/MSbox,TRUE,https://github.com/yonghuidong/msbox,10130,0,2019-12-31T15:18:04Z,NA
mschart,"Create native charts for 'Microsoft PowerPoint' and 'Microsoft Word' documents. 
 These can then be edited and annotated. Functions are provided to let users create charts, modify 
 and format their content. The chart's underlying data is automatically saved within the 
 'Word' document or 'PowerPoint' presentation. It extends package 'officer' that does 
 not contain any feature for 'Microsoft' native charts production. ",2019-11-14,David Gohel,https://ardata-fr.github.io/mschart/,TRUE,https://github.com/ardata-fr/mschart,17535,83,2019-11-14T22:14:26Z,211.26506024096386
mscstts,"R Client for the Microsoft Cognitive Services 
  'Text-to-Speech' REST API, including voice synthesis. A valid account 
  must be registered at the Microsoft Cognitive Services website 
  <https://www.microsoft.com/cognitive-services/> in order to 
  obtain a (free) API key. Without an API key, this package will not 
  work properly.",2020-05-23,John Muschelli,https://github.com/muschellij2/mscstts,TRUE,https://github.com/muschellij2/mscstts,11057,5,2020-05-22T15:22:04Z,2211.4
MSEtool,"Simulation tools for management strategy evaluation are provided for the 'DLMtool' operating model to inform data-rich fisheries. 
  'MSEtool' provides complementary assessment models of varying complexity with standardized reporting, diagnostic tools for evaluating 
  assessment models within closed-loop simulation, and helper functions for building more complex operating models and management procedures.",2020-05-05,Tom Carruthers,http://www.datalimitedtoolkit.org,TRUE,https://github.com/tcarruth/msetool,9866,1,2020-05-29T19:32:38Z,9866
MSG,A companion to the Chinese book ``Modern Statistical Graphics''.,2019-09-03,Yihui Xie,https://github.com/yihui/MSG,TRUE,https://github.com/yihui/msg,18615,22,2020-02-06T16:41:17Z,846.1363636363636
MSGARCH,"Fit (by Maximum Likelihood or MCMC/Bayesian), simulate, and forecast various Markov-Switching GARCH models as described in Ardia et al. (2019) <doi:10.18637/jss.v091.i04>.",2020-04-20,David Ardia,https://github.com/keblu/MSGARCH,TRUE,https://github.com/keblu/msgarch,25777,44,2020-04-20T21:37:34Z,585.8409090909091
msgr,"Provides new functions info(), warn() and error(), similar to message(),
    warning() and stop() respectively. However, the new functions can have a 'level'
    associated with them, so that when executed the global level option determines whether
    they are shown or not. This allows debug modes, outputting more information. The can also
    output all messages to a log file.",2019-12-16,Chad Goymer,https://github.com/ChadGoymer/msgr,TRUE,https://github.com/chadgoymer/msgr,2399,1,2020-05-23T07:41:06Z,2399
msigdbr,"Provides the 'Molecular Signatures Database' (MSigDB) gene sets
    typically used with the 'Gene Set Enrichment Analysis' (GSEA) software
    (Subramanian et al. 2005 <doi:10.1073/pnas.0506580102>, Liberzon et al. 2015
    <doi:10.1016/j.cels.2015.12.004>) in a standard R data frame with key-value
    pairs. The package includes the original human gene symbols and NCBI/Entrez
    IDs as well as the equivalents for frequently studied model organisms such
    as mouse, rat, pig, fly, and yeast.",2020-05-14,Igor Dolgalev,https://github.com/igordot/msigdbr,TRUE,https://github.com/igordot/msigdbr,22453,23,2020-05-14T15:10:09Z,976.2173913043479
msm,"Functions for fitting continuous-time Markov and hidden
    Markov multi-state models to longitudinal data.  Designed for
    processes observed at arbitrary times in continuous time (panel data)
    but some other observation schemes are supported. Both Markov
    transition rates and the hidden Markov output process can be modelled
    in terms of covariates, which may be constant or piecewise-constant
    in time.",2019-12-16,Christopher Jackson,https://github.com/chjackson/msm,TRUE,https://github.com/chjackson/msm,575523,17,2020-02-04T10:46:04Z,33854.294117647056
msos,"Multivariate Analysis methods and data sets used
    in John Marden's book Multivariate Statistics: Old School (2015) <ISBN:978-1456538835>.
    This also serves as a companion package for the 
    STAT 571: Multivariate Analysis course offered by the Department of Statistics
    at the University of Illinois at Urbana-Champaign ('UIUC'). ",2020-01-08,James Balamuta,"https://github.com/coatless/msos,
http://istics.net/stat/Multivariate/",TRUE,https://github.com/coatless/msos,17030,1,2020-01-07T19:55:26Z,17030
MSRDT,"This is a implementation of design methods for multi-state reliability demonstration tests (MSRDT) with failure count data, 
    which is associated with the work from the published paper ""Multi-state Reliability Demonstration Tests"" by Suiyao Chen et al. (2017) <doi:10.1080/08982112.2017.1314493>.
    It implements two types of MSRDT, multiple periods (MP) and multiple failure modes (MFM). 
    For MP, two different scenarios with criteria on cumulative periods (Cum) or separate periods (Sep) are implemented respectively.
    It also provides the implementation of conventional design method, namely binomial tests for failure count data.",2020-06-02,Suiyao Chen,https://github.com/ericchen12377/MSRDT,TRUE,https://github.com/ericchen12377/msrdt,0,2,2020-06-04T17:08:04Z,0
mStats,"This is a tool for epidemiologist, medical data analyst, 
    medical or public health professionals. It contains three domains of functions:
    functions for 1) data management, 2) statistical analysis and 3) calculating 
    epidemiological measures. The calculations are mainly based on three books, 
    1) Betty R. K, (2006, ISBN:978–0–86542–871–3), 
    2) B. Burt Gerstman (2013, ISBN:978-1-4443-3608-5) and 
    3) Douglas G Altman (2005, ISBN:0 7279 1375 1).",2020-03-31,Myo Minn Oo,https://myominnoo.github.io/,TRUE,https://github.com/myominnoo/mstats,1536,1,2020-05-01T08:54:36Z,1536
MTA,Build multiscalar territorial analysis based on various contexts.,2019-10-16,Timothée Giraud,https://github.com/riatelab/MTA/,TRUE,https://github.com/riatelab/mta,10820,5,2019-10-21T08:27:42Z,2164
mthapower,"Calculate Sample Size and Power for
    Association Studies Involving Mitochondrial DNA Haplogroups.
    Based on formulae by Samuels et al. AJHG, 2006. 78(4):713-720. <DOI:10.1086/502682>.",2019-05-14,Aurora Baluja,https://github.com/aurora-mareviv/mthapower,TRUE,https://github.com/aurora-mareviv/mthapower,8849,2,2019-06-22T21:40:08Z,4424.5
MTLR,"An implementation of Multi-Task Logistic Regression (MTLR) for R. 
  This package is based on the method proposed by Yu et al. (2011) which utilized MTLR for generating individual survival curves
  by learning feature weights which vary across time. This model was further extended to account for left and interval censored data.",2019-06-03,Humza Haider,https://github.com/haiderstats/MTLR,TRUE,https://github.com/haiderstats/mtlr,6261,6,2019-10-14T00:23:51Z,1043.5
MtreeRing,"Use morphological image processing and edge detection algorithms to automatically measure tree ring widths on digital images. Users can also manually mark tree rings on species with complex anatomical structures. The arcs of inner-rings and angles of successive inclined ring boundaries are used to correct ring-width series. The package provides a Shiny-based application, allowing R beginners to easily analyze tree ring images and export ring-width series in standard file formats.",2019-10-03,Jingning Shi,https://github.com/ropensci/MtreeRing,TRUE,https://github.com/ropensci/mtreering,8355,12,2019-12-09T13:35:10Z,696.25
MTSYS,"Mahalanobis-Taguchi (MT) system is a collection of multivariate
    analysis methods developed for the field of quality engineering. MT system
    consists of two families depending on their purpose. One is a family of
    Mahalanobis-Taguchi (MT) methods (in the broad sense) for diagnosis (see
    Woodall, W. H., Koudelik, R., Tsui, K. L., Kim, S. B., Stoumbos, Z. G., and
    Carvounis, C. P. (2003) <doi:10.1198/004017002188618626>) and the other is a
    family of Taguchi (T) methods for forecasting (see Kawada, H., and Nagata, Y.
    (2015) <doi:10.17929/tqs.1.12>). The MT package contains three basic methods
    for the family of MT methods and one basic method for the family of T
    methods. The MT method (in the narrow sense), the Mahalanobis-Taguchi
    Adjoint (MTA) methods, and the Recognition-Taguchi (RT) method are for the
    MT method and the two-sided Taguchi (T1) method is for the family of T
    methods. In addition, the Ta and Tb methods, which are the improved versions
    of the T1 method, are included.",2017-09-10,Akifumi Okayama,https://github.com/okayaa/MTSYS,TRUE,https://github.com/okayaa/mtsys,9291,1,2019-12-06T08:28:00Z,9291
mudata2,"Formatting and structuring multi-parameter spatiotemporal data
  is often a time-consuming task. This package offers functions and data structures 
  designed to easily organize and visualize these data for applications in geology, 
  paleolimnology, dendrochronology, and paleoclimate. See Dunnington and Spooner (2018)
  <doi:10.1139/facets-2017-0026>.",2020-03-20,Dewey Dunnington,"https://paleolimbot.github.io/mudata2,
https://github.com/paleolimbot/mudata2",TRUE,https://github.com/paleolimbot/mudata2,15548,20,2020-03-20T19:06:33Z,777.4
mudfold,"Nonparametric unfolding item response theory (IRT) model for dichotomous data (see W.H. Van Schuur (1984). Structure in Political Beliefs: A New Model for Stochastic Unfolding with Application to European Party Activists, and W.J.Post (1992). Nonparametric Unfolding Models: A Latent Structure Approach). The package implements MUDFOLD (Multiple UniDimensional unFOLDing), an iterative item selection algorithm that constructs unfolding scales from dichotomous preferential-choice data without explicitly assuming a parametric form of the item response functions. Scale diagnostics from Post(1992) and estimates for the person locations proposed by Johnson(2006) and Van Schuur(1984) are also available. This model can be seen as the unfolding variant of Mokken(1971) scaling method.",2019-12-19,Spyros Balafas,https://github.com/cran/mudfold,TRUE,https://github.com/cran/mudfold,11424,2,2019-12-19T19:20:02Z,5712
muHVT,Constructing hierarchical voronoi tessellations for a given data set and overlay heatmap for variables at various levels of the tessellations for in-depth data analysis. See <https://en.wikipedia.org/wiki/Voronoi_diagram> for more information. Credits to Mu Sigma for their continuous support throughout the development of the package.  ,2020-01-21,Mu Sigma,https://github.com/Mu-Sigma/muHVT,TRUE,https://github.com/mu-sigma/muhvt,6262,10,2020-01-24T09:45:04Z,626.2
multgee,"GEE solver for correlated nominal or ordinal multinomial responses
    using a local odds ratios parameterization.",2020-04-20,Anestis Touloumis,http://github.com/AnestisTouloumis/multgee,TRUE,https://github.com/anestistouloumis/multgee,30187,5,2020-05-13T20:34:41Z,6037.4
multicolor,Add multiple colors to text that is printed to the console.,2020-02-03,Amanda Dobbyn,http://github.com/aedobbyn/multicolor/,TRUE,https://github.com/aedobbyn/multicolor,10515,46,2020-02-03T15:52:36Z,228.58695652173913
multigraph,"Functions to plot and manipulate multigraphs, signed and valued graphs, bipartite graphs, multilevel graphs, and Cayley graphs with different layout options. Please note that this package still under a devel version. ",2020-02-28,Antonio Rivero Ostoic,http://github.com/mplex/multigraph/,TRUE,https://github.com/mplex/multigraph,15893,16,2020-05-18T09:02:57Z,993.3125
multilevelPSA,"Conducts and visualizes propensity score analysis for multilevel, 
  or clustered data. Bryer & Pruzek (2011) <doi:10.1080/00273171.2011.636693>.",2018-03-22,Jason Bryer,http://github.com/jbryer/multilevelPSA,TRUE,https://github.com/jbryer/multilevelpsa,16546,10,2020-04-05T03:21:42Z,1654.6
multilevelTools,"Effect sizes, diagnostics and performance metrics for
  multilevel and mixed effects models.
  Includes marginal and conditional 'R2' estimates for linear mixed effects models
  based on Johnson (2014) <doi:10.1111/2041-210X.12225>.",2020-03-04,Joshua F. Wiley,"http://joshuawiley.com/multilevelTools,
https://github.com/JWiley/multilevelTools",TRUE,https://github.com/jwiley/multileveltools,1829,1,2020-04-28T04:43:18Z,1829
multilinguer,"Provides install functions of other languages 
             such as 'java', 'python' for windows and macos.",2020-01-31,Chanyub Park,https://github.com/mrchypark/multilinguer,TRUE,https://github.com/mrchypark/multilinguer,6479,3,2020-02-02T16:52:25Z,2159.6666666666665
multinets,"Analyze multilevel networks as described in Lazega et al (2008)
    <doi:10.1016/j.socnet.2008.02.001> and in Lazega and Snijders 
    (2016, ISBN:978-3-319-24520-1). The package was developed essentially as an 
    extension to 'igraph'.",2019-12-14,Neylson Crepalde,https://github.com/neylsoncrepalde/multinets,TRUE,https://github.com/neylsoncrepalde/multinets,8329,12,2019-12-14T18:11:07Z,694.0833333333334
multinomineq,"
    Implements Gibbs sampling and Bayes factors for multinomial models with
    linear inequality constraints on the vector of probability parameters. As
    special cases, the model class includes models that predict a linear order 
    of binomial probabilities (e.g., p[1] < p[2] < p[3] < .50) and mixture models 
    assuming that the parameter vector p must be inside the convex hull of a 
    finite number of predicted patterns (i.e., vertices). A formal definition of 
    inequality-constrained multinomial models and the implemented computational
    methods is provided in: Heck, D.W., & Davis-Stober, C.P. (2019). 
    Multinomial models with linear inequality constraints: Overview and improvements 
    of computational methods for Bayesian inference. Journal of Mathematical 
    Psychology, 91, 70-87. <doi:10.1016/j.jmp.2019.03.004>.
    Inequality-constrained multinomial models have applications in the area of 
    judgment and decision making to fit and test random utility models  
    (Regenwetter, M., Dana, J., & Davis-Stober, C.P. (2011). Transitivity of 
    preferences. Psychological Review, 118, 42–56, <doi:10.1037/a0021150>) or to 
    perform outcome-based strategy classification to select the decision strategy 
    that provides the best account for a vector of observed choice frequencies 
    (Heck, D.W., Hilbig, B.E., & Moshagen, M. (2017). From information 
    processing to decisions: Formalizing and comparing probabilistic choice models. 
    Cognitive Psychology, 96, 26–40. <doi:10.1016/j.cogpsych.2017.05.003>).",2019-05-16,Daniel W. Heck,https://github.com/danheck/multinomineq,TRUE,https://github.com/danheck/multinomineq,3717,2,2020-01-24T14:40:11Z,1858.5
multiplex,"Algebraic procedures for the analysis of multiple social networks are delivered with this 
	    package as described in Ostoic (2020) <DOI:10.18637/jss.v092.i11>. Among other things, it 
	    makes it possible to create and manipulate multiplex, multimode, and multilevel network data 
	    with different formats. There are effective ways available to treat multiple networks with 
	    routines that combine algebraic systems like the partially ordered semigroup or the semiring 
	    structure with the relational bundles occurring in different types of multivariate network 
	    data sets. It also provides an algebraic approach for affiliation networks through Galois 
	    derivations between families of the pairs of subsets in the two domains.",2020-02-28,Antonio Rivero Ostoic,http://github.com/mplex/multiplex/,TRUE,https://github.com/mplex/multiplex,37691,11,2019-09-13T10:49:42Z,3426.4545454545455
muRty,Calculates k-best solutions and costs for an assignment problem following the method outlined in Murty (1968) <doi:10.1287/opre.16.3.682>.,2020-02-29,Aljaz Jelenko,https://github.com/arg0naut91/muRty,TRUE,https://github.com/arg0naut91/murty,5418,1,2020-02-29T13:32:02Z,5418
mvMORPH,"Fits multivariate (Brownian Motion, Early Burst, ACDC, Ornstein-Uhlenbeck and Shifts) models of continuous traits evolution on trees and time series. 'mvMORPH' also proposes high-dimensional multivariate comparative tools (linear models using Generalized Least Squares and multivariate tests) based on penalized likelihood.  See
    Clavel et al. (2015) <DOI:10.1111/2041-210X.12420>, Clavel et al. (2019) <DOI:10.1093/sysbio/syy045>, and Clavel & Morlon (2020) <DOI:10.1093/sysbio/syaa010>.",2020-04-17,Julien Clavel,https://github.com/JClavel/mvMORPH,TRUE,https://github.com/jclavel/mvmorph,37314,10,2020-06-08T15:55:54Z,3731.4
mvp,"Fast manipulation of symbolic multivariate polynomials
  using the 'Map' class of the Standard Template Library.  The package
  uses print and coercion methods from the 'mpoly' package (Kahle 2013,
  ""Multivariate polynomials in R"".  The R Journal, 5(1):162), but offers
  speed improvements.  It is comparable in speed to the 'spray' package
  for sparse arrays, but retains the symbolic benefits of 'mpoly'.",2019-09-05,Robin K. S. Hankin,https://github.com/RobinHankin/mvp.git,TRUE,https://github.com/robinhankin/mvp,8368,3,2020-03-11T09:34:30Z,2789.3333333333335
mvPot,"Tools for high-dimensional peaks-over-threshold inference and simulation
  of spatial extremal processes.",2018-04-09,Raphael de Fondeville,http://github.com/r-fndv/mvPot,TRUE,https://github.com/r-fndv/mvpot,27469,0,2020-01-09T16:05:13Z,NA
mvrsquared,"Compute the coefficient of determination for outcomes in n-dimensions. 
  May be useful for multidimensional predictions (such as a multinomial model) or
  calculating goodness of fit from latent variable models such as probabilistic
  topic models like latent Dirichlet allocation or deterministic topic models 
  like latent semantic analysis. Based on Jones (2019) <arXiv:1911.11061>.",2020-02-20,Tommy Jones,https://github.com/TommyJones/mvrsquared,TRUE,https://github.com/tommyjones/mvrsquared,1770,0,2020-03-30T02:19:53Z,NA
mwaved,"Computes the Wavelet deconvolution estimate of a common signal
    present in multiple channels that have possible different levels of blur
    and long memory additive error, see Kulik, Sapatinas and Wishart (2015), <doi:10.1016/j.acha.2014.04.004>.",2019-11-10,Justin Rory Wishart,https://github.com/jrwishart/mwaved,TRUE,https://github.com/jrwishart/mwaved,17322,0,2019-11-09T08:40:38Z,NA
myTAI,Investigate the evolution of biological processes by capturing evolutionary signatures in transcriptomes (Drost et al. (2017) <doi:10.1093/bioinformatics/btx835>). The aim of this tool is to provide a transcriptome analysis environment for answering questions regarding the evolution of biological processes (Drost et al. (2016) <doi:10.1101/051565>).,2020-01-10,Hajk-Georg Drost,https://github.com/HajkD/myTAI,TRUE,https://github.com/hajkd/mytai,21587,13,2020-04-30T21:38:07Z,1660.5384615384614
n1qn1,"Provides 'Scilab' 'n1qn1', or Quasi-Newton BFGS
      ""qn"" without constraints and 'qnbd' or Quasi-Newton BFGS with constraints.
       This takes more memory than traditional L-BFGS.  The n1qn1 routine is useful since it allows prespecification of a Hessian.
       If the Hessian is near enough the truth in optimization it can speed up the optimization problem. Both algorithms are described in the
       'Scilab' optimization documentation located at 
       <https://www.scilab.org/sites/default/files/optimization_in_scilab.pdf>.",2020-03-19,Matthew Fidler,https://github.com/nlmixrdevelopment/n1qn1,TRUE,https://github.com/nlmixrdevelopment/n1qn1,15833,1,2020-03-15T02:37:30Z,15833
N2H4,"Provides some functions to get Korean text sample from news articles in
             Naver which is popular news portal service <https://news.naver.com/> in Korea.",2020-03-20,Chanyub Park,http://github.com/forkonlp/N2H4,TRUE,https://github.com/forkonlp/n2h4,5166,162,2020-03-19T22:29:46Z,31.88888888888889
naaccr,"Functions for reading cancer record files which follow a format
    defined by the North American Association of Central Cancer Registries
    (NAACCR).",2019-12-17,Nathan Werth,https://github.com/WerthPADOH/naaccr,TRUE,https://github.com/werthpadoh/naaccr,2467,6,2020-02-20T16:08:38Z,411.1666666666667
NACHO,"NanoString nCounter data are gene expression assays
    where there is no need for the use of enzymes or amplification
    protocols and work with fluorescent barcodes (Geiss et al. (2018)
    <doi:10.1038/nbt1385>). Each barcode is assigned a
    messenger-RNA/micro-RNA (mRNA/miRNA) which after bonding with its
    target can be counted. As a result each count of a specific barcode
    represents the presence of its target mRNA/miRNA. 'NACHO' (NAnoString
    quality Control dasHbOard) is able to analyse the exported NanoString
    nCounter data and facilitates the user in performing a quality
    control. 'NACHO' does this by visualising quality control metrics,
    expression of control genes, principal components and sample specific
    size factors in an interactive web application.",2020-05-26,Mickaël Canouil,"https://github.com/mcanouil/NACHO,
https://mcanouil.github.io/NACHO",TRUE,https://github.com/mcanouil/nacho,5074,4,2020-05-26T22:37:16Z,1268.5
nadiv,"Constructs (non)additive genetic relationship matrices, and their
    inverses, from a pedigree to be used in linear mixed effect models (A.K.A.
    the 'animal model'). Also includes other functions to facilitate the use of
    animal models. Some functions have been created to be used in conjunction
    with the R package 'asreml' for the 'ASReml' software, which can be
    obtained upon purchase from 'VSN' international 
    (<http://www.vsni.co.uk/software/asreml>).",2019-10-20,Matthew Wolak,http://github.com/matthewwolak/nadiv,TRUE,https://github.com/matthewwolak/nadiv,36859,6,2019-10-29T21:15:36Z,6143.166666666667
naivebayes,"In this implementation of the Naive Bayes classifier following class conditional distributions are available: Bernoulli, Categorical, Gaussian, Poisson and non-parametric representation of the class conditional density estimated via Kernel Density Estimation. Implemented classifiers handle missing data and can take advantage of sparse data.",2020-03-08,Michal Majka,"https://github.com/majkamichal/naivebayes,
https://majkamichal.github.io/naivebayes/",TRUE,https://github.com/majkamichal/naivebayes,106147,17,2020-03-08T17:51:29Z,6243.941176470588
nakagami,"Density, distribution function, quantile function and random 
    generation for the Nakagami distribution of Nakagami (1960) 
    <doi:10.1016/B978-0-08-009306-2.50005-4>.",2019-12-02,Jonas Moss,https://github.com/JonasMoss/nakagami,TRUE,https://github.com/jonasmoss/nakagami,2673,0,2019-12-09T09:16:26Z,NA
namedCapture,"User-friendly wrappers for 
 named capture regular expressions.
 Introduction and comparison in research paper
 by Hocking (2019), R Journal.
 <doi:10.32614/RJ-2019-050>
 RE2 engine ('re2r' package)
 <https://github.com/qinwf/re2r>
 was removed from CRAN in Mar 2020
 so must be installed from github.",2020-04-01,Toby Dylan Hocking,https://github.com/tdhock/namedCapture,TRUE,https://github.com/tdhock/namedcapture,10925,4,2020-04-01T16:18:08Z,2731.25
namer,It names the 'R Markdown' chunks of files based on the filename.,2019-12-16,Steph Locke,https://github.com/lockedata/namer,TRUE,https://github.com/lockedata/namer,7505,76,2020-01-06T08:03:33Z,98.75
nametagger,"Wraps the 'nametag' library <https://github.com/ufal/nametag>, allowing users to find and extract entities (names, persons, locations, addresses, ...) in raw text and build your own entity recognition models.
    Based on a maximum entropy Markov model which is described in Strakova J., Straka M. and Hajic J. (2013) <http://ufal.mff.cuni.cz/~straka/papers/2013-tsd_ner.pdf>.",2020-06-04,Jan Wijffels,https://github.com/bnosac/nametagger,TRUE,https://github.com/bnosac/nametagger,0,0,2020-05-30T09:46:55Z,NA
nandb,"Calculation of molecular number and brightness from
    fluorescence microscopy image series. The software was published in a
    2016 paper <doi:10.1093/bioinformatics/btx434>. The seminal paper for
    the technique is Digman et al. 2008 <doi:10.1529/biophysj.107.114645>.
    A review of the technique was published in 2017
    <doi:10.1016/j.ymeth.2017.12.001>.",2020-05-08,Rory Nolan,"https://rorynolan.github.io/nandb,
https://github.com/rorynolan/nandb",TRUE,https://github.com/rorynolan/nandb,12014,2,2020-05-08T03:25:28Z,6007
naniar,"Missing values are ubiquitous in data and need to be explored and
    handled in the initial stages of analysis. 'naniar' provides data structures 
    and functions that facilitate the plotting of missing values and examination 
    of imputations. This allows missing data dependencies to be explored with 
    minimal deviation from the common work patterns of 'ggplot2' and tidy data. 
    The work is fully discussed at Tierney & Cook (2018) <arXiv:1809.02264>.",2020-04-30,Nicholas Tierney,https://github.com/njtierney/naniar,TRUE,https://github.com/njtierney/naniar,178072,488,2020-05-19T08:25:34Z,364.9016393442623
nanostringr,"Provides quality control (QC), normalization, and
    batch effect correction operations for 'NanoString nCounter' data,
    Talhouk et al. (2016) <doi:10.1371/journal.pone.0153844>.  Various
    metrics are used to determine which samples passed or failed QC.  Gene
    expression should first be normalized to housekeeping genes, before a
    reference-based approach is used to adjust for batch effects.  Raw
    NanoString data can be imported in the form of Reporter Code Count
    (RCC) files.",2019-05-09,Derek Chiu,"https://github.com/OVCARE/nanostringr,
https://ovcare.github.io/nanostringr",TRUE,https://github.com/ovcare/nanostringr,5176,2,2019-09-27T20:41:43Z,2588
nasapower,"Client for 'NASA' 'POWER' global meteorology, surface solar
    energy and climatology data 'API'.  'POWER' (Prediction Of Worldwide Energy
    Resource) data are freely available global meteorology and surface solar
    energy climatology data for download with a resolution of 1/2 by 1/2 arc
    degree longitude and latitude and are funded through the 'NASA' Earth
    Science Directorate Applied Science Program.  For more on the data
    themselves, a web-based data viewer and web access, please see
    <https://power.larc.nasa.gov/>.",2019-11-18,Adam H. Sparks,https://docs.ropensci.org/nasapower/,TRUE,https://github.com/ropensci/nasapower,11251,42,2020-04-25T05:30:01Z,267.8809523809524
nat,"NeuroAnatomy Toolbox (nat) enables analysis and visualisation of 3D
    biological image data, especially traced neurons. Reads and writes 3D images
    in NRRD and 'Amira' AmiraMesh formats and reads surfaces in 'Amira' hxsurf
    format. Traced neurons can be imported from and written to SWC and 'Amira'
    LineSet and SkeletonGraph formats. These data can then be visualised in 3D
    via 'rgl', manipulated including applying calculated registrations, e.g.
    using the 'CMTK' registration suite, and analysed. There is also a simple
    representation for neurons that have been subjected to 3D skeletonisation
    but not formally traced; this allows morphological comparison between
    neurons including searches and clustering (via the 'nat.nblast' extension
    package).",2020-02-07,Gregory Jefferis,"https://github.com/natverse/nat, https://natverse.github.io",TRUE,https://github.com/natverse/nat,26850,34,2020-04-26T15:56:26Z,789.7058823529412
nat.nblast,"Extends package 'nat' (NeuroAnatomy Toolbox) by providing a
    collection of NBLAST-related functions for neuronal morphology comparison (Costa et al. (2016) <doi: 10.1016/j.neuron.2016.06.012>).",2020-01-23,Gregory Jefferis,"https://github.com/natverse/nat.nblast, https://natverse.github.io",TRUE,https://github.com/natverse/nat.nblast,15114,10,2020-02-11T06:38:20Z,1511.4
nat.templatebrains,"Extends package 'nat' (NeuroAnatomy Toolbox) by providing objects
    and functions for handling template brains.",2018-06-24,Gregory Jefferis,https://github.com/jefferislab/nat.templatebrains,TRUE,https://github.com/jefferislab/nat.templatebrains,16477,3,2020-04-17T07:40:05Z,5492.333333333333
nationwider,"Web scraping the <https://www.nationwide.co.uk> for up-to-date data on 
    house price indices. Download data in tidy format.",2020-04-06,Kostas Vasilopoulos,https://github.com/kvasilopoulos/nationwider,TRUE,https://github.com/kvasilopoulos/nationwider,3714,0,2020-04-06T14:37:45Z,NA
natmanager,"Provides streamlined installation for packages from the 'natverse',
    a suite of R packages for computational neuroanatomy built on top of the
    'nat' 'NeuroAnatomy Toolbox' package. Installation of the complete
    'natverse' suite requires a 'GitHub' user account and personal access token
    'GITHUB_PAT'. 'natmanager' will help the end user set this up if necessary.",2020-03-11,Sridhar Jagannathan,https://github.com/natverse/natmanager,TRUE,https://github.com/natverse/natmanager,2274,1,2020-05-17T10:39:11Z,2274
natserv,"Interface to 'NatureServe' (<https://www.natureserve.org/>).
    Includes methods to get data, image metadata, search taxonomic names,
    and make maps.",2020-05-16,Scott Chamberlain,"https://docs.ropensci.org/natserv,
https://github.com/ropensci/natserv",TRUE,https://github.com/ropensci/natserv,89109,9,2020-05-18T14:18:24Z,9901
NatureSounds,Collection of example animal sounds for bioacoustic analysis.,2020-03-13,Marcelo Araya-Salas,https://github.com/maRce10/NatureSounds,TRUE,https://github.com/marce10/naturesounds,14483,0,2020-05-11T21:32:11Z,NA
nc,"User-friendly functions for extracting a data
 table (row for each match, column for each group)
 from non-tabular text data using regular expressions,
 and for melting columns that match a regular expression.
 Patterns are defined using a readable syntax
 that makes it easy to build complex patterns
 in terms of simpler, re-usable sub-patterns.
 Named R arguments are translated to column names
 in the output; capture groups without names are used
 internally in order to provide a standard interface
 to three regular expression C libraries (PCRE, RE2, ICU).
 Output can also include numeric columns via
 user-specified type conversion functions.
 RE2 engine (re2r package) was removed from CRAN in Mar 2020
 so must be installed from github.",2020-05-14,Toby Dylan Hocking,https://github.com/tdhock/nc,TRUE,https://github.com/tdhock/nc,4521,6,2020-05-16T20:32:04Z,753.5
ncdfgeom,Tools to create time series and geometry 'NetCDF' files.,2019-08-28,David Blodgett,https://code.usgs.gov/water/ncdfgeom,TRUE,https://github.com/usgs-r/ncdfgeom,25913,10,2020-03-22T21:01:54Z,2591.3
ncmeta,"Extract metadata from 'NetCDF' data sources, these can be files, file handles or
 servers. This package leverages and extends the lower level functions of the 'RNetCDF' package 
 providing a consistent set of functions that all return data frames. We introduce named concepts 
 of 'grid', 'axis' and 'source' which are all meaningful entities without formal definition in the 
 'NetCDF' library <https://www.unidata.ucar.edu/software/netcdf/>. 'RNetCDF' matches the library 
 itself with only the named concepts of 'variables', 'dimensions' and 'attributes'. 'ncmeta'
 provides a required framework for the in-development 'tidync' project <https://github.com/hypertidy/tidync>.",2020-05-12,Michael Sumner,https://github.com/hypertidy/ncmeta,TRUE,https://github.com/hypertidy/ncmeta,73589,6,2020-05-12T11:26:19Z,12264.833333333334
ncvreg,"Fits regularization paths for linear regression, GLM, and Cox
  regression models using lasso or nonconvex penalties, in particular the
  minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD)
  penalty, with options for additional L2 penalties (the ""elastic net"" idea).
  Utilities for carrying out cross-validation as well as post-fitting
  visualization, summarization, inference, and prediction are also provided.",2020-02-13,Patrick Breheny,"http://pbreheny.github.io/ncvreg,
https://github.com/pbreheny/ncvreg",TRUE,https://github.com/pbreheny/ncvreg,98884,24,2020-05-13T16:43:27Z,4120.166666666667
ndtv,"Renders dynamic network data from 'networkDynamic' objects as movies, interactive animations, or other representations of changing relational structures and attributes.",2019-05-22,Skye Bender-deMoll,https://github.com/statnet/ndtv,TRUE,https://github.com/statnet/ndtv,120281,31,2020-02-29T06:04:36Z,3880.032258064516
neatmaps,"Simplify the exploratory data analysis process for multiple network
             data sets with the help of hierarchical clustering, consensus 
             clustering and heatmaps. Multiple network data consists of multiple
             disjoint networks that have common variables (e.g. ego networks). 
             This package contains the necessary tools for exploring such data,
             from the data pre-processing stage to the creation of dynamic
             visualizations.",2019-05-12,Philippe Boileau,https://github.com/PhilBoileau/neatmaps,TRUE,https://github.com/philboileau/neatmaps,9550,3,2019-11-21T22:06:51Z,3183.3333333333335
neatRanges,"Collapse, partition, combine, fill gaps in and expand date/time ranges.",2020-03-29,Aljaz Jelenko,https://github.com/arg0naut91/neatRanges,TRUE,https://github.com/arg0naut91/neatranges,4277,2,2020-03-29T22:18:42Z,2138.5
neatStats,"User-friendly, clear and simple statistics, primarily for
  publication in psychological science. The main functions are wrappers for
  other packages, but there are various additions as well. Every relevant step
  from data aggregation to reportable printed statistics is covered for basic
  experimental designs.",2020-05-10,Gáspár Lukács,https://github.com/gasparl/neatstats,TRUE,https://github.com/gasparl/neatstats,1683,0,2020-06-07T09:33:24Z,NA
negenes,"Estimating the number of essential genes in a genome on
    the basis of data from a random transposon mutagenesis experiment,
    through the use of a Gibbs sampler.
    Lamichhane et al. (2003) <doi:10.1073/pnas.1231432100>.",2019-08-05,Karl W Broman,https://github.com/kbroman/negenes,TRUE,https://github.com/kbroman/negenes,19140,1,2019-08-05T15:50:34Z,19140
neo2R,"The aim of the neo2R is to provide simple and low level connectors
   for querying neo4j graph databases (<https://neo4j.com/>).
   The objects returned by the query functions are either lists or data.frames
   with very few post-processing.
   It allows fast processing of queries returning many records.
   And it let the user handle post-processing according to the data model
   and his needs.",2020-03-28,Patrice Godard,https://github.com/patzaw/neo2r,TRUE,https://github.com/patzaw/neo2r,1381,3,2020-03-28T05:58:37Z,460.3333333333333
neonUtilities,"NEON data packages can be accessed through the NEON Data Portal <https://data.neonscience.org/home>
    or through the NEON Data API (see <https://data.neonscience.org/data-api> for documentation). Data delivered from
    the Data Portal are provided as monthly zip files packaged within a parent zip file, while individual files
    can be accessed from the API. This package provides tools that aid in discovering, downloading, and reformatting 
    data prior to use in analyses. This includes downloading data via the API, merging data tables by type, and 
    converting formats. For more information, see the readme file at <https://github.com/NEONScience/NEON-utilities>.",2020-06-03,Claire Lunch,https://github.com/NEONScience/NEON-utilities,TRUE,https://github.com/neonscience/neon-utilities,13400,35,2020-06-03T01:09:58Z,382.85714285714283
neotoma,"Access paleoecological datasets from the Neotoma Paleoecological
    Database using the published API (<http://api.neotomadb.org/>).  The functions
    in this package access various pre-built API functions and attempt to return
    the results from Neotoma in a usable format for researchers and the public.",2019-01-05,Simon J. Goring,https://github.com/ropensci/neotoma,TRUE,https://github.com/ropensci/neotoma,27854,24,2019-12-09T13:39:11Z,1160.5833333333333
neptune,"Interface to 'Neptune', experiment tracking tool that helps you organize
    your machine learning experiments. You can log your hyperparameter, metrics, model binaries and
    performance charts, organize them with tags and names and share everything easily in the app.
    For more information see <https://neptune.ai/>.",2020-03-25,Jakub Czakon,https://github.com/neptune-ai/neptune-r,TRUE,https://github.com/neptune-ai/neptune-r,947,1,2020-03-25T13:06:58Z,947
nesRdata,Serves data from the United States Environmental Protection Agency (USEPA) National Eutrophication Survey <https://www.epa.gov/national-aquatic-resource-surveys>.,2020-04-30,Joseph Stachelek,https://github.com/jsta/nesRdata,TRUE,https://github.com/jsta/nesrdata,6929,2,2020-04-29T22:08:11Z,3464.5
nestfs,"Implementation of forward selection based on cross-validated
             linear and logistic regression.",2019-09-21,Marco Colombo,https://github.com/mcol/nestfs,TRUE,https://github.com/mcol/nestfs,9172,0,2019-09-21T13:53:38Z,NA
netdiffuseR,"Empirical statistical analysis, visualization and simulation of
    diffusion and contagion processes on networks. The package implements algorithms
    for calculating network diffusion statistics such as transmission rate, hazard
    rates, exposure models, network threshold levels, infectiousness (contagion),
    and susceptibility. The package is inspired by work published in Valente,
    et al., (2015) <DOI:10.1016/j.socscimed.2015.10.001>; Valente (1995) <ISBN:
    9781881303213>, Myers (2000) <DOI:10.1086/303110>, Iyengar and others (2011)
    <DOI:10.1287/mksc.1100.0566>, Burt (1987) <DOI:10.1086/228667>; among others.",2020-05-07,George Vega Yon  (<https://orcid.org/0000-0002-3171-0844>,"https://github.com/USCCANA/netdiffuseR,
https://USCCANA.github.io/netdiffuseR",TRUE,https://github.com/usccana/netdiffuser,16836,49,2020-05-06T18:25:54Z,343.59183673469386
netgen,"Methods for the generation of a wide range of network geographies,
    e.g., grid networks or clustered networks. Useful for the generation of
    benchmarking instances for the investigation of, e.g., Vehicle-Routing-Problems
    or Travelling Salesperson Problems.",2020-01-08,Jakob Bossek,https://github.com/jakobbossek/netgen,TRUE,https://github.com/jakobbossek/netgen,18261,8,2019-07-24T09:19:24Z,2282.625
netgsa,"Carry out Network-based Gene Set Analysis by incorporating external information about interactions among genes, as well as novel interactions learned from data.",2019-03-27,Jing Ma,https://github.com/drjingma/netgsa,TRUE,https://github.com/drjingma/netgsa,16066,3,2020-02-19T22:25:05Z,5355.333333333333
NetLogoR,"Build and run spatially explicit
    agent-based models using only the R platform. 'NetLogoR' follows the same
    framework as the 'NetLogo' software
    (Wilensky, 1999 <http://ccl.northwestern.edu/netlogo/>) and is a translation
    in R of the structure and functions of 'NetLogo'.
    'NetLogoR' provides new R classes to define model agents and functions to
    implement spatially explicit agent-based models in the R environment.
    This package allows benefiting of the fast and easy coding phase from the
    highly developed 'NetLogo' framework, coupled with the versatility, power
    and massive resources of the R software.
    Examples of three models (Ants <http://ccl.northwestern.edu/netlogo/models/Ants>,
    Butterfly (Railsback and Grimm, 2012) and Wolf-Sheep-Predation
    <http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation>) written using
    'NetLogoR' are available. The 'NetLogo' code of the original version of these
    models is provided alongside.
    A programming guide inspired from the 'NetLogo' Programming Guide
    (<https://ccl.northwestern.edu/netlogo/docs/programming.html>) and a dictionary
    of 'NetLogo' primitives (<https://ccl.northwestern.edu/netlogo/docs/dictionary.html>)
    equivalences are also available.
    NOTE: To increment 'time', these functions can use a for loop or can be
    integrated with a discrete event simulator, such as 'SpaDES'
    (<https://cran.r-project.org/package=SpaDES>).
    The suggested package 'fastshp' can be installed with
    'install.packages(""fastshp"", repos = ""https://rforge.net"", type = ""source"")'.",2020-03-02,Sarah Bauduin,"http://netlogor.predictiveecology.org,
https://github.com/PredictiveEcology/NetLogoR/",TRUE,https://github.com/predictiveecology/netlogor,10454,24,2020-02-28T17:32:30Z,435.5833333333333
netmeta,"A comprehensive set of functions providing frequentist methods for network meta-analysis and supporting Schwarzer et al. (2015) <DOI:10.1007/978-3-319-21416-0>, Chapter 8 ""Network Meta-Analysis"":
 - frequentist network meta-analysis following Rücker (2012) <DOI:10.1002/jrsm.1058>;
 - net heat plot and design-based decomposition of Cochran's Q according to Krahn et al. (2013) <DOI:10.1186/1471-2288-13-35>;
 - measures characterizing the flow of evidence between two treatments by König et al. (2013) <DOI:10.1002/sim.6001>;
 - ranking of treatments (frequentist analogue of SUCRA) according to Rücker & Schwarzer (2015) <DOI:10.1186/s12874-015-0060-8>;
 - partial order of treatment rankings ('poset') and Hasse diagram for 'poset' (Carlsen & Bruggemann, 2014) <DOI:10.1002/cem.2569>; (Rücker & Schwarzer, 2017) <DOI:10.1002/jrsm.1270>;
 - split direct and indirect evidence to check consistency (Dias et al., 2010) <DOI:10.1002/sim.3767>, (Efthimiou et al., 2019) <DOI:10.1002/sim.8158>;
 - league table with network meta-analysis results;
 - additive network meta-analysis for combinations of treatments (Rücker et al., 2019) <DOI:10.1002/bimj.201800167>;
 - network meta-analysis of binary data using the Mantel-Haenszel or non-central hypergeometric distribution method (Efthimiou et al., 2019) <DOI:10.1002/sim.8158>;
 - 'comparison-adjusted' funnel plot (Chaimani & Salanti, 2012) <DOI:10.1002/jrsm.57>;
 - automated drawing of network graphs described in Rücker & Schwarzer (2016) <DOI:10.1002/jrsm.1143>.",2020-04-16,Jochem König,https://github.com/guido-s/netmeta http://meta-analysis-with-r.org,TRUE,https://github.com/guido-s/netmeta,52912,5,2020-04-16T12:06:23Z,10582.4
NetMix,"Variational EM estimation of mixed-membership stochastic blockmodel for networks,
             incorporating node-level predictors of mixed-membership vectors, as well as 
             dyad-level predictors. For networks observed over time, the model defines a hidden
             Markov process that allows the effects of node-level predictors to evolve in discrete,
             historical periods. In addition, the package offers a variety of utilities for 
             exploring results of estimation, including tools for conducting posterior 
             predictive checks of goodness-of-fit and several plotting functions. The package 
             implements methods described in Olivella, Pratt and Imai (2019) ``Dynamic Stochastic
             Blockmodel Regression for Social Networks: Application to International Conflicts'',
             available at <http://santiagoolivella.info/wp-content/uploads/2018/07/dSBM_Reg.pdf>.",2020-01-14,Santiago Olivella,NA,TRUE,https://github.com/solivella/netmix,3842,3,2020-01-14T19:46:05Z,1280.6666666666667
netrankr,"Implements methods for centrality related analyses of networks. 
    While the package includes the possibility to build more than 20 indices, 
    its main focus lies on index-free assessment of centrality via partial 
    rankings obtained by neighborhood-inclusion or positional dominance. These 
    partial rankings can be analyzed with different methods, including 
    probabilistic methods like computing expected node ranks and relative 
    rank probabilities (how likely is it that a node is more central than another?).
    The methodology is described in depth in the vignettes and in
    Schoch (2018) <doi:10.1016/j.socnet.2017.12.003>.",2018-09-18,David Schoch,https://schochastics.github.io/netrankr,TRUE,https://github.com/schochastics/netrankr,22991,25,2020-03-26T14:21:43Z,919.64
netstat,"R interface for the 'netstat' command line utility used to retrieve and parse 
    commonly used network statistics, including available and in-use 
    transmission control protocol (TCP) ports. Primers offering technical background information 
    on the 'netstat' 
    command line utility are available in the ""Linux System Administrator's Manual"" 
    by Michael Kerrisk (2014) 
    <http://man7.org/linux/man-pages/man8/netstat.8.html>, and on the Microsoft website (2017) 
    <https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/netstat>.",2020-01-23,Steve Condylios,https://github.com/stevecondylios/netstat,TRUE,https://github.com/stevecondylios/netstat,2817,0,2020-03-13T01:04:23Z,NA
NetWeaver,Implements various simple function utilities and flexible pipelines to generate circular images for visualizing complex genomic and network data analysis features.,2019-02-26,Minghui Wang,https://github.com/mw201608/NetWeaver/,TRUE,https://github.com/mw201608/netweaver,10523,1,2019-07-22T17:09:18Z,10523
networkABC,"We developed an inference tool based on approximate Bayesian computation to decipher network data and assess the strength of the inferred links between network's actors. It is a new multi-level approximate Bayesian computation (ABC) approach. At the first level, the method captures the global properties of the network, such as scale-freeness and clustering coefficients, whereas the second level is targeted to capture local properties, including the probability of each couple of genes being linked. Up to now, Approximate Bayesian Computation (ABC) algorithms have been scarcely used in that setting and, due to the computational overhead, their application was limited to a small number of genes. On the contrary, our algorithm was made to cope with that issue and has low computational cost. It can be used, for instance, for elucidating gene regulatory network, which is an important step towards understanding the normal cell physiology and complex pathological phenotype. Reverse-engineering consists in using gene expressions over time or over different experimental conditions to discover the structure of the gene network in a targeted cellular process. The fact that gene expression data are usually noisy, highly correlated, and have high dimensionality explains the need for specific statistical methods to reverse engineer the underlying network. ",2020-03-03,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/networkABC",TRUE,https://github.com/fbertran/networkabc,5486,3,2020-03-03T08:17:48Z,1828.6666666666667
NetworkRiskMeasures,"Implements some risk measures for (financial) networks, such as DebtRank, Impact Susceptibility, Impact Diffusion and Impact Fluidity. ",2020-03-05,Carlos Cinelli,https://github.com/carloscinelli/NetworkRiskMeasures,TRUE,https://github.com/carloscinelli/networkriskmeasures,14770,26,2020-03-05T10:46:51Z,568.0769230769231
networktools,"Includes assorted tools for network analysis. Bridge centrality; goldbricker; MDS, PCA, & eigenmodel network plotting.",2020-04-20,Payton Jones,https://CRAN.R-project.org/package=networktools,TRUE,https://github.com/paytonjjones/networktools,23703,5,2020-04-19T13:50:41Z,4740.6
networktree,Methods to create tree models with correlation-based network models (multivariate normal distributions). ,2020-03-18,Payton Jones,https://paytonjjones.github.io/networktree,TRUE,https://github.com/paytonjjones/networktree,7133,2,2020-05-13T14:31:57Z,3566.5
NeuralSens,"Analysis functions to quantify inputs importance in neural network models.
  Functions are available for calculating and plotting the inputs importance and obtaining
  the activation function of each neuron layer and its derivatives. The importance of a given
  input is defined as the distribution of the derivatives of the output with respect to that
  input in each training data point.",2020-05-15,José Portela González,https://github.com/JaiPizGon/NeuralSens,TRUE,https://github.com/jaipizgon/neuralsens,7617,3,2020-05-15T07:44:42Z,2539
neurobase,"Base package for 'Neuroconductor', which includes many helper 
    functions that interact with objects of class 'nifti', implemented by
    package 'oro.nifti', for reading/writing and also other manipulation 
    functions.",2020-01-14,John Muschelli,NA,TRUE,https://github.com/muschellij2/neurobase,29350,4,2020-05-29T19:31:27Z,7337.5
neverhpfilter,"In the working paper titled ""Why You Should Never Use the Hodrick-Prescott 
   Filter"", James D. Hamilton proposes a new alternative to economic time series 
   filtering. The neverhpfilter package provides functions and data for reproducing his work. Hamilton (2017) <doi:10.3386/w23429>.",2020-02-09,Justin M. Shea,https://justinmshea.github.io/neverhpfilter/,TRUE,https://github.com/justinmshea/neverhpfilter,8581,8,2020-03-22T21:00:52Z,1072.625
newsanchor,"Interface to gather news from the 'News API', based on a multilevel query <https://newsapi.org/>. A personal API key is required. ",2019-06-29,Buhl Yannik,NA,TRUE,https://github.com/correlaid/newsanchor,6348,28,2019-06-29T12:48:56Z,226.71428571428572
newscatcheR,"Programmatically collect normalized news from
    (almost) any website. An 'R' clone of the
    <https://github.com/kotartemiy/newscatcher> 'Python' module.",2020-06-05,Novica Nakov,https://github.com/discindo/newscatcheR/,TRUE,https://github.com/discindo/newscatcher,30,3,2020-06-09T19:28:12Z,10
newsmap,"Semi-supervised model for geographical document classification (Watanabe 2018) <doi:10.1080/21670811.2017.1293487>. 
    This package currently contains seed dictionaries in English, German, French, Spanish, Russian, Hebrew, Arabic Japanese and Chinese (Simplified and Traditional).",2020-02-02,Kohei Watanabe,https://github.com/koheiw/newsmap,TRUE,https://github.com/koheiw/newsmap,12528,27,2020-02-02T21:40:44Z,464
NFP,"An implementation of the network fingerprint framework that introduced 
  in paper ""Network fingerprint: a knowledge-based characterization of biomedical 
  networks"" (Cui, 2015) <doi:10.1038/srep13286>. This method worked by making 
  systematic comparisons to a set of well-studied ""basic networks"", measuring 
  both the functional and topological similarity.  A biological could be
  characterized as a spectrum-like vector consisting of similarities to basic 
  networks. It shows great potential in biological network study.",2019-10-14,Yang Cao,https://github.com/yiluheihei/NFP,TRUE,https://github.com/yiluheihei/nfp,10900,2,2019-10-14T14:48:35Z,5450
ngram,"An n-gram is a sequence of n ""words"" taken, in order, from a
    body of text.  This is a collection of utilities for creating,
    displaying, summarizing, and ""babbling"" n-grams.  The
    'tokenization' and ""babbling"" are handled by very efficient C
    code, which can even be built as its own standalone library.
    The babbler is a simple Markov chain.  The package also offers
    a vignette with complete example 'workflows' and information about
    the utilities offered in the package.",2017-11-21,Drew Schmidt,https://github.com/wrathematics/ngram,TRUE,https://github.com/wrathematics/ngram,68346,56,2020-05-22T17:34:52Z,1220.4642857142858
NGSSEML,"Due to a large quantity of non-Gaussian time series and reliability data, the R-package non-Gaussian state-space with exact marginal likelihood is useful for modeling and forecasting non-Gaussian time series and reliability data via non-Gaussian state-space models with the exact marginal likelihood easily, see Gamerman, Santos and Franco (2013) <doi:10.1111/jtsa.12039> and Santos, Gamerman and Franco (2017) <doi:10.1109/TR.2017.2670142>. The package gives codes for formulating and specifying the non-Gaussian state-space models in the R language. Inferences for the parameters of the model can be made under the classical and Bayesian. Furthermore, prediction, filtering, and smoothing procedures can be used to perform inferences for the latent parameters. Applications include, e.g., count, volatility, piecewise exponential, and software reliability data.",2020-01-19,Thiago Rezende dos Santos,https://github.com/hadht/NGSSEML-R-Package,TRUE,https://github.com/hadht/ngsseml-r-package,2158,0,2020-01-21T20:26:27Z,NA
nhanesA,"Utility to retrieve data from the National Health and Nutrition 
	Examination Survey (NHANES) website <https://www.cdc.gov/nchs/nhanes/index.htm>.",2018-10-17,Christopher J. Endres,https://cran.r-project.org/package=nhanesA,TRUE,https://github.com/cjendres1/nhanes,24052,9,2019-06-23T00:35:38Z,2672.4444444444443
nhdR,"Tools for working with the National Hydrography Dataset, with 
    functions for querying, downloading, and networking both the NHD 
    <https://www.usgs.gov/core-science-systems/ngp/national-hydrography> 
    and NHDPlus <https://nhdplus.com/NHDPlus/> datasets. ",2020-03-23,Joseph Stachelek,https://github.com/jsta/nhdR,TRUE,https://github.com/jsta/nhdr,6127,19,2020-05-11T15:07:08Z,322.4736842105263
nhlapi,"Retrieves and processes the data exposed by the open 'NHL' API. This includes information on players, teams, games, tournaments, drafts, standings, schedules and other endpoints. A lower-level interface to access the data via URLs directly is also provided.",2020-05-25,Jozef Hajnala,https://github.com/jozefhajnala/nhlapi,TRUE,https://github.com/jozefhajnala/nhlapi,142,4,2020-05-25T15:28:19Z,35.5
nhlscrape,"Add game events to a database file to use for statistical analysis of hockey games. This means we only call the 'NHL' API
    once for each game we want to add. We will have very fast retrieval of data once games have been added since the data is stored locally.
    We use the API located at <https://statsapi.web.nhl.com/api/v1/teams> with supplemental data from <https://www.nhl.com/scores/>.
    Other endpoints can be found at <https://gitlab.com/dword4/nhlapi>.",2020-02-25,Adam Azoulay,https://github.com/adamazoulay/nhlscrape,TRUE,https://github.com/adamazoulay/nhlscrape,2366,4,2020-06-05T23:07:31Z,591.5
NHSRdatasets,"Free United Kingdom National Health Service (NHS) and other healthcare, or population health-related data for education and training purposes. This package currently contains a single simulated hospital dataset for teaching regression methods, with the addition of more datasets planned for future releases.  This package exists to support skills development in the NHS-R community: <https://nhsrcommunity.com/>.",2020-05-04,Chris Mainey,"https://github.com/nhs-r-community/NHSRdatasets,
https://nhs-r-community.github.io/NHSRdatasets/",TRUE,https://github.com/nhs-r-community/nhsrdatasets,4245,26,2020-05-04T14:41:27Z,163.26923076923077
nichevol,"A collection of tools that allow users to perform critical steps 
    in the process of assessing ecological niche evolution over phylogenies, with
    uncertainty incorporated explicitly in reconstructions. The method proposed
    here for ancestral reconstruction of ecological niches characterizes species'
    niches using a bin-based approach that incorporates uncertainty in estimations.
    Compared to other existing methods, the approaches presented here reduce risk
    of overestimation of amounts and rates of ecological niche evolution. The
    main analyses include: initial exploration of environmental data in occurrence
    records and accessible areas, preparation of data for phylogenetic analyses,
    executing comparative phylogenetic analyses of ecological niches, and plotting
    for interpretations. Details on the theoretical background and methods used 
    can be found in: Peterson et al. (1999) <doi:10.1126/science.285.5431.1265>,
    Soberon and Peterson (2005) <doi:10.17161/bi.v2i0.4>,
    Peterson (2011) <doi:10.1111/j.1365-2699.2010.02456.x>,
    Barve et al. (2011) <doi:10.1111/ecog.02671>, 
    Owens et al. (2013) <doi:10.1016/j.ecolmodel.2013.04.011>, and
    Saupe et al. (2018) <doi:10.1093/sysbio/syx084>.",2020-03-02,Marlon E. Cobos,https://github.com/marlonecobos/nichevol,TRUE,https://github.com/marlonecobos/nichevol,1315,8,2020-03-13T18:39:08Z,164.375
nima,"Miscellaneous R functions developed as collateral damage over the
    course of work in statistical and scientific computing for research. These
    include, for example, utilities that supplement existing idiosyncrasies of
    the R language, extend existing plotting functionality and aesthetics, help
    prepare data objects for imputation, and extend access to command line tools
    and systems-level information.",2020-03-06,Nima Hejazi,https://github.com/nhejazi/nima,TRUE,https://github.com/nhejazi/nima,13253,0,2020-03-06T02:01:37Z,NA
nimble,"A system for writing hierarchical statistical models largely
    compatible with 'BUGS' and 'JAGS', writing nimbleFunctions to operate models and
    do basic R-style math, and compiling both models and nimbleFunctions via custom-
    generated C++. 'NIMBLE' includes default methods for MCMC, particle filtering,
    Monte Carlo Expectation Maximization, and some other tools. The nimbleFunction
    system makes it easy to do things like implement new MCMC samplers from R,
    customize the assignment of samplers to different parts of a model from R, and
    compile the new samplers automatically via C++ alongside the samplers 'NIMBLE'
    provides. 'NIMBLE' extends the 'BUGS'/'JAGS' language by making it extensible:
    New distributions and functions can be added, including as calls to external
    compiled code. Although most people think of MCMC as the main goal of the
    'BUGS'/'JAGS' language for writing models, one can use 'NIMBLE' for writing
    arbitrary other kinds of model-generic algorithms as well. A full User Manual is
    available at <https://r-nimble.org>.",2020-05-22,Christopher Paciorek,"https://r-nimble.org, https://github.com/nimble-dev/nimble",TRUE,https://github.com/nimble-dev/nimble,47698,83,2020-06-08T21:06:23Z,574.6746987951807
nimbleEcology,"Common ecological distributions for 'nimble' models in the form of nimbleFunction objects. 
  Includes Cormack-Jolly-Seber, occupancy, dynamic occupancy, hidden Markov, dynamic hidden Markov, and N-mixture models.
  (Jolly (1965) <DOI: 10.2307/2333826>, Seber (1965) <DOI: 10.2307/2333827>, Turek et al. (2016) <doi:10.1007/s10651-016-0353-z>).",2020-05-29,Benjamin R. Goldstein,https://github.com/nimble-dev/nimbleEcology,TRUE,https://github.com/nimble-dev/nimbleecology,3833,7,2020-05-31T19:30:43Z,547.5714285714286
nipals,Principal Components Analysis of a matrix using Non-linear Iterative Partial Least Squares or weighted Expectation Maximization PCA with Gram-Schmidt orthogonalization of the scores and loadings. Optimized for speed. See Andrecut (2009) <doi:10.1089/cmb.2008.0221>.,2020-01-24,Kevin Wright,http://kwstat.github.io/nipals/,TRUE,https://github.com/kwstat/nipals,15380,6,2020-01-23T03:44:52Z,2563.3333333333335
nlaR,"Client for programmatic access to the 2007 and 2012 National 
  Lakes Assessment database <https://www.epa.gov/national-aquatic-resource-surveys/nla> 
  containing data for hundreds of lakes in the lower 48 states of the contiguous US.",2019-01-22,Joseph Stachelek,https://github.com/jsta/nlaR,TRUE,https://github.com/jsta/nlar,6417,2,2019-09-11T12:44:28Z,3208.5
nlist,"Create and manipulate numeric list (nlist) objects.
  An nlist is an S3 list of uniquely named numeric atomic (natomic) objects.
  An natomic object is an integer or double vector, matrix or array.
  An nlists object is a S3 class list of nlist objects with the 
  same names, dimensionalities and typeofs.
  Numeric list objects are of interest because they are the raw data inputs 
  for analytic engines such as 'JAGS', 'STAN' and 'TMB'.
  Numeric lists objects, which are useful for storing multiple realizations of
  of simulated data sets, can be converted to 
  coda::mcmc and coda::mcmc.list objects.",2020-01-24,Joe Thorley,https://github.com/poissonconsulting/nlist,TRUE,https://github.com/poissonconsulting/nlist,1999,2,2020-06-09T23:47:19Z,999.5
nlmixr,"Fit and compare nonlinear mixed-effects models in differential
    equations with flexible dosing information commonly seen in pharmacokinetics
    and pharmacodynamics (Almquist, Leander, and Jirstrand 2015 
    <doi:10.1007/s10928-015-9409-1>). Differential equation solving is 
    by compiled C code provided in the 'RxODE' package
    (Wang, Hallow, and James 2015 <doi:10.1002/psp4.12052>).",2020-03-18,Wenping Wang,https://github.com/nlmixrdevelopment/nlmixr,TRUE,https://github.com/nlmixrdevelopment/nlmixr,15614,63,2020-06-03T15:23:07Z,247.84126984126985
NLMR,"Provides neutral landscape models (<doi:10.1007/BF02275262>,
    <http://sci-hub.tw/10.1007/bf02275262>).  
    Neutral landscape models range from ""hard"" 
    neutral models (completely random distributed), to ""soft"" neutral models 
    (definable spatial characteristics) and generate landscape patterns that are 
    independent of ecological processes.
    Thus, these patterns can be used as null models in landscape ecology. 'nlmr' 
    combines a large number of algorithms from other published software for 
    simulating neutral landscapes. The simulation results are obtained in a
    geospatial data format (raster* objects from the 'raster' package) and can,
    therefore, be used in any sort of raster data operation that is performed 
    with standard observation data.                                                                                                  ",2020-01-23,Marco Sciaini,https://ropensci.github.io/NLMR/,TRUE,https://github.com/ropensci/nlmr,16270,49,2019-12-03T15:44:10Z,332.0408163265306
nlraa,"Additional nonlinear regression functions using self-start (SS) algorithms. One of the functions is the Beta growth function proposed by Yin et al. (2003) <doi:10.1093/aob/mcg029>. There are several other functions with breakpoints (e.g. linear-plateau, plateau-linear, exponential-plateau, plateau-exponential, quadratic-plateau, plateau-quadratic and bilinear), a non-rectangular hyperbola and a bell-shaped curve. Twenty one (21) new self-start (SS) functions in total. This package also supports the publication 'Nonlinear regression Models and applications in agricultural research' by Archontoulis and Miguez (2015) <doi:10.2134/agronj2012.0506>, a book chapter with similar material <doi:10.2134/appliedstatistics.2016.0003.c15> and a publication by Oddi et. al. (2019) in Ecology and Evolution <doi:10.1002/ece3.5543>. The function 'nlsLMList' uses nlsLM for fitting, but it is otherwise almost identical to 'nlme::nlsList'.In addition, this release of the package provides functions for conducting simulation for 'nlme' and 'gnls' objects as well as bootstrapping. These functions are intended to work with the modeling framework of the 'nlme' package. It also provides four vignettes with extended examples.",2020-04-25,Fernando Miguez,NA,TRUE,https://github.com/femiguez/nlraa,2454,2,2020-06-05T15:20:22Z,1227
nlrx,"Setup, run and analyze 'NetLogo' (<https://ccl.northwestern.edu/netlogo/>) model simulations in 'R'.
    'nlrx' experiments use a similar structure as 'NetLogos' Behavior Space experiments. 
    However, 'nlrx' offers more flexibility and additional tools for running and analyzing complex simulation designs and sensitivity analyses.
    The user defines all information that is needed in an intuitive framework, using class objects.
    Experiments are submitted from 'R' to 'NetLogo' via 'XML' files that are dynamically written, based on specifications defined by the user.
    By nesting model calls in future environments, large simulation design with many runs can be executed in parallel.
    This also enables simulating 'NetLogo' experiments on remote high performance computing machines.
    In order to use this package, 'Java' and 'NetLogo' (>= 5.3.1) need to be available on the executing system.",2020-02-07,Jan Salecker,"https://docs.ropensci.org/nlrx, https://github.com/ropensci/nlrx/",TRUE,https://github.com/ropensci/nlrx,6598,44,2020-03-12T07:44:43Z,149.95454545454547
NlsyLinks,"Utilities and kinship information for behavior genetics and
    developmental research using the National Longitudinal Survey of Youth
    (NLSY; <http://www.bls.gov/nls/>).",2016-04-19,Will Beasley,"http://liveoak.github.io/NlsyLinks,
https://github.com/LiveOak/NlsyLinks,
https://r-forge.r-project.org/projects/nlsylinks",TRUE,https://github.com/liveoak/nlsylinks,16746,0,2019-11-01T22:00:22Z,NA
nltm,"Fits a non-linear transformation model ('nltm') for
        analyzing survival data, see Tsodikov (2003) <doi:10.1111/1467-9868.00414>. The
        class of 'nltm' includes the following currently supported
        models: Cox proportional hazard, proportional hazard cure,
        proportional odds, proportional hazard - proportional hazard
        cure, proportional hazard - proportional odds cure, Gamma
        frailty, and proportional hazard - proportional odds.",2019-08-01,Gilda Garibotti,http://github.com/mclements/nltm,TRUE,https://github.com/mclements/nltm,4915,0,2019-08-01T14:50:01Z,NA
nLTT,"Provides functions to calculate the normalised Lineage-Through-
    Time (nLTT) statistic, given two phylogenetic trees. The nLTT statistic measures
    the difference between two Lineage-Through-Time curves, where each curve is
    normalised both in time and in number of lineages.",2020-01-13,Thijs Janzen,https://github.com/thijsjanzen/nLTT,TRUE,https://github.com/thijsjanzen/nltt,23587,4,2020-06-04T08:30:07Z,5896.75
nmaINLA,"Performs network meta-analysis using integrated nested Laplace approximations ('INLA') which is described in Guenhan, Held, and Friede (2018) <doi:10.1002/jrsm.1285>. 
             Includes methods to assess the heterogeneity and inconsistency in the network. Contains more than ten different network meta-analysis data. 
             'INLA' package can be obtained from <http://www.r-inla.org>. We recommend the testing version.",2020-04-07,Burak Kuersad Guenhan,https://github.com/gunhanb/nmaINLA,TRUE,https://github.com/gunhanb/nmainla,9507,3,2020-04-07T12:58:02Z,3169
NMOF,"Functions, examples and data from the first and the
  second edition of ""Numerical Methods and Optimization in Finance""
  by M. Gilli, D. Maringer and E. Schumann
  (2019, ISBN:978-0128150658).  The package provides
  implementations of optimisation heuristics
  (Differential Evolution, Genetic Algorithms,
  Particle Swarm Optimisation, Simulated Annealing and
  Threshold Accepting), and other optimisation tools,
  such as grid search and greedy search.
  There are also functions for the valuation of
  financial instruments, such as bonds and options, and
  functions that help with stochastic simulations.",2020-04-06,Enrico Schumann,"http://enricoschumann.net/NMOF,
https://github.com/enricoschumann/NMOF, https://gitlab.com/NMOF",TRUE,https://github.com/enricoschumann/nmof,62216,5,2020-06-07T07:49:56Z,12443.2
nmslibR,"A Non-Metric Space Library ('NMSLIB' <https://github.com/nmslib/nmslib>) wrapper, which according to the authors ""is an efficient cross-platform similarity search library and a toolkit for evaluation of similarity search methods. The goal of the 'NMSLIB' <https://github.com/searchivarius/nmslib> Library is to create an effective and comprehensive toolkit for searching in generic non-metric spaces. Being comprehensive is important, because no single method is likely to be sufficient in all cases. Also note that exact solutions are hardly efficient in high dimensions and/or non-metric spaces. Hence, the main focus is on approximate methods"". The wrapper also includes Approximate Kernel k-Nearest-Neighbor functions based on the 'NMSLIB' <https://github.com/searchivarius/nmslib> 'Python' Library.",2020-03-08,Lampros Mouselimis,https://github.com/mlampros/nmslibR,TRUE,https://github.com/mlampros/nmslibr,9278,8,2020-03-08T11:03:34Z,1159.75
nngeo,"K-nearest neighbor search for projected and non-projected 'sf' spatial layers. Nearest neighbor search uses (1) C code from 'GeographicLib' for lon-lat point layers, (2) function nn2() from package 'RANN' for projected point layers, or (3) function st_distance() from package 'sf' for line or polygon layers. The package also includes several other utility functions for spatial analysis.",2020-04-04,Michael Dorman,https://github.com/michaeldorman/nngeo/,TRUE,https://github.com/michaeldorman/nngeo,20903,38,2020-03-08T08:24:14Z,550.078947368421
nnlib2Rcpp,"Contains versions of Autoencoder, BP, LVQ, MAM NN and a module to define custom neural networks.",2020-06-08,Vasilis Nikolaidis,https://github.com/VNNikolaidis/nnlib2Rcpp,TRUE,https://github.com/vnnikolaidis/nnlib2rcpp,346,3,2020-06-08T13:35:40Z,115.33333333333333
NNS,"Nonlinear nonparametric statistics using partial moments.  Partial moments are the elements of variance and asymptotically approximate the area of f(x).  These robust statistics provide the basis for nonlinear analysis while retaining linear equivalences.  NNS offers: Numerical integration, Numerical differentiation, Clustering, Correlation, Dependence, Causal analysis, ANOVA, Regression, Classification, Seasonality, Autoregressive modeling, Normalization and Stochastic dominance.  All routines based on: Viole, F. and Nawrocki, D. (2013), Nonlinear Nonparametric Statistics: Using Partial Moments (ISBN: 1490523995).",2020-05-19,Fred Viole,NA,TRUE,https://github.com/ovvo-financial/nns,42014,17,2020-06-09T18:07:37Z,2471.4117647058824
nnTensor,"Some functions for performing non-negative matrix factorization, non-negative CANDECOMP/PARAFAC (CP) decomposition, non-negative Tucker decomposition, and generating toy model data. See Andrzej Cichock et al (2009) <doi:10.1002/9780470747278> and the reference section of GitHub README.md <https://github.com/rikenbit/nnTensor>, for details of the methods.",2020-06-04,Koki Tsuyuzaki,https://github.com/rikenbit/nnTensor,TRUE,https://github.com/rikenbit/nntensor,9493,6,2020-06-04T11:02:49Z,1582.1666666666667
noaastormevents,"Allows users to explore and plot data from the
    National Oceanic and Atmospheric Administration (NOAA) 
    Storm Events database through R for United States counties. 
    Functionality includes matching storm event listings by time and 
    location to hurricane best tracks data. This work was 
    supported by grants from the Colorado Water Center, the National Institute 
    of Environmental Health Sciences (R00ES022631) and the National Science 
    Foundation (1331399). ",2019-04-09,Brooke Anderson,https://github.com/geanders/noaastormevents,TRUE,https://github.com/geanders/noaastormevents,7868,7,2020-06-09T22:16:33Z,1124
noctua,"Designed to be compatible with the 'R' package 'DBI' (Database Interface)
    when connecting to Amazon Web Service ('AWS') Athena <https://aws.amazon.com/athena/>.
    To do this the 'R' 'AWS' Software Development Kit ('SDK') 'paws' 
    <https://github.com/paws-r/paws> is used as a driver.",2020-05-14,Dyfan Jones,https://github.com/DyfanJones/noctua,TRUE,https://github.com/dyfanjones/noctua,4532,11,2020-05-27T15:40:57Z,412
nodbi,"Simplified document database manipulation and analysis,
    including support for many 'NoSQL' databases, including document 
    databases ('Elasticsearch', 'CouchDB', 'MongoDB'), 
    'key-value' databases ('Redis'), and (with limitations)
    SQLite/json1.",2019-11-11,Scott Chamberlain,https://github.com/ropensci/nodbi,TRUE,https://github.com/ropensci/nodbi,7598,52,2019-12-09T13:40:54Z,146.1153846153846
nodiv,"An implementation of the nodiv algorithm, see Borregaard, M.K., Rahbek, C., Fjeldsaa, J., Parra, J.L., Whittaker, R.J. & Graham, C.H. 2014. Node-based analysis of species distributions. Methods in Ecology and Evolution 5(11): 1225-1235. <DOI:10.1111/2041-210X.12283>. Package for phylogenetic analysis of species distributions. The main function goes through each node in the phylogeny, compares the distributions of the two descendant nodes, and compares the result to a null model. This highlights nodes where major distributional divergence have occurred. The distributional divergence for these nodes is mapped using the SOS statistic.",2020-05-26,Michael Krabbe Borregaard,https://github.com/mkborregaard/nodiv,TRUE,https://github.com/mkborregaard/nodiv,20346,2,2020-05-26T11:03:09Z,10173
noisyCE2,"Cross-Entropy optimisation of unconstrained deterministic and noisy
    functions illustrated in Rubinstein and Kroese (2004, ISBN:
    978-1-4419-1940-3) through a highly flexible and customisable function which 
    allows user to define custom variable domains, sampling distributions,
    updating and smoothing rules, and stopping criteria. Several built-in
    methods and settings make the package very easy-to-use under standard
    optimisation problems.",2019-08-20,Flavio Santi,https://www.flaviosanti.it/software/noisyCE2,TRUE,https://github.com/f-santi/noisyce2,3148,0,2019-08-21T08:29:48Z,NA
nombre,"Converts numeric vectors to character vectors of
    English number names. Provides conversion to cardinals, ordinals,
    numerators, and denominators. Supports negative and non-integer
    numbers.",2020-05-25,Alexander Rossell Hayes,https://github.com/rossellhayes/nombre,TRUE,https://github.com/rossellhayes/nombre,159,0,2020-05-22T19:59:38Z,NA
nomisr,"Access UK official statistics from the 'Nomis' database. 
    'Nomis' includes data from the Census, the Labour Force Survey, DWP benefit 
    statistics and other economic and demographic data from the Office for 
    National Statistics, based around statistical geographies. See 
    <https://www.nomisweb.co.uk/api/v01/help> for full API documentation.",2020-03-02,Evan Odell,"https://github.com/ropensci/nomisr,
https://docs.evanodell.com/nomisr",TRUE,https://github.com/ropensci/nomisr,9918,22,2020-05-19T13:52:13Z,450.8181818181818
nomnoml,"A tool for drawing sassy 'UML' diagrams based on a simple syntax,
  see <http://www.nomnoml.com>. Supports styling, R Markdown and exporting diagrams 
  in the PNG format.",2020-05-26,Javier Luraschi,https://github.com/javierluraschi/nomnoml,TRUE,https://github.com/javierluraschi/nomnoml,4620,135,2020-05-26T20:38:36Z,34.22222222222222
nomogramFormula,"
  A nomogram, which can be carried out in 'rms' package, provides a 
    graphical explanation of a prediction process. However, it is not very easy
    to draw straight lines, read points and probabilities accurately. Even, it 
    is hard for users to calculate total points and probabilities for all 
    subjects.
  This package provides formula_rd() and formula_lp() functions to fit the 
    formula of total points with raw data and linear predictors respectively by
    polynomial regression. Function points_cal() will help you calculate the 
    total points. prob_cal() can be used to calculate the probabilities after
    lrm(), cph() or psm() regression. 
  For more complex condition, interaction or restricted cubic spine, TotalPoints.rms() 
    can be used.",2020-01-28,Jing Zhang,https://github.com/yikeshu0611/nomogramFormula,TRUE,https://github.com/yikeshu0611/nomogramformula,3941,0,2019-12-22T11:07:18Z,NA
nonlinearICP,"Performs 'nonlinear Invariant Causal Prediction' to estimate the 
    causal parents of a given target variable from data collected in
    different experimental or environmental conditions, extending
    'Invariant Causal Prediction' from Peters, Buehlmann and Meinshausen (2016), 
    <arXiv:1501.01332>, to nonlinear settings. For more details, see C. Heinze-Deml, 
    J. Peters and N. Meinshausen: 'Invariant Causal Prediction for Nonlinear Models', 
    <arXiv:1706.08576>.",2017-07-31,Christina Heinze-Deml,https://github.com/christinaheinze/nonlinearICP-and-CondIndTests,TRUE,https://github.com/christinaheinze/nonlinearicp-and-condindtests,9015,10,2019-11-12T14:45:32Z,901.5
nonlinearTseries,"Functions for nonlinear time series analysis. This package permits
    the computation of the  most-used nonlinear statistics/algorithms
    including generalized correlation dimension, information dimension,
    largest Lyapunov exponent, sample entropy and Recurrence
    Quantification Analysis (RQA), among others. Basic routines
    for surrogate data testing are also included. Part of this work
    was based on the  book ""Nonlinear time series analysis"" by
    Holger Kantz and Thomas Schreiber (ISBN: 9780521529020).",2020-05-03,Constantino A. Garcia,https://github.com/constantino-garcia/nonlinearTseries,TRUE,https://github.com/constantino-garcia/nonlineartseries,49468,12,2020-05-02T15:11:10Z,4122.333333333333
nonneg.cg,"Minimize a differentiable function subject to all the variables being non-negative (i.e. >= 0),
  using a Conjugate-Gradient algorithm based on a modified Polak-Ribiere-Polyak formula as described in
  (Li, Can, 2013, <https://www.hindawi.com/journals/jam/2013/986317/abs/>).",2019-09-05,David Cortes,https://github.com/david-cortes/nonneg_cg,TRUE,https://github.com/david-cortes/nonneg_cg,6353,1,2020-01-23T07:30:20Z,6353
nosoi,"The aim of 'nosoi' (pronounced no.si) is to provide a flexible agent-based stochastic transmission chain/epidemic simulator (Lequime et al. bioRxiv 2020.03.03.973107). It is named after the daimones of plague, sickness and disease that escaped Pandora's jar in the Greek mythology. 'nosoi' is able to take into account the influence of multiple variable on the transmission process (e.g. dual-host systems (such as arboviruses), within-host viral dynamics, transportation, population structure), alone or taken together, to create complex but relatively intuitive epidemiological simulations.",2020-05-12,Sebastian Lequime,https://github.com/slequime/nosoi,TRUE,https://github.com/slequime/nosoi,2771,3,2020-05-15T14:28:52Z,923.6666666666666
nowcasting,"It contains the tools to implement dynamic factor models to forecast economic variables. The user will be able to construct pseudo real time vintages, use information criteria for determining the number of factors and shocks, estimate the model, and visualize results among other things.",2019-08-01,Daiane Marcolino de Mattos,https://github.com/nmecsys/nowcasting,TRUE,https://github.com/nmecsys/nowcasting,13490,30,2019-07-12T13:04:03Z,449.6666666666667
np,"Nonparametric (and semiparametric) kernel methods that seamlessly handle a mix of continuous, unordered, and ordered factor data types. We would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <http://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <http://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <http://www.sharcnet.ca>).",2020-02-06,Jeffrey S. Racine,https://github.com/JeffreyRacine/R-Package-np,TRUE,https://github.com/jeffreyracine/r-package-np,350648,29,2020-02-06T12:22:02Z,12091.310344827587
NPflow,"Dirichlet process mixture of multivariate normal, skew normal or skew t-distributions
             modeling oriented towards flow-cytometry data preprocessing applications. Method is 
             detailed in: Hejblum, Alkhassimn, Gottardo, Caron & Thiebaut (2019) <doi: 10.1214/18-AOAS1209>.",2020-02-06,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/npflow,15631,2,2020-02-06T12:00:43Z,7815.5
nprcgenekeepr,"Provides genetic tools for colony management and is a derivation 
    of the work in Amanda Vinson and Michael J Raboin (2015) 
    <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4671785/> ""A Practical 
    Approach for Designing Breeding Groups to Maximize Genetic Diversity in a 
    Large Colony of Captive Rhesus Macaques ('Macaca' 'mulatto')"".
    It provides a 'Shiny' application with an exposed API. 
    The application supports five groups of functions: 
    (1) Quality control of studbooks contained in text files or 'Excel' 
    workbooks and of pedigrees within 'LabKey' Electronic Health Records 
    (EHR); 
    (2) Creation of pedigrees from a list of animals using the 'LabKey' EHR 
    integration; 
    (3) Creation and display of an age by sex pyramid plot of the living 
    animals within the designated pedigree; 
    (4) Generation of genetic value analysis reports; and 
    (5) Creation of potential breeding groups with and without proscribed sex 
    ratios and defined maximum kinships.",2020-06-02,R. Mark Sharp,"https://rmsharp.github.io/nprcgenekeepr/,
https://github.com/rmsharp/nprcgenekeepr",TRUE,https://github.com/rmsharp/nprcgenekeepr,0,0,2020-05-27T01:34:36Z,NA
npsurvSS,"A number of statistical tests have been proposed to compare two 
  survival curves, including the difference in (or ratio of) t-year 
  survival, difference in (or ratio of) p-th percentile survival, difference in
  (or ratio of) restricted mean survival time, and the weighted log-rank test. 
  Despite the multitude of options, the convention in survival studies is to assume
  proportional hazards and to use the unweighted log-rank test for design and 
  analysis. This package provides sample size and power 
  calculation for all of the above statistical tests with allowance for 
  flexible accrual, censoring, and survival (eg. Weibull, piecewise-exponential, 
  mixture cure). It is the companion R package to the paper by Yung and Liu (2019)
  <doi:10.1111/biom.13196>. Specific to the weighted log-rank test, users may 
  specify which approximations they wish to use to estimate the large-sample mean 
  and variance. The default option has been shown to provide substantial
  improvement over the conventional sample size and power equations based on Schoenfeld 
  (1981) <doi:10.1093/biomet/68.1.316>.",2019-12-18,Godwin Yung,http://github.com/godwinyung/npsurvSS,TRUE,https://github.com/godwinyung/npsurvss,2412,0,2019-12-16T00:12:09Z,NA
nse,Collection of functions designed to calculate numerical standard error (NSE) of univariate time series as described in Ardia et al. (2018) <doi:10.2139/ssrn.2741587> and Ardia and Bluteau (2017) <doi:10.21105/joss.00172>.,2018-09-13,Keven Bluteau,https://github.com/keblu/nse,TRUE,https://github.com/keblu/nse,13745,0,2020-04-21T04:45:13Z,NA
nse2r,"Fetch data related to stocks, index, futures & options from the 
    'NSE (National Stock Exchange, India)'. This package is community maintained 
    and is not officially supported by 'NSE'. The accuracy of data is only as 
    correct as provided on <https://www.nseindia.com>.",2020-01-08,Aravind Hebbali,"https://github.com/rsquaredacademy/nse2r,
https://nse2r.rsquaredacademy.com/",TRUE,https://github.com/rsquaredacademy/nse2r,2682,4,2020-04-13T06:56:03Z,670.5
NSO1212,National Statistical Office of Mongolia (NSO) is the national statistical service and an organization of Mongolian government. NSO provides open access and official data via its web site <http://www.1212.mn/> and API <http://opendata.1212.mn/en/doc>. The package NSO1212 has functions for accessing the API service. The functions are compatible with the API v2.0 and get data sets and its detailed informations from the API.,2020-05-13,Makhgal Ganbold,https://github.com/galaamn/NSO1212,TRUE,https://github.com/galaamn/nso1212,4762,3,2020-05-13T08:11:54Z,1587.3333333333333
nsrr,"Allows users to access data from the National Sleep
    Research Resource ('NSRR') <https://sleepdata.org/>.",2019-09-17,John Muschelli,https://github.com/muschellij2/nsrr,TRUE,https://github.com/muschellij2/nsrr,5294,3,2020-02-07T16:08:41Z,1764.6666666666667
nucim,"
    Tools for 4D nucleome imaging. 
    Quantitative analysis of the 3D nuclear landscape recorded with super-resolved fluorescence microscopy. 
    See Volker J. Schmid, Marion Cremer, Thomas Cremer (2017) <doi:10.1016/j.ymeth.2017.03.013>.",2020-05-29,Volker Schmid,https://bioimaginggroup.github.io/nucim/,TRUE,https://github.com/bioimaginggroup/nucim,11185,2,2020-05-29T11:09:59Z,5592.5
nullabor,"Tools for visual inference. Generate null data sets
    and null plots using permutation and simulation. Calculate distance metrics
    for a lineup, and examine the distributions of metrics.",2020-02-25,Di Cook,http://github.com/dicook/nullabor,TRUE,https://github.com/dicook/nullabor,25142,45,2020-02-24T22:24:09Z,558.7111111111111
nvctr,"The n-vector framework uses the normal vector to the Earth ellipsoid
  (called n-vector) as a non-singular position representation that turns out to
  be very convenient for practical position calculations.
  The n-vector is simple to use and gives exact answers for all global positions,
  and all distances, for both ellipsoidal and spherical Earth models.
  This package is a translation of the 'Matlab' library from FFI,
  the Norwegian Defence Research Establishment, as described in Gade (2010)
  <doi:10.1017/S0373463309990415>.",2019-03-07,Enrico Spinielli,https://github.com/euctrl-pru/nvctr,TRUE,https://github.com/euctrl-pru/nvctr,4696,7,2020-05-10T12:00:56Z,670.8571428571429
nycflights13,"Airline on-time data for all flights departing NYC
    in 2013.  Also includes useful 'metadata' on airlines, airports,
    weather, and planes.",2019-09-16,Hadley Wickham,http://github.com/hadley/nycflights13,TRUE,https://github.com/hadley/nycflights13,1235179,85,2019-09-16T17:29:09Z,14531.517647058823
nzilbb.labbcat,"'LaBB-CAT' is a web-based language corpus management
 system developed by the New Zealand Institute of Language, Brain
 and Behaviour (NZILBB) - see <https://labbcat.canterbury.ac.nz>.
 This package defines functions for accessing corpus data in a 'LaBB-CAT'
 instance. You must have at least version 20200108.1025 of 'LaBB-CAT'
 to use this package.
 For more information about 'LaBB-CAT', see
 Robert Fromont and Jennifer Hay (2008) <doi:10.3366/E1749503208000142>
 or 
 Robert Fromont (2017) <doi:10.1016/j.csl.2017.01.004>.",2020-01-16,Robert Fromont,"https://github.com/nzilbb/labbcat-R,
https://labbcat.canterbury.ac.nz",TRUE,https://github.com/nzilbb/labbcat-r,6169,0,2020-01-16T14:18:39Z,NA
oai,"A general purpose client to work with any 'OAI-PMH'
    (Open Archives Initiative Protocol for 'Metadata' Harvesting) service.
    The 'OAI-PMH' protocol is described at
    <http://www.openarchives.org/OAI/openarchivesprotocol.html>.
    Functions are provided to work with the 'OAI-PMH' verbs: 'GetRecord',
    'Identify', 'ListIdentifiers', 'ListMetadataFormats', 'ListRecords', and
    'ListSets'.",2019-09-07,Scott Chamberlain,https://github.com/ropensci/oai,TRUE,https://github.com/ropensci/oai,93435,9,2020-05-18T14:24:30Z,10381.666666666666
objectremover,"An 'RStudio' addin to assist with removing objects from the global environment. Features include removing objects according to name patterns and object type. During the course of an analysis, temporary objects are often created and this tool assists with removing them quickly. This can be useful when memory management within 'R' is important.",2019-06-23,Alan Yeung,https://github.com/alan-y/objectremover,TRUE,https://github.com/alan-y/objectremover,4959,1,2019-08-04T19:12:40Z,4959
oce,"Supports the analysis of Oceanographic data, including 'ADCP'
    measurements, measurements made with 'argo' floats, 'CTD' measurements,
    sectional data, sea-level time series, coastline and topographic data, etc.
    Provides specialized functions for calculating seawater properties such as
    potential temperature in either the 'UNESCO' or 'TEOS-10' equation of state.
    Produces graphical displays that conform to the conventions of the
    Oceanographic literature. This package is discussed extensively in
    Dan Kelley's book Oceanographic Analysis with R, published
    in 2018 by 'Springer-Verlag' with ISBN 978-1-4939-8842-6.",2020-02-21,Dan Kelley,https://dankelley.github.io/oce,TRUE,https://github.com/dankelley/oce,99716,82,2020-06-06T15:38:53Z,1216.0487804878048
oceanis,"Creating maps for statistical analysis such as proportional circles, chroropleth, typology and flows. Some functions use 'shiny' or 'leaflet' technologies for dynamism and interactivity.
	The great features are :
	- Create maps in a web environment where the parameters are modifiable on the fly ('shiny' and 'leaflet' technology).
	- Create interactive maps through zoom and pop-up ('leaflet' technology).
	- Create frozen maps with the possibility to add labels.",2020-06-02,Sébastien CALVET - PSAR-AT - DR Provence-Alpes-Cote dAzur - INSEE,https://github.com/insee-psar-at/oceanis-package/,TRUE,https://github.com/insee-psar-at/oceanis-package,6014,5,2020-06-02T08:51:05Z,1202.8
oceanwaves,"Calculate ocean wave height summary statistics and process data 
    from bottom-mounted pressure sensor data loggers. Derived primarily from 
    MATLAB functions provided by U. Neumeier at 
    <http://neumeier.perso.ch/matlab/waves.html>. Wave number 
    calculation based on the algorithm in Hunt, J. N. (1979, ISSN:0148-9895) 
    ""Direct Solution of Wave Dispersion Equation"", American Society of Civil 
    Engineers Journal of the Waterway, Port, Coastal, and Ocean Division, 
    Vol 105, pp 457-459.",2019-10-07,Luke Miller,"https://github.com/millerlp/oceanwaves,
https://millerlp.github.io/oceanwaves/",TRUE,https://github.com/millerlp/oceanwaves,2845,2,2020-02-05T22:13:20Z,1422.5
ocedata,"Several Oceanographic data sets are provided for use
    by the 'oce' package and for other purposes.",2020-06-06,Dan Kelley,https://dankelley.github.io/ocedata,TRUE,https://github.com/dankelley/ocedata,22375,4,2020-06-06T13:52:12Z,5593.75
ocs4R,Provides an Interface to Open Collaboration Services 'OCS' (<http://www.open-collaboration-services.org/>) REST API.,2020-03-09,Emmanuel Blondel,https://github.com/eblondel/ocs4R,TRUE,https://github.com/eblondel/ocs4r,1300,3,2020-05-28T07:27:41Z,433.3333333333333
ODB,"Functions to create, connect, update and query 'HSQL' databases embedded in Open Document Databases files, as 'OpenOffice' and 'LibreOffice' do.",2020-03-11,Sylvain Mareschal,http://bioinformatics.ovsa.fr/ODB,TRUE,https://github.com/maressyl/r.odb,18406,0,2020-05-03T10:34:48Z,NA
odbc,A DBI-compatible interface to ODBC databases.,2020-01-10,Jim Hester,https://github.com/r-dbi/odbc,TRUE,https://github.com/r-dbi/odbc,1192504,249,2020-06-02T16:45:08Z,4789.172690763052
oddsratio,"Simplified odds ratio calculation of GAM(M)s &
    GLM(M)s. Provides structured output (data frame) of all predictors and
    their corresponding odds ratios and confident intervals for further
    analyses.  It helps to avoid false references of predictors and
    increments by specifying these parameters in a list instead of using
    'exp(coef(model))' (standard approach of odds ratio calculation for
    GLMs) which just returns a plain numeric output.  For GAM(M)s, odds
    ratio calculation is highly simplified with this package since it
    takes care of the multiple 'predict()' calls of the chosen predictor
    while holding other predictors constant. Also, this package allows
    odds ratio calculation of percentage steps across the whole predictor
    distribution range for GAM(M)s.  In both cases, confident intervals
    are returned additionally. Calculated odds ratio of GAM(M)s can be
    inserted into the smooth function plot.",2020-05-24,Patrick Schratz,https://github.com/pat-s/oddsratio,TRUE,https://github.com/pat-s/oddsratio,35277,24,2020-05-25T08:54:38Z,1469.875
oddstream,"We proposes a framework that provides real time support for early detection of
    anomalous series within a large collection of streaming time series data. By definition, anomalies
    are rare in comparison to a system's typical behaviour. We define an anomaly as an observation that
    is very unlikely given the forecast distribution. The algorithm first forecasts a boundary for the
    system's typical behaviour using a representative sample of the typical behaviour of the system. An
    approach based on extreme value theory is used for this boundary prediction process. Then a sliding
    window is used to test for anomalous series within the newly arrived collection of series. Feature
    based representation of time series is used as the input to the model. To cope with concept drift,
    the forecast boundary for the system's typical behaviour is updated periodically.  More details
    regarding the algorithm can be found in Talagala, P. D., Hyndman, R. J., Smith-Miles, K., et al.
    (2019) <doi:10.1080/10618600.2019.1617160>.",2019-12-16,Priyanga Dilini Talagala,NA,TRUE,https://github.com/pridiltal/oddstream,2418,48,2020-04-02T09:12:41Z,50.375
ODEnetwork,"Simulates a network of ordinary differential equations of order
    two. The package provides an easy interface to construct networks. In addition
    you are able to define different external triggers to manipulate the trajectory.
    The method is described by Surmann, Ligges, and Weihs (2014) <doi:10.1109/ENERGYCON.2014.6850482>.",2020-04-03,Dirk Surmann,https://github.com/surmann/ODEnetwork,TRUE,https://github.com/surmann/odenetwork,7270,3,2020-04-03T12:18:16Z,2423.3333333333335
odin,"Generate systems of ordinary differential equations
    (ODE) and integrate them, using a domain specific language
    (DSL).  The DSL uses R's syntax, but compiles to C in order to
    efficiently solve the system.  A solver is not provided, but
    instead interfaces to the packages 'deSolve' and 'dde' are
    generated.  With these, while solving the differential equations,
    no allocations are done and the calculations remain entirely in
    compiled code.  Alternatively, a model can be transpiled to R for
    use in contexts where a C compiler is not present.  After
    compilation, models can be inspected to return information about
    parameters and outputs, or intermediate values after calculations.
    'odin' is not targeted at any particular domain and is suitable
    for any system that can be expressed primarily as mathematical
    expressions.  Additional support is provided for working with
    delays (delay differential equations, DDE), using interpolated
    functions during interpolation, and for integrating quantities
    that represent arrays.",2019-07-02,Rich FitzJohn,https://github.com/mrc-ide/odin,TRUE,https://github.com/mrc-ide/odin,6895,43,2020-05-28T09:37:58Z,160.34883720930233
oem,"Solves penalized least squares problems for big tall data
    using the orthogonalizing EM algorithm of Xiong et al. (2016) 
    <doi:10.1080/00401706.2015.1054436>. The main fitting function is oem() and the
    functions cv.oem() and xval.oem() are for cross validation, the latter being an
    accelerated cross validation function for linear models. The big.oem() function
    allows for out of memory fitting.",2020-06-04,Jared Huling,"https://arxiv.org/abs/1801.09661,
https://github.com/jaredhuling/oem,
https://jaredhuling.github.io/oem",TRUE,https://github.com/jaredhuling/oem,22271,14,2020-06-04T18:24:28Z,1590.7857142857142
oenb,"Tools to access data from the data web service of the Oesterreichische Nationalbank (OeNB), <https://www.oenb.at/en/Statistics/User-Defined-Tables/webservice.html>.",2020-03-19,Franz X. Mohr,https://github.com/franzmohr/oenb,TRUE,https://github.com/franzmohr/oenb,1299,0,2020-03-10T21:14:10Z,NA
officedown,"Allows production of 'Microsoft' corporate documents from 'R Markdown' by 
 reusing formatting defined in 'Microsoft Word' documents. You can reuse table styles, 
 list styles but also add column sections, landscape oriented pages. Table and image 
 captions as well as cross-references are transformed into 'Microsoft Word' fields, 
 allowing documents edition and merging without issue with references; the syntax 
 conforms to the 'bookdown' cross-reference definition. Objects generated by 
 the 'officer' package are also supported in the 'knitr' chunks. 
 'Microsoft PowerPoint' presentations also benefit from this as well as the 
 ability to produce editable vector graphics in 'PowerPoint' and also to 
 define placeholder where content is to be added.",2020-06-03,David Gohel,https://davidgohel.github.io/officedown,TRUE,https://github.com/davidgohel/officedown,0,169,2020-06-04T12:13:23Z,0
officer,"Access and manipulate 'Microsoft Word' and 'Microsoft PowerPoint' documents from R. 
  The package focuses on tabular and graphical reporting from R; it also provides two functions
  that let users get document content into data objects. A set of functions 
  lets add and remove images, tables and paragraphs of text in new or existing documents. 
  When working with 'PowerPoint' presentations, slides can be added or removed; shapes inside 
  slides can also be added or removed. When working with 'Word' documents, a cursor can be 
  used to help insert or delete content at a specific location in the document. The package 
  does not require any installation of Microsoft products to be able to write Microsoft files.",2020-05-18,David Gohel,https://davidgohel.github.io/officer,TRUE,https://github.com/davidgohel/officer,1041593,354,2020-05-23T15:47:51Z,2942.353107344633
ohenery,"Supports the modeling of ordinal random variables, 
    like the outcomes of races, via Softmax regression,
    under the Harville <doi:10.1080/01621459.1973.10482425> and
    Henery <doi:10.1111/j.2517-6161.1981.tb01153.x> models.",2019-10-15,Steven E. Pav,https://github.com/shabbychef/ohenery,TRUE,https://github.com/shabbychef/ohenery,2826,2,2019-10-15T04:32:19Z,1413
OHPL,"Ordered homogeneity pursuit lasso (OHPL)
    algorithm for group variable selection proposed in Lin et al. (2017)
    <DOI:10.1016/j.chemolab.2017.07.004>. The OHPL method exploits the
    homogeneity structure in high-dimensional data and enjoys the
    grouping effect to select groups of important variables
    automatically. This feature makes it particularly useful for
    high-dimensional datasets with strongly correlated variables,
    such as spectroscopic data.",2019-05-18,Nan Xiao,"https://ohpl.io, https://ohpl.io/doc/,
https://github.com/nanxstats/OHPL",TRUE,https://github.com/nanxstats/ohpl,10491,3,2020-04-23T22:55:01Z,3497
ohtadstats,"Calculate's Tomoka Ohta's partitioning of linkage disequilibrium,
 deemed D-statistics, for pairs of loci. Petrowski et al. (2019) <doi:10.5334/jors.250>.",2019-11-15,Paul F. Petrowski,https://github.com/pfpetrowski/OhtaDStats,TRUE,https://github.com/pfpetrowski/ohtadstats,8483,1,2019-11-15T02:55:08Z,8483
ollggamma,"Density, distribution function, quantile function and random generation for the Odd Log-Logistic Generalized Gamma proposed in Prataviera, F. et al (2017) <doi:10.1080/00949655.2016.1238088>.",2020-02-20,Matheus H. J. Saldanha,https://mjsaldanha.com/posts/ollggamma,TRUE,https://github.com/matheushjs/ollggamma,1721,0,2020-02-01T02:17:31Z,NA
olsrr,"Tools designed to make it easier for users, particularly beginner/intermediate R users 
    to build ordinary least squares regression models. Includes comprehensive regression output, 
    heteroskedasticity tests, collinearity diagnostics, residual diagnostics, measures of influence, 
    model fit assessment and variable selection procedures.",2020-02-10,Aravind Hebbali,"https://olsrr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/olsrr",TRUE,https://github.com/rsquaredacademy/olsrr,153906,84,2020-02-24T11:45:21Z,1832.2142857142858
omicwas,"In bulk epigenome/transcriptome experiments, molecular expression
    is measured in a tissue, which is a mixture of multiple types of cells.
    This package tests association of a disease/phenotype with a molecular marker
    for each cell type.
    The proportion of cell types in each sample needs to be given as input.
    The package is applicable to epigenome-wide association study (EWAS) and
    differential gene expression analysis.
    Takeuchi and Kato (submitted)
    ""omicwas: cell-type-specific epigenome-wide and transcriptome association study"".",2020-06-02,Fumihiko Takeuchi,https://github.com/fumi-github/omicwas,TRUE,https://github.com/fumi-github/omicwas,1274,0,2020-06-02T07:50:10Z,NA
omu,"Facilitates the creation of intuitive figures to describe metabolomics data by utilizing Kyoto Encyclopedia of Genes and Genomes (KEGG) hierarchy data, and gathers functional orthology and gene data using the package 'KEGGREST' to access the 'KEGG' API.",2020-05-18,Connor Tiffany,"https://github.com/connor-reid-tiffany/Omu,
https://www.kegg.jp/kegg/rest/keggapi.html",TRUE,https://github.com/connor-reid-tiffany/omu,6601,0,2020-04-22T23:30:51Z,NA
onemap,"Analysis of molecular marker data from model (backcrosses,
    F2 and recombinant inbred lines) and non-model systems (i. e.
    outcrossing species). For the later, it allows statistical
    analysis by simultaneously estimating linkage and linkage
    phases (genetic map construction) according to Wu et al. (2002)
    <doi:10.1006/tpbi.2002.1577>. All analysis are based on multipoint 
    approaches using hidden Markov models.",2020-02-17,Gabriel Margarido,https://github.com/augusto-garcia/onemap,TRUE,https://github.com/augusto-garcia/onemap,23719,17,2020-03-02T19:51:02Z,1395.235294117647
onnx,"R Interface to 'ONNX' - Open Neural Network Exchange <https://onnx.ai/>. 
             'ONNX' provides an open source format for machine learning models. 
             It defines an extensible computation graph model, as well as definitions
             of built-in operators and standard data types.",2018-04-25,Yuan Tang,https://github.com/onnx/onnx-r,TRUE,https://github.com/onnx/onnx-r,7325,27,2019-12-19T03:32:11Z,271.2962962962963
oolong,"Intended to create standard human-in-the-loop validity tests for typical automated content analysis such as topic modeling and dictionary-based methods. This package offers a standard workflow with functions to prepare, administer and evaluate a human-in-the-loop validity test. This package provides functions for validating topic models using word intrusion and Topic intrusion tests, as described in Chang et al. (2009) <https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models>. This package also provides functions for generating gold-standard data which are useful for validating dictionary-based methods. The default settings of all generated tests match those suggested in Chang et al. (2009) and Song et al. (2020) <doi:10.1080/10584609.2020.1723752>.",2020-03-21,Chung-hong Chan,https://github.com/chainsawriot/oolong,TRUE,https://github.com/chainsawriot/oolong,979,13,2020-03-20T12:51:48Z,75.3076923076923
OOR,"Implementation of optimistic optimization methods for global optimization of deterministic or stochastic functions. The algorithms feature guarantees of the convergence to a global optimum. They require minimal assumptions on the (only local) smoothness, where the smoothness parameter does not need to be known. They are expected to be useful for the most difficult functions when we have no information on smoothness and the gradients are unknown or do not exist. Due to the weak assumptions, however, they can be mostly effective only in small dimensions, for example, for hyperparameter tuning.",2020-03-23,M. Binois,http://github.com/mbinois/OOR,TRUE,https://github.com/mbinois/oor,11865,0,2020-03-23T11:55:48Z,NA
opalr,"Data integration Web application for biobanks by 'OBiBa'. 'Opal' is
    the core database application for biobanks. Participant data, once
    collected from any data source, must be integrated and stored in a central
    data repository under a uniform model. 'Opal' is such a central repository.
    It can import, process, validate, query, analyze, report, and export data.
    'Opal' is typically used in a research center to analyze the data acquired at
    assessment centres. Its ultimate purpose is to achieve seamless
    data-sharing among biobanks. This 'Opal' client allows to interact with 'Opal'
    web services and to perform operations on the R server side. 'DataSHIELD'
    administration tools are also provided.",2020-06-08,Yannick Marcon,"https://www.obiba.org/ https://www.obiba.org/pages/products/opal/
https://doi.org/10.1093/ije/dyx180 http://www.datashield.ac.uk/",TRUE,https://github.com/obiba/opalr,8141,1,2020-06-08T08:04:12Z,8141
openair,"Tools to analyse, interpret and understand air
    pollution data. Data are typically hourly time series
    and both monitoring data and dispersion model output
    can be analysed.  Many functions can also be applied to
    other data, including meteorological and traffic data.",2020-04-02,David Carslaw,http://davidcarslaw.github.io/openair/,TRUE,https://github.com/davidcarslaw/openair,194876,153,2020-06-09T15:34:27Z,1273.6993464052287
opencage,"Tool for accessing the OpenCage API, which provides forward
    geocoding (from placename to longitude and latitude) and reverse geocoding (from
    longitude and latitude to placename).",2018-01-16,Maëlle Salmon,http://github.com/ropensci/opencage,TRUE,https://github.com/ropensci/opencage,16148,72,2019-12-09T21:20:46Z,224.27777777777777
opencastR,Query the external API of a 'Opencast' video management server for information related to the recorded videos. For more information about 'Opencast' see: <https://opencast.org>.,2020-03-19,Daniel Ebbert,http://opencastr.ebbert.nrw/,TRUE,https://github.com/ebbertd/opencastr,2807,0,2020-03-19T11:24:17Z,NA
opencv,"Experimenting with computer vision and machine learning in R. This 
    package exposes some of the available 'OpenCV' vision algorithms, such as edge, 
    body or face detection. These can either be applied to analyze static images,
    or to filter live video footage from a camera device.",2019-04-01,Jeroen Ooms,https://github.com/ropensci/opencv,TRUE,https://github.com/ropensci/opencv,9795,87,2020-05-16T11:02:18Z,112.58620689655173
opendatatoronto,"Access data from the ""City of Toronto
    Open Data Portal"" (<https://open.toronto.ca>) directly from R.",2020-03-29,Sharla Gelfand,"https://sharlagelfand.github.io/opendatatoronto/,
https://github.com/sharlagelfand/opendatatoronto/",TRUE,https://github.com/sharlagelfand/opendatatoronto,3981,46,2020-06-04T15:07:03Z,86.54347826086956
OpenImageR,"Incorporates functions for image preprocessing, filtering and image recognition. The package takes advantage of 'RcppArmadillo' to speed up computationally intensive functions. The histogram of oriented gradients descriptor is a modification of the 'findHOGFeatures' function of the 'SimpleCV' computer vision platform, the average_hash(), dhash() and phash() functions are based on the 'ImageHash' python library. The Gabor Feature Extraction functions are based on 'Matlab' code of the paper, ""CloudID: Trustworthy cloud-based and cross-enterprise biometric identification"" by M. Haghighat, S. Zonouz, M. Abdel-Mottaleb, Expert Systems with Applications, vol. 42, no. 21, pp. 7905-7916, 2015, <doi:10.1016/j.eswa.2015.06.025>. The 'SLIC' and 'SLICO' superpixel algorithms were explained in detail in (i) ""SLIC Superpixels Compared to State-of-the-art Superpixel Methods"", Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Suesstrunk, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, num. 11, p. 2274-2282, May 2012, <doi:10.1109/TPAMI.2012.120> and (ii) ""SLIC Superpixels"", Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Suesstrunk, EPFL Technical Report no. 149300, June 2010.",2019-12-01,Lampros Mouselimis,https://github.com/mlampros/OpenImageR,TRUE,https://github.com/mlampros/openimager,80494,41,2019-12-04T15:25:02Z,1963.2682926829268
OpenLand,"Tools for the analysis of land use and cover (LUC) time series. It 
    includes support for loading spatiotemporal raster data and synthesized 
    spatial plotting. Several LUC change (LUCC) metrics in regular or irregular 
    time intervals can be extracted and visualized through one- and multistep 
    sankey and chord diagrams. A complete intensity analysis according to 
    Aldwaik and Pontius (2012) <doi:10.1016/j.landurbplan.2012.02.010> is 
    implemented, including tools for the generation of standardized multilevel 
    output graphics.",2020-04-19,Reginal Exavier,https://github.com/reginalexavier/OpenLand,TRUE,https://github.com/reginalexavier/openland,1129,1,2020-04-29T06:38:43Z,1129
openmetrics,"Provides a client for the open-source monitoring and alerting
  toolkit, 'Prometheus', that emits metrics in the 'OpenMetrics' format. Allows
  users to automatically instrument 'Plumber' and 'Shiny' applications, collect
  standard process metrics, as well as define custom counter, gauge, and
  histogram metrics of their own.",2020-04-23,Aaron Jacobs,https://github.com/atheriel/openmetrics,TRUE,https://github.com/atheriel/openmetrics,960,1,2020-04-23T16:55:24Z,960
OpenML,"We provide an R interface to 'OpenML.org' which is an online machine learning platform where researchers can access open data, download and upload data sets, share their machine learning tasks and experiments and organize them online to work and collaborate with other researchers. 
    The R interface allows to query for data sets with specific properties, and allows the downloading and uploading of data sets, tasks, flows and runs. 
    See <https://www.openml.org/guide/api> for more information.",2019-09-21,Giuseppe Casalicchio,https://github.com/openml/openml-r,TRUE,https://github.com/openml/openml-r,22420,77,2019-10-16T13:54:36Z,291.16883116883116
OpenMx,"Create structural equation models that can be manipulated programmatically.
    Models may be specified with matrices or paths (LISREL or RAM)
    Example models include confirmatory factor, multiple group, mixture
    distribution, categorical threshold, modern test theory, differential
    Fit functions include full information maximum likelihood, maximum likelihood, and weighted least squares.
    equations, state space, and many others.
	Support and advanced package binaries available at <http://openmx.ssri.psu.edu>.
    The software is described in Neale, Hunter, Pritikin, Zahery, Brick,
    Kirkpatrick, Estabrook, Bates, Maes, & Boker (2016) <doi:10.1007/s11336-014-9435-8>.",2020-06-07,Joshua N. Pritikin,"http://openmx.ssri.psu.edu, https://github.com/OpenMx/OpenMx",TRUE,https://github.com/openmx/openmx,439267,52,2020-06-07T19:38:36Z,8447.442307692309
OpenRepGrid,"Analyze repertory grids, a qualitative-quantitative 
    data collection technique devised by George A. Kelly in the 1950s. Today, grids are used across 
    various domains ranging from clinical psychology to marketing. The package contains
    functions to quantitatively analyze and visualize repertory grid data 
    (see e.g. Bell, 2005, <doi:10.1002/0470013370.ch9>; 
    Fransella, Bell, & Bannister, 2004, ISBN: 978-0-470-09080-0).",2018-05-31,Mark Heckmann,"http://openrepgrid.org,
https://github.com/markheckmann/OpenRepGrid",TRUE,https://github.com/markheckmann/openrepgrid,19187,12,2020-06-01T12:48:48Z,1598.9166666666667
openSTARS,"An open source implementation of the 'STARS' toolbox
    (Peterson & Ver Hoef, 2014, <doi:10.18637/jss.v056.i02>) using 'R' and 'GRASS GIS'.
    It prepares the *.ssn object needed for the 'SSN' package.
    A Digital Elevation Model (DEM) is used to derive stream networks 
    (in contrast to 'STARS' that can clean an existing stream network).",2020-05-21,Mira Kattwinkel,https://github.com/MiKatt/openSTARS,TRUE,https://github.com/mikatt/openstars,9065,20,2020-05-21T19:16:19Z,453.25
opentripplanner,"Setup and connect to 'OpenTripPlanner' (OTP) <http://www.opentripplanner.org/>.
    OTP is an open source platform for multi-modal and multi-agency
    journey planning written in 'Java'. The package allows you to manage a local version or 
    connect to remote OTP server.
    This package has been peer-reviewed by rOpenSci (v. 0.2.0.0).",2020-06-09,Malcolm Morgan,"https://github.com/ropensci/opentripplanner,
https://docs.ropensci.org/opentripplanner/",TRUE,https://github.com/ropensci/opentripplanner,3008,44,2020-06-09T12:56:13Z,68.36363636363636
openVA,"Implements multiple existing open-source algorithms for coding cause of death from verbal autopsies. The methods implemented include 'InterVA4' by Byass et al (2012) <doi:10.3402/gha.v5i0.19281>, 'InterVA5' by Byass at al (2019) <doi:10.1186/s12916-019-1333-6>, 'InSilicoVA' by McCormick et al (2016) <doi:10.1080/01621459.2016.1152191>, 'NBC' by Miasnikof et al (2015) <doi:10.1186/s12916-015-0521-2>, and a replication of 'Tariff' method by James et al (2011) <doi:10.1186/1478-7954-9-31> and Serina, et al. (2015) <doi:10.1186/s12916-015-0527-9>. It also provides tools for data manipulation tasks commonly used in Verbal Autopsy analysis and implements easy graphical visualization of individual and population level statistics. The 'NBC' method is implemented by the 'nbc4va' package that can be installed from <https://github.com/rrwen/nbc4va>. Note that this package was not developed by authors affiliated with the Institute for Health Metrics and Evaluation and thus unintentional discrepancies may exist in the implementation of the 'Tariff' method.",2020-05-04,Zehang Richard Li,https://github.com/verbal-autopsy-software/openVA,TRUE,https://github.com/verbal-autopsy-software/openva,18359,0,2020-05-10T03:19:33Z,NA
openxlsx,"Simplifies the creation of Excel .xlsx files by
    providing a high level interface to writing, styling and editing
    worksheets. Through the use of 'Rcpp', read/write times are comparable
    to the 'xlsx' and 'XLConnect' packages with the added benefit of
    removing the dependency on Java.",2020-05-06,Philipp Schauberger,"https://ycphs.github.io/openxlsx/index.html,
https://github.com/ycphs/openxlsx",TRUE,https://github.com/ycphs/openxlsx,4997063,47,2020-05-19T08:30:20Z,106320.48936170213
opera,"Misc methods to form online predictions, for regression-oriented 
    time-series, by combining a finite set of forecasts provided by the user. See 
             Cesa-Bianchi and Lugosi (2006) <doi:10.1017/CBO9780511546921> for an overview. ",2020-03-18,Pierre Gaillard,http://pierre.gaillard.me/opera.html,TRUE,https://github.com/dralliag/opera,19347,23,2020-03-18T11:12:51Z,841.1739130434783
oppr,"A decision support tool for prioritizing conservation projects.
    Prioritizations can be developed by maximizing expected feature richness,
    expected phylogenetic diversity, the number of features that meet
    persistence targets, or identifying a set of projects that meet persistence
    targets for minimal cost. Constraints (e.g. lock in specific actions) and
    feature weights can also be specified to further customize prioritizations.
    After defining a project prioritization problem, solutions can be obtained
    using exact algorithms, heuristic algorithms, or random processes. In
    particular, it is recommended to install the 'Gurobi' optimizer (available
    from <https://www.gurobi.com>) because it can identify optimal solutions
    very quickly. Finally, methods are provided for comparing different
    prioritizations and evaluating their benefits. For more information, see
    Hanson et al. (2019) <doi:10.1111/2041-210X.13264>.",2020-05-20,Jeffrey O Hanson,"https://prioritizr.github.io/oppr,
https://github.com/prioritizr/oppr",TRUE,https://github.com/prioritizr/oppr,6978,4,2020-05-19T21:04:47Z,1744.5
OptimClassifier,"Patterns searching and binary classification in economic and financial data is a
              large field of research. There are a large part of the data
              that the target variable is binary. Nowadays, many methodologies
              are used, this package collects most popular and compare different
              configuration options for Linear Models (LM), Generalized Linear Models (GLM), 
              Linear Mixed Models (LMM), Discriminant Analysis (DA), 
              Classification And Regression Trees (CART), Neural Networks (NN) and Support Vector Machines (SVM).",2020-01-14,Agustin Perez-Martin,https://economistgame.github.io/OptimClassifier,TRUE,https://github.com/economistgame/optimclassifier,11809,2,2020-01-01T10:38:45Z,5904.5
optmatch,"Distance based bipartite matching using the RELAX-IV minimum cost flow solver,
    oriented to matching of treatment and control groups in observational
    studies. Routines are provided to generate distances from generalised linear models (propensity
    score matching), formulas giving variables on which to limit matched distances, stratified or
    exact matching directives, or calipers, alone or in combination.",2019-12-06,Ben B. Hansen,https://github.com/markmfredrickson/optmatch,TRUE,https://github.com/markmfredrickson/optmatch,183969,26,2020-06-05T20:20:24Z,7075.7307692307695
optparse,"A command line parser inspired by Python's 'optparse' library to
    be used with Rscript to write ""#!"" shebang scripts that accept short and
    long flag/options.",2020-04-16,Trevor L Davis,https://github.com/trevorld/r-optparse,TRUE,https://github.com/trevorld/r-optparse,383484,95,2020-04-16T18:13:10Z,4036.6736842105265
orderly,"Order, create and store reports from R.  By defining a
    lightweight interface around the inputs and outputs of an
    analysis, a lot of the repetitive work for reproducible research
    can be automated.  We define a simple format for organising and
    describing work that facilitates collaborative reproducible
    research and acknowledges that all analyses are run multiple
    times over their lifespans.",2020-01-12,Rich FitzJohn,https://github.com/vimc/orderly,TRUE,https://github.com/vimc/orderly,3731,79,2020-06-09T11:14:24Z,47.22784810126582
ordinal,"Implementation of cumulative link (mixed) models also known
    as ordered regression models, proportional odds models, proportional
    hazards models for grouped survival times and ordered logit/probit/...
    models. Estimation is via maximum likelihood and mixed models are fitted
    with the Laplace approximation and adaptive Gauss-Hermite quadrature.
    Multiple random effect terms are allowed and they may be nested, crossed or
    partially nested/crossed. Restrictions of symmetry and equidistance can be
    imposed on the thresholds (cut-points/intercepts). Standard model
    methods are available (summary, anova, drop-methods, step,
    confint, predict etc.) in addition to profile methods and slice
    methods for visualizing the likelihood function and checking
    convergence.",2019-12-15,Rune Haubo Bojesen Christensen,https://github.com/runehaubo/ordinal,TRUE,https://github.com/runehaubo/ordinal,890097,11,2020-05-11T06:37:44Z,80917.90909090909
ore,"Provides an alternative to R's built-in functionality for handling
    regular expressions, based on the Onigmo library. Offers first-class
    compiled regex objects, partial matching and function-based substitutions,
    amongst other features.",2019-11-02,Jon Clayden,https://github.com/jonclayden/ore,TRUE,https://github.com/jonclayden/ore,137114,53,2019-11-01T09:29:28Z,2587.056603773585
orf,"An implementation of the Ordered Forest estimator as developed 
    in Lechner & Okasa (2019) <arXiv:1907.02436>. The Ordered Forest flexibly
    estimates the conditional probabilities of models with ordered categorical
    outcomes (so-called ordered choice models). Additionally to common machine 
    learning algorithms the 'orf' package provides functions for estimating
    marginal effects as well as statistical inference thereof and thus provides
    similar output as in standard econometric models for ordered choice. The
    core forest algorithm relies on the fast C++ forest implementation from
    the 'ranger' package (Wright & Ziegler, 2017) <arXiv:1508.04409>.",2020-01-31,Gabriel Okasa,https://github.com/okasag/orf,TRUE,https://github.com/okasag/orf,2641,5,2020-02-07T10:08:13Z,528.2
origami,"A general framework for the application of cross-validation schemes
    to particular functions. By allowing arbitrary lists of results, origami
    accommodates a range of cross-validation applications.",2020-01-16,Jeremy Coyle,https://tlverse.org/origami,TRUE,https://github.com/tlverse/origami,12689,20,2020-01-16T22:21:51Z,634.45
originr,"Get species origin data (whether species is native/invasive) from the
    following sources on the web: Encyclopedia of Life (<http://eol.org>), Flora
    'Europaea' (<http://rbg-web2.rbge.org.uk/FE/fe.html>), Global Invasive Species
    Database (<http://www.iucngisd.org/gisd>), the Native Species Resolver
    (<http://bien.nceas.ucsb.edu/bien/tools/nsr/nsr-ws/>), Integrated Taxonomic
    Information Service (<http://www.itis.gov/>), and Global Register of
    Introduced and Invasive Species (<http://www.griis.org/>).",2018-04-30,Scott Chamberlain,https://github.com/ropensci/originr,TRUE,https://github.com/ropensci/originr,12808,14,2020-06-03T21:21:31Z,914.8571428571429
oro.nifti,"Functions for the input/output and visualization of
    medical imaging data that follow either the 'ANALYZE', 'NIfTI' or 'AFNI'
    formats.  This package is part of the Rigorous Analytics bundle.",2020-06-08,Brandon Whitcher,"http://rig.oro.us.com, http://rigorousanalytics.blogspot.com",TRUE,https://github.com/bjw34032/oro.nifti,79830,1,2020-06-08T13:33:53Z,79830
osfr,"An interface for interacting with 'OSF' (<https://osf.io>). 'osfr' 
    enables you to access open research materials and data, or create and
    manage your own private or public projects.",2020-02-17,Aaron Wolen,"https://docs.ropensci.org/osfr, https://github.com/ropensci/osfr",TRUE,https://github.com/ropensci/osfr,2216,109,2020-02-18T17:19:34Z,20.3302752293578
osmose,"The multispecies and individual-based model (IBM) 'OSMOSE'
  (Shin and Curry (2001) <doi:10.1016/S0990-7440(01)01106-8> and Shin and Curry 
  (2004) <doi:10.1139/f03-154>) focuses on fish species. This model assumes 
  opportunistic predation based on spatial co-occurrence and size adequacy 
  between a predator and its prey (size-based opportunistic predation). It
  represents fish individuals grouped into schools, which are characterized by 
  their size, weight, age, taxonomy and geographical location (2D model), and 
  which undergo major processes of fish life cycle (growth, explicit predation, 
  natural and starvation mortalities, reproduction and migration) and fishing 
  exploitation. The model needs basic biological parameters that are often 
  available for a wide range of species, and which can be found in 'FishBase' 
  for instance (see <http://www.fishbase.org/search.php>), and fish spatial 
  distribution data. This package provides tools to build and run simulations 
  using the 'OSMOSE' model.",2020-04-28,Nicolas Barrier,http://www.osmose-model.org/,TRUE,https://github.com/osmose-model/osmose,8330,3,2020-04-28T09:07:02Z,2776.6666666666665
osmplotr,"Bespoke images of 'OpenStreetMap' ('OSM') data and data
    visualisation using 'OSM' objects.",2018-12-19,Mark Padgham,https://github.com/ropensci/osmplotr,TRUE,https://github.com/ropensci/osmplotr,18073,120,2020-02-24T16:39:24Z,150.60833333333332
OSMscale,"Functionality to handle and project lat-long coordinates, easily download background maps
    and add a correct scale bar to 'OpenStreetMap' plots in any map projection.",2017-04-12,Berry Boessenkool,https://github.com/brry/OSMscale,TRUE,https://github.com/brry/osmscale,13279,1,2019-09-03T23:13:44Z,13279
osrm,"An interface between R and the OSRM API. OSRM is a routing
    service based on OpenStreetMap data. See <http://project-osrm.org/> for more
    information. This package allows to compute distances (travel time and 
    kilometric distance) between points and travel time matrices.",2020-04-14,Timothée Giraud,https://github.com/rCarto/osrm,TRUE,https://github.com/rcarto/osrm,38860,119,2020-04-14T12:33:57Z,326.5546218487395
otp,"Generating and validating One-time Password based on 
    Hash-based Message Authentication Code (HOTP) 
    and Time Based One-time Password (TOTP)
    according to RFC 4226 <https://tools.ietf.org/html/rfc4226> and
    RFC 6238 <https://tools.ietf.org/html/rfc6238>.",2020-05-05,Randy Lai,https://github.com/randy3k/otp,TRUE,https://github.com/randy3k/otp,489,8,2020-05-06T20:35:54Z,61.125
otsad,"Implements a set of online fault detectors for time-series, called: PEWMA see M. Carter
             et al. (2012) <doi:10.1109/SSP.2012.6319708>, SD-EWMA and TSSD-EWMA see H. Raza et al. 
             (2015) <doi:10.1016/j.patcog.2014.07.028>, KNN-CAD see E. Burnaev et al. (2016)
             <arXiv:1608.04585>, KNN-LDCD see V. Ishimtsev et al. (2017) <arXiv:1706.03412> and 
             CAD-OSE see M. Smirnov (2018) <https://github.com/smirmik/CAD>. The first three 
             algorithms belong to prediction-based techniques and the last three belong to 
             window-based techniques. In addition, the SD-EWMA and PEWMA algorithms are algorithms 
             designed to work in stationary environments, while the other four 
             are algorithms designed to work in non-stationary environments.",2019-09-06,Alaiñe Iturria,https://github.com/alaineiturria/otsad,TRUE,https://github.com/alaineiturria/otsad,6223,12,2019-09-06T11:13:26Z,518.5833333333334
otuSummary,"Summarizes the taxonomic composition, diversity contribution of the rare and abundant community by using OTU (operational taxonomic unit) table which was generated by analyzing pipeline of 'QIIME' or 'mothur'. The rare biosphere in this package is subset by the relative abundance threshold (for details about rare biosphere please see Lynch and Neufeld (2015) <doi:10.1038/nrmicro3400>).",2020-03-31,Sizhong Yang,https://github.com/cam315/otuSummary,TRUE,https://github.com/cam315/otusummary,7070,0,2020-03-29T20:51:06Z,NA
outbreaks,"Empirical or simulated disease outbreak data, provided either as
    RData or as text files.",2019-01-21,Finlay Campbell,https://github.com/reconhub/outbreaks,TRUE,https://github.com/reconhub/outbreaks,23295,39,2020-04-27T08:03:25Z,597.3076923076923
outcomerate,"Standardized survey outcome rate functions, including the response rate, contact rate, cooperation rate, and refusal rate. These outcome rates allow survey researchers to measure the quality of survey data using definitions published by the American Association of Public Opinion Research (AAPOR). For details on these standards, see AAPOR (2016) <https://www.aapor.org/Standards-Ethics/Standard-Definitions-(1).aspx>. ",2018-10-06,Rafael Pilliard Hellwig,https://github.com/ropensci/outcomerate,TRUE,https://github.com/ropensci/outcomerate,5806,5,2020-05-16T22:30:24Z,1161.2
outForest,"Provides a random forest based implementation of
    the method described in Chapter 7.1.2 (Regression model based anomaly
    detection) of Chandola et al. (2009)
    <doi.acm.org/10.1145/1541880.1541882>. It works as follows: Each
    numeric variable is regressed onto all other variables by a random
    forest. If the scaled absolute difference between observed value and
    out-of-bag prediction of the corresponding random forest is
    suspiciously large, then a value is considered an outlier. The package
    offers different options to replace such outliers, e.g. by realistic
    values found via predictive mean matching. Once the method is trained
    on a reference data, it can be applied to new data.",2020-01-13,Michael Mayer,https://github.com/mayer79/outForest,TRUE,https://github.com/mayer79/outforest,2079,3,2020-01-09T18:21:19Z,693
outliertree,"Will try to fit decision trees that try to ""predict"" values for each column based on the values of each other column.
	Along the way, each time a split is evaluated, it will take the observations that fall into each branch as a homogeneous
	cluster in which it will search for outliers in the 1-d distribution of the column being predicted. Outliers are determined
	according to confidence intervals in this 1-d distribution, and need to have a large gap with respect to the next observation
	in sorted order to be flagged as outliers. Since outliers are searched for in a decision tree branch, it will know the conditions
	that make it a rare observation compared to others that meet the same conditions, and the conditions will always be correlated
	with the target variable (as it's being predicted from them). Full procedure is described in Cortes (2020) <arXiv:2001.00636>.
	Loosely based on the 'GritBot' <https://www.rulequest.com/gritbot-info.html> software.",2020-04-19,David Cortes,https://github.com/david-cortes/outliertree,TRUE,https://github.com/david-cortes/outliertree,4854,17,2020-06-07T15:36:33Z,285.52941176470586
ouxy,"Performs statistical inference on the models of adaptive trait evolution under approximate Bayesian computation. This can simulate traits from four models, compute trait data summary statistics. Parameters are estimated under Approximate Bayesian Computation, model selection as well as posterior parameter mean will be reported. Users need to enter a comparative dataset and a phylogenetic tree.",2020-05-28,Dwueng-Chwuan Jhwueng,NA,TRUE,https://github.com/djhwueng/ououcir,2947,0,2019-09-16T03:28:36Z,NA
overlap,"Provides functions to fit kernel density functions to
 data on temporal activity patterns of animals; estimate coefficients
 of overlapping of densities for two species; and calculate bootstrap
 estimates of confidence intervals.",2020-05-22,Mike Meredith and Martin Ridout,NA,TRUE,https://github.com/mikemeredith/overlap,41983,0,2020-05-09T03:11:17Z,NA
overture,"Simplifies MCMC setup by automatically looping through sampling 
    functions and saving the results.  Reduces the memory footprint of running 
    MCMC and saves samples to disk as the chain runs.  Allows samples from the 
    chain to be analyzed while the MCMC is still running.  Provides functions 
    for commonly performed operations such as calculating Metropolis acceptance 
    ratios and creating adaptive Metropolis samplers.  References: Roberts and 
    Rosenthal (2009) <doi:10.1198/jcgs.2009.06134>.",2019-08-10,Kurtis Shuler,https://github.com/kurtis-s/overture,TRUE,https://github.com/kurtis-s/overture,6482,3,2019-08-10T04:53:20Z,2160.6666666666665
owdbr,Tools for collecting municipal-level data <http://www.transparencia.gov.br/swagger-ui.html> from several Brazilian governmental social programs.,2019-11-11,Joao Pedro Oliveira dos Santos,https://github.com/kimjoaoun/owdbr,TRUE,https://github.com/kimjoaoun/owdbr,5663,10,2019-08-15T20:30:35Z,566.3
OwenQ,"Evaluates the Owen Q-function for an integer value of the degrees of freedom, by applying Owen's algorithm (1965) <doi:10.1093/biomet/52.3-4.437>. 
    It is useful for the calculation of the power of equivalence tests. ",2020-01-08,Stéphane Laurent,https://github.com/stla/OwenQ,TRUE,https://github.com/stla/owenq,3981,0,2019-12-21T08:40:37Z,NA
owmr,"Accesses OpenWeatherMap's (owm) <https://openweathermap.org/> API.
   'owm' itself is a service providing weather data in the past, in the future and now.
   Furthermore, 'owm' serves weather map layers usable in frameworks like 'leaflet'.
   In order to access the API, you need to sign up for an API key. There are free and paid plans.
   Beside functions for fetching weather data from 'owm', 'owmr' supplies
   tools to tidy up fetched data (for fast and simple access) and to show it on leaflet maps.",2020-01-11,Stefan Kuethe,"https://github.com/crazycapivara/owmr/,
https://crazycapivara.github.io/owmr/",TRUE,https://github.com/crazycapivara/owmr,12903,18,2020-04-20T17:42:11Z,716.8333333333334
ows4R,"Provides an Interface to Web-Services defined as standards by the Open Geospatial Consortium (OGC), including Web Feature Service
 (WFS) for vector data, Catalogue Service (CSW) for ISO/OGC metadata and associated standards such as the common web-service specification (OWS) and
 OGC Filter Encoding. The long-term purpose is to add support for additional OGC service standards such as Web Coverage Service (WCS) and
 Web Processing Service (WPS).",2020-05-27,Emmanuel Blondel,"https://github.com/eblondel/ows4R,
http://www.opengeospatial.org/standards",TRUE,https://github.com/eblondel/ows4r,10326,9,2020-05-27T13:41:50Z,1147.3333333333333
ozmaps,"Maps of Australian coastline and administrative regions. Data 
 can be drawn or accessed directly as simple features objects. Includes
 simple functions for country or state maps of Australia and in-built data
 sets of administrative regions from the Australian Bureau of Statistics 
 <https://www.abs.gov.au/>. Layers include electoral divisions and local 
 government areas, simplified from the original sources but with sufficient 
 detail to allow mapping of a local municipality. ",2020-04-02,Michael Sumner,https://github.com/mdsumner/ozmaps,TRUE,https://github.com/mdsumner/ozmaps,3733,5,2020-04-02T11:49:58Z,746.6
packageDiff,"It provides utility functions for investigating changes within R
    packages. The pkgInfo() function extracts package information such as
    exported and non-exported functions as well as their arguments. The
    pkgDiff() function compares this information for two versions of a package
    and creates a diff file viewable in a browser.",2020-01-16,Cole Beck,https://github.com/couthcommander/packageDiff,TRUE,https://github.com/couthcommander/packagediff,2106,1,2020-04-06T20:25:10Z,2106
packagefinder,"Search for R packages on CRAN directly from the R console, based on the packages' titles, short and long descriptions, or other fields. Combine multiple keywords with logical operators ('and', 'or'), view detailed information on any package and keep track of the latest package contributions to CRAN.",2020-03-31,Joachim Zuckarelli,"https://github.com/jsugarelli/packagefinder/,
http://www.zuckarelli.de/packagefinder/tutorial.html,
https://youtu.be/B96NMSo3nJI",TRUE,https://github.com/jsugarelli/packagefinder,12552,30,2020-03-16T21:06:57Z,418.4
packageRank,"Compute and visualize the cross-sectional and longitudinal number
    and rank percentile of package downloads from RStudio's CRAN mirror.",2020-05-08,Peter Li,https://github.com/lindbrook/packageRank,TRUE,https://github.com/lindbrook/packagerank,4746,12,2020-06-09T14:15:45Z,395.5
packrat,"Manage the R packages your project depends
    on in an isolated, portable, and reproducible way.",2018-11-14,Kevin Ushey,https://github.com/rstudio/packrat/,TRUE,https://github.com/rstudio/packrat,2529624,340,2020-04-10T20:05:58Z,7440.070588235294
pacman,"Tools to more conveniently perform tasks associated with
        add-on packages. pacman conveniently wraps library and package
        related functions and names them in an intuitive and consistent
        fashion.  It seeks to combine functionality from lower level
        functions which can speed up workflow.",2019-03-11,Tyler Rinker,https://github.com/trinker/pacman,TRUE,https://github.com/trinker/pacman,706142,196,2020-05-15T02:33:39Z,3602.765306122449
Pade,"Given a vector of Taylor series coefficients of sufficient length as input, the function returns the numerator and denominator coefficients for the Padé approximant of appropriate order (Baker, 1975) <ISBN:9780120748556>.",2020-06-02,Avraham Adler,https://github.com/aadler/Pade,TRUE,https://github.com/aadler/pade,16241,0,2020-06-02T05:15:09Z,NA
padr,"Transforms datetime data into a format ready for analysis.
    It offers two core functionalities; aggregating data to a higher level interval
    (thicken) and imputing records where observations were absent (pad). ",2020-05-12,Edwin Thoen,https://github.com/EdwinTh/padr,TRUE,https://github.com/edwinth/padr,430004,109,2020-05-12T07:47:46Z,3944.9908256880735
PAFit,Statistical methods for estimating preferential attachment and node fitness generative mechanisms in temporal complex networks are provided. Thong Pham et al. (2015) <doi:10.1371/journal.pone.0137796>. Thong Pham et al. (2016) <doi:10.1038/srep32558>. Thong Pham et al. (2020) <doi:10.18637/jss.v092.i03>. ,2020-02-17,Thong Pham,https://github.com/thongphamthe/PAFit,TRUE,https://github.com/thongphamthe/pafit,33968,9,2020-02-19T04:59:50Z,3774.222222222222
pagedown,"Use the paged media properties in CSS and the JavaScript
  library 'paged.js' to split the content of an HTML document into discrete
  pages. Each page can have its page size, page numbers, margin boxes, and
  running headers, etc. Applications of this package include books, letters,
  reports, papers, business cards, resumes, and posters.",2020-05-04,Yihui Xie,https://github.com/rstudio/pagedown,TRUE,https://github.com/rstudio/pagedown,29731,511,2020-05-04T23:17:09Z,58.18199608610568
pagenum,A simple way to add page numbers to base/ggplot/lattice graphics.,2017-07-13,Kevin Wright,https://github.com/kwstat/pagenum,TRUE,https://github.com/kwstat/pagenum,13310,0,2019-09-13T17:52:42Z,NA
pairwiseComparisons,"Multiple pairwise comparison tests on tidy data for
    one-way analysis of variance for both between-subjects and
    within-subjects designs. Currently, it supports only the most common
    types of statistical analyses and tests: parametric (Welch's and
    Student's t-test), nonparametric (Durbin-Conover test Dunn test),
    robust (Yuen’s trimmed means test), and Bayes Factor (Student's
    t-test).",2020-05-29,Indrajeet Patil,"https://indrajeetpatil.github.io/pairwiseComparisons/,
https://github.com/IndrajeetPatil/pairwiseComparisons",TRUE,https://github.com/indrajeetpatil/pairwisecomparisons,29379,22,2020-06-07T20:52:31Z,1335.409090909091
pak,"The goal of 'pak' is to make package installation faster and
    more reliable. In particular, it performs all HTTP operations in parallel,
    so metadata resolution and package downloads are fast. Metadata and package
    files are cached on the local disk as well. 'pak' has a dependency solver,
    so it finds version conflicts before performing the installation. This
    version of 'pak' supports CRAN, 'Bioconductor' and 'GitHub' packages as well.",2019-02-19,Gábor Csárdi,https://pak.r-lib.org/,TRUE,https://github.com/r-lib/pak,9407,212,2020-03-23T15:27:00Z,44.37264150943396
palaeoSig,"Several tests of quantitative palaeoenvironmental reconstructions 
  from microfossil assemblages, including the null model tests of the 
  statistically significant of reconstructions developed by Telford and Birks
  (2011) <doi:10.1016/j.quascirev.2011.03.002>, and tests of the effect of 
  spatial autocorrelation on transfer function model performance using methods 
  from Telford and Birks (2009) <doi:10.1016/j.quascirev.2008.12.020> and 
  Trachsel and Telford (2016) <doi:10.5194/cp-12-1215-2016>. Age-depth models with 
  generalized mixed-effect regression from Heegaard et al (2005)
  <doi:10.1191/0959683605hl836rr> are also included.",2019-06-28,Richard Telford,https://github.com/richardjtelford/palaeoSig,TRUE,https://github.com/richardjtelford/palaeosig,15407,0,2019-12-24T21:56:49Z,NA
palasso,"Implements sparse regression with paired covariates (Rauschenberger et al. 2019 <doi:10.1007/s11634-019-00375-6>). For the optional shrinkage, install ashr (<https://github.com/stephens999/ashr>) and CorShrink (<https://github.com/kkdey/CorShrink>) from GitHub (see README).",2019-11-19,Armin Rauschenberger,https://github.com/rauschenberger/palasso,TRUE,https://github.com/rauschenberger/palasso,9458,1,2020-05-25T08:20:31Z,9458
paleobioDB,"Includes 19 functions to wrap each endpoint of
    the PaleobioDB API, plus 8 functions to visualize and process the fossil
    data. The API documentation for the Paleobiology Database can be found in
    <http://paleobiodb.org/data1.1/>.",2019-02-26,Sara Varela,https://github.com/ropensci/paleobioDB,TRUE,https://github.com/ropensci/paleobiodb,19379,28,2019-12-09T13:46:12Z,692.1071428571429
paleotree,"Provides tools for transforming, a posteriori time-scaling, and
    modifying phylogenies containing extinct (i.e. fossil) lineages. In particular,
    most users are interested in the functions timePaleoPhy, bin_timePaleoPhy,
    cal3TimePaleoPhy and bin_cal3TimePaleoPhy, which date cladograms of
    fossil taxa using stratigraphic data. This package also contains a large number
    of likelihood functions for estimating sampling and diversification rates from
    different types of data available from the fossil record (e.g. range data,
    occurrence data, etc). paleotree users can also simulate diversification and
    sampling in the fossil record using the function simFossilRecord, which is a
    detailed simulator for branching birth-death-sampling processes composed of
    discrete taxonomic units arranged in ancestor-descendant relationships. Users
    can use simFossilRecord to simulate diversification in incompletely sampled
    fossil records, under various models of morphological differentiation (i.e.
    the various patterns by which morphotaxa originate from one another), and
    with time-dependent, longevity-dependent and/or diversity-dependent rates of
    diversification, extinction and sampling. Additional functions allow users to
    translate simulated ancestor-descendant data from simFossilRecord into standard
    time-scaled phylogenies or unscaled cladograms that reflect the relationships
    among taxon units.",2019-12-12,David W. Bapst,https://github.com/dwbapst/paleotree,TRUE,https://github.com/dwbapst/paleotree,49332,13,2019-12-12T17:07:57Z,3794.769230769231
paletteer,"The choices of color palettes in R can be quite
    overwhelming with palettes spread over many packages with many
    different API's. This packages aims to collect all color palettes
    across the R ecosystem under the same package with a streamlined API.",2020-06-07,See AUTHORS file.,https://github.com/EmilHvitfeldt/paletteer,TRUE,https://github.com/emilhvitfeldt/paletteer,54618,393,2020-06-07T18:13:38Z,138.9770992366412
palm,"Functions to fit point process models using the Palm likelihood. First proposed by Tanaka, Ogata, and Stoyan (2008) <DOI:10.1002/bimj.200610339>, maximisation of the Palm likelihood can provide computationally efficient parameter estimation for point process models in situations where the full likelihood is intractable. This package is chiefly focused on Neyman-Scott point processes, but can also fit the void processes proposed by Jones-Todd et al. (in press) <DOI:10.1002/sim.8046>. The development of this package was motivated by the analysis of capture-recapture surveys on which individuals cannot be identified---the data from which can conceptually be seen as a clustered point process (Stevenson, Borchers, and Fewster, in press <DOI:10.1111/biom.12983>). As such, some of the functions in this package are specifically for the estimation of cetacean density from two-camera aerial surveys.",2018-12-08,Ben Stevenson,https://github.com/b-steve/palm,TRUE,https://github.com/b-steve/palm,11692,1,2019-08-19T01:03:24Z,11692
palr,"Colour palettes for data, based on some well known public data
    sets. Includes helper functions to map absolute values to known palettes, and 
    capture the work of image colour mapping as raster data sets. ",2020-01-30,Michael D. Sumner,https://github.com/AustralianAntarcticDivision/palr,TRUE,https://github.com/australianantarcticdivision/palr,60955,1,2020-01-30T03:17:14Z,60955
pals,"A comprehensive collection of color palettes, colormaps, and tools to evaluate them.",2019-12-04,Kevin Wright,http://kwstat.github.io/pals/,TRUE,https://github.com/kwstat/pals,71309,55,2019-12-04T21:46:22Z,1296.5272727272727
pamm,"Simulation functions to assess or explore the power of a dataset to estimates significant random effects (intercept or slope) in a mixed model. The functions are based on the ""lme4"" and ""lmerTest"" packages.",2020-01-22,Julien Martin,https://github.com/JulienGAMartin/pamm_R,TRUE,https://github.com/juliengamartin/pamm_r,17775,0,2020-01-21T19:05:48Z,NA
pammtools,"The Piece-wise exponential (Additive Mixed) Model
    (PAMM; Bender and Scheipl (2018) <doi: 10.1177/1471082X17748083>) is a
    powerful model class for the analysis of survival (or time-to-event) data,
    based on Generalized Additive (Mixed) Models (GA(M)Ms). It offers intuitive specification and robust estimation of complex survival models with stratified baseline hazards, random effects, time-varying effects, time-dependent covariates and cumulative effects (Bender and others (2018) <doi: 10.1093/biostatistics/kxy003>.
    pammtools provides tidy workflow for survival analysis with PAMMs,
    including data simulation, transformation and other functions for data
    preprocessing and model post-processing as well as visualization.",2020-06-06,Andreas Bender,https://github.com/adibender/pammtools,TRUE,https://github.com/adibender/pammtools,8929,20,2020-06-06T15:27:46Z,446.45
pander,"Contains some functions catching all messages, 'stdout' and other
    useful information while evaluating R code and other helpers to return user
    specified text elements (like: header, paragraph, table, image, lists etc.)
    in 'pandoc' markdown or several type of R objects similarly automatically
    transformed to markdown format. Also capable of exporting/converting (the
    resulting) complex 'pandoc' documents to e.g. HTML, 'PDF', 'docx' or 'odt'. This
    latter reporting feature is supported in brew syntax or with a custom reference
    class with a smarty caching 'backend'.",2018-11-06,Gergely Daróczi,http://rapporter.github.io/pander,TRUE,https://github.com/rapporter/pander,1089294,256,2020-05-27T00:03:50Z,4255.0546875
pandocfilters,"The document converter 'pandoc' <http://pandoc.org/> is widely used
    in the R community. One feature of 'pandoc' is that it can produce and consume
    JSON-formatted abstract syntax trees (AST). This allows to transform a given
    source document into JSON-formatted AST, alter it by so called filters and pass
    the altered JSON-formatted AST back to 'pandoc'. This package provides functions
    which allow to write such filters in native R code. 
    Although this package is inspired by the Python package 'pandocfilters' 
    <https://github.com/jgm/pandocfilters/>, it provides additional convenience functions which make it simple to use the 'pandocfilters' package as a 
    report generator. Since 'pandocfilters' inherits most of it's functionality
    from 'pandoc' it can create documents in many formats 
    (for more information see <http://pandoc.org/>) but is also bound to the same
    limitations as 'pandoc'.",2019-11-26,Florian Schwendinger,"http://pandoc.org/, https://github.com/jgm/pandocfilters/",TRUE,https://github.com/jgm/pandocfilters,28082,341,2020-02-13T00:15:25Z,82.35190615835778
PanelMatch,"Implements a set of methodological tools
	     that enable researchers to apply matching methods to
	     time-series cross-sectional data. Imai, Kim, and Wang
	     (2018) <http://web.mit.edu/insong/www/pdf/tscs.pdf> 
	     proposes a nonparametric generalization of the
	     difference-in-differences estimator, which does not rely
	     on the linearity assumption as often done in
	     practice. Researchers first select a method of matching
	     each treated observation for a given unit in a
	     particular time period with control observations from
	     other units in the same time period that have a similar
	     treatment and covariate history. These methods include
	     standard matching methods based on propensity score and
	     Mahalanobis distance, as well as weighting methods. Once 
	     matching is done, both short-term and long-term average 
	     treatment effects for the treated can be estimated with 
	     standard errors. The package also offers a visualization 
	     technique that allows researchers to assess the quality 
	     of matches by examining the resulting covariate balance.",2020-02-28,In Song Kim,NA,TRUE,https://github.com/insongkim/panelmatch,1849,39,2020-06-03T20:33:39Z,47.41025641025641
panelr,"Provides an object type and associated tools for storing and 
  wrangling panel data. Implements several methods for creating regression
  models that take advantage of the unique aspects of 
  panel data. Among other capabilities, automates the ""within-between"" 
  (also known as ""between-within"" and ""hybrid"") panel regression specification
  that combines the desirable aspects of both fixed effects and random effects 
  econometric models and fits them as multilevel models 
  (Allison, 2009 <doi:10.4135/9781412993869.d33>; 
  Bell & Jones, 2015 <doi:10.1017/psrm.2014.7>). These models can also be 
  estimated via generalized estimating equations 
  (GEE; McNeish, 2019 <doi:10.1080/00273171.2019.1602504>) and Bayesian 
  estimation is (optionally) supported via 'Stan'. 
  Supports estimation of asymmetric effects models via first differences
  (Allison, 2019 <doi:10.1177/2378023119826441>) as well as a generalized
  linear model extension thereof using GEE. ",2020-03-08,Jacob A. Long,https://panelr.jacob-long.com,TRUE,https://github.com/jacob-long/panelr,16234,52,2020-03-08T21:32:01Z,312.1923076923077
panelWranglR,"Leading/lagging a panel, creating dummy variables,
             taking panel differences, looking for panel autocorrelations,
             and more. Implemented via a 'data.table' back end. ",2019-10-03,Juraj Szitás,https://github.com/JSzitas/panelWranglR,TRUE,https://github.com/jszitas/panelwranglr,2844,1,2019-10-03T09:34:18Z,2844
pangaear,"Tools to interact with the 'Pangaea' Database
    (<https://www.pangaea.de>), including functions for searching for data,
    fetching 'datasets' by 'dataset' 'ID', and working with the 'Pangaea'
    'OAI-PMH' service.",2020-01-22,Scott Chamberlain,"https://github.com/ropensci/pangaear (devel),
https://docs.ropensci.org/pangaear (documentation)",TRUE,https://github.com/ropensci/pangaear,17646,11,2020-01-22T20:03:43Z,1604.1818181818182
papeR,"A toolbox for writing 'knitr', 'Sweave' or other 'LaTeX'- or 'markdown'-based
	     reports and to prettify the output of various estimated models.",2019-01-03,Benjamin Hofner,http://github.com/hofnerb/papeR,TRUE,https://github.com/hofnerb/paper,39487,20,2019-07-18T11:23:59Z,1974.35
paradox,"Define parameter spaces, constraints and
    dependencies for arbitrary algorithms, to program on such spaces. Also
    includes statistical designs and random samplers. Objects are
    implemented as 'R6' classes.",2020-04-15,Michel Lang,"https://paradox.mlr-org.com, https://github.com/mlr-org/paradox",TRUE,https://github.com/mlr-org/paradox,40750,17,2020-05-29T09:54:04Z,2397.0588235294117
parallelDist,"A fast parallelized alternative to R's native 'dist' function to
    calculate distance matrices for continuous, binary, and multi-dimensional
    input matrices, which supports a broad variety of 41 predefined distance
    functions from the 'stats', 'proxy' and 'dtw' R packages, as well as user-
    defined functions written in C++. For ease of use, the 'parDist' function
    extends the signature of the 'dist' function and uses the same parameter
    naming conventions as distance methods of existing R packages. The package
    is mainly implemented in C++ and leverages the 'RcppParallel' package to
    parallelize the distance computations with the help of the 'TinyThread'
    library. Furthermore, the 'Armadillo' linear algebra library is used for
    optimized matrix operations during distance calculations. The curiously
    recurring template pattern (CRTP) technique is applied to avoid virtual
    functions, which improves the Dynamic Time Warping calculations while
    the implementation stays flexible enough to support different DTW step
    patterns and normalization methods.",2018-12-12,Alexander Eckert,"https://github.com/alexeckert/parallelDist,
https://www.alexandereckert.com/R",TRUE,https://github.com/alexeckert/paralleldist,28069,36,2019-06-14T00:11:55Z,779.6944444444445
ParallelLogger,"Support for parallel computation with progress bar, and option to stop or proceed on errors. Also provides logging to console and disk,
  and the logging persists in the parallel threads. Additional functions support function call automation with delayed execution (e.g. for executing functions in
  parallel).",2020-06-07,Martijn Schuemie,"https://ohdsi.github.io/ParallelLogger,
https://github.com/OHDSI/ParallelLogger",TRUE,https://github.com/ohdsi/parallellogger,14795,5,2020-06-03T15:16:33Z,2959
parallelMap,"Unified parallelization framework for multiple
    back-end, designed for internal package and interactive usage.  The
    main operation is parallel mapping over lists.  Supports 'local',
    'multicore', 'mpi' and 'BatchJobs' mode.  Allows tagging of the
    parallel operation with a level name that can be later selected by the
    user to switch on parallel execution for exactly this operation.",2020-03-26,Bernd Bischl,"https://parallelmap.mlr-org.com,
https://github.com/berndbischl/parallelMap",TRUE,https://github.com/berndbischl/parallelmap,391152,58,2020-05-25T07:17:04Z,6744
parameters,"Utilities for processing the parameters of various
    statistical models. Beyond computing p values, CIs, and other indices
    for a wide variety of models (see support list of insight; Lüdecke,
    Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), this package
    implements features like bootstrapping or simulating of parameters and
    models, feature reduction (feature extraction and variable selection)
    as well as functions to describe data and variable characteristics
    (e.g. skewness, kurtosis, smoothness or distribution).",2020-06-08,Daniel Lüdecke,https://easystats.github.io/parameters/,TRUE,https://github.com/easystats/parameters,194517,102,2020-06-09T13:57:09Z,1907.0294117647059
ParamHelpers,"Functions for parameter descriptions and operations
    in black-box optimization, tuning and machine learning. Parameters can
    be described (type, constraints, defaults, etc.), combined to
    parameter sets and can in general be programmed on. A useful OptPath
    object (archive) to log function evaluations is also provided.",2020-03-24,Bernd Bischl,"https://paramhelpers.mlr-org.com,
https://github.com/mlr-org/ParamHelpers",TRUE,https://github.com/mlr-org/paramhelpers,404936,26,2020-05-25T07:56:20Z,15574.461538461539
ParBayesianOptimization,"Fast, flexible framework for implementing Bayesian optimization of model 
	hyperparameters according to the methods described in Snoek et al. <arXiv:1206.2944>.
	The package allows the user to run scoring function in parallel, save intermediary 
	results, and tweak other aspects of the process to fully utilize the computing resources
	available to the user.",2020-02-24,Samuel Wilson,https://github.com/AnotherSamWilson/ParBayesianOptimization,TRUE,https://github.com/anothersamwilson/parbayesianoptimization,12087,39,2020-05-15T18:13:38Z,309.9230769230769
parlitools,"Provides various tools for analysing UK political data, including 
    election result datasets, hexagonal cartograms and functions to 
    retrieve council member data.",2020-01-12,Evan Odell,"https://docs.evanodell.com/parlitools,
https://github.com/EvanOdell/parlitools/",TRUE,https://github.com/evanodell/parlitools,15415,18,2020-01-12T18:07:33Z,856.3888888888889
parsetools,"Tools and utilities for dealing with parse data. 
    Parse data represents the parse tree as data with location and type
    information.  This package provides functions for navigating the  
    parse tree as a data frame.",2020-04-08,Andrew Redd,https://github.com/RDocTaskForce/parsetools,TRUE,https://github.com/rdoctaskforce/parsetools,13557,12,2020-04-07T21:25:22Z,1129.75
parsnip,"A common interface is provided to allow users to specify a model without having to remember the different argument names across different functions or computational engines (e.g. 'R', 'Spark', 'Stan', etc). ",2020-05-06,Max Kuhn,"https://tidymodels.github.io/parsnip,
https://github.com/tidymodels/parsnip",TRUE,https://github.com/tidymodels/parsnip,94793,303,2020-06-08T16:37:38Z,312.84818481848185
partition,"A fast and flexible framework for agglomerative
    partitioning. 'partition' uses an approach called
    Direct-Measure-Reduce to create new variables that maintain the
    user-specified minimum level of information. Each reduced variable is
    also interpretable: the original variables map to one and only one
    variable in the reduced data set. 'partition' is flexible, as well:
    how variables are selected to reduce, how information loss is
    measured, and the way data is reduced can all be customized.
    'partition' is based on the Partition framework discussed in Millstein
    et al. (2020) <doi: 10.1093/bioinformatics/btz661>.",2020-05-24,Malcolm Barrett,"https://uscbiostats.github.io/partition/,
https://github.com/USCbiostats/partition",TRUE,https://github.com/uscbiostats/partition,5361,14,2020-05-24T22:11:45Z,382.92857142857144
partitions,"Additive partitions of integers.  Enumerates the
  partitions, unequal partitions, and restricted partitions of an
  integer; the three corresponding partition functions are also
  given.  Set partitions are now included.",2019-10-21,Robin K. S. Hankin,https://github.com/RobinHankin/partitions.git,TRUE,https://github.com/robinhankin/partitions,209095,3,2020-05-01T20:45:30Z,69698.33333333333
partools,"Miscellaneous utilities for parallelizing large
   computations.  Alternative to MapReduce.
   File splitting and distributed operations such as sort and aggregate.
   ""Software Alchemy"" method for parallelizing most statistical methods,
   presented in N. Matloff, Parallel Computation for Data Science,
   Chapman and Hall, 2015.  Includes a debugging aid.",2017-04-10,Norm Matloff,https://github.com/matloff/partools,TRUE,https://github.com/matloff/partools,19353,36,2020-05-22T21:56:28Z,537.5833333333334
parzer,"Parse geographic coordinates from various formats
    to decimal degree numeric values. Parse coordinates into
    their parts (degree, minutes, seconds); calculate hemisphere
    from coordinates; pull out individually degrees,
    minutes, or seconds; add and subtract degrees, minutes,
    and seconds. C++ code herein originally inspired from code
    written by Jeffrey D. Bogan (<http://bit.ly/CLongLatString>),
    but then completely re-written.",2020-03-29,Scott Chamberlain,"https://github.com/ropensci/parzer (devel)
https://docs.ropensci.org/parzer (docs)",TRUE,https://github.com/ropensci/parzer,1427,45,2020-03-31T15:30:37Z,31.711111111111112
passport,"Smooths the process of working with country names and codes via 
    powerful parsing, standardization, and conversion utilities arranged in a 
    simple, consistent API. Country name formats include multiple sources 
    including the Unicode Common Locale Data 
    Repository (CLDR, <http://cldr.unicode.org/>) common-sense standardized 
    names in hundreds of languages.",2017-11-30,Edward Visel,"https://github.com/alistaire47/passport,
https://alistaire47.github.io/passport/",TRUE,https://github.com/alistaire47/passport,9007,33,2020-04-19T23:43:20Z,272.93939393939394
passt,"Simulates judgments of frequency and duration based on
    the Probability Associator Time (PASS-T) model. PASS-T is a memory
    model based on a simple competitive artificial neural network. It 
    can imitate human judgments of frequency and duration, which have
    been extensively studied in cognitive psychology
    (e.g. Hintzman (1970) <doi:10.1037/h0028865>, Betsch et al. (2010)
    <https://psycnet.apa.org/record/2010-18204-003>). The PASS-T model
    is an extension of the PASS model (Sedlmeier, 2002,
    ISBN:0198508638). The package provides an easy way to run
    simulations, which can then be compared with empirical data in
    human judgments of frequency and duration.",2019-12-05,Johannes Titz,https://github.com/johannes-titz/passt,TRUE,https://github.com/johannes-titz/passt,2121,0,2020-02-05T13:23:45Z,NA
pastecs,"Regularisation, decomposition and analysis of space-time series.
  The pastecs R package is a PNEC-Art4 and IFREMER (Benoit Beliaeff
  <Benoit.Beliaeff@ifremer.fr>) initiative to bring PASSTEC 2000 functionalities to R.",2018-03-15,Philippe Grosjean,https://github.com/phgrosjean/pastecs,TRUE,https://github.com/phgrosjean/pastecs,584902,1,2020-05-04T13:44:19Z,584902
patchwork,"The 'ggplot2' package provides a strong API for sequentially 
    building up a plot, but does not concern itself with composition of multiple
    plots. 'patchwork' is a package that expands the API to allow for 
    arbitrarily complex composition of plots by, among others, providing 
    mathematical operators for combining multiple plots. Other packages that try 
    to address this need (but with a different approach) are 'gridExtra' and 
    'cowplot'.",2019-12-01,Thomas Lin Pedersen,"https://patchwork.data-imaginist.com,
https://github.com/thomasp85/patchwork",TRUE,https://github.com/thomasp85/patchwork,122813,1555,2019-12-02T12:52:10Z,78.97942122186495
patentsview,"Provides functions to simplify the 'PatentsView' API
    (<http://www.patentsview.org/api/doc.html>) query language,
    send GET and POST requests to the API's seven endpoints, and parse the data
    that comes back.",2019-01-28,Christopher Baker,https://ropensci.github.io/patentsview/index.html,TRUE,https://github.com/ropensci/patentsview,12865,16,2020-05-01T23:39:09Z,804.0625
pathfindR,"Enrichment analysis enables researchers to uncover mechanisms 
    underlying a phenotype. However, conventional methods for enrichment 
    analysis do not take into account protein-protein interaction information, 
    resulting in incomplete conclusions. pathfindR is a tool for enrichment 
    analysis utilizing active subnetworks. The main function identifies active 
    subnetworks in a protein-protein interaction network using a user-provided 
    list of genes and associated p values. It then performs enrichment analyses 
    on the identified subnetworks, identifying enriched terms (i.e. pathways or, 
    more broadly, gene sets) that possibly underlie the phenotype of interest.
    pathfindR also offers functionalities to cluster the enriched terms and 
    identify representative terms in each cluster, to score the enriched terms 
    per sample and to visualize analysis results. The enrichment, clustering and 
    other methods implemented in pathfindR are described in detail in 
    Ulgen E, Ozisik O, Sezerman OU. 2019. pathfindR: An R Package for 
    Comprehensive Identification of Enriched Pathways in Omics Data Through 
    Active Subnetworks. Front. Genet. <doi:10.3389/fgene.2019.00858>.",2020-06-07,Ege Ulgen,"https://egeulgen.github.io/pathfindR/,
https://github.com/egeulgen/pathfindR",TRUE,https://github.com/egeulgen/pathfindr,14234,61,2020-06-04T12:34:28Z,233.34426229508196
pathfindR.data,"This is a data-only package, containing data needed to run the CRAN 
    package 'pathfindR', a package for enrichment analysis utilizing active 
    subnetworks. This package contains protein-protein interaction network data, 
    data related to gene sets and example input/output data.",2020-06-04,Ege Ulgen,https://github.com/egeulgen/pathfindR.data,TRUE,https://github.com/egeulgen/pathfindr.data,0,0,2020-05-29T15:01:16Z,NA
patternize,"Quantification of variation in organismal color patterns as
    obtained from image data. Patternize defines homology between pattern positions
    across images either through fixed landmarks or image registration. Pattern
    identification is performed by categorizing the distribution of colors using RGB
    thresholds or image segmentation.",2018-11-23,Steven Van Belleghem,https://github.com/StevenVB12/patternize,TRUE,https://github.com/stevenvb12/patternize,10571,12,2020-05-12T17:21:08Z,880.9166666666666
Patterns,"A modeling tool dedicated to biological network modeling. It allows for single or joint modeling of, for instance, genes and proteins. It starts with the selection of the actors that will be the used in the reverse engineering upcoming step. An actor can be included in that selection based on its differential measurement (for instance gene expression or protein abundance) or on its time course profile. Wrappers for actors clustering functions and cluster analysis are provided. It also allows reverse engineering of biological networks taking into account the observed time course patterns of the actors. Many inference functions are provided and dedicated to get specific features for the inferred network such as sparsity, robust links, high confidence links or stable through resampling links. Some simulation and prediction tools are also available for cascade networks. Example of use with microarray or RNA-Seq data are provided.",2019-11-13,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/Patterns",TRUE,https://github.com/fbertran/patterns,3140,3,2019-11-13T22:05:02Z,1046.6666666666667
PAutilities,"A collection of utilities that are useful for a broad range of
    tasks that are common in physical activity research, including the
    following: creation of Bland-Altman plots, formatted descriptive
    statistics, metabolic calculations (e.g. basal metabolic rate predictions)
    and conversions, demographic calculations (age and age-for-body-mass-index
    percentile), bout analysis of moderate-to-vigorous intensity physical
    activity, and analysis of bout detection algorithm performance.",2020-05-17,Paul R. Hibbing,https://github.com/paulhibbing/PAutilities,TRUE,https://github.com/paulhibbing/pautilities,7714,0,2020-05-16T19:28:18Z,NA
pavo,"A cohesive framework for parsing, analyzing and
    organizing colour from spectral data.",2020-02-08,Rafael Maia,"http://pavo.colrverse.com, https://github.com/rmaia/pavo/",TRUE,https://github.com/rmaia/pavo,43042,18,2020-06-08T08:57:48Z,2391.222222222222
pbapply,"A lightweight package that adds
  progress bar to vectorized R functions
  ('*apply'). The implementation can easily be added
  to functions where showing the progress is
  useful (e.g. bootstrap). The type and style of the
  progress bar (with percentages or remaining time)
  can be set through options.
  Supports several parallel processing backends.",2019-08-31,Peter Solymos,https://github.com/psolymos/pbapply,TRUE,https://github.com/psolymos/pbapply,1064234,77,2020-06-08T21:57:26Z,13821.22077922078
pbdMPI,"An efficient interface to MPI by utilizing S4
        classes and methods with a focus on Single Program/Multiple Data
        ('SPMD')
        parallel programming style, which is intended for batch parallel
        execution.",2020-01-29,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdmpi,53107,2,2020-01-27T18:32:21Z,26553.5
pbdSLAP,"Utilizing scalable linear algebra packages mainly
        including 'BLACS', 'PBLAS', and 'ScaLAPACK' in double precision via
        'pbdMPI' based on 'ScaLAPACK' version 2.0.2.",2020-02-28,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdslap,38049,0,2020-02-24T01:04:59Z,NA
pbdZMQ,"'ZeroMQ' is a well-known library for high-performance
    asynchronous messaging in scalable, distributed applications.  This
    package provides high level R wrapper functions to easily utilize
    'ZeroMQ'. We mainly focus on interactive client/server programming
    frameworks. For convenience, a minimal 'ZeroMQ' library (4.2.2)
    is shipped with 'pbdZMQ', which can be used if no system installation
    of 'ZeroMQ' is available.  A few wrapper functions compatible with
    'rzmq' are also provided.",2018-05-05,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdzmq,372455,14,2019-10-26T00:39:05Z,26603.928571428572
pbixr,"Access data and metadata from 'Microsoft' 'Power BI' ('.pbix', <https://powerbi.microsoft.com>) documents with R. The 'pbixr' package enables one to extract 'Power Query M' formulas (<https://docs.microsoft.com/en-us/power-query/>) and 'Data Analysis Expressions' ('DAX', <https://docs.microsoft.com/en-us/dax/>) queries and their properties, report layout and style, and data and data models.",2020-05-31,Don Diproto,https://github.com/pbixr/pbixr,TRUE,https://github.com/pbixr/pbixr,10,0,2020-05-31T23:01:42Z,NA
pbmcapply,"A light-weight package helps you track and visualize
  the progress of parallel version of vectorized R functions (mc*apply).
  Parallelization (mc.core > 1) works only on *nix (Linux, Unix such as macOS) system due to
  the lack of fork() functionality, which is essential for mc*apply, on Windows.",2019-07-10,Kevin Kuang,https://github.com/kvnkuang/pbmcapply,TRUE,https://github.com/kvnkuang/pbmcapply,103237,25,2019-07-10T20:15:04Z,4129.48
PBSadmb,"A collection of software provides R support for 'ADMB'
             (Automatic Differentiation Model Builder) and a 'GUI'
             interface facilitates the conversion of 'ADMB' template
             code to 'C code' followed by compilation to a binary executable.
             Stand-alone functions can also be run by users
             not interested in clicking a 'GUI'.",2019-03-19,Rowan Haigh,"https://github.com/pbs-software/pbs-admb,
https://github.com/pbs-software/pbs-modelling",TRUE,https://github.com/pbs-software/pbs-admb,16078,0,2020-01-29T19:19:11Z,NA
PBSddesolve,"Functions for solving systems of delay differential equations by
   interfacing with numerical routines written by Simon N. Wood, including
   contributions from Benjamin J. Cairns. These numerical routines first
   appeared in Simon Wood's 'solv95' program. This package includes a vignette
   and a complete user's guide. 'PBSddesolve' originally appeared on CRAN under
   the name 'ddesolve'. That version is no longer supported. The current name
   emphasizes a close association with other 'PBS' packages, particularly
   'PBSmodelling'.",2019-12-09,Rowan Haigh,https://github.com/pbs-software/pbs-ddesolve,TRUE,https://github.com/pbs-software/pbs-ddesolve,23961,0,2019-12-09T19:24:36Z,NA
pbv,"
    Computes probabilities of the bivariate normal distribution
    in a vectorized R function (Drezner & Wesolowsky, 1990, 
    <doi:10.1080/00949659008811236>).",2020-05-11,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/pbv,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/pbv,39017,0,2020-05-12T09:36:06Z,NA
pcadapt,"Methods to detect genetic markers involved in biological
    adaptation. 'pcadapt' provides statistical tools for outlier detection based on
    Principal Component Analysis. Implements the method described in (Luu, 2016)
    <DOI:10.1111/1755-0998.12592>.",2020-05-05,Florian Privé,https://github.com/bcm-uga/pcadapt,TRUE,https://github.com/bcm-uga/pcadapt,25976,23,2020-05-05T08:13:26Z,1129.391304347826
PCADSC,"A suite of non-parametric, visual tools for assessing differences in data structures
    for two datasets that contain different observations of the same variables. These tools are all 
    based on Principal Component Analysis (PCA) and thus effectively address differences in the structures
    of the covariance matrices of the two datasets. The PCASDC tools consist of easy-to-use, 
    intuitive plots that each focus on different aspects of the PCA decompositions. The cumulative eigenvalue
    (CE) plot describes differences in the variance components (eigenvalues) of the deconstructed covariance matrices. The
    angle plot presents the information loss when moving from the PCA decomposition of one dataset to the 
    PCA decomposition of the other. The chroma plot describes the loading patterns of the two datasets, thereby
    presenting the relative weighting and importance of the variables from the original dataset. ",2017-04-19,Anne H. Petersen,https://github.com/annepetersen1/PCADSC,TRUE,https://github.com/annepetersen1/pcadsc,8856,0,2020-05-04T09:15:38Z,NA
PCAmatchR,"Matches cases to controls based on genotype principle components (PC). 
      In order to produce better results, matches are based on the weighted 
      distance of PCs where the weights are equal to the % variance explained 
      by that PC. A weighted Mahalanobis distance metric (Kidd et al. (1987)
      <DOI:10.1016/0031-3203(87)90066-5>) is used to determine matches. ",2020-04-24,Derek W. Brown,https://github.com/machiela-lab/PCAmatchR,TRUE,https://github.com/machiela-lab/pcamatchr,636,1,2020-06-09T12:05:40Z,636
pccc,"An implementation of the pediatric complex chronic conditions (CCC)
    classification system using R and C++.",2020-06-02,Seth Russell,https://github.com/CUD2V/pccc,TRUE,https://github.com/cud2v/pccc,9165,3,2020-05-20T23:17:32Z,3055
pcFactorStan,"Provides convenience functions and pre-programmed
    Stan models related to the paired comparison factor model. Its purpose
    is to make fitting paired comparison data using Stan easy.",2020-04-25,Joshua N. Pritikin,https://github.com/jpritikin/pcFactorStan,TRUE,https://github.com/jpritikin/pcfactorstan,7122,2,2020-04-22T15:24:09Z,3561
PCMBase,"Phylogenetic comparative methods represent models of continuous trait 
  data associated with the tips of a phylogenetic tree. Examples of such models 
  are Gaussian continuous time branching stochastic processes such as Brownian 
  motion (BM) and Ornstein-Uhlenbeck (OU) processes, which regard the data at the 
  tips of the tree as an observed (final) state of a Markov process starting from 
  an initial state at the root and evolving along the branches of the tree. The 
  PCMBase R package provides a general framework for manipulating such models. 
  This framework consists of an application programming interface for specifying 
  data and model parameters, and efficient algorithms for simulating trait evolution 
  under a model and calculating the likelihood of model parameters for an assumed
  model and trait data. The package implements a growing collection of models, 
  which currently includes BM, OU, BM/OU with jumps, two-speed OU as well as mixed 
  Gaussian models, in which different types of the above models can be associated 
  with different branches of the tree. The PCMBase package is limited to 
  trait-simulation and likelihood calculation of (mixed) Gaussian phylogenetic 
  models. The PCMFit package provides functionality for ML and Bayesian fit of 
  these models to tree and trait data. The package web-site 
  <https://venelin.github.io/PCMBase/>
  provides access to the documentation and other resources. ",2019-12-12,Venelin Mitov,"https://venelin.github.io/PCMBase/, https://venelin.github.io",TRUE,https://github.com/venelin/pcmbase,7641,3,2020-05-03T08:53:28Z,2547
PCMBaseCpp,"Provides a C++ backend for multivariate phylogenetic comparative
  models implemented in the R-package 'PCMBase'. Can be used in combination
  with 'PCMBase' to enable fast and parallel likelihood calculation. Implements
  the pruning likelihood calculation algorithm described in Mitov et al. (2018) 
  <arXiv:1809.09014>. Uses the 'SPLITT' C++ library for parallel tree traversal 
  described in Mitov and Stadler (2018) <doi:10.1111/2041-210X.13136>.",2020-03-23,Venelin Mitov,"https://github.com/venelin/PCMBaseCpp, https://venelin.github.io",TRUE,https://github.com/venelin/pcmbasecpp,2934,0,2020-03-22T22:06:11Z,NA
pcr,"Calculates the amplification efficiency and curves from real-time 
  quantitative PCR (Polymerase Chain Reaction) data. Estimates the relative 
  expression from PCR data using the double delta CT and the standard curve 
  methods Livak & Schmittgen (2001) <doi:10.1006/meth.2001.1262>. Tests for 
  statistical significance using two-group tests and linear regression 
  Yuan et al. (2006) <doi: 10.1186/1471-2105-7-85>.",2020-04-01,Mahmoud Ahmed,https://github.com/MahShaaban/pcr,TRUE,https://github.com/mahshaaban/pcr,21565,8,2020-04-01T05:29:34Z,2695.625
PCRedux,"Extracts features from amplification curve data of quantitative Polymerase Chain Reactions (qPCR) (Pabinger S. et al. (2014) <doi:10.1016/j.bdq.2014.08.002>) for machine learning purposes. Helper functions prepare the amplification curve data for processing as functional data (e.g., Hausdorff distance) or enable the plotting of amplification curve classes (negative, ambiguous, positive). The hookreg() and hookregNL() functions (Burdukiewicz M. et al. (2018) <doi:10.1016/j.bdq.2018.08.001>) can be used to predict amplification curves with an hook effect-like curvature. The pcrfit_single() function can be used to extract features from an amplification curve.",2020-03-06,Stefan Roediger,https://CRAN.R-project.org/package=PCRedux,TRUE,https://github.com/pcruniversum/pcredux,9279,5,2020-03-06T07:37:12Z,1855.8
pct,"Functions and example data to teach and
  increase the reproducibility of the methods and code underlying 
  the Propensity to Cycle Tool (PCT), a research project and web application 
  hosted at <https://www.pct.bike/>. 
  For an academic paper on the methods,
  see Lovelace et al (2017) <doi:10.5198/jtlu.2016.862>.",2020-03-02,Robin Lovelace,"https://itsleeds.github.io/pct/, https://github.com/ITSLeeds/pct",TRUE,https://github.com/itsleeds/pct,7347,7,2020-03-11T20:29:32Z,1049.5714285714287
pcts,"Classes and methods for modelling and simulation of
    periodically correlated (PC) and periodically integrated time
    series.  Compute theoretical periodic autocovariances and related
    properties of PC autoregressive moving average models. Some original
    methods including Boshnakov & Iqelan (2009)
    <doi:10.1111/j.1467-9892.2009.00617.x>, Boshnakov (1996)
    <doi:10.1111/j.1467-9892.1996.tb00281.x>.",2020-02-16,Georgi N. Boshnakov,https://geobosh.github.io/pcts https://github.com/GeoBosh/pcts,TRUE,https://github.com/geobosh/pcts,2630,1,2020-06-03T15:21:31Z,2630
pdfetch,"Download economic and financial time series from public sources, 
  including the St Louis Fed's FRED system, Yahoo Finance, the US Bureau of Labor Statistics, 
  the US Energy Information Administration, the World Bank, Eurostat, the European Central Bank,
  the Bank of England, the UK's Office of National Statistics, Deutsche Bundesbank, and INSEE.",2019-07-30,Abiel Reinhart,https://github.com/abielr/pdfetch,TRUE,https://github.com/abielr/pdfetch,68713,6,2019-07-30T04:12:35Z,11452.166666666666
pdfsearch,"Includes functions for keyword search of pdf files. There is
    also a wrapper that includes searching of all files within a single
    directory.",2019-01-09,Brandon LeBeau,https://github.com/lebebr01/pdfsearch,TRUE,https://github.com/lebebr01/pdfsearch,13846,21,2020-02-11T21:00:00Z,659.3333333333334
pdp,"A general framework for constructing partial dependence (i.e., 
  marginal effect) plots from various types machine learning models in R.",2018-08-27,Brandon Greenwell,"https://bgreenwell.github.io/pdp/index.html,
https://github.com/bgreenwell/pdp",TRUE,https://github.com/bgreenwell/pdp,117665,71,2020-04-14T16:21:03Z,1657.2535211267605
pdqr,"Create, transform, and summarize custom random
    variables with distribution functions (analogues of 'p*()', 'd*()',
    'q*()', and 'r*()' functions from base R). Two types of distributions
    are supported: ""discrete"" (random variable has finite number of output
    values) and ""continuous"" (infinite number of values in the form of
    continuous random variable). Functions for distribution
    transformations and summaries are available. Implemented approaches
    often emphasize approximate and numerical solutions: all distributions
    assume finite support and finite values of density function; some
    methods implemented with simulation techniques.",2019-12-15,Evgeni Chasnovski,"https://github.com/echasnovski/pdqr,
https://echasnovski.github.io/pdqr",TRUE,https://github.com/echasnovski/pdqr,2745,11,2020-06-02T19:32:15Z,249.54545454545453
PDQutils,"A collection of tools for approximating the 'PDQ' functions
    (respectively, the cumulative distribution, density, and quantile) of
    probability distributions via classical expansions involving moments and
    cumulants.",2017-03-18,Steven E. Pav,https://github.com/shabbychef/PDQutils,TRUE,https://github.com/shabbychef/pdqutils,28952,5,2019-11-08T04:11:00Z,5790.4
pdSpecEst,"An implementation of data analysis tools for samples of symmetric or 
  Hermitian positive definite matrices, such as collections of covariance matrices 
  or spectral density matrices. The tools in this package can be used to perform: (i) 
  intrinsic wavelet transforms for curves (1D) or surfaces (2D) of Hermitian positive 
  definite matrices with applications to dimension reduction, denoising and clustering in the 
  space of Hermitian positive definite matrices; and (ii) exploratory data analysis and inference 
  for samples of positive definite matrices by means of intrinsic data depth functions and 
  rank-based hypothesis tests in the space of Hermitian positive definite matrices.",2020-01-08,Joris Chau,https://github.com/JorisChau/pdSpecEst,TRUE,https://github.com/jorischau/pdspecest,13167,0,2020-01-11T10:21:07Z,NA
pdynmc,"Linear dynamic panel data modeling based on linear and
    nonlinear moment conditions as proposed by
    Holtz-Eakin, Newey, and Rosen (1988) <doi:10.2307/1913103>,
    Ahn and Schmidt (1995) <doi:10.1016/0304-4076(94)01641-C>,
    and Arellano and Bover (1995) <doi:10.1016/0304-4076(94)01642-D>.
    Estimation of the model parameters relies on numerical optimization
    and the computation of closed form solutions. For inference and specification
    testing, Windmeijer (2005) <doi:10.1016/j.jeconom.2004.02.005>
    corrected standard errors, serial correlation tests, tests for overidentification,
    and Wald tests are available.",2020-05-07,Markus Fritsch,https://github.com/markusfritsch/pdynmc,TRUE,https://github.com/markusfritsch/pdynmc,1691,1,2020-05-08T15:59:34Z,1691
PeakSegDisk,"Disk-based implementation of
 Functional Pruning Optimal Partitioning with up-down constraints
 <arXiv:1810.00117> for single-sample peak calling
 (independently for each sample and genomic problem),
 can handle huge data sets (10^7 or more).",2019-11-18,Toby Dylan Hocking,http://github.com/tdhock/PeakSegDisk,TRUE,https://github.com/tdhock/peaksegdisk,6496,1,2020-01-15T20:17:19Z,6496
pedometrics,An R implementation of some useful tools employed in the field of pedometrics.,2020-02-09,Alessandro Samuel-Rosa,https://github.com/samuel-rosa/pedometrics,TRUE,https://github.com/samuel-rosa/pedometrics,23133,3,2020-02-09T19:34:12Z,7711
pedprobr,"An implementation of the Elston-Stewart algorithm for calculating
    pedigree likelihoods given genetic marker data (Elston and Stewart (1971) 
    <doi:10.1159/000152448>). The standard algorithm is extended to allow inbred 
    founders. Mutation modelling is supported by the 'pedmut' package. 'pedprobr' 
    is part of the ped suite, a collection of packages for pedigree analysis in R, 
    based on 'pedtools' for handling pedigrees and markers.",2020-03-21,Magnus Dehli Vigeland,https://github.com/magnusdv/pedprobr,TRUE,https://github.com/magnusdv/pedprobr,2844,1,2020-05-27T10:19:17Z,2844
pedquant,"
    Provides an interface to access public economic and financial data for 
    economic research and quantitative analysis. The data sources including 
    NBS, FRED, Yahoo Finance, 163 Finance and etc. ",2020-04-09,Shichen Xie,https://github.com/ShichenXie/pedquant,TRUE,https://github.com/shichenxie/pedquant,6142,19,2020-05-29T16:07:05Z,323.2631578947368
pedSimulate,"Simulate pedigree, genetic merits and phenotypes with random mating followed by (non)random selection with different patterns for males and females.
   Bijma, P. & Rutten, M. (2002) <https://pdfs.semanticscholar.org/ac22/e2961cc7797a121d956abd1ecbaddc017f87.pdf>.",2020-04-26,Mohammad Ali Nilforooshan,https://github.com/nilforooshan/pedSimulate,TRUE,https://github.com/nilforooshan/pedsimulate,1328,0,2020-04-26T05:04:52Z,NA
pedtools,"A lightweight, but comprehensive collection of tools for creating, 
    manipulating and visualising pedigrees and genetic marker data. Pedigrees 
    can be read from text files or created on the fly with built-in functions. 
    A range of utilities enable modifications like adding or removing individuals,
    breaking loops, and merging pedigrees. Pedigree plots are produced by wrapping
    the plotting functionality of the 'kinship2' package.",2020-03-21,Magnus Dehli Vigeland,https://github.com/magnusdv/pedtools,TRUE,https://github.com/magnusdv/pedtools,3658,7,2020-05-28T19:31:14Z,522.5714285714286
PeerPerformance,"Provides functions to perform the peer performance
    analysis of funds' returns as described in Ardia and Boudt (2018) <doi:10.1016/j.jbankfin.2017.10.014>.",2020-04-21,David Ardia,https://github.com/ArdiaD/PeerPerformance,TRUE,https://github.com/ardiad/peerperformance,13767,6,2020-04-21T04:11:44Z,2294.5
penaltyLearning,"Implementations of algorithms from 
 Learning Sparse Penalties for Change-point Detection
 using Max Margin Interval Regression, by
 Hocking, Rigaill, Vert, Bach
 <http://proceedings.mlr.press/v28/hocking13.html>
 published in proceedings of ICML2013.",2020-05-14,Toby Dylan Hocking,https://github.com/tdhock/penaltyLearning,TRUE,https://github.com/tdhock/penaltylearning,12540,8,2020-05-14T15:45:44Z,1567.5
penPHcure,"Implementation of the semi-parametric proportional-hazards (PH) of Sy and Taylor (2000) <doi:10.1111/j.0006-341X.2000.00227.x> extended to time-varying covariates. Estimation and variable selection are based on the methodology described in Beretta and Heuchenne (2019) <doi:10.1080/02664763.2018.1554627>; confidence intervals of the parameter estimates may be computed using a bootstrap approach. Moreover, data following the PH cure model may be simulated using a method similar to Hendry (2014) <doi:10.1002/sim.5945>, where the event-times are generated on a continuous scale from a piecewise exponential distribution conditional on time-varying covariates.",2019-12-03,Alessandro Beretta,https://github.com/a-beretta/penPHcure,TRUE,https://github.com/a-beretta/penphcure,2379,0,2019-12-03T14:25:31Z,NA
pense,"Robust penalized elastic net S and MM estimator for linear
    regression. The method is described in detail in
    Cohen Freue, G. V., Kepplinger, D., Salibian-Barrera, M., and Smucler, E.
    (2017) <https://gcohenfr.github.io/pdfs/PENSE_manuscript.pdf>.",2020-02-09,David Kepplinger,https://github.com/dakep/pense-rpkg,TRUE,https://github.com/dakep/pense-rpkg,11102,1,2020-02-09T16:36:45Z,11102
pensim,"Simulation of continuous, correlated high-dimensional data with 
    time to event or binary response, and parallelized functions for Lasso, 
    Ridge, and Elastic Net penalized regression with repeated starts and 
    two-dimensional tuning of the Elastic Net.",2020-04-20,Levi Waldron,https://waldronlab.io/pensim,TRUE,https://github.com/waldronlab/pensim,16717,0,2020-04-17T13:04:10Z,NA
pepr,"A PEP, or Portable Encapsulated Project, is a dataset that 
    subscribes to the PEP structure for organizing metadata. It is written using
    a simple YAML + CSV format, it is your one-stop solution to metadata 
    management across data analysis environments. This package reads this 
    standardized project configuration structure into R.",2020-06-04,Michal Stolarczyk,NA,TRUE,https://github.com/pepkit/pepr,0,3,2020-06-04T13:43:54Z,0
Peptides,Includes functions to calculate several physicochemical properties and indices for amino-acid sequences as well as to read and plot 'XVG' output files from the 'GROMACS' molecular dynamics package.,2020-05-10,Daniel Osorio,https://github.com/dosorio/Peptides/,TRUE,https://github.com/dosorio/peptides,36657,24,2020-05-18T13:01:03Z,1527.375
perccalc,"An implementation of two functions that estimate values for percentiles from an ordered categorical variable as described by Reardon (2011, isbn:978-0-87154-372-1). One function estimates percentile differences from two percentiles while the other returns the values for every percentile from 1 to 100.",2019-12-17,Jorge Cimentada,"https://cimentadaj.github.io/perccalc/,
https://github.com/cimentadaj/perccalc",TRUE,https://github.com/cimentadaj/perccalc,8693,3,2020-05-24T09:28:33Z,2897.6666666666665
performance,"Utilities for computing measures to assess model quality,
    which are not directly provided by R's 'base' or 'stats' packages. These 
    include e.g. measures like r-squared, intraclass correlation coefficient
    (Nakagawa, Johnson & Schielzeth (2017) <doi:10.1098/rsif.2017.0213>), 
    root mean squared error or functions to check models for overdispersion, 
    singularity or zero-inflation and more. Functions apply to a large variety of
    regression models, including generalized linear models, mixed effects models
    and Bayesian models.",2020-05-03,Daniel Lüdecke,https://easystats.github.io/performance/,TRUE,https://github.com/easystats/performance,242279,174,2020-06-09T07:49:53Z,1392.4080459770114
PerformanceAnalytics,"Collection of econometric functions for performance and risk 
    analysis. In addition to standard risk and performance metrics, this 
    package aims to aid practitioners and researchers in utilizing the latest
    research in analysis of non-normal return streams.  In general, it is most 
    tested on return (rather than price) data on a regular scale, but most 
    functions will work with irregular return data as well, and increasing
    numbers of functions will work with P&L or price data where possible.",2020-02-06,Brian G. Peterson,https://github.com/braverock/PerformanceAnalytics,TRUE,https://github.com/braverock/performanceanalytics,1014299,115,2020-04-01T05:28:42Z,8819.991304347826
periscope,"An enterprise-targeted scalable and UI-standardized 'shiny' framework 
    including a variety of developer convenience functions with the goal of both 
    streamlining robust application development while assisting with creating a 
    consistent user experience regardless of application or developer.",2020-05-22,Constance Brett,"https://github.com/cb4ds/periscope.git,
http://periscopeapps.org:3838, https://www.canvasxpress.org",TRUE,https://github.com/cb4ds/periscope,7449,10,2020-05-22T23:58:20Z,744.9
permutations,Manipulates invertible functions from a finite set to itself.  Can transform from word form to cycle form and back.,2020-02-07,Robin K. S. Hankin,https://github.com/RobinHankin/permutations.git,TRUE,https://github.com/robinhankin/permutations,20475,1,2020-02-07T22:39:54Z,20475
permutes,"Helps you determine the analysis window to use when analyzing densely-sampled
    time-series data, such as EEG data, using permutation testing (Maris & Oostenveld 2007)
    <doi:10.1016/j.jneumeth.2007.03.024>. These permutation tests can help identify the timepoints
    where significance of an effect begins and ends, and the results can be plotted in various
    types of heatmap for reporting.",2019-07-21,Cesko C. Voeten,NA,TRUE,https://github.com/cvoeten/permutes,7399,2,2019-07-21T16:10:14Z,3699.5
personalized,"Provides functions for fitting and validation of models for subgroup
    identification and personalized medicine / precision medicine under the general subgroup
    identification framework of Chen et al. (2017) <doi:10.1111/biom.12676>.
    This package is intended for use for both randomized controlled trials and
    observational studies.",2019-11-07,Jared Huling,"https://jaredhuling.github.io/personalized/,
https://arxiv.org/abs/1809.07905",TRUE,https://github.com/jaredhuling/personalized,15356,11,2020-01-14T16:24:02Z,1396
peRspective,"Interface to the 'Perspective' API, which can be found at the following URL: <https://github.com/conversationai/perspectiveapi#perspective-comment-analyzer-api>. 
    The 'Perspective' API uses machine learning models to score the perceived impact a comment might have on a conversation (i.e. TOXICITY, INFLAMMATORY, etc.).     
    'peRspective' provides access to the API and returns tidy data frames with results of the specified machine learning model(s).",2019-05-20,Fabio Votta,https://github.com/favstats/peRspective,TRUE,https://github.com/favstats/perspective,3878,28,2020-01-26T16:42:13Z,138.5
pesel,"Automatic estimation of number of principal components in PCA
    with PEnalized SEmi-integrated Likelihood (PESEL). See Piotr Sobczyk, Malgorzata Bogdan, Julie Josse
    'Bayesian dimensionality reduction with PCA using penalized semi-integrated likelihood' 
    (2017) <doi:10.1080/10618600.2017.1340302>.",2020-03-04,Piotr Sobczyk,https://github.com/psobczyk/pesel,TRUE,https://github.com/psobczyk/pesel,5834,4,2019-06-21T16:52:24Z,1458.5
PetfindeR,"
  Wrapper of the 'Petfinder API' <https://www.petfinder.com/developers/v2/docs/> that implements 
  methods for interacting with and extracting data from the 'Petfinder' database. The 'Petfinder 
  REST API' allows access to the 'Petfinder' database, one of the largest online databases of 
  adoptable animals and animal welfare organizations across North America.",2019-08-23,Aaron Schlegel,https://github.com/aschleg/PetfindeR,TRUE,https://github.com/aschleg/petfinder,4706,1,2019-10-03T13:29:10Z,4706
petrinetR,"Functions for the construction of Petri Nets. Petri Nets can be replayed by firing enabled transitions.
     Silent transitions will be hidden by the execution handler. Also includes functionalities for the visualization of Petri Nets and
     export of Petri Nets to PNML (Petri Net Markup Language) files.",2019-03-08,Gert Janssenswillen,https://www.bupar.net,TRUE,https://github.com/gertjanssenswillen/petrinetr,18558,2,2019-07-29T13:47:00Z,9279
pewdata,"Reproducible, programmatic retrieval of survey datasets from the
    Pew Research Center.",2020-02-05,Frederick Solt,https://github.com/fsolt/pewdata,TRUE,https://github.com/fsolt/pewdata,12140,5,2020-02-03T17:26:57Z,2428
PGRdup,"Provides functions to aid the identification of probable/possible
    duplicates in Plant Genetic Resources (PGR) collections using
    'passport databases' comprising of information records of each constituent
    sample. These include methods for cleaning the data, creation of a
    searchable Key Word in Context (KWIC) index of keywords associated with
    sample records and the identification of nearly identical records with
    similar information by fuzzy, phonetic and semantic matching of keywords.",2020-02-10,J. Aravind,"https://cran.r-project.org/package=PGRdup,
https://github.com/aravind-j/PGRdup,
https://doi.org/10.5281/zenodo.841963,
https://aravind-j.github.io/PGRdup/,
https://www.rdocumentation.org/packages/PGRdup",TRUE,https://github.com/aravind-j/pgrdup,19847,1,2020-02-23T21:54:52Z,19847
phangorn,"Package contains methods for estimation of phylogenetic trees and
    networks using Maximum Likelihood, Maximum Parsimony, distance methods and
    Hadamard conjugation. Allows to compare trees, models selection and offers
    visualizations for trees and split networks. ",2019-06-19,Klaus Schliep,https://github.com/KlausVigo/phangorn,TRUE,https://github.com/klausvigo/phangorn,421024,114,2020-06-07T16:14:35Z,3693.1929824561403
phaseR,"Performs a qualitative analysis of one- and two-dimensional
   autonomous ordinary differential equation systems, using phase plane methods.
   Programs are available to identify and classify equilibrium points, plot the
   direction field, and plot trajectories for multiple initial conditions. In
   the one-dimensional case, a program is also available to plot the phase
   portrait. Whilst in the two-dimensional case, programs are additionally
   available to plot nullclines and stable/unstable manifolds of saddle points.
   Many example systems are provided for the user. For further details can be
   found in Grayling (2014) <doi:10.32614/RJ-2014-023>.",2019-10-12,Michael J Grayling,https://github.com/mjg211/phaseR,TRUE,https://github.com/mjg211/phaser,28528,6,2019-11-26T14:44:32Z,4754.666666666667
PHEindicatormethods,"Functions to calculate commonly used public health statistics and 
    their confidence intervals using methods approved for use in the production  
    of Public Health England indicators such as those presented via Fingertips 
    (<http://fingertips.phe.org.uk/>). It provides functions for the generation 
    of proportions, crude rates, means, directly standardised rates, indirectly 
    standardised rates, standardised mortality ratios, slope and relative index
    of inequality and life expectancy. 
    Statistical methods are referenced in the following publications. 
    Breslow NE, Day NE (1987) <doi:10.1002/sim.4780080614>.
    Dobson et al (1991) <doi:10.1002/sim.4780100317>. 
    Armitage P, Berry G (2002) <doi:10.1002/9780470773666>.
    Wilson EB. (1927) <doi:10.1080/01621459.1927.10502953>.
    Altman DG et al (2000, ISBN: 978-0-727-91375-3).
    Chiang CL. (1968, ISBN: 978-0-882-75200-6).
    Newell C. (1994, ISBN: 978-0-898-62451-9).
    Eayres DP, Williams ES (2004) <doi:10.1136/jech.2003.009654>.
    Silcocks PBS et al (2001) <doi:10.1136/jech.55.1.38>.
    Low and Low (2004) <doi:10.1093/pubmed/fdh175>.",2020-04-14,Anderson Georgina,NA,TRUE,https://github.com/publichealthengland/pheindicatormethods,10053,6,2020-04-12T11:55:23Z,1675.5
phenesse,"Generates Weibull-parameterized estimates of phenology for any percentile of 
    a distribution using the framework established in Cooke (1979)
    <doi:10.1093/biomet/66.2.367>.. Extensive testing against other 
    estimators suggest the weib_percentile() function is especially useful in 
    generating more accurate and less biased estimates of onset and offset. 
    Non-parametric bootstrapping can be used to generate confidence intervals 
    around those estimates. Additionally, this package offers an easy way to 
    perform non-parametric bootstrapping to generate confidence intervals for 
    quantile estimates, mean estimates, or any statistical function of interest.",2020-03-28,Michael Belitz,https://github.com/mbelitz/phenesse,TRUE,https://github.com/mbelitz/phenesse,2458,2,2020-03-28T17:55:51Z,1229
phenofit,"
    The merits of 'TIMESAT' and 'phenopix' are adopted. Besides, a simple and 
    growing season dividing method and a practical snow elimination method 
    based on Whittaker were proposed. 7 curve fitting methods and 4 phenology 
    extraction methods were provided. Parameters boundary are considered for 
    every curve fitting methods according to their ecological meaning. 
    And 'optimx' is used to select best optimization method for different 
    curve fitting methods.
    Reference:
    Dongdong Kong, R package: A state-of-the-art Vegetation Phenology extraction package, 
    phenofit version 0.2.3, <https://github.com/kongdd/phenofit>;
    Zhang, Q., Kong, D., Shi, P., Singh, V.P., Sun, P., 2018. Vegetation phenology 
    on the Qinghai-Tibetan Plateau and its response to climate change (1982–2013). 
    Agric. For. Meteorol. 248, 408–417. <doi:10.1016/j.agrformet.2017.10.026>.",2020-04-02,Dongdong Kong,https://github.com/kongdd/phenofit,TRUE,https://github.com/kongdd/phenofit,5812,21,2020-04-07T12:15:20Z,276.76190476190476
PhenotypeSimulator,"Simulation is a critical part of method development and assessment
    in quantitative genetics. 'PhenotypeSimulator' allows for the flexible 
    simulation of phenotypes under different models, including genetic variant 
    and  infinitesimal genetic effects (reflecting population structure) as well 
    as non-genetic covariate effects, observational noise and additional 
    correlation effects. The different phenotype components are combined into a 
    final phenotype while controlling for the proportion of variance explained 
    by each of the components. For each effect component, the number of 
    variables, their distribution and the design of their effect across traits 
    can be customised. For the simulation of the genetic effects, external 
    genotype data from a number of standard software ('plink', 'hapgen2'/
    'impute2', 'genome', 'bimbam', simple text files) can be imported. The final 
    simulated phenotypes and its components can be automatically saved into .rds 
    or .csv files. In addition, they can be saved in formats compatible with 
    commonly used genetic association software ('gemma', 'bimbam', 'plink', 
    'snptest', 'LiMMBo'). ",2019-05-15,Hannah Meyer,https://github.com/HannahVMeyer/PhenotypeSimulator,TRUE,https://github.com/hannahvmeyer/phenotypesimulator,12680,17,2019-07-31T21:46:41Z,745.8823529411765
philentropy,"Computes 46 optimized distance and similarity measures for comparing probability functions (Drost (2018) <doi:10.21105/joss.00765>). These comparisons between probability functions have their foundations in a broad range of scientific disciplines from mathematics to ecology. The aim of this package is to provide a core framework for clustering, classification, statistical inference, goodness-of-fit, non-parametric statistics, information theory, and machine learning tasks that are based on comparing univariate or multivariate probability functions.",2020-01-10,Hajk-Georg Drost,https://github.com/HajkD/philentropy,TRUE,https://github.com/hajkd/philentropy,46186,51,2020-04-26T15:43:00Z,905.6078431372549
phonfieldwork,"There are a lot of different typical tasks that have to be solved during phonetic research and experiments. This includes creating a presentation that will contain all stimuli, renaming and concatenating multiple sound files recorded during a session, automatic annotation in 'Praat' TextGrids (this is one of the sound annotation standards provided by 'Praat' software, see Boersma & Weenink 2018 <http://www.fon.hum.uva.nl/praat/>), creating an html table with annotations and spectrograms, and converting multiple formats ('Praat' TextGrid, 'EXMARaLDA', 'ELAN', and 'FLEx' flextext). All of these tasks can be solved by a mixture of different tools (any programming language has programs for automatic renaming, and Praat contains scripts for concatenating and renaming files, etc.). 'phonfieldwork' provides a functionality that will make it easier to solve those tasks independently of any additional tools. You can also compare the functionality with other packages: 'rPraat' <https://CRAN.R-project.org/package=rPraat>, 'textgRid' <https://CRAN.R-project.org/package=textgRid>.",2020-06-07,George Moroz,"https://CRAN.R-project.org/package=phonfieldwork,
https://agricolamz.github.io/phonfieldwork/",TRUE,https://github.com/agricolamz/phonfieldwork,3799,0,2020-06-09T21:33:05Z,NA
phonics,"Provides a collection of phonetic algorithms including
    Soundex, Metaphone, NYSIIS, Caverphone, and others.",2019-06-21,James Howard,https://howardjp.github.io/phonics/,TRUE,https://github.com/howardjp/phonics,22377,20,2019-06-18T23:00:54Z,1118.85
phyclust,"Phylogenetic clustering (phyloclustering) is an evolutionary
        Continuous Time Markov Chain model-based approach to identify
        population structure from molecular data without assuming
        linkage equilibrium. The package phyclust (Chen 2011) provides a
        convenient implementation of phyloclustering for DNA and SNP data,
        capable of clustering individuals into subpopulations and identifying
        molecular sequences representative of those subpopulations. It is
        designed in C for performance, interfaced with R for visualization,
        and incorporates other popular open source programs including
        ms (Hudson 2002) <doi:10.1093/bioinformatics/18.2.337>,
        seq-gen (Rambaut and Grassly 1997)
        <doi:10.1093/bioinformatics/13.3.235>,
        Hap-Clustering (Tzeng 2005) <doi:10.1002/gepi.20063> and
        PAML baseml (Yang 1997, 2007) <doi:10.1093/bioinformatics/13.5.555>,
        <doi:10.1093/molbev/msm088>,
        for simulating data, additional analyses, and searching the best tree.
        See the phyclust website for more information, documentations and
        examples.",2020-05-11,Wei-Chen Chen,http://snoweye.github.io/phyclust/,TRUE,https://github.com/snoweye/phyclust,55466,5,2020-05-10T21:20:20Z,11093.2
phylin,"The spatial interpolation of genetic distances between
	     samples is based on a modified kriging method that
	     accepts a genetic distance matrix and generates a map of
	     probability of lineage presence. This package also offers
	     tools to generate a map of  potential contact zones
	     between groups with user-defined thresholds in the tree
	     to account for old and recent divergence. Additionally,
	     it has functions for IDW interpolation using genetic data
	     and midpoints.",2019-12-12,Pedro Tarroso,"https://www.r-project.org, https://github.com/ptarroso/phylin",TRUE,https://github.com/ptarroso/phylin,18239,3,2019-12-12T12:20:24Z,6079.666666666667
phylobase,"Provides a base S4 class for comparative methods, incorporating
    one or more trees and trait data.",2020-03-01,R Hackathon et al. (alphabetically: Ben Bolker,https://github.com/fmichonneau/phylobase,TRUE,https://github.com/fmichonneau/phylobase,140440,10,2020-03-01T07:08:18Z,14044
phylocomr,"Interface to 'Phylocom' (<http://phylodiversity.net/phylocom/>),
    a library for analysis of 'phylogenetic' community structure and
    character evolution. Includes low level methods for interacting with
    the three executables, as well as higher level interfaces for methods
    like 'aot', 'ecovolve', 'bladj', 'phylomatic', and more.",2019-12-20,Scott Chamberlain,"https://docs.ropensci.org/phylocomr,
https://github.com/ropensci/phylocomr",TRUE,https://github.com/ropensci/phylocomr,13243,16,2019-12-30T16:15:42Z,827.6875
PhylogeneticEM,"
    Implementation of the automatic shift detection method for
    Brownian Motion (BM) or Ornstein–Uhlenbeck (OU) models of trait evolution on
    phylogenies. Some tools to handle equivalent shifts configurations are also
    available. See Bastide et al. (2017) <doi:10.1111/rssb.12206> and
    Bastide et al. (2018) <doi:10.1093/sysbio/syy005>.",2020-02-11,Paul Bastide,https://github.com/pbastide/PhylogeneticEM,TRUE,https://github.com/pbastide/phylogeneticem,11753,9,2020-02-11T08:32:52Z,1305.888888888889
phylogram,"Contains functions for developing phylogenetic trees as
    deeply-nested lists (""dendrogram"" objects).
    Enables bi-directional conversion between dendrogram and
    ""phylo"" objects
    (see Paradis et al (2004) <doi:10.1093/bioinformatics/btg412>),
    and features several tools for command-line tree
    manipulation and import/export via Newick parenthetic text.",2018-06-25,Shaun Wilkinson,http://github.com/ropensci/phylogram,TRUE,https://github.com/ropensci/phylogram,19908,9,2019-12-09T21:21:51Z,2212
phylopath,"A comprehensive and easy to use R implementation of confirmatory
    phylogenetic path analysis as described by Von Hardenberg and Gonzalez-Voyer
    (2012) <doi:10.1111/j.1558-5646.2012.01790.x>.",2019-12-07,Wouter van der Bijl,http://Ax3man.github.io/phylopath/,TRUE,https://github.com/ax3man/phylopath,15389,8,2020-01-20T21:16:09Z,1923.625
phyloregion,"Computational infrastructure for biogeography, community ecology, 
    and biodiversity conservation (Daru et al. 2020) <doi:10.1101/2020.02.12.945691>. It is
    based on the conceptual work in Daru et al.(2017) <doi:10.1016/j.tree.2017.08.013> on 
    patterns and processes of biogeographical regionalization. Additionally, the package 
    contains fast and efficient functions to compute more standard conservation measures 
    such as phylogenetic diversity, phylogenetic endemism, evolutionary distinctiveness 
    and global endangerment, as well as compositional turnover (e.g., beta diversity). ",2020-03-30,Barnabas H. Daru,"https://github.com/darunabas/phyloregion,
https://darunabas.github.io/phyloregion/index.html",TRUE,https://github.com/darunabas/phyloregion,881,3,2020-05-25T04:32:32Z,293.6666666666667
phyloseqGraphTest,"Provides functions for graph-based multiple-sample
    testing and visualization of microbiome data, in particular data
    stored in 'phyloseq' objects. The tests are based on those
    described in Friedman and Rafsky (1979)
    <http://www.jstor.org/stable/2958919>, and the tests are described
    in more detail in Callahan et al. (2016)
    <doi:10.12688/f1000research.8986.1>.",2020-02-07,Julia Fukuyama,https://github.com/jfukuyama/phyloseqGraphTest,TRUE,https://github.com/jfukuyama/phyloseqgraphtest,13604,3,2020-02-07T13:10:09Z,4534.666666666667
phyr,"A collection of functions to do model-based phylogenetic analysis. 
    It includes functions to calculate community phylogenetic diversity,
    to estimate correlations among functional traits while accounting for 
    phylogenetic relationships, and to fit phylogenetic generalized linear
    mixed models. The Bayesian phylogenetic generalized linear mixed models
    are fitted with the 'INLA' package (<http://www.r-inla.org>).",2019-11-13,Daijiang Li,https://github.com/daijiang/phyr/,TRUE,https://github.com/daijiang/phyr,2926,13,2020-06-04T04:21:20Z,225.07692307692307
physiology,"A variety of formulae are provided for estimation
    of physiologic characteristics of infants, children, and adults.
    Calculations include: body surface area, ideal weight, airway
    dead-space, the alveolar gas equation, and GFR.  Each formula is
    referenced to the original publication. Future functions will cover
    more material with a focus on anaesthesia, critical care and
    peri-operative medicine.",2018-11-28,Jack O. Wasey,https://jackwasey.github.io/physiology/,TRUE,https://github.com/jackwasey/physiology,14923,7,2020-01-18T19:32:10Z,2131.8571428571427
phytools,"A wide range of functions for phylogenetic analysis. Functionality is concentrated in phylogenetic comparative biology, but also includes numerous methods for visualizing, manipulating, reading or writing, and even inferring phylogenetic trees and data. Included among the functions in phylogenetic comparative biology are various for ancestral state reconstruction, model-fitting, simulation of phylogenies and data, and multivariate analysis. There are a broad range of plotting methods for phylogenies and comparative data which include, but are not restricted to, methods for mapping trait evolution on trees, for projecting trees into phenotypic space or a geographic map, and for visualizing correlated speciation between trees. Finally, there are a number of functions for reading, writing, analyzing, inferring, simulating, and manipulating phylogenetic trees and comparative data not covered by other packages. For instance, there are functions for randomly or non-randomly attaching species or clades to a phylogeny, for estimating supertrees or consensus phylogenies from a set, for simulating trees and phylogenetic data under a range of models, and for a wide variety of other manipulations and analyses that phylogenetic biologists might find useful in their research.",2020-06-01,Liam J. Revell,http://github.com/liamrevell/phytools,TRUE,https://github.com/liamrevell/phytools,243202,96,2020-06-06T22:24:50Z,2533.3541666666665
piecepackr,"Functions to make board game graphics.  By default makes game diagrams, animations, and ""Print & Play"" layouts for the 'piecepack' <http://www.ludism.org/ppwiki> but can be configured to make graphics for other board game systems.",2020-05-13,Trevor L Davis,"https://trevorldavis.com/piecepackr,
https://github.com/piecepackr/piecepackr,
https://groups.google.com/forum/#!forum/piecepackr",TRUE,https://github.com/piecepackr/piecepackr,4458,4,2020-06-02T05:49:39Z,1114.5
piggyback,"Because larger (> 50 MB) data files cannot easily be committed to git,
  a different approach is required to manage data associated with an analysis in a 
  GitHub repository.  This package provides a simple work-around by allowing larger
  (up to 2 GB) data files to piggyback on a repository as assets attached to individual
  GitHub releases.  These files are not handled by git in any way, but instead are
  uploaded, downloaded, or edited directly by calls through the GitHub API. These
  data files can be versioned manually by creating different releases.  This approach
  works equally well with public or private repositories.  Data can be uploaded
  and downloaded programmatically from scripts. No authentication is required to
  download data from public repositories.",2020-02-25,Carl Boettiger,"https://docs.ropensci.org/piggyback,
https://github.com/ropensci/piggyback",TRUE,https://github.com/ropensci/piggyback,8804,110,2020-03-02T05:10:18Z,80.03636363636363
pillar,"Provides 'pillar' and 'colonnade' generics designed
    for formatting columns of data using the full range of colours
    provided by modern terminals.",2020-05-05,Kirill Müller,https://github.com/r-lib/pillar,TRUE,https://github.com/r-lib/pillar,20171224,97,2020-06-01T14:49:06Z,207950.76288659795
pim,"Fit a probabilistic index model as described in 
    Thas et al, 2012: <doi:10.1111/j.1467-9868.2011.01020.x>. The interface to the 
    modeling function has changed in this new version. The old version is
    still available at R-Forge.",2020-02-03,Joris Meys,https://github.com/CenterForStatistics-UGent/pim,TRUE,https://github.com/centerforstatistics-ugent/pim,12070,5,2020-02-03T17:17:01Z,2414
pinochet,"Packages data about the victims of the Pinochet regime as compiled by the Chilean National Commission for Truth and Reconciliation Report (1991, ISBN:9780268016463).",2019-06-03,Danilo Freire,http://github.com/danilofreire/pinochet,TRUE,https://github.com/danilofreire/pinochet,3593,15,2019-09-24T09:05:57Z,239.53333333333333
pinp,"A 'PNAS'-alike style for 'rmarkdown', derived from the
 'Proceedings of the National Academy of Sciences of the United States
 of America' ('PNAS', see <https://www.pnas.org>) 'LaTeX' style, and
 adapted for use with 'markdown' and 'pandoc'.",2019-09-15,Dirk Eddelbuettel and James Balamuta,http://dirk.eddelbuettel.com/code/pinp.html,TRUE,https://github.com/eddelbuettel/pinp,134564,111,2020-04-09T22:21:34Z,1212.2882882882882
pins,"Pin remote resources into a local cache to work offline,
  improve speed and avoid recomputing; discover and share resources
  in local folders, 'GitHub', 'Kaggle' or 'RStudio Connect'. Resources can 
  be anything from 'CSV', 'JSON', or image files to arbitrary R objects.",2020-05-28,Javier Luraschi,https://github.com/rstudio/pins,TRUE,https://github.com/rstudio/pins,20160,106,2020-06-03T02:32:44Z,190.18867924528303
pinyin,"Convert Chinese characters into Pinyin (the official romanization system for Standard Chinese in mainland China, Malaysia, Singapore, and Taiwan. See <https://en.wikipedia.org/wiki/Pinyin> for details), Sijiao (four or five numerical digits per character. See <https://en.wikipedia.org/wiki/Four-Corner_Method>.), Wubi (an input method with five strokes. See <https://en.wikipedia.org/wiki/Wubi_method>) or user-defined codes.",2019-05-02,Peng Zhao,https://github.com/pzhaonet/pinyin,TRUE,https://github.com/pzhaonet/pinyin,9397,28,2020-01-20T12:53:53Z,335.60714285714283
piRF,"Implements multiple state-of-the-art prediction interval methodologies for random forests. 
	These include: quantile regression intervals, out-of-bag intervals, bag-of-observations intervals, 
	one-step boosted random forest intervals, bias-corrected intervals, high-density intervals, and 
	split-conformal intervals. The implementations include a combination of novel adjustments to the 
	original random forest methodology and novel prediction interval methodologies. All of these 
	methodologies can be utilized using solely this package, rather than a collection of separate 
	packages. Currently, only regression trees are supported. Also capable of handling high dimensional data. 
	Roy, Marie-Helene and Larocque, Denis (2019) <doi:10.1177/0962280219829885>.
	Ghosal, Indrayudh and Hooker, Giles (2018) <arXiv:1803.08000>.
	Zhu, Lin and Lu, Jiaxin and Chen, Yihong (2019) <arXiv:1905.10101>.
	Zhang, Haozhe and Zimmerman, Joshua and Nettleton, Dan and Nordman, Daniel J. (2019) <doi:10.1080/00031305.2019.1585288>.
	Meinshausen, Nicolai (2006) <http://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdf>.
	Romano, Yaniv and Patterson, Evan and Candes, Emmanuel (2019) <arXiv:1905.03222>.
	Tung, Nguyen Thanh and Huang, Joshua Zhexue and Nguyen, Thuy Thi and Khan, Imran (2014) <doi:10.13140/2.1.2500.8002>.",2020-05-12,Chancellor Johnstone,http://github.com/chancejohnstone/piRF,TRUE,https://github.com/chancejohnstone/pirf,367,2,2020-05-24T20:12:49Z,183.5
pitchRx,"With 'pitchRx', one can easily obtain Major League Baseball Advanced
    Media's 'Gameday' data (as well as store it in a remote database). The
    'Gameday' website hosts a wealth of data in XML format, but perhaps most
    interesting is 'pitchfx'. Among other things, 'pitchfx' data can be used to
    recreate a baseball's flight path from a pitcher's hand to home plate. With
    pitchRx, one can easily create animations and interactive 3D 'scatterplots'
    of the baseball's flight path. 'pitchfx' data is also commonly used to
    generate a static plot of baseball locations at the moment they cross home
    plate. These plots, sometimes called strike-zone plots, can also refer to a
    plot of event probabilities over the same region. 'pitchRx' provides an easy
    and robust way to generate strike-zone plots using the 'ggplot2' package.",2015-12-09,Carson Sievert,http://cpsievert.github.com/pitchRx,TRUE,https://github.com/cpsievert/pitchrx,34159,104,2020-03-03T21:54:01Z,328.4519230769231
pivmet,"Collection of pivotal algorithms 
             for: relabelling the MCMC chains in order to undo the label 
             switching problem in Bayesian mixture models,
             as proposed in Egidi, Pappadà, Pauli and Torelli (2018a)<doi:10.1007/s11222-017-9774-2>;
             initializing the centers of the classical k-means algorithm 
             in order to obtain a better clustering solution. For further details see
             Egidi, Pappadà, Pauli and Torelli (2018b)<ISBN:9788891910233>.",2020-06-03,Leonardo Egidi,https://github.com/leoegidi/pivmet,TRUE,https://github.com/leoegidi/pivmet,5673,4,2020-06-09T13:09:18Z,1418.25
pivottabler,"Create regular pivot tables with just a few lines of R.  
    More complex pivot tables can also be created, e.g. pivot tables
    with irregular layouts, multiple calculations and/or derived 
    calculations based on multiple data frames.  Pivot tables are
    constructed using R only and can be written to a range of
    output formats (plain text, 'HTML', 'Latex' and 'Excel'), 
    including with styling/formatting.",2020-05-11,Christopher Bailiss,"http://www.pivottabler.org.uk/,
https://github.com/cbailiss/pivottabler",TRUE,https://github.com/cbailiss/pivottabler,31046,71,2020-05-12T06:13:07Z,437.2676056338028
pkgbuild,"Provides functions used to build R packages. Locates compilers
  needed to build R packages on various platforms and ensures the PATH is
  configured appropriately so R can use them.",2020-05-07,Jim Hester,https://github.com/r-lib/pkgbuild,TRUE,https://github.com/r-lib/pkgbuild,7222551,40,2020-05-06T17:41:02Z,180563.775
pkgdown,"Generate an attractive and useful website from a source package.
    'pkgdown' converts your documentation, vignettes, 'README', and more to 
    'HTML' making it easy to share information about your package online.",2020-04-09,Hadley Wickham,"https://pkgdown.r-lib.org, https://github.com/r-lib/pkgdown",TRUE,https://github.com/r-lib/pkgdown,1466334,481,2020-05-31T15:36:37Z,3048.5114345114343
pkgfilecache,"Manage optional data for your package. The data can be hosted anywhere, and you have to give a Uniform Resource Locator (URL) for each file. File integrity checks are supported. This is useful for package authors who need to ship more than the 5 Megabyte of data currently allowed by the the Comprehensive R Archive Network (CRAN).",2019-11-29,Tim Schäfer,https://github.com/dfsp-spirit/pkgfilecache,TRUE,https://github.com/dfsp-spirit/pkgfilecache,5781,5,2020-03-23T11:01:48Z,1156.2
pkgload,"Simulates the process of installing a package
    and then attaching it. This is a key part of the 'devtools' package as it
    allows you to rapidly iterate while developing a package.",2020-05-29,Jim Hester,https://github.com/r-lib/pkgload,TRUE,https://github.com/r-lib/pkgload,6016121,32,2020-05-29T12:56:18Z,188003.78125
pkgmaker,"Provides some low-level utilities to use for package
    development. It currently provides managers for multiple package specific
    options and registries, vignette, unit test and bibtex related utilities.
    It serves as a base package for packages like NMF, RcppOctave, doRNG, and
    as an incubator package for other general purposes utilities, that will
    eventually be packaged separately.
    It is still under heavy development and changes in the interface(s) are
    more than likely to happen.",2020-03-19,Renaud Gaujoux,https://renozao.github.io/pkgmaker,TRUE,https://github.com/renozao/pkgmaker,1629557,5,2020-03-19T02:44:08Z,325911.4
pkgndep,"It checks the heaviness of the packages that user's
    package depends on. For each package listed in the ""Depends"", ""Imports"" and
    ""Suggests"" fields in the DESCRIPTION file, it opens a new R session, loads the
    package and counts the number of namespaces that are loaded. The summary of
    the dependencies is visualized by a customized heatmap. Examples of dependency
    analysis can be found at <https://jokergoo.github.io/pkgndep/stat/>.",2020-05-21,Zuguang Gu,https://github.com/jokergoo/pkgndep,TRUE,https://github.com/jokergoo/pkgndep,230,8,2020-05-22T12:09:38Z,28.75
pkgnet,"Tools from the domain of graph theory can be used to quantify the complexity
             and vulnerability to failure of a software package. That is the guiding philosophy
             of this package. 'pkgnet' provides tools to analyze the dependencies between functions
             in an R package and between its imported packages.  See the pkgnet website for vignettes 
             and other supplementary information.",2020-04-06,Brian Burns,"https://github.com/uptake/pkgnet, https://uptake.github.io/pkgnet/",TRUE,https://github.com/uptake/pkgnet,15928,95,2020-05-30T04:33:06Z,167.66315789473686
pkgsearch,"Search CRAN metadata about packages by keyword, popularity,
    recent activity, package name and more. Uses the 'R-hub' search server,
    see <https://r-pkg.org> and the CRAN metadata database, that
    contains information about CRAN packages. Note that this is _not_
    a CRAN project.",2019-12-19,Gábor Csárdi,"https://github.com/r-hub/pkgsearch,
https://r-hub.github.io/pkgsearch",TRUE,https://github.com/r-hub/pkgsearch,9696,60,2020-06-09T12:33:52Z,161.6
PKNCA,"Compute standard Non-Compartmental Analysis (NCA) parameters for
    typical pharmacokinetic analyses and summarize them.",2020-06-01,Bill Denney,https://github.com/billdenney/pknca,TRUE,https://github.com/billdenney/pknca,26980,22,2020-06-01T16:07:33Z,1226.3636363636363
PKPDmisc,"A toolbox for data management common to pharmacokinetic and
  pharmacokinetic modeling and simulation, such as resampling,
  area-under-the-curve calculation, data chunking, custom csv
  output, and project scaffolding.",2020-04-07,Devin Pastoor,https://github.com/metrumresearchgroup/PKPDmisc,TRUE,https://github.com/metrumresearchgroup/pkpdmisc,11328,10,2020-04-04T15:35:52Z,1132.8
pksensi,"Applying the global sensitivity analysis workflow to investigate the parameter uncertainty and sensitivity in physiologically based kinetic (PK) models, especially the physiologically based pharmacokinetic/toxicokinetic model with multivariate outputs. The package also provides some functions to check the convergence and sensitivity of model parameters.   ",2020-05-08,Nan-Hung Hsieh,"https://github.com/nanhung/pksensi,
https://nanhung.rbind.io/pksensi",TRUE,https://github.com/nanhung/pksensi,7841,1,2020-06-08T14:55:36Z,7841
PlackettLuce,"Functions to prepare rankings data and fit the Plackett-Luce model
    jointly attributed to Plackett (1975) <doi:10.2307/2346567> and Luce
    (1959, ISBN:0486441369). The standard Plackett-Luce model is generalized
    to accommodate ties of any order in the ranking. Partial rankings, in which
    only a subset of items are ranked in each ranking, are also accommodated in
    the implementation. Disconnected/weakly connected networks implied by the
    rankings may be handled by adding pseudo-rankings with a hypothetical item.
    Optionally, a multivariate normal prior may be set on the log-worth
    parameters and ranker reliabilities may be incorporated as proposed by
    Raman and Joachims (2014) <doi:10.1145/2623330.2623654>. Maximum a
    posteriori estimation is used when priors are set. Methods are provided to
    estimate standard errors or quasi-standard errors for inference as well as
    to fit Plackett-Luce trees. See the package website or vignette for further
    details.",2019-09-16,Heather Turner,https://hturner.github.io/PlackettLuce/,TRUE,https://github.com/hturner/plackettluce,11607,6,2019-09-16T14:01:11Z,1934.5
plan,Supports the creation of 'burndown' charts and 'gantt' diagrams.,2018-05-30,Dan Kelley,http://github.com/dankelley/plan,TRUE,https://github.com/dankelley/plan,19806,30,2019-10-07T22:31:39Z,660.2
planar,Solves the electromagnetic problem of reflection and transmission at a planar multilayer interface. Also computed are the decay rates and emission profile for a dipolar emitter.,2016-02-29,Baptiste Auguie,https://github.com/baptiste/planar,TRUE,https://github.com/baptiste/planar,17660,5,2020-02-27T09:06:36Z,3532
PlaneGeometry,"An extensive set of plane geometry routines. Provides R6 classes representing triangles, circles, circular arcs, ellipses, elliptical arcs and lines, and their plot methods. Also provides R6 classes representing transformations: rotations, reflections, homotheties, scalings, general affine transformations, inversions, Möbius transformations. ",2020-02-24,Stéphane Laurent,https://github.com/stla/PlaneGeometry,TRUE,https://github.com/stla/planegeometry,2055,7,2020-04-18T19:52:24Z,293.57142857142856
plantecowrap,"Provides wrapping functions to add to capabilities to 'plantecophys' 
    (Duursma, 2015, <doi:10.1371/journal.pone.0143346>). Key added capabilities 
    include temperature responses of mesophyll conductance (gm, gmeso), apparent 
    Michaelis-Menten constant for rubisco carboxylation in air (Km, Kcair),and
    photorespiratory CO2 compensation point (GammaStar) for fitting A-Ci or A-Cc
    curves for C3 plants (for temperature responses of gm, Km, & GammaStar,  see 
    Bernacchi et al., 2002, <doi:10.1104/pp.008250>; for theory on fitting A-Ci 
    or A-Cc curves, see Farquhar et al., 1980; <doi:10.1007/BF00386231>, von 
    Caemmerer, 2000, ISBN:064306379X; Ethier & Livingston, 2004 
    <doi:10.1111/j.1365-3040.2004.01140.x>; and Gu et al., 2010, 
    <doi:10.1111/j.1365-3040.2010.02192.x>). Includes the ability to fit the 
    Arrhenius and modified Arrhenius temperature response functions (see Medlyn 
    et al., 2002, <doi:10.1046/j.1365-3040.2002.00891.x>) for maximum rubisco 
    carboxylation rates (Vcmax) and maximum electron transport rates (Jmax) (see
    Farquhar et al., 1980; <doi:10.1007/BF00386231>).",2020-04-03,Joseph Stinziano,https://github.com/jstinzi/plantecowrap,TRUE,https://github.com/jstinzi/plantecowrap,830,1,2020-04-27T14:29:18Z,830
plater,"Tools for interacting with data from experiments done in microtiter
    plates. Easily read in plate-shaped data and convert it to tidy format, 
    combine plate-shaped data with tidy data, and view tidy data in plate shape.  ",2020-03-24,Sean Hughes,"https://docs.ropensci.org/plater,
https://github.com/ropensci/plater",TRUE,https://github.com/ropensci/plater,11914,16,2020-03-17T16:25:30Z,744.625
platetools,"Collection of functions for working with multi-well microtitre
    plates, mainly 96, 384 and 1536 well plates.",2020-05-06,Scott Warchal,https://github.com/swarchal/platetools,TRUE,https://github.com/swarchal/platetools,14533,35,2020-05-06T09:34:56Z,415.22857142857146
pleiades,"Provides a set of functions for interacting with the
    'Pleiades' (<https://pleiades.stoa.org/>) 'API', including 
    getting status data, places data, and creating a 'GeoJSON' 
    based map on 'GitHub' 'gists'.",2017-06-15,Scott Chamberlain,https://github.com/ropensci/pleiades,TRUE,https://github.com/ropensci/pleiades,10069,7,2019-12-09T14:25:31Z,1438.4285714285713
plinkQC,"Genotyping arrays enable the direct measurement of an individuals
    genotype at thousands of markers. 'plinkQC' facilitates genotype quality
    control for genetic association studies as described by Anderson and
    colleagues (2010) <doi:10.1038/nprot.2010.116>. It makes 'PLINK' basic
    statistics (e.g. missing genotyping rates per individual, allele frequencies
    per genetic marker) and relationship functions accessible from 'R' and
    generates a per-individual and per-marker quality control report.
    Individuals and markers that fail the quality control can subsequently be
    removed to generate a new, clean dataset. Removal of individuals based on
    relationship status is optimised to retain as many individuals as possible
    in the study.",2019-10-19,Hannah Meyer,https://meyer-lab-cshl.github.io/plinkQC,TRUE,https://github.com/meyer-lab-cshl/plinkqc,8417,21,2020-03-13T12:16:46Z,400.8095238095238
PLNmodels,"The Poisson-lognormal model and variants can be used for 
    a variety of multivariate problems when count data are at play, including 
    principal component analysis for count data (Chiquet, Mariadassou and Robin, 
    2018 <doi:10.1214/18-AOAS1177>), discriminant analysis and 
    network inference (Chiquet, Mariadassou and Robin, 2018 <http://proceedings.mlr.press/v97/chiquet19a.html>). 
    Implements variational algorithms to fit such models accompanied with a set of 
    functions for visualization and diagnostic. ",2020-01-27,Julien Chiquet,https://jchiquet.github.io/PLNmodels/,TRUE,https://github.com/jchiquet/plnmodels,5366,31,2020-06-09T20:28:22Z,173.09677419354838
plot3logit,"An implementation of the ternary plot for interpreting regression
    coefficients of trinomial regression models, as proposed in Santi, Dickson
    and Espa (2019) <doi:10.1080/00031305.2018.1442368>. Ternary plots can be
    drawn using either 'ggtern' package (based on 'ggplot2') or 'Ternary'
    package (based on standard graphics).",2020-05-10,Flavio Santi,https://www.flaviosanti.it/software/plot3logit,TRUE,https://github.com/f-santi/plot3logit,6228,2,2020-06-09T14:31:44Z,3114
plotdap,"Easily visualize and animate 'tabledap' and 'griddap' objects obtained via the 'rerddap' package in a simple one-line command,  using either base graphics or 'ggplot2' graphics. 'plotdap' handles extracting and reshaping the data,  map projections and continental outlines.  Optionally the data can be animated through time using the 'gganmiate' package.",2020-03-20,Carson Sievert,https://github.com/ropensci/plotdap,TRUE,https://github.com/ropensci/plotdap,5860,9,2019-10-16T15:55:19Z,651.1111111111111
plotGMM,"The main function, plot_GMM, is used for plotting output from Gaussian mixture models (GMMs), 
    including both densities and overlaying mixture weight component curves from the fit GMM. The package
    also include the function, plot_cut_point, which plots the cutpoint (mu) from the GMM over a histogram
    of the distribution with several color options. Finally, the package includes the function, plot_mix_comps, 
    which is used in the plot_GMM function, and can be used to create a custom plot for overlaying mixture 
    component curves from GMMs. For the plot_mix_comps function, usage most often will be specifying 
    the ""fun"" argument within ""stat_function"" in a ggplot2 object.",2019-06-28,Philip Waggoner,NA,TRUE,https://github.com/pdwaggoner/plotgmm,6862,5,2020-06-08T15:37:32Z,1372.4
plotluck,"Examines the characteristics of a data frame and a formula to
    automatically choose the most suitable type of plot out of the following supported
    options: scatter, violin, box, bar, density, hexagon bin, spine plot, and
    heat map. The aim of the package is to let the user focus on what to plot,
    rather than on the ""how"" during exploratory data analysis. It also automates
    handling of observation weights, logarithmic axis scaling, reordering of
    factor levels, and overlaying smoothing curves and median lines. Plots are
    drawn using 'ggplot2'.",2019-06-26,Stefan Schroedl,https://github.com/stefan-schroedl/plotluck,TRUE,https://github.com/stefan-schroedl/plotluck,15066,44,2019-06-26T16:42:13Z,342.40909090909093
pls,"Multivariate regression methods
	Partial Least Squares Regression (PLSR), Principal Component
	Regression (PCR) and Canonical Powered Partial Least Squares (CPPLS).",2019-10-01,Bjørn-Helge Mevik,"http://mevik.net/work/software/pls.html,
https://github.com/bhmevik/pls",TRUE,https://github.com/bhmevik/pls,1523850,20,2020-05-03T16:46:38Z,76192.5
plsdof,"The plsdof package provides Degrees of Freedom estimates
        for Partial Least Squares (PLS) Regression. Model selection for
        PLS is based on various information criteria (aic, bic, gmdl)
        or on cross-validation. Estimates for the mean and covariance
        of the PLS regression coefficients are available. They allow
        the construction of approximate confidence intervals and the
        application of test procedures. Further, cross-validation
        procedures for Ridge Regression and Principal Components
        Regression are available.",2019-01-31,Nicole Kraemer,https://github.com/fbertran/plsdof,TRUE,https://github.com/fbertran/plsdof,20910,1,2019-10-01T10:39:23Z,20910
plsmod,"Bindings for additional regression models for use
    with the 'parsnip' package, including ordinary and spare partial least 
    squares models for regression and classification (Rohart et al (2017) 
    <doi:10.1371/journal.pcbi.1005752>).",2020-04-14,Max Kuhn,https://github.com/tidymodels/plsmod,TRUE,https://github.com/tidymodels/plsmod,788,6,2020-04-24T21:01:11Z,131.33333333333334
plsRbeta,"Provides Partial least squares Regression for (weighted) beta regression models (Bertrand 2013,  <http://journal-sfds.fr/article/view/215>) and k-fold cross-validation of such models using various criteria. It allows for missing data in the explanatory variables. Bootstrap confidence intervals constructions are also available.",2019-02-01,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/plsRbeta",TRUE,https://github.com/fbertran/plsrbeta,16532,1,2019-10-01T10:39:53Z,16532
plsRcox,"Provides Partial least squares Regression and various regular, sparse or kernel, techniques for fitting Cox models in high dimensional settings <doi:10.1093/bioinformatics/btu660>, Bastien, P., Bertrand, F., Meyer N., Maumy-Bertrand, M. (2015), Deviance residuals-based sparse PLS and sparse kernel PLS regression for censored data, Bioinformatics, 31(3):397-404. Cross validation criteria were studied in <arXiv:1810.02962>, Bertrand, F., Bastien, Ph. and Maumy-Bertrand, M. (2018), Cross validating extensions of kernel, sparse or regular partial least squares regression models to censored data.",2019-02-03,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/plsRcox",TRUE,https://github.com/fbertran/plsrcox,21800,1,2019-10-01T10:41:23Z,21800
plsRglm,Provides (weighted) Partial least squares Regression for generalized linear models and repeated k-fold cross-validation of such models using various criteria. It allows for missing data in the explanatory variables. Bootstrap confidence intervals constructions are also available.,2019-02-02,Frederic Bertrand,"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/plsRglm",TRUE,https://github.com/fbertran/plsrglm,37214,9,2019-10-01T10:41:55Z,4134.888888888889
plu,"Converts English phrases to singular or plural form
    based on the length of an associated vector.  Contains helper
    functions to create natural language lists from vectors and to include
    the length of a vector in natural language.",2020-06-09,Alexander Rossell Hayes,https://github.com/rossellhayes/plu,TRUE,https://github.com/rossellhayes/plu,0,0,2020-06-04T17:34:33Z,NA
plyr,"A set of tools that solves a common set of
    problems: you need to break a big problem down into manageable pieces,
    operate on each piece and then put all the pieces back together.  For
    example, you might want to fit a model to each spatial location or
    time point in your study, summarise data by panels or collapse
    high-dimensional arrays to simpler summary statistics. The development
    of 'plyr' has been generously supported by 'Becton Dickinson'.",2020-03-03,Hadley Wickham,"http://had.co.nz/plyr, https://github.com/hadley/plyr",TRUE,https://github.com/hadley/plyr,22372189,480,2020-03-03T15:10:13Z,46608.72708333333
pm4py,"Interface to 'PM4py' <http://pm4py.org>, a process mining library 
    in 'Python'. This package uses the 'reticulate' package to act as a bridge 
    between 'PM4Py' and the 'R' package 'bupaR'. It provides several process 
    discovery algorithms, evaluation measures, and alignments. ",2020-01-07,Felix Mannhardt,https://github.com/fmannhardt/pm4py,TRUE,https://github.com/fmannhardt/pm4py,5565,9,2020-02-02T12:22:12Z,618.3333333333334
PMA,"Performs Penalized Multivariate Analysis: a penalized
        matrix decomposition, sparse principal components analysis,
        and sparse canonical correlation analysis, described in
        Witten, Tibshirani and Hastie (2009)
        <doi:10.1093/biostatistics/kxp008> and Witten and Tibshirani
        (2009) Extensions of sparse canonical correlation analysis,
        with applications to genomic data
        <doi:10.2202/1544-6115.1470>.",2020-02-03,Daniela Witten and Rob Tibshirani,https://github.com/bnaras/PMA,TRUE,https://github.com/bnaras/pma,47982,0,2020-01-02T01:13:36Z,NA
pmd,"Paired mass distance (PMD) analysis proposed in Yu, Olkowicz and Pawliszyn (2018) <doi:10.1016/j.aca.2018.10.062> for gas/liquid chromatography–mass spectrometry (GC/LC-MS) based non-targeted analysis. PMD analysis including GlobalStd algorithm and structure/reaction directed analysis. GlobalStd algorithm could found independent peaks in m/z-retention time profiles based on retention time hierarchical cluster analysis and frequency analysis of paired mass distances within retention time groups. Structure directed analysis could be used to find potential relationship among those independent peaks in different retention time groups based on frequency of paired mass distances. A GUI for PMD analysis is also included as a 'shiny' application.",2020-06-04,Miao YU,https://yufree.github.io/pmd,TRUE,https://github.com/yufree/pmd,5551,3,2020-06-04T17:13:44Z,1850.3333333333333
pmdplyr,"Using the 'dplyr' package as a base, adds a family of functions designed to make manipulating panel data easier. Allows the addition of indexing variables to a tibble to create a pibble, and the manipulation of data based on those indexing variables.",2020-05-30,Nick Huntington-Klein,"https://nickch-k.github.io/pmdplyr,
https://github.com/NickCH-K/pmdplyr",TRUE,https://github.com/nickch-k/pmdplyr,3979,19,2020-05-30T02:03:18Z,209.42105263157896
PML,"Penalized Multi-Band Learning algorithm can be effectively implemented for circadian rhythm analysis and daily activity pattern characterization using actigraphy (continuously measured objective physical activity data). Functions for interactive visualization of actigraph data are also included. Method reference: Li, X., Kane, M., Zhang, Y., Sun, W., Song, Y., Dong, S., Lin, Q., Zhu, Q., Jiang, F., Zhao, H. (2019) A Novel Penalized Multi-band Learning Approach Characterizes the Consolidation of Sleep-Wake Circadian Rhythms During Early Childhood Development.",2020-02-11,Xinyue Li,https://github.com/xinyue-L/PML,TRUE,https://github.com/xinyue-l/pml,3861,0,2020-05-07T03:59:40Z,NA
pmml,"The Predictive Model Markup Language (PMML) is an XML-based language which provides a way for applications to define machine learning, statistical and data mining models and to share models between PMML compliant applications. More information about the PMML industry standard and the Data Mining Group can be found at <http://www.dmg.org>. The generated PMML can be imported into any PMML consuming application, such as Zementis Predictive Analytics products, which integrate with web services, relational database systems and deploy natively on Hadoop in conjunction with Hive, Spark or Storm, as well as allow predictive analytics to be executed for IBM z Systems mainframe applications and real-time, streaming analytics platforms. The package isofor (used for anomaly detection) can be installed with devtools::install_github(""Zelazny7/isofor"").",2020-04-22,Dmitriy Bolotov,"https://softwareag.github.io/r-pmml/,
https://github.com/SoftwareAG/r-pmml,
https://www.softwareag.com/corporate/products/az/zementis/default.html",TRUE,https://github.com/softwareag/r-pmml,255214,12,2020-04-22T02:01:30Z,21267.833333333332
pmpp,"Dynamic panel modelling framework based on an empirical-Bayes approach.
             Contains tools for computing point forecasts and bootstrapping prediction intervals.
             Reference: Liu et al. (2016) <doi:10.2139/ssrn.2889000>.",2019-10-15,Michal Oleszak,https://github.com/MichalOleszak/pmpp,TRUE,https://github.com/michaloleszak/pmpp,5938,0,2019-10-15T20:32:31Z,NA
PMwR,"Functions and examples for 'Portfolio
  Management with R': backtesting investment and
  trading strategies, computing profit/loss and
  returns, analysing trades, handling lists of
  transactions, reporting, and more.",2020-03-11,Enrico Schumann,"http://enricoschumann.net/PMwR/,
https://github.com/enricoschumann/PMwR,
https://gitlab.com/enricoschumann/PMwR",TRUE,https://github.com/enricoschumann/pmwr,7267,14,2020-05-26T15:30:07Z,519.0714285714286
pmxTools,"Pharmacometric tools for common data analytical tasks; closed-form solutions for calculating concentrations at given 
    times after dosing based on compartmental PK models (1-compartment, 2-compartment and 3-compartment, covering infusions, zero- 
    and first-order absorption, and lag times, after single doses and at steady state, per Bertrand & Mentre (2008) 
    <http://lixoft.com/wp-content/uploads/2016/03/PKPDlibrary.pdf>); parametric simulation from NONMEM-generated parameter estimates 
    and other output; and parsing, tabulating and plotting results generated by Perl-speaks-NONMEM (PsN).",2020-01-10,Justin Wilkins,https://github.com/kestrel99/pmxTools,TRUE,https://github.com/kestrel99/pmxtools,7610,8,2020-01-06T10:29:43Z,951.25
pointblank,"Validate data in data frames, 'tibble' objects, and in database
    tables (e.g., 'PostgreSQL' and 'MySQL'). Validation pipelines can be made
    using easily-readable, consecutive validation steps. Upon execution of the
    validation plan, several reporting options are available. User-defined
    thresholds for failure rates allow for the determination of appropriate
    reporting actions.",2020-04-02,Richard Iannone,https://github.com/rich-iannone/pointblank,TRUE,https://github.com/rich-iannone/pointblank,9985,278,2020-06-05T17:29:43Z,35.91726618705036
poio,"Read and write PO and POT files, for package translations.",2020-04-17,Richard Cotton,https://github.com/RL10N/poio,TRUE,https://github.com/rl10n/poio,11297,4,2020-04-17T03:18:44Z,2824.25
poismf,"Creates a low-rank factorization of a sparse counts matrix by maximizing Poisson likelihood with l1/l2 regularization
	with all non-negative latent factors (e.g. for recommender systems or topic modeling) (Cortes, (2018) <arXiv:1811.01908>).
	Similar to hierarchical Poisson factorization, but follows an optimization-based approach with regularization instead of a
	hierarchical structure, and is fit through either proximal gradient or conjugate gradient instead of
	variational inference.",2020-05-26,David Cortes,https://github.com/david-cortes/poismf,TRUE,https://github.com/david-cortes/poismf,3815,20,2020-05-29T16:55:13Z,190.75
poissonreg,"Bindings for Poisson regression models for use with the 
    'parsnip' package. Models include simple generalized linear models, 
    Bayesian models, and zero-inflated Poisson models (Zeileis, Kleiber, and 
    Jackman (2008) <doi:10.18637/jss.v027.i08>). ",2020-04-14,Max Kuhn,https://github.com/tidymodels/poissonreg,TRUE,https://github.com/tidymodels/poissonreg,902,6,2020-04-24T19:35:06Z,150.33333333333334
polAr,Toolbox for the Analysis of Political and Electoral Data from Argentina.,2020-05-16,Juan Pablo Ruiz Nicolini,https://github.com/electorArg/polAr,TRUE,https://github.com/electorarg/polar,406,3,2020-05-26T23:16:38Z,135.33333333333334
polaroid,"Create hexagonal shape sticker image.
  'polaroid' can be used in user's web browser.
  'polaroid' can be used in 'shinyapps.io'.
  In both way, user can download created 'hexSticker' as 'PNG' image.
  'polaroid' is built based on 'argonDash', 'colourpicker' and 'hexSticker' R package.",2020-03-30,Jinhwan Kim,https://github.com/jhk0530/polaroid,TRUE,https://github.com/jhk0530/polaroid,920,6,2020-04-03T17:48:17Z,153.33333333333334
policytree,"Multi-action treatment effect estimation and policy learning
 as in Zhou, Athey and Wager (2018) <arXiv:1810.04778>.",2020-03-21,Erik Sverdrup,https://github.com/grf-labs/policytree,TRUE,https://github.com/grf-labs/policytree,2350,11,2020-05-26T01:34:51Z,213.63636363636363
polite,"Be responsible when scraping data from websites by following polite principles: introduce yourself, ask for permission, take slowly and never ask twice. ",2019-11-30,Dmytro Perepolkin,https://github.com/dmi3kno/polite,TRUE,https://github.com/dmi3kno/polite,3653,186,2020-03-29T11:43:45Z,19.63978494623656
politicaldata,"Provides useful functions for obtaining commonly-used data
    in political analysis and political science, including from sources
    such as the Comparative Agendas Project <https://www.comparativeagendas.net>,
    which provides data on politics and policy from 20+ countries, the
    MIT Election and Data Science Lab <https://www.electionlab.mit.edu>,
    and FiveThirtyEight <https://www.FiveThirtyEight.com>.",2019-06-17,G. Elliott Morris,NA,TRUE,https://github.com/elliottmorris/politicaldata,6382,81,2019-08-10T13:38:32Z,78.79012345679013
pollen,"Supports analysis of aerobiological data. 
    Available features include determination of pollen season limits, 
    replacement of outliers (Kasprzyk and Walanus (2014) <doi:10.1007/s10453-014-9332-8>),
    and calculation of growing degree days (Baskerville and Emin (1969) <doi:10.2307/1933912>).",2020-03-15,Jakub Nowosad,https://nowosad.github.io/pollen/,TRUE,https://github.com/nowosad/pollen,13326,2,2020-03-18T15:23:05Z,6663
polmineR,"Library for corpus analysis using the Corpus Workbench as an
    efficient back end for indexing and querying large corpora. The package offers
    functionality to flexibly create partitions and to carry out basic statistical
    operations (count, co-occurrences etc.). The original full text of documents
    can be reconstructed and inspected at any time. Beyond that, the package is
    intended to serve as an interface to packages implementing advanced statistical
    procedures. Respective data structures (document term matrices, term co-
    occurrence matrices etc.) can be created based on the indexed corpora.",2019-12-17,Andreas Blaette,https://www.github.com/PolMine/polmineR,TRUE,https://github.com/polmine/polminer,18491,28,2019-12-18T20:23:57Z,660.3928571428571
polyclip,"R port of Angus Johnson's open source library Clipper. Performs polygon clipping operations (intersection, union, set minus, set difference) for polygonal regions of arbitrary complexity, including holes. Computes offset polygons (spatial buffer zones, morphological dilations, Minkowski dilations) for polygonal regions and polygonal lines. Computes Minkowski Sum of general polygons. There is a function for removing self-intersections from polygon data.",2019-03-14,Angus Johnson (C++ original,"http://www.angusj.com/delphi/clipper.php,
https://sourceforge.net/projects/polyclipping,
https://github.com/baddstats/polyclip",TRUE,https://github.com/baddstats/polyclip,1113683,16,2019-08-21T07:28:44Z,69605.1875
polyCub,"Numerical integration of continuously differentiable
    functions f(x,y) over simple closed polygonal domains.
    The following cubature methods are implemented:
    product Gauss cubature (Sommariva and Vianello, 2007,
    <doi:10.1007/s10543-007-0131-2>),
    the simple two-dimensional midpoint rule
    (wrapping 'spatstat' functions),
    adaptive cubature for radially symmetric functions via line
    integrate() along the polygon boundary (Meyer and Held, 2014,
    <doi:10.1214/14-AOAS743>, Supplement B),
    and integration of the bivariate Gaussian density based on
    polygon triangulation.
    For simple integration along the axes, the 'cubature' package
    is more appropriate.",2019-02-07,Sebastian Meyer,https://github.com/bastistician/polyCub,TRUE,https://github.com/bastistician/polycub,44418,3,2020-03-12T08:55:21Z,14806
polyglot,Use the R console as an interactive learning environment to memorize any two columns dataset.,2020-05-18,Félix Luginbuhl,"https://felixluginbuhl.com/polyglot,
https://github.com/lgnbhl/polyglot",TRUE,https://github.com/lgnbhl/polyglot,7759,1,2020-05-17T15:26:47Z,7759
polylabelr,"A wrapper around the C++ library 'polylabel' from 'Mapbox', 
    providing an efficient routine for finding the approximate pole of 
    inaccessibility of a polygon, which usually serves as an excellent candidate
    for labeling of a polygon.",2020-04-19,Johan Larsson,"https://github.com/jolars/polylabelr,
https://jolars.github.io/polylabelr",TRUE,https://github.com/jolars/polylabelr,20661,11,2020-04-19T16:56:16Z,1878.2727272727273
polyMatrix,"
  Implementation of class ""polyMatrix"" for storing a matrix of polynomials and implements 
  basic matrix operations; including a determinant and characteristic polynomial.
  It is based on the package 'polynom' and uses a lot of its methods to implement matrix operations.
  This package includes 3 methods of triangularization of polynomial matrices:
  Extended Euclidean algorithm which is most classical but numerically unstable;
  Sylvester algorithm based on LQ decomposition;
  Interpolation algorithm is based on LQ decomposition and Newton interpolation.
  Both methods are described in 
  D. Henrion & M. Sebek, Reliable numerical methods for polynomial matrix triangularization,
  IEEE Transactions on Automatic Control (Volume 44, Issue 3, Mar 1999, Pages 497-508) <doi:10.1109/9.751344>
  and in 
  Salah Labhalla, Henri Lombardi & Roger Marlin, 
  Algorithmes de calcule de la reduction de Hermite d'une matrice a coefficients polynomeaux,
  Theoretical Computer Science (Volume 161, Issue 1-2, July 1996, Pages 69-92) <doi:10.1016/0304-3975(95)00090-9>.",2020-06-04,Nikolai Ryzhkov,https://github.com/namezys/polymatrix,TRUE,https://github.com/namezys/polymatrix,2260,0,2020-02-25T10:51:59Z,NA
polyRAD,"Read depth data from genotyping-by-sequencing (GBS) or restriction 
  site-associated DNA sequencing (RAD-seq) are imported and used to make Bayesian
  probability estimates of genotypes in polyploids or diploids.  The genotype 
  probabilities, posterior mean genotypes, or most probable genotypes can then
  be exported for downstream analysis.  'polyRAD' is described by Clark et al.
  (2019) <doi:10.1534/g3.118.200913>.  A variant calling pipeline for highly
  duplicated genomes is also included and is described by Clark et al. (2020)
  <doi:10.1101/2020.01.11.902890>.",2020-05-12,Lindsay V. Clark,https://github.com/lvclark/polyRAD,TRUE,https://github.com/lvclark/polyrad,6986,10,2020-05-28T16:59:03Z,698.6
polyreg,"Automate formation and evaluation of polynomial regression models. The motivation for this package is described in 'Polynomial Regression As an Alternative to Neural Nets' by Xi Cheng, Bohdan Khomtchouk, Norman Matloff, and Pete Mohanty (<arXiv:1806.06850>).",2020-04-04,Norm Matloff,https://github.com/matloff/polyreg,TRUE,https://github.com/matloff/polyreg,4898,168,2020-04-22T06:54:03Z,29.154761904761905
pomdp,Provides the infrastructure to define and analyze the solutions of Partially Observable Markov Decision Processes (POMDP) models. The package includes pomdp-solve to solve POMDPs using a variety of exact and approximate value iteration algorithms. Smallwood and Sondik (1973) <doi:10.1287/opre.21.5.1071>.,2020-05-07,Hossein Kamalzadeh,https://github.com/farzad/pomdp,TRUE,https://github.com/farzad/pomdp,7149,2,2020-05-30T23:28:24Z,3574.5
pomp,"Tools for data analysis with partially observed Markov process (POMP) models (also known as stochastic dynamical systems, hidden Markov models, and nonlinear, non-Gaussian, state-space models).  The package provides facilities for implementing POMP models, simulating them, and fitting them to time series data by a variety of frequentist and Bayesian methods.  It is also a versatile platform for implementation of inference methods for general POMP models.",2020-04-10,Aaron A. King,https://kingaa.github.io/pomp/,TRUE,https://github.com/kingaa/pomp,80596,64,2020-06-03T16:28:23Z,1259.3125
pool,"Enables the creation of object pools, which make it less
    computationally expensive to fetch a new object. Currently the
    only supported pooled objects are 'DBI' connections.",2019-10-03,Joe Cheng,https://github.com/rstudio/pool,TRUE,https://github.com/rstudio/pool,149832,153,2019-10-04T16:34:49Z,979.2941176470588
poorman,A simple replication of key 'dplyr' verbs using only base R.,2020-05-10,Nathan Eastwood,https://github.com/nathaneastwood/poorman,TRUE,https://github.com/nathaneastwood/poorman,1713,119,2020-06-07T14:16:32Z,14.394957983193278
PopED,"Optimal experimental designs for both population and individual
    studies based on nonlinear mixed-effect models. Often this is based on a
    computation of the Fisher Information Matrix. This package was developed
    for pharmacometric problems, and examples and predefined models are available
    for these types of systems. The methods are described in Nyberg et al. 
    (2012) <doi:10.1016/j.cmpb.2012.05.005>, and Foracchia et al. (2004) 
    <doi:10.1016/S0169-2607(03)00073-7>.",2018-09-10,Andrew C. Hooker,http://poped.sourceforge.net,TRUE,https://github.com/andrewhooker/poped,23369,14,2020-06-05T15:32:56Z,1669.2142857142858
popEpi,"Enables computation of epidemiological statistics, including those 
    where counts or mortality rates of the reference population are used. 
    Currently supported: excess hazard models, rates, mean survival times, 
    relative survival, and standardized incidence and mortality ratios 
    (SIRs/SMRs), all of which can be easily adjusted for by covariates such as 
    age. Fast splitting and aggregation of 'Lexis' objects (from package 'Epi') 
    and other computations achieved using 'data.table'. ",2019-09-28,Joonas Miettinen,https://github.com/WetRobot/popEpi,TRUE,https://github.com/wetrobot/popepi,60325,2,2019-11-06T18:41:39Z,30162.5
popkin,"Provides functions to estimate the kinship matrix of individuals from a large set of biallelic SNPs, and extract inbreeding coefficients and the generalized FST (Wright's fixation index).  Method described in Ochoa and Storey (2016) <doi:10.1101/083923>.",2019-12-17,Alejandro Ochoa,https://github.com/StoreyLab/popkin/,TRUE,https://github.com/storeylab/popkin,9179,13,2020-02-18T21:29:04Z,706.0769230769231
poppr,"Population genetic analyses for hierarchical analysis of partially
    clonal populations built upon the architecture of the 'adegenet' package. 
    Originally described in Kamvar, Tabima, and Grünwald (2014) 
    <doi:10.7717/peerj.281> with version 2.0 described in Kamvar, Brooks, and 
    Grünwald (2015) <doi:10.3389/fgene.2015.00208>.",2020-06-02,Zhian N. Kamvar,"https://grunwaldlab.github.io/poppr,
https://github.com/grunwaldlab/poppr,
https://grunwaldlab.github.io/Population_Genetics_in_R/",TRUE,https://github.com/grunwaldlab/poppr,105968,40,2020-06-03T00:29:41Z,2649.2
poptrend,"Functions to estimate and plot smooth or linear population trends, or population indices, 
    from animal or plant count survey data.",2016-12-13,Jonas Knape,https://github.com/jknape/poptrend,TRUE,https://github.com/jknape/poptrend,9331,5,2020-04-21T16:36:39Z,1866.2
portalr,"Download and generate summaries for the rodent,
    plant, ant, and weather data from the Portal Project. Portal is a
    long-term (and ongoing) experimental monitoring site in the Chihuahua
    desert. The raw data files can be found at
    <https://github.com/weecology/portaldata>.",2020-04-28,Glenda M. Yenni,"https://weecology.github.io/portalr/,
https://github.com/weecology/portalr",TRUE,https://github.com/weecology/portalr,9061,8,2020-06-06T00:01:25Z,1132.625
portfolio,Classes for analysing and implementing equity portfolios.,2020-03-14,Jeff Enos,https://github.com/dgerlanc/portfolio,TRUE,https://github.com/dgerlanc/portfolio,44333,5,2020-03-10T02:09:28Z,8866.6
portfolioBacktest,"Automated backtesting of multiple portfolios over multiple 
    datasets of stock prices in a rolling-window fashion. Intended for 
    researchers and practitioners to backtest a set of different portfolios, 
    as well as by a course instructor to assess the students in their portfolio 
    design in a fully automated and convenient manner, with results conveniently 
    formatted in tables and plots. Each portfolio design is easily defined as a
    function that takes as input a window of the stock prices and outputs the 
    portfolio weights. Multiple portfolios can be easily specified as a list 
    of functions or as files in a folder. Multiple datasets can be conveniently 
    extracted randomly from different markets, different time periods, and 
    different subsets of the stock universe. The results can be later assessed 
    and ranked with tables based on a number of performance criteria (e.g., 
    expected return, volatility, Sharpe ratio, drawdown, turnover rate, return 
    on investment, computational time, etc.), as well as plotted in a number of 
    ways with nice barplots and boxplots.",2019-10-07,Daniel P. Palomar,"https://CRAN.R-project.org/package=portfolioBacktest,
https://github.com/dppalomar/portfolioBacktest",TRUE,https://github.com/dppalomar/portfoliobacktest,5169,17,2020-03-19T06:23:15Z,304.05882352941177
PostcodesioR,"Free UK geocoding using data from Office for National Statistics.
    It is using several functions to get information about post codes, outward
    codes, reverse geocoding, nearest post codes/outward codes, validation, or
    randomly generate a post code. API wrapper around <https://postcodes.io>.",2019-08-24,Eryk Walczak,https://github.com/ropensci/PostcodesioR/,TRUE,https://github.com/ropensci/postcodesior,3650,29,2020-03-04T19:28:59Z,125.86206896551724
postDoubleR,"Implements post double selection using double machine learning,
             see Chernozhukov, Chetverikov, Demirer, Duflo,
             Hansen, Newey, Robins (2017) <doi:10.1111/ectj.12097>, 
             for various models, using several back ends. Allows the user flexibility
             in specifying their own methods for estimation.  ",2019-10-07,Juraj Szitás,https://github.com/JSzitas/postDoubleR,TRUE,https://github.com/jszitas/postdoubler,2827,4,2019-10-19T20:35:24Z,706.75
posterdown,"Use 'rmarkdown' and 'pagedown' to generate
    HTML and PDF conference posters.",2019-10-09,Brent Thorne,https://github.com/brentthorne/posterdown,TRUE,https://github.com/brentthorne/posterdown,4112,534,2020-05-01T18:04:39Z,7.700374531835206
PosteriorBootstrap,"An implementation of a non-parametric statistical model using a
    parallelised Monte Carlo sampling scheme. The method implemented in this
    package allows non-parametric inference to be regularized for small sample
    sizes, while also being more accurate than approximations such as
    variational Bayes. The concentration parameter is an effective sample size
    parameter, determining the faith we have in the model versus the data. When
    the concentration is low, the samples are close to the exact Bayesian
    logistic regression method; when the concentration is high, the samples are
    close to the simplified variational Bayes logistic regression. The method is
    described in full in the paper Lyddon, Walker, and Holmes (2018),
    ""Nonparametric learning from Bayesian models with randomized objective
    functions"" <arXiv:1806.11544>.",2019-10-09,James Robinson,https://github.com/alan-turing-institute/PosteriorBootstrap/,TRUE,https://github.com/alan-turing-institute/posteriorbootstrap,2724,2,2019-10-31T14:25:24Z,1362
POUMM,"The Phylogenetic Ornstein-Uhlenbeck Mixed Model (POUMM) allows to 
    estimate the phylogenetic heritability of continuous traits, to test 
    hypotheses of neutral evolution versus stabilizing selection, to quantify 
    the strength of stabilizing selection, to estimate measurement error and to
    make predictions about the evolution of a phenotype and phenotypic variation 
    in a population. The package implements combined maximum likelihood and 
    Bayesian inference of the univariate Phylogenetic Ornstein-Uhlenbeck Mixed 
    Model, fast parallel likelihood calculation, maximum likelihood 
    inference of the genotypic values at the tips, functions for summarizing and
    plotting traces and posterior samples, functions for simulation of a univariate 
    continuous trait evolution model along a phylogenetic tree. So far, the 
    package has been used for estimating the heritability of quantitative traits
    in macroevolutionary and epidemiological studies, see e.g. 
    Bertels et al. (2017) <doi:10.1093/molbev/msx246> and 
    Mitov and Stadler (2018) <doi:10.1093/molbev/msx328>. The algorithm for 
    parallel POUMM likelihood calculation has been published in 
    Mitov and Stadler (2019) <doi:10.1111/2041-210X.13136>.",2019-12-05,Venelin Mitov,"https://venelin.github.io/POUMM/index.html,
https://github.com/venelin/POUMM",TRUE,https://github.com/venelin/poumm,9326,3,2019-12-07T07:25:06Z,3108.6666666666665
povcalnetR,"Provides an interface to compute poverty and inequality indicators for more than 160 countries and regions from the World Bank's database of household surveys. It has the same functionality as the 'Povcalnet' website (<http://iresearch.worldbank.org/PovcalNet/>). 'Povcalnet' is a computational tool that allows users to estimate poverty rates for regions, sets of countries or individual countries, over time and at any poverty line. 'Povcalnet' is managed jointly by the data and research group in the World Bank's development economics division. It draws heavily upon a strong collaboration with the poverty and equity global practice, which is responsible for the gathering and harmonization of the underlying survey data.",2020-05-19,Tony Fujs,https://github.com/worldbank/povcalnetR,TRUE,https://github.com/worldbank/povcalnetr,3276,6,2020-05-29T05:49:07Z,546
powdR,"Full pattern summation of X-ray powder diffraction data as
  described in Chipera and Bish (2002) <doi:10.1107/S0021889802017405>.
  Derives quantitative estimates of crystalline and amorphous phase
  concentrations in complex mixtures.",2020-05-04,Benjamin Butler,http://github.com/benmbutler/powdR,TRUE,https://github.com/benmbutler/powdr,7384,2,2020-06-09T10:33:11Z,3692
Power2Stage,"Contains functions to obtain the operational characteristics of 
    bioequivalence studies with 2-stage designs (TSD) via simulations.",2019-04-20,Detlew Labes,https://github.com/Detlew/Power2Stage,TRUE,https://github.com/detlew/power2stage,19972,1,2020-04-07T17:44:15Z,19972
poweRlaw,"An implementation of maximum likelihood estimators
    for a variety of heavy tailed distributions, including both the
    discrete and continuous power law distributions. Additionally, a
    goodness-of-fit based approach is used to estimate the lower cut-off
    for the scaling region.",2020-04-25,Colin Gillespie,https://github.com/csgillespie/poweRlaw,TRUE,https://github.com/csgillespie/powerlaw,83773,74,2020-05-19T21:35:05Z,1132.0675675675675
powerlmm,"Calculate power for the 'time x treatment' effect
    in two- and three-level multilevel longitudinal studies with missing data.
    Both the third-level factor (e.g. therapists, schools, or physicians),
    and the second-level factor (e.g. subjects), can be assigned random slopes.
    Studies with partially nested designs, unequal cluster sizes,
    unequal allocation to treatment arms, and different dropout patterns
    per treatment are supported. For all designs power can be
    calculated both analytically and via simulations. The analytical
    calculations extends the method described in Galbraith et al. (2002)
    <doi:10.1016/S0197-2456(02)00205-2>, to three-level models.
    Additionally, the simulation tools provides flexible ways to investigate
    bias, Type I errors and the consequences of model misspecification.",2018-08-14,Kristoffer Magnusson,https://github.com/rpsychologist/powerlmm,TRUE,https://github.com/rpsychologist/powerlmm,12831,67,2020-05-14T17:54:35Z,191.50746268656715
PowerTOST,"Contains functions to calculate power and sample size for
    various study designs used in bioequivalence studies. Use known.designs() to
    see the designs supported. Power and sample size can be obtained based on
    different methods, amongst them prominently the TOST procedure (two one-sided t-tests).
    See README and NEWS for further information.",2019-12-19,Detlew Labes,https://github.com/Detlew/PowerTOST,TRUE,https://github.com/detlew/powertost,45168,6,2020-05-28T13:20:00Z,7528
ppcong,"A simple interface for interacting with ProPublica's 'Congress' API,
    which provides data about current and former members of both chambers of the
    U.S. Congress and can be found at the following URL: <https://projects.propublica.org/api-docs/congress-api/>.",2019-12-12,Michael W. Kearney,https://github.com/mkearney/ppcong,TRUE,https://github.com/mkearney/ppcong,2007,5,2019-12-13T16:05:12Z,401.4
ppgmmga,Projection Pursuit (PP) algorithm for dimension reduction based on Gaussian Mixture Models (GMMs) for density estimation using Genetic Algorithms (GAs) to maximise an approximated negentropy index. For more details see Scrucca and Serafini (2019) <doi:10.1080/10618600.2019.1598871>.,2019-07-08,Alessio Serafini,https://github.com/luca-scr/ppgmmga,TRUE,https://github.com/luca-scr/ppgmmga,6466,3,2019-11-29T10:10:15Z,2155.3333333333335
ppitables,"The Poverty Probability Index (PPI) is a poverty measurement tool 
    for organizations and businesses with a mission to serve the poor. The PPI 
    is statistically-sound, yet simple to use: the answers to 10 questions about 
    a household’s characteristics and asset ownership are scored to compute the 
    likelihood that the household is living below the poverty line – or above by 
    only a narrow margin. This package contains country-specific lookup data tables
    used as reference to determine the poverty likelihood of a household based
    on their score from the country-specific PPI questionnaire. These lookup 
    tables have been extracted from documentation of the PPI found at 
    <https://www.povertyindex.org> and managed by Innovations for Poverty Action 
    <https://www.poverty-action.org>.",2020-01-08,Ernest Guevarra,https://github.com/validmeasures/ppitables,TRUE,https://github.com/validmeasures/ppitables,10288,3,2020-01-27T11:19:53Z,3429.3333333333335
PPMR,"Efficient statistical inference of two-sample MR (Mendelian Randomization) analysis. 
    It can account for the correlated instruments and the horizontal pleiotropy, 
    and can provide the accurate estimates of both causal effect and horizontal 
    pleiotropy effect as well as the two corresponding p-values. There are two main 
    functions in the 'PPMR' package. One is PMR_individual() for individual level data, 
    the other is PMR_summary() for summary data.",2019-08-09,Michael Kleinsasser,NA,TRUE,https://github.com/umich-biostatistics/ppmr,3094,0,2019-08-08T13:40:48Z,NA
PPQplan,"Assessment for statistically-based PPQ sampling plan, including calculating the passing probability, optimizing the baseline and high performance cutoff points, visualizing the PPQ plan and power dynamically. The analytical idea is based on the simulation methods from the textbook ""Burdick, R. K., LeBlond, D. J., Pfahler, L. B., Quiroz, J., Sidor, L., Vukovinsky, K., & Zhang, L. (2017). Statistical Methods for CMC Applications. In Statistical Applications for Chemistry, Manufacturing and Controls (CMC) in the Pharmaceutical Industry (pp. 227-250). Springer, Cham.""",2019-09-03,Yalin Zhu,"https://allenzhuaz.github.io/PPQplan/,
https://github.com/allenzhuaz/PPQplan",TRUE,https://github.com/allenzhuaz/ppqplan,6502,0,2019-09-03T22:24:19Z,NA
prais,"The Prais-Winsten estimator (Prais & Winsten, 1954) takes into account AR(1) serial correlation of the errors in a linear regression model. The procedure recursively estimates the coefficients and the error autocorrelation of the specified model until sufficient convergence of the AR(1) coefficient is attained.",2019-03-10,Franz X. Mohr,https://github.com/franzmohr/prais,TRUE,https://github.com/franzmohr/prais,26999,0,2020-06-03T20:38:47Z,NA
praise,"Build friendly R packages that
    praise their users if they have done something
    good, or they just need it to feel better.",2015-08-11,Gabor Csardi,https://github.com/gaborcsardi/praise,TRUE,https://github.com/gaborcsardi/praise,6879232,114,2019-07-04T08:47:53Z,60344.14035087719
prcbench,A testing workbench for evaluating precision-recall curves under various conditions.,2020-03-26,Takaya Saito,"http://takayasaito.github.io/prcbench/,
https://github.com/takayasaito/prcbench",TRUE,https://github.com/takayasaito/prcbench,14572,4,2020-03-26T22:27:14Z,3643
prcr,"Provides an easy-to-use yet adaptable set of tools to conduct person-center analysis using a two-step clustering procedure. As described in Bergman and El-Khouri (1999) <DOI:10.1002/(SICI)1521-4036(199910)41:6%3C753::AID-BIMJ753%3E3.0.CO;2-K>, hierarchical clustering is performed to determine the initial partition for the subsequent k-means clustering procedure.",2020-02-09,Joshua M Rosenberg,https://github.com/jrosen48/prcr,TRUE,https://github.com/jrosen48/prcr,14739,2,2020-02-08T19:12:40Z,7369.5
pre,"Derives prediction rule ensembles (PREs). Largely follows the
    procedure for deriving PREs as described in Friedman & Popescu (2008; 
    <DOI:10.1214/07-AOAS148>), with adjustments and improvements. The 
    main function pre() derives prediction rule ensembles consisting of 
    rules and/or linear terms for continuous, binary, count, multinomial, 
    and multivariate continuous responses. Function gpe() derives 
    generalized prediction ensembles, consisting of rules, hinge and linear 
    functions of the predictor variables.",2020-03-06,Marjolein Fokkema,https://github.com/marjoleinF/pre,TRUE,https://github.com/marjoleinf/pre,43331,38,2020-04-20T10:45:03Z,1140.2894736842106
precisely,"Estimate sample size based on precision rather than
    power. 'precisely' is a study planning tool to calculate sample size
    based on precision. Power calculations are focused
    on whether or not an estimate will be statistically significant;
    calculations of precision are based on the same principles as power
    calculation but turn the focus to the width of the confidence
    interval. 'precisely' is based on the work of Rothman and Greenland 
    (2018) <doi: 10.1097/EDE.0000000000000876>.",2020-06-02,Malcolm Barrett,https://github.com/malcolmbarrett/precisely,TRUE,https://github.com/malcolmbarrett/precisely,0,68,2020-06-03T21:37:52Z,0
precrec,"Accurate calculations and visualization of precision-recall and ROC (Receiver Operator Characteristics)
    curves.",2020-05-28,Takaya Saito,"http://takayasaito.github.io/precrec,
https://github.com/takayasaito/precrec",TRUE,https://github.com/takayasaito/precrec,32335,29,2020-06-03T20:11:21Z,1115
predict3d,"Draw 2 dimensional and three dimensional plot for multiple regression models using package 'ggplot2' and 'rgl'.
   Supports linear models (lm), generalized linear models (glm) and local polynomial regression fittings (loess).  ",2019-09-03,Keon-Woong Moon,https://github.com/cardiomoon/predict3d,TRUE,https://github.com/cardiomoon/predict3d,8566,5,2020-03-28T02:02:29Z,1713.2
prediction,"A one-function package containing 'prediction()', a type-safe alternative to 'predict()' that always returns a data frame. The 'summary()' method provides a data frame with average predictions, possibly over counterfactual versions of the data (a la the 'margins' command in 'Stata'). Marginal effect estimation is provided by the related package, 'margins' <https://cran.r-project.org/package=margins>. The package currently supports common model types (e.g., ""lm"", ""glm"") from the 'stats' package, as well as numerous other model classes from other add-on packages. See the README or main package documentation page for a complete listing.",2019-06-17,Thomas J. Leeper,https://github.com/leeper/prediction,TRUE,https://github.com/leeper/prediction,324571,72,2019-12-24T16:43:10Z,4507.930555555556
preference,"Design and analyze two-stage randomized trials with a continuous
    outcome measure. The package contains functions to compute the required 
    sample size needed to detect a given preference, treatment, and selection 
    effect; alternatively, the package contains functions that can report the 
    study power given a fixed sample size. Finally, analysis functions are 
    provided to test each effect using either summary data (i.e. means, 
    variances) or raw study data.",2018-11-29,Michael Kane,https://github.com/kaneplusplus/preference,TRUE,https://github.com/kaneplusplus/preference,9474,2,2019-07-28T21:01:42Z,4737
prereg,Provides a collection of templates to author preregistration documents for scientific studies in PDF format.,2019-01-09,Frederik Aust,https://github.com/crsh/prereg,TRUE,https://github.com/crsh/prereg,12775,35,2019-08-01T08:58:16Z,365
presentes,"Compilation and digitalization of the official registry of victims of state terrorism in Argentina during the last
             military coup. The original data comes from RUVTE-ILID (2019) <https://www.argentina.gob.ar/sitiosdememoria/ruvte/informe> and <http://basededatos.parquedelamemoria.org.ar/registros/>. The title, presentes, comes from present in spanish.",2019-11-05,Diego Kozlowski,https://diegokoz.github.io/presentes/,TRUE,https://github.com/diegokoz/presentes,2366,6,2019-11-26T15:06:19Z,394.3333333333333
prettyB,"Drop-in replacements for standard base graphics functions. The 
    replacements are prettier versions of the originals.",2019-05-17,Colin Gillespie,https://github.com/jumpingrivers/prettyB/,TRUE,https://github.com/jumpingrivers/prettyb,4109,51,2019-07-22T15:29:53Z,80.56862745098039
prettydoc,"Creating tiny yet beautiful documents and vignettes from R
    Markdown. The package provides the 'html_pretty' output format as an
    alternative to the 'html_document' and 'html_vignette' engines that
    convert R Markdown into HTML pages. Various themes and syntax highlight
    styles are supported.",2019-11-23,Yixuan Qiu,https://github.com/yixuan/prettydoc,TRUE,https://github.com/yixuan/prettydoc,232895,278,2020-05-12T16:59:42Z,837.7517985611511
prettyGraphs,"Simple and crisp publication-quality graphics for the ExPosition family of packages.
  See An ExPosition of the Singular Value Decomposition in R (Beaton et al 2014) <doi:10.1016/j.csda.2013.11.006>.",2018-12-18,Derek Beaton,NA,TRUE,https://github.com/derekbeaton/exposition-family_old,61403,2,2019-11-16T21:33:20Z,30701.5
prettyunits,"Pretty, human readable formatting of quantities.
    Time intervals: '1337000' -> '15d 11h 23m 20s'.
    Vague time intervals: '2674000' -> 'about a month ago'.
    Bytes: '1337' -> '1.34 kB'.",2020-01-24,Gabor Csardi,https://github.com/gaborcsardi/prettyunits,TRUE,https://github.com/gaborcsardi/prettyunits,9316452,85,2020-01-24T17:02:07Z,109605.31764705882
prevederer,"Easy and efficient access to the API provided by 'Prevedere', 
  an industry insights and predictive analytics company. Query and 
  download indicators, models and workbenches built with 'Prevedere' for further 
  analysis and reporting <https://www.prevedere.com/>.",2019-07-23,Wil Davis,"https://github.com/wkdavis/prevederer,
https://api.prevedere.com/index.html,
https://www.prevedere.com/",TRUE,https://github.com/wkdavis/prevederer,3349,1,2019-08-02T12:51:58Z,3349
prewas,"Standardize the pre-processing of genomic variants before 
    performing a bacterial genome-wide association study (bGWAS). prewas creates
    a variant matrix (where each row is a variant, each column is a sample, and 
    the entries are presence - 1 - or absence - 0 - of the variant) that can be 
    used as input for bGWAS tools. When creating the binary variant matrix, 
    prewas can perform 3 pre-processing steps including: dealing with 
    multiallelic SNPs, (optional) dealing with SNPs in overlapping genes, and 
    choosing a reference allele. prewas can output matrices for use with both 
    SNP-based bGWAS and gene-based bGWAS. This method is described in Saund et 
    al. (2019) <doi:10.1101/2019.12.20.873158>. prewas can also provide gene 
    matrices for variants with specific SnpEff annotations (Cingolani et al. 
    2012).",2020-03-21,Katie Saund,http://github.com/Snitkin-Lab-Umich/prewas,TRUE,https://github.com/snitkin-lab-umich/prewas,1723,2,2020-03-23T14:25:39Z,861.5
priceR,"Functions to aid in microeconomic analysis and handling of price and currency data. This includes extraction of relevant data (e.g. from World Bank API, and other sources), data cleaning/parsing, and standardisation.",2020-03-23,Steve Condylios,https://github.com/stevecondylios/priceR,TRUE,https://github.com/stevecondylios/pricer,4771,1,2020-03-22T21:18:24Z,4771
pricesensitivitymeter,"An implementation of the van Westendorp Price
    Sensitivity Meter in R, which is a survey-based approach
	to analyze consumer price preferences and sensitivity
    (van Westendorp 1976, isbn:9789283100386).",2019-08-23,Max Alletsee,https://github.com/alletsee/pricesensitivitymeter,TRUE,https://github.com/alletsee/pricesensitivitymeter,10265,6,2020-05-20T05:13:59Z,1710.8333333333333
princurve,"Fitting a principal curve to a data matrix in arbitrary dimensions. 
  Hastie and Stuetzle (1989) <doi:10.2307/2289936>.",2019-05-29,Kurt Hornik,https://github.com/rcannood/princurve,TRUE,https://github.com/rcannood/princurve,91933,23,2019-07-25T10:04:35Z,3997.086956521739
printr,"Extends the S3 generic function knit_print() in 'knitr'
    to automatically print some objects using an appropriate format such as
    Markdown or LaTeX. For example, data frames are automatically printed as
    tables, and the help() pages can also be rendered in 'knitr' documents.",2017-05-19,Yihui Xie,https://yihui.name/printr/,TRUE,https://github.com/yihui/printr,44053,114,2019-11-18T05:15:53Z,386.4298245614035
prioritizr,"Conservation prioritization using integer
    programming techniques. To solve large-scale problems, users
    should install the 'gurobi' optimizer
    (available from <http://www.gurobi.com/>).",2020-05-15,Jeffrey O Hanson,"https://prioritizr.net, https://github.com/prioritizr/prioritizr",TRUE,https://github.com/prioritizr/prioritizr,16384,43,2020-06-07T21:49:02Z,381.0232558139535
prioritizrdata,Conservation planning data sets for learning how to use the 'prioritizr' package <https://CRAN.R-project.org/package=prioritizr>.,2018-05-22,Richard Schuster,"https://prioritizr.github.io/prioritizrdata,
https://github.com/prioritizr/prioritizrdata",TRUE,https://github.com/prioritizr/prioritizrdata,9768,1,2019-11-09T04:02:35Z,9768
prism,"Allows users to access the Oregon State Prism climate data. Using
    the web service API data can easily downloaded in bulk and loaded into R for
    spatial analysis. Some user friendly visualizations are also provided.",2018-12-10,Hart Edmund,http://github.com/ropensci/prism,TRUE,https://github.com/ropensci/prism,16432,35,2020-05-13T16:50:56Z,469.48571428571427
PRISM.forecast,Implements Penalized Regression with Inferred Seasonality Module (PRISM) to generate forecast estimation of weekly unemployment initial claims using 'Google Trends' data. It includes required data and tools for backtesting the performance in 2007-2020.,2020-04-22,Dingdong Yi,https://github.com/ryanddyi/prism,TRUE,https://github.com/ryanddyi/prism,6170,0,2020-04-22T01:23:03Z,NA
prismadiagramR,"Creates 'PRISMA' <http://prisma-statement.org/> diagram from a minimal dataset of included and excluded studies and allows for more custom diagrams. 'PRISMA' diagrams are used to track the identification, screening, eligibility, and inclusion of studies in a systematic review. ",2020-05-04,Lionel Duarte,https://github.com/ltrainstg/prismadiagramR,TRUE,https://github.com/ltrainstg/prismadiagramr,590,0,2020-04-20T21:37:32Z,NA
prismatic,"Manipulate and visualize colors in a intuitive, low-dependency and 
    functional way. ",2019-12-01,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/prismatic,TRUE,https://github.com/emilhvitfeldt/prismatic,23886,73,2020-03-15T02:00:37Z,327.2054794520548
probably,"Models can be improved by post-processing class probabilities, by: recalibration, conversion to hard probabilities, assessment of equivocal zones, and other activities. 'probably' contains tools for conducting these operations. ",2020-06-05,Davis Vaughan,"https://github.com/tidymodels/probably/,
https://probably.tidymodels.org",TRUE,https://github.com/tidymodels/probably,7541,52,2020-06-05T14:53:27Z,145.01923076923077
ProbBayes,"Functions and datasets  to accompany J. Albert and J. Hu, ""Probability and Bayesian Modeling"", CRC Press, (2019, ISBN: 1138492566).",2020-03-06,Jim Albert,https://github.com/bayesball/ProbBayes,TRUE,https://github.com/bayesball/probbayes,1431,0,2020-05-27T18:27:09Z,NA
pROC,"Tools for visualizing, smoothing and comparing receiver operating characteristic (ROC curves). (Partial) area under the curve (AUC) can be compared with statistical tests based on U-statistics or bootstrap. Confidence intervals can be computed for (p)AUC or ROC curves.",2020-03-19,Xavier Robin,http://expasy.org/tools/pROC/,TRUE,https://github.com/xrobin/proc,2527008,79,2020-06-07T08:29:34Z,31987.443037974685
ProcData,"General tools for exploratory process data analysis. Process data refers to the data describing
    participants' problem solving processes in computer-based assessments. It is often recorded in computer
    log files. This package provides two action sequence generators and implements two automatic feature extraction methods that compress the information
    stored in process data, which often has a nonstandard format, into standard numerical vectors. This package
    also provides recurrent neural network based models that relate response processes with other binary or 
    scale variables of interest. The functions that involve training and evaluating neural networks are wrappers
    of functions in 'keras'.",2020-05-12,Xueying Tang,NA,TRUE,https://github.com/xytangtang/procdata,356,0,2020-05-09T03:35:01Z,NA
processanimateR,"Provides animated process maps based on the 'procesmapR' package.
  Cases stored in event logs created with with 'bupaR' S3 class eventlog() are
  rendered as tokens (SVG shapes) and animated according to their occurrence 
  times on top of the process map. For rendering SVG animations ('SMIL') and the
  'htmlwidget' package are used.",2020-03-13,Felix Mannhardt,https://github.com/bupaverse/processanimateR/,TRUE,https://github.com/bupaverse/processanimater,13707,31,2020-03-18T22:27:47Z,442.16129032258067
processcheckR,"Check compliance of event-data from (business) processes with respect to specified rules. Rules supported are of three types: frequency (activities that should (not) happen x number of times), order (succession between activities) and exclusiveness (and and exclusive choice between activities).",2019-11-05,Gert Janssenswillen,"https://www.bupar.net, https://github.com/bupaverse/processcheckr",TRUE,https://github.com/bupaverse/processcheckr,6403,3,2019-11-13T12:11:48Z,2134.3333333333335
processmapR,"Visualize event logs using directed graphs, i.e. process maps. Part of the 'bupaR' framework.",2020-03-11,Gert Janssenswillen,"https://www.bupar.net, https://github.com/bupaverse/processmapr",TRUE,https://github.com/bupaverse/processmapr,26322,2,2020-04-30T15:05:27Z,13161
processR,"Perform moderation, mediation, moderated mediation and moderated moderation. 
   Inspired from famous 'PROCESS' macro for 'SPSS' and 'SAS' created by Andrew Hayes. ",2020-01-27,Keon-Woong Moon,https://github.com/cardiomoon/processR,TRUE,https://github.com/cardiomoon/processr,8404,16,2020-03-08T04:25:08Z,525.25
prodigenr,"Create a project directory structure, along with typical files
    for that project.  This allows projects to be quickly and easily created,
    as well as for them to be standardized. Designed specifically with scientists
    in mind (mainly bio-medical researchers, but likely applies to other fields).",2019-07-01,Luke Johnston,https://github.com/lwjohnst86/prodigenr,TRUE,https://github.com/lwjohnst86/prodigenr,12572,26,2019-07-01T13:35:02Z,483.53846153846155
proffer,"Like similar profiling tools,
  the 'proffer' package automatically detects
  sources of slowness in R code.
  The distinguishing feature of 'proffer' is its utilization of
  'pprof', which supplies interactive visualizations
  that are efficient and easy to interpret.
  Behind the scenes, the 'profile' package converts
  native Rprof() data to a protocol buffer
  that 'pprof' understands.
  For the documentation of 'proffer',
  visit <https://r-prof.github.io/proffer>.
  To learn about the implementations and methodologies of
  'pprof', 'profile', and protocol buffers,
  visit <https://github.com/google/pprof>.
  <https://developers.google.com/protocol-buffers>,
  and <https://github.com/r-prof/profile>, respectively.",2020-03-23,William Michael Landau,"https://github.com/r-prof/proffer,
https://r-prof.github.io/proffer",TRUE,https://github.com/r-prof/proffer,2654,51,2020-05-22T15:31:22Z,52.03921568627451
profile,"Defines a data structure for profiler data, and methods to read and
    write from the 'Rprof' and 'pprof' file formats.",2020-05-11,Kirill Müller,"https://github.com/r-prof/profile,
https://r-prof.github.io/profile",TRUE,https://github.com/r-prof/profile,8611,8,2020-05-11T11:14:57Z,1076.375
ProFit,Get data / Define model / ??? / Profit! 'ProFit' is a Bayesian galaxy fitting tool that uses a fast 'C++' image generation library and a flexible interface to a large number of likelihood samplers.,2019-11-11,Aaron Robotham,https://github.com/ICRAR/ProFit,TRUE,https://github.com/icrar/profit,14831,20,2019-10-24T08:23:03Z,741.55
profmem,"A simple and light-weight API for memory profiling of R expressions.  The profiling is built on top of R's built-in memory profiler ('utils::Rprofmem()'), which records every memory allocation done by R (also native code).",2018-01-30,Henrik Bengtsson,https://github.com/HenrikBengtsson/profmem,TRUE,https://github.com/henrikbengtsson/profmem,58954,25,2020-05-02T22:08:29Z,2358.16
ProfoundData,"Provides an R interface for the PROFOUND database <doi:10.5880/PIK.2019.008>. The 
    PROFOUND database contains a wide range of data  to evaluate vegetation models and simulate climate 
    impacts at the forest stand scale. It includes 9 forest sites across Europe, and provides for them a site 
    description as well as soil, climate, CO2, Nitrogen deposition, tree-level, forest stand-level 
    and remote sensing data. Moreover, for a subset of 5 sites, also time series of carbon fluxes, 
    energy balances and soil water are available. ",2020-03-30,Florian Hartig,https://cost-fp1304-profound.github.io/ProfoundData/,TRUE,https://github.com/cost-fp1304-profound/profounddata,916,5,2020-05-04T17:33:30Z,183.2
progressr,"A minimal, unifying API for scripts and packages to report progress updates from anywhere including when using parallel processing.  The package is designed such that the developer can to focus on what progress should be reported on without having to worry about how to present it.  The end user has full control of how, where, and when to render these progress updates, e.g. in the terminal using utils::txtProgressBar() or progress::progress_bar(), in a graphical user interface using utils::winProgressBar(), tcltk::tkProgressBar() or shiny::withProgress(), via the speakers using beep::beepr(), or on a file system via the size of a file. Anyone can add additional, customized, progression handlers. The 'progressr' package uses R's condition framework for signaling progress updated. Because of this, progress can be reported from almost anywhere in R, e.g. from classical for and while loops, from map-reduce APIs like the lapply() family of functions, 'purrr', 'plyr', and 'foreach'. It will also work with parallel processing via the 'future' framework, e.g. future.apply::future_lapply(), furrr::future_map(), and 'foreach' with 'doFuture'. The package is compatible with Shiny applications.",2020-05-19,Henrik Bengtsson,https://github.com/HenrikBengtsson/progressr,TRUE,https://github.com/henrikbengtsson/progressr,10262,125,2020-05-19T21:23:51Z,82.096
PROJ,"A wrapper around the generic coordinate transformation software 'PROJ'
  that transforms geospatial coordinates from one coordinate reference system ('CRS') 
  to another. This includes cartographic projections as well as geodetic transformations. 
  Version 6.0.0 or higher is required, earlier versions if available are not used 
  leaving this package harmlessly non-functional. The intention is for this package 
  to be used by user-packages such as 'reproj', and that the older 'PROJ.4' and version 5 
  pathways be provided by the 'proj4' package. Separating this disruptive version
  change (from 4.0 and 5.0, to 6.0 and above) allows the use of existing and 
  stable code in 'proj4' alongside the new idioms and requirements of modern 'PROJ'
  using this package. The 'PROJ' library is available from <https://proj.org/>. ",2020-04-15,Michael D. Sumner,https://github.com/hypertidy/PROJ,TRUE,https://github.com/hypertidy/proj,4606,7,2020-05-13T11:05:22Z,658
ProjectionBasedClustering,"A clustering approach applicable to every projection method is proposed here. The two-dimensional scatter plot of any projection method can construct a topographic map which displays unapparent data structures by using distance and density information of the data. The generalized U*-matrix renders this visualization in the form of a topographic map, which can be used to automatically define the clusters of high-dimensional data. The whole system is the generalization of on an idea from the book ""Projection-Based Clustering through Self-Organization and Swarm Intelligence"" <DOI:10.1007/978-3-658-20540-9>. Selecting the correct projection method will result in a visualization in which mountains surround each cluster. The number of clusters can be determined by counting valleys on the topographic map. Most projection methods are wrappers for already available methods in R. By contrast, the neighbor retrieval visualizer (NeRV) is based on C++ source code of the 'dredviz' software package, and the Curvilinear Component Analysis (CCA) is translated from 'MATLAB' ('SOM Toolbox' 2.0) to R.",2020-03-29,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/projectionbasedclustering,11735,0,2020-04-20T14:22:20Z,NA
projections,"Provides functions and graphics for projecting daily incidence based on past incidence, and estimates of the serial interval and reproduction number. Projections are based on a branching process using a Poisson-distributed number of new cases per day, similar to the model used for estimating R0 in 'EpiEstim' or in 'earlyR', and described by Nouvellet et al. (2017) <doi:10.1016/j.epidem.2017.02.012>.",2018-08-27,Thibaut Jombart,http://www.repidemicsconsortium.org/projections,TRUE,https://github.com/reconhub/projections,11809,8,2020-06-03T15:28:04Z,1476.125
ProjectTemplate,"Provides functions to
    automatically build a directory structure for a new R
    project. Using this structure, 'ProjectTemplate'
    automates data loading, preprocessing, library
    importing and unit testing.",2020-05-11,Aleksandar Blagotic [ctb,http://projecttemplate.net,TRUE,https://github.com/johnmyleswhite/projecttemplate,58205,563,2020-05-11T18:42:20Z,103.38365896980461
projmgr,"Provides programmatic access to 'GitHub' API with a
    focus on project management.  Key functionality includes
    setting up issues and milestones from R objects or 'YAML' configurations,
    querying outstanding or completed tasks, and generating progress updates
    in tables, charts, and RMarkdown reports. Useful for those using 'GitHub' in personal,
    professional, or academic settings with an emphasis on streamlining
    the workflow of data analysis projects.",2019-08-05,Emily Riederer,https://github.com/emilyriederer/projmgr,TRUE,https://github.com/emilyriederer/projmgr,3458,63,2020-02-01T20:01:32Z,54.888888888888886
projpred,"
    Performs projection predictive feature selection for generalized linear models
    (see, Piironen, Paasiniemi and Vehtari, 2018, <arXiv:1810.02406>).
    The package is compatible with the 'rstanarm' and 'brms' packages, but other 
    reference models can also be used. See the package vignette for more 
    information and examples.",2020-04-01,Juho Piironen,"https://mc-stan.org/projpred, https://discourse.mc-stan.org/",TRUE,https://github.com/stan-dev/projpred,16337,57,2020-06-02T20:05:02Z,286.6140350877193
promises,"Provides fundamental abstractions for doing asynchronous programming
    in R using promises. Asynchronous programming is useful for allowing a single
    R process to orchestrate multiple tasks in the background while also attending
    to something else. Semantics are similar to 'JavaScript' promises, but with a
    syntax that is idiomatic R.",2020-06-09,Joe Cheng,"https://rstudio.github.io/promises,
https://github.com/rstudio/promises",TRUE,https://github.com/rstudio/promises,8629331,150,2020-06-09T22:20:27Z,57528.87333333334
propr,"The bioinformatic evaluation of gene co-expression often begins with
    correlation-based analyses. However, correlation lacks validity when
    applied to relative data, including count data generated by next-generation
    sequencing. This package implements several metrics for proportionality, including
    phi [Lovell et al (2015) <DOI:10.1371/journal.pcbi.1004075>] and
    rho [Erb and Notredame (2016) <DOI:10.1007/s12064-015-0220-8>]. This package also
    implements several metrics for differential proportionality. Unlike correlation,
    these measures give the same result for both relative and absolute data.",2019-12-16,Thomas Quinn,http://github.com/tpq/propr,TRUE,https://github.com/tpq/propr,28518,33,2020-04-15T06:15:19Z,864.1818181818181
ProPublicaR,"Provides wrapper functions to access the ProPublica's Congress and Campaign Finance APIs.
    The Congress API provides near real-time access to legislative data from the House of 
    Representatives, the Senate and the Library of Congress.
    The Campaign Finance API provides data from United States Federal Election Commission 
    filings and other sources. The API covers summary information for candidates and 
    committees, as well as certain types of itemized data.
    For more information about these APIs go to: <https://www.propublica.org/datastore/apis>.",2020-04-16,Aleksander Dietrichson,NA,TRUE,https://github.com/dietrichson/propublicar,4603,4,2020-04-16T18:01:01Z,1150.75
prospectr,"Functions to preprocess spectroscopic data 
    and conduct (representative) sample selection/calibration sampling.",2020-03-14,Antoine Stevens,https://github.com/l-ramirez-lopez/prospectr,TRUE,https://github.com/l-ramirez-lopez/prospectr,32110,2,2020-05-27T18:13:03Z,16055
protr,"Comprehensive toolkit for generating various numerical
    features of protein sequences described in Xiao et al. (2015)
    <DOI:10.1093/bioinformatics/btv042>. For full functionality,
    the software 'ncbi-blast+' is needed, see
    <https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download>
    for more information.",2019-05-18,Nan Xiao,"https://nanx.me/protr/, https://github.com/nanxstats/protr,
http://protr.org",TRUE,https://github.com/nanxstats/protr,36035,27,2020-04-23T16:27:51Z,1334.6296296296296
protViz,"Helps with quality checks, visualizations 
    and analysis of mass spectrometry data, coming from proteomics 
    experiments. The package is developed, tested and used at the Functional 
    Genomics Center Zurich <https://fgcz.ch>. We use this package
    mainly for prototyping, teaching, and having fun with proteomics data.
    But it can also be used to do data analysis for small scale data sets.",2020-05-02,Christian Panse,https://github.com/cpanse/protViz/,TRUE,https://github.com/cpanse/protviz,27384,5,2020-04-24T09:47:55Z,5476.8
proxyC,"
    Computes proximity between rows or columns of large matrices efficiently in C++.
    Functions are optimised for large sparse matrices using the Armadillo and Intel TBB libraries.
    Among several built-in similarity/distance measures, computation of correlation,
    cosine similarity and Euclidean distance is particularly fast. ",2019-07-21,Kohei Watanabe,NA,TRUE,https://github.com/koheiw/proxyc,116205,8,2019-07-20T19:11:01Z,14525.625
prozor,"Determine minimal protein set explaining
    peptide spectrum matches. Utility functions for creating fasta amino acid databases with decoys and contaminants.
    Peptide false discovery rate estimation for target decoy search results on psm, precursor, peptide and protein
    level.",2018-07-26,Witold Wolski,https://github.com/protviz/prozor,TRUE,https://github.com/protviz/prozor,13400,3,2020-06-05T09:24:20Z,4466.666666666667
pryr,"Useful tools to pry back the covers of R and understand the
    language at a deeper level.",2018-02-18,Hadley Wickham,https://github.com/hadley/pryr,TRUE,https://github.com/hadley/pryr,763391,183,2020-04-03T14:12:50Z,4171.535519125683
PSCBS,Segmentation of allele-specific DNA copy number data and detection of regions with abnormal copy number within each parental chromosome.  Both tumor-normal paired and tumor-only analyses are supported.,2019-05-05,Henrik Bengtsson,https://github.com/HenrikBengtsson/PSCBS,TRUE,https://github.com/henrikbengtsson/pscbs,84839,5,2019-12-15T04:01:57Z,16967.8
pscl,"Bayesian analysis of item-response theory (IRT) models,
	     roll call analysis; computing highest density regions; maximum
	     likelihood estimation of zero-inflated and hurdle models for count
	     data; goodness-of-fit measures for GLMs; data sets used
	     in writing	and teaching at the Political Science
	     Computational Laboratory; seats-votes curves.",2020-03-07,Simon Jackman,http://github.com/atahk/pscl,TRUE,https://github.com/atahk/pscl,622069,22,2020-04-20T17:55:46Z,28275.863636363636
psd,"Produces power spectral density estimates through iterative
    refinement of the optimal number of sine-tapers at each frequency. This
    optimization procedure is based on the method of Riedel and Sidorenko
    (1995), which minimizes the Mean Square Error (sum of variance and bias)
    at each frequency, but modified for computational stability.",2019-03-20,Andrew J. Barbour,"https://github.com/abarbour/psd, Barbour and Parker (2014):
https://doi.org/10.1016/j.cageo.2013.09.015, Riedel and
Sidorenko (1995): https://doi.org/10.1109/78.365298",TRUE,https://github.com/abarbour/psd,28201,7,2020-01-13T22:05:31Z,4028.714285714286
psda,"A toolbox in symbolic data framework as a statistical learning and data mining solution for symbolic polygonal data analysis. This study is a new approach in data analysis and it was proposed by 
            Silva et al. (2019) <doi:10.1016/j.knosys.2018.08.009>. The package presents the estimation of main descriptive statistical measures, e.g, mean, covariance, variance, correlation and coefficient of variation. 
            In addition, a method to obtain polygonal data from classical data is presented. Empirical probability distribution function based on symbolic polygonal histogram and a regression model with its main measures are presented.",2020-05-24,Wagner Silva,https://github.com/wagnerjorge/psda,TRUE,https://github.com/wagnerjorge/psda,10790,0,2020-05-23T17:06:19Z,NA
psData,"This R package includes functions for gathering commonly used and
    regularly maintained data set in political science. It also includes
    functions for combining components from these data sets into variables that
    have been suggested in the literature, but are not regularly maintained.",2016-09-03,Christopher Gandrud,http://cran.r-project.org/package=psData,TRUE,https://github.com/christophergandrud/psdata,17506,34,2019-10-09T11:19:14Z,514.8823529411765
psfmi,"
	Provides functions to apply pooling or backward selection 
	of logistic, Cox regression and Multilevel (mixed models) prediction 
	models in multiply imputed datasets. Backward selection can be done 
	from the pooled model using Rubin's Rules (RR), the D1, D2, D3 and 
	promising median p-values method. The model can contain 
	continuous, dichotomous, categorical predictors and interaction terms 
	between all	these type of predictors. Continuous predictors	can also 
	be introduced as restricted cubic spline coefficients. It is also possible 
	to force (spline) predictors or interaction terms in the model during predictor 
	selection. The package includes a function to evaluate the stability 
	of the models	using bootstrapping and cluster bootstrapping. The package further 
	contains functions to generate pooled model performance measures in multiply 
	imputed datasets as ROC/AUC, R-squares, Brier score, fit test values and 
	calibration	plots for logistic regression models. A function to apply 
	Bootstrap internal validation	is also available where two methods can be 
	used to combine bootstrapping and	multiple imputation. One method, boot_MI, 
	first draws	bootstrap samples and	subsequently performs multiple imputation and with 
	the other method, MI_boot, first bootstrap samples are drawn from each imputed 
	dataset before results are combined. The adjusted intercept after shrinkage of
	the pooled regression coefficients can be subsequently obtained. Backward selection	
	as part of internal validation is also an option. Also a function to externally 
	validate logistic	prediction models in multiple imputed datasets is available.
	Eekhout (2017) <doi:10.1186/s12874-017-0404-7>.
	Wiel (2009) <doi:10.1093/biostatistics/kxp011>.
	Marshall (2009) <doi:10.1186/1471-2288-9-57>.",2020-02-03,Martijn Heymans,https://github.com/mwheymans/psfmi,TRUE,https://github.com/mwheymans/psfmi,4520,0,2020-04-06T10:23:12Z,NA
psidR,"Makes it easy to build panel data in wide format from Panel Survey
    of Income Dynamics ('PSID') delivered raw data. Downloads data directly from
    the PSID server using the 'SAScii' package. 'psidR' takes care of merging
    data from each wave onto a cross-period index file, so that individuals can be
    followed over time. The user must specify which years they are interested in,
    and the 'PSID' variable names (e.g. ER21003) for each year (they differ in each
    year). The package offers helper functions to retrieve variable names from different
    waves. There are different panel data designs and sample subsetting criteria
    implemented (""SRC"", ""SEO"", ""immigrant"" and ""latino"" samples).",2020-02-26,Florian Oswald,https://github.com/floswald/psidR,TRUE,https://github.com/floswald/psidr,28566,33,2020-02-27T09:04:08Z,865.6363636363636
PSSMCOOL,"Returns almost all features that has been extracted from Position Specific 
             Scoring Matrix (PSSM) so far, which is a matrix of L rows (L is protein length) 
             and 20 columns produced by 'PSI-BLAST' which is a program to produce
             PSSM Matrix from multiple sequence alignment of proteins
             see <https://www.ncbi.nlm.nih.gov/books/NBK2590/> for mor details. some 
             of these features are described in Zahiri, J., et al.(2013)
             <DOI:10.1016/j.ygeno.2013.05.006>,
             Saini, H., et al.(2016)
             <DOI:10.17706/jsw.11.8.756-767>,
             Ding, S., et al.(2014)
             <DOI:10.1016/j.biochi.2013.09.013>,
             Cheng, C.W., et al.(2008)
             <DOI:10.1186/1471-2105-9-S12-S6>,
             Juan, E.Y., et al.(2009)
             <DOI:10.1109/CISIS.2009.194>. ",2020-05-08,Alireza Mohammadi,"http://possum.erc.monash.edu/help.jsp,
https://github.com/Alireza9651501005/PSSMCOOL",TRUE,https://github.com/alireza9651501005/pssmcool,388,0,2020-05-02T19:32:59Z,NA
pstest,"The propensity score is one of the most widely used tools in
    studying the causal effect of a treatment, intervention, or policy. Given that
    the propensity score is usually unknown, it has to be estimated, implying that
    the reliability of many treatment effect estimators depends on the correct
    specification of the (parametric) propensity score. This package implements the
    data-driven nonparametric diagnostic tools for detecting propensity score
    misspecification proposed by Sant'Anna and Song (2019) <doi:10.1016/j.jeconom.2019.02.002>.",2019-08-26,Pedro H. C. SantAnna,https://github.com/pedrohcgs/pstest,TRUE,https://github.com/pedrohcgs/pstest,8648,1,2020-03-25T23:01:05Z,8648
PSweight,"Supports propensity score weighting analysis of observational studies and randomized trials. Enables the estimation and inference of average causal effects among target populations with binary and multiple treatments using the methods developed in Li, Morgan and Zaslavsky (2018) <doi:10.1080/01621459.2016.1260466> and Li and Li (2019) <doi:10.1214/19-AOAS1282>.",2020-05-04,Tianhui Zhou,https://github.com/thuizhou/PSweight,TRUE,https://github.com/thuizhou/psweight,582,0,2020-05-29T20:10:12Z,NA
psychmeta,"Tools for computing bare-bones and psychometric meta-analyses and for generating psychometric data for use in meta-analysis simulations. Supports bare-bones, individual-correction, and artifact-distribution methods for meta-analyzing correlations and d values. Includes tools for converting effect sizes, computing sporadic artifact corrections, reshaping meta-analytic databases, computing multivariate corrections for range variation, and more. Bugs can be reported to <https://github.com/psychmeta/psychmeta/issues> or <issues@psychmeta.com>.",2020-06-07,Jeffrey A. Dahlke,NA,TRUE,https://github.com/psychmeta/psychmeta,24134,16,2020-06-07T18:47:21Z,1508.375
psycho,"The main goal of the psycho package is to provide tools for psychologists, neuropsychologists and neuroscientists, 
   to facilitate and speed up the time spent on data analysis. It aims at supporting best practices and tools to format the output 
   of statistical methods to directly paste them into a manuscript, ensuring statistical reporting standardization and conformity.",2020-01-22,Dominique Makowski,https://github.com/neuropsychology/psycho.R,TRUE,https://github.com/neuropsychology/psycho.r,53671,96,2020-02-06T04:20:14Z,559.0729166666666
psychonetrics,"Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data <doi:10.31234/osf.io/8ha93>. Allows for confirmatory testing and fit as well as exploratory model search.",2020-04-15,Sacha Epskamp,http://psychonetrics.org/,TRUE,https://github.com/sachaepskamp/psychonetrics,6951,9,2020-06-09T12:51:55Z,772.3333333333334
psychrolib,"
    Implementation of 'PsychroLib'
    <https://github.com/psychrometrics/psychrolib> library which contains
    functions to enable the calculation properties of moist and dry air in both
    metric (SI) and imperial (IP) systems of units. References: Meyer, D. and
    Thevenard, D (2019) <doi.org/10.21105/joss.01137>.",2020-04-12,Hongyuan Jia,https://github.com/psychrometrics/psychrolib,TRUE,https://github.com/psychrometrics/psychrolib,1611,61,2020-04-12T06:50:21Z,26.40983606557377
ptstem,"Wraps a collection of stemming algorithms for the Portuguese
    Language.",2020-05-12,Daniel Falbel,https://github.com/dfalbel/ptstem,TRUE,https://github.com/dfalbel/ptstem,12787,13,2020-05-11T18:00:41Z,983.6153846153846
ptvapi,"Access the 'Public Transport Victoria' Timetable API 
    <https://www.ptv.vic.gov.au/footer/data-and-reporting/datasets/ptv-timetable-api/>,
    with results returned as familiar R data structures. Retrieve information on
    stops, routes, disruptions, departures, and more.",2020-06-03,David Neuzerling,https://github.com/mdneuzerling/ptvapi,TRUE,https://github.com/mdneuzerling/ptvapi,0,7,2020-06-02T21:21:16Z,0
ptw,"Parametric Time Warping aligns patterns, i.e. it aims to
        put corresponding features at the same locations. The algorithm
        searches for an optimal polynomial describing the warping. It
        is possible to align one sample to a reference, several samples
        to the same reference, or several samples to several
        references. One can choose between calculating individual
        warpings, or one global warping for a set of samples and one
        reference. Two optimization criteria are implemented: RMS (Root
        Mean Square error) and WCC (Weighted Cross Correlation). Both
	warping of peak profiles and of peak lists are supported. A
	vignette for the latter is contained in the inst/doc directory
	of the source package - the vignette source can be found on
	the package github site.",2019-11-26,Ron Wehrens,https://github.com/rwehrens/ptw,TRUE,https://github.com/rwehrens/ptw,60235,4,2019-11-26T11:07:09Z,15058.75
PTXQC,"Generates Proteomics (PTX) quality control (QC) reports for shotgun LC-MS data analyzed with the 
             MaxQuant software suite (from .txt files) or mzTab files (ideally from OpenMS 'QualityControl' tool).
             Reports are customizable (target thresholds, subsetting) and available in HTML or PDF format.
             Published in J. Proteome Res., Proteomics Quality Control: Quality Control Software for MaxQuant Results (2015)
             <doi:10.1021/acs.jproteome.5b00780>.",2020-06-09,Chris Bielow,https://github.com/cbielow/PTXQC,TRUE,https://github.com/cbielow/ptxqc,16906,18,2020-05-14T07:17:18Z,939.2222222222222
pubchunks,"Get chunks of XML scholarly articles without 
    having to know how to work with XML. Custom mappers
    for each publisher and for each article section pull 
    out the information you want. Works with outputs from 
    package 'fulltext', 'xml2' package documents, and file paths to 
    XML documents.",2019-01-21,Scott Chamberlain,https://github.com/ropensci/pubchunks,TRUE,https://github.com/ropensci/pubchunks,6655,7,2020-03-13T18:28:45Z,950.7142857142857
pubh,"A toolbox for making R functions and capabilities more
    accessible to students and professionals from Epidemiology and
    Public Health related disciplines. Includes a function to report 
    coefficients and confidence intervals from models using robust
    standard errors (when available), functions that expand 'ggplot2'
    plots and functions relevant for introductory papers in Epidemiology 
    or Public Health. Please note that use of the 
    provided data sets is for educational purposes only.",2020-06-02,Josie Athens,https://github.com/josie-athens/pubh,TRUE,https://github.com/josie-athens/pubh,11434,0,2020-06-02T00:29:33Z,NA
pubmedR,A set of tools to extract bibliographic content from 'PubMed' database using 'NCBI' REST API <https://www.ncbi.nlm.nih.gov/home/develop/api/>.,2020-04-03,Massimo Aria,https://github.com/massimoaria/pubmedR,TRUE,https://github.com/massimoaria/pubmedr,5992,3,2020-05-09T08:09:44Z,1997.3333333333333
PUlasso,"Efficient algorithm for solving PU (Positive and Unlabeled) problem in low or high dimensional setting with lasso or group lasso penalty. The algorithm uses Maximization-Minorization and (block) coordinate descent. Sparse calculation and parallel computing are supported for the computational speed-up. See Hyebin Song, Garvesh Raskutti (2018) <arXiv:1711.08129>.",2019-04-28,Hyebin Song,https://arxiv.org/abs/1711.08129,TRUE,https://github.com/hsong1/pulasso,14741,3,2019-11-03T16:43:01Z,4913.666666666667
pulsar,"Model selection for penalized graphical models using the Stability Approach to Regularization Selection ('StARS'), with options for speed-ups including Bounded StARS (B-StARS), batch computing, and other stability metrics (e.g., graphlet stability G-StARS). Christian L. Müller, Richard Bonneau, Zachary Kurtz (2016) <arXiv:1605.07072>.",2019-08-22,Zachary Kurtz,"http://github.com/zdk123/pulsar, http://arxiv.org/abs/1605.07072",TRUE,https://github.com/zdk123/pulsar,17058,7,2019-08-22T14:56:37Z,2436.8571428571427
purrr,"A complete and consistent functional programming
    toolkit for R.",2020-04-17,Lionel Henry,"http://purrr.tidyverse.org, https://github.com/tidyverse/purrr",TRUE,https://github.com/tidyverse/purrr,17215235,877,2020-05-28T13:29:26Z,19629.686431014823
purrrlyr,"Some functions at the intersection of 'dplyr' and
    'purrr' that formerly lived in 'purrr'.",2020-05-02,Lionel Henry,https://github.com/hadley/purrrlyr,TRUE,https://github.com/hadley/purrrlyr,101441,99,2020-04-29T06:45:20Z,1024.6565656565656
purrrogress,"Provides functions to easily add progress bars to 
    apply calls.",2019-07-22,Andrew Redd,https://github.com/halpo/purrrogress,TRUE,https://github.com/halpo/purrrogress,9938,58,2019-09-05T17:54:19Z,171.3448275862069
pushbar,"Create sliders from left, right, top and bottom which may include any html or 'Shiny' input or output.",2019-03-15,John Coene,https://github.com/JohnCoene/pushbar,TRUE,https://github.com/johncoene/pushbar,4965,43,2019-11-03T10:48:46Z,115.46511627906976
puzzle,"To Simplify the time consuming and error prone task of assembling complex data sets for non-linear mixed effects modeling. Users are able to select from different absorption processes such as zero and first order, or a combination of both. Furthermore, data sets containing data from several entities, responses, and covariates can be simultaneously assembled. ",2019-11-28,Mario Gonzalez Sales,https://github.com/syneoshealth/puzzle,TRUE,https://github.com/syneoshealth/puzzle,2386,0,2019-11-27T08:19:04Z,NA
pvaluefunctions,"Contains functions to compute and plot confidence distributions, confidence densities, p-value functions and s-value (surprisal) functions for several commonly used estimates. Instead of just calculating one p-value and one confidence interval, p-value functions display p-values and confidence intervals for many levels thereby allowing to gauge the compatibility of several parameter values with the data. These methods are discussed by Infanger D, Schmidt-Trucksäss A. (2019) <doi:10.1002/sim.8293>; Poole C. (1987) <doi:10.2105/AJPH.77.2.195>; Schweder T, Hjort NL. (2002) <doi:10.1111/1467-9469.00285>; Bender R, Berg G, Zeeb H. (2005) <doi:10.1002/bimj.200410104> ; Singh K, Xie M, Strawderman WE. (2007) <doi:10.1214/074921707000000102>; Rothman KJ, Greenland S, Lash TL. (2008, ISBN:9781451190052); Amrhein V, Trafimow D, Greenland S. (2019) <doi:10.1080/00031305.2018.1543137>; and Greenland S. (2019) <doi:10.1080/00031305.2018.1529625>.",2019-11-29,Denis Infanger,https://github.com/DInfanger/pvaluefunctions,TRUE,https://github.com/dinfanger/pvaluefunctions,5889,8,2020-05-05T20:28:50Z,736.125
PWFSLSmoke,"Utilities for working with air quality monitoring data
    with a focus on small particulates (PM2.5) generated by wildfire
    smoke. Functions are provided for downloading available data from
    the United States 'EPA' <https://www.epa.gov/outdoor-air-quality-data> and
    it's 'AirNow' air quality site <https://www.airnow.gov>.
    Additional sources of PM2.5 data made accessible by the package include:
    'AIRSIS' (password protected) <https://www.oceaneering.com/data-management/>
    and 'WRCC' <https://wrcc.dri.edu/cgi-bin/smoke.pl>.
    Data compilations are provided by 'PWFSL'
    <https://www.fs.fed.us/pnw/pwfsl/>.",2019-07-18,Jonathan Callahan,https://github.com/MazamaScience/PWFSLSmoke,TRUE,https://github.com/mazamascience/pwfslsmoke,14047,8,2020-02-24T20:56:29Z,1755.875
pwr,Power analysis functions along the lines of Cohen (1988).,2020-03-17,Helios De Rosario,https://github.com/heliosdrm/pwr,TRUE,https://github.com/heliosdrm/pwr,746512,63,2020-05-20T20:29:09Z,11849.396825396825
pxR,"Provides a set of functions for reading and writing PC-Axis files, used by different statistical organizations around the globe for data dissemination.",2020-06-07,Carlos J. Gil Bellosta,https://github.com/cjgb/pxR,TRUE,https://github.com/cjgb/pxr,31506,16,2020-05-16T12:57:27Z,1969.125
pxweb,"Generic interface for the PX-Web/PC-Axis API. The PX-Web/PC-Axis
    API is used by organizations such as Statistics Sweden and Statistics
    Finland to disseminate data. The R package can interact with all
    PX-Web/PC-Axis APIs to fetch information about the data hierarchy, extract
    metadata and extract and parse statistics to R data.frame format. PX-Web is
    a solution to disseminate PC-Axis data files in dynamic tables on the web.
    Since 2013 PX-Web contains an API to disseminate PC-Axis files.",2019-01-07,Mans Magnusson,https://github.com/rOpenGov/pxweb/,TRUE,https://github.com/ropengov/pxweb,24302,40,2020-05-12T05:58:10Z,607.55
pyinit,"Deterministic Pena-Yohai initial estimator for robust S estimators
    of regression. The procedure is described in detail in
    Pena, D., & Yohai, V. (1999) <doi:10.2307/2670164>.",2019-08-02,David Kepplinger,https://github.com/dakep/pyinit,TRUE,https://github.com/dakep/pyinit,10117,1,2019-08-02T22:40:23Z,10117
pzfx,Read and write 'GraphPad Prism' '.pzfx' files in R.,2019-01-08,Yue Jiang,https://github.com/Yue-Jiang/pzfx,TRUE,https://github.com/yue-jiang/pzfx,8370,3,2019-10-30T03:03:18Z,2790
QAIG,"A tool for automatic generation of sibling items from a parent item model defined by
           the user. It is an implementation of the process automatic item generation (AIG) focused
           on generating quantitative multiple-choice type of items (see Embretson, Kingston
           (2018) <doi:10.1111/jedm.12166>).",2020-05-20,Subhabrata Patra,https://github.com/shubh-b/QAIG,TRUE,https://github.com/shubh-b/qaig,4457,0,2020-05-21T06:00:07Z,NA
qap,Implements heuristics for the Quadratic Assignment Problem (QAP). Currently only a simulated annealing heuristic is available.,2017-02-27,Michael Hahsler,NA,TRUE,https://github.com/mhahsler/qap,770294,1,2019-08-27T18:29:54Z,770294
qcapower,"Researchers working with Qualitative Comparative Analysis (QCA)
    can use the package to estimate power of a sufficient term
    using permutation tests. A term can be anything: A condition, conjunction or 
    disjunction of any combination of these. The package further allows users to plot 
    the estimation results and to estimate the number of cases required to achieve a
    certain level of power, given a prespecified null and alternative hypothesis.
    Reference for the article introducing power estimation for QCA is: 
    Rohlfing, Ingo (2018) <doi:10.1017/pan.2017.30> 
    (ungated version: <doi:10.17605/OSF.IO/PC4DF>).",2020-03-02,Ingo Rohlfing,https://github.com/ingorohlfing/qcapower,TRUE,https://github.com/ingorohlfing/qcapower,1445,1,2020-03-29T16:09:31Z,1445
qcc,"Shewhart quality control charts for continuous, attribute and count data. Cusum and EWMA charts. Operating characteristic curves. Process capability analysis. Pareto chart and cause-and-effect chart. Multivariate control charts.",2017-07-11,Luca Scrucca,https://github.com/luca-scr/qcc,TRUE,https://github.com/luca-scr/qcc,336717,22,2020-05-28T15:24:06Z,15305.318181818182
qdap,"Automates many of the tasks associated with quantitative discourse analysis of transcripts containing discourse
              including frequency counts of sentence types, words, sentences, turns of talk, syllables and other assorted
              analysis tasks. The package provides parsing tools for preparing transcript data. Many functions enable the user
              to aggregate data by any number of grouping variables, providing analysis and seamless integration with other R
              packages that undertake higher level analysis and visualization of text. This affords the user a more efficient
              and targeted analysis. 'qdap' is designed for transcript analysis, however, many functions are applicable to other
              areas of Text Mining/ Natural Language Processing.",2020-04-20,Tyler Rinker,http://trinker.github.com/qdap/,TRUE,https://github.com/trinker/qdap,1852825,134,2020-04-20T14:55:40Z,13827.05223880597
QFASA,"Accurate estimates of the diets of predators are required
    in many areas of ecology, but for many species current methods are
    imprecise, limited to the last meal, and often biased. The diversity
    of fatty acids and their patterns in organisms, coupled with the
    narrow limitations on their biosynthesis, properties of digestion in
    monogastric animals, and the prevalence of large storage reservoirs of
    lipid in many predators, led us to propose the use of quantitative
    fatty acid signature analysis (QFASA) to study predator diets.",2019-06-14,Justin Kamerman,https://CRAN.R-project.org/package=QFASA,TRUE,https://github.com/justinkamerman/qfasa,11742,0,2019-06-17T14:12:49Z,NA
qgg,"Provides an infrastructure for efficient processing of large-scale genetic and phenotypic data including core functions for: 1) fitting linear mixed models, 2) constructing marker-based genomic relationship matrices, 3) estimating genetic parameters (heritability and correlation), 4) performing genomic prediction and genetic risk profiling, and 5) single or multi-marker association analyses.
    Rohde et al. (2019) <doi:10.1101/503631>.",2020-04-21,Peter Soerensen,https://github.com/psoerensen/qgg,TRUE,https://github.com/psoerensen/qgg,2353,7,2020-04-21T07:03:35Z,336.14285714285717
QGglmm,"Compute various quantitative genetics parameters from a Generalised Linear Mixed Model (GLMM) estimates. Especially, it yields the observed phenotypic mean, phenotypic variance and additive genetic variance.",2020-01-07,Pierre de Villemereuil,NA,TRUE,https://github.com/devillemereuil/qgglmm,13440,8,2020-04-19T10:22:09Z,1680
qgraph,"Weighted network visualization and analysis, as well as Gaussian graphical model computation. See Epskamp et al. (2012) <doi:10.18637/jss.v048.i04>.",2020-02-21,Sacha Epskamp,http://sachaepskamp.com/qgraph,TRUE,https://github.com/sachaepskamp/qgraph,452400,44,2020-02-28T15:08:33Z,10281.818181818182
qicharts2,"Functions for making run charts, Shewhart control charts and
    Pareto charts for continuous quality improvement. Included control charts are:
    I, MR, Xbar, S, T, C, U, U', P, P', and G charts. Non-random variation in the
    form of minor to moderate persistent shifts in data over time is identified by
    the Anhoej rules for unusually long runs and unusually few crossing 
    [Anhoej, Olesen (2014) <doi:10.1371/journal.pone.0113825>].
    Non-random variation in the form of larger, possibly transient, shifts is
    identified by Shewhart's 3-sigma rule [Mohammed, Worthington, Woodall (2008)
    <doi:10.1136/qshc.2004.012047>].",2020-03-15,Jacob Anhoej,https://github.com/anhoej/qicharts2,TRUE,https://github.com/anhoej/qicharts2,30947,23,2020-06-07T08:38:12Z,1345.5217391304348
qif,"Developed to perform the estimation and inference for regression 
    coefficient parameters in longitudinal marginal models using the method of 
    quadratic inference functions. Like generalized estimating equations, this 
    method is also a quasi-likelihood inference method. It has been showed that 
    the method gives consistent estimators of the regression coefficients even if 
    the correlation structure is misspecified, and it is more efficient than GEE 
    when the correlation structure is misspecified. Based on Qu, A., Lindsay, 
    B.G. and Li, B. (2000) <doi:10.1093/biomet/87.4.823>.",2019-07-20,Michael Kleinsasser,NA,TRUE,https://github.com/umich-biostatistics/qif,3252,0,2019-07-18T15:51:27Z,NA
qiitr,"Qiita is a technical knowledge sharing and collaboration platform for programmers.
  See <https://qiita.com/api/v2/docs> for more information.",2020-05-16,Hiroaki Yutani,https://github.com/yutannihilation/qiitr,TRUE,https://github.com/yutannihilation/qiitr,9590,5,2020-05-16T05:56:07Z,1918
qmethod,"Analysis of Q methodology, used to identify distinct perspectives existing within a group.
  This methodology is used across social, health and environmental sciences to understand diversity of attitudes, discourses, or decision-making styles (for more information, see <http://qmethod.org>).
  A single function runs the full analysis. Each step can be run separately using the corresponding functions: for automatic flagging of Q-sorts (manual flagging is optional), for statement scores, for distinguishing and consensus statements, and for general characteristics of the factors.
  Additional functions are available to import and export data, to print and plot, to import raw data from individual *.CSV files, and to make printable cards.
  The package also offers functions to print Q cards and to generate Q distributions for study administration.
  The package uses principal components and it allows manual or automatic flagging, a number of mathematical methods for rotation, and a number of correlation coefficients for the initial correlation matrix.
  See further details in the package documentation, and in the web pages below, which include a cookbook, guidelines for more advanced analysis (how to perform manual flagging or change the sign of factors), data management, and a beta graphical user interface for online and offline use.",2020-02-13,Aiora Zabala  (Main author,"https://github.com/aiorazabala/qmethod,
https://github.com/aiorazabala/qmethod/wiki",TRUE,https://github.com/aiorazabala/qmethod,22379,28,2020-05-04T17:31:23Z,799.25
qpdf,"Content-preserving transformations transformations of PDF files such 
    as split, combine, and compress. This package interfaces directly to the 'qpdf' 
    C++ API and does not require any command line utilities. Note that 'qpdf' does
    not read actual content from PDF files: to extract text and data you need the
    'pdftools' package.",2019-03-07,Jeroen Ooms,"https://github.com/ropensci/qpdf (devel),
http://qpdf.sourceforge.net/ (upstream)",TRUE,https://github.com/ropensci/qpdf,206976,31,2019-11-16T15:30:45Z,6676.645161290323
qqplotr,Extensions of 'ggplot2' Q-Q plot functionalities.,2020-02-04,Adam Loy,https://github.com/aloy/qqplotr,TRUE,https://github.com/aloy/qqplotr,39163,35,2020-02-19T16:47:22Z,1118.942857142857
qqtest,"Provides the function qqtest which incorporates uncertainty in its
    qqplot display(s) so that the user might have a better sense of the
    evidence against the specified distributional hypothesis.  qqtest draws a
    quantile quantile plot for visually assessing whether the data come from a
    test distribution that has been defined in one of many ways.  The vertical
    axis plots the data quantiles, the horizontal those of a test distribution.
    The default behaviour generates 1000 samples from the test distribution and
    overlays the plot with shaded pointwise interval estimates for the ordered
    quantiles from the test distribution.  A small number of independently
    generated exemplar quantile plots can also be overlaid.  Both the interval
    estimates and the exemplars provide different comparative information to
    assess the evidence provided by the qqplot for or against the hypothesis
    that the data come from the test distribution (default is normal or
    gaussian).  Finally, a visual test of significance (a lineup plot) can also
    be displayed to test the null hypothesis that the data come from the test
    distribution.",2020-03-16,Wayne Oldford,"https://github.com/rwoldford/qqtest,
https://rwoldford.github.io/qqtest/",TRUE,https://github.com/rwoldford/qqtest,19192,0,2020-03-16T15:49:28Z,NA
qs,Provides functions for quickly writing and reading any R object to and from disk.  ,2020-03-10,Travers Ching,https://github.com/traversc/qs,TRUE,https://github.com/traversc/qs,53192,161,2020-06-04T07:28:41Z,330.3850931677019
qtl,"Analysis of experimental crosses to identify genes
  (called quantitative trait loci, QTLs) contributing to variation in
  quantitative traits.
  Broman et al. (2003) <doi:10.1093/bioinformatics/btg112>.",2020-03-11,Karl W Broman <broman@wisc.edu> and Hao Wu,"https://rqtl.org, https://github.com/kbroman/qtl",TRUE,https://github.com/kbroman/qtl,141136,55,2020-05-13T13:41:11Z,2566.109090909091
qtl2pleio,"We implement an
    adaptation of Jiang & Zeng's (1995) <https://www.genetics.org/content/140/3/1111> likelihood ratio test for testing
    the null hypothesis of pleiotropy against the alternative hypothesis,
    two separate quantitative trait loci. The test differs from that in Jiang & Zeng (1995) <https://www.genetics.org/content/140/3/1111> 
    and that in Tian et al. (2016) <doi:10.1534/genetics.115.183624> in
    that our test accommodates multiparental populations.",2019-11-05,Frederick J Boehm,https://github.com/fboehm/qtl2pleio,TRUE,https://github.com/fboehm/qtl2pleio,2486,2,2020-06-10T01:34:05Z,1243
qtlbook,"Datasets for the book, A Guide to QTL Mapping with R/qtl.
    Broman and Sen (2009) <doi:10.1007/978-0-387-92125-9>.",2019-06-28,Karl W Broman,"http://rqtl.org/book, https://github.com/kbroman/qtlbook",TRUE,https://github.com/kbroman/qtlbook,18641,5,2019-06-28T13:57:29Z,3728.2
qtlcharts,"Web-based interactive charts (using D3.js) for the analysis of
    experimental crosses to identify genetic loci (quantitative trait
    loci, QTL) contributing to variation in quantitative traits.",2019-02-05,Karl W Broman,"https://kbroman.org/qtlcharts,
https://github.com/kbroman/qtlcharts",TRUE,https://github.com/kbroman/qtlcharts,21987,78,2020-06-09T04:28:31Z,281.88461538461536
quadmesh,"Create surface forms from matrix or 'raster' data for flexible plotting and
 conversion to other mesh types. The functions 'quadmesh' or 'triangmesh'
 produce a continuous surface as a 'mesh3d' object as used by the 'rgl'
 package. This is used for plotting raster data in 3D (optionally with
 texture), and allows the application of a map projection without data loss and 
 many processing applications that are restricted by inflexible regular grid rasters.
 There are discrete forms of these continuous surfaces available with
 'dquadmesh' and 'dtriangmesh' functions.",2020-04-15,Michael D. Sumner,https://github.com/hypertidy/quadmesh,TRUE,https://github.com/hypertidy/quadmesh,20066,18,2020-05-13T16:28:59Z,1114.7777777777778
qualmap,"Provides a set of functions for taking qualitative GIS data, hand drawn on a map, and 
   converting it to a simple features object. These tools are focused on data that are drawn on a map
   that contains some type of polygon features. For each area identified on the map, the id numbers
   of these polygons can be entered as vectors and transformed using qualmap.",2020-05-13,Christopher Prener,https://github.com/slu-openGIS/qualmap,TRUE,https://github.com/slu-opengis/qualmap,8714,11,2020-05-13T14:29:13Z,792.1818181818181
qualtRics,"Provides functions to access survey results directly into R using 
    the 'Qualtrics' API. 'Qualtrics' <https://www.qualtrics.com/about/> is an 
    online survey and data collection software platform. See 
    <https://api.qualtrics.com/> for more information about the 'Qualtrics' API. 
    This package is community-maintained and is not officially supported by 
    'Qualtrics'.",2020-05-22,Julia Silge,"https://docs.ropensci.org/qualtRics/,
https://github.com/ropensci/qualtRics",TRUE,https://github.com/ropensci/qualtrics,21239,127,2020-05-25T20:02:13Z,167.23622047244095
Quandl,"Functions for interacting directly with the Quandl API to offer data in a number of formats usable in R, downloading a zip with all data from a Quandl database, and the ability to search. This R package uses the Quandl API. For more information go to <https://www.quandl.com/docs/api>. For more help on the package itself go to <https://www.quandl.com/help/r>.",2019-06-12,Dave Dotson,https://github.com/quandl/quandl-r,TRUE,https://github.com/quandl/quandl-r,480238,106,2019-07-08T13:12:29Z,4530.547169811321
quantable,"Methods which streamline the descriptive analysis of quantitative
    matrices. Matrix columns are samples while rows are features i.e. proteins, genes.
    Includes methods for visualization (e.g. Heatmaps, Volcanos, pairwise QQ, Bland-Altman plot),
    summary statistics (e.g. CV), data normalization methods (e.g. robustscale). Read function for Progenesis.  ",2018-05-15,Witold Wolski,https://github.com/protViz/quantable,TRUE,https://github.com/protviz/quantable,18685,7,2020-03-12T09:46:28Z,2669.285714285714
quantdates,"Functions to manipulate dates and count days for quantitative finance analysis. The 'quantdates' package considers leap, holidays and business days for relevant calendars in a financial context to simplify quantitative finance calculations, consistent with International Swaps and Derivatives Association (ISDA) (2006) <https://www.isda.org/book/2006-isda-definitions/> regulations.",2020-06-09,Julian Chitiva,NA,TRUE,https://github.com/quantilma/quantdates,0,1,2020-06-05T23:05:10Z,0
quanteda,"A fast, flexible, and comprehensive framework for 
    quantitative text analysis in R.  Provides functionality for corpus management,
    creating and manipulating tokens and ngrams, exploring keywords in context, 
    forming and manipulating sparse matrices
    of documents by features and feature co-occurrences, analyzing keywords, computing feature similarities and
    distances, applying content dictionaries, applying supervised and unsupervised machine learning, 
    visually representing text and text analyses, and more. ",2020-03-18,Kenneth Benoit,https://quanteda.io,TRUE,https://github.com/quanteda/quanteda,474380,587,2020-05-24T17:04:48Z,808.1431005110733
quanteda.textmodels,"Scaling models and classifiers for sparse matrix objects representing 
    textual data in the form of a document-feature matrix.  Includes original 
    implementations of 'Laver', 'Benoit', and Garry's (2003) <doi:10.1017/S0003055403000698>,
    'Wordscores' model, Perry and 'Benoit's' (2017) <arXiv:1710.08963> class affinity scaling model, 
    and 'Slapin' and 'Proksch's' (2008) <doi:10.1111/j.1540-5907.2008.00338.x> 'wordfish'
    model, as well as methods for correspondence analysis, latent semantic analysis,
    and fast Naive Bayes and linear 'SVMs' specially designed for sparse textual data.",2020-03-13,Kenneth Benoit,https://github.com/quanteda/quanteda.textmodels,TRUE,https://github.com/quanteda/quanteda.textmodels,8913,11,2020-06-02T10:58:23Z,810.2727272727273
quantities,"Integration of the 'units' and 'errors' packages for a complete
    quantity calculus system for R vectors, matrices and arrays, with automatic
    propagation, conversion, derivation and simplification of magnitudes and
    uncertainties. Documentation about 'units' and 'errors' is provided in the
    papers by Pebesma, Mailund & Hiebert (2016, <doi:10.32614/RJ-2016-061>) and
    by Ucar, Pebesma & Azcorra (2018, <doi:10.32614/RJ-2018-075>), included in
    those packages as vignettes; see 'citation(""quantities"")' for details.",2020-06-06,Iñaki Ucar,https://github.com/r-quantities/quantities,TRUE,https://github.com/r-quantities/quantities,6577,16,2020-06-09T15:30:59Z,411.0625
quantmod,"Specify, build, trade, and analyse quantitative financial trading strategies.",2020-03-31,Joshua M. Ulrich,http://www.quantmod.com https://github.com/joshuaulrich/quantmod,TRUE,https://github.com/joshuaulrich/quantmod,5634959,513,2020-05-23T13:52:20Z,10984.325536062379
QuantNorm,"Modifies the distance matrix obtained from data with batch effects, so as to improve the performance of sample pattern detection, such as clustering, dimension reduction, and construction of networks between subjects. The method has been published in Bioinformatics (Fei et al, 2018, <doi:10.1093/bioinformatics/bty117>). Also available on 'GitHub' <https://github.com/tengfei-emory/QuantNorm>.",2019-02-01,Teng Fei,NA,TRUE,https://github.com/tengfei-emory/quantnorm,6769,10,2019-09-22T18:27:40Z,676.9
Quartet,"Calculates the number of four-taxon subtrees consistent with a pair
  of cladograms, calculating the symmetric quartet distance of Bandelt & Dress (1986),
  Reconstructing the shape of a tree from observed dissimilarity data,
  Advances in Applied Mathematics, 7, 309-343 <doi:10.1016/0196-8858(86)90038-2>, 
  and using the tqDist algorithm of Sand et al. (2014), tqDist: a library for
  computing the quartet and triplet distances between binary or general trees,
  Bioinformatics, 30, 2079–2080 <doi:10.1093/bioinformatics/btu157>
  for pairs of binary trees.",2020-01-28,Martin R. Smith,https://github.com/ms609/Quartet,TRUE,https://github.com/ms609/quartet,6473,3,2020-06-08T09:04:37Z,2157.6666666666665
queryparser,Translate 'SQL' 'SELECT' statements into lists of 'R' expressions.,2020-05-10,Ian Cook,https://github.com/ianmcook/queryparser,TRUE,https://github.com/ianmcook/queryparser,4548,36,2020-05-09T21:35:23Z,126.33333333333333
questionr,"Set of functions to make the processing and analysis of
    surveys easier : interactive shiny apps and addins for data recoding,
    contingency tables, dataset metadata handling, and several convenience
    functions.",2020-05-26,Julien Barnier,https://juba.github.io/questionr/,TRUE,https://github.com/juba/questionr,1232187,52,2020-05-26T12:57:11Z,23695.903846153848
quickPlot,"A high-level plotting system, built using 'grid' graphics, that is
    optimized for speed and modularity. This has great utility for quick
    visualizations when testing code, with the key benefit that visualizations
    are updated independently of one another.",2018-11-09,Eliot J B McIntire,"http://quickplot.predictiveecology.org,
https://github.com/PredictiveEcology/quickPlot",TRUE,https://github.com/predictiveecology/quickplot,39393,5,2019-11-09T23:49:38Z,7878.6
quietR,"Simplifies output suppression logic in R packages, as it's common
    to develop some form of it in R. 'quietR' intends to simplify that problem 
    and allow a set of simple toggle functions to be used to suppress console 
    output.",2019-06-17,Thomas Johnson,https://github.com/thomascjohnson/quietR,TRUE,https://github.com/thomascjohnson/quietr,3693,1,2019-06-16T19:21:26Z,3693
quokar,"Diagnostics methods for quantile regression models for detecting influential observations:
  robust distance methods for general quantile regression models; generalized Cook's distance and 
  Q-function distance method for quantile regression models using aymmetric Laplace distribution. Reference
  of this method can be found in Luis E. Benites, Víctor H. Lachos, Filidor E. Vilca (2015) <arXiv:1509.05099v1>; 
  mean posterior probability and Kullback–Leibler divergence methods for Bayes quantile regression model.
  Reference of this method is Bruno Santos, Heleno Bolfarine (2016) <arXiv:1601.07344v1>.",2017-11-10,Wenjing Wang,https://github.com/wenjingwang/quokar,TRUE,https://github.com/wenjingwang/quokar,7936,5,2019-07-14T03:49:44Z,1587.2
qwraps2,"A collection of (wrapper) functions the creator found useful
    for quickly placing data summaries and formatted regression results into
    '.Rnw' or '.Rmd' files. Functions for generating commonly used graphics,
    such as receiver operating curves or Bland-Altman plots, are also provided
    by 'qwraps2'.  'qwraps2' is a updated version of a package 'qwraps'. The
    original version 'qwraps' was never submitted to CRAN but can be found at
    <https://github.com/dewittpe/qwraps/>. The implementation and limited scope
    of the functions within 'qwraps2' <https://github.com/dewittpe/qwraps2/> is
    fundamentally different from 'qwraps'.",2019-12-02,Peter DeWitt,https://github.com/dewittpe/qwraps2/,TRUE,https://github.com/dewittpe/qwraps2,65741,23,2020-03-17T22:27:35Z,2858.304347826087
R.cache,"Memoization can be used to speed up repetitive and computational expensive function calls.  The first time a function that implements memoization is called the results are stored in a cache memory.  The next time the function is called with the same set of parameters, the results are momentarily retrieved from the cache avoiding repeating the calculations.  With this package, any R object can be cached in a key-value storage where the key can be an arbitrary set of R objects.  The cache memory is persistent (on the file system).",2019-12-06,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.cache,TRUE,https://github.com/henrikbengtsson/r.cache,361642,25,2019-12-06T14:08:11Z,14465.68
R.devices,"Functions for creating plots and image files in a unified way
    regardless of output format (EPS, PDF, PNG, SVG, TIFF, WMF, etc.). Default
    device options as well as scales and aspect ratios are controlled in a uniform
    way across all device types. Switching output format requires minimal changes
    in code. This package is ideal for large-scale batch processing, because it
    will never leave open graphics devices or incomplete image files behind, even on
    errors or user interrupts.",2019-10-24,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.devices,TRUE,https://github.com/henrikbengtsson/r.devices,159360,14,2019-12-03T23:02:02Z,11382.857142857143
R.filesets,"A file set refers to a set of files located in one or more directories on the file system.  This package provides classes and methods to locate, setup, subset, navigate and iterate such sets.  The API is designed such that these classes can be extended via inheritance to provide a richer API for special file formats.  Moreover, a specific name format is defined such that filenames and directories can be considered to have full names which consists of a name followed by comma-separated tags.  This adds additional flexibility to identify file sets and individual files.  NOTE: This package's API should be considered to be in an beta stage.  Its main purpose is currently to support the aroma.* packages, where it is one of the main core components; if you decide to build on top of this package, please contact the author first.",2019-04-18,Henrik Bengtsson,"https://github.com/HenrikBengtsson/R.filesets,
http://www.aroma-project.org/",TRUE,https://github.com/henrikbengtsson/r.filesets,67405,1,2019-12-15T03:20:46Z,67405
R.matlab,"Methods readMat() and writeMat() for reading and writing MAT files.  For user with MATLAB v6 or newer installed (either locally or on a remote host), the package also provides methods for controlling MATLAB (trademark) via R and sending and retrieving data between R and MATLAB.",2018-09-27,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.matlab,TRUE,https://github.com/henrikbengtsson/r.matlab,317090,68,2019-12-04T00:35:40Z,4663.088235294118
R.methodsS3,"Methods that simplify the setup of S3 generic functions and S3 methods.  Major effort has been made in making definition of methods as simple as possible with a minimum of maintenance for package developers.  For example, generic functions are created automatically, if missing, and naming conflict are automatically solved, if possible.  The method setMethodS3() is a good start for those who in the future may want to migrate to S4.  This is a cross-platform package implemented in pure R that generates standard S3 methods.",2020-02-14,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.methodsS3,TRUE,https://github.com/henrikbengtsson/r.methodss3,2457071,0,2020-02-14T14:27:54Z,NA
R.oo,Methods and classes for object-oriented programming in R with or without references.  Large effort has been made on making definition of methods as simple as possible with a minimum of maintenance for package developers.  The package has been developed since 2001 and is now considered very stable.  This is a cross-platform package implemented in pure R that defines standard S3 classes without any tricks.,2019-11-03,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.oo,TRUE,https://github.com/henrikbengtsson/r.oo,2255212,16,2020-02-14T04:48:15Z,140950.75
R.rsp,"The RSP markup language makes any text-based document come alive.  RSP provides a powerful markup for controlling the content and output of LaTeX, HTML, Markdown, AsciiDoc, Sweave and knitr documents (and more), e.g. 'Today's date is <%=Sys.Date()%>'.  Contrary to many other literate programming languages, with RSP it is straightforward to loop over mixtures of code and text sections, e.g. in month-by-month summaries.  RSP has also several preprocessing directives for incorporating static and dynamic contents of external files (local or online) among other things.  Functions rstring() and rcat() make it easy to process RSP strings, rsource() sources an RSP file as it was an R script, while rfile() compiles it (even online) into its final output format, e.g. rfile('report.tex.rsp') generates 'report.pdf' and rfile('report.md.rsp') generates 'report.html'.  RSP is ideal for self-contained scientific reports and R package vignettes.  It's easy to use - if you know how to write an R script, you'll be up and running within minutes.",2019-10-17,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.rsp,TRUE,https://github.com/henrikbengtsson/r.rsp,391462,26,2020-03-10T04:40:37Z,15056.23076923077
R.temis,"An integrated solution to perform
    a series of text mining tasks such as importing and cleaning a corpus, and
    analyses like terms and documents counts, lexical summary, terms
    co-occurrences and documents similarity measures, graphs of terms,
    correspondence analysis and hierarchical clustering. Corpora can be imported
    from spreadsheet-like files, directories of raw text files,
    as well as from 'Dow Jones Factiva', 'LexisNexis', 'Europresse' and 'Alceste' files.",2019-06-17,Milan Bouchet-Valat,https://github.com/nalimilan/R.TeMiS,TRUE,https://github.com/nalimilan/r.temis,7244,17,2020-04-01T16:31:45Z,426.11764705882354
R.utils,Utility functions useful when programming and developing R packages.,2019-12-08,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.utils,TRUE,https://github.com/henrikbengtsson/r.utils,2239430,42,2020-04-23T21:28:59Z,53319.76190476191
r2d3,"Suite of tools for using 'D3', a library for producing dynamic, interactive data
  visualizations. Supports translating objects into 'D3' friendly data structures, rendering
  'D3' scripts, publishing 'D3' visualizations, incorporating 'D3' in R Markdown, creating
  interactive 'D3' applications with Shiny, and distributing 'D3' based 'htmlwidgets' in R
  packages.",2018-12-18,Javier Luraschi,https://github.com/rstudio/r2d3,TRUE,https://github.com/rstudio/r2d3,1331510,400,2019-08-09T22:28:17Z,3328.775
r2dii.data,"These datasets support the implementation in R of
    the software 'PACTA' (Paris Agreement Capital Transition Assessment),
    which is a free tool that calculates the alignment between financial
    assets and climate scenarios (<https://2degrees-investing.org/>).
    Financial institutions use 'PACTA' to study how their capital
    allocation impacts the climate. Because both financial institutions
    and market data providers keep their data private, this package
    provides fake, public data to enable the development and use of
    'PACTA' in R.",2020-06-03,Mauro Lepore,"https://2degreesinvesting.github.io/r2dii.data/,
https://github.com/2DegreesInvesting/r2dii.data",TRUE,https://github.com/2degreesinvesting/r2dii.data,1677,0,2020-06-09T13:00:46Z,NA
r2dii.match,"These tools implement in R a fundamental part of
    the software 'PACTA' (Paris Agreement Capital Transition Assessment),
    which is a free tool that calculates the alignment between financial
    portfolios and climate scenarios (<https://2degrees-investing.org/>).
    Financial institutions use 'PACTA' to study how their capital
    allocation impacts the climate. This package matches data from
    financial portfolios to asset level data from market-intelligence
    databases (e.g. power plant capacities, emission factors, etc.). This
    is the first step to assess if a financial portfolio aligns with
    climate goals.",2020-06-04,Mauro Lepore,"https://2degreesinvesting.github.io/r2dii.match,
https://github.com/2DegreesInvesting/r2dii.match",TRUE,https://github.com/2degreesinvesting/r2dii.match,1190,0,2020-06-05T02:01:57Z,NA
r2glmm,"The model R squared and semi-partial R squared for the linear and
    generalized linear mixed model (LMM and GLMM) are computed with confidence
    limits. The R squared measure from Edwards et.al (2008) <DOI:10.1002/sim.3429>
    is extended to the GLMM using penalized quasi-likelihood (PQL) estimation
    (see Jaeger et al. 2016 <DOI:10.1080/02664763.2016.1193725>). Three methods
    of computation are provided and described as follows. First, The
    Kenward-Roger approach. Due to some inconsistency between the 'pbkrtest'
    package and the 'glmmPQL' function, the Kenward-Roger approach in the
    'r2glmm' package is limited to the LMM. Second, The method introduced
    by Nakagawa and Schielzeth (2013) <DOI:10.1111/j.2041-210x.2012.00261.x>
    and later extended by Johnson (2014) <DOI:10.1111/2041-210X.12225>.
    The 'r2glmm' package only computes marginal R squared for the LMM and does
    not generalize the statistic to the GLMM; however, confidence limits and
    semi-partial R squared for fixed effects are useful additions. Lastly, an
    approach using standardized generalized variance (SGV) can be used for
    covariance model selection. Package installation instructions can be found
    in the readme file.",2017-08-05,Byron Jaeger,https://github.com/bcjaeger/r2glmm,TRUE,https://github.com/bcjaeger/r2glmm,19736,9,2020-03-05T16:54:31Z,2192.8888888888887
r2pmml,"R wrapper for the JPMML-R library <https://github.com/jpmml/jpmml-r>,
    which converts R models to Predictive Model Markup Language (PMML).",2020-02-05,Villu Ruusmann,https://github.com/jpmml/r2pmml,TRUE,https://github.com/jpmml/r2pmml,6282,61,2020-05-25T20:10:20Z,102.98360655737704
r2sundials,"Wrapper for widely used 'SUNDIALS' software (SUite of Nonlinear and DIfferential/ALgebraic Equation Solvers) and more precisely to its 'CVODES' solver. It is aiming to solve ordinary differential equations (ODE) and optionally pending forward sensitivity problem. The wrapper is made 'R' friendly by allowing to pass custom parameters to user's callback functions. Such functions can be both written in 'R' and in 'C++' ('RcppArmadillo' flavor). In case of 'C++', performance is greatly improved so this option is highly advisable when performance matters. If provided, Jacobian matrix can be calculated either in dense or sparse format. In the latter case 'rmumps' package is used to solve corresponding linear systems. Root finding and pending event management are optional and can be specified as 'R' or 'C++' functions too. This makes them a very flexible tool for controlling the ODE system during the time course simulation. 'SUNDIALS' library was published in Hindmarsh et al. (2005) <doi:10.1145/1089014.1089020>.",2020-03-15,Serguei Sokol,NA,TRUE,https://github.com/sgsokol/r2sundials,2262,1,2020-03-12T16:26:36Z,2262
R2SWF,"Using the 'Ming' library
    <http://www.libming.org/> to create Flash animations.
    Users can either use the 'SWF' device swf() to generate 'SWF' file
    directly through plotting functions like plot() and lines(),
    or convert images of other formats ('SVG', 'PNG', 'JPEG') into 'SWF'.",2020-05-09,Yixuan Qiu,https://github.com/yixuan/R2SWF,TRUE,https://github.com/yixuan/r2swf,21458,1,2020-05-10T12:10:29Z,21458
r3PG,"Provides a flexible and easy-to-use interface for the Physiological Processes Predicting Growth (3-PG) model written in Fortran. The r3PG serves as a flexible and easy-to-use interface for the 3-PGpjs (monospecific, evenaged and evergreen forests) described in Landsberg & Waring (1997) <doi:10.1016/S0378-1127(97)00026-1> and the 3-PGmix (deciduous, uneven-aged or mixed-species forests) described in Forrester & Tang (2016) <doi:10.1016/j.ecolmodel.2015.07.010>.",2020-06-02,Volodymyr Trotsiuk,https://github.com/trotsiuk/r3PG,TRUE,https://github.com/trotsiuk/r3pg,503,1,2020-06-02T18:18:48Z,503
R3port,"Create and combine HTML and PDF reports from within R.
    Possibility to design tables and listings for reporting and also include R plots.",2020-03-16,Richard Hooijmaijers,https://github.com/RichardHooijmaijers/R3port,TRUE,https://github.com/richardhooijmaijers/r3port,7528,8,2020-03-16T14:21:17Z,941
r4ss,"A collection of R functions for use with Stock Synthesis, a
    fisheries stock assessment modeling platform written in ADMB by Dr. Richard
    D.  Methot at the NOAA Northwest Fisheries Science Center. The functions
    include tools for summarizing and plotting results, manipulating files,
    visualizing model parameterizations, and various other common stock
    assessment tasks.",2019-10-18,Ian G. Taylor,https://github.com/r4ss/r4ss,TRUE,https://github.com/r4ss/r4ss,25993,16,2020-06-04T22:36:29Z,1624.5625
R6,"Creates classes with reference semantics, similar to R's built-in
    reference classes. Compared to reference classes, R6 classes are simpler
    and lighter-weight, and they are not built on S4 classes so they do not
    require the methods package. These classes allow public and private
    members, and they support inheritance, even when the classes are defined in
    different packages.",2019-11-12,Winston Chang,"https://r6.r-lib.org, https://github.com/r-lib/R6/",TRUE,https://github.com/r-lib/r6,23342939,285,2019-12-13T00:55:58Z,81905.04912280702
R62S3,"After defining an R6 class, R62S3 is used to automatically generate optional S3/S4 generics and methods for dispatch. Also allows piping for R6 objects.",2020-03-09,Raphael Sonabend,https://github.com/RaphaelS1/R62S3/,TRUE,https://github.com/raphaels1/r62s3,15157,18,2020-03-18T18:36:58Z,842.0555555555555
raceland,"Implements a computational framework for a pattern-based, 
    zoneless analysis, and visualization of (ethno)racial topography. It is a reimagined
    approach for analyzing residential segregation and racial diversity based on 
    the concept of 'landscape’ used in the domain of landscape ecology.",2020-04-02,Jakub Nowosad,https://nowosad.github.io/raceland/,TRUE,https://github.com/nowosad/raceland,4120,3,2020-06-09T19:17:47Z,1373.3333333333333
radiant,"A platform-independent browser-based interface for business
    analytics in R, based on the shiny package. The application combines the
    functionality of radiant.data, radiant.design, radiant.basics,
    radiant.model, and radiant.multivariate.",2020-04-11,Vincent Nijs,https://github.com/radiant-rstats/radiant,TRUE,https://github.com/radiant-rstats/radiant,39354,234,2020-05-15T06:22:06Z,168.17948717948718
radiant.basics,"The Radiant Basics menu includes interfaces for probability 
    calculation, central limit theorem simulation, comparing means and proportions, 
    goodness-of-fit testing, cross-tabs, and correlation. The application extends 
    the functionality in radiant.data.",2020-03-24,Vincent Nijs,"https://github.com/radiant-rstats/radiant.basics,
https://radiant-rstats.github.io/radiant.basics,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.basics,32624,4,2020-03-23T18:58:34Z,8156
radiant.data,"The Radiant Data menu includes interfaces for loading, saving,
    viewing, visualizing, summarizing, transforming, and combining data. It also
    contains functionality to generate reproducible reports of the analyses
    conducted in the application.",2020-03-23,Vincent Nijs,"https://github.com/radiant-rstats/radiant.data,
https://radiant-rstats.github.io/radiant.data,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.data,40379,34,2020-05-26T01:17:11Z,1187.6176470588234
radiant.design,"The Radiant Design menu includes interfaces for design of
    experiments, sampling, and sample size calculation. The application extends
    the functionality in radiant.data.",2020-03-24,Vincent Nijs,"https://github.com/radiant-rstats/radiant.design,
https://radiant-rstats.github.io/radiant.design,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.design,30242,6,2020-03-24T08:21:06Z,5040.333333333333
radiant.model,"The Radiant Model menu includes interfaces for linear and logistic
    regression, naive Bayes, neural networks, classification and regression trees,
    model evaluation, collaborative filtering, decision analysis, and simulation. 
    The application extends the functionality in radiant.data.",2020-03-24,Vincent Nijs,"https://github.com/radiant-rstats/radiant.model,
https://radiant-rstats.github.io/radiant.model,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.model,33269,12,2020-04-10T06:20:32Z,2772.4166666666665
radiant.multivariate,"The Radiant Multivariate menu includes interfaces for perceptual
    mapping, factor analysis, cluster analysis, and conjoint analysis. The
    application extends the functionality in radiant.data.",2020-03-25,Vincent Nijs,"https://github.com/radiant-rstats/radiant.multivariate,
https://radiant-rstats.github.io/radiant.multivariate,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.multivariate,31347,5,2020-03-25T00:04:24Z,6269.4
radsafer,"Provides functions for radiation safety, also known as ""radiation protection"" and ""radiological control"". The science of radiation protection is called ""health physics"" and its engineering functions are called ""radiological engineering"". Functions in this package cover many of the computations needed by radiation safety professionals. Examples include: obtaining updated calibration and source check values for radiation monitors to account for radioactive decay in a reference source, simulating instrument readings to better understand measurement uncertainty, correcting instrument readings for geometry and ambient atmospheric conditions. Many of these functions are described in Johnson and Kirby (2011, ISBN-13:  978-1609134198). Utilities are also included for developing inputs and processing outputs with radiation transport codes, such as MCNP, a general-purpose Monte Carlo N-Particle code that can be used for neutron, photon, electron, or coupled neutron/photon/electron transport (Werner et. al. (2018) <doi:10.2172/1419730>).",2020-02-28,Mark Hogue,https://github.com/markhogue/radsafer,TRUE,https://github.com/markhogue/radsafer,5485,1,2020-06-10T01:42:32Z,5485
Radviz,"An implementation of the radviz projection in R. It enables the visualization of
    multidimensional data while maintaining the relation to the original dimensions.
    This package provides functions to create and plot radviz projections, and a number of summary
    plots that enable comparison and analysis. For reference see Ankerst *et al.* (1996) 
    (<http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.1811>) for original implementation, 
    see Di Caro *et al* (2012) (<http://link.springer.com/chapter/10.1007/978-3-642-13672-6_13>) 
    for the original method for dimensional anchor arrangements, see Demsar *et al.* (2007) 
    (<doi:10.1016/j.jbi.2007.03.010>) for the original Freeviz implementation.",2020-03-29,Yann Abraham,http://github.com/yannabraham/Radviz,TRUE,https://github.com/yannabraham/radviz,12334,7,2020-03-27T10:45:23Z,1762
RAdwords,"Aims at loading Google Adwords data into R. Adwords is an online
    advertising service that enables advertisers to display advertising copy to web
    users (see <https://developers.google.com/adwords/> for more information). 
    Therefore the package implements three main features. First, the package
    provides an authentication process for R with the Google Adwords API (see 
    <https://developers.google.com/adwords/api/> for more information) via OAUTH2.
    Second, the package offers an interface to apply the Adwords query language in
    R and query the Adwords API with ad-hoc reports. Third, the received data are
    transformed into suitable data formats for further data processing and data
    analysis.",2019-01-28,Johannes Burkhardt,"https://github.com/jburkhardt/RAdwords,
https://developers.google.com/adwords,
https://developers.google.com/adwords/api/",TRUE,https://github.com/jburkhardt/radwords,44276,91,2019-07-24T12:29:09Z,486.54945054945057
ragg,"Anti-Grain Geometry (AGG) is a high-quality and high-performance
    2D drawing library. The 'ragg' package provides a set of graphic devices 
    based on AGG to use as alternative to the raster devices provided through
    the 'grDevices' package.",2020-05-14,Thomas Lin Pedersen,"https://ragg.r-lib.org, https://github.com/r-lib/ragg",TRUE,https://github.com/r-lib/ragg,16222,75,2020-06-04T08:25:39Z,216.29333333333332
rags2ridges,"Proper L2-penalized ML estimators for the
  precision matrix as well as supporting functions to employ these estimators
  in a graphical modeling setting.",2019-12-17,Carel F.W. Peeters,https://github.com/CFWP/rags2ridges,TRUE,https://github.com/cfwp/rags2ridges,20724,5,2020-05-27T20:32:59Z,4144.8
RAhrefs,"Enables downloading detailed reports from <https://ahrefs.com>
    about backlinks from pointing to website, provides authentication with an 
    API key as well as ordering, grouping and filtering functionalities.",2019-07-28,Leszek Siemiński,https://ahrefs.com/,TRUE,https://github.com/leszek-sieminski/rahrefs,3329,10,2019-07-29T19:31:52Z,332.9
rai,"A modified implementation of stepwise regression that greedily searches 
    the space of interactions among features in order to build polynomial regression models.
    Furthermore, the hypothesis tests conducted are valid-post model selection
    due to the use of a revisiting procedure that implements an alpha-investing
    rule. As a result, the set of rejected sequential hypotheses is proven to 
    control the marginal false discover rate. When not searching for polynomials,
    the package provides a statistically valid algorithm
    to run and terminate stepwise regression. For more information, see 
    Johnson, Stine, and Foster (2019) <arXiv:1510.06322>.",2019-07-02,Kory D. Johnson,https://github.com/korydjohnson/rai,TRUE,https://github.com/korydjohnson/rai,3554,2,2020-02-17T08:49:04Z,1777
rainette,"An R implementation of the Reinert text clustering method. For more 
    details about the algorithm see the included vignettes or Reinert (1990) 
    <doi:10.1177/075910639002600103>.",2020-05-09,Julien Barnier,https://juba.github.io/rainette/,TRUE,https://github.com/juba/rainette,1403,29,2020-06-03T13:10:24Z,48.37931034482759
ralger,"The goal of 'ralger' is to facilitate web scraping in R. 
    The user has the ability to extract a vector with scrap(), a tidy dataframe using tidy_scrap(), a table with table_scrap() and web links with weblink_scrap().",2020-04-12,Mohamed El Fodil Ihaddaden,https://github.com/feddelegrand7/ralger,TRUE,https://github.com/feddelegrand7/ralger,3175,5,2020-04-12T21:59:36Z,635
rAltmetric,"Provides a programmatic interface to the citation information and alternate metrics provided by 'Altmetric'. Data from Altmetric allows researchers to immediately track the impact of their published work, without having to wait for citations. This allows for faster engagement with the audience interested in your work. For more information, visit <https://www.altmetric.com/>.",2017-04-19,Karthik Ram,https://github.com/ropensci/rAltmetric,TRUE,https://github.com/ropensci/raltmetric,18905,35,2019-12-09T14:27:01Z,540.1428571428571
rAmCharts,"Provides an R interface for using 'AmCharts' Library. Based on
    'htmlwidgets', it provides a global architecture to generate 'JavaScript' source
    code for charts. Most of classes in the library have their equivalent in R
    with S4 classes; for those classes, not all properties have been referenced but
    can easily be added in the constructors. Complex properties (e.g. 'JavaScript'
    object) can be passed as named list. See examples at 
    <http://datastorm-open.github.io/introduction_ramcharts/> 
    and <http://www.amcharts.com/> for
    more information about the library. The package includes the free version
    of 'AmCharts' Library. Its only limitation is a small link to the web site
    displayed on your charts. If you enjoy this library, do not hesitate to refer
    to this page <http://www.amcharts.com/online-store/> to purchase a licence,
    and thus support its creators and get a period of Priority Support. See also
    <http://www.amcharts.com/about/> for more information about 'AmCharts' company.",2019-12-06,Benoit Thieurmel,http://datastorm-open.github.io/introduction_ramcharts/,TRUE,https://github.com/datastorm-open/ramcharts,41452,44,2019-12-06T14:41:34Z,942.0909090909091
RAMClustR,"A feature clustering algorithm for non-targeted mass spectrometric metabolomics data. This method is compatible with gas and liquid chromatography coupled mass spectrometry, including indiscriminant tandem mass spectrometry <DOI: 10.1021/ac501530d> data. ",2019-09-20,Corey D. Broeckling,https://github.com/cbroeckl/RAMClustR,TRUE,https://github.com/cbroeckl/ramclustr,5033,5,2020-06-02T00:42:48Z,1006.6
ramcmc,"Function for adapting the shape of the random walk Metropolis proposal
    as specified by robust adaptive Metropolis algorithm by Vihola (2012) <DOI:10.1007/s11222-011-9269-5>. 
    Package also includes fast functions for rank-one Cholesky update and downdate.
    These functions can be used directly from R or the corresponding C++ header files 
    can be easily linked to other R packages.",2018-05-29,Jouni Helske,NA,TRUE,https://github.com/helske/ramcmc,17353,2,2019-06-17T13:53:16Z,8676.5
ramlegacy,"Contains functions to download, cache and read in 'Excel' version of the
    RAM Legacy Stock Assessment Data Base, an online compilation of stock assessment
    results for commercially exploited marine populations from around the world. 
    The database is named after Dr. Ransom A. Myers whose original stock-recruitment database,
    is no longer being updated. More information about the database can be found at
    <https://ramlegacy.org/>. Ricard, D., Minto, C., Jensen, O.P. and Baum, J.K. (2012) <doi:10.1111/j.1467-2979.2011.00435.x>.",2019-05-16,Carl Boettiger,https://github.com/ropensci/ramlegacy,TRUE,https://github.com/ropensci/ramlegacy,3903,3,2019-12-09T14:27:53Z,1301
randgeo,"Generate random positions (latitude/longitude), 
    Well-known text ('WKT') points or polygons, or 'GeoJSON' points or 
    polygons. ",2018-05-18,Scott Chamberlain,https://github.com/ropensci/randgeo,TRUE,https://github.com/ropensci/randgeo,10115,10,2019-12-09T14:29:47Z,1011.5
randomForestExplainer,"A set of tools to help explain which variables are most important in a random forests. Various variable importance measures are calculated and visualized in different settings in order to get an idea on how their importance changes depending on our criteria (Hemant Ishwaran and Udaya B. Kogalur and Eiran Z. Gorodeski and Andy J. Minn and Michael S. Lauer (2010) <doi:10.1198/jasa.2009.tm08622>, Leo Breiman (2001) <doi:10.1023/A:1010933404324>).",2019-09-18,Yue Jiang,https://github.com/ModelOriented/randomForestExplainer,TRUE,https://github.com/modeloriented/randomforestexplainer,26585,158,2020-02-02T22:56:04Z,168.2594936708861
randomizr,"Generates random assignments for common experimental designs and 
	    random samples for common sampling designs.",2019-09-06,Alexander Coppock,"https://declaredesign.org/r/randomizr/,
https://github.com/DeclareDesign/randomizr",TRUE,https://github.com/declaredesign/randomizr,54306,23,2019-09-13T16:56:59Z,2361.1304347826085
randquotes,"Connects to the site <http://quotesondesign.com/> 
            that uses the 'WordPress' built-in REST API 
            to provide a way for you to grab quotes.",2019-10-25,AbdulMajedRaja RS,https://github.com/amrrs/randquotes,TRUE,https://github.com/amrrs/randquotes,6410,7,2019-10-25T19:11:31Z,915.7142857142857
rangeBuilder,"Provides tools for filtering occurrence records, generating alpha-hull-derived range polygons and mapping species distributions. ",2019-12-10,Pascal Title,https://github.com/ptitle/rangeBuilder,TRUE,https://github.com/ptitle/rangebuilder,14625,4,2019-12-10T15:01:31Z,3656.25
rangeMapper,"Tools for easy generation of (life-history) traits maps based on
    species range (extent-of-occurrence) maps.",2019-10-25,Mihai Valcu,https://github.com/valcu/rangeMapper,TRUE,https://github.com/valcu/rangemapper,27754,3,2019-10-25T17:48:48Z,9251.333333333334
ranger,"A fast implementation of Random Forests, particularly suited for high
          dimensional data. Ensembles of classification, regression, survival and
          probability prediction trees are supported. Data from genome-wide association
          studies can be analyzed efficiently. In addition to data frames, datasets of
          class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') 
          can be directly analyzed.",2020-01-10,Marvin N. Wright,https://github.com/imbs-hl/ranger,TRUE,https://github.com/imbs-hl/ranger,1060002,545,2020-05-11T15:32:25Z,1944.9577981651375
Rankcluster,"Implementation of a model-based clustering algorithm for
    ranking data (C. Biernacki, J. Jacques (2013) <doi:10.1016/j.csda.2012.08.008>). 
    Multivariate rankings as well as partial rankings are taken
    into account. This algorithm is based on an extension of the Insertion
    Sorting Rank (ISR) model for ranking data, which is a meaningful and
    effective model parametrized by a position parameter (the modal ranking,
    quoted by mu) and a dispersion parameter (quoted by pi). The heterogeneity
    of the rank population is modelled by a mixture of ISR, whereas conditional
    independence assumption is considered for multivariate rankings.",2020-02-20,Quentin Grimonprez,NA,TRUE,https://github.com/modal-inria/rankcluster,23256,0,2020-05-28T11:48:52Z,NA
RankingProject,"Functions to generate plots and tables for comparing independently-
    sampled populations. Companion package to ""A Primer on Visualizations
    for Comparing Populations, Including the Issue of Overlapping Confidence
    Intervals"" by Wright, Klein, and Wieczorek (2019)
    <DOI:10.1080/00031305.2017.1392359> and ""A Joint Confidence Region for an
    Overall Ranking of Populations"" by Klein, Wright, and Wieczorek (2020, in
    press).",2020-01-29,Jerzy Wieczorek,http://github.com/civilstat/RankingProject,TRUE,https://github.com/civilstat/rankingproject,9326,4,2020-01-29T20:46:45Z,2331.5
RANN,"Finds the k nearest neighbours for every point in a given dataset
    in O(N log N) time using Arya and Mount's ANN library (v1.1.3). There is
    support for approximate as well as exact searches, fixed radius searches
    and 'bd' as well as 'kd' trees. The distance is computed using the L2
    (Euclidean) metric. Please see package 'RANN.L1' for the same
    functionality using the L1 (Manhattan, taxicab) metric.",2019-01-08,Sunil Arya and David Mount,https://github.com/jefferis/RANN,TRUE,https://github.com/jefferis/rann,1131048,33,2020-02-28T06:22:19Z,34274.181818181816
rapbase,"Provide common functions and resources for registry specific
    R-packages at Rapporteket
    <https://rapporteket.github.io/rapporteket/articles/short_introduction.html>.
    This package is relevant for developers of packages/registries at
    Rapporteket.",2019-08-07,Are Edvardsen,http://github.com/Rapporteket/rapbase,TRUE,https://github.com/rapporteket/rapbase,3229,0,2020-02-28T14:03:04Z,NA
rapiclient,"Access services specified in OpenAPI (formerly Swagger) format.
  It is not a code generator. Client is generated dynamically as a list of R 
  functions.",2020-01-17,Darko Bergant,https://github.com/bergant/rapiclient,TRUE,https://github.com/bergant/rapiclient,11174,28,2020-01-17T11:08:19Z,399.07142857142856
rapport,"Facilitating the creation of reproducible statistical
    report templates. Once created, rapport templates can be exported to
    various external formats (HTML, LaTeX, PDF, ODT etc.) with pandoc as the
    converter backend.",2015-11-18,Aleksandar Blagotić,http://rapport-package.info/,TRUE,https://github.com/rapporter/rapport,34095,48,2019-11-03T12:44:00Z,710.3125
RAPTOR,"Performs wood cell anatomical data analyses on spatially explicit xylem (tracheids) datasets 
                  derived from thin sections of woody tissue. The package includes functions for visualisation, 
                  detection and alignment of continuous tracheid radial file (defined as rows) and individual tracheid position 
                  within an annual ring of coniferous species. This package is designed to be used with elaborate cell output, 
                  e.g. as provided with ROXAS (von Arx & Carrer, 2014 <doi:10.1016/j.dendro.2013.12.001>). The package has been validated for Picea abies, 
                  Larix Siberica, Pinus cembra and Pinus sylvestris.",2020-03-09,Richard L. Peters,"https://the-hull.github.io/raptor/,
https://github.com/the-hull/RAPTOR",TRUE,https://github.com/the-hull/raptor,7071,1,2020-03-19T22:43:30Z,7071
raptr,"Biodiversity is in crisis. The overarching aim of conservation
    is to preserve biodiversity patterns and processes. To this end, protected
    areas are established to buffer species and preserve biodiversity processes.
    But resources are limited and so protected areas must be cost-effective.
    This package contains tools to generate plans for protected areas
    (prioritizations), using spatially explicit targets for biodiversity
    patterns and processes. To obtain solutions in a feasible amount  of time,
    this package uses the commercial 'Gurobi' software package (obtained from
    <http://www.gurobi.com/>). For more information on using
    this package, see Hanson et al. (2018) <doi:10.1111/2041-210X.12862>.",2020-03-11,Jeffrey O Hanson,"https://jeffrey-hanson.com/raptr,
https://github.com/jeffreyhanson/raptr",TRUE,https://github.com/jeffreyhanson/raptr,13946,2,2020-05-25T03:27:22Z,6973
raster,"Reading, writing, manipulating, analyzing and modeling of gridded spatial data. The package implements basic and high-level functions. Processing of very large files is supported. There is a also support for vector data operations such as intersections. See the manual and tutorials on <https://rspatial.org/> to get started.",2020-04-19,Robert J. Hijmans,https://rspatial.org/raster,TRUE,https://github.com/rspatial/raster,3353310,86,2020-06-04T00:34:24Z,38991.976744186046
rasterDT,"
  Fast alternatives to several relatively slow 'raster' package
  functions. For large rasters, the functions run from 5 to
  approximately 100 times faster than the 'raster' package functions
  they replace. The 'fasterize' package, on which one function in this
  package depends, includes an implementation of the scan line
  algorithm attributed to Wylie et al. (1967)
  <doi:10.1145/1465611.1465619>.",2020-03-04,Joshua OBrien,https://github.com/JoshOBrien/rasterDT/,TRUE,https://github.com/joshobrien/rasterdt,1508,10,2020-02-26T16:03:34Z,150.8
rasterly,"It aims to easily and rapidly generate raster data in R, even for very large datasets, with an aesthetics-based mapping syntax that should be familiar to users of the 'ggplot2' package. While 'rasterly' does not attempt to reproduce the full functionality of the 'Datashader' graphics pipeline system for Python, the 'rasterly' API has several core elements in common with that software package.",2020-06-08,Zehao Xu,NA,TRUE,https://github.com/plotly/rasterly,2716,38,2020-06-04T14:25:10Z,71.47368421052632
rasterpdf,"The ability to plot raster graphics in PDF files can be useful
    when one needs multi-page documents, but the plots contain so many
    individual elements that (the usual) use of vector graphics results in
    inconveniently large file sizes. Internally, the package plots each
    individual page as a PNG, and then combines them in one PDF file.",2019-11-22,Ilari Scheinin,"https://ilarischeinin.github.io/rasterpdf,
https://github.com/ilarischeinin/rasterpdf",TRUE,https://github.com/ilarischeinin/rasterpdf,3114,3,2019-11-23T11:24:24Z,1038
rasterVis,"Methods for enhanced visualization and interaction with raster data. It implements visualization methods for quantitative data and categorical data, both for univariate and multivariate rasters. It also provides methods to display spatiotemporal rasters, and vector fields. See the website for examples.",2019-12-13,Oscar Perpinan Lamigueiro,http://oscarperpinan.github.io/rastervis,TRUE,https://github.com/oscarperpinan/rastervis,373851,54,2020-05-13T16:11:01Z,6923.166666666667
Rata,"Automated test assembly of linear and adaptive tests using the 
    mixed-integer programming. The full documentation and tutorials are at 
    <https://github.com/xluo11/Rata>.",2019-10-24,Xiao Luo,https://github.com/xluo11/Rata,TRUE,https://github.com/xluo11/rata,2554,1,2019-10-24T14:51:57Z,2554
ratematrix,"Estimates the evolutionary rate matrix (R) using Markov chain Monte Carlo (MCMC) as described in Caetano and Harmon (2017) <doi:10.1111/2041-210X.12826>. The package has functions to run MCMC chains, plot results, evaluate convergence, and summarize posterior distributions.",2020-02-26,Daniel Caetano,https://github.com/Caetanods/ratematrix,TRUE,https://github.com/caetanods/ratematrix,9880,4,2020-03-29T15:58:57Z,2470
RAthena,"Designed to be compatible with the R package 'DBI' (Database Interface)
    when connecting to Amazon Web Service ('AWS') Athena <https://aws.amazon.com/athena/>.
    To do this 'Python' 'Boto3' Software Development Kit ('SDK')
    <https://boto3.amazonaws.com/v1/documentation/api/latest/index.html> is used as a driver.",2020-05-14,Dyfan Jones,https://github.com/DyfanJones/RAthena,TRUE,https://github.com/dyfanjones/rathena,7113,16,2020-05-27T15:40:17Z,444.5625
ratPASTA,"Used for processing data obtained from behaviour experiments studying
    acoustic startle response, a reflex to a loud sound, modulated by several 
    brain regions. The input data is generated with PASTA (Platform for Acoustic 
    STArtle), a DIY device made from a kitchen scale that measures the twitch of 
    an animal standing on the device and records it as time-series data. The 
    function of this package is to import all data, process it in accordance 
    with default or custom metadata describing the experiment protocol, calculate 
    measurements and visualize the results. The PASTA solution and this package
    are described in Virag et al. (2020) <doi:10.1101/2020.04.10.035766>.",2020-06-04,Ivan Kodvanj,https://github.com/ikodvanj/ratPASTA,TRUE,https://github.com/ikodvanj/ratpasta,697,0,2020-06-03T21:54:31Z,NA
raustats,"Functions for downloading Australian economic statistics
  from the Australian Bureau of Statistics (ABS) (see <https://www.abs.gov.au/>) and
  Reserve Bank of Australia (RBA) (see <https://www.rba.gov.au/>) websites.",2020-01-09,David Mitchell,https://github.com/mitcda/raustats,TRUE,https://github.com/mitcda/raustats,5306,7,2020-01-18T09:13:24Z,758
rAvis,"Interface to <http://proyectoavis.com> database. 
    It provides means to download data filtered by species, order,
    family, and several other criteria. Provides also basic functionality to
    plot exploratory maps of the datasets.",2015-06-22,Javier González Hernández,https://github.com/ropensci/rAvis,TRUE,https://github.com/ropensci/ravis,15258,2,2019-12-09T14:30:25Z,7629
rawr,"Retrieves pure R code from popular R websites, including github <https://github.com>, 
    kaggle <https://www.kaggle.com>, datacamp <https://www.datacamp.com>, 
    and R blogs made using R blogdown <https://github.com/rstudio/blogdown>.",2020-06-08,Steve Condylios,https://github.com/stevecondylios/rawr,TRUE,https://github.com/stevecondylios/rawr,3323,10,2020-06-07T23:56:09Z,332.3
rayimage,"Uses convolution-based techniques to generate simulated camera bokeh, depth of field, and other camera effects, using an image and an optional depth map. Accepts both filename inputs and in-memory array representations of images and matrices. Includes functions to perform 2D convolutions, reorient and resize images/matrices, add image overlays, generate camera vignette effects, and add titles to images. ",2020-04-12,Tyler Morgan-Wall,"https://www.rayimage.dev,
https://github.com/tylermorganwall/rayimage",TRUE,https://github.com/tylermorganwall/rayimage,3331,19,2020-04-18T18:19:29Z,175.31578947368422
rayrender,"Render scenes using pathtracing. Build 3D scenes out of spheres, cubes, planes, disks, triangles, line segments, cylinders, ellipsoids, and 3D models in the 'Wavefront' OBJ file format. Supports several material types, textures, multicore rendering, and tone-mapping. Based on the ""Ray Tracing in One Weekend"" book series. Peter Shirley (2018) <https://raytracing.github.io>.",2020-04-19,Tyler Morgan-Wall,"https://www.rayrender.net,
https://github.com/tylermorganwall/rayrender",TRUE,https://github.com/tylermorganwall/rayrender,14723,151,2020-06-04T00:12:52Z,97.50331125827815
rayshader,"Uses a combination of raytracing and multiple hill shading methods to produce 2D and 3D data visualizations and maps. Includes water detection and layering functions, programmable color palette generation, several built-in textures for hill shading, 2D and 3D plotting options, a built-in path tracer, 'Wavefront' OBJ file export, and the ability to save 3D visualizations to a 3D printable format.",2020-04-18,Tyler Morgan-Wall,https://github.com/tylermorganwall/rayshader,TRUE,https://github.com/tylermorganwall/rayshader,32601,1188,2020-06-06T17:06:38Z,27.44191919191919
RBaseX,"'BaseX' <http://basex.org> is a XML database engine and a compliant 'XQuery 3.1' processor with full support of 'W3C Update Facility'. This package is a full client-implementation of the client/server protocol for 'BaseX' and provides functionalities to create, manipulate and query on XML-data. ",2020-05-01,Ben Engbers,https://github.com/BenEngbers/RBaseX,TRUE,https://github.com/benengbers/rbasex,2801,3,2020-04-20T10:42:12Z,933.6666666666666
rbefdata,"Basic R package to access data structures offered by any
    BEFdata portal instance.",2013-11-18,Claas-Thido Pfaff,https://github.com/befdata/rbefdata,TRUE,https://github.com/befdata/rbefdata,15846,1,2019-12-13T10:34:38Z,15846
rbgm,"Facilities for working with Atlantis box-geometry model (BGM) 
 files. Atlantis is a deterministic, biogeochemical, whole-of-ecosystem model. 
 Functions are provided to read from BGM files directly, preserving their 
 internal topology, as well as helper functions to generate spatial data from these
 mesh forms. This functionality aims to simplify the creation and modification of box 
 and geometry as well as the ability to integrate with other data sources. ",2020-04-12,Michael D. Sumner,https://research.csiro.au/atlantis/,TRUE,https://github.com/australianantarcticdivision/rbgm,11350,3,2020-04-12T14:01:38Z,3783.3333333333335
rbhl,"Interface to 'Biodiversity' 'Heritage' Library ('BHL')
    (<https://www.biodiversitylibrary.org/>) API
    (<https://www.biodiversitylibrary.org/docs/api3.html>). 'BHL' is a
    repository of 'digitized' literature on 'biodiversity'
    studies, including 'floras', research papers, and more.",2020-01-29,Scott Chamberlain,"https://github.com/ropensci/rbhl (devel)
https://docs.ropensci.org/rbhl (documentation)",TRUE,https://github.com/ropensci/rbhl,17892,12,2020-06-02T17:13:52Z,1491
rbi,"Provides a complete interface to 'LibBi', a library for Bayesian inference (see <http://libbi.org> and <doi:10.18637/jss.v067.i10> for more information). This includes functions for manipulating 'LibBi' models, for reading and writing 'LibBi' input/output files, for converting 'LibBi' output to provide traces for use with the coda package, and for running 'LibBi' to conduct inference.",2020-04-17,Sebastian Funk,https://github.com/sbfnk/RBi,TRUE,https://github.com/sbfnk/rbi,13141,15,2020-04-21T16:38:10Z,876.0666666666667
rbin,"Manually bin data using weight of evidence and information value. Includes other binning 
    methods such as equal length, quantile and winsorized. Options for combining levels of categorical
    data are also available. Dummy variables can be generated based on the bins created using any of 
    the available binning methods. References: Siddiqi, N. (2006) <doi:10.1002/9781119201731.biblio>.",2020-05-14,Aravind Hebbali,"https://github.com/rsquaredacademy/rbin,
https://rbin.rsquaredacademy.com",TRUE,https://github.com/rsquaredacademy/rbin,10384,9,2020-05-14T13:40:15Z,1153.7777777777778
rbiom,"
    A toolkit for working with Biological Observation Matrix ('BIOM') files.
    Features include reading/writing all 'BIOM' formats, rarefaction, alpha
    diversity, beta diversity (including 'UniFrac'), summarizing counts by 
    taxonomic level, and sample subsetting. Standalone functions for 
    reading, writing, and subsetting phylogenetic trees are also provided. 
    All CPU intensive operations are encoded in C with multi-thread support.",2020-05-29,Daniel P. Smith,https://cmmr.github.io/rbiom/index.html,TRUE,https://github.com/cmmr/rbiom,131,3,2020-05-29T21:28:13Z,43.666666666666664
rbison,"Interface to the 'USGS' 'BISON' (<https://bison.usgs.gov/>)
    API, a 'database' for species occurrence data. Data comes from
    species in the United States from participating data providers. You can get
    data via 'taxonomic' and location based queries. A simple function
    is provided to help visualize data.",2020-06-08,Scott Chamberlain,"https://github.com/ropensci/rbison (devel)
https://docs.ropensci.org/rbison (docs)",TRUE,https://github.com/ropensci/rbison,52016,10,2020-06-08T21:46:55Z,5201.6
RblDataLicense,"R interface to access prices and market data with the 
    'Bloomberg Data License' service from 
    <https://www.bloomberg.com/professional/product/data-license/>. 
    As a prerequisite, a valid Data License from 'Bloomberg' is needed 
    together with the corresponding SFTP credentials and whitelisting 
    of the IP from which accessing the service. 
    This software and its author are in no way affiliated, 
    endorsed, or approved by 'Bloomberg' or any of its affiliates.
    'Bloomberg' is a registered trademark.",2020-01-08,Emanuele Guidotti,"https://github.com/emanuele-guidotti/RblDataLicense,
https://rbldatalicense.r-package.org,
https://emanueleguidotti.dev/RblDataLicense/",TRUE,https://github.com/emanuele-guidotti/rbldatalicense,5564,7,2020-03-24T18:26:20Z,794.8571428571429
Rblpapi,An R Interface to 'Bloomberg' is provided via the 'Blp API'.,2019-04-07,Whit Armstrong,"http://dirk.eddelbuettel.com/code/rblpapi.html,
https://github.com/Rblp/Rblpapi",TRUE,https://github.com/rblp/rblpapi,88415,121,2020-05-20T01:37:46Z,730.702479338843
rblt,"An R-shiny application to plot datalogger time series at a microsecond precision as Acceleration, Temperature, 
  Pressure, Light intensity from CATS, AXY-TREK LUL and WACU bio-loggers. It is possible to link behavioral labels extracted
  from 'BORIS' software <http://www.boris.unito.it> or manually written in a csv file.
  CATS bio-logger are manufactured by <http://www.cats.is>, AXY-TREK are manufactured by <http://www.technosmart.eu> and 
  LUL and WACU are manufactured by <http://www.iphc.cnrs.fr/-MIBE-.html>.",2019-12-05,Sebastien Geiger,https://github.com/sg4r/rblt,TRUE,https://github.com/sg4r/rblt,5553,0,2019-12-03T20:45:31Z,NA
RBNZ,"Provides a convenient way of accessing data published by the Reserve Bank of New Zealand (RBNZ) on their website, <https://www.rbnz.govt.nz/statistics>. A range of financial and economic data is provided in spreadsheet format including exchange and interest rates, commercial lending statistics, Reserve Bank market operations, financial institution statistics, household financial data, New Zealand debt security information, and economic indicators. This package provides a method to download those spreadsheets and read them directly into R.",2020-04-10,Jasper Watson,NA,TRUE,https://github.com/rntq472/rbnz,842,0,2020-04-10T21:38:47Z,NA
Rborist,"Scalable implementation of classification and regression forests, as described by Breiman (2001), <DOI:10.1023/A:1010933404324>.",2019-10-31,Mark Seligman,"http://www.suiji.org/arborist, https://github.com/suiji/Arborist",TRUE,https://github.com/suiji/arborist,50436,73,2020-05-31T00:39:42Z,690.9041095890411
rbraries,"Interface to the 'Libraries.io' API (<https://libraries.io/api>).
    'Libraries.io' indexes data from 36 different package managers for 
    programming languages.",2020-03-18,Scott Chamberlain,"https://docs.ropensci.org/rbraries,
https://github.com/ropensci/rbraries",TRUE,https://github.com/ropensci/rbraries,6816,16,2020-03-19T13:46:24Z,426
rbw,"Residual balancing is a robust method of constructing weights for
  marginal structural models, which can be used to estimate marginal effects of
  time-varying treatments and controlled direct/mediator effects in causal mediation
  analysis (Zhou and Wodtke 2020 <doi:10.1017/pan.2020.2>). This
  package provides two main functions, rbwPanel() and rbwMed(), that produce
  residual balancing weights for analyzing time-varying treatments and
  causal mediation respectively.",2020-04-15,Xiang Zhou,http://github.com/xiangzhou09/rbw,TRUE,https://github.com/xiangzhou09/rbw,836,3,2020-04-13T21:38:55Z,278.6666666666667
Rcan,"Tools for basic and advance cancer statistics and graphics.
	Groups individual data, merges registry data and population data, calculates age-specific rate, age-standardized rate, cumulative risk, estimated annual percentage rate with standards error. Creates graphics across variable and
    time, such as age-specific trends, bar chart and period-cohort trends.",2020-05-19,Mathieu Laversanne,https://github.com/timat35/Rcan,TRUE,https://github.com/timat35/rcan,8589,4,2020-05-19T09:16:14Z,2147.25
RCarb,"Translation of the 'MATLAB' program 'Carb' (Nathan and Mauz 2008 <DOI:10.1016/j.radmeas.2007.12.012>; Mauz and Hoffmann 2014) for dose rate modelling for carbonate-rich samples in the context of trapped charged dating (e.g., luminescence dating) applications. ",2019-06-03,Sebastian Kreutzer,https://r-lum.github.io/RCarb/,TRUE,https://github.com/r-lum/rcarb,10219,0,2020-01-31T18:08:24Z,NA
rchallenge,"A simple data science challenge system using R Markdown and 'Dropbox' <https://www.dropbox.com/>.
    It requires no network configuration, does not depend on external platforms
    like e.g. 'Kaggle' <https://www.kaggle.com/> and can be easily installed on a personal computer.",2020-01-19,Adrien Todeschini,https://adrtod.github.io/rchallenge,TRUE,https://github.com/adrtod/rchallenge,13833,5,2020-01-14T11:24:04Z,2766.6
rcheology,Provides a dataset of functions in all base packages of R versions 1.0.1 onwards.,2020-04-30,David Hugh-Jones,https://github.com/hughjonesd/rcheology,TRUE,https://github.com/hughjonesd/rcheology,9956,26,2020-06-09T15:09:41Z,382.9230769230769
rcites,A programmatic interface to the Species+ <https://speciesplus.net/> database via the Species+/CITES Checklist API <https://api.speciesplus.net/>.,2019-05-24,Jonas Geschke,"https://ropensci.github.io/rcites/,
https://github.com/ropensci/rcites",TRUE,https://github.com/ropensci/rcites,7128,10,2020-03-29T19:03:21Z,712.8
RClickhouse,"'Yandex Clickhouse' (<https://clickhouse.yandex/>) is a high-performance relational column-store database to enable
    big data exploration and 'analytics' scaling to petabytes of data. Methods are
    provided that enable working with 'Yandex Clickhouse' databases via
    'DBI' methods and using 'dplyr'/'dbplyr' idioms.",2020-03-06,Christian Hotz-Behofsits,https://github.com/IMSMWU/RClickhouse,TRUE,https://github.com/imsmwu/rclickhouse,10590,47,2020-03-31T14:58:00Z,225.31914893617022
rclipboard,"Leverages the functionality of 'clipboard.js', a JavaScript library
    for HMTL5-based copy to clipboard from web pages (see <https://clipboardjs.com>
    for more information), and provides a reactive copy-to-clipboard UI button 
    component, called 'rclipButton', for 'shiny' R applications.",2019-07-02,Sebastien Bihorel,http://github.com/sbihorel/rclipboard,TRUE,https://github.com/sbihorel/rclipboard,16729,29,2019-07-02T21:09:13Z,576.8620689655172
RcmdrPlugin.temis,"An 'R Commander' plug-in providing an integrated solution to perform
    a series of text mining tasks such as importing and cleaning a corpus, and
    analyses like terms and documents counts, vocabulary tables, terms
    co-occurrences and documents similarity measures, time series analysis,
    correspondence analysis and hierarchical clustering. Corpora can be imported
    from spreadsheet-like files, directories of raw text files, 'Twitter' queries,
    as well as from 'Dow Jones Factiva', 'LexisNexis', 'Europresse' and 'Alceste' files.",2018-06-22,Milan Bouchet-Valat,https://github.com/nalimilan/R.TeMiS,TRUE,https://github.com/nalimilan/r.temis,46442,17,2020-04-01T16:31:45Z,2731.8823529411766
rco,"Automatically apply different strategies to optimize R code. 
    'rco' functions take R code as input, and returns R code as output.",2020-02-08,Juan Cruz Rodriguez,https://jcrodriguez1989.github.io/rco/,TRUE,https://github.com/jcrodriguez1989/rco,1539,56,2020-05-03T14:33:43Z,27.482142857142858
RColetum,"Get your data (forms, structures, answers) from Coletum 
    <https://coletum.com> to handle and analyse.",2019-11-05,André Smaniotto,https://github.com/geo-sapiens/RColetum,TRUE,https://github.com/geo-sapiens/rcoletum,7710,6,2019-11-11T11:58:03Z,1285
rcoreoa,"Client for the CORE API (<https://core.ac.uk/docs/>).
    CORE (<https://core.ac.uk>) aggregates open access research
    outputs from repositories and journals worldwide and make them
    available to the public.",2018-09-20,Scott Chamberlain,https://github.com/ropensci/rcoreoa,TRUE,https://github.com/ropensci/rcoreoa,9820,12,2020-04-30T18:45:28Z,818.3333333333334
rcosmo,"Handling and Analysing Spherical, 
      HEALPix and Cosmic Microwave Background data on a HEALPix grid.",2020-02-14,Daniel Fryer,https://github.com/frycast/rcosmo,TRUE,https://github.com/frycast/rcosmo,7753,11,2020-02-19T00:24:17Z,704.8181818181819
Rcpp,"The 'Rcpp' package provides R functions as well as C++ classes which
 offer a seamless integration of R and C++. Many R data types and objects can be
 mapped back and forth to C++ equivalents which facilitates both writing of new
 code as well as easier integration of third-party libraries. Documentation
 about 'Rcpp' is provided by several vignettes included in this package, via the
 'Rcpp Gallery' site at <http://gallery.rcpp.org>, the paper by Eddelbuettel and
 Francois (2011, <doi:10.18637/jss.v040.i08>), the book by Eddelbuettel (2013,
 <doi:10.1007/978-1-4614-6868-4>) and the paper by Eddelbuettel and Balamuta (2018,
 <doi:10.1080/00031305.2017.1375990>); see 'citation(""Rcpp"")' for details.",2020-04-09,Dirk Eddelbuettel,"http://www.rcpp.org, http://dirk.eddelbuettel.com/code/rcpp.html,
https://github.com/RcppCore/Rcpp",TRUE,https://github.com/rcppcore/rcpp,36562762,527,2020-06-07T13:50:35Z,69379.055028463
RcppAlgos,"Provides optimized functions and flexible combinatorial iterators
    implemented in C++ with 'Rcpp' for solving problems in combinatorics and
    computational mathematics. Utilizes parallel programming via 'RcppThread'
    for maximal performance. Also makes use of the RMatrix class from the
    'RcppParallel' library. There are combination/permutation functions with
    constraint parameters that allow for generation of all results of a vector
    meeting specific criteria (e.g. generating integer partitions/compositions
    or finding all combinations such that the sum is between two bounds).
    Capable of generating specific combinations/permutations (e.g. retrieve
    only the nth lexicographical result) which sets up nicely for
    parallelization as well as random sampling. Gmp support permits exploration
    where the total number of results is large (e.g. comboSample(10000, 500,
    n = 4)). Additionally, there are several high performance number theoretic
    functions that are useful for problems common in computational mathematics.
    Some of these functions make use of the fast integer division library
    'libdivide'. The primeSieve function is based on the segmented sieve of
    Eratosthenes implementation by Kim Walisch. It is also efficient for large
    numbers by using the cache friendly improvements originally developed by
    Tomás Oliveira. Finally, there is a prime counting function that implements
    Legendre's formula based on the work of Kim Walisch.",2020-03-24,Joseph Wood,"https://github.com/jwood000/RcppAlgos, https://gmplib.org/,
https://github.com/kimwalisch/primesieve, http://libdivide.com,
https://github.com/kimwalisch/primecount,
http://ridiculousfish.com/,
http://sweet.ua.pt/tos/software/prime_sieve.html",TRUE,https://github.com/jwood000/rcppalgos,31210,25,2020-04-26T17:38:03Z,1248.4
RcppArmadillo,"'Armadillo' is a templated C++ linear algebra library (by Conrad
 Sanderson) that aims towards a good balance between speed and ease of use. Integer,
 floating point and complex numbers are supported, as well as a subset of
 trigonometric and statistics functions. Various matrix decompositions are
 provided through optional integration with LAPACK and ATLAS libraries.
 The 'RcppArmadillo' package includes the header files from the templated
 'Armadillo' library. Thus users do not need to install 'Armadillo' itself in
 order to use 'RcppArmadillo'. From release 7.800.0 on, 'Armadillo' is
 licensed under Apache License 2; previous releases were under licensed as
 MPL 2.0 from version 3.800.0 onwards and LGPL-3 prior to that;
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to Armadillo) is licensed under
 the GNU GPL version 2 or later, as is the rest of 'Rcpp'. Note that
 Armadillo requires a fairly recent compiler; for the g++ family at least
 version 4.6.* is required. ",2020-06-09,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.armadillo.html,TRUE,https://github.com/rcppcore/rcpparmadillo,9445484,105,2020-06-09T14:31:10Z,89956.99047619048
RcppBigIntAlgos,"Features the multiple polynomial quadratic sieve (MPQS) algorithm
    for factoring large integers and a vectorized factoring function that
    returns the complete factorization of an integer. The MPQS is based off of
    the seminal work of Carl Pomerance (1984) <doi:10.1007/3-540-39757-4_17>
    along with the modification of multiple polynomials introduced by Peter
    Montgomery and J. Davis as outlined by Robert D. Silverman (1987)
    <doi:10.1090/S0025-5718-1987-0866119-8>. Utilizes the C library
    GMP (GNU Multiple Precision Arithmetic). The Pollard's rho algorithm for
    factoring smaller numbers is the same algorithm used by the factorize
    function in the 'gmp' package.",2020-04-23,Joseph Wood,"https://github.com/jwood000/RcppBigIntAlgos, https://gmplib.org/,
http://mathworld.wolfram.com/QuadraticSieve.html,
http://micsymposium.org/mics_2011_proceedings/mics2011_submission_28.pdf,
https://www.math.colostate.edu/~hulpke/lectures/m400c/quadsievex.pdf,
https://blogs.msdn.microsoft.com/devdev/2006/06/19/factoring-large-numbers-with-quadratic-sieve/",TRUE,https://github.com/jwood000/rcppbigintalgos,636,4,2020-04-16T23:10:16Z,159
RcppCCTZ,"'Rcpp' Access to the 'CCTZ' timezone library is provided. 'CCTZ' is
 a C++ library for translating between absolute and civil times using the rules
 of a time zone. The 'CCTZ' source code, released under the Apache 2.0 License,
 is included in this package. See <https://github.com/google/cctz> for more
 details.",2020-03-18,Dirk Eddelbuettel,https://github.com/eddelbuettel/rcppcctz,TRUE,https://github.com/eddelbuettel/rcppcctz,276953,18,2020-05-12T23:13:49Z,15386.277777777777
RcppClassic,"The 'RcppClassic' package provides a deprecated C++ library which
 facilitates the integration of R and C++. New projects should use the new 'Rcpp'
 'API' in the 'Rcpp' package.",2019-12-09,Dirk Eddelbuettel and Romain Francois,NA,TRUE,https://github.com/eddelbuettel/rcppclassic,38610,1,2019-12-07T20:17:33Z,38610
RcppDate,"'date' is a C++ header library offering extensive date
 and time functionality for the C++11, C++14 and C++17 standards
 written by Howard Hinnant and released under the MIT license. A
 slightly modified version has been accepted (along with 'tz.h') as
 part of C++20. This package regroups all header files from the
 upstream repository by Howard Hinnant so that other R packages can
 use them in their C++ code. At present, few of the types have
 explicit 'Rcpp' wrapper though these may be added as needed.",2020-03-24,Dirk Eddelbuettel,https://github.com/eddelbuettel/rcppdate,TRUE,https://github.com/eddelbuettel/rcppdate,1000,9,2020-03-25T01:23:50Z,111.11111111111111
RcppDynProg,Dynamic Programming implemented in 'Rcpp'.  Includes example partition and out of sample fitting applications.  Also supplies additional custom coders for the 'vtreat' package.,2019-07-24,John Mount,"https://github.com/WinVector/RcppDynProg/,
https://winvector.github.io/RcppDynProg/",TRUE,https://github.com/winvector/rcppdynprog,6466,10,2020-02-02T16:58:55Z,646.6
RcppEigen,"R and 'Eigen' integration using 'Rcpp'.
 'Eigen' is a C++ template library for linear algebra: matrices, vectors,
 numerical solvers and related algorithms.  It supports dense and sparse
 matrices on integer, floating point and complex numbers, decompositions of
 such matrices, and solutions of linear systems. Its performance on many
 algorithms is comparable with some of the best implementations based on
 'Lapack' and level-3 'BLAS'. The 'RcppEigen' package includes the header
 files from the 'Eigen' C++ template library (currently version 3.3.4). Thus
 users do not need to install 'Eigen' itself in order to use 'RcppEigen'.
 Since version 3.1.1, 'Eigen' is licensed under the Mozilla Public License
 (version 2); earlier version were licensed under the GNU LGPL version 3 or
 later. 'RcppEigen' (the 'Rcpp' bindings/bridge to 'Eigen') is licensed under
 the GNU GPL version 2 or later, as is the rest of 'Rcpp'.",2019-11-16,Douglas Bates,http://dirk.eddelbuettel.com/code/rcpp.eigen.html,TRUE,https://github.com/rcppcore/rcppeigen,9211103,54,2020-03-29T15:59:09Z,170575.9814814815
RcppEnsmallen,"'Ensmallen' is a templated C++ mathematical optimization library 
 (by the 'MLPACK' team) that provides a simple set of abstractions for writing an
 objective function to optimize. Provided within are various standard and
 cutting-edge optimizers that include full-batch gradient descent techniques, 
 small-batch techniques, gradient-free optimizers, and constrained optimization.
 The 'RcppEnsmallen' package includes the header files from the 'Ensmallen' library
 and pairs the appropriate header files from 'armadillo' through the 
 'RcppArmadillo' package. Therefore, users do not need to install 'Ensmallen' nor
 'Armadillo' to use 'RcppEnsmallen'. Note that 'Ensmallen' is licensed under 
 3-Clause BSD, 'Armadillo' starting from 7.800.0 is licensed under Apache License 2,
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to 'Armadillo') is licensed under 
 the GNU GPL version 2 or later. Thus, 'RcppEnsmallen' is also licensed under
 similar terms. Note that 'Ensmallen' requires a compiler that supports 
 'C++11' and 'Armadillo' 8.400 or later.",2020-04-24,James Joseph Balamuta,"https://github.com/coatless/rcppensmallen,
https://github.com/mlpack/ensmallen, http://ensmallen.org/",TRUE,https://github.com/coatless/rcppensmallen,9115,22,2020-04-24T05:20:18Z,414.3181818181818
RcppExamples,"Examples for Seamless R and C++ integration
 The 'Rcpp' package contains a C++ library that facilitates the integration of
 R and C++ in various ways. This package provides some usage examples.
 Note that the documentation in this package currently does not cover all the
 features in the package. The site <http://gallery.rcpp.org> regroups a large
 number of examples for 'Rcpp'.",2019-08-24,Dirk Eddelbuettel and Romain Francois,http://dirk.eddelbuettel.com/code/rcpp.examples.html,TRUE,https://github.com/eddelbuettel/rcppexamples,21507,28,2019-08-24T22:38:33Z,768.1071428571429
RcppGetconf,"The 'getconf' command-line tool provided by 'libc' allows
 querying of a large number of system variables. This package provides
 similar functionality.",2018-11-16,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.getconf.html,TRUE,https://github.com/eddelbuettel/rcppgetconf,5587,1,2020-04-28T01:16:13Z,5587
RcppHNSW,"'Hnswlib' is a C++ library for Approximate Nearest Neighbors. This 
 package provides a minimal R interface by relying on the 'Rcpp' package. See 
 <https://github.com/nmslib/hnswlib> for more on 'hnswlib'. 'hnswlib' is 
 released under Version 2.0 of the Apache License.",2019-09-20,James Melville,https://github.com/jlmelville/rcpphnsw,TRUE,https://github.com/jlmelville/rcpphnsw,45257,18,2020-06-06T22:58:02Z,2514.277777777778
RcppHungarian,"Header library and R functions to solve minimum cost bipartite matching problem 
 using Huhn-Munkres algorithm (Hungarian algorithm; <https://en.wikipedia.org/wiki/Hungarian_algorithm>;
 Kuhn (1955) doi:10.1002/nav.3800020109). 
 This is a repackaging of code written by Cong Ma in the GitHub repo <https://github.com/mcximing/hungarian-algorithm-cpp>.",2019-08-02,Justin Silverman,https://github.com/jsilve24/RcppHungarian,TRUE,https://github.com/jsilve24/rcpphungarian,3379,0,2019-08-02T17:22:54Z,NA
RcppMLPACK,"'MLPACK' is an intuitive, fast, scalable C++ machine learning
   library, meant to be a machine learning analog to 'LAPACK'. It
   aims to implement a wide array of machine learning methods
   and function as a Swiss army knife for machine learning
   researchers: 'MLPACK' is available from <http://www.mlpack.org/>;
   sources are included in the package.",2020-04-21,Qiang Kou,"https://github.com/thirdwing/RcppMLPACK1, http://www.mlpack.org/",TRUE,https://github.com/thirdwing/rcppmlpack1,16333,56,2020-04-17T14:13:18Z,291.6607142857143
RcppMsgPack,"'MsgPack' header files are provided for use by R packages, along 
 with the ability to access, create and alter 'MsgPack' objects directly from R.
 'MsgPack' is an efficient binary serialization format. It lets you exchange
 data among multiple languages like 'JSON' but it is faster and smaller.
 Small integers are encoded into a single byte, and typical short strings
 require only one extra byte in addition to the strings themselves. This
 package provides headers from the 'msgpack-c' implementation for C and
 C++(11) for use by R, particularly 'Rcpp'. The included 'msgpack-c' headers
 are licensed under the Boost Software License (Version 1.0); the code added
 by this package as well the R integration are licensed under the GPL (>= 2).
 See the files 'COPYRIGHTS' and 'AUTHORS' for a full list of  copyright holders
 and contributors to 'msgpack-c'.  ",2018-11-18,Travers Ching and Dirk Eddelbuettel; the authors and contributors of MsgPack,NA,TRUE,https://github.com/eddelbuettel/rcppmsgpack,10312,15,2020-05-10T01:29:22Z,687.4666666666667
RcppNumerical,"A collection of open source libraries for numerical computing
    (numerical integration, optimization, etc.) and their integration with
    'Rcpp'.",2019-12-02,Yixuan Qiu,https://github.com/yixuan/RcppNumerical,TRUE,https://github.com/yixuan/rcppnumerical,56035,44,2019-12-02T03:24:58Z,1273.5227272727273
RcppParallel,"High level functions for parallel programming with 'Rcpp'.
    For example, the 'parallelFor()' function can be used to convert the work of
    a standard serial ""for"" loop into a parallel one and the 'parallelReduce()'
    function can be used for accumulating aggregate or other values.",2020-05-06,Kevin Ushey,"http://rcppcore.github.io/RcppParallel,
https://github.com/RcppCore/RcppParallel",TRUE,https://github.com/rcppcore/rcppparallel,1156915,121,2020-06-08T22:16:29Z,9561.280991735537
RcppProgress,"Allows to display a progress bar in the R
    console for long running computations taking place in c++ code,
    and support for interrupting those computations even in multithreaded
    code, typically using OpenMP.",2020-02-06,Karl Forner,https://github.com/kforner/rcpp_progress,TRUE,https://github.com/kforner/rcpp_progress,572194,21,2020-05-29T07:58:38Z,27247.333333333332
RcppStreams,"The 'Streamulus' (template, header-only) library by
 Irit Katriel (at <https://github.com/iritkatriel/streamulus>)
 provides a very powerful yet convenient framework for stream
 processing. This package connects 'Streamulus' to R by providing 
 both the header files and all examples.",2019-02-25,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.streams.html,TRUE,https://github.com/eddelbuettel/rcppstreams,15330,15,2020-05-25T20:36:18Z,1022
RcppThread,"Provides a C++11-style thread class and thread pool that can safely
    be interrupted from R.",2019-10-19,Thomas Nagler,https://github.com/tnagler/RcppThread,TRUE,https://github.com/tnagler/rcppthread,50202,30,2019-10-19T11:17:06Z,1673.4
RcppTOML,"The configuration format defined by 'TOML' (which expands to
 ""Tom's Obvious Markup Language"") specifies an excellent format (described at
 <https://github.com/toml-lang/toml>) suitable for both human editing as well
 as the common uses of a machine-readable format. This package uses 'Rcpp' to
 connect the 'cpptoml' parser written by Chase Geigle (in modern C++11) to R.",2019-06-25,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.toml.html,TRUE,https://github.com/eddelbuettel/rcpptoml,166534,18,2020-05-23T23:57:06Z,9251.888888888889
Rcrawler,"Performs parallel web crawling and web scraping. It is designed to crawl, parse and store web pages to produce data that can be directly used for analysis application. For details see Khalil and Fakir (2017) <DOI:10.1016/j.softx.2017.04.004>.",2018-11-11,Salim Khalil,https://github.com/salimk/Rcrawler/,TRUE,https://github.com/salimk/rcrawler,31431,244,2020-05-22T21:46:25Z,128.8155737704918
rcrossref,"Client for various 'CrossRef' 'APIs', including 'metadata' search
    with their old and newer search 'APIs', get 'citations' in various formats
    (including 'bibtex', 'citeproc-json', 'rdf-xml', etc.), convert 'DOIs'
    to 'PMIDs', and 'vice versa', get citations for 'DOIs', and get links to
    full text of articles when available.",2020-03-19,Scott Chamberlain,"https://docs.ropensci.org/rcrossref,
https://github.com/ropensci/rcrossref",TRUE,https://github.com/ropensci/rcrossref,47491,128,2020-06-08T18:42:00Z,371.0234375
Rcsdp,R interface to the CSDP semidefinite programming library. Installs version 6.1.1 of CSDP from the COIN-OR website if required. An existing installation of CSDP may be used by passing the proper configure arguments to the installation command. See the INSTALL file for further details.,2020-03-09,Hector Corrada Bravo,https://projects.coin-or.org/Csdp/,TRUE,https://github.com/hcorrada/rcsdp,160897,0,2020-03-09T16:32:44Z,NA
Rcssplot,"Provides a means to style plots through cascading style sheets.
    This separates the aesthetics from the data crunching in plots and charts.",2019-12-13,Tomasz Konopka,https://github.com/tkonopka/Rcssplot,TRUE,https://github.com/tkonopka/rcssplot,10055,4,2019-12-13T18:42:25Z,2513.75
RCzechia,Administrative regions and other spatial objects of the Czech Republic.,2020-05-04,Jindra Lacko,https://github.com/jlacko/RCzechia,TRUE,https://github.com/jlacko/rczechia,11273,9,2020-06-04T14:22:00Z,1252.5555555555557
Rd2roxygen,"Functions to convert Rd to 'roxygen' documentation. It can parse an
    Rd file to a list, create the 'roxygen' documentation and update the original
    R script (e.g. the one containing the definition of the function)
    accordingly. This package also provides utilities that can help developers
    build packages using 'roxygen' more easily. The 'formatR' package can be used
    to reformat the R code in the examples sections so that the code will be
    more readable.",2020-04-16,Yihui Xie,https://github.com/yihui/Rd2roxygen,TRUE,https://github.com/yihui/rd2roxygen,33028,21,2020-04-16T04:32:03Z,1572.7619047619048
rdatacite,"Client for the web service methods provided
    by 'DataCite' (<https://www.datacite.org/>), including functions to interface with
    their 'RESTful' search API. The API is backed by 'Elasticsearch', allowing
    expressive queries, including faceting.",2020-03-04,Scott Chamberlain,"https://docs.ropensci.org/rdatacite,
https://github.com/ropensci/rdatacite",TRUE,https://github.com/ropensci/rdatacite,15858,20,2020-03-04T01:04:49Z,792.9
rdataretriever,"Provides an R interface to the Data Retriever
    <http://data-retriever.org/> via the Data Retriever's
    command line interface. The Data Retriever automates the
    tasks of finding, downloading, and cleaning public datasets,
    and then stores them in a local database.",2019-05-25,Daniel McGlinn,https://github.com/ropensci/rdataretriever/,TRUE,https://github.com/ropensci/rdataretriever,11255,28,2020-05-08T13:15:07Z,401.9642857142857
rde,"Allows caching of raw data directly in R code. This allows R
  scripts and R Notebooks to be shared and re-run on a machine without access
  to the original data. Cached data is encoded into an ASCII string that can
  be pasted into R code. When the code is run, the data is automatically
  loaded from the cached version if the original data file is unavailable.
  Works best for small datasets (a few hundred observations).",2018-07-02,Stefan Kloppenborg,https://github.com/kloppen/rde,TRUE,https://github.com/kloppen/rde,6049,1,2019-11-03T22:51:42Z,6049
rDEA,"Data Envelopment Analysis for R, estimating robust DEA scores without and with environmental variables and doing returns-to-scale tests.",2020-02-06,Jaak Simm,https://github.com/jaak-s/rDEA,TRUE,https://github.com/jaak-s/rdea,31831,15,2020-02-06T00:01:25Z,2122.0666666666666
rdefra,Get data from DEFRA's UK-AIR website <https://uk-air.defra.gov.uk/>. It basically scrapes the HTML content.,2020-04-06,Claudia Vitolo,"https://docs.ropensci.org/rdefra,
https://github.com/ropensci/rdefra",TRUE,https://github.com/ropensci/rdefra,10590,10,2020-04-05T13:08:05Z,1059
rdflib,"The Resource Description Framework, or 'RDF' is a widely used
             data representation model that forms the cornerstone of the 
             Semantic Web. 'RDF' represents data as a graph rather than 
             the familiar data table or rectangle of relational databases.
             The 'rdflib' package provides a friendly and concise user interface
             for performing common tasks on 'RDF' data, such as reading, writing
             and converting between the various serializations of 'RDF' data,
             including 'rdfxml', 'turtle', 'nquads', 'ntriples', and 'json-ld';
             creating new 'RDF' graphs, and performing graph queries using 'SPARQL'.
             This package wraps the low level 'redland' R package which
             provides direct bindings to the 'redland' C library.  Additionally,
             the package supports the newer and more developer friendly
             'JSON-LD' format through the 'jsonld' package. The package
             interface takes inspiration from the Python 'rdflib' library.",2020-01-10,Carl Boettiger,https://github.com/ropensci/rdflib,TRUE,https://github.com/ropensci/rdflib,14691,26,2020-01-24T18:54:20Z,565.0384615384615
rdhs,"Provides a client for (1) querying the DHS API for survey indicators
  and metadata (<https://api.dhsprogram.com/#/index.html>), (2) identifying surveys
  and datasets for analysis, (3) downloading survey datasets from the DHS website,
  (4) loading datasets and associate metadata into R, and (5) extracting variables
  and combining datasets for pooled analysis.",2019-03-19,OJ Watson,https://ropensci.github.io/rdhs/,TRUE,https://github.com/ropensci/rdhs,7084,20,2020-03-20T19:34:49Z,354.2
RDieHarder,"The 'RDieHarder' package provides an R interface to 
 the 'DieHarder' suite of random number generators and tests that 
 was developed by Robert G. Brown and David Bauer, extending 
 earlier work by George Marsaglia and others. The 'DieHarder'
 library is included, but if a version is already installed
 it will be used instead.",2019-12-07,Dirk Eddelbuettel,https://github.com/eddelbuettel/rdieharder,TRUE,https://github.com/eddelbuettel/rdieharder,14424,4,2019-12-06T14:03:33Z,3606
Rdimtools,"We provide linear and nonlinear dimension reduction techniques.
	Intrinsic dimension estimation methods for exploratory analysis are also provided.
    For more details on dimensionality techniques, see the paper by
    Ma and Zhu (2013) <doi:10.1111/j.1751-5823.2012.00182.x> if you are interested in
    statistical approach, or Engel, Huttenberger, and Hamann (2012)
    <doi:10.4230/OASIcs.VLUDS.2011.135> for a broader multi-disciplinary overview.",2020-05-22,Kisung You,http://kyoustat.com/Rdimtools,TRUE,https://github.com/kyoustat/rdimtools,17982,12,2020-05-28T02:38:32Z,1498.5
rdist,A common framework for calculating distance matrices.,2020-05-04,Nello Blaser,https://github.com/blasern/rdist,TRUE,https://github.com/blasern/rdist,20462,14,2020-05-04T14:21:40Z,1461.5714285714287
rdiversity,"Provides a framework for the measurement and partitioning of
    the (similarity-sensitive) biodiversity of a metacommunity and its
    constituent subcommunities. Richard Reeve, et al. (2016) 
    <arXiv:1404.6520v3>.",2020-05-20,Sonia Mitchell,https://github.com/boydorr/rdiversity,TRUE,https://github.com/boydorr/rdiversity,9851,2,2020-05-20T08:29:37Z,4925.5
RDML,"Imports real-time thermo cycler (qPCR) data from Real-time PCR
    Data Markup Language (RDML) and transforms to the appropriate formats of
    the 'qpcR' and 'chipPCR' packages. Contains a dendrogram visualization 
    for the structure of RDML object and GUI for RDML editing.",2019-06-25,Konstantin A. Blagodatskikh,https://github.com/kablag/RDML,TRUE,https://github.com/kablag/rdml,19959,15,2020-03-11T11:13:44Z,1330.6
rdoxygen,"Create doxygen documentation for source code in R packages. 
  Includes a RStudio Addin, that allows to trigger the doxygenize process.",2017-05-25,Clemens Schmid,https://github.com/nevrome/rdoxygen,TRUE,https://github.com/nevrome/rdoxygen,7550,9,2019-09-04T13:39:14Z,838.8888888888889
rdpla,"Interact with the Digital Public Library of America
    <https://dp.la> ('DPLA') 'REST' 'API'
    <https://dp.la/info/developers/codex/> from R, including search
    and more.",2017-08-13,Scott Chamberlain,https://github.com/ropensci/rdpla,TRUE,https://github.com/ropensci/rdpla,10984,7,2019-12-09T14:44:32Z,1569.142857142857
rdryad,"Interface to the Dryad ""Solr"" API, their ""OAI-PMH"" service, and
    fetch datasets. Dryad (<http://datadryad.org/>) is a curated host of
    data underlying scientific publications.",2018-06-18,Scott Chamberlain,https://github.com/ropensci/rdryad,TRUE,https://github.com/ropensci/rdryad,26113,22,2020-02-04T16:16:59Z,1186.9545454545455
rdtLite,"Defines functions that can be used to collect provenance as
  an R script executes or during a console session. The output is a text 
  file in PROV-JSON format.",2019-12-04,Barbara Lerner,https://github.com/End-to-end-provenance/rdtLite,TRUE,https://github.com/end-to-end-provenance/rdtlite,6281,1,2019-12-09T19:20:09Z,6281
rdwd,"Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see 
             <https://www.dwd.de/EN/climate_environment/cdc/cdc.html> for more information).
             Choose files with 'selectDWD()', download and process data sets with 'dataDWD()' and 'readDWD()'.",2020-02-18,Berry Boessenkool,https://github.com/brry/rdwd,TRUE,https://github.com/brry/rdwd,16761,26,2020-06-06T23:23:28Z,644.6538461538462
reactable,"Interactive data tables for R, based on the 'React Table'
    JavaScript library. Provides an HTML widget that can be used in 'R Markdown'
    documents and 'Shiny' applications, or viewed from an R console.",2020-05-28,Greg Lin,"https://glin.github.io/reactable,
https://github.com/glin/reactable",TRUE,https://github.com/glin/reactable,10548,211,2020-06-07T22:46:50Z,49.99052132701422
reactlog,"Building interactive web applications with R is incredibly easy
  with 'shiny'. Behind the scenes, 'shiny' builds a reactive graph that can
  quickly become intertwined and difficult to debug. 'reactlog' 
  (Schloerke 2019) <doi:10.5281/zenodo.2591517> provides a visual insight into
  that black box of 'shiny' reactivity by constructing a directed dependency
  graph of the application's reactive state at any time point in a reactive
  recording.",2019-03-22,Barret Schloerke,"https://rstudio.github.io/reactlog/,
https://github.com/rstudio/reactlog,
https://community.rstudio.com/tags/reactlog",TRUE,https://github.com/rstudio/reactlog,48516,60,2020-06-03T17:29:51Z,808.6
reactR,"Make it easy to use 'React' in R with 'htmlwidget' scaffolds,
              helper dependency functions, an embedded 'Babel' 'transpiler',
              and examples.",2020-01-24,Facebook Inc,https://github.com/react-R/reactR,TRUE,https://github.com/react-r/reactr,27197,180,2020-02-01T21:39:08Z,151.09444444444443
read.dbc,Functions for reading and decompressing the DBC (compressed DBF) files. Please note that this is the file format used by the Brazilian Ministry of Health (DATASUS) to publish healthcare datasets. It is not related to the FoxPro or CANdb DBC file formats.,2016-09-16,Daniela Petruzalek,https://github.com/danicat/read.dbc,TRUE,https://github.com/danicat/read.dbc,24439,32,2020-02-03T12:43:37Z,763.71875
readabs,"Downloads, imports, and tidies time series data from the 
    Australian Bureau of Statistics <https://www.abs.gov.au/>.",2019-12-04,Matt Cowgill,https://github.com/mattcowgill/readabs,TRUE,https://github.com/mattcowgill/readabs,11791,28,2020-05-14T00:59:27Z,421.10714285714283
readit,"
    Providing just one primary function, 'readit' uses a set of reasonable
    heuristics to apply the appropriate reader function to the given file path.
    As long as the data file has an extension, and the data is (or can be
    coerced to be) rectangular, readit() can probably read it.",2018-03-13,Ryan Price,https://github.com/ryapric/readit,TRUE,https://github.com/ryapric/readit,7874,25,2020-01-30T19:39:15Z,314.96
readJDX,"Import data written in the JCAMP-DX format. This is an instrument-independent format used in the field of spectroscopy. Examples include IR, NMR, and Raman spectroscopy. See the vignette for background and supported formats.  The official JCAMP-DX site is <http://www.jcamp-dx.org/>.",2019-11-12,Bryan A. Hanson,https://github.com/bryanhanson/readJDX,TRUE,https://github.com/bryanhanson/readjdx,12719,3,2019-11-12T18:54:16Z,4239.666666666667
readr,"The goal of 'readr' is to provide a fast and friendly way to read
    rectangular data (like 'csv', 'tsv', and 'fwf'). It is designed to flexibly
    parse many types of data found in the wild, while still cleanly failing when
    data unexpectedly changes.",2018-12-21,Jim Hester,"http://readr.tidyverse.org, https://github.com/tidyverse/readr",TRUE,https://github.com/tidyverse/readr,13230444,763,2020-05-28T14:02:17Z,17340.031454783748
readsdmx,"Read Statistical Data and Metadata Exchange (SDMX) XML data. 
    This the main transmission format used in official statistics. Data can be imported from
    local SDMX-ML files or a SDMX web-service and will be read in 'as is' into a dataframe object.
    The 'RapidXML' C++ library <http://rapidxml.sourceforge.net> is used to parse the XML data.",2019-10-03,Matthew de Queljoe,https://github.com/mdequeljoe/readsdmx,TRUE,https://github.com/mdequeljoe/readsdmx,5460,3,2019-10-03T14:56:53Z,1820
readstata13,Function to read and write the 'Stata' file format.,2018-05-26,Sebastian Jeworutzki,https://github.com/sjewo/readstata13,TRUE,https://github.com/sjewo/readstata13,776031,34,2019-08-14T21:31:28Z,22824.441176470587
readtext,"Functions for importing and handling text files and formatted text
    files with additional meta-data, such including '.csv', '.tab', '.json', '.xml',
    '.html', '.pdf', '.doc', '.docx', '.rtf', '.xls', '.xlsx', and others.",2020-03-04,Kenneth Benoit,http://github.com/quanteda/readtext,TRUE,https://github.com/quanteda/readtext,163645,83,2020-03-04T06:25:46Z,1971.6265060240964
readtextgrid,"'Praat' is a widely used tool for manipulating, annotating and 
    analyzing speech and acoustic data. It stores annotation data in a 
    format called a 'TextGrid'. This package provides a way to read these 
    files into R.",2020-02-17,Tristan Mahr,https://github.com/tjmahr/readtextgrid,TRUE,https://github.com/tjmahr/readtextgrid,1696,9,2020-02-07T16:05:12Z,188.44444444444446
readthat,"Quickly read contents from files or URLs. Functions provide a simple, consistent, and
    performant interface for reading (all at once or line-by-line) the contents of files or web pages. ",2019-10-22,Michael W. Kearney,https://github.com/mkearney/readthat,TRUE,https://github.com/mkearney/readthat,2586,28,2019-10-18T15:17:06Z,92.35714285714286
readwritesqlite,"Reads and writes data frames to 'SQLite'
    databases while preserving time zones (for POSIXct columns),
    projections (for 'sfc' columns), units (for 'units' columns), levels
    (for factors and ordered factors) and classes for logical, Date and
    'hms' columns.  It also logs changes to tables and provides more
    informative error messages.",2020-04-07,Joe Thorley,https://github.com/poissonconsulting/readwritesqlite,TRUE,https://github.com/poissonconsulting/readwritesqlite,4523,33,2020-06-08T21:22:08Z,137.06060606060606
readxl,"Import excel files into R. Supports '.xls' via the
    embedded 'libxls' C library <https://github.com/libxls/libxls> and
    '.xlsx' via the embedded 'RapidXML' C++ library
    <http://rapidxml.sourceforge.net>.  Works on Windows, Mac and Linux
    without external dependencies.",2019-03-13,Hadley Wickham,"https://readxl.tidyverse.org, https://github.com/tidyverse/readxl",TRUE,https://github.com/tidyverse/readxl,12090550,553,2020-05-28T15:31:09Z,21863.56238698011
readxlsb,Import data from 'Excel' binary (.xlsb) workbooks into R.,2020-04-14,Michael Allen,https://github.com/velofrog/readxlsb,TRUE,https://github.com/velofrog/readxlsb,17002,8,2020-04-13T06:03:59Z,2125.25
rebird,"A programmatic client for the eBird database, including functions
    for searching for bird observations by geographic location (latitude,
    longitude), eBird hotspots, location identifiers, by notable sightings, by
    region, and by taxonomic name.",2019-10-24,Sebastian Pardo,http://github.com/ropensci/rebird,TRUE,https://github.com/ropensci/rebird,50075,45,2020-05-13T15:38:16Z,1112.7777777777778
RECA,"Relevant Component Analysis (RCA) tries to find a linear
    transformation of the feature space such that the effect of irrelevant
    variability is reduced in the transformed space.",2019-05-17,Nan Xiao,"https://nanx.me/RECA/, https://github.com/nanxstats/RECA",TRUE,https://github.com/nanxstats/reca,15890,6,2020-04-23T22:56:49Z,2648.3333333333335
recipes,"An extensible framework to create and preprocess 
    design matrices. Recipes consist of one or more data manipulation 
    and analysis ""steps"". Statistical parameters for the steps can 
    be estimated from an initial data set and then applied to 
    other data sets. The resulting design matrices can then be used 
    as inputs into statistical or machine learning models. ",2020-05-01,Max Kuhn,"https://github.com/tidymodels/recipes,
https://tidymodels.github.io/recipes/",TRUE,https://github.com/tidymodels/recipes,3254852,295,2020-06-09T15:22:32Z,11033.396610169491
recmap,"Provides an interface and a C++ implementation of the RecMap MP2
  construction heuristic (Panse C. (2018) <doi:10.18637/jss.v086.c01>). This algorithm
  draws maps according to a given statistical value (e.g., election results,
  population or epidemiological data). The basic idea of the RecMap algorithm is
  that each map region (e.g., different countries) is represented by a
  rectangle. The area of each rectangle represents the statistical value given
  as input (maintain zero cartographic error). Documentation about the usage
  of the recmap algorithm is provided by a vignette included in this package.",2020-02-20,Christian Panse,NA,TRUE,https://github.com/cpanse/recmap,26609,15,2020-02-20T06:48:11Z,1773.9333333333334
recommenderlab,"Provides a research infrastructure to test and develop
    recommender algorithms including UBCF, IBCF, FunkSVD and association
    rule-based algorithms.",2019-08-27,Michael Hahsler,https://github.com/mhahsler/recommenderlab,TRUE,https://github.com/mhahsler/recommenderlab,145739,155,2019-10-08T17:59:02Z,940.2516129032258
recorder,"A lightweight toolkit to validate new observations when computing
    their predictions with a predictive model. The validation process 
    consists of two steps: (1) record relevant statistics and meta data of the
    variables in the original training data for the predictive model and
    (2) use these data to run a set of basic validation tests on the new set of 
    observations.",2019-06-13,Lars Kjeldgaard,https://github.com/smaakage85/recorder,TRUE,https://github.com/smaakage85/recorder,4181,4,2019-06-13T08:28:49Z,1045.25
reda,"Contains implementations of recurrent event data analysis routines
    including (1) survival and recurrent event data simulation from
    stochastic process point of view by the thinning method
    proposed by Lewis and Shedler (1979) <doi:10.1002/nav.3800260304>
    and the inversion method introduced in Cinlar (1975, ISBN:978-0486497976),
    (2) the mean cumulative function (MCF) estimation by the
    Nelson-Aalen estimator of the cumulative hazard rate function,
    (3) two-sample recurrent event responses comparison with the pseudo-score
    tests proposed by Lawless and Nadeau (1995) <doi:10.2307/1269617>,
    (4) gamma frailty model with spline rate function following
    Fu, et al. (2016) <doi:10.1080/10543406.2014.992524>.",2019-11-03,Wenjie Wang,https://github.com/wenjie2wang/reda,TRUE,https://github.com/wenjie2wang/reda,18527,7,2020-04-16T14:34:08Z,2646.714285714286
ReDaMoR,"The aim of this package is to manipulate relational data models in R.
   It provides functions to create, modify and export data models in json format.
   It also allows importing models created with 'MySQL Workbench' (<https://www.mysql.com/products/workbench/>).
   These functions are accessible through a graphical user interface made with 'shiny'.
   Constraints such as types, keys, uniqueness and mandatory fields are automatically checked and corrected when editing a model.
   Finally, real data can be confronted to a model to check their compatibility.",2020-03-31,Patrice Godard,https://github.com/patzaw/ReDaMoR,TRUE,https://github.com/patzaw/redamor,914,5,2020-03-31T13:45:26Z,182.8
REDCapExporter,"Export all data, including metadata, from a REDCap (Research
    Electronic Data Capture) Project via the REDCap API
    <https://projectredcap.org/wp-content/resources/REDCapTechnicalOverview.pdf>.
    The exported (meta)data will be processed and formatted into a stand alone R
    data package which can be installed and shared between researchers.  Several
    default reports are generated as vignettes in the resulting package.",2020-05-15,Peter DeWitt,https://github.com/dewittpe/REDCapExporter,TRUE,https://github.com/dewittpe/redcapexporter,2871,1,2020-05-15T16:24:08Z,2871
REDCapR,"Encapsulates functions to streamline calls from R to the REDCap
    API.  REDCap (Research Electronic Data CAPture) is a web application for
    building and managing online surveys and databases developed at Vanderbilt
    University.  The Application Programming Interface (API) offers an avenue
    to access and modify data programmatically, improving the capacity for
    literate and reproducible programming.",2020-04-22,Will Beasley,"https://github.com/OuhscBbmc/REDCapR, http://ouhsc.edu/bbmc/,
http://project-redcap.org",TRUE,https://github.com/ouhscbbmc/redcapr,25769,48,2020-05-09T00:05:44Z,536.8541666666666
REddyProc,"Standard and extensible Eddy-Covariance data post-processing 
  (Wutzler et al. (2018) <doi:10.5194/bg-15-5015-2018>)
  includes  
  uStar-filtering, gap-filling, and flux-partitioning.
  The Eddy-Covariance (EC)  micrometeorological technique quantifies continuous 
  exchange fluxes of gases, energy, and momentum between an ecosystem and the atmosphere.
  It is important for understanding ecosystem dynamics and upscaling exchange fluxes.
  (Aubinet et al. (2012) <doi:10.1007/978-94-007-2351-1>).
  This package inputs pre-processed (half-)hourly data and supports further processing. 
  First, a quality-check and filtering is performed based on the relationship between 
  measured flux and friction
  velocity (uStar) to discard biased data 
  (Papale et al. (2006) <doi:10.5194/bg-3-571-2006>).
  Second, gaps in the data are filled based on information from environmental conditions
  (Reichstein et al. (2005) <doi:10.1111/j.1365-2486.2005.001002.x>).
  Third, the net flux of carbon dioxide is partitioned
  into its gross fluxes in and out of the ecosystem by night-time 
  based and day-time based approaches
  (Lasslop et al. (2010) <doi:10.1111/j.1365-2486.2009.02041.x>).",2020-03-18,Thomas Wutzler,"https://www.bgc-jena.mpg.de/bgi/index.php/Services/REddyProcWeb,
https://github.com/bgctw/REddyProc",TRUE,https://github.com/bgctw/reddyproc,15210,25,2020-02-07T12:03:08Z,608.4
redist,"Enables researchers to sample redistricting plans from a pre-
    specified target distribution using a Markov Chain Monte Carlo algorithm.
    The package allows for the implementation of various constraints in the
    redistricting process such as geographic compactness and population parity
    requirements. The algorithm also can be used in combination with efficient
    simulation methods such as simulated and parallel tempering algorithms. Tools
    for analysis such as inverse probability reweighting and plotting functionality
    are included. The package implements methods described in Fifield, Higgins, Imai
    and Tarr (2016) ``A New Automated Redistricting Simulator Using Markov Chain
    Monte Carlo,'' working paper available at
    <https://imai.fas.harvard.edu/research/files/redist.pdf>.",2018-12-15,Ben Fifield,NA,TRUE,https://github.com/kosukeimai/redist,16996,12,2019-10-15T13:09:24Z,1416.3333333333333
redlistr,"A toolbox created by members of the International Union for
    Conservation of Nature (IUCN) Red List of Ecosystems Committee for
    Scientific Standards. Primarily, it is a set of tools suitable
    for calculating the metrics required for making assessments of species and
    ecosystems against the IUCN Red List of Threatened Species and the IUCN Red
    List of Ecosystems categories and criteria. See the IUCN website for
    detailed guidelines, the criteria, publications and other information.",2019-07-11,Calvin Lee,https://github.com/red-list-ecosystem/redlistr,TRUE,https://github.com/red-list-ecosystem/redlistr,9442,15,2019-07-12T03:13:55Z,629.4666666666667
RefManageR,"Provides tools for importing and working with bibliographic
    references. It greatly enhances the 'bibentry' class by providing a class
    'BibEntry' which stores 'BibTeX' and 'BibLaTeX' references, supports 'UTF-8'
    encoding, and can be easily searched by any field, by date ranges, and by
    various formats for name lists (author by last names, translator by full names,
    etc.). Entries can be updated, combined, sorted, printed in a number of styles,
    and exported. 'BibTeX' and 'BibLaTeX' '.bib' files can be read into 'R' and
    converted to 'BibEntry' objects. Interfaces to 'NCBI Entrez', 'CrossRef', and
    'Zotero' are provided for importing references and references can be created
    from locally stored 'PDF' files using 'Poppler'. Includes functions for citing
    and generating a bibliography with hyperlinks for documents prepared with
    'RMarkdown' or 'RHTML'.",2019-04-03,Mathew W. McLean,https://github.com/ropensci/RefManageR/,TRUE,https://github.com/ropensci/refmanager,166167,81,2020-01-29T00:07:26Z,2051.4444444444443
regions,"Validating sub-national statistical typologies, re-coding across 
    standard typologies of sub-national statistics, and making valid aggregate
    level imputation, re-aggregation, re-weighting and projection down to 
    lower hierarchical levels to create meaningful data panels and time series.",2020-06-04,Daniel Antal,https://regions.danielantal.eu/,TRUE,https://github.com/ropengov/regions,0,0,2020-06-03T18:14:13Z,NA
regmedint,"'R' re-implementation of the regression-based causal mediation analysis with a treatment-mediator interaction term, as originally implemented in the 'SAS' macro by Valeri and VanderWeele (2013) <doi:10.1037/a0031034> and Valeri and VanderWeele (2015) <doi:10.1097/EDE.0000000000000253>. Linear and logistic models are supported for the mediator model. Linear, logistic, loglinear, Poisson, negative binomial, Cox, and accelerated failure time (exponential and Weibull) models are supported for the outcome model.",2020-05-11,Kazuki Yoshida,https://kaz-yos.github.io/regmedint/,TRUE,https://github.com/kaz-yos/regmedint,398,4,2020-05-07T10:46:25Z,99.5
regnet,"Network-based regularization has achieved success in variable selection for 
    high-dimensional biological data due to its ability to incorporate correlations among 
    genomic features. This package provides procedures of network-based variable selection 
    for generalized linear models (Ren et al. (2017) <doi:10.1186/s12863-017-0495-5> and 
    Ren et al. (2019) <doi:10.1002/gepi.22194>). Two recent additions are the robust network 
    regularization for the survival response and the network regularization for continuous 
    response. Functions for other regularization methods will be included in the forthcoming 
    upgraded versions. ",2019-06-08,Jie Ren,https://github.com/jrhub/regnet,TRUE,https://github.com/jrhub/regnet,10875,4,2020-06-04T23:28:52Z,2718.75
regrrr,"Compiling regression results into a publishable format, conducting post-hoc hypothesis testing, and plotting moderating effects (the effect of X on Y becomes stronger/weaker as Z increases).",2020-02-02,Rui K. Yang,NA,TRUE,https://github.com/raykyang/regrrr,4757,1,2020-02-02T21:13:42Z,4757
RegSDC,"Implementation of the methods described in the paper with the above title: Langsrud, Ø. (2019) <doi:10.1007/s11222-018-9848-9>. Open view-only version at <https://rdcu.be/bfeWQ>. The package can be used to generate synthetic or hybrid continuous microdata, and the relationship to the original data can be controlled in several ways. A function for replacing suppressed tabular cell frequencies with decimal numbers is included.",2020-05-08,Øyvind Langsrud,https://github.com/olangsrud/RegSDC,TRUE,https://github.com/olangsrud/regsdc,5330,0,2020-05-08T12:53:46Z,NA
regtools,"Tools for linear, nonlinear and nonparametric regression
             and classification.  Novel graphical methods for assessment 
             of parametric models using nonparametric methods. One 
             vs. All and All vs. All multiclass classification, optional
             class probabilities adjustment.  Nonparametric regression 
             (k-NN) for general dimension, local-linear option.  Nonlinear 
             regression with Eickert-White method for dealing with 
             heteroscedasticity.  Utilities for converting time series
             to rectangular form.  Utilities for conversion between
             factors and indicator variables.  Some code related to
             ""Statistical Regression and Classification: from Linear
             Models to Machine Learning"", N. Matloff, 2017, CRC,
             ISBN 9781498710916.",2019-08-25,Norm Matloff,https://github.com/matloff/regtools,TRUE,https://github.com/matloff/regtools,16647,81,2020-06-09T06:34:04Z,205.5185185185185
ReIns,"Functions from the book ""Reinsurance: Actuarial and Statistical Aspects"" (2017) by Hansjoerg Albrecher, Jan Beirlant and Jef Teugels <http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470772689.html>.",2020-05-17,Tom Reynkens,"http://www.hec.unil.ch/halbrech_files/reinsurance.html,
https://github.com/TReynkens/ReIns",TRUE,https://github.com/treynkens/reins,22674,5,2020-05-16T07:58:32Z,4534.8
remoter,"A set of utilities for client/server computing with R, controlling
    a remote R session (the server) from a local one (the client).  Simply set
    up a server (see package vignette for more details) and connect to it from
    your local R session ('RStudio', terminal, etc).  The client/server
    framework is a custom 'REPL' and runs entirely in your R session without the
    need for installing a custom environment on your system.  Network
    communication is handled by the 'ZeroMQ' library by way of the 'pbdZMQ'
    package.",2018-01-05,Drew Schmidt,https://github.com/RBigData/remoter,TRUE,https://github.com/rbigdata/remoter,15193,59,2019-10-26T14:04:52Z,257.50847457627117
REndo,"Fits linear models with endogenous regressor using latent instrumental variable approaches. 
    The methods included in the package are Lewbel's (1997) <doi:10.2307/2171884> higher moments approach as well as 
    Lewbel's (2012) <doi:10.1080/07350015.2012.643126> heteroscedasticity approach, Park and Gupta's (2012) <doi:10.1287/mksc.1120.0718> joint estimation method 
    that uses Gaussian copula and Kim and Frees's (2007) <doi:10.1007/s11336-007-9008-1> multilevel generalized
    method of moment approach that deals with endogeneity in a multilevel setting.
    These are statistical techniques to address the endogeneity problem where no external instrumental variables are needed.
    Note that with version 2.0.0 sweeping changes were introduced which greatly improve functionality and usability but break backwards compatibility.",2020-05-24,Raluca Gui,https://github.com/mmeierer/REndo,TRUE,https://github.com/mmeierer/rendo,21645,4,2020-05-03T19:23:20Z,5411.25
rentrez,"Provides an R interface to the NCBI's 'EUtils' API, 
    allowing users to search databases like 'GenBank' 
    <https://www.ncbi.nlm.nih.gov/genbank/> and 'PubMed' 
    <https://www.ncbi.nlm.nih.gov/pubmed/>, process the 
    results of those searches and pull data into their R sessions.",2019-05-02,David Winter,http://github.com/ropensci/rentrez,TRUE,https://github.com/ropensci/rentrez,179110,137,2019-11-03T13:44:16Z,1307.3722627737227
renv,"A dependency management toolkit for R. Using 'renv', you can create
    and manage project-local R libraries, save the state of these libraries to
    a 'lockfile', and later restore your library as required. Together, these
    tools can help make your projects more isolated, portable, and reproducible.",2020-05-06,Kevin Ushey,https://rstudio.github.io/renv,TRUE,https://github.com/rstudio/renv,81701,382,2020-06-08T21:07:45Z,213.87696335078533
repeated,"Various functions to fit models for non-normal repeated
    measurements, such as Binary Random Effects Models with Two Levels of Nesting,
    Bivariate Beta-binomial Regression Models, Marginal Bivariate Binomial Regression Models,
    Cormack capture-recapture models, Continuous-time Hidden Markov Chain Models, 
    Discrete-time Hidden Markov Chain Models,
    Changepoint Location Models using a Continuous-time Two-state Hidden Markov Chain,
    generalized nonlinear autoregression models, multivariate Gaussian copula models,
    generalized non-linear mixed models with one random effect,  
    generalized non-linear mixed models using h-likelihood for one random effect, 
    Repeated Measurements Models for Counts with Frailty or Serial Dependence,
    Repeated Measurements Models for Continuous Variables with Frailty or Serial Dependence,
    Ordinal Random Effects Models with Dropouts, marginal homogeneity models for square
    contingency tables, correlated negative binomial models with Kalman update.
    References include Lindey's text books, 
    JK Lindsey (2001) <isbn-10:0198508123> and JK Lindsey (1999) <isbn-10:0198505590>.",2019-07-13,Bruce Swihart,http://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/repeated,12944,0,2019-07-12T18:16:11Z,NA
REPLesentR,"Create presentations and display them inside the R 'REPL'
    (Read-Eval-Print loop), aka the R console. Presentations can be written in
    'RMarkdown' or any other text format. A set of convenient navigation options
    as well as code evaluation during a presentation is provided. It is great
    for tech talks with live coding examples and tutorials. While this is not a
    replacement for standard presentation formats, it's old-school looks might
    just be what sets it apart. This project has been inspired by the
    'REPLesent' project for presentations in the 'Scala' 'REPL'.",2019-11-26,Sebastian Warnholz,NA,TRUE,https://github.com/wahani/replesentr,5894,4,2019-11-26T09:27:26Z,1473.5
replicateBE,"Performs comparative bioavailability calculations for Average Bioequivalence with
  Expanding Limits (ABEL). Implemented are 'Method A' and 'Method B' and the detection of outliers.
  If the design allows, assessment of the empiric Type I Error and iteratively adjusting alpha to
  control the consumer risk.
  Average Bioequivalence - optionally with a tighter (narrow therapeutic index drugs) or wider
  acceptance range (Gulf Cooperation Council, South Africa: Cmax) - is implemented as well.",2020-04-09,Helmut Schütz,https://github.com/Helmut01/replicateBE,TRUE,https://github.com/helmut01/replicatebe,5195,4,2020-04-09T13:28:23Z,1298.75
repr,"String and binary representations of objects for several formats /
    mime types.",2020-01-28,Philipp Angerer,https://github.com/IRkernel/repr/,TRUE,https://github.com/irkernel/repr,775342,40,2020-01-28T11:48:21Z,19383.55
represtools,"Reproducible research tools automates the creation of an analysis directory structure and work flow. There are R markdown
  skeletons which encapsulate typical analytic work flow steps. Functions will create appropriate modules which may
  pass data from one step to another.",2019-10-03,Brian Fannin,https://pirategrunt.com/represtools/,TRUE,https://github.com/pirategrunt/represtools,11363,17,2019-10-03T14:58:29Z,668.4117647058823
reproducible,"Collection of high-level, robust, machine- and OS-independent tools
    for making deeply reproducible and reusable content in R.
    The three workhorse functions are Cache, prepInputs, and Require; 
    these allow for nested caching, robust to environments, and objects with
    environments (like functions), and data retrieval and processing, and 
    package handling in continuous workflow environments. In all cases,
    efforts are made to make the first and subsequent calls of functions have 
    the same result, but vastly faster at subsequent times by way of checksums
    and digesting. Several features are still under active development, including
    cloud storage of cached objects, allowing for sharing between users.",2020-05-20,Eliot J B McIntire,"https://reproducible.predictiveecology.org,
https://github.com/PredictiveEcology/reproducible",TRUE,https://github.com/predictiveecology/reproducible,34795,24,2020-05-19T16:21:44Z,1449.7916666666667
reproj,"Transform coordinates from a specified source to a specified 
 target map projection. This uses the 'PROJ' library directly, by wrapping the 
 'PROJ' package (if functional), otherwise the 'proj4' package. The 'reproj()' 
 function is generic, methods may be added to remove the need for an explicit 
 source definition. If 'proj4' is in use 'reproj()' handles the requirement for 
 conversion of angular units where necessary. This is for use primarily to 
 transform generic data formats and direct leverage of the underlying
 'PROJ' library. (There are transformations that aren't possible with 'PROJ' and
 that are provided by the 'GDAL' library, a limitation which users of this 
 package should be aware of.) The 'PROJ' library is available at 
 <https://proj.org/>.  ",2020-04-15,Michael D. Sumner,https://github.com/hypertidy/reproj/,TRUE,https://github.com/hypertidy/reproj,13374,1,2020-05-13T11:12:41Z,13374
repurrrsive,"Recursive lists in the form of R objects, 'JSON',
    and 'XML', for use in teaching and examples. Examples include color
    palettes, Game of Thrones characters, 'GitHub' users and repositories,
    music collections, and entities from the Star Wars universe. Data from
    the 'gapminder' package is also included, as a simple data frame and
    in nested and split forms.",2019-07-15,Jennifer Bryan,https://github.com/jennybc/repurrrsive,TRUE,https://github.com/jennybc/repurrrsive,61975,110,2019-07-15T20:30:52Z,563.4090909090909
Require,"A single key function, 'Require' that wraps 'install.packages',
    'remotes::install_github', 'versions::install.versions', and 'base::require'
    that allows for reproducible workflows. As with other functions in a
    reproducible workflow, this package emphasizes functions that return the 
    same result whether it is the first or subsequent times running the function.",2020-06-05,Eliot J B McIntire,"https://Require.predictiveecology.org,
https://github.com/PredictiveEcology/Require",TRUE,https://github.com/predictiveecology/require,0,0,2020-06-02T20:36:05Z,NA
rerddap,"General purpose R client for 'ERDDAP' servers. Includes
    functions to search for 'datasets', get summary information on
    'datasets', and fetch 'datasets', in either 'csv' or 'netCDF' format.
    'ERDDAP' information: 
    <https://upwell.pfeg.noaa.gov/erddap/information.html>.",2019-07-20,Scott Chamberlain,https://github.com/ropensci/rerddap,TRUE,https://github.com/ropensci/rerddap,22192,30,2020-05-15T14:33:59Z,739.7333333333333
rerddapXtracto,"Contains three functions that access
    environmental data from any 'ERDDAP' data web service. The rxtracto() function extracts
    data along a trajectory for a given ""radius"" around the point. The
    rxtracto_3D() function extracts data in a box. The rxtractogon() function
    extracts data in a polygon. All of those three function use the 'rerddap' package
    to extract the data, and should work with any 'ERDDAP' server.
    There are also two functions, plotBBox() and plotTrack() that use the 'plotdap'
    package to simplify the creation of maps of the data.",2020-02-17,Roy Mendelssohn,https://github.com/rmendels/rerddapXtracto,TRUE,https://github.com/rmendels/rerddapxtracto,6750,7,2020-02-17T20:16:44Z,964.2857142857143
reReg,"A collection of regression models for recurrent event process and failure time data. Available methods include these from Xu et al. (2017) <doi:10.1080/01621459.2016.1173557>, Lin et al. (2000) <doi:10.1111/1467-9868.00259>, Wang et al. (2001) <doi:10.1198/016214501753209031>, Ghosh and Lin (2003) <doi:10.1111/j.0006-341X.2003.00102.x>, and Huang and Wang (2004) <doi:10.1198/016214504000001033>.",2019-12-01,Sy Han (Steven) Chiou,http://github.com/stc04003/reReg,TRUE,https://github.com/stc04003/rereg,20963,4,2020-06-09T19:20:06Z,5240.75
rerf,"R-RerF (aka Randomer Forest (RerF) or Random Projection
  Forests) is an algorithm developed by Tomita (2016) <arXiv:1506.03410v2>
  which is similar to Random Forest - Random Combination (Forest-RC)
  developed by Breiman (2001) <doi:10.1023/A:1010933404324>.  Random
  Forests create axis-parallel, or orthogonal trees. That is, the feature
  space is recursively split along directions parallel to the axes of the
  feature space. Thus, in cases in which the classes seem inseparable
  along any single dimension, Random Forests may be suboptimal.  To
  address this, Breiman also proposed and characterized Forest-RC, which
  uses linear combinations of coordinates rather than individual
  coordinates, to split along.  This package, 'rerf', implements RerF
  which is similar to Forest-RC.  The difference between the two
  algorithms is where the random linear combinations occur: Forest-RC
  combines features at the per tree level whereas RerF takes linear
  combinations of coordinates at every node in the tree.",2019-03-15,Jesse Patsolic [ctb,https://github.com/neurodata/R-RerF,TRUE,https://github.com/neurodata/r-rerf,10743,59,2019-12-03T18:21:58Z,182.08474576271186
resampledata,"Package of data sets from ""Mathematical Statistics
    with Resampling in R"" (1st Ed. 2011, 2nd Ed. 2018) by Laura Chihara and Tim Hesterberg.",2019-08-30,Albert Y. Kim,https://github.com/rudeboybert/resampledata,TRUE,https://github.com/rudeboybert/resampledata,20079,11,2019-08-30T11:11:31Z,1825.3636363636363
reshape2,"Flexibly restructure and aggregate data using just two
    functions: melt and 'dcast' (or 'acast').",2020-04-09,Hadley Wickham,https://github.com/hadley/reshape,TRUE,https://github.com/hadley/reshape,20104670,192,2020-04-09T16:50:36Z,104711.82291666667
resourcer,"A resource represents some data or a computation unit. It is 
    described by a URL and credentials. This package proposes a Resource model
    with ""resolver"" and ""client"" classes to facilitate the access and the usage of the 
    resources.",2020-05-15,Yannick Marcon,NA,TRUE,https://github.com/obiba/resourcer,1198,0,2020-05-25T19:30:00Z,NA
ResourceSelection,"Resource Selection (Probability) Functions
  for use-availability wildlife data
  based on weighted distributions as described in
  Lele and Keim (2006) <doi:10.1890/0012-9658(2006)87%5B3021:WDAEOR%5D2.0.CO;2>,
  Lele (2009) <doi:10.2193/2007-535>,
  and Solymos & Lele (2016) <doi:10.1111/2041-210X.12432>.",2019-07-22,Peter Solymos,https://github.com/psolymos/ResourceSelection,TRUE,https://github.com/psolymos/resourceselection,171804,4,2019-07-22T14:33:57Z,42951
restatapi,"Eurostat is the statistical office of the European Union and provides high quality statistics for Europe.
             Large set of the data is disseminated through the Eurostat database (<https://ec.europa.eu/eurostat/data/database>). 
             The tools are using the REST API with the Statistical Data and Metadata eXchange (SDMX <https://sdmx.org>) Web Services 
             (<https://ec.europa.eu/eurostat/web/sdmx-web-services/about-this-service>) to search and download data from 
             the Eurostat database using the SDMX standard. ",2020-05-29,Mátyás Mészáros,https://github.com/eurostat/restatapi,TRUE,https://github.com/eurostat/restatapi,8076,3,2020-06-02T15:29:54Z,2692
restorepoint,"Debugging with restore points instead of break points. A restore
    point stores all local variables when called inside a function. The stored
    values can later be retrieved and evaluated in a modified R console that
    replicates the function's environment. To debug step by step, one can simply
    copy & paste the function body from the R script. Particularly convenient
    in combination with ""RStudio"". See the ""Github"" page inst/vignettes for a
    tutorial.",2019-01-02,Sebastian Kranz,https://github.com/skranz/restorepoint,TRUE,https://github.com/skranz/restorepoint,12499,13,2019-12-02T12:25:57Z,961.4615384615385
RestRserve,"
  Allows to easily create high-performance full featured HTTP APIs from R
  functions. Provides high-level classes such as 'Request', 'Response',
  'Application', 'Middleware' in order to streamline server side
  application development. Out of the box allows to serve requests using
  'Rserve' package, but flexible enough to integrate with other HTTP servers
  such as 'httpuv'.",2020-04-12,Dmitriy Selivanov,"http://restrserve.org, https://github.com/rexyai/RestRserve",TRUE,https://github.com/rexyai/restrserve,1764,153,2020-04-12T05:34:39Z,11.529411764705882
reticulate,"Interface to 'Python' modules, classes, and functions. When calling
    into 'Python', R data types are automatically converted to their equivalent 'Python'
    types. When values are returned from 'Python' to R they are converted back to R
    types. Compatible with all versions of 'Python' >= 2.7.",2020-05-27,Kevin Ushey,https://github.com/rstudio/reticulate,TRUE,https://github.com/rstudio/reticulate,2233658,1104,2020-06-09T18:45:19Z,2023.2409420289855
retistruct,"Reconstructs retinae by morphing a flat surface with cuts (a
    dissected flat-mount retina) onto a curvilinear surface (the standard retinal
    shape). It can estimate the position of a point on the intact adult retina
    to within 8 degrees of arc (3.6% of nasotemporal axis). The coordinates in
    reconstructed retinae can be transformed to visuotopic coordinates.",2020-04-04,David C. Sterratt,http://davidcsterratt.github.io/retistruct/,TRUE,https://github.com/davidcsterratt/retistruct,17222,5,2020-04-04T09:40:44Z,3444.4
retrosheet,"A collection of tools to import and structure the (currently) single-season
    event, game-log, roster, and schedule data available from <http://www.retrosheet.org>.
    In particular, the event (a.k.a. play-by-play) files can be especially difficult to parse.
    This package does the parsing on those files, returning the requested data in the most
    practical R structure to use for sabermetric or other analyses.",2020-05-15,Colin Douglas,http://github.com/colindouglas/retrosheet,TRUE,https://github.com/colindouglas/retrosheet,9137,0,2020-05-19T12:37:27Z,NA
retry,Provide simple mechanism to repeatedly evaluate an expression until either it succeeds or timeout exceeded. It is useful in situations that random failures could happen.,2020-04-23,Randy Lai,https://github.com/randy3k/retry,TRUE,https://github.com/randy3k/retry,644,3,2020-05-06T20:35:09Z,214.66666666666666
revdbayes,"Provides functions for the Bayesian analysis of extreme value
    models.  The 'rust' package <https://cran.r-project.org/package=rust> is
    used to simulate a random sample from the required posterior distribution.
    The functionality of 'revdbayes' is similar to the 'evdbayes' package
    <https://cran.r-project.org/package=evdbayes>, which uses Markov Chain
    Monte Carlo ('MCMC') methods for posterior simulation.  Also provided
    are functions for making inferences about the extremal index, using 
    the K-gaps model of Suveges and Davison (2010) <doi:10.1214/09-AOAS292>.
    Also provided are d,p,q,r functions for the Generalised Extreme Value 
    ('GEV') and Generalised Pareto ('GP') distributions that deal 
    appropriately with cases where the shape parameter is very close to zero.",2019-12-02,Paul J. Northrop,"https://paulnorthrop.github.io/revdbayes/,
http://github.com/paulnorthrop/revdbayes",TRUE,https://github.com/paulnorthrop/revdbayes,36768,4,2020-01-13T11:43:23Z,9192
revealjs,"R Markdown format for 'reveal.js' presentations, a framework 
  for easily creating beautiful presentations using HTML.",2017-03-13,Hakim El Hattab,https://github.com/rstudio/revealjs,TRUE,https://github.com/rstudio/revealjs,49909,236,2020-03-02T12:07:36Z,211.47881355932202
revss,"Implements the estimation techniques described in Rousseeuw &
    Verboven (2002) <doi:10.1016/S0167-9473(02)00078-6> for the location and
    scale of very small samples.",2020-06-03,Avraham Adler,https://github.com/aadler/revss,TRUE,https://github.com/aadler/revss,0,1,2020-05-31T17:24:04Z,0
revtools,"Researchers commonly need to summarize scientific information, a process known as 'evidence synthesis'. The first stage of a synthesis process (such as a systematic review or meta-analysis) is to download a list of references from academic search engines such as 'Web of Knowledge' or 'Scopus'. The traditional approach to systematic review is then to sort these data manually, first by locating and removing duplicated entries, and then screening to remove irrelevant content by viewing titles and abstracts (in that order). 'revtools' provides interfaces for each of these tasks. An alternative approach, however, is to draw on tools from machine learning to visualise patterns in the corpus. In this case, you can use 'revtools' to render ordinations of text drawn from article titles, keywords and abstracts, and interactively select or exclude individual references, words or topics.",2019-12-17,Martin J. Westgate,https://revtools.net,TRUE,https://github.com/mjwestgate/revtools,11779,26,2020-01-10T02:27:18Z,453.03846153846155
rex,A friendly interface for the construction of regular expressions.,2020-04-21,Jim Hester,https://github.com/kevinushey/rex,TRUE,https://github.com/kevinushey/rex,3960323,212,2020-04-21T17:14:30Z,18680.76886792453
Rfacebook,Provides an interface to the Facebook API.,2017-05-25,Pablo Barbera,https://github.com/pablobarbera/Rfacebook,TRUE,https://github.com/pablobarbera/rfacebook,148075,339,2020-05-22T15:41:02Z,436.7994100294985
rfacebookstat,"Load data by campaigns, ads, ad sets and insights, ad account and business manager 
    from Facebook Marketing API into R. For more details see official documents by Facebook 
    Marketing API <https://developers.facebook.com/docs/marketing-apis/>.",2020-05-29,Alexey Seleznev,"http://selesnow.github.io/rfacebookstat,
https://www.youtube.com/playlist?list=PLD2LDq8edf4pItOb-vZTG5AXZK2niJ8_R",TRUE,https://github.com/selesnow/rfacebookstat,10046,16,2020-05-29T13:18:39Z,627.875
Rfast,"A collection of fast (utility) functions for data analysis. Column- and row- wise means, medians, variances, minimums, maximums, many t, F and G-square tests, many regressions (normal, logistic, Poisson), are some of the many fast functions. References: a) Tsagris M., Papadakis M. (2018). Taking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1 <doi:10.7287/peerj.preprints.26605v1>. b) Tsagris M. and Papadakis M. (2018). Forward regression in R: from the extreme slow to the extreme fast. Journal of Data Science, 16(4): 771--780. <doi:10.6339/JDS.201810_16(4).00006>. ",2020-03-08,Manos Papadakis,https://github.com/RfastOfficial/Rfast,TRUE,https://github.com/rfastofficial/rfast,110641,33,2020-06-03T08:37:47Z,3352.757575757576
Rfast2,"A collection of fast statistical and utility functions for data analysis. Functions for regression, maximum likelihood, column-wise statistics and many more have been included. C++ has been utilized to speed up the functions.",2019-12-16,Manos Papadakis,https://github.com/RfastOfficial/Rfast2,TRUE,https://github.com/rfastofficial/rfast2,12915,6,2020-05-27T05:10:07Z,2152.5
RfEmpImp,"Functions for methods for multiple imputation using chained random
    forests. Implemented algorithms can handle missing data in both continuous
    and categorical variables by using prediction-based or node-based
    conditional distributions constructed using random forests. For
    prediction-based imputation, the method based on the empirical distribution
    of out-of-bag prediction errors of random forests and the method based on
    normality assumption are provided. For node-based imputation, the method
    based on the conditional distribution formed by predicting nodes of random
    forests and the method based on measures of proximities of random forests
    are provided. More details of the statistical methods can be found in
    Hong et al. (2020) <arXiv:2004.14823>.",2020-05-16,Shangzhi Hong,https://github.com/shangzhi-hong/RfEmpImp,TRUE,https://github.com/shangzhi-hong/rfempimp,324,3,2020-06-06T13:01:54Z,108
rfigshare,"An interface to 'figshare' (http://figshare.com), a scientific repository to archive and assign 'DOIs' to data, software, figures, and more.",2015-06-15,Carl Boettiger,https://github.com/ropensci/rfigshare,TRUE,https://github.com/ropensci/rfigshare,27320,40,2019-12-09T16:12:46Z,683
rfinterval,"An integrated package for constructing random forest prediction intervals using a fast implementation package 'ranger'. This package can apply the following three methods described in Haozhe Zhang, Joshua Zimmerman, Dan Nettleton, and Daniel J. Nordman (2019) <doi:10.1080/00031305.2019.1585288>: the out-of-bag prediction interval, the split conformal method, and the quantile regression forest.",2019-07-18,Haozhe Zhang,http://github.com/haozhestat/rfinterval,TRUE,https://github.com/haozhestat/rfinterval,3569,3,2019-07-19T17:57:02Z,1189.6666666666667
rfishbase,"A programmatic interface to <http://www.fishbase.org>, re-written
    based on an accompanying 'RESTful' API. Access tables describing over 30,000
    species of fish, their biology, ecology, morphology, and more. This package also
    supports experimental access to <http://www.sealifebase.org> data, which contains
    nearly 200,000 species records for all types of aquatic life not covered by
    'FishBase.'",2019-06-27,Carl Boettiger,https://github.com/ropensci/rfishbase,TRUE,https://github.com/ropensci/rfishbase,33656,59,2020-06-03T15:23:46Z,570.4406779661017
RFishBC,"Helps fisheries scientists collect measurements from calcified
    structures and back-calculate estimated lengths at previous ages using
    standard procedures and models. This is intended to replace much of the
    functionality provided by the now out-dated 'fishBC' software
    (<https://fisheries.org/bookstore/all-titles/software/70317/>).",2019-12-12,Derek Ogle,http://derekogle.com/RFishBC,TRUE,https://github.com/droglenc/rfishbc,6630,3,2020-03-17T22:56:32Z,2210
rfisheries,"A programmatic interface to 'openfisheries.org'. This package is
    part of the 'rOpenSci' suite (http://ropensci.org).",2016-02-19,Karthik Ram,http://www.github.com/ropensci/rfisheries,TRUE,https://github.com/ropensci/rfisheries,16978,16,2019-12-09T21:25:44Z,1061.125
rfishnet2,"Provides data processing and summarization of data from FishNet2.net
  in text and graphical outputs. Allows efficient filtering of information and
  data cleaning.",2019-12-13,Kennedy Dorsey,https://github.com/kdors/rfishnet2,TRUE,https://github.com/kdors/rfishnet2,1674,0,2020-05-18T14:23:24Z,NA
rflights,"Query plane tickets, from several airlines, using the 'Kiwi' API
    (similar to 'Google Flights').
    The API is documented at <https://docs.kiwi.com/>.",2019-09-18,Juan Cruz Rodriguez,https://github.com/jcrodriguez1989/rflights/,TRUE,https://github.com/jcrodriguez1989/rflights,4257,4,2020-01-19T17:50:00Z,1064.25
rfm,"Tools for RFM (recency, frequency and monetary value) analysis. 
    Generate RFM score from both transaction and customer level data. Visualize the
    relationship between recency, frequency and monetary value using heatmap, 
    histograms, bar charts and scatter plots. Includes a 'shiny' app for 
    interactive segmentation. References:
    i. Blattberg R.C., Kim BD., Neslin S.A (2008) <doi:10.1007/978-0-387-72579-6_12>.",2020-04-23,Aravind Hebbali,"https://github.com/rsquaredacademy/rfm,
https://rfm.rsquaredacademy.com/",TRUE,https://github.com/rsquaredacademy/rfm,19467,28,2020-04-23T12:12:42Z,695.25
RFmerge,"S3 implementation of the Random Forest MErging Procedure (RF-MEP), which combines two or more satellite-based datasets (e.g., precipitation products, topography) with ground observations to produce a new dataset with improved spatio-temporal distribution of the target field. In particular, this package was developed to merge different Satellite-based Rainfall Estimates (SREs) with measurements from rain gauges, in order to obtain a new precipitation dataset where the time series in the rain gauges are used to correct different types of errors present in the SREs. However, this package might be used to merge other hydrological/environmental satellite fields with point observations. For details, see Baez-Villanueva et al. (2020) <doi:10.1016/j.rse.2019.111606>. Bugs / comments / questions / collaboration of any kind are very welcomed.",2020-05-22,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/RFmerge,TRUE,https://github.com/hzambran/rfmerge,1857,7,2020-05-21T16:56:33Z,265.2857142857143
rfoaas,R access to the 'FOAAS' (F... Off As A Service) web service is provided.,2020-01-09,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rfoaas.html,TRUE,https://github.com/eddelbuettel/rfoaas,18931,26,2020-06-03T22:56:31Z,728.1153846153846
rfordummies,"Contains all the code examples in the book ""R for Dummies"" (2nd
    edition) by Andrie de Vries and Joris Meys. You can view the table of 
    contents as well as the sample code for each chapter.",2019-03-19,Andrie de Vries,"https://rfordummies.com, http://andrie.github.io/rfordummies/",TRUE,https://github.com/andrie/rfordummies,18684,1,2019-07-31T15:07:11Z,18684
rfPermute,"Estimate significance of importance metrics
    for a Random Forest model by permuting the response
    variable. Produces null distribution of importance
    metrics for each predictor variable and p-value of
    observed. Provides summary and visualization functions for 'randomForest' 
    results.",2020-02-23,Eric Archer,https://github.com/EricArcher/rfPermute,TRUE,https://github.com/ericarcher/rfpermute,26398,14,2020-05-13T01:13:58Z,1885.5714285714287
Rfssa,"Methods and tools for implementing functional singular spectrum analysis for functional time series
    as described in Haghbin H., Najibi, S.M., Mahmoudvand R., Trinka J., Maadooliat M. (2019). Functional singular spectrum Analysis. Manuscript submitted for publication. ",2019-09-12,Hossein Haghbin,https://github.com/haghbinh/Rfssa.git,TRUE,https://github.com/haghbinh/rfssa,5007,2,2019-09-16T14:50:44Z,2503.5
rfUtilities,"Utilities for Random Forest model selection, class balance
    correction, significance test, cross validation and partial dependency
    plots.",2019-10-03,Jeffrey S. Evans,https://github.com/jeffreyevans/rfUtilities,TRUE,https://github.com/jeffreyevans/rfutilities,37349,4,2020-03-20T02:06:17Z,9337.25
Rgb,"Classes and methods to efficiently handle (slice, annotate, draw ...) genomic features (such as genes or transcripts), and an interactive interface to browse them.",2018-03-18,Sylvain Mareschal,http://bioinformatics.ovsa.fr/Rgb,TRUE,https://github.com/maressyl/r.rgb,13540,0,2020-05-03T10:33:13Z,NA
rgbif,"A programmatic interface to the Web Service methods
    provided by the Global Biodiversity Information Facility ('GBIF';
    <https://www.gbif.org/developer/summary>). 'GBIF' is a database
    of species occurrence records from sources all over the globe.
    'rgbif' includes functions for searching for taxonomic names,
    retrieving information on data providers, getting species occurrence
    records, getting counts of occurrence records, and using the 'GBIF'
    tile map service to make 'rasters' summarizing huge amounts of data.",2020-05-28,Scott Chamberlain,"https://github.com/ropensci/rgbif (devel),
https://docs.ropensci.org/rgbif (documentation),
https://books.ropensci.org/occurrences/ (user manual)",TRUE,https://github.com/ropensci/rgbif,130601,101,2020-05-28T19:16:13Z,1293.079207920792
RGCxGC,"Toolbox for chemometrics analysis of bidimensional gas 
    chromatography data. This package import data for common scientific data
    format (NetCDF) and fold it to 2D chromatogram. Then, it can perform
    preprocessing and multivariate analysis. In the preprocessing algorithms,
    baseline correction, smoothing, and peak alignment are available.
    While in multivariate analysis, multiway principal component analysis is
    incorporated.",2020-03-29,Cristian Quiroz-Moreno,https://github.com/DanielQuiroz97/RGCxGC,TRUE,https://github.com/danielquiroz97/rgcxgc,5029,1,2020-04-22T07:07:28Z,5029
rgdax,"Allow access to both public and private end points to Coinbase Pro (erstwhile GDAX) 
    cryptocurrency exchange. For authenticated flow, users must have valid api, secret and passphrase to be able to connect.",2019-01-07,Dheeraj Agarwal,https://github.com/DheerajAgarwal/rgdax/,TRUE,https://github.com/dheerajagarwal/rgdax,11279,24,2019-07-13T10:04:15Z,469.9583333333333
rGEDI,"Set of tools for downloading, reading, visualizing and processing GEDI Level1B, Level2A and Level2B data.",2020-05-07,Carlos Alberto Silva,https://github.com/carlos-alberto-silva/rGEDI,TRUE,https://github.com/carlos-alberto-silva/rgedi,1824,42,2020-06-03T00:02:25Z,43.42857142857143
RGENERATE,"A method 'generate()' is implemented in this package for the random
    generation of vector time series according to models obtained by 'RMAWGEN',
    'vars' or other packages.  This package was created to generalize the
    algorithms of the 'RMAWGEN' package for the analysis and generation of any
    environmental vector time series.",2017-02-11,Emanuele Cordano,https://github.com/ecor/RGENERATE,TRUE,https://github.com/ecor/rgenerate,21172,1,2020-04-11T11:51:30Z,21172
RGENERATEPREC,"The method 'generate()' is extended for spatial multi-site
    stochastic generation of daily precipitation. It generates precipitation
    occurrence in several sites using logit regression (Generalized Linear
    Models) and D.S. Wilks' approach (Journal of Hydrology, 1998).",2019-11-27,Emanuele Cordano,https://github.com/ecor/RGENERATEPREC,TRUE,https://github.com/ecor/rgenerateprec,15280,1,2019-11-27T01:16:22Z,15280
rgenius,"Download the lyrics of your favorite songs in text and table formats. 
    Also search for related songs or song information.
    More information: <https://docs.genius.com/> .",2020-05-11,Alberto Almuiña,https://github.com/AlbertoAlmuinha/rgenius,TRUE,https://github.com/albertoalmuinha/rgenius,502,4,2020-05-11T16:02:41Z,125.5
rgeolocate,"Connectors to online and offline sources for taking IP addresses
    and geolocating them to country, city, timezone and other geographic ranges. For
    individual connectors, see the package index.",2020-05-17,Os Keyes,NA,TRUE,https://github.com/ironholds/rgeolocate,32768,61,2020-05-16T23:12:44Z,537.1803278688525
rgeopat2,"Supports analysis of spatial data processed with the 'GeoPAT' 2
    software <http://sil.uc.edu/cms/index.php?id=geopat2>. 
    Available features include creation of a grid based on the 'GeoPAT' 2
    grid header file and reading a 'GeoPAT' 2 text outputs.",2020-03-08,Jakub Nowosad,https://github.com/Nowosad/rgeopat2,TRUE,https://github.com/nowosad/rgeopat2,10675,10,2020-02-29T19:03:53Z,1067.5
rgexf,"Create, read and write 'GEXF' (Graph Exchange 'XML' Format) graph
    files (used in 'Gephi' and others). Using the 'XML' package, it allows the user to
    easily build/read graph files including attributes, 'GEXF' visual attributes (such
    as color, size, and position), network dynamics (for both edges and nodes) and
    edge weighting. Users can build/handle graphs element-by-element or massively
    through data-frames, visualize the graph on a web browser through 'gexf-js' (a
    'javascript' library) and interact with the 'igraph' package.",2020-02-17,George Vega Yon,https://gvegayon.github.io/rgexf,TRUE,https://github.com/gvegayon/rgexf,515254,11,2020-02-12T21:07:43Z,46841.27272727273
rgho,"Access WHO Global Health Observatory
    (<http://www.who.int/gho/>)
    data from R via the Athena web service
    (<http://apps.who.int/gho/data/node.resources.api>),
    an application program interface providing
    a simple query interface to the World
    Health Organization's data and statistics content.",2020-04-07,Antoine Filipovic-Pierucci,https://github.com/kzarca/rgho,TRUE,https://github.com/kzarca/rgho,13351,0,2020-03-10T14:33:25Z,NA
rglobi,"A programmatic interface to the web service methods
    provided by Global Biotic Interactions (GloBI). GloBI provides 
    access to spatial-temporal species interaction records from 
    sources all over the world. rglobi provides methods to search 
    species interactions by location, interaction type, and 
    taxonomic name. In addition, it supports Cypher, a graph query
    language, to allow for executing custom queries on the GloBI 
    aggregate species interaction data set.",2019-12-07,Jorrit Poelen,https://github.com/ropensci/rglobi,TRUE,https://github.com/ropensci/rglobi,24547,10,2020-05-13T13:27:02Z,2454.7
rgsp,Functions to calculate Sample Number and Average Sample Number for Repetitive Group Sampling Plan Based on Cpk as given in Aslam et al. (2013) (<DOI:10.1080/00949655.2012.663374>).,2018-10-26,Muhammad Yaseen,"https://github.com/myaseen208/rgsp,
https://myaseen208.github.io/rgsp/",TRUE,https://github.com/myaseen208/rgsp,6132,0,2019-12-03T16:59:19Z,NA
rhandsontable,"An R interface to the 'Handsontable' JavaScript library, which is a
    minimalist Excel-like data grid editor.  See <https://handsontable.com/> for details.",2018-11-20,Jonathan Owen,http://jrowen.github.io/rhandsontable/,TRUE,https://github.com/jrowen/rhandsontable,344974,289,2020-02-05T01:51:56Z,1193.681660899654
rhierbaps,"Implements the hierarchical Bayesian analysis of populations structure (hierBAPS) 
  algorithm of Cheng et al. (2013) <doi:10.1093/molbev/mst028> for clustering DNA sequences 
  from multiple sequence alignments in FASTA format. 
  The implementation includes improved defaults and plotting capabilities 
  and unlike the original 'MATLAB' version removes singleton SNPs by default.",2019-12-11,Gerry Tonkin-Hill,https://github.com/gtonkinhill/rhierbaps,TRUE,https://github.com/gtonkinhill/rhierbaps,7510,15,2019-12-11T06:39:19Z,500.6666666666667
rhub,"Run 'R CMD check' on any of the 'R-hub' (<https://builder.r-hub.io/>)
    architectures, from the command line. The current architectures include
    'Windows', 'macOS', 'Solaris' and various 'Linux' distributions.",2019-04-08,Gábor Csárdi,"https://github.com/r-hub/rhub, https://r-hub.github.io/rhub/",TRUE,https://github.com/r-hub/rhub,344195,274,2020-06-02T14:44:31Z,1256.1861313868612
ribd,"Recursive algorithms for computing various relatedness coefficients, 
    including pairwise kinship, kappa and identity coefficients. Both autosomal 
    and X-linked coefficients are computed. Founders are allowed to be inbred. 
    In addition to the standard pairwise coefficients, ribd also computes a range
    of lesser-known coefficients, including generalised kinship coefficients 
    (Karigl (1981) <doi:10.1111/j.1469-1809.1981.tb00341.x>; Weeks and 
    Lange (1988) <https:www.ncbi.nlm.nih.gov/pmc/articles/PMC1715269>),  
    two-locus coefficients (Thompson (1988) <doi:10.1093/imammb/5.4.261>) and 
    multi-person coefficients. This package is part of the ped suite, 
    a collection of packages for pedigree analysis with 'pedtools' as the core 
    package for creating and handling pedigree objects.",2020-02-03,Magnus Dehli Vigeland,https://github.com/magnusdv/ribd,TRUE,https://github.com/magnusdv/ribd,2795,2,2020-05-14T13:58:56Z,1397.5
ribiosUtils,"Provides interface to the Bioinfo-C (internal name: BIOS) library and utilities. 'ribiosUtils' is a swiss-knife for computational biology in drug discovery, providing functions and utilities with minimal external dependency and maximal efficiency.",2020-03-06,Jitao David Zhang,https://github.com/bedapub/ribiosUtils,TRUE,https://github.com/bedapub/ribiosutils,1291,0,2020-04-11T11:45:29Z,NA
ridge,"Linear and logistic ridge regression functions. Additionally includes special functions for 
            genome-wide single-nucleotide polymorphism (SNP) data.",2020-03-20,Steffen Moritz,http://github.com/SteffenMoritz/ridge,TRUE,https://github.com/steffenmoritz/ridge,53917,9,2020-03-20T02:53:29Z,5990.777777777777
ridigbio,"An interface to iDigBio's search API that allows downloading
  specimen records. Searches are returned as a data.frame. Other functions
  such as the metadata end points return lists of information. iDigBio is a US
  project focused on digitizing and serving museum specimen collections on the
  web. See <https://www.idigbio.org> for information on iDigBio.",2017-02-16,Matthew Collins,https://github.com/iDigBio/ridigbio,TRUE,https://github.com/idigbio/ridigbio,44224,15,2020-05-27T17:43:08Z,2948.266666666667
riem,"Allows to get weather data from Automated Surface Observing System (ASOS) stations (airports) in the
    whole world thanks to the Iowa Environment Mesonet website.",2016-09-10,Maëlle Salmon,http://github.com/ropenscilabs/riem,TRUE,https://github.com/ropenscilabs/riem,18343,32,2020-04-22T12:06:41Z,573.21875
RiemBase,"We provide a number of algorithms to estimate fundamental statistics including Fréchet mean and geometric median for manifold-valued data. Also, C++ header files are contained that implement elementary operations on manifolds such as Sphere, Grassmann, and others. See Bhattacharya and Bhattacharya (2012) <doi:10.1017/CBO9781139094764> if you are interested in statistics on manifolds, and Absil et al (2007, ISBN:9780691132983) on computational aspects of optimization on matrix manifolds.",2020-03-21,Kisung You,http://github.com/kyoustat/RiemBase,TRUE,https://github.com/kyoustat/riembase,7185,1,2020-03-21T14:28:18Z,7185
Riex,"Retrieves efficiently and reliably Investors Exchange ('IEX') stock and market data using 'IEX Cloud API'. The platform is offered by Investors Exchange Group (IEX Group).
    Main goal is to leverage 'R' capabilities including existing packages to effectively provide financial and statistical analysis as well as visualization in support of fact-based decisions.
    In addition, continuously improve and enhance 'Riex' by applying best practices and being in tune with users' feedback and requirements.
    Please, make sure to review and acknowledge Investors Exchange Group (IEX Group) terms and conditions before using 'Riex' (<https://iexcloud.io/terms/>).",2019-05-05,Myriam Ibrahim,https://github.com/TheEliteAnalyst/Riex,TRUE,https://github.com/theeliteanalyst/riex,4542,2,2019-06-12T00:16:41Z,2271
rif,"Client for 'Neuroscience' Information Framework ('NIF') 'APIs'
    (<https://neuinfo.org/>; <https://neuinfo.org/about/webservices>).
    Package includes functions for each 'API' route, and gives back data
    in tidy data.frame format.",2017-05-16,Scott Chamberlain,https://github.com/ropensci/rif,TRUE,https://github.com/ropensci/rif,9327,5,2019-12-09T18:56:20Z,1865.4
Rilostat,"Tools to download data from the ilostat database
    <https://ilostat.ilo.org> together with search and
    manipulation utilities.",2020-05-27,David Bescond,https://ilostat.github.io/Rilostat/,TRUE,https://github.com/ilostat/rilostat,11891,10,2020-06-05T07:00:26Z,1189.1
RInside,"C++ classes to embed R in C++ (and C) applications
 A C++ class providing the R interpreter is offered by this package
 making it easier to have ""R inside"" your C++ application. As R itself
 is embedded into your application, a shared library build of R is
 required. This works on Linux, OS X and even on Windows provided you
 use the same tools used to build R itself. Numerous examples are
 provided in the nine subdirectories of the examples/ directory of
 the installed package: standard, 'mpi' (for parallel computing), 'qt'
 (showing how to embed 'RInside' inside a Qt GUI application), 'wt'
 (showing how to build a ""web-application"" using the Wt toolkit),
 'armadillo' (for 'RInside' use with 'RcppArmadillo'), 'eigen' (for
 'RInside' use with 'RcppEigen'), and 'c_interface' for a basic C
 interface and 'Ruby' illustration.  The examples use 'GNUmakefile(s)'
 with GNU extensions, so a GNU make is required (and will use the
 'GNUmakefile' automatically). 'Doxygen'-generated documentation of
 the C++ classes is available at the 'RInside' website as well.",2020-03-12,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rinside.html,TRUE,https://github.com/eddelbuettel/rinside,58787,104,2020-03-12T15:03:32Z,565.2596153846154
Rinstapkg,"Provides functions to use the 'Instagram' API to get feed and user 
    information, but also performs basic in-app functionality such as liking, 
    commenting, following, and blocking. Use of this package means that you will 
    not use it to spam, harass, or perform other nefarious acts. For more details 
    on how to use the API please see this package's website 
    <https://eric88tchong.github.io/Rinstapkg/> for more information, documentation, 
    and examples.",2019-06-08,Eric Tchong,https://github.com/eric88tchong/Rinstapkg,TRUE,https://github.com/eric88tchong/rinstapkg,4100,4,2019-06-11T18:15:07Z,1025
rintrojs,"A wrapper for the 'Intro.js' library (For more info: <http://www.introjs.com>). 
  This package makes it easy to include step-by-step introductions, and clickable hints in a 'Shiny' 
  application. It supports both static introductions in the UI, and programmatic introductions from 
  the server-side. ",2019-05-29,Carl Ganz,https://github.com/carlganz/rintrojs,TRUE,https://github.com/carlganz/rintrojs,41620,85,2020-05-09T19:47:41Z,489.6470588235294
rio,"Streamlined data import and export by making assumptions that
    the user is probably willing to make: 'import()' and 'export()' determine
    the data structure from the file extension, reasonable defaults are used for
    data import and export (e.g., 'stringsAsFactors=FALSE'), web-based import is
    natively supported (including from SSL/HTTPS), compressed files can be read
    directly without explicit decompression, and fast import packages are used where
    appropriate. An additional convenience function, 'convert()', provides a simple
    method for converting between file types.",2018-11-26,Thomas J. Leeper,https://github.com/leeper/rio,TRUE,https://github.com/leeper/rio,3793052,427,2020-03-01T20:50:56Z,8883.025761124121
rIP,"Takes an array of IPs and the keys for the services the user wishes to use (IP Hub, IP Intel, and Proxycheck), 
    and passes these to all respective APIs. Returns a dataframe with the IP addresses (used for merging), 
    country, ISP, labels for non-US IP Addresses, VPS use, and recommendations for blocking. The package 
    also provides optional visualization tools for checking the distributions. Additional
    functions are provided to call each discrete API endpoint. The package and methods are detailed in the recent paper 
    Waggoner, Kennedy, and Clifford (2019) <doi:10.21105/joss.01285>.",2019-05-29,Ryan Kennedy,http://joss.theoj.org/papers/10.21105/joss.01285,TRUE,https://github.com/mahdlab/rip,7098,18,2020-05-28T15:16:07Z,394.3333333333333
ripe,"Functions in a 'magrittr' pipeline are evaluated sequentially making it
         impossible to rerun them directly from the end of the pipeline, while preserving 
         stochastic characteristics embedded within the pipeline. This package 
         allows the user to rerun pipelines using natural 'magrittr' syntax.",2019-12-06,Jonathan Sidi,https://github.com/yonicd/ripe,TRUE,https://github.com/yonicd/ripe,2300,10,2019-12-06T10:49:46Z,230
Rirt,"Parameter estimation, computation of probability, information, and 
    (log-)likelihood, and visualization of item/test characteristic curves and
    item/test information functions for three uni-dimensional item response theory
    models: the 3-parameter-logistic model, generalized partial credit model, 
    and graded response model. The full documentation and tutorials are at 
    <https://github.com/xluo11/Rirt>.",2019-10-23,Xiao Luo,https://github.com/xluo11/Rirt,TRUE,https://github.com/xluo11/rirt,2592,1,2019-10-23T18:48:58Z,2592
riskclustr,"A collection of functions related to the study of etiologic heterogeneity both across disease subtypes and across individual disease markers. The included functions allow one to quantify the extent of etiologic heterogeneity in the context of a case-control study, and provide p-values to test for etiologic heterogeneity across individual risk factors. Begg CB, Zabor EC, Bernstein JL, Bernstein L, Press MF, Seshan VE (2013) <doi: 10.1002/sim.5902>.",2020-05-26,Emily C. Zabor,"http://www.emilyzabor.com/riskclustr/,
https://github.com/zabore/riskclustr",TRUE,https://github.com/zabore/riskclustr,4877,1,2020-05-26T14:41:55Z,4877
riskParityPortfolio,"Fast design of risk parity portfolios for financial investment.
    The goal of the risk parity portfolio formulation is to equalize or distribute
    the risk contributions of the different assets, which is missing if we simply
    consider the overall volatility of the portfolio as in the mean-variance
    Markowitz portfolio. In addition to the vanilla formulation, where the risk
    contributions are perfectly equalized subject to no shortselling and budget
    constraints, many other formulations are considered that allow for box
    constraints and shortselling, as well as the inclusion of additional
    objectives like the expected return and overall variance. See vignette for
    a detailed documentation and comparison, with several illustrative examples.
    The package is based on the papers:
    Y. Feng, and D. P. Palomar (2015). SCRIP: Successive Convex Optimization Methods
    for Risk Parity Portfolio Design. IEEE Trans. on Signal Processing, vol. 63,
    no. 19, pp. 5285-5300. <doi:10.1109/TSP.2015.2452219>.
    F. Spinu (2013), An Algorithm for Computing Risk Parity Weights.
    <doi:10.2139/ssrn.2297383>.
    T. Griveau-Billion, J. Richard, and T. Roncalli (2013). A fast algorithm for computing 
    High-dimensional risk parity portfolios. <arXiv:1311.4057>.",2019-10-07,Daniel P. Palomar,"https://CRAN.R-project.org/package=riskParityPortfolio,
https://github.com/dppalomar/riskParityPortfolio,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2015.2452219",TRUE,https://github.com/dppalomar/riskparityportfolio,10553,47,2020-06-08T12:35:01Z,224.53191489361703
RiskPortfolios,"Collection of functions designed to compute risk-based portfolios as described 
    in Ardia et al. (2017) <doi:10.1007/s10479-017-2474-7> and Ardia et al. (2017) <doi:10.21105/joss.00171>.",2020-04-20,David Ardia,https://github.com/ArdiaD/RiskPortfolios,TRUE,https://github.com/ardiad/riskportfolios,18826,20,2020-04-19T20:51:02Z,941.3
riskyr,"Risk-related information (like the prevalence of conditions and the sensitivity and specificity of diagnostic tests or treatment decisions) can be expressed in terms of probabilities or frequencies. By providing a toolbox of methods and metrics, 'riskyr' computes, translates, and visualizes risk-related information in a variety of ways. Offering multiple complementary perspectives on the interplay between key parameters renders teaching and training of risk literacy more transparent. ",2019-01-03,Hansjoerg Neth,"http://riskyr.org, https://github.com/hneth/riskyr",TRUE,https://github.com/hneth/riskyr,7266,9,2020-05-31T16:14:13Z,807.3333333333334
ritis,"An interface to the Integrated Taxonomic Information System ('ITIS')
    (<https://www.itis.gov>). Includes functions to work with the 'ITIS' REST
    API methods (<https://www.itis.gov/ws_description.html>), as well as the
    'Solr' web service (<https://www.itis.gov/solr_documentation.html>).",2020-04-17,Scott Chamberlain,"https://github.com/ropensci/ritis (devel)
https://docs.ropensci.org/ritis/ (docs)",TRUE,https://github.com/ropensci/ritis,106931,11,2020-05-07T16:03:36Z,9721
riverdist,"Reads river network shape files and computes network distances.
    Also included are a variety of computation and graphical tools designed 
    for fisheries telemetry research, such as minimum home range, kernel density 
    estimation, and clustering analysis using empirical k-functions with 
    a bootstrap envelope.  Tools are also provided for editing the river 
    networks, meaning there is no reliance on external software.",2020-06-02,Matt Tyers,https://cran.r-project.org/package=riverdist,TRUE,https://github.com/mbtyers/riverdist,13886,8,2020-06-02T19:26:02Z,1735.75
rivr,"A tool for undergraduate and graduate courses in open-channel
    hydraulics. Provides functions for computing normal and critical depths,
    steady-state water surface profiles (e.g. backwater curves) and unsteady flow
    computations (e.g. flood wave routing).",2020-02-27,Michael C Koohafkan,https://github.com/mkoohafkan/rivr,TRUE,https://github.com/mkoohafkan/rivr,16409,9,2020-02-27T19:59:43Z,1823.2222222222222
rJava,"Low-level interface to Java VM very much like .C/.Call and friends. Allows creation of objects, calling methods and accessing fields.",2020-03-24,Simon Urbanek,http://www.rforge.net/rJava/,TRUE,https://github.com/s-u/rjava,9320833,197,2020-05-19T22:04:33Z,47313.8730964467
RJDemetra,"Interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>), the seasonal adjustment software officially
    recommended to the members of the European Statistical System (ESS) and the European System of Central Banks.
    It offers full access to all options and outputs of 'JDemetra+', including the two leading seasonal adjustment methods
    TRAMO/SEATS+ and X-12ARIMA/X-13ARIMA-SEATS.",2020-03-11,Alain Quartier-la-Tente,https://github.com/jdemetra/rjdemetra,TRUE,https://github.com/jdemetra/rjdemetra,9896,27,2020-03-12T14:27:56Z,366.51851851851853
rjdmarkdown,"Functions to have nice 'rmarkdown' outputs of the 
  seasonal and trading day adjustment models made with 'RJDemetra'.",2020-05-08,Alain Quartier-la-Tente,https://github.com/AQLT/rjdmarkdown,TRUE,https://github.com/aqlt/rjdmarkdown,391,3,2020-05-08T21:11:18Z,130.33333333333334
rjdqa,"Add-in to the 'RJDemetra' package on seasonal adjustments.
    It allows to produce quality assessments outputs (dashboards, quality report matrix, etc.).",2019-06-17,Alain Quartier-la-Tente,https://github.com/AQLT/rjdqa,TRUE,https://github.com/aqlt/rjdqa,3668,1,2019-07-07T13:03:47Z,3668
RJSDMX,"Provides functions to retrieve data and metadata from providers 
			 that disseminate data by means of SDMX web services. 
			 SDMX (Statistical Data and Metadata eXchange) is a standard that 
			 has been developed with the aim of simplifying the exchange of 
			 statistical information. 
			 More about the SDMX standard and the SDMX Web Services 
			 can be found at: <https://sdmx.org>.",2020-02-27,Attilio Mattiocco,https://github.com/amattioc/SDMX/,TRUE,https://github.com/amattioc/sdmx,23764,61,2020-05-25T09:31:30Z,389.57377049180326
rjsonapi,"Consumer for APIs that Follow the JSON API Specification
    (<http://jsonapi.org/>). Package mostly consumes data - with experimental
    support for serving JSON API data.",2017-01-09,Scott Chamberlain,https://github.com/ropensci/rjsonapi,TRUE,https://github.com/ropensci/rjsonapi,10989,28,2019-12-09T18:56:47Z,392.4642857142857
rjstat,"Handle 'JSON-stat' format (<https://json-stat.org>) in R.
    Not all features are supported, especially the extensive metadata
    features of 'JSON-stat'.",2020-03-22,Aaron Schumacher,https://github.com/ajschumacher/rjstat,TRUE,https://github.com/ajschumacher/rjstat,19092,29,2020-03-21T21:32:18Z,658.3448275862069
rjwsacruncher,"'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>) is the seasonal adjustment software officially recommended
  to the members of the European Statistical System and the European System of Central Banks. Seasonal adjustment models performed
  with 'JDemetra+' can be stored into workspaces. 'JWSACruncher' (<https://github.com/jdemetra/jwsacruncher/releases>) is a console tool that 
  re-estimates all the multi-processing defined in a workspace and to export the result. 'rjwsacruncher' allows to launch easily the 'JWSACruncher'.",2019-06-15,Alain Quartier-la-Tente,https://github.com/AQLT/rjwsacruncher,TRUE,https://github.com/aqlt/rjwsacruncher,4049,1,2020-03-12T17:06:14Z,4049
rkeops,"The 'KeOps' library lets you compute generic reductions of very large arrays 
    whose entries are given by a mathematical formula. It combines a tiled reduction scheme 
    with an automatic differentiation engine, and can be used through 'R', 'Matlab', 'NumPy' or 
    'PyTorch' backends. It is perfectly suited to the computation of Kernel dot products 
    and the associated gradients, even when the full kernel matrix does not fit into 
    the GPU memory.",2020-05-25,Benjamin Charlier,"https://www.kernel-operations.io/,
https://github.com/getkeops/keops/",TRUE,https://github.com/getkeops/keops,1057,183,2020-05-25T10:52:27Z,5.775956284153006
rKolada,"Methods for downloading and processing data and metadata from 'Kolada', the official Swedish regions and municipalities database.",2020-06-07,Love Hansson,"https://lchansson.github.io/rKolada,
https://github.com/lchansson/rKolada",TRUE,https://github.com/lchansson/rkolada,379,0,2020-06-06T12:20:27Z,NA
rLakeAnalyzer,"Standardized methods for calculating common important derived
    physical features of lakes including water density based based on
    temperature, thermal layers, thermocline depth, lake number, Wedderburn
    number, Schmidt stability and others.",2019-06-09,Luke Winslow,NA,TRUE,https://github.com/gleon/rlakeanalyzer,29422,19,2019-09-25T14:11:52Z,1548.5263157894738
rlang,"A toolbox for working with base types, core R features
  like the condition system, and core 'Tidyverse' features like tidy
  evaluation.",2020-05-02,Lionel Henry,"http://rlang.r-lib.org, https://github.com/r-lib/rlang",TRUE,https://github.com/r-lib/rlang,31788998,273,2020-06-09T09:41:21Z,116443.21611721611
rlas,Read and write 'las' and 'laz' binary file formats. The LAS file format is a public file format for the interchange of 3-dimensional point cloud data between data users. The LAS specifications are approved by the American Society for Photogrammetry and Remote Sensing <https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities>. The LAZ file format is an open and lossless compression scheme for binary LAS format versions 1.0 to 1.3 <https://laszip.org/>.,2020-06-02,Jean-Romain Roussel,https://github.com/Jean-Romain/rlas,TRUE,https://github.com/jean-romain/rlas,48945,20,2020-05-27T18:05:14Z,2447.25
Rlda,"Estimates the Bayesian LDA model for mixed-membership clustering based on different types of data
    (i.e., Multinomial, Bernoulli, and Binomial entries). Albuquerque, Valle and Li (2019) <doi:10.1016/j.knosys.2018.10.024>.",2018-12-13,Pedro Albuquerque and Denis Valle and Daijiang Li,https://www.sciencedirect.com/science/article/pii/S0950705118305100,TRUE,https://github.com/pedrobsb/rlda,10840,6,2019-07-26T02:42:16Z,1806.6666666666667
rless,"Converts LESS to CSS. 
    It uses V8 engine, where LESS parser is run. Functions for
    LESS text, file or folder conversion are provided.
    This work was supported by a junior grant research project by 
    Czech Science Foundation 'GACR' no. 'GJ18-04150Y'.",2019-07-31,Jonas Vaclavek,https://github.com/ciirc-kso/rless,TRUE,https://github.com/ciirc-kso/rless,3763,1,2019-07-31T19:01:48Z,3763
Rlgt,"An implementation of a number of Global Trend models for time series forecasting 
    that are Bayesian generalizations and extensions of some Exponential Smoothing models. 
    The main differences/additions include 1) nonlinear global trend, 2) Student-t error 
    distribution, and 3) a function for the error size, so heteroscedasticity. The methods 
    are particularly useful for short time series. When tested on the well-known M3 dataset,
    they are able to outperform all classical time series algorithms. The models are fitted 
    with MCMC using the 'rstan' package.",2019-06-14,Christoph Bergmeir,https://github.com/cbergmeir/Rlgt,TRUE,https://github.com/cbergmeir/rlgt,6179,9,2019-07-29T03:42:11Z,686.5555555555555
rlist,"Provides a set of functions for data manipulation with
    list objects, including mapping, filtering, grouping, sorting,
    updating, searching, and other useful functions. Most functions
    are designed to be pipeline friendly so that data processing with
    lists can be chained.",2016-04-04,Kun Ren,"https://renkun.me/rlist, https://github.com/renkun-ken/rlist,
https://renkun.me/rlist-tutorial",TRUE,https://github.com/renkun-ken/rlist,1903649,142,2020-04-23T14:13:08Z,13405.978873239437
RLRsim,"Rapid, simulation-based exact (restricted) likelihood ratio tests
    for testing the presence of variance components/nonparametric terms for
    models fit with nlme::lme(),lme4::lmer(), lmeTest::lmer(), gamm4::gamm4(),
    mgcv::gamm() and SemiPar::spm().",2020-03-25,Fabian Scheipl,https://github.com/fabian-s/RLRsim,TRUE,https://github.com/fabian-s/rlrsim,101332,8,2020-03-23T18:36:59Z,12666.5
RLumShiny,"A collection of 'shiny' applications for the R package
    'Luminescence'. These mainly, but not exclusively, include applications for
    plotting chronometric data from e.g. luminescence or radiocarbon dating. It
    further provides access to bootstraps tooltip and popover functionality and
    contains the 'jscolor.js' library with a custom 'shiny' output binding.",2019-01-11,Christoph Burow,https://tzerk.github.io/RLumShiny/,TRUE,https://github.com/tzerk/rlumshiny,28932,5,2019-10-27T20:19:56Z,5786.4
rly,R implementation of the common parsing tools 'lex' and 'yacc'.,2018-09-10,Marek Jagielski,https://github.com/systemincloud/rly,TRUE,https://github.com/systemincloud/rly,16546,25,2019-08-11T21:57:17Z,661.84
rmangal,An interface to the 'Mangal' database - a collection of ecological networks. This package includes functions to work with the 'Mangal RESTful API' methods (<https://mangal.io/doc/api>).,2019-10-03,Steve Vissault,"https://mangal.io, https://github.com/ropensci/rmangal",TRUE,https://github.com/ropensci/rmangal,2836,6,2020-03-29T18:23:31Z,472.6666666666667
rmapshaper,"Edit and simplify 'geojson', 'Spatial', and 'sf'
    objects.  This is wrapper around the 'mapshaper' 'JavaScript' library
    by Matthew Bloch <https://github.com/mbloch/mapshaper/> to perform
    topologically-aware polygon simplification, as well as other
    operations such as clipping, erasing, dissolving, and converting
    'multi-part' to 'single-part' geometries.  It relies on the
    'geojsonio' package for working with 'geojson' objects, the 'sf'
    package for working with 'sf' objects, and the 'sp' and 'rgdal'
    packages for working with 'Spatial' objects.",2020-04-01,Andy Teucher,https://github.com/ateucher/rmapshaper,TRUE,https://github.com/ateucher/rmapshaper,219867,115,2020-05-09T00:10:44Z,1911.8869565217392
rmapzen,"Provides an interface to 'Mapzen'-based APIs (including 
    geocode.earth, Nextzen, and NYC GeoSearch) for geographic search 
    and geocoding, isochrone calculation, and vector data to draw map tiles. 
    See <https://mapzen.com/documentation/> for more information. The original 
    Mapzen has gone out of business, but 'rmapzen' can be set up to work with 
    any provider who implements the Mapzen API. ",2019-08-19,Tarak Shah,https://tarakc02.github.io/rmapzen/,TRUE,https://github.com/tarakc02/rmapzen,11386,34,2019-08-19T22:36:31Z,334.88235294117646
RMariaDB,"Implements a 'DBI'-compliant interface to 'MariaDB'
    (<https://mariadb.org/>) and 'MySQL' (<https://www.mysql.com/>)
    databases.",2019-12-18,Kirill Müller,"https://rmariadb.r-dbi.org, https://github.com/r-dbi/RMariaDB,
https://downloads.mariadb.org/connector-c/",TRUE,https://github.com/r-dbi/rmariadb,147841,76,2019-12-31T11:27:29Z,1945.2763157894738
rmarkdown,Convert R Markdown documents into a variety of formats.,2020-05-31,Yihui Xie,https://github.com/rstudio/rmarkdown,TRUE,https://github.com/rstudio/rmarkdown,16362482,1818,2020-06-08T04:07:35Z,9000.265126512651
rmatio,"Read and write 'Matlab' MAT files from R. The 'rmatio'
    package supports reading MAT version 4, MAT version 5 and MAT
    compressed version 5. The 'rmatio' package can write version 5 MAT
    files and version 5 files with variable compression.",2019-03-18,Stefan Widgren,https://github.com/stewid/rmatio,TRUE,https://github.com/stewid/rmatio,77142,9,2019-11-16T17:06:11Z,8571.333333333334
RMAWGEN,"S3 and S4 functions are implemented for spatial multi-site
    stochastic generation of daily time series of temperature and
    precipitation. These tools make use of Vector AutoRegressive models (VARs).
    The weather generator model is then saved as an object and is calibrated by
    daily instrumental ""Gaussianized"" time series through the 'vars' package
    tools. Once obtained this model, it can it can be used for weather
    generations and be adapted to work with several climatic monthly time
    series.",2019-12-12,Emanuele Cordano,"https://github.com/ecor/RMAWGEN,
https://docs.google.com/file/d/0B66otCUk3Bv6V3RPbm1mUG4zVHc/edit,
http://presentations.copernicus.org/EGU2012-14026_presentation.pdf,
http://presentations.copernicus.org/EGU2012-5404_presentation.pdf",TRUE,https://github.com/ecor/rmawgen,33886,0,2019-12-12T18:08:57Z,NA
rmd,"The 'rmd' package manages multiple R markdown packages. These R markdown packages include currently 'rmarkdown', 'knitr', 'bookdown', 'bookdownplus', 'blogdown', 'rticles',  'tinytex', 'xaringan', 'citr',  and 'mindr'. They can be installed and loaded in a single step with the 'rmd' package. The conflicts between these packages are evaluated as well.",2020-03-01,Peng Zhao,https://github.com/pzhaonet/rmd,TRUE,https://github.com/pzhaonet/rmd,6852,26,2020-05-19T23:30:29Z,263.53846153846155
rmdfiltr,"A collection of 'Lua' filters that extend the functionality
  of R Markdown templates (e.g., count words or post-process 'pandoc-citeproc'-
  citations).",2019-12-11,Frederik Aust,https://github.com/crsh/rmdfiltr,TRUE,https://github.com/crsh/rmdfiltr,8211,30,2019-12-17T19:08:43Z,273.7
rmdformats,"HTML formats and templates for 'rmarkdown' documents, with some extra
    features such as automatic table of contents, lightboxed figures, dynamic
    crosstab helper.",2020-03-11,Julien Barnier,https://github.com/juba/rmdformats,TRUE,https://github.com/juba/rmdformats,65047,385,2020-05-26T13:01:52Z,168.95324675324676
rmdpartials,"
		Use 'rmarkdown' partials, also know as child documents in
		'knitr', so you can make components for HTML, PDF, and Word documents. 
		The package provides various helper functions to make certain functions easier. 
		You may want to use this package, if you want to flexibly summarise objects 
		using a combination of figures, tables, text, and HTML widgets. 
		Unlike HTML widgets, the output is Markdown and can hence be turn into other
		output formats than HTML.",2020-06-04,Ruben Arslan,https://github.com/rubenarslan/rmdpartials,TRUE,https://github.com/rubenarslan/rmdpartials,0,0,2020-06-06T06:42:42Z,NA
rmdplugr,"Formats for R Markdown that undo modifications by
    'pandoc' and 'rmarkdown' to original 'latex' templates, such as
    smaller margins, paragraph spacing, and compact titles. In addition, 
    enhancements such as author blocks with affiliations and
    headers and footers are introduced. All of this functionality is built 
    around plugins that modify the default 'pandoc' template without relying on 
    custom templates.",2020-01-09,Johan Larsson,"https://github.com/jolars/rmdplugr,
https://jolars.github.io/rmdplugr/",TRUE,https://github.com/jolars/rmdplugr,3567,0,2020-01-10T14:15:05Z,NA
rMEA,"A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Ramseyer & Tschacher (2011) <doi:10.1037/a0023419>.",2019-03-22,Johann R. Kleinbub,https://github.com/kleinbub/rMEA http://www.psync.ch,TRUE,https://github.com/kleinbub/rmea,8094,3,2019-08-01T12:24:37Z,2698
rmetalog,"Implementation of the metalog distribution in R.
    The metalog distribution is a modern, highly flexible, data-driven distribution. 
    Metalogs are developed by Keelin (2016) <doi:10.1287/deca.2016.0338>.
    This package provides functions to build these distributions from raw data. 
    Resulting metalog objects are then useful for exploratory and probabilistic analysis.",2020-03-10,Isaac Faber,NA,TRUE,https://github.com/isaacfab/rmetalog,6767,15,2020-03-11T01:11:49Z,451.1333333333333
rmio,"Provides header files of 'mio', a cross-platform C++11 header-only 
    library for memory mapped file IO <https://github.com/mandreyel/mio>.",2020-01-08,Florian Privé,https://github.com/privefl/rmio,TRUE,https://github.com/privefl/rmio,17850,4,2020-01-03T12:15:03Z,4462.5
RMixtComp,"Mixture Composer <https://github.com/modal-inria/MixtComp> is a project to build mixture models with
    heterogeneous data sets and partially missing data management. 
    It includes 8 models for real, categorical, counting, functional and ranking data.",2020-01-07,Quentin Grimonprez,"https://github.com/modal-inria/MixtComp,
https://massiccc.lille.inria.fr/",TRUE,https://github.com/modal-inria/mixtcomp,3864,4,2020-05-27T14:25:47Z,966
RMixtCompIO,"Mixture Composer <https://github.com/modal-inria/MixtComp> is a project to build mixture models with
    heterogeneous data sets and partially missing data management. 
    It includes models for real, categorical, counting, functional and ranking data.
    This package contains the minimal R interface of the C++ 'MixtComp' library.",2019-12-16,Quentin Grimonprez,"https://github.com/modal-inria/MixtComp,
https://massiccc.lille.inria.fr/",TRUE,https://github.com/modal-inria/mixtcomp,3596,4,2020-05-27T14:25:47Z,899
RMixtCompUtilities,"Mixture Composer <https://github.com/modal-inria/MixtComp> is a project to build mixture models with
    heterogeneous data sets and partially missing data management. This package contains graphical, getter and some utility 
    functions to facilitate the analysis of 'MixtComp' output.",2019-12-19,Quentin Grimonprez,"https://github.com/modal-inria/MixtComp,
https://massiccc.lille.inria.fr/",TRUE,https://github.com/modal-inria/mixtcomp,3546,4,2020-05-27T14:25:47Z,886.5
rmonad,"
    A monadic solution to pipeline analysis. All operations -- and the errors,
    warnings and messages they emit -- are merged into a directed graph. Infix
    binary operators mediate when values are stored, how exceptions are
    handled, and where pipelines branch and merge. The resulting structure may
    be queried for debugging or report generation. 'rmonad' complements, rather
    than competes with, non-monadic pipeline packages like 'magrittr' or
    'pipeR'. This work is funded by the NSF (award number 1546858).",2020-02-14,Zebulun Arendsee,https://github.com/arendsee/rmonad,TRUE,https://github.com/arendsee/rmonad,10325,53,2020-02-13T20:22:12Z,194.81132075471697
rms,"Regression modeling, testing, estimation, validation,
	graphics, prediction, and typesetting by storing enhanced model design
	attributes in the fit.  'rms' is a collection of functions that
	assist with and streamline modeling.  It also contains functions for
	binary and ordinal logistic regression models, ordinal models for
  continuous Y with a variety of distribution families, and the Buckley-James
	multiple regression model for right-censored responses, and implements
	penalized maximum likelihood estimation for logistic and ordinary
	linear models.  'rms' works with almost any regression model, but it
	was especially written to work with binary or ordinal regression
	models, Cox regression, accelerated failure time models,
	ordinary linear models,	the Buckley-James model, generalized least
	squares for serially or spatially correlated observations, generalized
	linear models, and quantile regression.  Bayesian methods are implemented for binary and ordinal logistic regression with or without random effects.",2020-06-04,Frank E Harrell Jr,"https://hbiostat.org/R/rms, https://github.com/harrelfe/rms,
http://hbiostat.org/doc/rms,
https://www.nicholas-ollberding.com/post/an-introduction-to-the-harrell-verse-predictive-modeling-using-the-hmisc-and-rms-packages",TRUE,https://github.com/harrelfe/rms,930718,86,2020-06-08T15:12:50Z,10822.302325581395
rmsfuns,"Contains several useful navigation helper functions, including easily building
    folder paths, quick viewing dataframes in 'Excel', creating date vectors and changing the
    console prompt to reflect time.",2020-05-05,Nico Katzke,https://rmsfuns.nfkatzke.com,TRUE,https://github.com/nicktz/rmsfuns,10530,1,2020-05-05T10:00:55Z,10530
Rmst,"Assemble the panels of computerized adaptive multistage testing by the 
    bottom-up and the top-down approach, and simulate the administration of the assembled 
    panels. The full documentation and tutorials are at <https://github.com/xluo11/Rmst>.
    Reference: Luo and Kim (2018) <doi:10.1111/jedm.12174>.",2019-11-12,Xiao Luo,https://github.com/xluo11/Rmst,TRUE,https://github.com/xluo11/rmst,2059,2,2019-11-02T02:57:50Z,1029.5
rmumps,"Some basic features of 'MUMPS' (Multifrontal Massively Parallel
         sparse direct Solver) are wrapped in a class whose methods can be used
         for sequentially solving a sparse linear system (symmetric or not)
         with one or many right hand sides (dense or sparse).
         There is a possibility to do separately symbolic analysis,
         LU (or LDL^t) factorization and system solving.
         Third part ordering libraries are included and can be used: 'PORD', 'METIS', 'SCOTCH'.
         'MUMPS' method was first described in Amestoy et al. (2001) <doi:10.1137/S0895479899358194>
         and Amestoy et al. (2006) <doi:10.1016/j.parco.2005.07.004>.",2020-02-20,Serguei Sokol,"http://mumps.enseeiht.fr/, https://github.com/sgsokol/rmumps/",TRUE,https://github.com/sgsokol/rmumps,20438,7,2020-02-20T13:34:59Z,2919.714285714286
rmutil,"A toolkit of functions for nonlinear regression and repeated
    measurements not to be used by itself but called by other Lindsey packages such
    as 'gnlm', 'stable', 'growth', 'repeated', and 'event' 
    (available at <http://www.commanster.eu/rcode.html>).",2020-06-09,Bruce Swihart,http://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/rmutil,149073,0,2020-06-09T18:30:07Z,NA
rMVP,"A memory-efficient, visualize-enhanced, parallel-accelerated Genome-Wide Association Study (GWAS) tool. It can
    (1) effectively process large data, 
    (2) rapidly evaluate population structure, 
    (3) efficiently estimate variance components several algorithms, 
    (4) implement parallel-accelerated association tests of markers three methods, 
    (5) globally efficient design on GWAS process computing, 
    (6) enhance visualization of related information. 
    'rMVP' contains three models GLM (Alkes Price (2006) <DOI:10.1038/ng1847>), MLM (Jianming Yu (2006) <DOI:10.1038/ng1702>) 
    and FarmCPU (Xiaolei Liu (2016) <doi:10.1371/journal.pgen.1005767>); variance components estimation methods EMMAX 
    (Hyunmin Kang (2008) <DOI:10.1534/genetics.107.080101>;), FaSTLMM (method: Christoph Lippert (2011) <DOI:10.1038/nmeth.1681>, 
    R implementation from 'GAPIT2': You Tang and Xiaolei Liu (2016) <DOI:10.1371/journal.pone.0107684> and 
    'SUPER': Qishan Wang and Feng Tian (2014) <DOI:10.1371/journal.pone.0107684>), and HE regression 
    (Xiang Zhou (2017) <DOI:10.1214/17-AOAS1052>).",2020-05-07,Xiaolei Liu,https://github.com/xiaolei-lab/rMVP,TRUE,https://github.com/xiaolei-lab/rmvp,3629,103,2020-06-06T08:18:07Z,35.23300970873787
rmweather,"An integrated set of tools to allow data users to conduct 
    meteorological normalisation on air quality data. This meteorological 
    normalisation technique uses predictive random forest models to remove 
    variation of pollutant concentrations so trends and interventions can be 
    explored in a robust way. For examples, see Grange et al. (2018) 
    <doi:10.5194/acp-18-6223-2018> and Grange and Carslaw (2019) 
    <doi:10.1016/j.scitotenv.2018.10.344>.",2020-06-07,Stuart K. Grange,https://github.com/skgrange/rmweather,TRUE,https://github.com/skgrange/rmweather,7386,8,2020-06-03T08:28:32Z,923.25
RMySQL,"Legacy 'DBI' interface to 'MySQL' / 'MariaDB' based on old code
    ported from S-PLUS. A modern 'MySQL' client based on 'Rcpp' is available 
    from the 'RMariaDB' package.",2020-03-14,Jeroen Ooms,https://downloads.mariadb.org/connector-c/ (upstream),TRUE,https://github.com/r-dbi/rmysql,2046013,190,2020-05-16T10:07:26Z,10768.48947368421
rnassqs,"Interface to access data via the United States Department of 
  Agriculture's National Agricultural Statistical Service (NASS) 'Quick Stats' 
  web API <https://quickstats.nass.usda.gov/api>. Convenience functions 
  facilitate building queries based on available parameters and valid parameter 
  values.",2019-08-19,Nicholas Potter,https://github.com/ropensci/rnassqs,TRUE,https://github.com/ropensci/rnassqs,4442,22,2020-02-13T22:28:49Z,201.9090909090909
rnaturalearth,Facilitates mapping by making natural earth map data from <http://www.naturalearthdata.com/> more easily available to R users.,2017-03-21,Andy South,https://github.com/ropenscilabs/rnaturalearth,TRUE,https://github.com/ropenscilabs/rnaturalearth,132715,133,2019-12-05T12:31:34Z,997.8571428571429
rnaturalearthdata,Vector map data from <http://www.naturalearthdata.com/>. Access functions are provided in the accompanying package 'rnaturalearth'.,2017-02-21,Andy South,https://github.com/ropenscilabs/rnaturalearthdata,TRUE,https://github.com/ropenscilabs/rnaturalearthdata,82497,8,2019-12-09T18:57:47Z,10312.125
rnbp,"Use the <http://api.nbp.pl/> API through R. Retrieve
    currency exchange rates and gold prices data published by the
    National Bank of Poland in form of convenient R objects.",2019-07-28,Ryszard Szymanski,NA,TRUE,https://github.com/szymanskir/rnbp,3333,0,2019-07-29T07:44:05Z,NA
rncl,"An interface to the Nexus Class Library which allows parsing
    of NEXUS, Newick and other phylogenetic tree file formats. It provides
    elements of the file that can be used to build phylogenetic objects
    such as ape's 'phylo' or phylobase's 'phylo4(d)'. This functionality
    is demonstrated with 'read_newick_phylo()' and 'read_nexus_phylo()'.",2020-02-10,Francois Michonneau,https://github.com/fmichonneau/rncl,TRUE,https://github.com/fmichonneau/rncl,163187,6,2020-02-09T22:40:09Z,27197.833333333332
RNeXML,"Provides access to phyloinformatic data in 'NeXML' format.  The
    package should add new functionality to R such as the possibility to
    manipulate 'NeXML' objects in more various and refined way and compatibility
    with 'ape' objects.",2020-05-10,Carl Boettiger,"https://docs.ropensci.org/RNeXML,
https://github.com/ropensci/RNeXML",TRUE,https://github.com/ropensci/rnexml,144137,14,2020-05-10T04:10:17Z,10295.5
rngtools,"Provides a set of functions for working with
    Random Number Generators (RNGs). In particular, a generic
    S4 framework is defined for getting/setting the current RNG, or RNG data
    that are embedded into objects for reproducibility.
    Notably, convenient default methods greatly facilitate the way current
    RNG settings can be changed.",2020-01-23,Renaud Gaujoux,https://renozao.github.io/rngtools,TRUE,https://github.com/renozao/rngtools,1740462,5,2020-03-30T02:12:27Z,348092.4
RNHANES,"Tools for downloading and analyzing CDC NHANES data, with a focus
    on analytical laboratory data.",2016-11-29,Herb Susmann,http://github.com/silentspringinstitute/RNHANES,TRUE,https://github.com/silentspringinstitute/rnhanes,13980,17,2019-06-11T17:27:44Z,822.3529411764706
RNifti,"Provides very fast read and write access to images stored in the
    NIfTI-1 and ANALYZE-7.5 formats, with seamless synchronisation between
    compiled C and interpreted R code. Also provides a simple image viewer, and
    a C/C++ API that can be used by other packages. Not to be confused with
    'RNiftyReg', which performs image registration.",2020-01-31,Jon Clayden,https://github.com/jonclayden/RNifti,TRUE,https://github.com/jonclayden/rnifti,97356,21,2020-06-03T21:08:58Z,4636
RNiftyReg,"Provides an 'R' interface to the 'NiftyReg' image registration tools
    <http://sourceforge.net/projects/niftyreg/>. Linear and nonlinear registration
    are supported, in two and three dimensions.",2020-04-01,Jon Clayden,https://github.com/jonclayden/RNiftyReg,TRUE,https://github.com/jonclayden/rniftyreg,34362,25,2020-04-05T18:16:01Z,1374.48
Rnmr1D,Perform the complete processing of a set of proton nuclear magnetic resonance spectra from the free induction decay (raw data) and based on a processing sequence (macro-command file). An additional file specifies all the spectra to be considered by associating their sample code as well as the levels of experimental factors to which they belong. More detail can be found in Jacob et al. (2017) <doi:10.1007/s11306-017-1178-y>.,2019-12-06,Daniel Jacob,https://github.com/INRA/Rnmr1D,TRUE,https://github.com/inra/rnmr1d,6537,5,2020-01-17T09:13:14Z,1307.4
rnn,"Implementation of a Recurrent Neural Network architectures in native R, including Long Short-Term Memory (Hochreiter and Schmidhuber, <doi:10.1162/neco.1997.9.8.1735>), Gated Recurrent Unit (Chung et al., <arXiv:1412.3555>) and vanilla RNN.",2019-05-27,Bastiaan Quast,"http://qua.st/rnn, https://github.com/bquast/rnn",TRUE,https://github.com/bquast/rnn,37357,58,2020-04-25T10:02:52Z,644.0862068965517
rnoaa,"Client for many 'NOAA' data sources including the 'NCDC' climate
    'API' at <https://www.ncdc.noaa.gov/cdo-web/webservices/v2>, with functions for
    each of the 'API' 'endpoints': data, data categories, data sets, data types,
    locations, location categories, and stations. In addition, we have an interface
    for 'NOAA' sea ice data, the 'NOAA' severe weather inventory, 'NOAA' Historical
    Observing 'Metadata' Repository ('HOMR') data, 'NOAA' storm data via 'IBTrACS',
    tornado data via the 'NOAA' storm prediction center, and more.",2020-04-07,Scott Chamberlain,"https://docs.ropensci.org/rnoaa (website),
https://github.com/ropensci/rnoaa (devel)",TRUE,https://github.com/ropensci/rnoaa,135607,247,2020-06-08T21:53:23Z,549.0161943319838
rnrfa,"Utility functions to retrieve data from the UK National River Flow Archive (<http://nrfa.ceh.ac.uk/>, terms and conditions: <http://nrfa.ceh.ac.uk/costs-terms-and-conditions>). The package contains R wrappers to the UK NRFA data temporary-API. There are functions to retrieve stations falling in a bounding box, to generate a map and extracting time series and general information.",2020-05-25,Claudia Vitolo,http://cvitolo.github.io/rnrfa/,TRUE,https://github.com/cvitolo/rnrfa,27276,9,2020-05-25T09:43:15Z,3030.6666666666665
Rnumerai,"Routines to interact with the Numerai Machine Learning Tournament
  API <https://numer.ai>. The functionality includes the ability to automatically download the
  current tournament data, submit predictions, and to get information for your
  user. General 'GraphQL' queries can also be executed.",2020-04-18,Eric Hare,https://github.com/Omni-Analytics-Group/Rnumerai,TRUE,https://github.com/omni-analytics-group/rnumerai,8577,18,2020-05-18T11:32:53Z,476.5
roadoi,"This web client interfaces Unpaywall <https://unpaywall.org/products/api>, formerly
    oaDOI, a service finding free full-texts of academic papers by linking DOIs with 
    open access journals and repositories. It provides unified access to various data sources 
    for open access full-text links including Crossref and the Directory of Open Access 
    Journals (DOAJ). API usage is free and no registration is required.",2019-09-15,Najko Jahn,https://github.com/ropensci/roadoi,TRUE,https://github.com/ropensci/roadoi,14294,38,2020-06-03T09:07:35Z,376.1578947368421
roben,"Gene-environment (G×E) interactions have important implications to elucidate the 
    etiology of complex diseases beyond the main genetic and environmental effects. 
    Outliers and data contamination in disease phenotypes of G×E studies have been commonly 
    encountered, leading to the development of a broad spectrum of robust penalization methods. 
    Nevertheless, within the Bayesian framework, the issue has not been taken care of in existing 
    studies. We develop a robust Bayesian variable selection method for G×E interaction 
    studies. The proposed Bayesian method can effectively accommodate heavy-tailed errors and 
    outliers in the response variable while conducting variable selection by accounting for 
    structural sparsity. In particular, the spike-and-slab priors have been imposed on both 
    individual and group levels to identify important main and interaction effects. An efficient 
    Gibbs sampler has been developed to facilitate fast computation. The Markov chain Monte Carlo 
    algorithms of the proposed and alternative methods are efficiently implemented in C++.",2020-05-11,Jie Ren,https://github.com/jrhub/roben,TRUE,https://github.com/jrhub/roben,392,0,2020-06-05T02:00:33Z,NA
robin,"Assesses the robustness of the community structure of a network found by one or more community detection algorithm to give indications about their reliability. It detects if the community structure found by a set of algorithms is statistically significant and compares the different selected detection algorithms on the same network. robin helps to choose among different community detection algorithms the one that better fits the network of interest. Reference in Annamaria Carissimo, Luisa Cutillo, Italia De Feis (2018) <doi:10.1016/j.csda.2017.10.006>.",2020-05-18,Valeria Policastro,https://github.com/ValeriaPolicastro/robin,TRUE,https://github.com/valeriapolicastro/robin,2176,1,2020-06-08T10:42:38Z,2176
RobinHood,"Execute API calls to the RobinHood <https://robinhood.com> investing platform. Functionality includes accessing account data and current holdings, retrieving investment statistics and quotes, placing and canceling orders, getting market trading hours, searching investments by popular tag, and interacting with watch lists.",2020-05-23,Joseph Blubaugh,https://github.com/JestonBlu/RobinHood,TRUE,https://github.com/jestonblu/robinhood,7349,19,2020-05-23T13:40:03Z,386.7894736842105
robis,Client for the Ocean Biogeographic Information System (<https://obis.org>).,2019-06-03,Pieter Provoost,https://github.com/iobis/robis,TRUE,https://github.com/iobis/robis,12517,19,2020-05-27T13:52:53Z,658.7894736842105
RobMixReg,"Finite mixture models are a popular technique for modelling unobserved heterogeneity or to approximate general distribution functions in a semi-parametric way. They are used in a lot of different areas such as astronomy, biology, economics, marketing or medicine.
             This package is the implementation of popular robust mixture regression methods based on different algorithms including: fleximix, finite mixture models and latent class regression; CTLERob, component-wise adaptive trimming likelihood estimation; mixbi, bi-square estimation; mixL, Laplacian distribution; mixt, t-distribution; TLE, trimmed likelihood estimation.
             The implemented algorithms includes:  CTLERob stands for Component-wise adaptive Trimming Likelihood Estimation based mixture regression; mixbi stands for mixture regression based on bi-square estimation; mixLstands for mixture regression based on Laplacian distribution; TLE stands for Trimmed Likelihood Estimation based mixture regression. For more detail of the algorithms, please refer to below references. 
             Reference: Chun Yu, Weixin Yao, Kun Chen (2017) <doi:10.1002/cjs.11310>.
             NeyKov N, Filzmoser P, Dimova R et al. (2007) <doi:10.1016/j.csda.2006.12.024>.
             Bai X, Yao W. Boyer JE (2012) <doi:10.1016/j.csda.2012.01.016>.
             Wennan Chang, Xinyu Zhou, Yong Zang, Chi Zhang, Sha Cao (2020) <arXiv:2005.11599>.",2020-06-08,Wennan Chang,https://changwn.github.io/RobMixReg/,TRUE,https://github.com/changwn/robmixreg,1217,0,2020-06-09T05:51:13Z,NA
robotstxt,"Provides functions to download and parse 'robots.txt' files.
        Ultimately the package makes it easy to check if bots
        (spiders, crawler, scrapers, ...) are allowed to access specific
        resources on a domain.",2020-05-31,Peter Meissner,"https://docs.ropensci.org/robotstxt,
https://github.com/ropensci/robotstxt",TRUE,https://github.com/ropensci/robotstxt,28034,50,2020-06-07T21:24:58Z,560.68
robregcc,"We implement the algorithm estimating the parameters of the robust regression model with compositional covariates. The model simultaneously treats outliers and provides reliable parameter  estimates. Publication reference: Mishra, A., Mueller, C.,(2019) <arXiv:1909.04990>.  ",2019-10-14,Aditya Mishra,"https://arxiv.org/abs/1909.04990,
https://github.com/amishra-simonsfoundation/robregcc",TRUE,https://github.com/amishra-simonsfoundation/robregcc,2536,2,2019-10-13T15:11:40Z,1268
robsurvey,"Multiple functions to compute robust survey statistics. The package 
    supports the computations of robust means, totals, and ratios. Available 
    methods are Huber M-estimators, trimming, and winsorization. The package 
    'robsurvey' complements the 'survey' package. The package additionally 
    includes a weighted version of the resistant line function of base R (line()), 
    as well as two median based simple regression estimators. The methods are 
    described in Hulliger (1995) 
    <https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X199500114407/>.",2019-06-11,Martin Sterchi,https://github.com/martinSter/robsurvey,TRUE,https://github.com/martinster/robsurvey,3753,0,2019-10-11T15:37:22Z,NA
robustSingleCell,"Robust single cell clustering and comparison of population compositions across tissues and 
  experimental models via similarity analysis from Magen 2019 <doi:10.1101/543199>. ",2019-04-23,Assaf Magen,https://github.com/asmagen/robustSingleCell,TRUE,https://github.com/asmagen/robustsinglecell,4183,8,2019-12-19T12:24:04Z,522.875
robvis,"Helps users in quickly visualizing risk-of-bias 
    assessments performed as part of a systematic review. It allows users to 
    create weighted bar-plots of the distribution of risk-of-bias judgments 
    within each bias domain, in addition to traffic-light plots of the 
    specific domain-level judgments for each study. The resulting figures are 
    of publication quality and are formatted according the risk-of-bias 
    assessment tool use to perform the assessments. Currently, the supported 
    tools are ROB2.0 (for randomized controlled trials; Sterne et al (2019)  
    <doi:10.1136/bmj.l4898>), ROBINS-I (for non-randomised studies of 
    interventions; Sterne et al (2016) <doi:10.1136/bmj.i4919>), and QUADAS-2 
    (for diagnostic accuracy studies; Whiting et al (2011) 
    <doi:10.7326/0003-4819-155-8-201110180-00009>).",2019-11-22,Luke McGuinness,https://github.com/mcguinlu/robvis,TRUE,https://github.com/mcguinlu/robvis,4465,10,2020-05-21T09:58:44Z,446.5
ROCR,"ROC graphs, sensitivity/specificity curves, lift charts,
  and precision/recall plots are popular examples of trade-off
  visualizations for specific pairs of performance measures. ROCR is a
  flexible tool for creating cutoff-parameterized 2D performance curves
  by freely combining two from over 25 performance measures (new
  performance measures can be added using a standard interface).
  Curves from different cross-validation or bootstrapping runs can be
  averaged by different methods, and standard deviations, standard
  errors or box plots can be used to visualize the variability across
  the runs. The parameterization can be visualized by printing cutoff
  values at the corresponding curve positions, or by coloring the
  curve according to cutoff. All components of a performance plot can
  be quickly adjusted using a flexible parameter dispatching
  mechanism. Despite its flexibility, ROCR is easy to use, with only
  three commands and reasonable default values for all optional
  parameters.",2020-05-02,Felix G.M. Ernst,http://ipa-tys.github.io/ROCR/,TRUE,https://github.com/ipa-tys/rocr,2689932,16,2020-05-01T11:51:46Z,168120.75
Rodam,"'ODAM' (Open Data for Access and Mining) is a framework that implements a simple way to make research data broadly accessible and fully available for reuse, including by a script language such as R. The main purpose is to make a data set accessible online with a minimal effort from the data provider, and to allow any scientists or bioinformaticians to be able to explore the data set and then extract a subpart or the totality of the data according to their needs. The Rodam package has only one class, 'odamws', that provides methods to allow you to retrieve online data using 'ODAM' Web Services. This obviously requires that data are implemented according the 'ODAM' approach , namely that the data subsets were deposited in the suitable data repository in the form of TSV files associated with  their metadata also described  in TSV files. See <http://www.slideshare.net/danieljacob771282/odam-open-data-access-and-mining>.",2019-03-21,Daniel Jacob,https://github.com/INRA/ODAM,TRUE,https://github.com/inra/odam,10515,2,2020-06-06T15:52:04Z,5257.5
rodeo,"Provides an R6 class and several utility methods to
    facilitate the implementation of models based on ordinary
    differential equations. The heart of the package is a code generator
    that creates compiled 'Fortran' (or 'R') code which can be passed to
    a numerical solver. There is direct support for solvers contained
    in packages 'deSolve' and 'rootSolve'.",2020-06-02,David Kneis,https://github.com/dkneis/rodeo,TRUE,https://github.com/dkneis/rodeo,12910,5,2020-06-02T10:10:16Z,2582
roll,Fast and efficient computation of rolling statistics for time-series data.,2020-01-17,Jason Foster,https://github.com/jjf234/roll,TRUE,https://github.com/jjf234/roll,65784,58,2020-06-08T01:17:07Z,1134.2068965517242
rollmatch,"Functions to perform propensity score matching on rolling entry interventions for which a suitable ""entry"" date is not observed for nonparticipants. For more details, please reference Witman et al. (2018) <https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-6773.13086>.",2020-06-02,Rob Chew,https://github.com/RTIInternational/rollmatch,TRUE,https://github.com/rtiinternational/rollmatch,8393,5,2020-06-02T13:57:17Z,1678.6
rollRegres,"Methods for fast rolling and expanding linear regression models. That is, series of linear regression models estimated on either an expanding window of data or a moving window of data. The methods use rank-one updates and downdates of the upper triangular matrix from a QR decomposition (see Dongarra, Moler, Bunch, and Stewart (1979) <doi:10.1137/1.9781611971811>).",2019-11-25,Benjamin Christoffersen,https://github.com/boennecd/rollRegres,TRUE,https://github.com/boennecd/rollregres,11274,7,2020-01-30T08:24:11Z,1610.5714285714287
rolypoly,"Using enrichment of genome-wide association summary statistics to
  identify trait-relevant cellular functional annotations.",2017-03-16,Diego Calderon,https://github.com/dcalderon/rolypoly,TRUE,https://github.com/dcalderon/rolypoly,9020,10,2019-09-14T17:30:10Z,902
ROMDB,"Load multiple movies, series, actors, directors etc from 'OMDB' API. More information in: <http://www.omdbapi.com/> .",2020-01-14,Alberto Almuiña,https://github.com/AlbertoAlmuinha/ROMDB,TRUE,https://github.com/albertoalmuinha/romdb,2063,1,2020-01-20T13:40:58Z,2063
rootWishart,"Functions for hypothesis testing in single and double Wishart
    settings, based on Roy's largest root. This test statistic is especially
    useful in multivariate analysis. The computations are based on results by
    Chiani (2014) <DOI:10.1016/j.jmva.2014.04.002> and Chiani (2016)
    <DOI:10.1016/j.jmva.2015.10.007>. They use the fact that the CDF is related
    to the Pfaffian of a matrix that can be computed in a finite number of
    iterations. This package takes advantage of the Boost and Eigen C++ libraries
    to perform multi-precision linear algebra.",2018-03-17,Maxime Turgeon,http://github.com/turgeonmaxime/rootWishart,TRUE,https://github.com/turgeonmaxime/rootwishart,10813,1,2020-06-01T20:15:54Z,10813
ropenaq,"Allows access to air quality data from the API of
    the OpenAQ platform <https://docs.openaq.org/>, with the different
    services the API offers (getting measurements for a given query,
    getting latest measurements, getting lists of available
    countries/cities/locations). ",2020-03-26,Maëlle Salmon,"https://docs.ropensci.org/ropenaq,
http://github.com/ropensci/ropenaq",TRUE,https://github.com/ropensci/ropenaq,19117,54,2020-05-11T13:50:00Z,354.01851851851853
ropenblas,"The 'ropenblas' package (<https://prdm0.github.io/ropenblas/>) is useful for users of any 'GNU/Linux' distribution. It will be possible to download, compile and link the 'OpenBLAS' library (<https://www.openblas.net/>) with the R language, always by the same procedure, regardless of the 'GNU/Linux' distribution used. With the 'ropenblas' package it is possible to download, compile and link the latest version of the 'OpenBLAS' library even the repositories of the 'GNU/Linux' distribution used do not include the latest versions of 'OpenBLAS'. If of interest, older versions of the 'OpenBLAS' library may be considered. Linking R with an optimized version of 'BLAS' (<http://www.netlib.org/blas/>) may improve the computational performance of R code. The 'OpenBLAS' library is an optimized implementation of 'BLAS' that can be easily linked to R with the 'ropenblas' package.    ",2020-05-23,Pedro Rafael D. Marinho,"https://prdm0.github.io/ropenblas/,
https://github.com/prdm0/ropenblas",TRUE,https://github.com/prdm0/ropenblas,3743,17,2020-05-23T02:01:11Z,220.1764705882353
ROpenCVLite,"Installs 'OpenCV' for use by other packages. 'OpenCV' <https://opencv.org/> 
    is library of programming functions mainly aimed at real-time computer 
    vision. This 'Lite' version contains the stable base version of 'OpenCV' and 
    does not contain any of its externally contributed modules.",2020-06-06,Simon Garnier,"https://swarm-lab.github.io/ROpenCVLite/,
https://github.com/swarm-lab/ROpenCVLite",TRUE,https://github.com/swarm-lab/ropencvlite,4896,37,2020-06-06T14:33:08Z,132.32432432432432
Ropj,"Read the data from Origin(R) project files ('*.opj')
	<https://www.originlab.com/doc/User-Guide/Origin-File-Types>.
	No write support is planned.",2020-03-14,Ivan Krylov,https://github.com/aitap/Ropj,TRUE,https://github.com/aitap/ropj,5303,0,2020-04-12T08:51:55Z,NA
roptim,"Perform general purpose optimization in R using C++. A unified 
    wrapper interface is provided to call C functions of the five optimization 
    algorithms ('Nelder-Mead', 'BFGS', 'CG', 'L-BFGS-B' and 'SANN') underlying 
    optim().",2020-04-02,Yi Pan,https://github.com/ypan1988/roptim/,TRUE,https://github.com/ypan1988/roptim,8135,7,2020-04-02T09:20:32Z,1162.142857142857
rorcid,"Client for the 'Orcid.org' API (<https://orcid.org/>).
    Functions included for searching for people, searching by 'DOI',
    and searching by 'Orcid' 'ID'.",2020-02-06,Scott Chamberlain,"https://github.com/ropensci/rorcid (devel),
https://docs.ropensci.org/rorcid (docs)",TRUE,https://github.com/ropensci/rorcid,19381,90,2020-05-26T18:31:27Z,215.34444444444443
rosm,"Download and plot Open Street Map <http://www.openstreetmap.org/>,
    Bing Maps <http://www.bing.com/maps> and other tiled map sources. Use to create 
    basemaps quickly and add hillshade to vector-based maps.",2019-07-22,Dewey Dunnington,https://github.com/paleolimbot/rosm,TRUE,https://github.com/paleolimbot/rosm,98842,17,2019-07-22T01:04:25Z,5814.235294117647
rosr,"Creates reproducible academic projects with integrated academic elements, including datasets, references, codes, images, manuscripts, dissertations, slides and so on. These elements are well connected so that they can be easily synchronized and updated. ",2020-05-11,Peng Zhao,https://github.com/pzhaonet/rosr,TRUE,https://github.com/pzhaonet/rosr,4113,18,2020-05-07T11:47:23Z,228.5
rotasym,"Implementation of the tests for rotational symmetry on the
     hypersphere proposed in García-Portugués, Paindaveine and Verdebout
     (2020) <doi:10.1080/01621459.2019.1665527>. The package also implements the proposed
     distributions on the hypersphere, based on the tangent-normal
     decomposition, and allows for the replication of the data
     application considered in the paper.",2020-03-09,Eduardo García-Portugués,https://github.com/egarpor/rotasym,TRUE,https://github.com/egarpor/rotasym,4215,0,2020-03-08T23:10:09Z,NA
rotations,"Tools for working with rotational data, including
    simulation from the most commonly used distributions on SO(3),
    methods for different Bayes, mean and median type estimators for
    the central orientation of a sample, confidence/credible
    regions for the central orientation based on those estimators and
    a novel visualization technique for rotation data.  Most recently,
    functions to identify potentially discordant (outlying) values
    have been added.  References: Bingham, Melissa A. and Nordman, Dan J. and Vardeman, Steve B. (2009) <doi:10.1198/jasa.2009.ap08741>,
    Bingham, Melissa A and Vardeman, Stephen B and Nordman, Daniel J (2009) <doi:10.1214/09-BA423>,
    Bingham, Melissa A and Nordman, Daniel J and Vardeman, Stephen B (2010) <doi:10.1016/j.csda.2009.11.020>,
    Leon, C.A. and Masse, J.C. and Rivest, L.P. (2006) <doi:10.1016/j.jmva.2005.03.009>,
    Hartley, R and Aftab, K and Trumpf, J. (2011) <doi:10.1109/CVPR.2011.5995745>,
    Stanfill, Bryan and Genschel, Ulrike and Hofmann, Heike (2013) <doi:10.1080/00401706.2013.826145>,
    Maonton, Jonathan (2004) <doi:10.1109/ICARCV.2004.1469774>, 
    Mardia, KV and Jupp, PE (2000, ISBN:9780471953333), 
    Rancourt, D. and Rivest, L.P. and Asselin, J. (2000) <doi:10.1111/1467-9876.00180>,
    Chang, Ted and Rivest, Louis-Paul (2001) <doi:10.1214/aos/1009210690>, 
    Fisher, Nicholas I. (1996, ISBN:0521568900).",2020-04-03,Bryan Stanfill,https://github.com/stanfill/rotationsC,TRUE,https://github.com/stanfill/rotationsc,16731,0,2020-04-02T13:26:10Z,NA
rotl,"An interface to the 'Open Tree of Life' API to retrieve
    phylogenetic trees, information about studies used to assemble the
    synthetic tree, and utilities to match taxonomic names to 'Open Tree
    identifiers'. The 'Open Tree of Life' aims at assembling a
    comprehensive phylogenetic tree for all named species.",2019-09-28,Francois Michonneau,https://github.com/ropensci/rotl,TRUE,https://github.com/ropensci/rotl,128416,26,2020-06-02T09:19:35Z,4939.076923076923
rotor,"Conditionally rotate or back-up files based on
    their size or the date of the last backup; inspired by the 'Linux'
    utility 'logrotate'.",2020-01-07,Stefan Fleck,https://s-fleck.github.io/rotor/,TRUE,https://github.com/s-fleck/rotor,5944,9,2020-01-28T08:32:33Z,660.4444444444445
RoughSets,"Implementations of algorithms for data analysis based on the
    rough set theory (RST) and the fuzzy rough set theory (FRST). We not only
    provide implementations for the basic concepts of RST and FRST but also
    popular algorithms that derive from those theories. The methods included in the
    package can be divided into several categories based on their functionality:
    discretization, feature selection, instance selection, rule induction and
    classification based on nearest neighbors. RST was introduced by Zdzisław
    Pawlak in 1982 as a sophisticated mathematical tool to model and process
    imprecise or incomplete information. By using the indiscernibility relation for
    objects/instances, RST does not require additional parameters to analyze the
    data. FRST is an extension of RST. The FRST combines concepts of vagueness and
    indiscernibility that are expressed with fuzzy sets (as proposed by Zadeh, in
    1965) and RST.",2019-12-15,Andrzej Janusz,https://github.com/janusza/RoughSets,TRUE,https://github.com/janusza/roughsets,29888,17,2020-01-25T18:44:43Z,1758.1176470588234
roundhouse,"An R wrapper to the 'Internet Chuck Norris database' ('ICNDb') API for 
  generating random Chuck Norris facts.",2018-09-16,Brandon Greenwell,ttps://github.com/bgreenwell/roundhouse,TRUE,https://github.com/bgreenwell/roundhouse,6074,3,2019-09-14T19:11:11Z,2024.6666666666667
roxygen2,"Generate your Rd documentation, 'NAMESPACE' file,
    and collation field using specially formatted comments. Writing
    documentation in-line with code makes it easier to keep your
    documentation up-to-date as your requirements change. 'Roxygen2' is
    inspired by the 'Doxygen' system for C++.",2020-03-11,Hadley Wickham,"https://roxygen2.r-lib.org/, https://github.com/r-lib/roxygen2",TRUE,https://github.com/r-lib/roxygen2,4594996,393,2020-05-28T18:22:30Z,11692.101781170484
roxygen2md,"Converts elements of 'roxygen' documentation to
    'markdown'.",2019-06-17,Kirill Müller,"https://roxygen2md.r-lib.org, https://github.com/r-lib/roxygen2md",TRUE,https://github.com/r-lib/roxygen2md,4704,61,2020-03-02T10:47:58Z,77.11475409836065
roxytest,"Various tests as 'roxygen2' roclets: e.g. 'testthat' and 'tinytest' tests. 
  Also other static analysis tools as checking parameter documentation consistency and others.",2020-06-03,Mikkel Meyer Andersen,NA,TRUE,https://github.com/mikldk/roxytest,0,83,2020-06-03T17:30:11Z,0
rPackedBar,Packed bar charts are a variation of treemaps for visualizing skewed data.  The concept was introduced by Xan Gregg at 'JMP'.,2019-06-17,Adam Spannbauer,https://github.com/AdamSpannbauer/rPackedBar,TRUE,https://github.com/adamspannbauer/rpackedbar,7900,1,2019-06-16T13:59:11Z,7900
RPANDA,"Implements macroevolutionary analyses on phylogenetic trees. See
    Morlon et al. (2010) <DOI:10.1371/journal.pbio.1000493>, Morlon et al. (2011)
    <DOI:10.1073/pnas.1102543108>, Condamine et al. (2013) <DOI:10.1111/ele.12062>, 
    Morlon et al. (2014) <DOI:10.1111/ele.12251>, Manceau et al. (2015) <DOI:10.1111/ele.12415>,
    Lewitus & Morlon (2016) <DOI:10.1093/sysbio/syv116>, Drury et al. (2016) <DOI:10.1093/sysbio/syw020>,
    Manceau et al. (2016) <DOI:10.1093/sysbio/syw115>, Morlon et al. (2016) <DOI:10.1111/2041-210X.12526>, Clavel & Morlon (2017) <DOI:10.1073/pnas.1606868114>, 
    Drury et al. (2017) <DOI:10.1093/sysbio/syx079>, Lewitus & Morlon (2017) <DOI:10.1093/sysbio/syx095>, 
    Drury et al. (2018) <DOI:10.1371/journal.pbio.2003563>, Clavel et al. (2019) <DOI:10.1093/sysbio/syy045>, Maliet et al. (2019) <DOI:10.1038/s41559-019-0908-0>, Billaud et al. (2019) <DOI:10.1093/sysbio/syz057>, Lewitus et al. (2019) <DOI:10.1093/sysbio/syz061>, and Aristide & Morlon (2019) <DOI:10.1111/ele.13385>.",2020-03-06,Hélène Morlon,https://github.com/hmorlon/PANDA,TRUE,https://github.com/hmorlon/panda,22561,14,2020-05-07T08:15:34Z,1611.5
rpart,"Recursive partitioning for classification, 
  regression and survival trees.  An implementation of most of the 
  functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.",2019-04-12,Beth Atkinson,"https://github.com/bethatkinson/rpart,
https://cran.r-project.org/package=rpart",TRUE,https://github.com/bethatkinson/rpart,3121962,14,2020-05-18T20:35:58Z,222997.2857142857
rpdo,"Monthly Pacific Decadal Oscillation (PDO) index
    values from January 1900 to present.",2020-03-04,Joe Thorley,https://github.com/poissonconsulting/rpdo,TRUE,https://github.com/poissonconsulting/rpdo,18050,1,2020-05-08T01:16:36Z,18050
RPEXE.RPEXT,"This reduced piecewise exponential survival software implements the likelihood ratio test and backward elimination procedure in Han, Schell, and Kim (2012 <doi:10.1080/19466315.2012.698945>, 2014 <doi:10.1002/sim.5915>), and Han et al. (2016 <doi:10.1111/biom.12590>). Inputs to the program can be either times when events/censoring occur or the vectors of total time on test and the number of events. Outputs of the programs are times and the corresponding p-values in the backward elimination. Details about the model and implementation are given in Han et al. 2014. This program can run in R version 3.2.2 and above.",2020-05-21,Gang Han,https://github.com/hangangtrue/RPEXE.RPEXT,TRUE,https://github.com/hangangtrue/rpexe.rpext,8357,1,2020-05-22T22:29:17Z,8357
rpf,"The purpose of this package is to factor out logic
    and math common to Item Factor Analysis fitting, diagnostics, and
    analysis. It is envisioned as core support code suitable for more
    specialized IRT packages to build upon. Complete access to optimized C
    functions are made available with R_RegisterCCallable().",2020-05-07,Joshua Pritikin,https://github.com/jpritikin/rpf,TRUE,https://github.com/jpritikin/rpf,351075,0,2020-02-18T12:03:46Z,NA
rpg,"Allows ad hoc queries and reading and
    writing data frames to and from a database.",2017-10-29,Timothy H. Keitt,"http://github.com/thk686/rpg, http://www.keittlab.org/",TRUE,https://github.com/thk686/rpg,15721,14,2019-09-05T19:32:25Z,1122.9285714285713
rphylopic,"Work with 'Phylopic' web service (<http://phylopic.org/api/>) 
    to get 'silhouette' images of 'organisms', search names, and more.
    Includes functions for adding 'silhouettes' to both base plots and
    ggplot2 plots.",2020-06-04,Scott Chamberlain,https://github.com/sckott/rphylopic,TRUE,https://github.com/sckott/rphylopic,6017,67,2020-06-06T14:59:52Z,89.80597014925372
rpmodel,"Implements the P-model (Stocker et al., 2019 <doi:10.5194/gmd-2019-200>), predicting acclimated parameters of the enzyme kinetics of C3 photosynthesis, assimilation, and dark respiration rates as a function of the environment (temperature, CO2, vapour pressure deficit, light, atmospheric pressure).",2019-12-04,Benjamin Stocker,https://github.com/stineb/rpmodel,TRUE,https://github.com/stineb/rpmodel,2834,12,2020-05-18T14:25:13Z,236.16666666666666
Rpolyhedra,A polyhedra database scraped from various sources as R6 objects and 'rgl' visualizing capabilities.,2019-03-26,Alejandro Baranek,https://github.com/ropensci/Rpolyhedra,TRUE,https://github.com/ropensci/rpolyhedra,11507,8,2020-05-20T01:22:45Z,1438.375
rpostgis,"Provides an interface between R and 'PostGIS'-enabled
    'PostgreSQL' databases to transparently transfer spatial
    data. Both vector (points, lines, polygons) and raster data are
    supported in read and write modes. Also provides convenience
    functions to execute common procedures in 'PostgreSQL/PostGIS'.",2019-11-20,David Bucklin,https://mablab.org/rpostgis/index.html,TRUE,https://github.com/mablab/rpostgis,31649,53,2019-11-24T20:30:16Z,597.1509433962265
rpostgisLT,"Integrates R and the 'PostgreSQL/PostGIS' database 
    system to build and manage animal trajectory (movement) data sets. 
    The package relies on 'ltraj' objects from the R package 'adehabitatLT',
    building the analogous 'pgtraj' data structure in 'PostGIS'. Functions
    allow users to seamlessly transfer between 'ltraj' and 'pgtraj', as
    well as build new 'pgtraj' directly from location data stored in the 
    database.",2018-03-02,Balázs Dukai,https://github.com/mablab/rpostgisLT,TRUE,https://github.com/mablab/rpostgislt,10410,9,2020-05-08T07:41:43Z,1156.6666666666667
RPostgres,"Fully 'DBI'-compliant 'Rcpp'-backed interface to
    'PostgreSQL' <https://www.postgresql.org/>, an open-source relational
    database.",2019-12-18,Kirill Müller,"https://rpostgres.r-dbi.org, https://github.com/r-dbi/RPostgres",TRUE,https://github.com/r-dbi/rpostgres,317252,206,2020-04-26T02:55:22Z,1540.0582524271845
rPraat,"Read, write and manipulate 'Praat' TextGrid, PitchTier, Pitch, IntensityTier, Formant, Sound, and Collection files <http://www.fon.hum.uva.nl/praat/>.",2020-04-04,Tomas Boril,https://github.com/bbTomas/rPraat/,TRUE,https://github.com/bbtomas/rpraat,11185,12,2020-04-04T21:52:32Z,932.0833333333334
rpredictit,"Wrapper to retrieve market data, explore available markets, and plot historical price data from the 'PredictIt' public API (<https://www.predictit.org/api/marketdata/all/>).
    The package comes with a demo 'shiny' application for illustrating example use cases.
    License to use data made available via the API is for non-commercial use and 'PredictIt' is the sole source of such data.",2020-03-18,Daniel Kovtun,https://github.com/danielkovtun/rpredictit,TRUE,https://github.com/danielkovtun/rpredictit,2008,0,2020-03-18T01:33:25Z,NA
RPresto,"Implements a 'DBI' compliant interface to Presto. Presto is
    an open source distributed SQL query engine for running interactive
    analytic queries against data sources of all sizes ranging from
    gigabytes to petabytes: <https://prestodb.io/>.",2019-10-18,Onur Ismail Filiz,https://github.com/prestodb/RPresto,TRUE,https://github.com/prestodb/rpresto,39011,105,2019-10-22T17:57:13Z,371.53333333333336
rprev,"Estimates disease prevalence for a given index date, using existing
    registry data extended with Monte Carlo simulations.",2020-03-20,Stuart Lacy,https://github.com/stulacy/rprev-dev,TRUE,https://github.com/stulacy/rprev-dev,13347,0,2020-03-22T18:43:47Z,NA
rprime,"'Eprime' is a set of programs for administering psychological
    experiments by computer. This package provides functions for loading,
    parsing, filtering and exporting data in the text files produced by
    'Eprime' experiments.",2015-05-29,Tristan Mahr,http://github.com/tjmahr/rprime,TRUE,https://github.com/tjmahr/rprime,14796,15,2019-08-05T18:44:53Z,986.4
RProtoBuf,"Protocol Buffers are a way of encoding structured data in an
 efficient yet extensible format. Google uses Protocol Buffers for almost all
 of its internal 'RPC' protocols and file formats.  Additional documentation
 is available in two included vignettes one of which corresponds to our 'JSS'
 paper (2016, <doi:10.18637/jss.v071.i02>. Either version 2 or 3 of the
 'Protocol Buffers' 'API' is supported.",2020-03-28,Romain Francois,https://github.com/eddelbuettel/rprotobuf,TRUE,https://github.com/eddelbuettel/rprotobuf,60145,50,2020-05-29T00:15:34Z,1202.9
rpubchem,"Access PubChem data (compounds, substance, assays) using R.
 Structural information is provided in the form of SMILES strings. 
 It currently only provides access to a subset of the 
 precalculated data stored by PubChem. Bio-assay data can be accessed to 
 obtain descriptions as well as the actual data. It is also possible to search for assay ID's by keyword. ",2016-12-27,Rajarshi Guha,"https://github.com/rajarshi/cdkr,
https://pubchem.ncbi.nlm.nih.gov/",TRUE,https://github.com/rajarshi/cdkr,20428,30,2020-03-16T02:38:29Z,680.9333333333333
rpubs,Extract code only or with the output from an Rpubs <https://rpubs.com/> article and write the code-block to R script file.,2020-02-05,Aep Hidayatuloh,https://github.com/aephidayatuloh/rpubs,TRUE,https://github.com/aephidayatuloh/rpubs,1943,1,2020-03-28T15:13:53Z,1943
RPyGeo,"Provides access to ArcGIS geoprocessing tools by building an 
             interface between R and the ArcPy Python side-package via the 
             reticulate package. ",2018-11-14,Alexander Brenning,https://github.com/fapola/RPyGeo,TRUE,https://github.com/fapola/rpygeo,19337,19,2020-04-05T08:20:52Z,1017.7368421052631
rQCC,"Constructs robust quality control chart based on the median or Hodges-Lehmann estimator (location) and the median absolute deviation (MAD) or Shamos estimator (scale). These estimators are all unbiased with a sample of finite size. For more details, see Park, Kim and Wang (2020) <doi:10.1080/03610918.2019.1699114>. This work was partially supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (NRF-2017R1A2B4004169).",2020-03-01,Chanseok Park,https://github.com/AppliedStat/R,TRUE,https://github.com/appliedstat/r,5171,1,2020-03-01T08:04:50Z,5171
rqdatatable,"Implements the 'rquery' piped Codd-style query algebra using 'data.table'.  This allows
   for a high-speed in memory implementation of Codd-style data manipulation tools.",2020-02-11,John Mount,"https://github.com/WinVector/rqdatatable/,
https://winvector.github.io/rqdatatable/",TRUE,https://github.com/winvector/rqdatatable,29177,30,2020-02-28T06:54:39Z,972.5666666666667
RQuantLib,"The 'RQuantLib' package makes parts of 'QuantLib' accessible from R
 The 'QuantLib' project aims to provide a comprehensive software framework
 for quantitative finance. The goal is to provide a standard open source library
 for quantitative analysis, modeling, trading, and risk management of financial
 assets.",2020-04-02,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rquantlib.html,TRUE,https://github.com/eddelbuettel/rquantlib,103772,79,2020-04-02T12:03:10Z,1313.5696202531647
Rquefts,"An implementation of the QUEFTS (Quantitative Evaluation of the Native Fertility of Tropical Soils) model. The model (1) estimates native nutrient (N, P, K) supply of soils from a few soil chemical properties; and (2) computes crop yield given that supply, fertilizer application and crop parameters. See Janssen et al. (1990) <doi:10.1016/0016-7061(90)90021-Z> for the technical details and Sattari et al. (2014) <doi:10.1016/j.fcr.2013.12.005> for a recent evaluation and improvements.",2020-03-13,Robert J. Hijmans,https://github.com/cropmodels/Rquefts/,TRUE,https://github.com/cropmodels/rquefts,3037,0,2020-04-20T01:03:05Z,NA
rquery,"A piped query generator based on Edgar F. Codd's relational
    algebra, and on production experience using 'SQL' and 'dplyr' at big data
    scale.  The design represents an attempt to make 'SQL' more teachable by
    denoting composition by a sequential pipeline notation instead of nested
    queries or functions.   The implementation delivers reliable high 
    performance data processing on large data systems such as 'Spark',
    databases, and 'data.table'. Package features include: data processing trees
    or pipelines as observable objects (able to report both columns
    produced and columns used), optimized 'SQL' generation as an explicit
    user visible table modeling step, plus explicit query reasoning and checking.",2020-02-18,John Mount,"https://github.com/WinVector/rquery/,
https://winvector.github.io/rquery/",TRUE,https://github.com/winvector/rquery,69957,96,2020-03-13T13:17:11Z,728.71875
rr2,"Three methods to calculate R2 for models with correlated errors, 
    including Phylogenetic GLS, Phylogenetic Logistic Regression, Linear Mixed 
    Models (LMMs), and Generalized Linear Mixed Models (GLMMs). See details in 
    Ives 2018 <doi:10.1093/sysbio/syy060>.",2019-05-09,Anthony Ives,https://github.com/arives/rr2,TRUE,https://github.com/arives/rr2,6557,12,2019-12-22T01:12:58Z,546.4166666666666
rrapply,"The 'rrapply'-package contains a single function rrapply(), providing an extended implementation of 'R'-base rapply() by allowing to recursively apply a function to elements of a nested list based on a general condition function and including the possibility to prune or aggregate nested list elements from the result. In addition, special arguments can be supplied to access the name and location in the nested list of the element under evaluation. The rrapply() function is implemented in 'R''s 'C' interface and requires no other package dependencies.",2020-06-04,Joris Chau,https://github.com/JorisChau/rrapply,TRUE,https://github.com/jorischau/rrapply,0,5,2020-06-02T07:24:06Z,0
Rraven,A tool to exchange data between R and 'Raven' sound analysis software (Cornell Lab of Ornithology). Functions work on data formats compatible with the R package 'warbleR'.,2020-06-08,Marcelo Araya-Salas,https://github.com/maRce10/Rraven,TRUE,https://github.com/marce10/rraven,10870,3,2020-05-17T15:37:57Z,3623.3333333333335
rrd,"Makes it easy to import the data from a 'RRD' database 
   (<https://oss.oetiker.ch/rrdtool/>) directly into R data structures. The 
   resulting objects are 'tibble' objects or a list of 'tibble' objects, making
   it easy to manipulate the data.  The package uses `librrd` to import the 
   numerical data in a `RRD` database directly into R data structures without 
   using intermediate formats.",2019-07-05,Andrie de Vries,"https://github.com/andrie/rrd/, https://andrie.github.io/rrd/",TRUE,https://github.com/andrie/rrd,2855,4,2019-12-13T06:29:37Z,713.75
rredlist,"'IUCN' Red List (<http://apiv3.iucnredlist.org/api/v3/docs>) client.
    The 'IUCN' Red List is a global list of threatened and endangered species.
    Functions cover all of the Red List 'API' routes. An 'API' key is required.",2020-01-28,Scott Chamberlain,"https://github.com/ropensci/rredlist (devel)
https://docs.ropensci.org/rredlist (docs)",TRUE,https://github.com/ropensci/rredlist,114138,21,2020-05-20T21:35:02Z,5435.142857142857
rrepast,"An R and Repast integration tool for running individual-based
    (IbM) simulation models developed using 'Repast Simphony' Agent-Based framework
    directly from R code supporting multicore execution. This package 
    integrates 'Repast Simphony' models within R environment, making easier 
    the tasks of running and analyzing model output data for 
    automated parameter calibration and for carrying out uncertainty and
    sensitivity analysis using the power of R environment.",2020-02-19,Antonio Prestes Garcia,https://github.com/antonio-pgarcia/rrepast,TRUE,https://github.com/antonio-pgarcia/rrepast,15673,2,2020-02-18T15:36:23Z,7836.5
rroad,"Computation of the International Roughness Index (IRI) given a
    longitudinal road profile. The IRI can be calculated for a single road segment
    or for a sequence of segments with a fixed length (e. g. 100m). For the latter,
    an overlap of the segments can be selected. The IRI and likewise the algorithms
    for its determination are defined in Sayers, Michael W; Gillespie, Thomas D;
    Queiroz, Cesar A.V. 1986. The International Road Roughness Experiment (IRRE) :
    establishing correlation and a calibration standard for measurements. World
    Bank technical paper; no. WTP 45. Washington, DC : The World Bank. (ISBN
    0-8213-0589-1) available from <http://documents.worldbank.org/curated/en/326081468740204115>.",2018-02-21,Viliam Simko,http://github.com/vsimko/rroad,TRUE,https://github.com/vsimko/rroad,7881,10,2020-05-07T15:21:22Z,788.1
rRofex,"Execute API calls to the 'Matba Rofex' <https://apihub.primary.com.ar> trading platform. Functionality includes accessing account data and current holdings, retrieving investment quotes, placing and canceling orders, and getting reference data for instruments.",2020-06-04,Augusto Hassel,"https://matbarofex.github.io/rRofex,
https://github.com/matbarofex/rRofex",TRUE,https://github.com/matbarofex/rrofex,289,13,2020-06-04T17:26:30Z,22.23076923076923
rromeo,"Fetches information from the 'SHERPA/RoMEO' API
  <http://www.sherpa.ac.uk/romeo/apimanual.php> which indexes policies of
  journal regarding the archival of scientific manuscripts before and/or after
  peer-review as well as formatted manuscripts.",2020-03-11,Matthias Grenié,"https://docs.ropensci.org/rromeo/,
https://github.com/ropensci/rromeo",TRUE,https://github.com/ropensci/rromeo,4286,13,2020-04-04T10:13:27Z,329.6923076923077
RRPP,"Linear model calculations are made for many random versions of data.  
    Using residual randomization in a permutation procedure, sums of squares are 
    calculated over many permutations to generate empirical probability distributions 
    for evaluating model effects.  This packaged is described by 
    Collyer & Adams (2018) <doi:10.1111/2041-210X.13029>.  Additionally, coefficients, statistics, fitted values, and residuals generated over many 
    permutations can be used for various procedures including pairwise tests, prediction, classification, and
    model comparison.  This package should provide most tools one could need for the analysis of
    high-dimensional data, especially in ecology and evolutionary biology, but certainly other fields, as well.",2020-05-28,Michael Collyer,https://github.com/mlcollyer/RRPP,TRUE,https://github.com/mlcollyer/rrpp,34160,2,2020-06-02T19:06:29Z,17080
RRRR,"Methods for estimating online robust reduced-rank regression. 
    The Gaussian maximum likelihood estimation method is described in Johansen, S. (1991) <doi:10.2307/2938278>.
    The majorisation-minimisation estimation method is partly described in Zhao, Z., & Palomar, D. P. (2017) <doi:10.1109/GlobalSIP.2017.8309093>.
    The description of the generic stochastic successive upper-bound minimisation method
    and the sample average approximation can be found in Razaviyayn, M., Sanjabi, M., & Luo, Z. Q. (2016) <doi:10.1007/s10107-016-1021-7>.",2020-05-08,Yangzhuoran Yang,"https://pkg.yangzhuoranyang.com/RRRR/,
https://github.com/FinYang/RRRR",TRUE,https://github.com/finyang/rrrr,1408,0,2020-05-09T03:48:32Z,NA
RSAGA,"Provides access to geocomputing and terrain analysis functions
    of the geographical information system (GIS) 'SAGA' (System for Automated
    Geoscientific Analyses) from within R by running the command line version of
    SAGA. This package furthermore provides several R functions for handling ASCII
    grids, including a flexible framework for applying local functions (including
    predict methods of fitted models) and focal functions to multiple grids. SAGA
    GIS is available under GPLv2 / LGPLv2 licence from 
    <http://sourceforge.net/projects/saga-gis/>.",2018-11-12,Alexander Brenning,https://github.com/r-spatial/RSAGA,TRUE,https://github.com/r-spatial/rsaga,132365,14,2020-04-05T08:31:23Z,9454.642857142857
rsample,"Classes and functions to create and summarize different types of resampling objects (e.g. bootstrap, cross-validation). ",2020-06-04,Max Kuhn,"https://rsample.tidymodels.org,
https://github.com/tidymodels/rsample",TRUE,https://github.com/tidymodels/rsample,294840,179,2020-06-04T14:40:32Z,1647.1508379888269
rscala,"'Scala' <http://www.scala-lang.org/> is embedded in 'R' and callbacks from 'Scala' to 'R' are available. Support is provided to write 'R' packages that access 'Scala'. After installation, please run 'rscala::scalaConfig()'.  The vignette provides an update of the original paper <doi:10.18637/jss.v092.i04>.",2020-04-05,David B. Dahl,https://github.com/dbdahl/rscala,TRUE,https://github.com/dbdahl/rscala,51775,85,2020-04-05T03:24:37Z,609.1176470588235
RSCAT,"As an advanced approach to computerized adaptive testing (CAT), 
  shadow testing (van der Linden(2005) <doi:10.1007/0-387-29054-0>) dynamically 
  assembles entire shadow tests as a part of 
  selecting items throughout the testing process.
  Selecting items from shadow tests guarantees the compliance of all content 
  constraints defined by the blueprint. 'RSCAT' is an R package for the 
  shadow-test approach to CAT. The objective of 
  'RSCAT' is twofold: 1) Enhancing the effectiveness of shadow-test CAT simulation;
  2) Contributing to the academic and scientific community for CAT research.",2020-01-17,Bingnan Jiang,NA,TRUE,https://github.com/act-org/rscat,4616,3,2020-05-24T15:48:05Z,1538.6666666666667
rsconnect,"Programmatic deployment interface for 'RPubs', 'shinyapps.io', and
    'RStudio Connect'. Supported content types include R Markdown documents,
    Shiny applications, Plumber APIs, plots, and static web content.",2019-12-13,JJ Allaire,https://github.com/rstudio/rsconnect,TRUE,https://github.com/rstudio/rsconnect,37258845,63,2020-03-23T17:54:39Z,591410.2380952381
rscontract,"Provides a generic implementation of the 'RStudio' connection contract to 
    make it easier for database connections, and other type of connections, opened 
    via R packages integrate with the connections pane inside the 'RStudio' interactive
    development environment (IDE).",2020-02-10,Javier Luraschi,https://github.com/rstudio/rscontract,TRUE,https://github.com/rstudio/rscontract,3869,13,2020-02-10T17:56:36Z,297.61538461538464
rscopus,"Uses Elsevier 'Scopus' API
    <https://dev.elsevier.com/sc_apis.html> to download 
    information about authors and their citations.",2019-09-17,John Muschelli,"https://dev.elsevier.com/sc_apis.html,
https://github.com/muschellij2/rscopus",TRUE,https://github.com/muschellij2/rscopus,53088,41,2020-03-23T16:32:32Z,1294.8292682926829
rscorecard,"A method to download Department of Education College
     Scorecard data using the public API
     <https://collegescorecard.ed.gov/data/documentation/>. It is based on
     the 'dplyr' model of piped commands to select and filter data in a
     single chained function call.  An API key from the U.S. Department of
     Education is required.",2020-06-03,Benjamin Skinner,https://github.com/btskinner/rscorecard,TRUE,https://github.com/btskinner/rscorecard,19919,17,2020-06-02T23:53:59Z,1171.7058823529412
rsdmx,"Set of classes and methods to read data and metadata documents
  exchanged through the Statistical Data and Metadata Exchange (SDMX) framework,
  currently focusing on the SDMX XML standard format (SDMX-ML).",2020-04-07,Emmanuel Blondel,"https://github.com/opensdmx/rsdmx, http://www.sdmx.org",TRUE,https://github.com/opensdmx/rsdmx,74448,77,2020-04-07T11:18:34Z,966.8571428571429
rSEA,"SEA performs simultaneous feature-set testing for (gen)omics data. It tests the unified null hypothesis controls the family-wise error rate for all possible pathways. The unified null hypothesis is defined as: ""The proportion of true features in the set is less than or equal to the threshold c"", where c is selected by the user. Family-wise error rate control is provided through use of closed testing with Simes test. For more information on closed testing with Simes see Goeman et al. (2019) <doi:10.1093/biomet/asz041> and for more information about the properties and performance of SEA procedure see Ebrahimpoor et al. (2019) <doi:10.1093/bib/bbz074>.",2020-03-23,Mitra Ebrahimpoor,https://github.com/mitra-ep/rSEA,TRUE,https://github.com/mitra-ep/rsea,6021,0,2020-03-16T21:39:23Z,NA
RSelenium,"Provides a set of R bindings for the 'Selenium 2.0 WebDriver'
    (see <https://selenium.dev/documentation/en/>
    for more information) using the 'JsonWireProtocol' (see
    <https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol> for more
    information). 'Selenium 2.0 WebDriver' allows driving a web browser
    natively as a user would either locally or on a remote machine using
    the Selenium server it marks a leap forward in terms of web browser
    automation. Selenium automates web browsers (commonly referred to as
    browsers). Using RSelenium you can automate browsers locally or
    remotely.",2020-02-03,John Harrison,http://docs.ropensci.org/RSelenium,TRUE,https://github.com/ropensci/rselenium,234464,258,2020-02-01T05:11:48Z,908.7751937984497
rsf,"A report of statistical findings (RSF) project
    template is generated using a 'bookdown' format. 'YAML' fields can be
    further customized. Additional helper functions provide extra features
    to the RSF.",2020-04-10,Derek Chiu,"https://github.com/dchiu911/rsf, https://dchiu911.github.io/rsf",TRUE,https://github.com/dchiu911/rsf,4178,0,2020-04-23T22:15:16Z,NA
RSGHB,"Functions for estimating models using a Hierarchical Bayesian (HB) framework. The flexibility comes in allowing the user to specify the likelihood function directly instead of assuming predetermined model structures. Types of models that can be estimated with this code include the family of discrete choice models (Multinomial Logit, Mixed Logit, Nested Logit, Error Components Logit and Latent Class) as well ordered response models like ordered probit and ordered logit. In addition, the package allows for flexibility in specifying parameters as either fixed (non-varying across individuals) or random with continuous distributions. Parameter distributions supported include normal, positive/negative log-normal, positive/negative censored normal, and the Johnson SB distribution. Kenneth Train's Matlab and Gauss code for doing Hierarchical Bayesian estimation has served as the basis for a few of the functions included in this package. These Matlab/Gauss functions have been rewritten to be optimized within R. Considerable code has been added to increase the flexibility and usability of the code base. Train's original Gauss and Matlab code can be found here: <http://elsa.berkeley.edu/Software/abstracts/train1006mxlhb.html> See Train's chapter on HB in Discrete Choice with Simulation here: <http://elsa.berkeley.edu/books/choice2.html>; and his paper on using HB with non-normal distributions here: <http://eml.berkeley.edu//~train/trainsonnier.pdf>. The authors would also like to thank the invaluable contributions of Stephane Hess and the Choice Modelling Centre: <https://cmc.leeds.ac.uk/>.",2019-07-03,Jeff Dumont,https://github.com/RSGInc/RSGHB,TRUE,https://github.com/rsginc/rsghb,36788,17,2019-07-03T20:46:11Z,2164
rsimsum,"Summarise results from simulation studies and compute Monte Carlo
  standard errors of commonly used summary statistics. This package is modelled 
  on the 'simsum' user-written command in 'Stata' (White I.R., 2010 
  <http://www.stata-journal.com/article.html?article=st0200>), further extending
  it with additional functionality.",2020-04-15,Alessandro Gasparini,https://ellessenne.github.io/rsimsum/,TRUE,https://github.com/ellessenne/rsimsum,10501,9,2020-05-31T08:51:38Z,1166.7777777777778
rsinaica,"Easy-to-use functions for downloading air quality data from the 
    Mexican National Air Quality Information System (SINAICA).  Allows you to 
    query pollution and meteorological parameters from more than a hundred
    monitoring stations located throughout Mexico. See <https://sinaica.inecc.gob.mx> 
    for more information.",2019-02-04,Diego Valle-Jones,"https://hoyodesmog.diegovalle.net/rsinaica/,
https://github.com/diegovalle/rsinaica",TRUE,https://github.com/diegovalle/rsinaica,7024,6,2020-05-05T11:52:25Z,1170.6666666666667
RSiteCatalyst,"Functions for interacting with the Adobe Analytics API V1.4
    (<https://api.omniture.com/admin/1.4/rest/>).",2019-11-05,Willem Paling,NA,TRUE,https://github.com/randyzwitch/rsitecatalyst,76055,124,2020-05-06T12:40:11Z,613.3467741935484
rskey,"Create custom keyboard shortcuts to examine code selected in the 'Rstudio' editor.
             F3 can for example yield 'str(selection)' and F7 open the source
             code of CRAN and base package functions on 'github'.",2020-06-05,Berry Boessenkool,NA,TRUE,https://github.com/brry/rskey,3610,1,2020-06-05T11:13:09Z,3610
rslp,"Implements the ""Stemming Algorithm for the Portuguese Language"" <DOI:10.1109/SPIRE.2001.10024>.",2020-05-11,Daniel Falbel,https://github.com/dfalbel/rslp,TRUE,https://github.com/dfalbel/rslp,12561,13,2020-05-11T16:43:16Z,966.2307692307693
rslurm,"Functions that simplify submitting R scripts to a 'Slurm' 
    workload manager, in part by automating the division of embarrassingly
    parallel calculations across cluster nodes.",2019-11-15,Philippe Marchand,https://github.com/SESYNC-ci/rslurm,TRUE,https://github.com/sesync-ci/rslurm,16335,32,2020-06-04T16:23:11Z,510.46875
RSNNS,"The Stuttgart Neural Network Simulator (SNNS) is a library
    containing many standard implementations of neural networks. This
    package wraps the SNNS functionality to make it available from
    within R. Using the 'RSNNS' low-level interface, all of the
    algorithmic functionality and flexibility of SNNS can be accessed.
    Furthermore, the package contains a convenient high-level
    interface, so that the most common neural network topologies and
    learning algorithms integrate seamlessly into R.",2019-09-17,Christoph Bergmeir,https://github.com/cbergmeir/RSNNS,TRUE,https://github.com/cbergmeir/rsnns,216299,20,2019-09-16T23:32:43Z,10814.95
rsnps,"A programmatic interface to various 'SNP' 'datasets'
    on the web: 'OpenSNP' (<https://opensnp.org>), and 'NBCIs' 'dbSNP' database
    (<https://www.ncbi.nlm.nih.gov/projects/SNP>). Functions
    are included for searching for 'NCBI'. For 'OpenSNP', functions are included 
    for getting 'SNPs', and data for 'genotypes', 'phenotypes', annotations, 
    and bulk downloads of data by user.",2018-09-20,Scott Chamberlain,https://github.com/ropensci/rsnps,TRUE,https://github.com/ropensci/rsnps,22235,40,2019-12-09T19:25:09Z,555.875
RSocrata,"Provides easier interaction with
    'Socrata' open data portals <http://dev.socrata.com>.
    Users can provide a 'Socrata' data set resource URL,
    or a 'Socrata' Open Data API (SoDA) web query,
    or a 'Socrata' ""human-friendly"" URL,
    returns an R data frame. Converts dates to 'POSIX'
    format and manages throttling by 'Socrata'.
    Users can upload data to 'Socrata' portals directly
    from R.",2019-10-23,Hugh Devlin,https://github.com/Chicago/RSocrata,TRUE,https://github.com/chicago/rsocrata,41098,165,2019-10-23T18:28:01Z,249.0787878787879
rsoi,"Downloads Southern Oscillation Index, Oceanic Nino
    Index, North Pacific Gyre Oscillation data, North Atlantic Oscillation
    and Arctic Oscillation. Data sources are described in the README file.",2020-03-25,Sam Albers,"https://github.com/boshek/rsoi, https://boshek.github.io/rsoi/",TRUE,https://github.com/boshek/rsoi,12789,8,2020-05-21T05:58:15Z,1598.625
rspa,"Minimally adjust the values of numerical records in a data.frame, such
    that each record satisfies a predefined set of equality and/or inequality
    constraints. The constraints can be defined using the 'validate' package. 
    The core algorithms have recently been moved to the 'lintools' package,
    refer to 'lintools' for a more basic interface and access to a version
    of the algorithm that works with sparse matrices.",2019-06-19,Mark van der Loo,https://github.com/markvanderloo/rspa,TRUE,https://github.com/markvanderloo/rspa,21620,2,2019-06-19T14:48:11Z,10810
rsparse,"Implements many algorithms for statistical learning on 
  sparse matrices - matrix factorizations, matrix completion, 
  elastic net regressions, factorization machines. 
  Also 'rsparse' enhances 'Matrix' package by providing methods for 
  multithreaded <sparse, dense> matrix products and native slicing of 
  the sparse matrices in Compressed Sparse Row (CSR) format.
  List of the algorithms for regression problems:
  1) Elastic Net regression via Follow The Proximally-Regularized Leader (FTRL) 
  Stochastic Gradient Descent (SGD), as per McMahan et al(, <doi:10.1145/2487575.2488200>)
  2) Factorization Machines via SGD, as per Rendle (2010, <doi:10.1109/ICDM.2010.127>)
  List of algorithms for matrix factorization and matrix completion:
  1) Weighted Regularized Matrix Factorization (WRMF) via Alternating Least 
  Squares (ALS) - paper by Hu, Koren, Volinsky (2008, <doi:10.1109/ICDM.2008.22>)
  2) Maximum-Margin Matrix Factorization via ALS, paper by Rennie, Srebro 
  (2005, <doi:10.1145/1102351.1102441>)
  3) Fast Truncated Singular Value Decomposition (SVD), Soft-Thresholded SVD, 
  Soft-Impute matrix completion via ALS - paper by Hastie, Mazumder 
  et al. (2014, <arXiv:1410.2596>)
  4) Linear-Flow matrix factorization, from 'Practical linear models for 
  large-scale one-class collaborative filtering' by Sedhain, Bui, Kawale et al 
  (2016, ISBN:978-1-57735-770-4)
  5) GlobalVectors (GloVe) matrix factorization via SGD, paper by Pennington, 
  Socher, Manning (2014, <https://www.aclweb.org/anthology/D14-1162>)
  Package is reasonably fast and memory efficient - it allows to work with large
  datasets - millions of rows and millions of columns. This is particularly useful 
  for practitioners working on recommender systems.",2020-04-01,Dmitriy Selivanov,https://github.com/rexyai/rsparse,TRUE,https://github.com/rexyai/rsparse,24850,134,2020-04-05T05:32:13Z,185.44776119402985
RSpectra,"R interface to the 'Spectra' library
    <https://spectralib.org/> for large-scale eigenvalue and SVD
    problems. It is typically used to compute a few
    eigenvalues/vectors of an n by n matrix, e.g., the k largest eigenvalues,
    which is usually more efficient than eigen() if k << n. This package
    provides the 'eigs()' function that does the similar job as in 'Matlab',
    'Octave', 'Python SciPy' and 'Julia'. It also provides the 'svds()' function
    to calculate the largest k singular values and corresponding
    singular vectors of a real matrix. The matrix to be computed on can be
    dense, sparse, or in the form of an operator defined by the user.",2019-12-01,Yixuan Qiu,https://github.com/yixuan/RSpectra,TRUE,https://github.com/yixuan/rspectra,690670,55,2019-11-29T21:56:08Z,12557.636363636364
rsppfp,"An implementation of functionalities to transform directed graphs that are bound to a set of
  known forbidden paths. There are several transformations, following the rules provided by Villeneuve 
  and Desaulniers (2005) <doi: 10.1016/j.ejor.2004.01.032>, and Hsu et al. (2009) <doi: 10.1007/978-3-642-03095-6_60>. 
  The resulting graph is generated in a data-frame format. See rsppfp website for more information, 
  documentation an examples.",2019-02-19,Melina Vidoni,https://github.com/melvidoni/rsppfp,TRUE,https://github.com/melvidoni/rsppfp,5569,3,2019-10-02T03:33:58Z,1856.3333333333333
RSQL,"Allows the user to generate and execute select, insert, update and delete 'SQL' queries the underlying database without having to explicitly write 'SQL' code. ",2020-05-06,Alejandro Baranek,https://github.com/rOpenStats/RSQL,TRUE,https://github.com/ropenstats/rsql,2663,1,2020-05-16T19:52:35Z,2663
RSQLite,"Embeds the 'SQLite' database engine in R and
    provides an interface compliant with the 'DBI' package. The source for
    the 'SQLite' engine is included.",2020-01-07,Kirill Müller,"https://rsqlite.r-dbi.org, https://github.com/r-dbi/RSQLite",TRUE,https://github.com/r-dbi/rsqlite,4441847,202,2020-04-17T03:11:40Z,21989.341584158417
Rssa,"Methods and tools for Singular Spectrum Analysis including decomposition, forecasting and gap-filling for univariate and multivariate time series.",2020-02-28,Anton Korobeynikov,http://github.com/asl/rssa,TRUE,https://github.com/asl/rssa,40572,36,2020-02-27T07:23:56Z,1127
RSSL,"A collection of implementations of semi-supervised classifiers
    and methods to evaluate their performance. The package includes implementations
    of, among others, Implicitly Constrained Learning, Moment Constrained Learning,
    the Transductive SVM, Manifold regularization, Maximum Contrastive Pessimistic
    Likelihood estimation, S4VM and WellSVM.",2020-02-04,Jesse Krijthe,http://www.github.com/jkrijthe/RSSL,TRUE,https://github.com/jkrijthe/rssl,21217,44,2020-02-07T16:12:12Z,482.20454545454544
rstan,"User-facing R functions are provided to parse, compile, test,
    estimate, and analyze Stan models by accessing the header-only Stan library
    provided by the 'StanHeaders' package. The Stan project develops a probabilistic
    programming language that implements full Bayesian statistical inference
    via Markov Chain Monte Carlo, rough Bayesian inference via 'variational'
    approximation, and (optionally penalized) maximum likelihood estimation via
    optimization. In all three cases, automatic differentiation is used to quickly
    and accurately evaluate gradients without burdening the user with the need to
    derive the partial derivatives.",2020-02-11,Ben Goodrich,"http://discourse.mc-stan.org, http://mc-stan.org",TRUE,https://github.com/stan-dev/rstan,1393314,678,2020-06-03T22:22:11Z,2055.0353982300885
rstanarm,"Estimates previously compiled regression models using the 'rstan'
    package, which provides the R interface to the Stan C++ library for Bayesian
    estimation. Users specify models via the customary R syntax with a formula and
    data.frame plus some additional arguments for priors.",2020-02-11,Simon Wood [cph,"https://mc-stan.org/rstanarm/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/rstanarm,404178,243,2020-06-03T22:28:19Z,1663.283950617284
rstanemax,"Perform sigmoidal Emax model fit using 'Stan' in a formula notation, without writing 'Stan' model code.",2019-11-19,Kenta Yoshida,https://github.com/yoshidk6/rstanemax,TRUE,https://github.com/yoshidk6/rstanemax,4077,0,2020-02-01T06:13:09Z,NA
rstantools,"Provides various tools for developers of R packages interfacing
    with 'Stan' <https://mc-stan.org>, including functions to set up the required 
    package structure, S3 generics and default methods to unify function naming 
    across 'Stan'-based R packages, and vignettes with recommendations for 
    developers.",2019-09-15,Jonah Gabry,"https://mc-stan.org/rstantools/, https://discourse.mc-stan.org/",TRUE,https://github.com/stan-dev/rstantools,435564,25,2020-06-03T22:29:43Z,17422.56
rstap,Estimates previously compiled stap regression models using the 'rstan' package. Users specify models via a custom R syntax with a formula and data.frame plus additional arguments for priors.,2019-02-06,Adam Peterson,https://biostatistics4socialimpact.github.io/rstap,TRUE,https://github.com/biostatistics4socialimpact/rstap,6028,4,2020-05-04T20:38:56Z,1507
rstatix,"Provides a simple and intuitive pipe-friendly framework, coherent with the 'tidyverse' design philosophy, 
    for performing basic statistical tests, including t-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses. 
    The output of each test is automatically transformed into a tidy data frame to facilitate visualization. 
    Additional functions are available for reshaping, reordering, manipulating and visualizing correlation matrix.  
    Functions are also included to facilitate the analysis of factorial experiments, including purely 'within-Ss' designs 
    (repeated measures), purely 'between-Ss' designs, and mixed 'within-and-between-Ss' designs. 
    It's also possible to compute several effect size metrics, including ""eta squared"" for ANOVA, ""Cohen's d"" for t-test and 
    'Cramer V' for the association between categorical variables. 
    The package contains helper functions for identifying univariate and multivariate outliers, assessing normality and homogeneity of variances.",2020-04-28,Alboukadel Kassambara,https://rpkgs.datanovia.com/rstatix/,TRUE,https://github.com/kassambara/rstatix,402532,107,2020-06-05T21:11:04Z,3761.9813084112147
RStoolbox,"Toolbox for remote sensing image processing and analysis such as
    calculating spectral indices, principal component transformation, unsupervised
    and supervised classification or fractional cover analyses.",2019-07-23,Benjamin Leutner,"http://bleutner.github.io/RStoolbox,
https://github.com/bleutner/RStoolbox",TRUE,https://github.com/bleutner/rstoolbox,74249,160,2019-11-08T09:14:34Z,464.05625
rstpm2,"R implementation of generalized survival models (GSMs), smooth accelerated failure time (AFT) models and Markov multi-state models. For the GSMs, g(S(t|x))=eta(t,x) for a link function g, survival S at time t with covariates x and a linear predictor eta(t,x). The main assumption is that the time effect(s) are smooth <doi:10.1177/0962280216664760>. For fully parametric models with natural splines, this re-implements Stata's 'stpm2' function, which are flexible parametric survival models developed by Royston and colleagues. We have extended the parametric models to include any smooth parametric smoothers for time. We have also extended the model to include any smooth penalized smoothers from the 'mgcv' package, using penalized likelihood. These models include left truncation, right censoring, interval censoring, gamma frailties and normal random effects <doi:10.1002/sim.7451>. For the smooth AFTs, S(t|x) = S_0(t*eta(t,x)), where the baseline survival function S_0(t)=exp(-exp(eta_0(t))) is modelled for natural splines for eta_0, and the time-dependent cumulative acceleration factor eta(t,x)=\int_0^t exp(eta_1(u,x)) du for log acceleration factor eta_1(u,x). The Markov multi-state models allow for a range of models with smooth transitions to predict transition probabilities, length of stay, utilities and costs, with differences, ratios and standardisation.",2019-11-05,Mark Clements,http://github.com/mclements/rstpm2,TRUE,https://github.com/mclements/rstpm2,21173,13,2019-11-25T10:48:39Z,1628.6923076923076
rstudioapi,"Access the RStudio API (if available) and provide informative error
    messages when it's not.",2020-02-07,Kevin Ushey,https://github.com/rstudio/rstudioapi,TRUE,https://github.com/rstudio/rstudioapi,12826287,106,2020-06-09T01:23:07Z,121002.7075471698
RSuite,"Supports safe and reproducible solutions development in R.
        It will help you with environment separation per project,
        dependency management, local packages creation and preparing
        deployment packs for your solutions.",2019-06-10,Walerian Sokolowski,https://rsuite.io,TRUE,https://github.com/wlogsolutions/rsuite,9870,128,2020-02-19T08:22:47Z,77.109375
rsvd,"Low-rank matrix decompositions are fundamental tools and widely used for data
  analysis, dimension reduction, and data compression. Classically, highly accurate 
  deterministic matrix algorithms are used for this task. However, the emergence of 
  large-scale data has severely challenged our computational ability to analyze big data. 
  The concept of randomness has been demonstrated as an effective strategy to quickly produce
  approximate answers to familiar problems such as the singular value decomposition (SVD). 
  The rsvd package provides several randomized matrix algorithms such as the randomized 
  singular value decomposition (rsvd), randomized principal component analysis (rpca), 
  randomized robust principal component analysis (rrpca), randomized interpolative 
  decomposition (rid), and the randomized CUR decomposition (rcur). In addition several plot 
  functions are provided.",2020-02-17,N. Benjamin Erichson,https://github.com/erichson/rSVD,TRUE,https://github.com/erichson/rsvd,205084,65,2019-07-28T21:45:14Z,3155.1384615384613
RSvgDevice,"A graphics device for R that uses the w3.org xml standard
        for Scalable Vector Graphics.",2014-04-25,T Jake Luciani,https://github.com/mdecorde/RSvgDevice,TRUE,https://github.com/mdecorde/rsvgdevice,15002,134,2020-06-09T15:14:18Z,111.95522388059702
RSwissMaps,"Allows to link data to Swiss administrative divisions (municipalities,
    districts, cantons) and to plot and save customised maps thereof.  Furthermore, the
    package allows to generate tailored templates for data collection.  The used geodata
    is publicly available on the Swiss Federal Statistical Office website
    <https://www.bfs.admin.ch/bfs/de/home/dienstleistungen/geostat/geodaten-bundesstatistik.html>. ",2019-06-09,David Zumbach,NA,TRUE,https://github.com/zumbov2/rswissmaps,11974,12,2019-12-09T08:13:06Z,997.8333333333334
rsyncrosim,"'SyncroSim' is a generalized framework for managing scenario-based 
    datasets (<https://syncrosim.com/>). 'rsyncrosim' provides an interface to 
    'SyncroSim'. Simulation models can be added to 'SyncroSim' in order to 
    transform these datasets, taking advantage of general features such as 
    defining scenarios of model inputs, running Monte Carlo simulations, and 
    summarizing model outputs. 'rsyncrosim' requires 'Syncrosim' 2.2.13 or higher 
    (API documentation: <http://docs.syncrosim.com/>).",2020-06-04,Colin Daniel,https://github.com/syncrosim/rsyncrosim,TRUE,https://github.com/syncrosim/rsyncrosim,0,3,2020-06-09T13:42:35Z,0
rt,"Provides a programmatic interface to the 'Request Tracker' (RT) 
  HTTP API <https://rt-wiki.bestpractical.com/wiki/REST>. 'RT' is a popular 
  ticket tracking system.",2020-04-27,Bryce Mecum,https://github.com/nceas/rt,TRUE,https://github.com/nceas/rt,770,3,2020-05-17T16:48:25Z,256.6666666666667
rt.test,"Performs one-sample t-test based on robustified statistics using median/MAD (TA) and Hodges-Lehmann/Shamos (TB). For more details, see Park and Wang (2018)<arXiv:1807.02215>. This work was partially supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (No. NRF-2017R1A2B4004169).  ",2018-07-10,Chanseok Park,https://github.com/statpnu/R-package,TRUE,https://github.com/statpnu/r-package,7522,1,2019-08-03T07:58:12Z,7522
rtdists,"Provides response time distributions (density/PDF,
       distribution function/CDF, quantile function, and random
       generation): (a) Ratcliff diffusion model (Ratcliff &
       McKoon, 2008, <doi:10.1162/neco.2008.12-06-420>) based on C
       code by Andreas and Jochen Voss and (b) linear ballistic
       accumulator (LBA; Brown & Heathcote, 2008,
       <doi:10.1016/j.cogpsych.2007.12.002>) with different
       distributions underlying the drift rate.",2020-03-06,Henrik Singmann,https://github.com/rtdists/rtdists/,TRUE,https://github.com/rtdists/rtdists,40036,23,2020-03-08T21:18:38Z,1740.695652173913
rtemps,"A collection of R Markdown templates for nicely structured, reproducible 
    data analyses in R. The templates have embedded examples on how to write 
    citations, footnotes, equations and use colored message/info boxes, how to 
    cross-reference different parts/sections in the report, provide a nice 
    table of contents (toc) with a References section and proper R session 
    information as well as examples using DT tables and ggplot2 graphs. 
    The bookdown Lite template theme supports code folding.",2020-05-25,John Zobolas,https://github.com/bblodfon/rtemps,TRUE,https://github.com/bblodfon/rtemps,2065,0,2020-05-25T10:29:45Z,NA
rticles,"A suite of custom R Markdown formats and templates for
  authoring journal articles and conference submissions.",2020-02-05,Yihui Xie,https://github.com/rstudio/rticles,TRUE,https://github.com/rstudio/rticles,323301,731,2020-02-05T16:35:19Z,442.2722298221614
rtide,"Calculates tide heights based on tide station harmonics.
    It includes the harmonics data for 637 US stations.
    The harmonics data was converted from <https://github.com/poissonconsulting/rtide/blob/master/data-raw/harmonics-dwf-20151227-free.tar.bz2>,
    NOAA web site data processed by David Flater for 'XTide'.
    The code to calculate tide heights from the harmonics is based on 'XTide'.",2020-03-18,Joe Thorley,https://github.com/poissonconsulting/rtide,TRUE,https://github.com/poissonconsulting/rtide,11706,10,2020-05-08T01:17:21Z,1170.6
rtika,"Extract text or metadata from over a thousand file types, using Apache Tika <https://tika.apache.org/>. Get either plain text or structured XHTML content. ",2020-04-25,Sasha Goodman,"https://docs.ropensci.org/rtika, http://github.com/ropensci/rtika",TRUE,https://github.com/ropensci/rtika,9097,44,2020-04-24T18:08:37Z,206.75
rtimicropem,"Supports the input and reproducible analysis of RTI
    MicroPEM output files.",2019-05-15,Maëlle Salmon,"https://github.com/ropensci/rtimicropem,
https://docs.ropensci.org/rtimicropem/",TRUE,https://github.com/ropensci/rtimicropem,8224,9,2019-12-05T21:22:26Z,913.7777777777778
RTL,"Collection of functions and metadata to complement core packages
    in Finance and Commodities, including futures expiry tables and <http://www.morningstarcommodity.com/>
    API functions. See <https://github.com/risktoollib/RTL>.",2020-06-07,Philippe Cote,https://github.com/risktoollib/RTL,TRUE,https://github.com/risktoollib/rtl,1433,1,2020-06-07T17:27:27Z,1433
rtodoist,"Allows you to interact with the API of the ""Todoist"" platform.
    'Todoist' <https://todoist.com/> provides an online task manager service for teams.",2020-05-14,Cervan Girard,https://github.com/ThinkR-open/rtodoist,TRUE,https://github.com/thinkr-open/rtodoist,388,4,2020-05-28T11:39:56Z,97
rTorch,"'R' implementation and interface of the Machine Learning platform 
    'PyTorch' <https://pytorch.org/> developed in 'Python'. It requires a 'conda'
    environment with 'torch' and 'torchvision' to provide 'PyTorch' functions, 
    methods and classes. The key object in 'PyTorch' is the tensor which is in
    essence a multidimensional array. These tensors are fairly flexible to perform
    calculations in CPUs as well as 'GPUs' to accelerate the process.",2019-08-05,Alfonso R. Reyes,https://github.com/f0nzie/rTorch,TRUE,https://github.com/f0nzie/rtorch,3680,51,2019-08-02T18:14:48Z,72.15686274509804
Rtrack,"A toolkit for the analysis of paths from spatial tracking experiments (such as the Morris water maze) and calculation of goal-finding strategies. 
    This package is centered on an approach using machine learning for path classification.",2020-05-04,Rupert Overall,"https://rupertoverall.net/Rtrack/,
https://github.com/rupertoverall/Rtrack",TRUE,https://github.com/rupertoverall/rtrack,3175,2,2020-05-22T14:13:17Z,1587.5
RTransferEntropy,Measuring information flow between time series with Shannon and Rényi transfer entropy. See also Dimpfl and Peter (2013) <doi:10.1515/snde-2012-0044> and Dimpfl and Peter (2014) <doi:10.1016/j.intfin.2014.03.004> for theory and applications to financial time series. Additional references can be found in the theory part of the vignette.,2019-08-19,Simon Behrendt,https://github.com/BZPaper/RTransferEntropy,TRUE,https://github.com/bzpaper/rtransferentropy,10131,11,2019-08-19T12:46:13Z,921
rtrek,"Provides datasets related to the Star Trek fictional universe and functions for working with the data.
    The package also provides access to real world datasets based on the televised series and other related licensed media productions.
    It interfaces with the Star Trek API (STAPI) (<http://stapi.co/>), 
    Memory Alpha (<http://memory-alpha.wikia.com/>), and Memory Beta (<http://memory-beta.wikia.com/>) 
    to retrieve data, metadata and other information relating to Star Trek.
    It also contains several local datasets covering a variety of topics. 
    The package also provides functions for working with data from other Star Trek-related 
    R data packages containing larger datasets not stored in 'rtrek'.",2019-12-15,Matthew Leonawicz,https://github.com/leonawicz/rtrek,TRUE,https://github.com/leonawicz/rtrek,7111,30,2020-02-14T20:16:01Z,237.03333333333333
RTriangle,"This is a port of Jonathan Shewchuk's Triangle library to
    R. From his description: ""Triangle generates exact Delaunay
    triangulations, constrained Delaunay triangulations, conforming
    Delaunay triangulations, Voronoi diagrams, and high-quality
    triangular meshes. The latter can be generated with no small or
    large angles, and are thus suitable for finite element analysis.""",2018-01-31,Jonathan Richard Shewchuk [ctb,"https://github.com/davidcsterratt/RTriangle,
http://www.cs.cmu.edu/~quake/triangle.html",TRUE,https://github.com/davidcsterratt/rtriangle,21766,5,2019-06-24T14:34:00Z,4353.2
rtrim,"The TRIM model is widely used for estimating growth and decline of
    animal populations based on (possibly sparsely available) count data. The
    current package is a reimplementation of the original TRIM software developed
    at Statistics Netherlands by Jeroen Pannekoek. See
    <https://www.cbs.nl/en-gb/society/nature-and-environment/indices-and-trends%2d%2dtrim%2d%2d>
    for more information about TRIM.",2020-04-21,Patrick Bogaart,https://github.com/markvanderloo/rtrim,TRUE,https://github.com/markvanderloo/rtrim,12930,7,2020-06-02T11:28:53Z,1847.142857142857
Rtsne,"An R wrapper around the fast T-distributed Stochastic
    Neighbor Embedding implementation by Van der Maaten  (see <https://github.com/lvdmaaten/bhtsne/> for more information on the original implementation).",2018-11-10,Jesse Krijthe,https://github.com/jkrijthe/Rtsne,TRUE,https://github.com/jkrijthe/rtsne,674689,223,2020-03-20T11:30:16Z,3025.5112107623318
Rttf2pt1,"Contains the program 'ttf2pt1', for use with the
    'extrafont' package. This product includes software developed by the 'TTF2PT1'
    Project and its contributors.",2020-01-10,Winston Chang,https://github.com/wch/Rttf2pt1,TRUE,https://github.com/wch/rttf2pt1,850847,7,2020-01-08T18:56:12Z,121549.57142857143
rtweet,"An implementation of calls designed to collect and organize Twitter data via Twitter's REST and stream Application Program Interfaces (API), which can be found at the following URL: <https://developer.twitter.com/en/docs>.
 This package has been peer-reviewed by rOpenSci (v. 0.6.9).",2020-01-08,Michael W. Kearney,https://CRAN.R-project.org/package=rtweet,TRUE,https://github.com/ropensci/rtweet,191854,497,2020-01-06T19:37:43Z,386.0241448692153
rtypeform,"An R interface to the 'typeform'
    <https://typeform.com> application program interface.  Also provides
    functions for downloading your results.",2020-03-23,Colin Gillespie,https://github.com/csgillespie/rtypeform,TRUE,https://github.com/csgillespie/rtypeform,14528,7,2020-05-05T19:21:40Z,2075.4285714285716
rucrdtw,"R bindings for functions from the UCR Suite by Rakthanmanon et al. (2012) <DOI:10.1145/2339530.2339576>, which enables ultrafast subsequence
      search for a best match under Dynamic Time Warping and Euclidean Distance.",2020-03-04,Philipp Boersch-Supan,https://github.com/pboesu/rucrdtw,TRUE,https://github.com/pboesu/rucrdtw,24471,12,2020-03-03T11:45:07Z,2039.25
ruimtehol,"Wraps the 'StarSpace' library <https://github.com/facebookresearch/StarSpace> 
    allowing users to calculate word, sentence, article, document, webpage, link and entity 'embeddings'. 
    By using the 'embeddings', you can perform text based multi-label classification, 
    find similarities between texts and categories, do collaborative-filtering based recommendation 
    as well as content-based recommendation, find out relations between entities, calculate 
    graph 'embeddings' as well as perform semi-supervised learning and multi-task learning on plain text. 
    The techniques are explained in detail in the paper: 'StarSpace: Embed All The Things!' by Wu et al. (2017), available at <arXiv:1709.03856>.",2020-01-10,Jan Wijffels,https://github.com/bnosac/ruimtehol,TRUE,https://github.com/bnosac/ruimtehol,7246,87,2020-01-12T19:38:43Z,83.28735632183908
ruler,"Tools for creating data validation pipelines and
    tidy reports. This package offers a framework for exploring and
    validating data frame like objects using 'dplyr' grammar of data
    manipulation.",2020-05-09,Evgeni Chasnovski,"https://echasnovski.github.io/ruler/,
https://github.com/echasnovski/ruler",TRUE,https://github.com/echasnovski/ruler,11758,26,2020-06-07T07:08:58Z,452.2307692307692
rules,"Bindings for additional models for use with the 'parsnip' package. 
    Models include prediction rule ensembles (Friedman and Popescu, 2008) 
    <doi:10.1214/07-AOAS148>, C5.0 rules (Quinlan, 1992 ISBN: 1558602380), and 
    Cubist (Kuhn and Johnson, 2013) <doi:10.1007/978-1-4614-6849-3>. ",2020-05-20,Max Kuhn,"https://github.com/tidymodels/rules, https://rules.tidymodels.org",TRUE,https://github.com/tidymodels/rules,303,17,2020-05-26T15:19:03Z,17.823529411764707
runes,Convert a string of text characters to Elder Futhark Runes <https://en.wikipedia.org/wiki/Elder_Futhark>.,2020-05-29,Bryan Jenks,NA,TRUE,https://github.com/tallguyjenks/runes,1551,3,2020-05-31T03:14:51Z,517
runner,"Fully supports rolling windows operations by controlling window length,
  window lag, time indexing. With runner one can apply any R function on rolling
  windows. Package eases work with equally and unequally spaced time series.",2020-05-17,Dawid Kałędkowski,NA,TRUE,https://github.com/gogonzo/runner,9991,13,2020-04-26T06:41:11Z,768.5384615384615
runstats,"Provides methods for fast computation of running sample 
    statistics for time series. These include: (1) mean, (2) 
    standard deviation, and (3) variance over a fixed-length window 
    of time-series, (4) correlation, (5) covariance, and (6) 
    Euclidean distance (L2 norm) between short-time pattern and 
    time-series. Implemented methods utilize Convolution Theorem to 
    compute convolutions via Fast Fourier Transform (FFT).",2019-11-14,Marta Karas,https://github.com/martakarass/runstats,TRUE,https://github.com/martakarass/runstats,6241,1,2019-11-14T19:55:57Z,6241
rust,"Uses the generalized ratio-of-uniforms (RU) method to simulate
    from univariate and (low-dimensional) multivariate continuous distributions.
    The user specifies the log-density, up to an additive constant. The RU
    algorithm is applied after relocation of mode of the density to zero, and
    the user can choose a tuning parameter r. For details see Wakefield, Gelfand
    and Smith (1991) <DOI:10.1007/BF01889987>, Efficient generation of random
    variates via the ratio-of-uniforms method, Statistics and Computing (1991)
    1, 129-133.  A Box-Cox variable transformation can be used to make the input
    density suitable for the RU method and to improve efficiency.  In the
    multivariate case rotation of axes can also be used to improve efficiency.
    From version 1.2.0 the 'Rcpp' package 
    <https://cran.r-project.org/package=Rcpp> can be used to improve efficiency.",2019-12-20,Paul J. Northrop,"https://paulnorthrop.github.io/rust/,
http://github.com/paulnorthrop/rust",TRUE,https://github.com/paulnorthrop/rust,29495,0,2020-01-06T12:44:22Z,NA
rv,"Implements a simulation-based random variable class and a suite of
  methods for extracting parts of random vectors, calculating extremes of random
  vectors, and generating random vectors under a variety of distributions 
  following Kerman and Gelman (2007) <doi:10.1007/s11222-007-9020-4>. ",2020-02-03,Jouni Kerman,https://github.com/jsta/rv,TRUE,https://github.com/jsta/rv,16314,2,2020-05-07T12:32:42Z,8157
Rvcg,"Operations on triangular meshes based on 'VCGLIB'. This package
    integrates nicely with the R-package 'rgl' to render the meshes processed by
    'Rvcg'. The Visualization and Computer Graphics Library (VCG for short) is
    an open source portable C++ templated library for manipulation, processing
    and displaying with OpenGL of triangle and tetrahedral meshes. The library,
    composed by more than 100k lines of code, is released under the GPL license,
    and it is the base of most of the software tools of the Visual Computing Lab of
    the Italian National Research Council Institute ISTI <http://vcg.isti.cnr.it>,
    like 'metro' and 'MeshLab'. The 'VCGLIB' source is pulled from trunk
    <https://github.com/cnr-isti-vclab/vcglib> and patched to work with options
    determined by the configure script as well as to work with the header files
    included by 'RcppEigen'.",2020-02-07,Stefan Schlager,"http://github.com/zarquon42b/Rvcg, http://vcg.sf.net/",TRUE,https://github.com/zarquon42b/rvcg,42397,15,2020-02-12T16:11:01Z,2826.4666666666667
RVerbalExpressions,"Build regular expressions using grammar and functionality inspired 
    by <https://github.com/VerbalExpressions>. Usage of the %>% is encouraged to
    build expressions in a chain-like fashion.",2019-11-06,Tyler Littlefield,https://github.com/tyluRp/RVerbalExpressions,TRUE,https://github.com/tylurp/rverbalexpressions,3333,222,2019-11-07T02:52:38Z,15.013513513513514
rversions,"Query the main 'R' 'SVN' repository to find the
    versions 'r-release' and 'r-oldrel' refer to, and also all previous
    'R' versions and their release dates.",2020-05-25,Gábor Csárdi,"https://github.com/r-hub/rversions,
https://r-hub.github.io/rversions",TRUE,https://github.com/r-hub/rversions,2995367,20,2020-06-07T12:07:12Z,149768.35
rvertnet,"Retrieve, map and summarize data from the 'VertNet.org' 
    archives (<http://vertnet.org/>).  Functions allow searching by many 
    parameters, including 'taxonomic' names, places, and dates. In addition, 
    there is an interface for conducting spatially delimited searches, and 
    another for requesting large 'datasets' via email.",2020-01-29,Scott Chamberlain,"https://github.com/ropensci/rvertnet (devel)
https://docs.ropensci.org/rvertnet (documentation)",TRUE,https://github.com/ropensci/rvertnet,51448,5,2020-01-29T17:15:11Z,10289.6
rvest,"Wrappers around the 'xml2' and 'httr' packages to
    make it easy to download, then manipulate, HTML and XML.",2019-11-08,Hadley Wickham,"http://rvest.tidyverse.org/, https://github.com/tidyverse/rvest",TRUE,https://github.com/tidyverse/rvest,8710308,1169,2020-01-31T19:22:25Z,7451.076133447391
rvg,"Vector Graphics devices for Microsoft 
  PowerPoint and Excel. Functions extending package 'officer' are provided to 
  embed 'DrawingML' graphics into 'Microsoft PowerPoint' presentations and 
  'Microsoft Excel' workbooks.",2020-02-17,David Gohel,https://davidgohel.github.io/rvg,TRUE,https://github.com/davidgohel/rvg,233809,111,2020-02-17T20:05:42Z,2106.387387387387
rvinecopulib,"Provides an interface to 'vinecopulib', a C++ library for vine 
 copula modeling. The 'rvinecopulib' package implements the core features of the
 popular 'VineCopula' package, in particular inference algorithms for both vine 
 copula and bivariate copula models. Advantages over 'VineCopula' are a sleeker 
 and more modern API, improved performances, especially in high dimensions, 
 nonparametric and multi-parameter families, and the ability to model discrete 
 variables. The 'rvinecopulib' package includes 'vinecopulib' as header-only 
 C++ library (currently version 0.5.2). Thus users do not need to install 
 'vinecopulib' itself in order to use 'rvinecopulib'. Since their initial 
 releases, 'vinecopulib' is licensed under the MIT License, and 'rvinecopulib' 
 is licensed under the GNU GPL version 3.",2020-05-07,Thomas Nagler,NA,TRUE,https://github.com/vinecopulib/rvinecopulib,14810,6,2020-05-07T09:47:09Z,2468.3333333333335
rvkstat,"Load data from vk.com api about your communiti users and views,
    ads performance, post on user wall and etc. For more detail see 
    <https://vk.com/dev/first_guide>.	",2019-12-11,Alexey Seleznev,http://selesnow.github.io/rvkstat,TRUE,https://github.com/selesnow/rvkstat,3989,11,2020-05-08T14:57:52Z,362.6363636363636
rwalkr,"Provides API to Melbourne pedestrian data in tidy
    data form.",2020-03-20,Earo Wang,http://pkg.earo.me/rwalkr,TRUE,https://github.com/earowang/rwalkr,15561,7,2020-03-20T21:29:16Z,2223
rwavelet,"Perform wavelet analysis (orthogonal, translation invariant, tensorial, 1-2-3d transforms, thresholding, block thresholding, linear,...) with applications to data compression or denoising/regression. The core of the code is a port of 'MATLAB' Wavelab toolbox written by D. Donoho, A. Maleki and M. Shahram (<https://statweb.stanford.edu/~wavelab/>).",2019-03-14,F. Navarro and C. Chesneau,http://github.com/fabnavarro/rwavelet,TRUE,https://github.com/fabnavarro/rwavelet,6196,3,2019-09-20T08:08:54Z,2065.3333333333335
rWBclimate,"This package will download model predictions from 15 different global circulation models in 20 year intervals from the world bank.  Users can also access historical data, and create maps at 2 different spatial scales.",2014-04-19,Edmund Hart,http://github.com/ropensci/rWBclimate,TRUE,https://github.com/ropensci/rwbclimate,17933,54,2020-04-24T17:19:46Z,332.0925925925926
RWDataPlyr,"A tool to read and manipulate data generated from 'RiverWare'(TM) 
    <http://www.riverware.org/> simulations. 'RiverWare' and 'RiverSMART' 
    generate data in ""rdf"", ""csv"", and ""nc"" format. This package provides an 
    interface to read, aggregate, and summarize data from one or more 
    simulations in a 'dplyr' pipeline.",2020-04-17,Alan Butler,https://github.com/BoulderCodeHub/RWDataPlyr,TRUE,https://github.com/bouldercodehub/rwdataplyr,7094,2,2020-04-17T17:00:08Z,3547
rwhatsapp,"A straightforward, easy-to-use and robust parsing package which aims to
    digest history files from the popular messenger service 'WhatsApp' in all locales
    and from all devices.",2020-03-18,Johannes Gruber,https://github.com/JBGruber/rwhatsapp,TRUE,https://github.com/jbgruber/rwhatsapp,5376,37,2020-04-24T12:21:50Z,145.2972972972973
RWiener,"Provides Wiener process distribution functions,
  namely the Wiener first passage time density, CDF, quantile and random
  functions. Additionally supplies a modelling function (wdm) and further
  methods for the resulting object.",2020-05-04,Dominik Wabersich,https://github.com/yeagle/RWiener,TRUE,https://github.com/yeagle/rwiener,72189,2,2020-05-04T19:58:59Z,36094.5
rWind,Tools for download and manage surface wind and sea currents data from the Global Forecasting System <https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs> and to compute connectivity between locations.,2020-02-17,Javier Fernández-López,http://allthiswasfield.blogspot.com.es/,TRUE,https://github.com/jabiologo/rwind,15875,15,2020-02-17T16:50:43Z,1058.3333333333333
Rwofost,"An implementation of the WOFOST (""World Food Studies"") crop growth model. WOFOST is a dynamic simulation model that uses daily weather data, and crop, soil and management parameters to simulate crop growth and development. See De Wit et al. (2019) <doi:10.1016/j.agsy.2018.06.018> for a recent review of the history and use of the model.",2020-03-25,Robert J. Hijmans,https://github.com/cropmodels/Rwofost,TRUE,https://github.com/cropmodels/rwofost,1314,4,2020-04-20T01:03:24Z,328.5
Rxnat,"Allows communication with Extensible Neuroimaging Archive Toolkit <https://www.xnat.org>. 
  'Rxnat' is using the 'XNAT' REST API to perform data queries and download images.",2020-04-17,Adi Gherman,NA,TRUE,https://github.com/adigherman/rxnat,4951,0,2020-06-04T16:14:19Z,NA
RxODE,"Facilities for running simulations from ordinary
    differential equation (ODE) models, such as pharmacometrics and other
    compartmental models.  A compilation manager translates the ODE model
    into C, compiles it, and dynamically loads the object code into R for
    improved computational efficiency.  An event table object facilitates
    the specification of complex dosing regimens (optional) and sampling
    schedules.  NB: The use of this package requires both C and
    Fortran compilers, for details on their use with R please see
    Section 6.3, Appendix A, and Appendix D in the ""R Administration and
    Installation"" manual. Also the code is mostly released under GPL.  The
    VODE and LSODA are in the public domain.  The information is available
    in the inst/COPYRIGHTS. You can also obtain the archived SnakeCharmR for
    python integration from CRAN archives
    <https://cran.r-project.org/src/contrib/Archive/SnakeCharmR/> or
    <https://github.com/nlmixrdevelopment/SnakeCharmR>.",2020-03-13,Wenping Wang,https://nlmixrdevelopment.github.io/RxODE/,TRUE,https://github.com/nlmixrdevelopment/rxode,30608,21,2020-05-07T03:11:37Z,1457.5238095238096
rxylib,"Provides access to the 'xylib' C library for to import xy 
  data from powder diffraction, spectroscopy and other experimental methods.",2019-06-05,Sebastian Kreutzer,https://github.com/R-Lum/rxylib,TRUE,https://github.com/r-lum/rxylib,9680,6,2019-11-23T23:43:37Z,1613.3333333333333
Ryacas,Interface to the 'yacas' computer algebra system (<http://www.yacas.org/>).,2020-04-15,Mikkel Meyer Andersen,"https://github.com/r-cas/ryacas, http://www.yacas.org",TRUE,https://github.com/r-cas/ryacas,43245,17,2020-04-14T16:56:59Z,2543.823529411765
Ryacas0,"A legacy version of 'Ryacas', an interface to the 'yacas' computer algebra system (<http://www.yacas.org/>).",2019-10-09,Mikkel Meyer Andersen,"https://github.com/mikldk/ryacas0, http://www.yacas.org",TRUE,https://github.com/mikldk/ryacas0,3272,1,2020-01-06T23:07:03Z,3272
ryandexdirect,"Load data from 'Yandex Direct' API V5 
    <https://tech.yandex.ru/direct/doc/dg/concepts/about-docpage/> into R.
	Provide function for load lists of campaings, ads, keywords and other 
	objects from 'Yandex Direct' account. Also you can load statistic from
	API 'Reports Service' <https://tech.yandex.ru/direct/doc/reports/reports-docpage/>.
	And allows keyword bids management.",2020-06-09,Alexey Seleznev,"https://selesnow.github.io/ryandexdirect,
https://t.me/R4marketing,
https://www.youtube.com/playlist?list=PLD2LDq8edf4oUo0L9Kw77ZXf0KcV1hu67",TRUE,https://github.com/selesnow/ryandexdirect,7483,46,2020-05-21T09:41:43Z,162.67391304347825
RYandexTranslate,"'Yandex Translate' (https://translate.yandex.com/) is a statistical machine translation system.
	The system translates separate words, complete texts, and webpages.
	This package can be used to detect language from text and to translate it to supported target language.
	For more info: https://tech.yandex.com/translate/doc/dg/concepts/About-docpage/ .",2016-02-29,Mukul Chaware[aut,https://github.com/mukul13/RYandexTranslate,TRUE,https://github.com/mukul13/ryandextranslate,14762,14,2019-09-25T08:04:50Z,1054.4285714285713
rym,"Allows work with 'Management API' for load counters, segments, filters,
	user permissions and goals list from Yandex Metrica, 'Reporting API' allows you to get 
	information about the statistics of site visits and other data without
	using the web interface, 'Logs API' allows to receive non-aggregated data and 
	'Compatible with Google Analytics Core Reporting API v3' allows 
	receive information about site traffic and other data using field names 
	from Google Analytics Core API.	For more information see official 
	documents <https://tech.yandex.ru/metrika/doc/api2/concept/about-docpage/>.",2019-12-10,Alexey Seleznev,http://selesnow.github.io/rym,TRUE,https://github.com/selesnow/rym,8593,5,2020-05-08T14:56:08Z,1718.6
s2,"R bindings for Google's s2 library for geometric calculations on
    the sphere.",2019-08-29,Ege Rubak,"https://github.com/spatstat/s2,
https://code.google.com/archive/p/s2-geometry-library/",TRUE,https://github.com/spatstat/s2,11945,26,2019-08-16T06:55:55Z,459.4230769230769
s2net,"Implements the generalized semi-supervised elastic-net. This method extends the supervised elastic-net problem, and thus it is a practical solution to the problem of feature selection in semi-supervised contexts. Its mathematical formulation is presented from a general perspective, covering a wide range of models.  We focus on linear and logistic responses, but the implementation could be easily extended to other losses in generalized linear models. We develop a flexible and fast implementation, written in 'C++' using 'RcppArmadillo' and integrated into R via 'Rcpp' modules. See Culp, M. 2013 <doi:10.1080/10618600.2012.657139> for references on the Joint Trained Elastic-Net.",2020-01-16,Juan C. Laria,https://github.com/jlaria/s2net,TRUE,https://github.com/jlaria/s2net,2202,3,2020-01-31T10:22:03Z,734
sabre,"Calculates a degree of spatial association between regionalizations 
    or categorical maps using the information-theoretical V-measure 
    (Nowosad and Stepinski (2018) <doi:10.1080/13658816.2018.1511794>). It also
    offers an R implementation of the MapCurve method 
    (Hargrove et al. (2006) <doi:10.1007/s10109-006-0025-x>).",2019-10-17,Jakub Nowosad,https://nowosad.github.io/sabre/,TRUE,https://github.com/nowosad/sabre,8036,23,2019-10-17T08:46:28Z,349.39130434782606
saccades,"Functions for detecting eye fixations in raw eye-tracking
    data.  The detection is done using a velocity-based algorithm for
    saccade detection proposed by Ralf Engbert and Reinhold Kliegl in
    2003.  The algorithm labels segments as saccades when the velocity of
    the eye movement exceeds a certain threshold.  Anything between two
    saccades is considered a fixation.  Thus the algorithm is not
    appropriate for data containing episodes of smooth pursuit eye
    movements.",2015-03-18,Titus von der Malsburg,https://github.com/tmalsburg/saccades,TRUE,https://github.com/tmalsburg/saccades,14392,38,2019-09-16T14:27:34Z,378.7368421052632
safedata,"The SAFE Project (<https://www.safeproject.net/>) is a large 
	scale ecological experiment in Malaysian Borneo that explores the impact 
	of habitat fragmentation and conversion on ecosystem function and services. 
	Data collected at the SAFE Project is made available under a common format 
	through the Zenodo data repository and this package makes it easy to 
	discover and load that data into R.",2020-06-02,David Orme,https://imperialcollegelondon.github.io/safedata/index.html,TRUE,https://github.com/imperialcollegelondon/safedata,0,2,2020-05-28T14:20:51Z,0
safer,"A consistent interface to encrypt and decrypt strings, R objects and files using symmetric and asymmetric key encryption.",2018-07-24,KS Srikanth,https://github.com/talegari/safer,TRUE,https://github.com/talegari/safer,18618,12,2020-02-24T08:29:24Z,1551.5
safetyGraphics,A framework for evaluation of clinical trial safety. Users can interactively explore their data using the 'Shiny' application or create standalone 'htmlwidget' charts. Interactive charts are built using 'd3.js' and 'webcharts.js' 'JavaScript' libraries.,2020-01-15,Jeremy Wildfire,https://github.com/SafetyGraphics/safetyGraphics,TRUE,https://github.com/safetygraphics/safetygraphics,5545,28,2020-01-16T14:26:14Z,198.03571428571428
sail,"Sparse additive interaction learning with the strong heredity property, i.e., 
    an interaction is selected only if its corresponding main effects are also included. 
    Fits a linear model with non-linear interactions via penalized maximum likelihood. 
    Interactions are limited to a single exposure or environment variable. For more information, 
    see the website below and the accompanying paper: Bhatnagar et al., ""A sparse additive model for 
    high-dimensional interactions with an exposure variable"", 2019, <DOI:10.1101/445304>.",2019-12-13,Sahir Bhatnagar,https://sahirbhatnagar.com/sail,TRUE,https://github.com/sahirbhatnagar/sail,2271,3,2019-12-14T09:23:35Z,757
salesforcer,"Functions connecting to the 'Salesforce' Platform APIs (REST, SOAP, 
    Bulk 1.0, Bulk 2.0, and Metadata) <https://trailhead.salesforce.com/en/content/learn/modules/api_basics/api_basics_overview>. 
    Most all calls from these APIs are supported as they use CSV, XML or JSON data 
    that can be parsed into R data structures. For more details please see the 
    'Salesforce' API documentation and this package's website 
    <https://stevenmmortimer.github.io/salesforcer/> for more information, 
    documentation, and examples.",2019-06-10,Steven M. Mortimer,https://github.com/StevenMMortimer/salesforcer,TRUE,https://github.com/stevenmmortimer/salesforcer,11934,34,2020-06-09T17:27:48Z,351
samc,"An implementation of the framework described in ""Toward a unified
    framework for connectivity that disentangles movement and mortality in space
    and time"" by Fletcher et al. (2019) <doi:10.1111/ele.13333>. 
    Incorporates both resistance and absorption with spatial absorbing Markov 
    chains (SAMC) to provide several short-term and long-term predictions for 
    metrics related to connectivity in landscapes.",2020-05-19,Andrew Marx,https://andrewmarx.github.io/samc,TRUE,https://github.com/andrewmarx/samc,3429,1,2020-05-25T13:42:30Z,3429
sampler,"Determine sample sizes, draw samples, and conduct data analysis using data frames. It specifically enables you to determine simple random sample sizes, stratified sample sizes, and complex stratified sample sizes using a secondary variable such as population; draw simple random samples and stratified random samples from sampling data frames; determine which observations are missing from a random sample, missing by strata, duplicated within a dataset; and perform data analysis, including proportions, margins of error and upper and lower bounds for simple, stratified and cluster sample designs. ",2019-09-15,Michael Baldassaro,https://github.com/mbaldassaro/sampler,TRUE,https://github.com/mbaldassaro/sampler,9199,4,2019-09-15T15:27:54Z,2299.75
samplesize,Computes sample size for Student's t-test and for the Wilcoxon-Mann-Whitney test for categorical data. The t-test function allows paired and unpaired (balanced / unbalanced) designs as well as homogeneous and heterogeneous variances. The Wilcoxon function allows for ties.,2016-12-24,Ralph Scherer,https://github.com/shearer/samplesize,TRUE,https://github.com/shearer/samplesize,28814,5,2019-08-28T19:59:31Z,5762.8
samplesizeCMH,"
    Calculates the power and sample size for Cochran-Mantel-Haenszel tests. 
    There are also several helper functions for working with probability,
    odds, relative risk, and odds ratio values.",2017-12-21,Paul Egeler,https://github.com/pegeler/samplesizeCMH,TRUE,https://github.com/pegeler/samplesizecmh,9053,3,2019-12-03T06:28:27Z,3017.6666666666665
SamplingStrata,"In the field of stratified sampling design, this package offers an approach for the determination of the best stratification of a sampling frame, the one that ensures the minimum sample cost under the condition to satisfy precision constraints in a multivariate and multidomain case. This approach is based on the use of the genetic algorithm: each solution (i.e. a particular partition in strata of the sampling frame) is considered as an individual in a population; the fitness of all individuals is evaluated applying the Bethel-Chromy algorithm to calculate the sampling size satisfying precision constraints on the target estimates. Functions in the package allows to: (a) analyse the obtained results of the optimisation step; (b) assign the new strata labels to the sampling frame; (c) select a sample from the new frame accordingly to the best allocation. Functions for the execution of the genetic algorithm are a modified version of the functions in the 'genalg' package.  ",2020-03-02,Giulio Barcaroli,https://barcaroli.github.io/SamplingStrata,TRUE,https://github.com/barcaroli/samplingstrata,27077,3,2020-05-21T16:49:55Z,9025.666666666666
samurais,"Provides a variety of original and flexible user-friendly 
    statistical latent variable models and unsupervised learning algorithms to 
    segment and represent time-series data (univariate or multivariate), and 
    more generally, longitudinal data, which include regime changes. 
    'samurais' is built upon the following packages, each of them is an 
    autonomous time-series segmentation approach: Regression with Hidden 
    Logistic Process ('RHLP'), Hidden Markov Model Regression ('HMMR'), 
    Multivariate 'RHLP' ('MRHLP'), Multivariate 'HMMR' ('MHMMR'), Piece-Wise 
    regression ('PWR'). For the advantages/differences of each of them, the 
    user is referred to our mentioned paper references.",2019-07-28,Florian Lecocq,https://github.com/fchamroukhi/SaMUraiS,TRUE,https://github.com/fchamroukhi/samurais,3160,5,2020-01-22T17:31:40Z,632
sand,"Data sets for the book 'Statistical Analysis of 
  Network Data with R'.",2017-03-02,Eric D Kolaczyk,https://github.com/kolaczyk/sand,TRUE,https://github.com/kolaczyk/sand,38129,189,2020-06-06T15:11:50Z,201.74074074074073
sanityTracker,"During the preparation of data set(s) one usually performs
    some sanity checks. The idea is that irrespective of where the
    checks are performed, they are centralized by this package in order
    to list all at once with examples if a check failed.",2020-04-22,Marsel Scheer,https://github.com/MarselScheer/sanityTracker,TRUE,https://github.com/marselscheer/sanitytracker,621,0,2020-04-26T12:47:06Z,NA
sankeywheel,"By binding R functions and the 'Highcharts' <http://www.highcharts.com/> charting library, 'sankeywheel' package provides a simple way to draw dependency wheels and sankey diagrams.",2019-10-24,Zhenxing Cheng,https://github.com/czxa/sankeywheel,TRUE,https://github.com/czxa/sankeywheel,2963,21,2019-12-22T08:33:12Z,141.0952380952381
santoku,"A tool for cutting data into intervals. Allows singleton intervals.
  Always includes the whole range of data by default. Flexible labelling. 
  Convenience functions for cutting by quantiles etc. Handles dates and times.",2020-06-09,David Hugh-Jones,"https://github.com/hughjonesd/santoku,
https://hughjonesd.github.io/santoku/",TRUE,https://github.com/hughjonesd/santoku,2246,117,2020-06-09T15:19:49Z,19.196581196581196
sanzo,"Inspired by the art and color research of Sanzo Wada (1883-1967), 
    his ""Dictionary Of Color Combinations"" (2011, ISBN:978-4861522475), and the 
    interactive site by Dain M. Blodorn Kim <https://github.com/dblodorn/sanzo-wada>, 
    this package brings Wada's color combinations to R for easy use in data 
    visualizations. This package honors 60 of Wada's color combinations: 
    20 duos, 20 trios, and 20 quads.",2020-01-12,Jacqueline Maasch,https://github.com/jmaasch/sanzo,TRUE,https://github.com/jmaasch/sanzo,2001,12,2020-04-06T16:01:17Z,166.75
sapfluxnetr,"Access, modify, aggregate and plot data from the 'Sapfluxnet' project
  (<http://sapfluxnet.creaf.cat>), the first global database of sap flow measurements.",2020-05-11,Victor Granda,https://github.com/sapfluxnet/sapfluxnetr,TRUE,https://github.com/sapfluxnet/sapfluxnetr,4584,9,2020-05-11T10:11:10Z,509.3333333333333
saqgetr,"A collection of tools to access prepared air quality monitoring
    data files from web servers with ease and speed. Air quality data are 
    sourced from open and publicly accessible repositories and can be found in 
    these locations: 
    <https://www.eea.europa.eu/data-and-maps/data/airbase-the-european-air-quality-database-8> 
    and <http://discomap.eea.europa.eu/map/fme/AirQualityExport.htm>. The web 
    server space has been provided by Ricardo Energy & Environment.",2020-06-03,Stuart K. Grange,https://github.com/skgrange/saqgetr,TRUE,https://github.com/skgrange/saqgetr,4041,1,2020-06-03T07:35:29Z,4041
sars,"Implements the basic elements of the multi-model
    inference paradigm for up to twenty species-area relationship models (SAR), using simple
    R list-objects and functions, as in Triantis et al. 2012 <DOI:10.1111/j.1365-2699.2011.02652.x>.
    The package is scalable and users can easily create their own model and data objects. Additional
    SAR related functions are provided.",2020-05-31,Thomas J. Matthews,"https://github.com/txm676/sars, https://txm676.github.io/sars/",TRUE,https://github.com/txm676/sars,8137,3,2020-05-31T20:13:33Z,2712.3333333333335
sass,"An 'SCSS' compiler, powered by the 'LibSass' library. With this,
    R developers can use variables, inheritance, and functions to generate
    dynamic style sheets. The package uses the 'Sass CSS' extension language,
    which is stable, powerful, and CSS compatible.",2020-03-18,Richard Iannone,https://github.com/rstudio/sass,TRUE,https://github.com/rstudio/sass,60660,67,2020-03-03T04:57:47Z,905.3731343283582
SASxport,"Functions for reading, listing
    the contents of, and writing 'SAS' 'xport' format files.
    The functions support reading and writing of either
    individual data frames or sets of data frames.  Further,
    a mechanism has been provided for customizing how
    variables of different data types are stored.",2020-03-10,"Gregory R. Warnes <greg@warnes.net>
    --
    Unless otherwise noted",https://github.com/warnes/SASxport,TRUE,https://github.com/warnes/sasxport,42918,7,2020-03-10T14:50:43Z,6131.142857142857
SAVER,"An implementation of a regularized regression prediction and 
    empirical Bayes method to recover the true gene expression profile in 
    noisy and sparse single-cell RNA-seq data. See Huang M, et al (2018) 
    <doi:10.1038/s41592-018-0033-z> for more details.",2019-11-13,Mo Huang,https://github.com/mohuangx/SAVER,TRUE,https://github.com/mohuangx/saver,8169,70,2020-02-23T17:58:48Z,116.7
sazedR,"Spectral and Average Autocorrelation Zero Distance Density
    ('sazed') is a method for estimating the season length of a 
    seasonal time series. 'sazed' is aimed at practitioners, as it employs only 
    domain-agnostic preprocessing and does not depend on parameter tuning or 
    empirical constants. The computation of 'sazed' relies on the efficient 
    autocorrelation computation methods suggested by Thibauld Nion (2012, URL: 
    <http://www.tibonihoo.net/literate_musing/autocorrelations.html>) and by 
    Bob Carpenter (2012, URL: 
    <https://lingpipe-blog.com/2012/06/08/autocorrelation-fft-kiss-eigen/>).",2019-09-16,Tiago Santos,https://github.com/mtoller/autocorr_season_length_detection/,TRUE,https://github.com/mtoller/autocorr_season_length_detection,6963,4,2019-10-15T05:14:00Z,1740.75
sboost,"Creates classifier for binary outcomes using Adaptive Boosting 
    (AdaBoost) algorithm on decision stumps with a fast C++ implementation. 
    For a description of AdaBoost, see Freund and Schapire (1997) 
    <doi:10.1006/jcss.1997.1504>. This type of classifier is nonlinear, but
    easy to interpret and visualize. Feature vectors may be a combination of
    continuous (numeric) and categorical (string, factor) elements. Methods 
    for classifier assessment, predictions, and cross-validation also included.",2019-04-08,Jadon Wagstaff,https://github.com/jadonwagstaff/sboost,TRUE,https://github.com/jadonwagstaff/sboost,5662,1,2020-04-22T01:17:41Z,5662
sbtools,"Tools for interacting with U.S. Geological Survey ScienceBase 
    <https://www.sciencebase.gov> interfaces. ScienceBase is a data cataloging and
    collaborative data management platform. Functions included for querying
    ScienceBase, and creating and fetching datasets.",2020-04-20,David Blodgett,https://github.com/USGS-R/sbtools,TRUE,https://github.com/usgs-r/sbtools,10992,16,2020-05-13T15:11:52Z,687
scaffolder,"Comprehensive set of tools for scaffolding R
  interfaces to modules, classes, functions, and documentations
  written in other programming languages, such as 'Python'.",2020-03-20,Yuan Tang,https://github.com/terrytangyuan/scaffolder,TRUE,https://github.com/terrytangyuan/scaffolder,1189,24,2020-05-22T19:01:55Z,49.541666666666664
scales,"Graphical scales map data to aesthetics, and
    provide methods for automatically determining breaks and labels for
    axes and legends.",2020-05-11,Hadley Wickham,"https://scales.r-lib.org, https://github.com/r-lib/scales",TRUE,https://github.com/r-lib/scales,21287624,224,2020-05-12T12:17:01Z,95034.03571428571
scatr,"Allows you to make clean, good-looking scatter plots with the option to 
    easily add marginal density or box plots on the axes. It is also available as a module for 'jamovi'
    (see <https://www.jamovi.org> for more information). 'Scatr' is based on the 
    'cowplot' package by Claus O. Wilke and the 'ggplot2' package by Hadley Wickham.",2017-12-05,Ravi Selker,https://github.com/raviselker/scatr,TRUE,https://github.com/raviselker/scatr,8190,2,2019-11-07T14:17:41Z,4095
scatterD3,"Creates 'D3' 'JavaScript' scatterplots from 'R' with interactive
    features : panning, zooming, tooltips, etc.",2020-03-10,Julien Barnier,https://juba.github.io/scatterD3/,TRUE,https://github.com/juba/scatterd3,62039,128,2020-06-05T10:50:47Z,484.6796875
scattermore,"C-based conversion of large scatterplot data to rasters. Speeds up
             plotting of data with millions of points.",2020-03-06,Mirek Kratochvil,https://github.com/exaexa/scattermore,TRUE,https://github.com/exaexa/scattermore,1438,39,2020-04-20T21:31:28Z,36.87179487179487
scBio,"Cellular population mapping (CPM) a deconvolution algorithm in which single-cell genomics is required in only one or a few samples, where in other samples of the same tissue, only bulk genomics is measured and the underlying fine resolution cellular heterogeneity is inferred.",2020-05-20,Amit Frishberg,https://github.com/amitfrish/scBio,TRUE,https://github.com/amitfrish/scbio,8183,11,2020-05-20T10:55:46Z,743.9090909090909
scdhlm,"Provides a set of tools for estimating hierarchical linear
    models and effect sizes based on data from single-case designs. 
    Functions are provided for calculating standardized mean difference effect sizes that 
    are directly comparable to standardized mean differences estimated from between-subjects randomized experiments,
    as described in Hedges, Pustejovsky, and Shadish (2012) <DOI:10.1002/jrsm.1052>; 
    Hedges, Pustejovsky, and Shadish (2013) <DOI:10.1002/jrsm.1086>; and 
    Pustejovsky, Hedges, and Shadish (2014) <DOI:10.3102/1076998614547577>. 
    Includes an interactive web interface.",2020-04-09,James Pustejovsky,https://github.com/jepusto/scdhlm,TRUE,https://github.com/jepusto/scdhlm,10658,2,2020-05-29T20:43:22Z,5329
SCGLR,"
    An extension of the Fisher Scoring Algorithm to combine PLS regression with GLM 
    estimation in the multivariate context. Covariates can also be grouped in themes.",2018-09-28,Guillaume Cornu,"https://scnext.github.io/SCGLR, https://github.com/SCnext/SCGLR,
https://cran.r-project.org/package=SCGLR",TRUE,https://github.com/scnext/scglr,16441,0,2020-04-22T16:43:07Z,NA
scholar,"Provides functions to extract citation data from Google
    Scholar.  Convenience functions are also provided for comparing
    multiple scholars and predicting future h-index values.",2018-07-03,Guangchuang Yu,NA,TRUE,https://github.com/jkeirstead/scholar,36199,205,2020-03-21T08:54:35Z,176.58048780487806
schrute,"The complete scripts from the American version of
    the Office television show in tibble format. Use this package to
    analyze and have fun with text from the best series of all time.",2020-03-30,Brad Lindblad,https://github.com/bradlindblad/schrute,TRUE,https://github.com/bradlindblad/schrute,4643,15,2020-04-28T02:48:49Z,309.53333333333336
scico,"Colour choice in information visualisation is important in order to
    avoid being mislead by inherent bias in the used colour palette. The 'scico'
    package provides access to the perceptually uniform and colour-blindness 
    friendly palettes developed by Fabio Crameri and released under the 
    ""Scientific Colour-Maps"" moniker. The package contains 24 different palettes 
    and includes both diverging and sequential types.",2020-06-08,Thomas Lin Pedersen,https://github.com/thomasp85/scico,TRUE,https://github.com/thomasp85/scico,68008,158,2020-06-08T10:56:30Z,430.43037974683546
scidb,An R interface to the 'SciDB' array database <http://scidb.org>.,2017-04-14,B. W. Lewis,http://paradigm4.github.io/SciDBR,TRUE,https://github.com/paradigm4/scidbr,16734,52,2020-02-07T20:11:39Z,321.8076923076923
scipub,"Create and format tables and APA statistics for
    scientific publication. This includes making a 'Table 1'
    to summarize demographics across groups, correlation tables
    with significance indicated by stars, and extracting formatted
    statistical summarizes from simple tests for in-text notation.
    The package also includes functions for Winsorizing data based
    on a Z-statistic cutoff.  ",2020-06-04,David Pagliaccio,"https://github.com/dpagliaccio/scipub,
https://dpagliaccio.github.io/scipub/",TRUE,https://github.com/dpagliaccio/scipub,294,0,2020-06-03T23:35:46Z,NA
SciViews,"Functions to install SciViews additions to R, and more
        tools.",2019-11-16,Philippe Grosjean,"https://github.com/SciViews/SciViews,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/sciviews,32928,3,2020-05-04T18:52:26Z,10976
sclero,"Provides functions to measure growth patterns and align
    sampling spots in chronologically deposited materials. The package is
    intended for the fields of sclerochronology, dendrochronology and geology.",2016-01-21,Mikko Vihtakari,https://github.com/MikkoVihtakari/sclero,TRUE,https://github.com/mikkovihtakari/sclero,10474,2,2019-06-18T06:32:38Z,5237
scopr,"Handling of behavioural data from the Ethoscope platform 
    (Geissmann, Garcia Rodriguez, Beckwith, French, Jamasb and Gilestro (2017) <DOI:10.1371/journal.pbio.2003026>).
    Ethoscopes (<http://gilestrolab.github.io/ethoscope/>) are an open source/open hardware framework made of 
    interconnected raspberry pis (<https://www.raspberrypi.org>) designed to quantify the behaviour of multiple 
    small animals in a distributed and real-time fashion. The default tracking algorithm records primary variables
    such as xy coordinates, dimensions and speed.
    This package is part of the rethomics framework <http://rethomics.github.io/>.",2019-02-15,Quentin Geissmann,https://github.com/rethomics/scopr,TRUE,https://github.com/rethomics/scopr,6978,3,2020-06-10T01:39:09Z,2326
SCOR,"A non-convex optimization package that optimizes any function under the criterion, combination of
              variables are on the surface of a unit sphere, as described in the paper : Das et al. (2019) <arXiv:1909.04024> .",2019-10-24,Debsurya De,https://github.com/synx21/SCOR,TRUE,https://github.com/synx21/scor,2753,2,2019-09-20T05:59:00Z,1376.5
scorecard,"
  The `scorecard` package makes the development of credit risk scorecard 
  easier and efficient by providing functions for some common tasks, 
  such as data partition, variable selection, woe binning, scorecard scaling,
  performance evaluation and report generation. These functions can also used
  in the development of machine learning models.
    The references including: 
  1. Refaat, M. (2011, ISBN: 9781447511199). Credit Risk Scorecard: 
  Development and Implementation Using SAS. 
  2. Siddiqi, N. (2006, ISBN: 9780471754510). Credit risk scorecards. 
  Developing and Implementing Intelligent Credit Scoring.",2020-04-10,Shichen Xie,https://github.com/ShichenXie/scorecard,TRUE,https://github.com/shichenxie/scorecard,67126,106,2020-05-29T15:57:56Z,633.2641509433962
scorepeak,"Provides peak functions, which enable us to detect peaks in time series. The methods implemented in this package are based on Girish Keshav Palshikar (2009) <https://www.researchgate.net/publication/228853276_Simple_Algorithms_for_Peak_Detection_in_Time-Series>.",2019-08-21,Shota Ochi,https://github.com/ShotaOchi/scorepeak,TRUE,https://github.com/shotaochi/scorepeak,2956,0,2019-08-22T04:44:56Z,NA
scoringRules,"Dictionary-like reference for computing scoring rules in a wide
    range of situations. Covers both parametric forecast distributions (such as
    mixtures of Gaussians) and distributions generated via simulation.",2019-08-20,Alexander Jordan,https://github.com/FK83/scoringRules,TRUE,https://github.com/fk83/scoringrules,33793,27,2020-05-24T21:19:41Z,1251.5925925925926
SCORPIUS,"An accurate and easy tool for performing linear trajectory inference on
  single cells using single-cell RNA sequencing data. In addition, SCORPIUS
  provides functions for discovering the most important genes with respect to
  the reconstructed trajectory, as well as nice visualisation tools.
  Cannoodt et al. (2016) <doi:10.1101/079509>.",2020-05-11,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,http://github.com/rcannood/SCORPIUS,TRUE,https://github.com/rcannood/scorpius,10955,31,2020-05-11T09:59:13Z,353.38709677419354
ScottKnottESD,"The Scott-Knott Effect Size Difference (ESD) test is a mean comparison approach that leverages a hierarchical clustering to partition the set of treatment means (e.g., means of variable importance scores, means of model performance) into statistically distinct groups with non-negligible difference [Tantithamthavorn et al., (2018) <doi:10.1109/TSE.2018.2794977>].",2018-05-08,Chakkrit Tantithamthavorn,https://github.com/klainfo/ScottKnottESD,TRUE,https://github.com/klainfo/scottknottesd,12009,12,2020-05-18T06:45:22Z,1000.75
scriptexec,"Run complex native scripts with a single command, similar to system commands.",2019-04-12,Sagie Gur-Ari,https://github.com/sagiegurari/scriptexec,TRUE,https://github.com/sagiegurari/scriptexec,9061,3,2020-05-24T17:57:41Z,3020.3333333333335
scriptName,"A small set of functions wrapping up the call stack and command
  line inspection needed to determine a running script's filename from
  within the script itself.",2019-06-19,Thomas Sibley,https://github.com/MullinsLab/scriptName,TRUE,https://github.com/mullinslab/scriptname,5868,3,2019-06-19T06:35:16Z,1956
scrm,"A coalescent simulator that allows the rapid simulation of
    biological sequences under neutral models of evolution. Different to other
    coalescent based simulations, it has an optional approximation parameter that
    allows for high accuracy while maintaining a linear run time cost for long
    sequences. It is optimized for simulating massive data sets as produced by Next-
    Generation Sequencing technologies for up to several thousand sequences.",2018-11-19,Paul Staab,https://github.com/scrm/scrm-r,TRUE,https://github.com/scrm/scrm-r,22447,7,2019-11-02T10:51:22Z,3206.714285714286
scrobbler,"'Last.fm'<https://www.last.fm> is a music platform focussed on building a 
    detailed profile of a users listening habits. It does this by 'scrobbling' (recording) 
    every track you listen to on other platforms ('spotify', 'youtube', 'soundcloud' etc)
    and transferring them to your 'Last.fm' database. This allows 'Last.fm' to act as a 
    complete record of your entire listening history. 'scrobbler' provides helper functions
    to download and analyse your listening history in R.",2020-02-24,Conor Neilson,https://github.com/condwanaland/scrobbler,TRUE,https://github.com/condwanaland/scrobbler,5688,0,2020-03-01T21:11:56Z,NA
scrubr,"Clean biological occurrence records. Includes functionality
    for cleaning based on various aspects of spatial coordinates,
    unlikely values due to political 'centroids', coordinates based on
    where collections of specimens are held, and more.",2020-04-07,Scott Chamberlain,"https://github.com/ropensci/scrubr (devel)
https://docs.ropensci.org/scrubr (docs)",TRUE,https://github.com/ropensci/scrubr,15799,29,2020-04-08T15:34:07Z,544.7931034482758
scrypt,"Functions for working with the scrypt key derivation functions
    originally described by Colin Percival
    <https://www.tarsnap.com/scrypt/scrypt.pdf> and in Percival and Josefsson
    (2016) <doi:10.17487/RFC7914>. Scrypt is a password-based key derivation
    function created by Colin Percival. The algorithm was specifically designed
    to make it costly to perform large-scale custom hardware attacks by
    requiring large amounts of memory.",2019-08-09,Bob Jansen [ctb,https://github.com/rstudio/rscrypt,TRUE,https://github.com/rstudio/rscrypt,15800,22,2019-08-10T19:26:00Z,718.1818181818181
scs,"Solves convex cone programs via operator splitting. Can solve:
    linear programs ('LPs'), second-order cone programs ('SOCPs'), semidefinite programs
    ('SDPs'), exponential cone programs ('ECPs'), and power cone programs ('PCPs'), or
    problems with any combination of those cones. 'SCS' uses 'AMD' (a set of routines for permuting sparse matrices prior to factorization) and 'LDL' (a sparse 'LDL' factorization and solve package) from 'SuiteSparse' (<http://www.suitesparse.com>).",2019-11-19,Florian Schwendinger [ctb,https://github.com/FlorianSchwendinger/scs,TRUE,https://github.com/florianschwendinger/scs,35961,2,2019-11-19T11:47:38Z,17980.5
scTenifoldNet,"A workflow based on machine learning methods to construct and compare single-cell gene regulatory networks (scGRN) using single-cell RNA-seq (scRNA-seq) data collected from different conditions. Uses principal component regression, tensor decomposition, and manifold alignment, to accurately identify even subtly shifted gene expression programs.",2020-05-13,Daniel Osorio,https://github.com/cailab-tamu/scTenifoldNet,TRUE,https://github.com/cailab-tamu/sctenifoldnet,3363,2,2020-06-08T15:18:42Z,1681.5
SCtools,"Extensions to the synthetic controls analyses 
    performed by the package 'Synth' as detailed in Abadie, Diamond, and Hainmueller (2011) 
    <doi:10.18637/jss.v042.i13>. Includes generating 
    and plotting placebos, post/pre-MSPE (mean squared prediction error) 
    significance tests and plots, and calculating average treatment effects 
    for multiple treated units. This package represents an implementation of 
    those methods suggested in  Abadie, Diamond,and Hainmueller (2010) <doi:10.1198/jasa.2009.ap08746> for
    use in synthetic control analysis.",2019-12-12,Bruno Castanho Silva,NA,TRUE,https://github.com/bcastanho/sctools,2552,4,2020-05-25T08:47:15Z,638
sctransform,"A normalization method for single-cell UMI count data using a 
  variance stabilizing transformation. The transformation is based on a 
  negative binomial regression model with regularized parameters. As part of the
  same regression framework, this package also provides functions for
  batch correction, and data correction. See Hafemeister and Satija 2019 
  <doi:10.1101/576827> for more details.",2019-12-17,Christoph Hafemeister,https://github.com/ChristophH/sctransform,TRUE,https://github.com/christophh/sctransform,110661,72,2019-12-17T12:54:20Z,1536.9583333333333
sdcHierarchies,"Provides functionality to generate, (interactively) modify (by adding, removing and renaming nodes) and convert nested hierarchies between different formats.
  These tree like structures can be used to define for example complex hierarchical tables used for statistical disclosure control.",2019-10-31,Bernhard Meindl,https://github.com/bernhard-da/sdcHierarchies,TRUE,https://github.com/bernhard-da/sdchierarchies,7951,0,2019-10-31T08:58:37Z,NA
sdcMicro,"Data from statistical agencies and other institutions are mostly
    confidential. This package (see also Templ, Kowarik and Meindl (2017) <doi:10.18637/jss.v067.i04>) can be used for the generation of anonymized
    (micro)data, i.e. for the creation of public- and scientific-use files.
    The theoretical basis for the methods implemented can be found in Templ (2017) <doi:10.1007/978-3-319-50272-4>.
    Various risk estimation and anonymisation methods are included. Note that the package
    includes a graphical user interface (Meindl and Templ, 2019 <doi:10.3390/a12090191>) that allows to use various methods of this
    package.",2020-02-11,Matthias Templ,https://github.com/sdcTools/sdcMicro,TRUE,https://github.com/sdctools/sdcmicro,95905,36,2020-05-19T10:53:12Z,2664.027777777778
sdcSpatial,"Privacy protected raster maps 
  can be created from spatial point data. Protection
  methods include smoothing of dichotomous variables by de Jonge and de Wolf (2016) 
  <doi:10.1007/978-3-319-45381-1_9>, continuous variables by de Wolf and 
  de Jonge (2018) <doi:10.1007/978-3-319-99771-1_23>, suppressing 
  revealing values and a generalization of the quad tree method by 
  Suñé, Rovira, Ibáñez and Farré (2017) <doi:10.2901/EUROSTAT.C2017.001>.",2019-07-19,Edwin de Jonge,https://github.com/edwindj/sdcSpatial,TRUE,https://github.com/edwindj/sdcspatial,3869,5,2020-05-23T22:06:07Z,773.8
sdcTable,"Methods for statistical disclosure control in
    tabular data such as primary and secondary cell suppression as described for example
    in Hundepol et al. (2012) <doi:10.1002/9781118348239> are covered in this package.",2020-03-10,Bernhard Meindl,https://github.com/sdcTools/sdcTable,TRUE,https://github.com/sdctools/sdctable,36720,2,2020-06-08T10:53:26Z,18360
SDLfilter,"Functions to filter GPS and/or Argos locations, as well as assessing sample sizes for the analysis of animal distributions. The filters remove temporal and spatial duplicates, fixes located at a given height from estimated high tide line, and locations with high error as described in Shimada et al. (2012) <doi:10.3354/meps09747> and Shimada et al. (2016) <doi:10.1007/s00227-015-2771-0>. Sample sizes for the analysis of animal distributions can be assessed by the conventional area-based approach or the alternative probability-based approach as described in Shimada et al. (in prep). ",2020-05-04,Takahiro Shimada,https://github.com/TakahiroShimada/SDLfilter,TRUE,https://github.com/takahiroshimada/sdlfilter,9822,2,2020-05-04T10:57:40Z,4911
SDMtune,"User-friendly framework that enables the training and the
    evaluation of species distribution models (SDMs). The package implements
    functions for data driven variable selection and model tuning and includes
    numerous utilities to display the results. All the functions used to select
    variables or to tune model hyperparameters have an interactive real-time
    chart displayed in the 'RStudio' viewer pane during their execution.",2020-03-11,Sergio Vignali,https://consbiol-unibern.github.io/SDMtune/,TRUE,https://github.com/consbiol-unibern/sdmtune,5220,3,2020-06-09T16:44:37Z,1740
seagull,"Proximal gradient descent solver for the operators lasso, group
    lasso, and sparse-group lasso. The implementation involves backtracking line
    search and warm starts. Input data needs to be clustered/grouped for the
    (sparse-)group lasso before calling these algorithms.",2020-03-25,Jan Klosa,https://github.com/jklosa/seagull,TRUE,https://github.com/jklosa/seagull,2418,2,2020-02-20T10:03:44Z,1209
searchConsoleR,"Provides an interface with the Google Search Console,
    formally called Google Webmaster Tools.",2019-09-06,Mark Edmondson,http://code.markedmondson.me/searchConsoleR/,TRUE,https://github.com/markedmondson1234/searchconsoler,34566,94,2019-10-22T16:22:10Z,367.72340425531917
searcher,"Provides a search interface to look up terms
    on 'Google', 'Bing', 'DuckDuckGo', 'Startpage', 'Twitter', 'StackOverflow', 
    'RStudio Community', 'GitHub', and 'BitBucket'. Upon searching, a browser 
    window will open with the aforementioned search results.",2020-02-06,James Balamuta,https://github.com/r-assist/searcher,TRUE,https://github.com/r-assist/searcher,11433,57,2019-12-31T22:13:51Z,200.57894736842104
seasonal,"Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment
    software by the US Census Bureau. It offers full access to almost all
    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model
    search, outlier detection and support for user defined holiday variables,
    such as Chinese New Year or Indian Diwali. A graphical user interface can be
    used through the 'seasonalview' package. Uses the X-13-binaries from the
    'x13binary' package.",2020-06-06,Christoph Sax,http://www.seasonal.website,TRUE,https://github.com/christophsax/seasonal,218013,89,2020-06-06T09:25:25Z,2449.5842696629215
see,"Provides plotting utilities supporting easystats-packages (<https://github.com/easystats/easystats>) 
    and some extra themes, geoms, and scales for 'ggplot2'. Color scales are 
    based on <https://www.materialui.co/colors>.",2020-04-25,Daniel Lüdecke,https://easystats.github.io/see/,TRUE,https://github.com/easystats/see,28314,254,2020-06-09T18:38:50Z,111.4724409448819
seeclickfixr,"Provides a wrapper to access data from the SeeClickFix
  web API for R. SeeClickFix is a central platform employed by many cities
  that allows citizens to request their city's services. This package
  creates several functions to work with all the built-in calls to the
  SeeClickFix API. Allows users to download service request data from
  numerous locations in easy-to-use dataframe format manipulable in
  standard R functions.",2016-12-07,Justin de Benedictis-Kessner,NA,TRUE,https://github.com/justindbk/seeclickfixr,13645,1,2019-07-06T14:49:18Z,13645
seeds,"Algorithms to calculate the hidden inputs of systems of differential equations. 
  These hidden inputs can be interpreted as a control that tries to minimize the
  discrepancies between a given model and taken measurements. The idea is 
  also called the Dynamic Elastic Net, as proposed in the paper ""Learning (from) the errors of a systems biology model"" 
  (Engelhardt, Froelich, Kschischo 2016) <doi:10.1038/srep20772>.
  To use the experimental SBML import function, the 'rsbml' package is required. For installation I refer to the official 'rsbml' page: <https://bioconductor.org/packages/release/bioc/html/rsbml.html>.",2020-03-20,Tobias Newmiwaka,https://github.com/Newmi1988/seeds,TRUE,https://github.com/newmi1988/seeds,1282,0,2020-03-18T16:18:49Z,NA
seg,"Measuring spatial segregation. The methods implemented in this 
        package include White's P index (1983) <doi:10.1086/227768>, 
        Morrill's D(adj) (1991), Wong's D(w) and D(s) (1993) 
        <doi:10.1080/00420989320080551>, and Reardon and O'Sullivan's set of 
        spatial segregation measures (2004) 
        <doi:10.1111/j.0081-1750.2004.00150.x>.",2019-12-18,Seong-Yun Hong,https://github.com/syunhong/seg,TRUE,https://github.com/syunhong/seg,28850,2,2019-12-28T16:13:44Z,14425
segmentr,"Given a likelihood provided by the user, this package applies it
    to a given matrix dataset in order to find change points in the data that
    maximize the sum of the likelihoods of all the segments. This package provides
    a handful of algorithms with different time complexities and assumption compromises
    so the user is able to choose the best one for the problem at hand. The implementation
    of the segmentation algorithms in this package are based on the paper by Bruno M. de Castro,
	Florencia Leonardi (2018) <arXiv:1501.01756>. The Berlin
	weather sample dataset was provided by Deutscher Wetterdienst <https://dwd.de/>.
	You can find all the references in the Acknowledgments section of this package's
	repository via the URL below.",2019-08-28,Thales Mello,https://github.com/thalesmello/segmentr,TRUE,https://github.com/thalesmello/segmentr,5255,1,2020-03-03T20:03:33Z,5255
segRDA,"Tools for modeling non-continuous linear responses of ecological communities to environmental data. The package is straightforward through three steps: (1) data ordering (function OrdData()), (2) split-moving-window analysis (function SMW()) and (3) piecewise redundancy analysis (function pwRDA()). Relevant references include Cornelius and Reynolds (1991) <doi:10.2307/1941559> and Legendre and Legendre (2012, ISBN: 9780444538697).",2019-07-31,Danilo C Vieira,https://github.com/DaniloCVieira/segRDA,TRUE,https://github.com/danilocvieira/segrda,3414,0,2019-08-05T15:44:19Z,NA
segregation,"Computes entropy-based segregation indices, as developed by
    Theil (1971) <isbn:978-0471858454>, with a focus on
    the Mutual Information Index (M) and Theil's Information Index (H).
    The M, further described by Mora and Ruiz-Castillo (2011) <doi:10.1111/j.1467-9531.2011.01237.x>
    and Frankel and Volij (2011) <doi:10.1016/j.jet.2010.10.008>,
    is a measure of segregation that is highly decomposable. The package provides
    tools to decompose the index by units and groups (local segregation),
    and by within and between terms.
    Includes standard error estimation by bootstrapping.",2019-09-20,Benjamin Elbers,http://github.com/elbersb/segregation,TRUE,https://github.com/elbersb/segregation,7692,14,2020-03-04T16:10:33Z,549.4285714285714
SelectBoost,"An implementation of the selectboost algorithm (Bertrand et al. 2020, <arXiv:1810.01670>), which is a general algorithm that improves the precision of any existing variable selection method. This algorithm is based on highly intensive simulations and takes into account the correlation structure of the data. It can either produce a confidence index for variable selection or it can be used in an experimental design planning perspective.",2020-02-23,Frederic Bertrand,"https://github.com/fbertran/SelectBoost,
http://www-irma.u-strasbg.fr/~fbertran/",TRUE,https://github.com/fbertran/selectboost,4397,4,2020-02-23T13:09:43Z,1099.25
selectr,"Translates a CSS3 selector into an equivalent XPath
  expression. This allows us to use CSS selectors when working with
  the XML package as it can only evaluate XPath expressions. Also
  provided are convenience functions useful for using CSS selectors on
  XML nodes. This package is a port of the Python package 'cssselect'
  (<https://cssselect.readthedocs.io/>).",2019-11-20,Simon Potter,https://sjp.co.nz/projects/selectr,TRUE,https://github.com/sjp/selectr,7590998,30,2020-04-29T08:46:44Z,253033.26666666666
semantic.dashboard,It offers functions for creating dashboard with Semantic UI. ,2020-04-07,Dominik Krzeminski,NA,TRUE,https://github.com/appsilon/semantic.dashboard,15818,127,2020-04-09T15:47:48Z,124.55118110236221
semEff,"Provides functionality to automatically calculate direct, indirect, 
    and total effects from piecewise structural equation models, comprising 
    lists of fitted models representing structured equations (Lefcheck 2016 
    <doi:10/f8s8rb>). Confidence intervals are provided via bootstrapping.",2020-03-25,Mark Murphy,https://github.com/murphymv/semEff,TRUE,https://github.com/murphymv/semeff,2335,1,2020-03-26T11:30:34Z,2335
SemNeT,"Implements several functions for the analysis of semantic networks including different network estimation algorithms, partial node bootstrapping (Kenett, Anaki, & Faust, 2014 <doi:10.3389/fnhum.2014.00407>), random walk simulation (Kenett & Austerweil, 2016 <http://alab.psych.wisc.edu/papers/files/Kenett16CreativityRW.pdf>), and a function to compute global network measures. Significance tests and plotting features are also implemented. ",2020-06-09,Alexander P. Christensen,https://github.com/AlexChristensen/SemNeT,TRUE,https://github.com/alexchristensen/semnet,4713,3,2020-06-09T17:53:45Z,1571
SemNetCleaner,"Implements several functions that automates the cleaning and spell-checking of text data. Also converges, finalizes, removes plurals and continuous strings, and puts text data in binary format for semantic network analysis. Uses the 'SemNetDictionaries' package to make the cleaning process more accurate, efficient, and reproducible.",2020-06-09,Alexander P. Christensen,https://github.com/AlexChristensen/SemNetCleaner,TRUE,https://github.com/alexchristensen/semnetcleaner,9634,3,2020-06-09T17:51:44Z,3211.3333333333335
SemNetDictionaries,Implements dictionaries that can be used in the 'SemNetCleaner' package. Also includes several functions aimed at facilitating the text cleaning analysis in the 'SemNetCleaner' package. This package is designed to integrate and update word lists and dictionaries based on each user's individual needs by allowing users to store and save their own dictionaries. Dictionaries can be added to the 'SemNetDictionaries' package by submitting user-defined dictionaries to <https://github.com/AlexChristensen/SemNetDictionaries>.,2020-06-08,Alexander P. Christensen,https://github.com/AlexChristensen/SemNetDictionaries,TRUE,https://github.com/alexchristensen/semnetdictionaries,5626,1,2020-06-09T17:49:38Z,5626
semPlot,Path diagrams and visual analysis of various SEM packages' output.,2019-08-20,Sacha Epskamp,https://github.com/SachaEpskamp/semPlot,TRUE,https://github.com/sachaepskamp/semplot,271586,40,2020-04-24T07:25:11Z,6789.65
semverutils,"Semantic Versions allow for standardized management versions. 
    This package implements semantic versioning handling in R. using R6 to 
    create a mutable object that can handle deciphering and checking versions. ",2020-02-22,Adam Wheeler,https://github.com/ajwtech/semverutils,TRUE,https://github.com/ajwtech/semverutils,1634,6,2020-02-14T07:22:26Z,272.3333333333333
sen2r,"Functions to download Sentinel-2 optical images
 and perform preliminary processing operations.
 'sen2r' provides the instruments required to easily perform
 (and eventually automate) the steps necessary to build a complete
 Sentinel-2 processing chain.
 A Graphical User Interface to facilitate data processing is also provided.
 For additional documentation refer to the following article: 
 Ranghetti et al. (2020) <doi:10.1016/j.cageo.2020.104473>.",2020-06-04,Luigi Ranghetti,"http://sen2r.ranghetti.info, https://github.com/ranghetti/sen2r",TRUE,https://github.com/ranghetti/sen2r,6841,71,2020-06-04T11:48:14Z,96.35211267605634
sensemakr,"Implements a suite of sensitivity analysis tools 
  that extends the traditional omitted variable bias framework and makes it easier 
  to understand the impact of omitted variables in regression models, as discussed in Cinelli, C. and Hazlett, C. (2020), ""Making Sense of Sensitivity: Extending Omitted Variable Bias."" Journal of the Royal Statistical Society, Series B (Statistical Methodology) <doi:10.1111/rssb.12348>.",2020-04-28,Carlos Cinelli,https://github.com/chadhazlett/sensemakr,TRUE,https://github.com/chadhazlett/sensemakr,3690,28,2020-05-01T21:54:11Z,131.78571428571428
sensibo.sky,"Provides an interface to the 'Sensibo Sky' API which allows to remotely control non-smart air conditioning units.
  See <https://sensibo.com> for more informations.",2019-06-24,Gabriele Baldassarre,https://github.com/theclue/sensibo.sky,TRUE,https://github.com/theclue/sensibo.sky,3509,0,2019-06-23T09:05:45Z,NA
sensiPhy,"An implementation of sensitivity analysis for phylogenetic comparative
 methods. The package is an umbrella of statistical and graphical methods that 
 estimate and report different types of uncertainty in PCM:
 (i) Species Sampling uncertainty (sample size; influential species and clades).
 (ii) Phylogenetic uncertainty (different topologies and/or branch lengths).
 (iii) Data uncertainty (intraspecific variation and measurement error).",2020-04-02,Gustavo Paterno,https://github.com/paternogbc/sensiPhy,TRUE,https://github.com/paternogbc/sensiphy,12919,8,2020-04-02T13:36:00Z,1614.875
sensobol,"It allows to rapidly compute, bootstrap and plot up to third-order Sobol' indices
    using the estimators by Saltelli et al. 2010 <doi:10.1016/j.cpc.2009.09.018> and 
    Jansen 1999 <doi:10.1016/S0010-4655(98)00154-4>. The 'sensobol' package also implements
    the algorithm by Khorashadi Zadeh et al. 2017 <doi:10.1016/j.envsoft.2017.02.001> to 
    calculate the approximation error in the computation of Sobol' first and
    total indices, an approach that allows to robustly screen influential from non-influential
    model inputs. Finally, it also provides functions to obtain publication-ready figures
    of the model output uncertainty and sensitivity-related analysis.",2020-02-25,Arnald Puy,http://github.com/arnaldpuy/sensobol,TRUE,https://github.com/arnaldpuy/sensobol,5575,0,2020-04-24T23:48:07Z,NA
sentencepiece,"Unsupervised text tokenizer allowing to perform byte pair encoding and unigram modelling. 
    Wraps the 'sentencepiece' library <https://github.com/google/sentencepiece> which provides a language independent tokenizer to split text in words and smaller subword units. 
    The techniques are explained in the paper ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"" by Taku Kudo and John Richardson (2018) <doi:10.18653/v1/D18-2012>.
    Provides as well straightforward access to pretrained byte pair encoding models and subword embeddings trained on Wikipedia using 'word2vec', 
    as described in ""BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages"" by Benjamin Heinzerling and Michael Strube (2018) <http://www.lrec-conf.org/proceedings/lrec2018/pdf/1049.pdf>.",2020-06-08,Jan Wijffels,https://github.com/bnosac/sentencepiece,TRUE,https://github.com/bnosac/sentencepiece,0,15,2020-06-05T11:10:03Z,0
SentimentAnalysis,"Performs a sentiment analysis of textual contents in R. This implementation
    utilizes various existing dictionaries, such as Harvard IV, or finance-specific 
    dictionaries. Furthermore, it can also create customized dictionaries. The latter 
    uses LASSO regularization as a statistical approach to select relevant terms based on 
    an exogenous response variable. ",2019-03-26,Stefan Feuerriegel,https://github.com/sfeuerriegel/SentimentAnalysis,TRUE,https://github.com/sfeuerriegel/sentimentanalysis,54618,119,2020-01-26T19:52:38Z,458.97478991596637
sentimentr,"Calculate text polarity sentiment at the sentence level and
         optionally aggregate by rows or grouping variable(s).",2019-03-22,Tyler Rinker,http://github.com/trinker/sentimentr,TRUE,https://github.com/trinker/sentimentr,100490,287,2019-07-22T18:50:06Z,350.13937282229966
sentometrics,"Optimized prediction based on textual sentiment, accounting for the intrinsic challenge that sentiment can be computed and pooled across texts and time in various ways. See Ardia et al. (2020) <doi:10.2139/ssrn.3067734>.",2020-03-11,Samuel Borms,https://github.com/sborms/sentometrics,TRUE,https://github.com/sborms/sentometrics,12084,54,2020-05-23T09:14:49Z,223.77777777777777
sentryR,"Unofficial client for 'Sentry' <https://sentry.io>,
  a self-hosted or cloud-based error-monitoring service. It will inform about
  errors in real-time, and includes integration with the 'Plumber' package.",2020-03-19,Joao Santiago,https://github.com/ozean12/sentryR,TRUE,https://github.com/ozean12/sentryr,1199,13,2020-04-02T09:48:00Z,92.23076923076923
seplyr,"The 'seplyr' (standard evaluation plying) package supplies improved
    standard evaluation adapter methods for important common 'dplyr' data manipulation tasks.
    In addition the 'seplyr' package supplies several new ""key operations
    bound together"" methods.  These include 'group_summarize()' (which
    combines grouping, arranging and calculation in an atomic unit),
    'add_group_summaries()' (which joins grouped summaries into a 'data.frame'
    in a well documented manner), 'add_group_indices()' (which adds
    per-group identifiers to a 'data.frame' without depending on row-order),
    'partition_mutate_qt()' (which optimizes mutate sequences), and 'if_else_device()'
    (which simulates per-row if-else blocks in expression sequences).",2020-05-24,John Mount,"https://github.com/WinVector/seplyr/,
https://winvector.github.io/seplyr/",TRUE,https://github.com/winvector/seplyr,28552,49,2020-05-23T23:13:03Z,582.6938775510204
seqDesign,"A modification of the preventive vaccine efficacy trial design of Gilbert, Grove et al. (2011, Statistical Communications in Infectious Diseases) is implemented, with application generally to individual-randomized clinical trials with multiple active treatment groups and a shared control group, and a study endpoint that is a time-to-event endpoint subject to right-censoring. The design accounts for the issues that the efficacy of the treatment/vaccine groups may take time to accrue while the multiple treatment administrations/vaccinations are given; there is interest in assessing the durability of treatment efficacy over time; and group sequential monitoring of each treatment group for potential harm, non-efficacy/efficacy futility, and high efficacy is warranted. The design divides the trial into two stages of time periods, where each treatment is first evaluated for efficacy in the first stage of follow-up, and, if and only if it shows significant treatment efficacy in stage one, it is evaluated for longer-term durability of efficacy in stage two. The package produces plots and tables describing operating characteristics of a specified design including an unconditional power for intention-to-treat and per-protocol/as-treated analyses; trial duration; probabilities of the different possible trial monitoring outcomes (e.g., stopping early for non-efficacy); unconditional power for comparing treatment efficacies; and distributions of numbers of endpoint events occurring after the treatments/vaccinations are given, useful as input parameters for the design of studies of the association of biomarkers with a clinical outcome (surrogate endpoint problem). The code can be used for a single active treatment versus control design and for a single-stage design.",2019-05-22,Michal Juraska,https://github.com/mjuraska/seqDesign,TRUE,https://github.com/mjuraska/seqdesign,15419,1,2020-05-13T22:40:22Z,15419
seqgendiff,"Generates/modifies RNA-seq data for use in simulations. We provide
    a suite of functions that will add a known amount of signal to a real 
    RNA-seq dataset. The advantage of using this approach over simulating under
    a theoretical distribution is that common/annoying aspects of the data
    are more preserved, giving a more realistic evaluation of your method. 
    The main functions are select_counts(), thin_diff(), thin_lib(), 
    thin_gene(), thin_2group(), thin_all(), and effective_cor(). See
    Gerard (2020) <doi:10.1186/s12859-020-3450-9> for details on the
    implemented methods.",2020-05-24,David Gerard,https://github.com/dcgerard/seqgendiff,TRUE,https://github.com/dcgerard/seqgendiff,4272,1,2020-05-24T17:57:40Z,4272
seqHMM,"Designed for fitting hidden (latent) Markov models and mixture
    hidden Markov models for social sequence data and other categorical time series.
    Also some more restricted versions of these type of models are available: Markov
    models, mixture Markov models, and latent class models. The package supports
    models for one or multiple subjects with one or multiple parallel sequences
    (channels). External covariates can be added to explain cluster membership in
    mixture models. The package provides functions for evaluating and comparing
    models, as well as functions for visualizing of multichannel sequence data and
    hidden Markov models. Models are estimated using maximum likelihood via the EM
    algorithm and/or direct numerical maximization with analytical gradients. All
    main algorithms are written in C++ with support for parallel computation. 
    Documentation is available via several vignettes in this page, and the  
    paper by Helske and Helske (2019, <doi:10.18637/jss.v088.i03>).",2019-10-22,Jouni Helske,NA,TRUE,https://github.com/helske/seqhmm,21961,55,2019-10-22T09:48:30Z,399.2909090909091
seqmagick,"Supports reading and writing sequences for different formats (currently interleaved and sequential formats for 'FASTA' and 'PHYLIP'), file conversion, and manipulation (e.g. filter sequences that contain specify pattern, export consensus sequence from an alignment).",2019-12-19,Guangchuang Yu,https://github.com/YuLab-SMU/seqmagick,TRUE,https://github.com/yulab-smu/seqmagick,3080,3,2019-12-19T09:12:36Z,1026.6666666666667
seqminer,"Integrate sequencing data (Variant call format, e.g. VCF or BCF) or meta-analysis results in R. This package can help you (1) read VCF/BCF/BGEN files by chromosomal ranges (e.g. 1:100-200); (2) read RareMETAL summary statistics files; (3) read tables from a tabix-indexed files; (4) annotate VCF/BCF files; (5) create customized workflow based on Makefile.",2020-03-02,Xiaowei Zhan,http://seqminer.genomic.codes,TRUE,https://github.com/zhanxw/seqminer,31373,15,2020-02-29T15:10:45Z,2091.5333333333333
seriation,"Infrastructure for ordering objects with an implementation of several
    seriation/sequencing/ordination techniques to reorder matrices, dissimilarity
    matrices, and dendrograms. Also provides (optimally) reordered heatmaps,
    color images and clustering visualizations like dissimilarity plots, and
    visual assessment of cluster tendency plots (VAT and iVAT).",2019-08-27,Michael Hahsler,https://github.com/mhahsler/seriation,TRUE,https://github.com/mhahsler/seriation,979297,44,2020-04-19T16:58:09Z,22256.75
serrsBayes,"Sequential Monte Carlo (SMC) algorithms for fitting a generalised additive
    mixed model (GAMM) to surface-enhanced resonance Raman spectroscopy (SERRS),
    using the method of Moores et al. (2016) <arXiv:1604.07299>. Multivariate
    observations of SERRS are highly collinear and lend themselves to a reduced-rank
    representation. The GAMM separates the SERRS signal into three components: a
    sequence of Lorentzian, Gaussian, or pseudo-Voigt peaks; a smoothly-varying baseline;
    and additive white noise. The parameters of each component of the model are estimated
    iteratively using SMC. The posterior distributions of the parameters given the observed
    spectra are represented as a population of weighted particles.",2020-02-05,Matt Moores,"https://github.com/mooresm/serrsBayes,
https://mooresm.github.io/serrsBayes",TRUE,https://github.com/mooresm/serrsbayes,8069,3,2020-05-28T02:56:28Z,2689.6666666666665
servr,"Start an HTTP server in R to serve static files, or dynamic
    documents that can be converted to HTML files (e.g., R Markdown) under a
    given directory.",2020-05-26,Yihui Xie,https://github.com/yihui/servr,TRUE,https://github.com/yihui/servr,305799,207,2020-05-27T01:47:54Z,1477.2898550724638
set,"More easy to get intersection, union or complementary set and combinations.",2020-02-22,Zhi Jin,https://github.com/yikeshu0611/set,TRUE,https://github.com/yikeshu0611/set,4377,0,2020-02-23T07:56:02Z,NA
set6,"An object-oriented package for mathematical sets, upgrading the current gold-standard {sets}. Many forms of mathematical sets are implemented, including (countably finite) sets, tuples, intervals (countably infinite or uncountable), and fuzzy variants. Wrappers extend functionality by allowing symbolic representations of complex operations on sets, including unions, (cartesian) products, exponentiation, and differences (asymmetric and symmetric).",2020-05-18,Raphael Sonabend,"https://xoopR.github.io/set6/, https://github.com/xoopR/set6",TRUE,https://github.com/xoopr/set6,13443,8,2020-06-08T08:46:07Z,1680.375
Seurat,"A toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. 'Seurat' aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See Satija R, Farrell J, Gennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, and Stuart T, Butler A, et al (2019) <doi:10.1016/j.cell.2019.05.031> for more details. Please note:  SDMTools is available is available from the CRAN archives with install.packages(""https://cran.rstudio.com//src/contrib/Archive/SDMTools/SDMTools_1.1-221.2.tar.gz"", repos = NULL); it is not in the standard repositories.",2020-04-16,Rahul Satija,"http://www.satijalab.org/seurat,
https://github.com/satijalab/seurat",TRUE,https://github.com/satijalab/seurat,336069,811,2020-04-17T17:37:59Z,414.38840937114674
sf,"Support for simple features, a standardized way to
    encode spatial vector data. Binds to 'GDAL' for reading and writing
    data, to 'GEOS' for geometrical operations, and to 'PROJ' for
    projection conversions and datum transformations.",2020-05-04,Edzer Pebesma,"https://r-spatial.github.io/sf/, https://github.com/r-spatial/sf/",TRUE,https://github.com/r-spatial/sf,4383957,740,2020-06-05T22:48:48Z,5924.266216216216
sfdct,"Build a constrained Delaunay triangulation from simple features
    objects, applying constraints based on input line segments, and triangle
    properties including maximum area, minimum internal angle. The triangulation code
    in 'RTriangle' uses the method of Cheng, Dey and Shewchuk (2012, ISBN:9781584887300). 
    For a low-dependency alternative with low-quality path-based constrained 
    triangulation see <https://CRAN.R-project.org/package=decido>. ",2018-03-23,Michael D. Sumner,https://github.com/hypertidy/sfdct,TRUE,https://github.com/hypertidy/sfdct,9494,1,2020-04-13T17:50:32Z,9494
sfheaders,"Converts between R and Simple Feature 'sf' objects, without depending
  on the Simple Feature library. Conversion functions are available at both the R level, 
  and through 'Rcpp'.",2020-05-13,David Cooley,https://dcooley.github.io/sfheaders/,TRUE,https://github.com/dcooley/sfheaders,57694,42,2020-05-13T05:31:18Z,1373.6666666666667
sgd,"A fast and flexible set of tools for large scale estimation. It
    features many stochastic gradient methods, built-in models, visualization
    tools, automated hyperparameter tuning, model checking, interval estimation,
    and convergence diagnostics.",2019-07-12,Junhyung Lyle Kim,https://github.com/airoldilab/sgd,TRUE,https://github.com/airoldilab/sgd,14267,53,2019-07-12T21:11:20Z,269.188679245283
sgmcmc,"Provides functions that performs popular stochastic gradient Markov chain Monte Carlo (SGMCMC) methods on user specified models. The required gradients are automatically calculated using 'TensorFlow' <https://www.tensorflow.org/>, an efficient library for numerical computation. This means only the log likelihood and log prior functions need to be specified. The methods implemented include stochastic gradient Langevin dynamics (SGLD), stochastic gradient Hamiltonian Monte Carlo (SGHMC), stochastic gradient Nose-Hoover thermostat (SGNHT) and their respective control variate versions for increased efficiency. References: M. Welling, Y. W. Teh (2011) <http://www.icml-2011.org/papers/398_icmlpaper.pdf>; T. Chen, E. B. Fox, C. E. Guestrin (2014) <arXiv:1402.4102>; N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, H. Neven (2014) <https://papers.nips.cc/paper/5592-bayesian-sampling-using-stochastic-gradient-thermostats>; J. Baker, P. Fearnhead, E. B. Fox, C. Nemeth (2017) <arXiv:1706.05439>. For more details see <doi:10.18637/jss.v091.i03>.",2019-10-24,Jack Baker,https://github.com/STOR-i/sgmcmc,TRUE,https://github.com/stor-i/sgmcmc,10195,25,2020-02-25T10:14:55Z,407.8
SGP,"An analytic framework for the calculation of norm- and criterion-referenced academic growth estimates using large scale, longitudinal education assessment data as developed in Betebenner (2009) <doi:10.1111/j.1745-3992.2009.00161.x>.",2020-01-30,Damian W. Betebenner,"https://sgp.io, https://github.com/CenterForAssessment/SGP,
https://CRAN.R-project.org/package=SGP",TRUE,https://github.com/centerforassessment/sgp,26838,18,2020-06-08T11:09:17Z,1491
SGPdata,Data sets utilized by the 'SGP' package as exemplars for users to conduct their own student growth percentiles (SGP) analyses.,2020-01-15,Damian W. Betebenner,"https://CenterForAssessment.github.io/SGPdata,
https://github.com/CenterForAssessment/SGPdata,
https://cran.r-project.org/package=SGPdata",TRUE,https://github.com/centerforassessment/sgpdata,21219,2,2020-01-14T23:53:52Z,10609.5
shades,"Functions for easily manipulating colours, creating colour scales and calculating colour distances.",2019-08-02,Jon Clayden,https://github.com/jonclayden/shades,TRUE,https://github.com/jonclayden/shades,97921,55,2019-08-05T16:05:25Z,1780.3818181818183
shadow,"Functions for calculating: (1) shadow height, (2) logical shadow flag, (3) shadow footprint, (4) Sky View Factor and (5) radiation load. Basic required inputs include a polygonal layer of obstacle outlines along with their heights (i.e. ""extruded polygons""), sun azimuth and sun elevation. The package also provides functions for related preliminary calculations: breaking polygons into line segments, determining azimuth of line segments, shifting segments by azimuth and distance, constructing the footprint of a line-of-sight between an observer and the sun, and creating a 3D grid covering the surface area of extruded polygons.",2020-04-01,Michael Dorman,https://github.com/michaeldorman/shadow/,TRUE,https://github.com/michaeldorman/shadow,16701,17,2020-04-04T10:39:34Z,982.4117647058823
shadowtext,"Implement shadowtextGrob() for 'grid' and geom_shadowtext() layer for 'ggplot2'.
             These functions create/draw text grob with background shadow.",2019-11-06,Guangchuang Yu,https://github.com/GuangchuangYu/shadowtext/,TRUE,https://github.com/guangchuangyu/shadowtext,14002,27,2019-11-06T05:34:02Z,518.5925925925926
shallot,"Implementations are provided for the models described in the paper D. B. Dahl, R. Day, J. Tsai (2017) <DOI:10.1080/01621459.2016.1165103>. The Ewens, Ewens-Pitman, Ewens attraction, Ewens-Pitman attraction, and ddCRP distributions are available for prior and posterior simulation. Posterior simulation is based on a user-supplied likelihood. Supporting functions for partition estimation and plotting are also provided.",2020-04-04,David B. Dahl,https://github.com/dbdahl/shallot,TRUE,https://github.com/dbdahl/shallot,13912,3,2020-04-04T01:49:49Z,4637.333333333333
ShapeRotator,"Here we describe a simple geometric rigid rotation approach that removes the effect of random translation and rotation, enabling the morphological analysis of 3D articulated structures. Our method is based on Cartesian coordinates in 3D space so it can be applied to any morphometric problem that also uses 3D coordinates. See Vidal-García, M., Bandara, L., Keogh, J.S. (2018) <doi:10.1002/ece3.4018>.",2020-05-06,Marta Vidal-Garcia,https://github.com/marta-vidalgarcia/ShapeRotator,TRUE,https://github.com/marta-vidalgarcia/shaperotator,470,7,2020-05-17T03:31:07Z,67.14285714285714
SHAPforxgboost,"The aim of 'SHAPforxgboost' is to aid in visual data investigations
 using SHAP (SHapley Additive exPlanation) visualization plots for 'XGBoost'. 
 It provides summary plot, dependence plot, interaction plot, and force plot. 
 It relies on the 'dmlc/xgboost' package to produce SHAP values.
 Please refer to 'slundberg/shap' for the original implementation of SHAP in 'Python'. ",2020-05-14,Yang Liu,https://github.com/liuyanguu/SHAPforxgboost,TRUE,https://github.com/liuyanguu/shapforxgboost,5978,28,2020-05-17T21:27:41Z,213.5
shapper,"Provides SHAP explanations of machine learning models. In applied machine learning, there is a strong belief that we need to strike a balance between interpretability and accuracy. However, in field of the Interpretable Machine Learning, there are more and more new ideas for explaining black-box models. One of the best known method for local explanations is SHapley Additive exPlanations (SHAP) introduced by Lundberg, S., et al., (2016) <arXiv:1705.07874> The SHAP method is used to calculate influences of variables on the particular observation. This method is based on Shapley values, a technique used in game theory. The R package 'shapper' is a port of the Python library 'shap'. ",2019-08-02,Szymon Maksymiuk,https://github.com/ModelOriented/shapper,TRUE,https://github.com/modeloriented/shapper,7727,38,2020-04-15T12:31:09Z,203.3421052631579
shar,"
  Analyse species-habitat associations in R. Therefore, information about the 
  location of the species is needed and about the environmental conditions. To test 
  for significance habitat associations, one of the two components is randomized. 
  Methods are mainly based on Plotkin et al. (2000) <doi:10.1006/jtbi.2000.2158> and 
  Harms et al. (2001) <doi:10.1111/j.1365-2745.2001.00615.x>.",2019-11-15,Maximillian H.K. Hesselbarth,https://r-spatialecology.github.io/shar,TRUE,https://github.com/r-spatialecology/shar,6563,2,2020-03-20T08:18:19Z,3281.5
sharpshootR,"Miscellaneous soil data management, summary, visualization, and conversion utilities to support soil survey.",2020-01-30,Dylan Beaudette,https://github.com/ncss-tech/aqp,TRUE,https://github.com/ncss-tech/aqp,20105,18,2020-06-09T19:28:39Z,1116.9444444444443
SHELF,"Implements various methods for eliciting a probability distribution
    for a single parameter from an expert or a group of experts. The expert
    provides a small number of probability judgements, corresponding
    to points on his or her cumulative distribution function. A range of parametric
    distributions can then be fitted and displayed, with feedback provided in the
    form of fitted probabilities and percentiles. For multiple experts, a weighted
    linear pool can be calculated. Also includes functions for eliciting beliefs
    about population distributions, eliciting multivariate distributions using a
    Gaussian copula, eliciting a Dirichlet distribution, and eliciting distributions 
    for variance parameters in a random effects meta-analysis model. R Shiny apps  
    for most of the methods are included. ",2020-02-08,Jeremy Oakley,https://github.com/OakleyJ/SHELF,TRUE,https://github.com/oakleyj/shelf,18179,1,2020-05-26T10:43:32Z,18179
ShiftShareSE,"Provides confidence intervals in least-squares regressions when the
  variable of interest has a shift-share structure, and in instrumental
  variables regressions when the instrument has a shift-share structure. The
  confidence intervals implement the AKM and AKM0 methods developed in Adão,
  Kolesár, and Morales (2019) <doi:10.1093/qje/qjz025>.",2020-01-07,Michal Kolesár,https://github.com/kolesarm/ShiftShareSE,TRUE,https://github.com/kolesarm/shiftsharese,3242,5,2020-01-09T15:08:44Z,648.4
shinipsum,"Prototype your 'shiny' apps quickly with these
    Lorem-Ipsum helper functions. Generate random elements
    for 'shiny' outputs that can be used as placeholder in your application.",2020-04-30,Colin Fay,https://github.com/Thinkr-open/shinipsum,TRUE,https://github.com/thinkr-open/shinipsum,733,64,2019-10-01T17:08:06Z,11.453125
shiny,"Makes it incredibly easy to build interactive web
    applications with R. Automatic ""reactive"" binding between inputs and
    outputs and extensive prebuilt widgets make it possible to build
    beautiful, responsive, and powerful applications with minimal effort.",2020-03-13,Winston Chang,http://shiny.rstudio.com,TRUE,https://github.com/rstudio/shiny,13371199,3844,2020-06-05T14:42:53Z,3478.4596774193546
shiny.i18n,"It provides easy internationalization of Shiny
    applications. It can be used as standalone translation package
    to translate reports, interactive visualizations or
    graphical elements as well.",2018-09-13,Dominik Krzemiński,http://github.com/Appsilon/shiny.i18n,TRUE,https://github.com/appsilon/shiny.i18n,8837,70,2020-06-01T16:57:38Z,126.24285714285715
shiny.info,Displays simple diagnostic information of the 'shiny' project in the user interface of the app.,2020-03-23,Jakub Nowicki,NA,TRUE,https://github.com/appsilon/shiny.info,1078,28,2020-04-06T15:38:13Z,38.5
shiny.semantic,"Creating a great user interface for your Shiny apps
    can be a hassle, especially if you want to work purely in R
    and don't want to use, for instance HTML templates. This
    package adds support for a powerful UI library Semantic UI -
    <http://semantic-ui.com/>. It also supports universal UI input 
    binding that works with various DOM elements.",2020-03-13,Dominik Krzeminski,NA,TRUE,https://github.com/appsilon/shiny.semantic,23117,246,2020-06-09T08:00:50Z,93.97154471544715
shinyAce,"Ace editor bindings to enable a rich text editing environment
    within Shiny.",2019-09-24,Vincent Nijs,NA,TRUE,https://github.com/trestletech/shinyace,238054,179,2020-05-26T00:43:14Z,1329.9106145251396
shinybrms,"A graphical user interface (GUI) for the 
    package 'brms' which allows to fit Bayesian regression models using 'Stan' 
    (<https://mc-stan.org/>) (more specifically, using its R interface, the 
    package 'rstan'). The GUI is a 'Shiny' (<https://shiny.rstudio.com/>) app, 
    i.e. it was created using the package 'shiny'.",2020-06-09,Frank Weber,https://github.com/fweber144/shinybrms,TRUE,https://github.com/fweber144/shinybrms,1068,1,2020-06-09T18:58:27Z,1068
shinybusy,"Add a global indicator (spinner, progress bar, gif) in your 'shiny' applications to show the user that the server is busy.",2019-10-29,Victor Perrier,https://github.com/dreamRs/shinybusy,TRUE,https://github.com/dreamrs/shinybusy,10747,71,2020-05-15T12:35:48Z,151.3661971830986
shinycssloaders,Automatically show loader animations while a Shiny output is (re)calculating. This is mostly a wrapper around the css-loaders created by Luke Hass <https://github.com/lukehaas/css-loaders>.,2020-01-16,Andras Sali,https://github.com/andrewsali/shinycssloaders,TRUE,https://github.com/andrewsali/shinycssloaders,235959,207,2020-06-09T04:02:38Z,1139.8985507246377
shinyCyJS,"Create Interactive Graph (Network) Visualizations. 
  'shinyCyJS' can be used in 'Shiny' apps or viewed from 'Rstudio' Viewer.
  'shinyCyJS' includes API to build Graph model like node or edge with customized attributes for R. 
  'shinyCyJS' is built with 'cytoscape.js' and 'htmlwidgets' R package.",2020-03-26,Jinhwan Kim,https://github.com/jhk0530/shinyCyJS,TRUE,https://github.com/jhk0530/shinycyjs,1021,2,2020-04-03T17:45:14Z,510.5
shinydashboard,"Create dashboards with 'Shiny'. This package provides
    a theme on top of 'Shiny', making it easy to create attractive dashboards.",2018-10-17,Winston Chang,http://rstudio.github.io/shinydashboard/,TRUE,https://github.com/rstudio/shinydashboard,1321760,656,2020-02-22T21:41:37Z,2014.878048780488
shinydashboardPlus,"Extend 'shinydashboard' with 'AdminLTE2' components. 
             'AdminLTE2' is a free 'Bootstrap 3' dashboard template available
             at <https://adminlte.io>. Customize boxes, add timelines and a lot more. ",2019-04-08,David Granjon,"https://github.com/RinteRface/shinydashboardPlus,
https://rinterface.com/shiny/shinydashboardPlus/",TRUE,https://github.com/rinterface/shinydashboardplus,116445,234,2020-05-07T06:36:35Z,497.62820512820514
shinyEffects,"Add fancy CSS effects to your 'shinydashboards' or 'shiny' apps.
             100% compatible with 'shinydashboardPlus' and 'bs4Dash'.",2018-11-18,David Granjon,"https://github.com/DivadNojnarg/shinyEffects,
https://divadnojnarg.github.io/shinyEffects/",TRUE,https://github.com/divadnojnarg/shinyeffects,28176,33,2019-10-14T06:43:36Z,853.8181818181819
shinyFeedback,Easily display user feedback in Shiny apps.,2020-04-29,Andy Merlino,https://github.com/merlinoa/shinyFeedback,TRUE,https://github.com/merlinoa/shinyfeedback,20569,98,2020-05-15T14:32:05Z,209.8877551020408
shinyFiles,"Provides functionality for client-side navigation of
    the server side file system in shiny apps. In case the app is running
    locally this gives the user direct access to the file system without the
    need to ""download"" files to a temporary location. Both file and folder
    selection as well as file saving is available.",2020-04-14,Thomas Lin Pedersen,https://github.com/thomasp85/shinyFiles,TRUE,https://github.com/thomasp85/shinyfiles,202374,117,2020-05-09T21:32:13Z,1729.6923076923076
shinyglide,"Insert Glide JavaScript component into Shiny applications for
    carousel or assistant-like user interfaces.",2019-10-12,Julien Barnier,"https://juba.github.io/shinyglide/,
https://github.com/juba/shinyglide",TRUE,https://github.com/juba/shinyglide,4291,47,2020-05-26T13:04:45Z,91.29787234042553
shinyHeatmaply,Access functionality of the 'heatmaply' package through 'Shiny UI'.,2020-04-06,Jonathan Sidi,https://github.com/yonicd/shinyHeatmaply,TRUE,https://github.com/yonicd/shinyheatmaply,16652,35,2020-04-03T11:08:19Z,475.77142857142854
shinyhelper,"Creates a lightweight way to add markdown helpfiles to 'shiny' apps,
    using modal dialog boxes, with no need to observe each help button separately.",2019-11-09,Chris Mason-Thom,NA,TRUE,https://github.com/cwthom/shinyhelper,35812,75,2019-11-09T13:03:05Z,477.49333333333334
ShinyItemAnalysis,"Interactive shiny application for analysis of educational tests and
    their items.",2020-05-04,Patricia Martinkova,"http://www.ShinyItemAnalysis.org,
https://CRAN.R-project.org/package=ShinyItemAnalysis",TRUE,https://github.com/patriciamar/shinyitemanalysis,25317,19,2020-05-18T11:42:43Z,1332.4736842105262
shinyjqui,"An extension to shiny that brings interactions and animation effects from
    'jQuery UI' library.",2020-02-03,Yang Tang,https://github.com/yang-tang/shinyjqui,TRUE,https://github.com/yang-tang/shinyjqui,78777,209,2020-02-13T15:53:25Z,376.92344497607655
shinyjs,"Perform common useful JavaScript operations in Shiny apps that will
    greatly improve your apps without having to know any JavaScript. Examples
    include: hiding an element, disabling an input, resetting an input back to
    its original value, delaying code execution by a few seconds, and many more
    useful functions for both the end user and the developer. 'shinyjs' can also
    be used to easily call your own custom JavaScript functions from R.",2020-01-13,Dean Attali,https://deanattali.com/shinyjs,TRUE,https://github.com/daattali/shinyjs,1354660,493,2020-06-09T04:06:49Z,2747.789046653144
shinyKnobs,"A collection of highly configurable, touch-enabled knob input controls for 'shiny'. These components can be styled to fit in perfectly in any app, and allow users to set precise values through many input modalities. Users can touch-and-drag, click-and-drag, scroll their mouse wheel, double click, or use keyboard input.",2020-02-13,Patrice Cote,https://github.com/cotepat/shinyKnobs,TRUE,https://github.com/cotepat/shinyknobs,1632,2,2020-01-07T11:51:30Z,816
shinyloadtest,"Assesses the number of concurrent users 'shiny'
  applications are capable of supporting, and for directing application changes
  in order to support a higher number of users. Provides facilities for recording
  'shiny' application sessions, playing recorded sessions against a target
  server at load, and analyzing the resulting metrics.",2020-01-09,Alan Dipert,"https://rstudio.github.io/shinyloadtest/,
https://github.com/rstudio/shinyloadtest",TRUE,https://github.com/rstudio/shinyloadtest,2563,76,2020-05-22T19:59:01Z,33.723684210526315
shinylogs,"Track and record the use of applications and the user's interactions with 'Shiny' inputs.
  Allow to save inputs clicked, output generated and eventually errors.",2019-08-21,Victor Perrier,https://github.com/dreamRs/shinylogs,TRUE,https://github.com/dreamrs/shinylogs,5160,50,2019-12-30T09:02:41Z,103.2
shinymanager,"Simple and secure authentification mechanism for single 'Shiny' applications.
    Credentials are stored in an encrypted 'SQLite' database. Source code of main application
    is protected until authentication is successful.",2020-02-28,Benoit Thieurmel,https://github.com/datastorm-open/shinymanager,TRUE,https://github.com/datastorm-open/shinymanager,8175,119,2020-06-02T12:51:20Z,68.69747899159664
shinyMobile,"Develop outstanding 'shiny' apps for 'iOS', 'Android', desktop as well as beautiful 'shiny' gadgets.
    'shinyMobile' is built on top of the latest 'Framework7' template <https://framework7.io>.
    Discover 14 new input widgets (sliders, vertical sliders, stepper, 
    grouped action buttons, toggles, picker, smart select, ...), 2 themes (light and dark), 
    12 new widgets (expandable cards, badges, chips, timelines, gauges, progress bars, ...) 
    combined with the power of server-side notifications such as alerts, modals, toasts,
    action sheets, sheets (and more) as well as 3 layouts (single, tabs and split).",2019-11-30,David Granjon,"https://github.com/RinteRface/shinyMobile,
https://rinterface.github.io/shinyMobile/",TRUE,https://github.com/rinterface/shinymobile,3667,170,2020-06-09T00:49:51Z,21.570588235294117
shinyMolBio,"Interactive visualization of 'RDML' files via 'shiny' apps. 
  Package provides (1) PCR plate interface with ability to select
  individual tubes and (2) amplification/melting plots with fast hiding and 
  highlighting individual curves.",2019-08-02,Konstantin A. Blagodatskikh,"https://github.com/kablag/shinyMolBio,
https://kablag.github.io/shinyMolBio/",TRUE,https://github.com/kablag/shinymolbio,3957,3,2020-05-07T09:37:28Z,1319
shinyNotes,"An enterprise-targeted scalable and customizable 'shiny' module providing an easy way to incorporate free-form note taking or discussion boards into applications.
    The package includes a 'shiny' module that can be included in any 'shiny' application to create a panel containing searchable, editable text broken down by section headers.
    Can be used with a local 'SQLite' database, or a compatible remote database of choice.",2020-02-05,Daniel Kovtun,https://github.com/danielkovtun/shinyNotes,TRUE,https://github.com/danielkovtun/shinynotes,1755,1,2020-01-31T03:24:18Z,1755
shinyobjects,"Troubleshooting reactive data in 'shiny' can be difficult. These functions will convert reactive data frames into functions and load all assigned objects into your local environment. If you create a dummy input object, as the function will suggest, you will be able to test your server and ui functions interactively.",2020-05-12,Jake Riley,NA,TRUE,https://github.com/rjake/shinyobjects,369,8,2020-06-02T02:27:10Z,46.125
shinypanels,"Create 'Shiny Apps' with collapsible vertical panels. 
    This package provides a new visual arrangement for elements on top of 'Shiny'. 
    Use the expand and collapse capabilities to leverage web applications with
    many elements to focus the user attention on the panel of interest.",2020-01-26,Juan Pablo Marin Diaz,http://github.com/datasketch/shinypanels,TRUE,https://github.com/datasketch/shinypanels,1930,18,2020-06-01T17:26:44Z,107.22222222222223
shinyrecipes,"This gadget allows you to use the 'recipes' package belonging to 'tidymodels' to carry 
    out the data preprocessing tasks in an interactive way. Build your 'recipe' by dragging the variables, 
    visually analyze your data to decide which steps to use, add those steps and preprocess your data.",2020-05-05,Alberto Almuiña,https://github.com/AlbertoAlmuinha/shinyrecipes,TRUE,https://github.com/albertoalmuinha/shinyrecipes,978,11,2020-05-06T12:41:12Z,88.9090909090909
shinyreforms,"Allows to create modular, reusable 'HTML'
    forms which can be embedded in your 'shiny' app with minimal effort.
    Features include conditional code execution on form submission,
    automatic input validation and input tooltips.",2020-05-12,Piotr Bajger,https://github.com/piotrbajger/shinyreforms,TRUE,https://github.com/piotrbajger/shinyreforms,371,8,2020-05-09T09:34:41Z,46.375
shinySearchbar,"Add a searchbar widget to your 'Shiny' application. The widget
  quickly integrates with any existing element containing text to highlight
  matches. Highlighting is done with the 'JavaScript' library 'mark.js'. The
  widget includes buttons to cycle through multiple instances of the match and
  automatically scroll to the matches in an overflow element (or window). The
  widget also displays the total number of matches and which match is currently
  being cycled through. The widget is structured as a 'Bootstrap 3' input
  group.",2020-06-02,Jesse Norris,https://github.com/jes-n/shiny-searchbar,TRUE,https://github.com/jes-n/shiny-searchbar,0,3,2020-06-08T01:30:31Z,0
shinystan,"A graphical user interface for interactive Markov chain Monte
    Carlo (MCMC) diagnostics and plots and tables helpful for analyzing a
    posterior sample. The interface is powered by the 'Shiny' web
    application framework from 'RStudio' and works with the output of MCMC 
    programs written in any programming language (and has extended 
    functionality for 'Stan' models fit using the 'rstan' and 'rstanarm' 
    packages).",2018-05-01,Jonah Gabry,"http://mc-stan.org/, http://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/shinystan,551624,161,2020-06-03T22:31:31Z,3426.2360248447203
shinytest,"For automated testing of Shiny applications, using a headless
    browser, driven through 'WebDriver'.",2019-05-06,Winston Chang,https://github.com/rstudio/shinytest,TRUE,https://github.com/rstudio/shinytest,91995,167,2020-03-25T21:28:05Z,550.8682634730538
shinyTime,"Provides a time input widget for Shiny. This widget allows intuitive time input in the
    '[hh]:[mm]:[ss]' or '[hh]:[mm]' (24H) format by using a separate numeric input for each time
    component. The interface with R uses date-time objects. See the project page for more
    information and examples.",2019-08-06,Gerhard Burger,"https://burgerga.github.io/shinyTime/,
https://github.com/burgerga/shinyTime",TRUE,https://github.com/burgerga/shinytime,42710,17,2019-08-06T20:05:45Z,2512.3529411764707
shinyTree,"Exposes bindings to jsTree -- a JavaScript library
    that supports interactive trees -- to enable a rich, editable trees in
    Shiny.",2019-05-27,Mike Schaffer,NA,TRUE,https://github.com/trestletech/shinytree,36617,101,2020-06-01T17:16:33Z,362.54455445544556
shinyWidgets,"Collection of custom input controls and user interface components for 'Shiny' applications. 
  Give your applications a unique and colorful style !",2020-06-01,Victor Perrier,https://github.com/dreamRs/shinyWidgets,TRUE,https://github.com/dreamrs/shinywidgets,528842,458,2020-06-01T08:49:05Z,1154.6768558951965
shinyypr,A user interface to the 'ypr' R package. 'Ypr' implements equilibrium-based yield per recruit methods for estimating the optimal yield for a fish population.,2020-03-24,Sebastian Dalgarno,https://github.com/poissonconsulting/shinyypr,TRUE,https://github.com/poissonconsulting/shinyypr,1811,0,2020-03-24T21:10:37Z,NA
shopifyr,"An interface to the Admin API of the E-commerce service Shopify,
    (<https://help.shopify.com/en/api/reference>).",2019-07-22,Charlie Friedemann,https://github.com/charliebone/shopifyr/,TRUE,https://github.com/charliebone/shopifyr,15846,11,2019-08-11T01:40:35Z,1440.5454545454545
shortcuts,"Integrates clipboard copied data in R Studio, loads and installs libraries within a R script and returns all valid arguments of a selected function.",2019-12-17,José Carlos Del Valle,https://github.com/jcval94/shortcuts,TRUE,https://github.com/jcval94/shortcuts,2480,3,2019-12-17T05:45:21Z,826.6666666666666
ShortForm,"Performs automatic creation of short forms of scales with an 
    ant colony optimization algorithm and a Tabu search. As implemented in the 
    package, the ant colony algorithm randomly selects items to build a model of 
    a specified length, then updates the probability of item selection according 
    to the fit of the best model within each set of searches. The algorithm 
    continues until the same items are selected by multiple ants a given number 
    of times in a row. On the other hand, the Tabu search changes one parameter at
    a time to be either free, constrained, or fixed while keeping track of the
    changes made and putting changes that result in worse fit in a ""tabu"" list
    so that the algorithm does not revisit them for some number of searches. 
    See Leite, Huang, & Marcoulides (2008) <doi:10.1080/00273170802285743> for
    an applied example of the ant colony algorithm, and Marcoulides & Falk (2018)
    <doi:10.1080/10705511.2017.1409074> for an applied example of the Tabu search.",2020-03-13,Anthony Raborn,https://github.com/AnthonyRaborn/ShortForm,TRUE,https://github.com/anthonyraborn/shortform,11914,3,2020-03-13T16:09:47Z,3971.3333333333335
shorts,"Create short sprint (<6sec) profiles using the split times or the radar gun data.
    Mono-exponential equation is used to estimate maximal sprinting speed (MSS), relative acceleration (TAU),
    and other parameters such us maximal acceleration (MAC) and maximal relative power (PMAX). These parameters 
    can be used to predict kinematic and kinetics variables and to compare individuals. The modeling method utilized
    in this package is based on the works of Chelly SM, Denis C. (2001) <doi: 10.1097/00005768-200102000-00024>,
    Clark KP, Rieger RH, Bruno RF, Stearne DJ. (2017) <doi: 10.1519/JSC.0000000000002081>, 
    Furusawa K, Hill AV, Parkinson JL (1927) <doi: 10.1098/rspb.1927.0035>, 
    Greene PR. (1986) <doi: 10.1016/0025-5564(86)90063-5>, and 
    Samozino P. (2018) <doi: 10.1007/978-3-319-05633-3_11>.",2020-05-08,Mladen Jovanovic,https://mladenjovanovic.github.io/shorts/,TRUE,https://github.com/mladenjovanovic/shorts,853,2,2020-05-07T20:30:48Z,426.5
showtext,"Making it easy to use various types of fonts ('TrueType',
    'OpenType', Type 1, web fonts, etc.) in R graphs, and supporting most output
    formats of R graphics including PNG, PDF and SVG. Text glyphs will be converted
    into polygons or raster images, hence after the plot has been created, it no
    longer relies on the font files. No external software such as 'Ghostscript' is
    needed to use this package.",2020-05-25,"Yixuan Qiu and authors/contributors of the
    included software. See file AUTHORS for details.",https://github.com/yixuan/showtext,TRUE,https://github.com/yixuan/showtext,288525,296,2020-05-21T18:14:55Z,974.7466216216217
ShrinkCovMat,"Provides nonparametric Steinian shrinkage estimators of the covariance matrix that are suitable in high dimensional settings, that is when the number of variables is larger than the sample size.",2019-07-30,Anestis Touloumis,http://github.com/AnestisTouloumis/ShrinkCovMat,TRUE,https://github.com/anestistouloumis/shrinkcovmat,16579,5,2020-01-17T09:50:38Z,3315.8
SHT,"We provide a collection of statistical hypothesis testing procedures ranging from classical to modern methods for non-trivial settings such as high-dimensional scenario. For the general treatment of statistical hypothesis testing, see the book by Lehmann and Romano (2005) <doi:10.1007/0-387-27605-X>.",2020-03-19,Kisung You,https://github.com/kyoustat/SHT,TRUE,https://github.com/kyoustat/sht,6251,2,2020-03-18T17:51:12Z,3125.5
sicegar,"Aims to quantify time intensity data by using sigmoidal and double sigmoidal curves. It fits straight lines, sigmoidal, and double sigmoidal curves on to time vs intensity data. Then all the fits are used to make decision on which model (sigmoidal, double sigmoidal, no signal or ambiguous) best describes the data. No signal means the intensity does not reach a high enough point or does not change at all over time. Sigmoidal means intensity starts from a small number than climbs to a maximum. Double sigmoidal means intensity starts from a small number, climbs to a maximum then starts to decay. After the decision between those four options, the algorithm gives the sigmoidal (or double sigmoidal) associated parameter values that quantifies the time intensity curve. The origin of the package name came from ""SIngle CEll Growth Analysis in R"".",2019-08-23,Claus O. Wilke,https://github.com/wilkelab/sicegar,TRUE,https://github.com/wilkelab/sicegar,11175,2,2019-08-23T17:48:23Z,5587.5
sidrar,"Allows the user to connect with IBGE's (Instituto Brasileiro de 
    Geografia e Estatistica, see <http://www.ibge.gov.br/> for more information)
    SIDRA API in a flexible way. SIDRA is the acronym to ""Sistema IBGE de 
    Recuperacao Automatica"" and is the system where IBGE turns available 
    aggregate data from their researches.",2020-01-27,Renato Prado Siqueira,http://github.com/rpradosiqueira/sidrar,TRUE,https://github.com/rpradosiqueira/sidrar,34092,24,2020-01-27T15:05:30Z,1420.5
sievePH,"Implements semiparametric estimation and testing procedures for a continuous, possibly multivariate, mark-specific hazard ratio (treatment/placebo) of an event of interest in a randomized treatment efficacy trial with a time-to-event endpoint, as described in Juraska M and Gilbert PB (2013), Mark-specific hazard ratio model with multivariate continuous marks: an application to vaccine efficacy. Biometrics 69(2):328 337 <doi:10.1111/biom.12016>, and in Juraska M and Gilbert PB (2015), Mark-specific hazard ratio model with missing multivariate marks. Lifetime Data Analysis 22(4): 606-25 <doi:10.1007/s10985-015-9353-9>. The former considers continuous multivariate marks fully observed in all subjects who experience the event of interest, whereas the latter extends the previous work to allow multivariate marks that are subject to missingness-at-random. For models with missing marks, two estimators are implemented based on (i) inverse probability weighting (IPW) of complete cases, and (ii) augmentation of the IPW estimating functions by leveraging correlations between the mark and auxiliary data to 'impute' the expected profile score vectors for subjects with missing marks. The augmented IPW estimator is doubly robust and recommended for use with incomplete mark data. The methods make two key assumptions: (i) the time-to-event is assumed to be conditionally independent of the mark given treatment, and (ii) the weight function in the semiparametric density ratio/biased sampling model is assumed to be exponential. Diagnostic testing procedures for evaluating validity of both assumptions are implemented. Summary and plotting functions are provided for estimation and inferential results.",2019-12-06,Michal Juraska,https://github.com/mjuraska/sievePH,TRUE,https://github.com/mjuraska/sieveph,4841,0,2019-12-06T00:32:48Z,NA
sigInt,Provides pseudo-likelihood methods for empirically analyzing common signaling games in international relations as described in Crisman-Cox and Gibilisco (2019) <doi:10.1017/psrm.2019.58>.,2019-12-17,Casey Crisman-Cox,https://github.com/ccrismancox/sigint,TRUE,https://github.com/ccrismancox/sigint,2309,0,2020-06-04T15:31:55Z,NA
sigminer,"Genomic alterations including single nucleotide
    substitution, copy number alteration, etc. are the major force for
    cancer initialization and development. Due to the specificity of
    molecular lesions caused by genomic alterations, we can generate
    characteristic alteration spectra, called 'signature' (Wang, Shixiang,
    et al.  (2020) <DOI:10.1101/2020.04.27.20082404> & Alexandrov, Ludmil
    B., et al. (2020) <DOI:10.1038/s41586-020-1943-3> & Macintyre, Geoff,
    et al. (2018) <DOI:10.1038/s41588-018-0179-8>).  This package helps
    users to extract, analyze and visualize signatures from genomic
    alteration records, thus providing new insight into cancer study.",2020-06-01,Shixiang Wang,https://github.com/ShixiangWang/sigminer,TRUE,https://github.com/shixiangwang/sigminer,3594,45,2020-06-09T02:52:53Z,79.86666666666666
Signac,"A framework for the analysis and exploration of single-cell chromatin data.
    The 'Signac' package contains functions for quantifying single-cell chromatin data,
    computing per-cell quality control metrics, dimension reduction
    and normalization, visualization, and DNA sequence motif analysis.
    Reference: Stuart and Butler et al. (2019) <doi:10.1016/j.cell.2019.05.031>.",2020-04-16,Tim Stuart,"https://github.com/timoast/signac, https://satijalab.org/signac",TRUE,https://github.com/timoast/signac,3028,40,2020-04-20T15:25:38Z,75.7
signalHsmm,"Predicts the presence of signal peptides in eukaryotic protein
    using hidden semi-Markov models. The implemented algorithm can be accessed from
    both the command line and GUI.",2018-11-15,Michal Burdukiewicz,https://github.com/michbur/signalhsmm,TRUE,https://github.com/michbur/signalhsmm,13451,2,2020-05-04T14:03:28Z,6725.5
signnet,"Methods for the analysis of signed networks. This includes several measures for structural balance as introduced by Cartwright and Harary (1956) <doi:10.1037/h0046049>, blockmodeling algorithms from Doreian (2008) <doi:10.1016/j.socnet.2008.03.005>, various centrality indices, and projections of signed two-mode networks introduced by Schoch (2020) <doi:10.1080/0022250X.2019.1711376>.",2020-03-04,David Schoch,https://github.com/schochastics/signnet,TRUE,https://github.com/schochastics/signnet,2411,9,2020-04-08T14:46:33Z,267.8888888888889
signs,"Provides convenience functions to replace hyphen-minuses (ASCII 45)
    with proper minus signs (Unicode character 2212). The true minus matches
    the plus symbol in width, line thickness, and height above the baseline.
    It was designed for mathematics, looks better in presentation,
    and is understood properly by screen readers.",2020-01-16,Benjamin E. Wolfe,https://benjaminwolfe.github.io/signs,TRUE,https://github.com/benjaminwolfe/signs,3392,14,2020-01-16T19:20:21Z,242.28571428571428
sigr,"Succinctly and correctly format statistical summaries of
    various models and tests (F-test, Chi-Sq-test, Fisher-test, T-test, and rank-significance).  The main purpose is unified reporting 
    of experimental results, working around issue such as the difficulty of
    extracting model summary facts (such as with 'lm'/'glm').  This package also
    includes empirical tests, such as bootstrap estimates.",2019-07-24,John Mount,"https://github.com/WinVector/sigr/,
https://winvector.github.io/sigr/",TRUE,https://github.com/winvector/sigr,40024,25,2020-02-02T17:07:14Z,1600.96
silicate,"Generate common data forms for complex data suitable for conversions and
 transmission by decomposition as paths or primitives. Paths are sequentially-linked records, 
 primitives are basic atomic elements and both can model many forms and be grouped into hierarchical 
 structures.  The universal models 'SC0' (structural) and 'SC' (labelled, relational) are composed of 
 edges and can represent any hierarchical form. Specialist models 'PATH', 'ARC' and 'TRI' provide the 
 most common intermediate forms used for converting from one form to another. The methods are
 inspired by the simplicial complex <https://en.wikipedia.org/wiki/Simplicial_complex> and 
 provide intermediate forms that relate spatial data structures to this mathematical construct. ",2020-05-12,Michael D. Sumner,https://github.com/hypertidy/silicate,TRUE,https://github.com/hypertidy/silicate,5082,41,2020-05-15T00:01:32Z,123.95121951219512
Sim.DiffProc,"It provides users with a wide range of tools to simulate, estimate, analyze, and visualize the dynamics of stochastic differential systems in both forms Ito and Stratonovich. Statistical analysis with parallel Monte Carlo and moment equations methods of SDE's. Enabled many searchers in different domains to use these equations to modeling practical problems in financial and actuarial modeling and other areas of application, e.g., modeling and simulate of first passage time problem in shallow water using the attractive center (Boukhetala K, 1996) ISBN:1-56252-342-2. ",2020-05-04,Arsalane Chouaib Guidoum,https://github.com/acguidoum/Sim.DiffProc,TRUE,https://github.com/acguidoum/sim.diffproc,54840,7,2020-05-06T10:44:19Z,7834.285714285715
sim2Dpredictr,"Provides tools for simulating spatially dependent predictors (continuous or binary),
    which are used to generate scalar outcomes in a (generalized) linear model framework. Continuous
    predictors are generated using traditional multivariate normal distributions or Gauss Markov random
    fields with several correlation function approaches (e.g., see Rue (2001) <doi:10.1111/1467-9868.00288>
    and Furrer and Sain (2010) <doi:10.18637/jss.v036.i10>), while binary predictors are generated using
    a Boolean model (see Cressie and Wikle (2011, ISBN: 978-0-471-69274-4)). Parameter vectors 
	exhibiting spatial clustering can also be easily specified by the user.  ",2020-03-14,Justin Leach,http://github.com/jmleach-bst/sim2Dpredictr,TRUE,https://github.com/jmleach-bst/sim2dpredictr,1268,0,2020-05-13T21:56:57Z,NA
SimBIID,"Provides some code to run simulations of state-space models, and then
             use these in the Approximate Bayesian Computation Sequential Monte Carlo (ABC-SMC) 
             algorithm of Toni et al. (2009) <doi:10.1098/rsif.2008.0172> and a bootstrap particle
             filter based particle Markov chain Monte Carlo (PMCMC) algorithm 
             (Andrieu et al., 2010 <doi:10.1111/j.1467-9868.2009.00736.x>). 
             Also provides functions to plot and summarise the outputs.",2020-05-20,Trevelyan J. McKinley,https://github.com/tjmckinley/SimBIID,TRUE,https://github.com/tjmckinley/simbiid,3959,1,2020-05-20T18:52:17Z,3959
simcdm,"Provides efficient R and 'C++' routines to simulate cognitive diagnostic
    model data for Deterministic Input, Noisy ""And"" Gate ('DINA') and
    reduced Reparameterized Unified Model ('rRUM') from 
    Culpepper and Hudson (2017) <doi: 10.1177/0146621617707511>,
    Culpepper (2015) <doi:10.3102/1076998615595403>, and
    de la Torre (2009) <doi:10.3102/1076998607309474>.",2019-03-10,James Joseph Balamuta,https://github.com/tmsalab/simcdm,TRUE,https://github.com/tmsalab/simcdm,7601,0,2020-03-18T03:45:25Z,NA
SimCorMultRes,Simulates correlated multinomial responses conditional on a marginal model specification.,2019-07-25,Anestis Touloumis,http://github.com/AnestisTouloumis/SimCorMultRes,TRUE,https://github.com/anestistouloumis/simcormultres,18634,7,2019-11-06T22:00:55Z,2662
SimDesign,"Provides tools to help safely and efficiently organize Monte Carlo simulations in R.
    The package controls the structure and back-end of Monte Carlo simulations
    by utilizing a general generate-analyse-summarise strategy. The functions provided control
    common simulation issues such as re-simulating non-convergent results, support parallel
    back-end and MPI distributed computations, save and restore temporary files,
    aggregate results across independent nodes, and provide native support for debugging.
    For a pedagogical introduction to the package refer to 
    Sigal and Chalmers (2016) <doi:10.1080/10691898.2016.1246953>.",2020-01-20,Phil Chalmers,"https://github.com/philchalmers/SimDesign,
https://github.com/philchalmers/SimDesign/wiki",TRUE,https://github.com/philchalmers/simdesign,67484,31,2020-04-24T00:46:51Z,2176.9032258064517
simex,"Implementation of the SIMEX-Algorithm by Cook & Stefanski (1994) <doi:10.1080/01621459.1994.10476871> and
    MCSIMEX by Küchenhoff, Mwalili & Lesaffre (2006) <doi:10.1111/j.1541-0420.2005.00396.x>.",2019-07-31,Wolfgang Lederer,http://wolfganglederer.github.io/simex/,TRUE,https://github.com/wolfganglederer/simex,35960,5,2019-07-30T23:50:00Z,7192
simExam,"Generates binary test data based on Item Response Theory using the two-parameter logistic model (Lord, 1980 <doi:10.4324/9780203056615>). Useful functions for test equating are included, e.g. functions for generating internal and external common items between test forms and a function to create a linkage plans between those forms. Ancillary functions for generating true item and person parameters as well as for calculating the probability of a person correctly answering an item are also included.",2019-08-02,Waldir Leoncio,NA,TRUE,https://github.com/wleoncio/simexam,3200,0,2019-07-31T13:18:31Z,NA
simfinR,"Uses the 'SimFin' (SIMmplifying FINnance) api at <https://simfin.com/data/access/api> to download financial data straight into your R session. 
    It includes financial statements -- balance sheet, cash flow and income statement -- and adjusted daily price of stocks.
    The available data is comprehensive, going back to 2005 and available for quarters (Q1, Q2, Q3, Q4) and years (FY).",2020-04-29,Marcelo S. Perlin,https://github.com/msperlin/simfinR/,TRUE,https://github.com/msperlin/simfinr,3591,5,2020-04-29T12:56:14Z,718.2
simhelpers,"Calculates performance criteria measures and associated Monte Carlo standard errors for simulation results. Includes functions to help run simulation studies. Our derivation and explanation of formulas and our general simulation workflow is closely aligned with the approach described by Morris, White, and Crowther (2019) <DOI: 10.1002/sim.8086>. ",2020-03-31,Megha Joshi,https://meghapsimatrix.github.io/simhelpers/index.html,TRUE,https://github.com/meghapsimatrix/simhelpers,958,5,2020-04-02T01:57:16Z,191.6
SimilaR,"An implementation of a novel method to quantify the similarity
    the code-base of R functions by means of program dependence graphs.
    Possible use cases include detection of code clones for improving
    software quality and of plagiarism among students' homework assignments.",2020-04-06,Maciej Bartoszuk,http://similar.rexamine.com/,TRUE,https://github.com/bartoszukm/similar,7846,2,2020-04-06T09:23:13Z,3923
SimInf,"Provides an efficient and very flexible framework to
    conduct data-driven epidemiological modeling in realistic large
    scale disease spread simulations. The framework integrates
    infection dynamics in subpopulations as continuous-time Markov
    chains using the Gillespie stochastic simulation algorithm and
    incorporates available data such as births, deaths and movements
    as scheduled events at predefined time-points. Using C code for
    the numerical solvers and 'OpenMP' (if available) to divide work
    over multiple processors ensures high performance when simulating
    a sample outcome. One of our design goals was to make the package
    extendable and enable usage of the numerical solvers from other R
    extension packages in order to facilitate complex epidemiological
    research. The package contains template models and can be extended
    with user-defined models. For more details see the paper by
    Widgren, Bauer, Eriksson and Engblom (2019)
    <doi:10.18637/jss.v091.i12>.",2020-05-23,Stefan Widgren,https://github.com/stewid/SimInf,TRUE,https://github.com/stewid/siminf,16790,15,2020-05-27T06:51:48Z,1119.3333333333333
simmer,"A process-oriented and trajectory-based Discrete-Event Simulation
    (DES) package for R. It is designed as a generic yet powerful framework. The
    architecture encloses a robust and fast simulation core written in 'C++' with
    automatic monitoring capabilities. It provides a rich and flexible R API that
    revolves around the concept of trajectory, a common path in the simulation
    model for entities of the same type. Documentation about 'simmer' is provided
    by several vignettes included in this package, via the paper by Ucar, Smeets
    & Azcorra (2019, <doi:10.18637/jss.v090.i02>), and the paper by Ucar,
    Hernández, Serrano & Azcorra (2018, <doi:10.1109/MCOM.2018.1700960>);
    see 'citation(""simmer"")' for details.",2020-06-06,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer",TRUE,https://github.com/r-simmer/simmer,54117,157,2020-06-06T19:41:31Z,344.69426751592357
simmer.bricks,Provides wrappers for common activity patterns in 'simmer' trajectories.,2019-01-09,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer.bricks",TRUE,https://github.com/r-simmer/simmer.bricks,8323,5,2020-06-06T17:28:03Z,1664.6
simmer.plot,A set of plotting methods for 'simmer' trajectories and simulations.,2020-04-25,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer.plot",TRUE,https://github.com/r-simmer/simmer.plot,27163,8,2020-06-06T17:25:54Z,3395.375
simPH,"Simulates and plots quantities of interest (relative
    hazards, first differences, and hazard ratios) for linear coefficients,
    multiplicative interactions, polynomials, penalised splines, and
    non-proportional hazards, as well as stratified survival curves from Cox
    Proportional Hazard models. It also simulates and plots marginal effects
    for multiplicative interactions.",2020-03-24,Christopher Gandrud,https://CRAN.R-project.org/package=simPH,TRUE,https://github.com/christophergandrud/simph,27508,14,2020-03-24T10:34:15Z,1964.857142857143
simplecolors,"A curated set of colors that are called using
    a standardized syntax: saturation + hue + lightness. For example, 
    ""brightblue4"" and ""mutedred2"". Functions exists to return individual colors 
    by name or to build palettes across or within hues. Most functions allow you 
    to visualize the palettes in addition to returning the desired hex codes.",2020-02-01,Jake Riley,https://github.com/rjake/simplecolors,TRUE,https://github.com/rjake/simplecolors,1835,1,2020-03-30T15:25:13Z,1835
simplePHENOTYPES,"The number of studies involving correlated traits and the availability of tools to handle this type of data has increased considerably in the last decade. With such a demand, we need tools for testing hypotheses related to single and multi-trait (correlated) phenotypes based on many genetic settings. Thus, we implemented various options for simulation of pleiotropy and Linkage Disequilibrium under additive, dominance and epistatic models. The simulation currently takes a marker data set as an input and then uses it for simulating multiple traits as described in Fernandes and Lipka (2020) <doi:10.1101/2020.01.11.902874>.",2020-05-06,Samuel Fernandes,https://github.com/samuelbfernandes/simplePHENOTYPES,TRUE,https://github.com/samuelbfernandes/simplephenotypes,2547,3,2020-06-09T20:06:46Z,849
simplevis,"Provides 'ggplot2' and 'leaflet' wrapper functions designed to simplify the creation of high quality graph and map visualisations. These functions only require inputs of data, variables and titles to provide beautiful interactive or image visualisations. However they allow for more flexibility if required. The intent is that high quality well-designed graphs and maps can be made more consistently with less effort, code and expertise than would otherwise be required.",2020-06-09,David Hodge,"https://statisticsnz.github.io/simplevis,
https://github.com/statisticsnz/simplevis",TRUE,https://github.com/statisticsnz/simplevis,1996,17,2020-06-09T01:39:42Z,117.41176470588235
simPop,"Tools and methods to simulate populations for surveys based
    on auxiliary data. The tools include model-based methods, calibration and
    combinatorial optimization algorithms. The package was developed with support of
    the International Household Survey Network, DFID Trust Fund TF011722 and funds
    from the World bank.",2019-07-18,Matthias Templ,https://github.com/statistikat/simPop,TRUE,https://github.com/statistikat/simpop,21661,15,2020-02-04T10:03:38Z,1444.0666666666666
simputation,"Easy to use interfaces to a number of imputation methods
        that fit in the not-a-pipe operator of the 'magrittr' package.",2020-03-13,Mark van der Loo,https://github.com/markvanderloo/simputation,TRUE,https://github.com/markvanderloo/simputation,27502,55,2020-03-13T20:37:31Z,500.03636363636366
simr,"Calculate power for generalised linear mixed models, using
    simulation. Designed to work with models fit using the 'lme4' package.
    Described in Green and MacLeod, 2016 <doi:10.1111/2041-210X.12504>.",2019-01-29,Green Peter,https://github.com/pitakakariki/simr,TRUE,https://github.com/pitakakariki/simr,36023,38,2020-04-29T06:43:47Z,947.9736842105264
simrel,"Simulate multivariate linear model data is useful in research and education weather 
    for comparison or create data with specific properties. This package lets user to simulate
    linear model data of wide range of properties with few tuning parameters.
    The package also consist of function to create plots for the simulation
    objects and A shiny app as RStudio gadget. It can be a handy tool for model comparison, 
    testing and many other purposes.",2020-05-06,Raju Rimal,https://simulatr.github.io/simrel/,TRUE,https://github.com/simulatr/simrel,15173,2,2020-05-05T23:09:12Z,7586.5
SiMRiv,"Provides functions to generate and analyze spatially-explicit individual-based multistate movements in rivers,
  heterogeneous and homogeneous spaces. This is done by incorporating landscape bias on local behaviour, based on
  resistance rasters. Although originally conceived and designed to simulate trajectories of species constrained to
  linear habitats/dendritic ecological networks (e.g. river networks), the simulation algorithm is built to be
  highly flexible and can be applied to any (aquatic, semi-aquatic or terrestrial) organism, independently on the
  landscape in which it moves. Thus, the user will be able to use the package to simulate movements either in
  homogeneous landscapes, heterogeneous landscapes (e.g. semi-aquatic animal moving mainly along rivers but also using
  the matrix), or even in highly contrasted landscapes (e.g. fish in a river network). The algorithm and its input
  parameters are the same for all cases, so that results are comparable. Simulated trajectories can then be used as
  mechanistic null models (Potts & Lewis 2014, <DOI:10.1098/rspb.2014.0231>) to test a variety of 'Movement Ecology'
  hypotheses (Nathan et al. 2008, <DOI:10.1073/pnas.0800375105>), including landscape effects (e.g. resources, 
  infrastructures) on animal movement and species site fidelity, or for predictive purposes (e.g. road mortality risk,
  dispersal/connectivity). The package should be relevant to explore a broad spectrum of ecological phenomena, such as
  those at the interface of animal behaviour, management, landscape and movement ecology, disease and invasive species
  spread, and population dynamics.",2019-12-19,Miguel Porto,"https://www.r-project.org, https://github.com/miguel-porto/SiMRiv",TRUE,https://github.com/miguel-porto/simriv,13274,7,2020-01-09T14:13:59Z,1896.2857142857142
simstandard,Creates simulated data from structural equation models with standardized loading.,2019-01-07,W. Joel Schneider,https://github.com/wjschne/simstandard,TRUE,https://github.com/wjschne/simstandard,5742,1,2020-02-15T14:52:37Z,5742
simTool,"Tool for statistical simulations that have two components. 
    One component generates the data and the other one
    analyzes the data. The main aims of the package are the reduction
    of the administrative source code (mainly loops and management code for the
    results) and a simple applicability of the package that allows the user to
    quickly learn how to work with it. Parallel computing is
    also supported. Finally, convenient functions are provided to summarize the
    simulation results.",2020-05-17,Marsel Scheer,https://github.com/MarselScheer/simTool,TRUE,https://github.com/marselscheer/simtool,15749,5,2020-05-19T21:10:19Z,3149.8
simts,"A system contains easy-to-use tools as a support for time series analysis courses. In particular, it incorporates a technique called Generalized Method of Wavelet Moments (GMWM) as well as its robust implementation for fast and robust parameter estimation of time series models which is described, for example, in Guerrier et al. (2013) <doi: 10.1080/01621459.2013.799920>. More details can also be found in the paper linked to via the URL below.",2019-07-21,Stéphane Guerrier,"https://github.com/SMAC-Group/simts,
https://arxiv.org/pdf/1607.04543.pdf",TRUE,https://github.com/smac-group/simts,5098,7,2020-06-05T14:24:37Z,728.2857142857143
simulator,"A framework for performing simulations such as those common in
    methodological statistics papers.  The design principles of this package
    are described in greater depth in Bien, J. (2016) ""The simulator: An Engine
    to Streamline Simulations,"" which is available at
    <http://faculty.bscb.cornell.edu/~bien/simulator.pdf>.",2016-07-12,Jacob Bien,http://github.com/jacobbien/simulator,TRUE,https://github.com/jacobbien/simulator,11779,39,2019-11-28T19:47:29Z,302.02564102564105
simule,"This is an R implementation of a constrained l1 minimization approach for estimating multiple Sparse Gaussian or Nonparanormal Graphical Models (SIMULE). The SIMULE algorithm can be used to estimate multiple related precision matrices. For instance, it can identify context-specific gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogenous data sets, this tool can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(simuleDemo) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Ritambhara Singh, Yanjun Qi (2017) <DOI:10.1007/s10994-017-5635-7>.",2018-07-02,Beilun Wang,https://github.com/QData/SIMULE,TRUE,https://github.com/qdata/simule,10159,3,2019-08-28T16:27:41Z,3386.3333333333335
sinew,"Create 'roxygen2' skeleton populated with information scraped from the
         within the function script. Also creates field entries for imports in the
         'DESCRIPTION' and import in the 'NAMESPACE' files. Can be run from the R
         console or through the 'RStudio' 'addin' menu.",2018-08-31,Jonathan Sidi,https://github.com/metrumresearchgroup/sinew,TRUE,https://github.com/metrumresearchgroup/sinew,12833,111,2020-02-28T02:45:55Z,115.61261261261261
SingleCaseES,"
  Provides R functions for calculating basic effect size indices for 
  single-case designs, including several non-overlap measures and parametric 
  effect size measures, and for estimating the gradual effects model developed 
  by Swan and Pustejovsky (2018) <DOI:10.1080/00273171.2018.1466681>. 
  Standard errors and confidence intervals (based on the assumption that the outcome 
  measurements are mutually independent) are provided for the subset of effect sizes 
  indices with known sampling distributions.",2019-08-29,James E. Pustejovsky,https://github.com/jepusto/SingleCaseES,TRUE,https://github.com/jepusto/singlecasees,8403,4,2020-05-07T01:31:32Z,2100.75
sirt,"
    Supplementary functions for item response models aiming
    to complement existing R packages. The functionality includes among others
    multidimensional compensatory and noncompensatory IRT models
    (Reckase, 2009, <doi:10.1007/978-0-387-89976-3>), 
    MCMC for hierarchical IRT models and testlet models
    (Fox, 2010, <doi:10.1007/978-1-4419-0742-4>), 
    NOHARM (McDonald, 1982, <doi:10.1177/014662168200600402>), 
    Rasch copula model (Braeken, 2011, <doi:10.1007/s11336-010-9190-4>;
    Schroeders, Robitzsch & Schipolowski, 2014, <doi:10.1111/jedm.12054>),
    faceted and hierarchical rater models (DeCarlo, Kim & Johnson, 2011,
    <doi:10.1111/j.1745-3984.2011.00143.x>),
    ordinal IRT model (ISOP; Scheiblechner, 1995, <doi:10.1007/BF02301417>), 
    DETECT statistic (Stout, Habing, Douglas & Kim, 1996, 
    <doi:10.1177/014662169602000403>), local structural equation modeling 
    (LSEM; Hildebrandt, Luedtke, Robitzsch, Sommer & Wilhelm, 2016,
    <doi:10.1080/00273171.2016.1142856>).",2020-02-17,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/sirt,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/sirt,313042,11,2020-04-18T14:06:31Z,28458.363636363636
sisal,"Implements the SISAL algorithm by Tikka and Hollmén. It is
        a sequential backward selection algorithm which uses a linear
        model in a cross-validation setting. Starting from the full
        model, one variable at a time is removed based on the
        regression coefficients. From this set of models, a
        parsimonious (sparse) model is found by choosing the model with
        the smallest number of variables among those models where the
        validation error is smaller than a threshold. Also implements
        extensions which explore larger parts of the search space
        and/or use ridge regression instead of ordinary least squares.",2020-02-15,Mikko Korpela,https://github.com/mvkorpel/sisal,TRUE,https://github.com/mvkorpel/sisal,12541,0,2020-02-14T17:25:01Z,NA
sismonr,"A tool for the simulation of gene expression profiles for in silico regulatory networks. The package generates gene regulatory networks, which include protein-coding and noncoding genes linked via different types of regulation: regulation of transcription, translation, RNA or protein decay, and post-translational modifications. The effect of genetic mutations on the system behaviour is accounted for via the simulation of genetically different in silico individuals. The ploidy of the system is not restricted to the usual haploid or diploid situations, but is defined by the user. A choice of stochastic simulation algorithms allow us to simulate the expression profiles (RNA and if applicable protein abundance) of the genes in the in silico system for the different in silico individuals. A tutorial explaining how to use the package is available at <https://oliviaab.github.io/sismonr/>. Manuscript in preparation; see also Angelin-Bonnet O., Biggs P.J. and Vignes M. (2018) <doi:10.1109/BIBM.2018.8621131>. Note that sismonr relies on Julia code called internally by the functions. No knowledge of Julia is required in order to use sismonr, but Julia must be installed on the computer (instructions can be found in the tutorial, the GitHub page or the vignette of the package).",2020-02-11,Olivia Angelin-Bonnet,https://oliviaab.github.io/sismonr/,TRUE,https://github.com/oliviaab/sismonr,4828,1,2020-02-11T01:45:23Z,4828
sistec,"The Brazilian system for diploma registration and validation on technical and superior
    courses are managing by 'Sistec' platform, see <https://sistec.mec.gov.br/>. This package provides 
    tools for Brazilian institutions to update the student's registration and make data analysis 
    about their situation, retention and drop out.",2020-05-11,Samuel Macêdo,https://github.com/r-ifpe/sistec,TRUE,https://github.com/r-ifpe/sistec,389,0,2020-06-09T21:21:57Z,NA
sitar,"Functions for fitting and plotting SITAR (Super
    Imposition by Translation And Rotation) growth curve models. SITAR is
    a shape-invariant model with a regression B-spline mean curve and
    subject-specific random effects on both the measurement and age
    scales.  The model was first described by Lindstrom (1995)
    <doi:10.1002/sim.4780141807> and developed as the SITAR method by Cole
    et al (2010) <doi:10.1093/ije/dyq115>.",2020-02-17,Tim Cole,https://github.com/statist7/sitar,TRUE,https://github.com/statist7/sitar,25123,4,2020-02-15T09:02:00Z,6280.75
siteymlgen,"The goal of 'siteymlgen' is to make it easy to organise
  the building of your 'R Markdown' website.
  The init() function placed within the first code chunk of the index.Rmd
  file of an 'R' project directory will initiate the generation of an automatically
  written _site.yml file. 'siteymlgen' recommends a specific naming
  convention for your 'R Markdown' files. This naming will ensure that
  your navbar layout is ordered according to a hierarchy.",2020-05-08,Adam Cribbs,https://github.com/Acribbs/siteymlgen,TRUE,https://github.com/acribbs/siteymlgen,400,0,2020-05-14T16:12:54Z,NA
sjlabelled,"Collection of functions dealing with labelled data, like reading and 
    writing data between R and other statistical software packages like 'SPSS',
    'SAS' or 'Stata', and working with labelled data. This includes easy ways 
    to get, set or change value and variable label attributes, to convert 
    labelled vectors into factors or numeric (and vice versa), or to deal with 
    multiple declared missing values.",2020-05-25,Daniel Lüdecke,https://strengejacke.github.io/sjlabelled,TRUE,https://github.com/strengejacke/sjlabelled,650508,48,2020-05-28T14:31:18Z,13552.25
sjmisc,"Collection of miscellaneous utility functions, supporting data 
    transformation tasks like recoding, dichotomizing or grouping variables, 
    setting and replacing missing values. The data transformation functions 
    also support labelled data, and all integrate seamlessly into a 
    'tidyverse'-workflow.",2020-05-28,Daniel Lüdecke,https://strengejacke.github.io/sjmisc,TRUE,https://github.com/strengejacke/sjmisc,727891,131,2020-05-28T14:31:29Z,5556.419847328244
sjPlot,"Collection of plotting and table output functions for data
    visualization. Results of various statistical analyses (that are commonly used
    in social sciences) can be visualized using this package, including simple and
    cross tabulated frequencies, histograms, box plots, (generalized) linear models,
    mixed effects models, principal component analysis and correlation matrices, 
    cluster analyses, scatter plots, stacked scales, effects plots of regression 
    models (including interaction terms) and much more. This package supports
    labelled data.",2020-05-24,Daniel Lüdecke,https://strengejacke.github.io/sjPlot/,TRUE,https://github.com/strengejacke/sjplot,521411,346,2020-05-28T14:31:39Z,1506.9682080924856
sjstats,"Collection of convenient functions for common statistical computations,
             which are not directly provided by R's base or stats packages.
             This package aims at providing, first, shortcuts for statistical measures, 
             which otherwise could only be calculated with additional effort 
             (like Cramer's V, Phi, or effect size statistics like Eta or Omega squared), 
             or for which currently no functions available. Second, another focus 
             lies on weighted variants of common statistical measures and tests 
             like weighted standard error, mean, t-test, correlation, and more.",2020-05-06,Daniel Lüdecke,"https://github.com/strengejacke/sjstats,
https://strengejacke.github.io/sjstats",TRUE,https://github.com/strengejacke/sjstats,548154,155,2020-05-28T14:31:49Z,3536.4774193548387
skedastic,"Implements numerous methods for detecting heteroskedasticity 
    (sometimes called heteroscedasticity) in the classical linear regression 
    model. These include the parametric and nonparametric tests of 
    Goldfeld and Quandt (1965) <doi:10.1080/01621459.1965.10480811>, the test 
    of Glejser (1969) <doi:10.1080/01621459.1969.10500976> as formulated by 
    Mittelhammer, Judge and Miller (2000, ISBN: 0-521-62394-4), the BAMSET 
    Test of Ramsey (1969) <doi:10.1111/j.2517-6161.1969.tb00796.x>, which uses 
    the BLUS residuals derived by Theil (1965) 
    <doi:10.1080/01621459.1965.10480851>, the test of Harvey (1976) 
    <doi:10.2307/1913974>, the test of Breusch and Pagan (1979) 
    <doi:10.2307/1911963> with and without the modification 
    proposed by Koenker (1981) <doi:10.1016/0304-4076(81)90062-2>, the test of 
    White (1980) <doi:10.2307/1912934>, the test and graphical Cook and Weisberg 
    (1983) <doi:10.1093/biomet/70.1.1>, and the test of Li and Yao (2019) 
    <doi:10.1016/j.ecosta.2018.01.001>. Homoskedasticity refers to the 
    assumption of constant variance that is imposed on the model errors 
    (disturbances); heteroskedasticity is the violation of this assumption.",2020-01-10,Thomas Farrar,http://github.com/tjfarrar/skedastic,TRUE,https://github.com/tjfarrar/skedastic,2717,3,2020-03-26T08:54:35Z,905.6666666666666
sketcher,"An implementation of image processing effects that convert a photo into a line drawing image. 
    For details, please refer to Tsuda, H. (2020). sketcher: An R package for converting a photo into a sketch style image. 
    <doi:10.31234/osf.io/svmw5>.",2020-05-25,Hiroyuki Tsuda,https://htsuda.net/sketcher/,TRUE,https://github.com/tsuda16k/sketcher,215,9,2020-05-26T04:40:24Z,23.88888888888889
skewlmm,"It fits scale mixture of skew-normal linear mixed models using an expectation–maximization (EM) type algorithm, including some possibilities for modeling the within-subject dependence. Details can be found in Schumacher, Lachos and Matos (2020) <arXiv:2002.01040>.",2020-05-15,Fernanda L. Schumacher,https://github.com/fernandalschumacher/skewlmm,TRUE,https://github.com/fernandalschumacher/skewlmm,1617,0,2020-05-15T19:58:37Z,NA
skimr,"A simple to use summary function that can be used with pipes
    and displays nicely in the console. The default summary statistics may
    be modified by the user as can the default formatting.  Support for
    data frames and vectors is included, and users can implement their own
    skim methods for specific object types as described in a vignette.
    Default summaries include support for inline spark graphs.
    Instructions for managing these on specific operating systems are
    given in the ""Using skimr"" vignette and the README.",2020-04-16,Elin Waring,"https://docs.ropensci.org/skimr (website),
https://github.com/ropensci/skimr",TRUE,https://github.com/ropensci/skimr,320038,758,2020-04-16T07:50:30Z,422.2137203166227
skpr,"Generates and evaluates D, I, A, Alias, E, T, and G optimal designs. Supports generation and evaluation of blocked and split/split-split/.../N-split plot designs. Includes parametric and Monte Carlo power evaluation functions, and supports calculating power for censored responses. Provides a framework to evaluate power using functions provided in other packages or written by the user. Includes a Shiny graphical user interface that displays the underlying code used to create and evaluate the design to improve ease-of-use and make analyses more reproducible.",2020-03-04,Tyler Morgan-Wall,https://github.com/tylermorganwall/skpr,TRUE,https://github.com/tylermorganwall/skpr,15461,73,2020-05-14T17:59:16Z,211.7945205479452
skynet,"A flexible tool that allows generating bespoke
    air transport statistics for urban studies based on publicly available
    data from the Bureau of Transport Statistics (BTS) in the United States
    <https://www.transtats.bts.gov/databases.asp?Mode_ID=1&Mode_Desc=Aviation&Subject_ID2=0>.",2020-06-02,Filipe Teixeira,https://github.com/FilipeamTeixeira/skynet,TRUE,https://github.com/filipeamteixeira/skynet,8632,7,2020-06-02T13:57:27Z,1233.142857142857
sleepr,"Use behavioural variables to score activity and infer sleep from bouts of immobility. 
    It is primarily designed to score sleep in fruit flies from Drosophila Activity Monitor (TriKinetics) and Ethoscope data.
    It implements sleep scoring using the ""five-minute rule"" (Hendricks et al. (2000) <DOI:10.1016/S0896-6273(00)80877-6>),
    activity classification for Ethoscopes (Geissmann et al. (2017) <DOI:10.1371/journal.pbio.2003026>) 
    and a new algorithm to detect when animals are dead.",2018-10-30,Quentin Geissmann,https://github.com/rethomics/sleepr,TRUE,https://github.com/rethomics/sleepr,6165,3,2020-06-10T01:27:55Z,2055
sleepwalk,"A tool to interactively explore the
  embeddings created by dimension reduction methods such as 
  Principal Components Analysis (PCA), Multidimensional Scaling (MDS), 
  T-distributed Stochastic Neighbour Embedding (t-SNE),
  Uniform Manifold Approximation and Projection (UMAP) or any other.",2020-02-26,Svetlana Ovchinnikova,https://anders-biostat.github.io/sleepwalk/,TRUE,https://github.com/anders-biostat/sleepwalk,5647,79,2020-02-26T17:09:17Z,71.48101265822785
SLEMI,"The implementation of the algorithm for estimation of mutual information and channel capacity from experimental data by classification procedures (logistic regression). Technically, it allows to estimate information-theoretic measures between finite-state input and multivariate, continuous output. Method described in Jetka et al. (2019) <doi:10.1371/journal.pcbi.1007132>.",2019-10-07,Tomasz Jetka,https://github.com/sysbiosig/SLEMI,TRUE,https://github.com/sysbiosig/slemi,2044,2,2019-10-04T11:16:39Z,1022
slga,Provides access to soil and landscape grid of Australia raster datasets via existing open geospatial consortium web coverage services. See <https://www.csiro.au/soil-and-landscape-grid>.  ,2020-03-31,Lauren OBrien,https://github.com/obrl-soil/slga,TRUE,https://github.com/obrl-soil/slga,3602,12,2020-03-31T02:29:12Z,300.1666666666667
slickR,"Create and customize interactive carousels
      using the 'Slick' JavaScript library and the
      'htmlwidgets' package. The carousels can contain
      plots produced in R, images, 'iframes', videos and
      other 'htmlwidgets'.  These carousels can be created
      directly from the R console, and viewed in the 'RStudio' 
      internal viewer, in Shiny apps and R Markdown documents.",2020-02-14,Jonathan Sidi,https://github.com/metrumresearchgroup/slickR,TRUE,https://github.com/metrumresearchgroup/slickr,19554,100,2020-02-14T12:53:23Z,195.54
slider,"Provides type-stable rolling window functions over
    any R data type. Cumulative and expanding windows are also supported.
    For more advanced usage, an index can be used as a secondary vector
    that defines how sliding windows are to be created.",2020-05-28,Davis Vaughan,https://github.com/DavisVaughan/slider,TRUE,https://github.com/davisvaughan/slider,61092,119,2020-05-28T17:36:58Z,513.3781512605042
SLOPE,"Efficient implementations for Sorted L-One Penalized Estimation 
    (SLOPE): generalized linear models regularized with the sorted L1-norm 
    (Bogdan et al. (2015) <doi:10/gfgwzt>). Supported models include ordinary 
    least-squares regression, binomial regression, multinomial regression, and 
    Poisson regression. Both dense and sparse  predictor matrices are supported.
    In addition, the package features predictor screening rules that enable fast
    and efficient solutions to high-dimensional problems.",2020-04-16,Johan Larsson,"https://jolars.github.io/SLOPE/, https://github.com/jolars/SLOPE",TRUE,https://github.com/jolars/slope,19481,3,2020-06-02T06:35:31Z,6493.666666666667
slouch,"An implementation of a phylogenetic comparative method. It can fit univariate among-species Ornstein-Uhlenbeck models of phenotypic trait evolution, where the trait evolves towards a primary optimum. The optimum can be modelled as a single parameter, as multiple discrete regimes on the phylogenetic tree, and/or with continuous covariates. See also Hansen (1997) <doi:10.2307/2411186>, Butler & King (2004) <doi:10.1086/426002>, Hansen et al. (2008) <doi:10.1111/j.1558-5646.2008.00412.x>.",2020-02-21,Bjørn Tore Kopperud,http://github.com/kopperud/slouch,TRUE,https://github.com/kopperud/slouch,6746,1,2020-05-26T14:17:24Z,6746
slurmR,"'Slurm', Simple Linux Utility for Resource Management
          <https://slurm.schedmd.com/>, is a popular 'Linux' based software used to 
          schedule jobs in 'HPC' (High Performance Computing) clusters. This R package
          provides a specialized lightweight wrapper of 'Slurm' with a syntax similar to
          that found in the 'parallel' R package. The package also includes a method for
          creating socket cluster objects spanning multiple nodes that can be used with
          the 'parallel' package.",2020-04-23,George Vega Yon,"https://github.com/USCbiostats/slurmR, https://slurm.schedmd.com/",TRUE,https://github.com/uscbiostats/slurmr,2418,22,2020-02-25T23:44:36Z,109.9090909090909
SmallCountRounding,"A statistical disclosure control tool to protect frequency tables in cases where small values are sensitive. The function PLSrounding() performs small count rounding of necessary inner cells so that all small frequencies of cross-classifications to be published (publishable cells) are rounded. This is equivalent to changing micro data since frequencies of unique combinations are changed. Thus, additivity and consistency are guaranteed. The methodology is described in Langsrud and Heldal (2018) <https://www.researchgate.net/publication/327768398>.",2019-10-17,Øyvind Langsrud,https://github.com/statisticsnorway/SmallCountRounding,TRUE,https://github.com/statisticsnorway/smallcountrounding,6531,2,2019-10-21T06:53:26Z,3265.5
smam,"Animal movement models including moving-resting process
    with embedded Brownian motion according to
    Yan et al. (2014) <doi:10.1007/s10144-013-0428-8>,
    Pozdnyakov et al. (2017) <doi:10.1007/s11009-017-9547-6>,
    Brownian motion with measurement error according to
    Pozdnyakov et al. (2014) <doi:10.1890/13-0532.1>,
    and moving-resting-handling process with embedded Brownian motion,
    Pozdnyakov et al. (2018) <arXiv:1806.00849>.",2020-01-17,Chaoran Hu,https://github.com/ChaoranHu/smam,TRUE,https://github.com/chaoranhu/smam,17400,2,2020-05-13T06:37:13Z,8700
smapr,"
    Facilitates programmatic access to NASA Soil Moisture Active
    Passive (SMAP) data with R. It includes functions to search for, acquire,
    and extract SMAP data.",2019-04-22,Maxwell Joseph,https://github.com/ropensci/smapr,TRUE,https://github.com/ropensci/smapr,13196,51,2020-05-24T16:41:06Z,258.7450980392157
smartdata,"Eases data preprocessing tasks, providing a data flow based 
   on a pipe operator which eases cleansing, transformation, oversampling, 
   or instance/feature selection operations.",2019-12-18,Ignacio Cordón,http://github.com/ncordon/smartdata,TRUE,https://github.com/ncordon/smartdata,7531,11,2019-12-18T02:27:15Z,684.6363636363636
SmartEDA,"Exploratory analysis on any input data describing the structure and the relationships present in the data. The package automatically select the variable and does related descriptive statistics. Analyzing information value, weight of evidence, custom tables, summary statistics, graphical techniques will be performed for both numeric and categorical predictors.",2020-04-25,Dayanand Ubrangala,https://daya6489.github.io/SmartEDA/,TRUE,https://github.com/daya6489/smarteda,12832,15,2020-04-25T12:17:07Z,855.4666666666667
smartR,"A tool for assessing bio-economic feedback in 
  different management scenarios (D'Andrea et al., 2020 
  <doi:10.1111/2041-210X.13394>). 'smartR' (Spatial Management and Assessment 
  of demersal Resources for Trawl fisheries) combines information from different
   tasks gathered within the European Data Collection Framework for the fishery
  sector. The 'smartR' package implements the SMART model (Russo et al., 2014 
  <doi:10.1371/journal.pone.0086222>), through the object-oriented 
  programming paradigm, and within this package it is possible to achieve the 
  complete set of analyses required by the SMART approach: from the editing and
   formatting of the raw data; the construction and maintenance of coherent 
  datasets; the numerical and visual inspection of the generated metadata; to 
  the final simulation of management scenarios and the forecast of their 
  effects. The interaction between the user and the application could take 
  place through invocation of methods via the command line or could be entirely
   committed to the graphical user interfaces (GUI).",2020-05-05,Lorenzo DAndrea,https://github.com/d-lorenz/smartR,TRUE,https://github.com/d-lorenz/smartr,4421,1,2020-05-06T08:10:42Z,4421
smerc,"Implements statistical methods for analyzing the counts of areal data,
    with a focus on the detection of spatial clusters and clustering.  The package has a heavy emphasis on spatial scan methods, which were first introduced by Kulldorff and Nagarwalla (1995) <doi:10.1002/sim.4780140809> and Kulldorff (1997) <doi:10.1080/03610929708831995>.",2020-05-26,Joshua French,NA,TRUE,https://github.com/jpfrench81/smerc,19375,1,2020-06-04T16:45:51Z,19375
smoof,"Provides generators for a high number of both single- and multi-
    objective test functions which are frequently used for the benchmarking of
    (numerical) optimization algorithms. Moreover, it offers a set of convenient
    functions to generate, plot and work with objective functions.",2020-02-18,Jakob Bossek,https://github.com/jakobbossek/smoof,TRUE,https://github.com/jakobbossek/smoof,80470,20,2020-04-02T06:31:14Z,4023.5
smooth,"Functions implementing Single Source of Error state space models for purposes of time series analysis and forecasting.
             The package includes Exponential Smoothing (Hyndman et al., 2008, <doi: 10.1007/978-3-540-71918-2>),
             SARIMA (Svetunkov & Boylan, 2019 <doi: 10.1080/00207543.2019.1600764>),
             Complex Exponential Smoothing (Svetunkov & Kourentzes, 2018, <doi: 10.13140/RG.2.2.24986.29123>),
             Simple Moving Average (Svetunkov & Petropoulos, 2018 <doi: 10.1080/00207543.2017.1380326>),
             Vector Exponential Smoothing (de Silva et al., 2010, <doi: 10.1177/1471082X0901000401>) in state space forms,
             several simulation functions and intermittent demand state space models. It also allows dealing with
             intermittent demand based on the iETS framework (Svetunkov & Boylan, 2017, <doi: 10.13140/RG.2.2.35897.06242>).",2020-04-05,"Ivan Svetunkov  (Lecturer at Centre for Marketing Analytics
    and Forecasting",https://github.com/config-i1/smooth,TRUE,https://github.com/config-i1/smooth,266789,42,2020-06-06T16:01:03Z,6352.119047619048
smoothr,"Tools for smoothing and tidying spatial features (i.e. lines and 
    polygons) to make them more aesthetically pleasing. Smooth curves, fill 
    holes, and remove small fragments from lines and polygons.",2020-01-23,Matthew Strimas-Mackey,"http://strimas.com/smoothr, https://github.com/mstrimas/smoothr",TRUE,https://github.com/mstrimas/smoothr,14055,69,2020-01-23T17:52:12Z,203.69565217391303
smovie,"Provides movies to help students to understand statistical 
  concepts.  The 'rpanel' package  <https://cran.r-project.org/package=rpanel> 
  is used to create interactive plots that move to illustrate key statistical 
  ideas and methods.  There are movies to: visualise probability distributions
  (including user-supplied ones); illustrate sampling distributions of the
  sample mean (central limit theorem), the median, the sample maximum 
  (extremal types theorem) and (the Fisher transformation of the) Pearson 
  product moment correlation coefficient; examine the influence of an 
  individual observation in simple linear regression; illustrate key concepts 
  in statistical hypothesis testing. Also provided are dpqr functions for the 
  distribution of the Fisher transformation of the correlation coefficient 
  under sampling from a bivariate normal distribution.",2020-01-08,Paul J. Northrop,"https://paulnorthrop.github.io/smovie/,
http://github.com/paulnorthrop/smovie/",TRUE,https://github.com/paulnorthrop/smovie,7297,0,2020-02-13T16:29:03Z,NA
snahelper,"'RStudio' addin which provides a GUI to visualize and analyse networks. 
    After finishing a session, the code to produce the plot is inserted in the current script.
    Alternatively, the function SNAhelperGadget() can be used directly from the console.
    Additional addins include the Netreader() for reading network files and Netbuilder() to create
    small networks via point and click.",2020-03-04,David Schoch,https://github.com/schochastics/snahelper,TRUE,https://github.com/schochastics/snahelper,5060,52,2020-03-04T13:51:34Z,97.3076923076923
snakecase,"A consistent, flexible and easy to use tool to parse and convert strings into cases like snake or camel among others.",2019-05-25,Malte Grosser,https://github.com/Tazinho/snakecase,TRUE,https://github.com/tazinho/snakecase,572421,90,2019-07-02T11:46:41Z,6360.233333333334
snotelr,"Programmatic interface to the 'SNOTEL' snow data
  (<https://www.wcc.nrcs.usda.gov/snow/>). Provides easy downloads of snow 
  data into your R work space or a local directory. Additional post-processing 
  routines to extract snow season indexes are provided.",2020-05-08,Koen Hufkens,https://github.com/khufkens/snotelr,TRUE,https://github.com/khufkens/snotelr,4030,4,2020-06-02T19:21:28Z,1007.5
SnowballC,"An R interface to the C 'libstemmer' library that implements
  Porter's word stemming algorithm for collapsing words to a common
  root to aid comparison of vocabulary. Currently supported languages are
  Danish, Dutch, English, Finnish, French, German, Hungarian, Italian,
  Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish
  and Turkish.",2020-04-01,Milan Bouchet-Valat,https://github.com/nalimilan/R.TeMiS,TRUE,https://github.com/nalimilan/r.temis,1814348,17,2020-04-01T16:31:45Z,106726.35294117648
snpEnrichment,Implements classes and methods for large scale SNP enrichment analysis (e.g. SNPs associated with genes expression in a GWAS signal).,2015-10-01,Mickael Canouil,https://github.com/mcanouil/snpEnrichment,TRUE,https://github.com/mcanouil/snpenrichment,15354,2,2019-12-03T14:09:44Z,7677
SNPknock,"Generate knockoffs for genetic data and hidden Markov models.
  For more information, see the website below and the accompanying papers: 
  ""Gene hunting with hidden Markov model knockoffs"", Sesia et al., Biometrika, 2019, (<doi:10.1093/biomet/asy033>).
  ""Multi-resolution localization of causal variants across the genome"", Sesia et al., bioRxiv, 2019, (<doi:10.1101/631390>).",2019-05-17,Matteo Sesia,https://msesia.github.io/snpknock,TRUE,https://github.com/msesia/snpknock,9072,1,2019-11-07T02:46:05Z,9072
soc.ca,"Specific and class specific multiple correspondence analysis on
    survey-like data. Soc.ca is optimized to the needs of the social scientist and
    presents easily interpretable results in near publication ready quality.",2016-02-09,Anton Grau Larsen,https://github.com/Rsoc/soc.ca,TRUE,https://github.com/rsoc/soc.ca,18618,10,2020-05-12T07:57:56Z,1861.8
socceR,"Functions for evaluating tournament predictions, simulating results from individual soccer matches and tournaments. See <http://sandsynligvis.dk/2018/08/03/world-cup-prediction-winners/> for more information.",2019-07-03,Claus Thorn Ekstrøm,https://github.com/ekstroem/socceR,TRUE,https://github.com/ekstroem/soccer,3502,1,2019-07-03T13:24:36Z,3502
sociome,"Accesses raw data via API and calculates social
    determinants of health measures for user-specified locations in the
    US, returning them in tidyverse- and sf-compatible data frames.",2020-03-19,Nik Krieger,NA,TRUE,https://github.com/nikkrieger/sociome,4517,6,2020-04-14T19:09:23Z,752.8333333333334
socviz,Supporting materials for a course and book on data visualization. It contains utility functions for graphs and several sample data sets. See Healy (2019) <ISBN 978-0691181622>.,2020-02-19,Kieran Healy,http://kjhealy.github.io/socviz/,TRUE,https://github.com/kjhealy/socviz,14328,134,2020-02-19T20:05:32Z,106.92537313432835
sofa,"Provides an interface to the 'NoSQL' database 'CouchDB'
    (<http://couchdb.apache.org>). Methods are provided for managing
    databases within 'CouchDB', including creating/deleting/updating/transferring,
    and managing documents within databases. One can connect with a local
    'CouchDB' instance, or a remote 'CouchDB' databases such as 'Cloudant'
    (<https://docs.cloudant.com>). Documents can be inserted directly from
    vectors, lists, data.frames, and 'JSON'. Targeted at 'CouchDB' v2 or
    greater.",2018-01-03,Scott Chamberlain,https://github.com/ropensci/sofa,TRUE,https://github.com/ropensci/sofa,14629,31,2020-01-31T18:00:26Z,471.9032258064516
soilDB,A collection of functions for reading data from USDA-NCSS soil databases.,2020-01-28,Dylan Beaudette,http://ncss-tech.github.io/AQP/,TRUE,https://github.com/ncss-tech/soildb,36790,19,2020-06-09T20:01:54Z,1936.3157894736842
Sojourn,"Provides a simple way for utilizing Sojourn methods for
    accelerometer processing, as detailed in Lyden K, Keadle S,
    Staudenmayer J, & Freedson P (2014) <doi:10.1249/MSS.0b013e3182a42a2d>,
    Ellingson LD, Schwabacher IJ, Kim Y, Welk GJ, & Cook DB (2016)
    <doi:10.1249/MSS.0000000000000915>, and Hibbing PR, Ellingson LD,
    Dixon PM, & Welk GJ (2018) <doi:10.1249/MSS.0000000000001486>.",2019-05-06,Paul R. Hibbing,http://github.com/paulhibbing/Sojourn,TRUE,https://github.com/paulhibbing/sojourn,4141,2,2019-11-02T06:52:56Z,2070.5
solaR,Calculation methods of solar radiation and performance of photovoltaic systems from daily and intradaily irradiation data sources.,2020-01-19,Oscar Perpiñán Lamigueiro,http://oscarperpinan.github.io/solar/,TRUE,https://github.com/oscarperpinan/solar,27639,25,2020-01-18T15:46:34Z,1105.56
solitude,"Isolation forest is anomaly detection method introduced by the paper Isolation based Anomaly Detection (Liu, Ting and Zhou <doi:10.1145/2133360.2133363>).",2019-12-07,Komala Sheshachala Srikanth,https://github.com/talegari/solitude,TRUE,https://github.com/talegari/solitude,12666,11,2019-09-26T05:07:26Z,1151.4545454545455
solrium,"Provides a set of functions for querying and parsing data
    from 'Solr' (<https://lucene.apache.org/solr>) 'endpoints' (local and
    remote), including search, 'faceting', 'highlighting', 'stats', and
    'more like this'. In addition, some functionality is included for
    creating, deleting, and updating documents in a 'Solr' 'database'.",2019-11-02,Scott Chamberlain,"https://github.com/ropensci/solrium (devel),
https://docs.ropensci.org/solrium/ (user manual)",TRUE,https://github.com/ropensci/solrium,110765,61,2020-04-22T16:14:50Z,1815.8196721311476
solvebio,"R language bindings for SolveBio's API.
    SolveBio is a biomedical knowledge hub that enables life science
    organizations to collect and harmonize the complex, disparate
    ""multi-omic"" data essential for today's R&D and BI needs.
    For more information, visit <https://www.solvebio.com>.",2020-01-08,David Caplan,https://github.com/solvebio/solvebio-r,TRUE,https://github.com/solvebio/solvebio-r,14891,2,2020-01-06T18:43:05Z,7445.5
soma,"This package provides an R implementation of the Self-Organising Migrating Algorithm, a general-purpose, stochastic optimisation algorithm. The approach is similar to that of genetic algorithms, although it is based on the idea of a series of ``migrations'' by a fixed set of individuals, rather than the development of successive generations. It can be applied to any cost-minimisation problem with a bounded parameter space, and is robust to local minima.",2014-11-25,Jon Clayden; based on the work of Ivan Zelinka,"https://github.com/jonclayden/soma/,
http://www.ft.utb.cz/people/zelinka/soma/",TRUE,https://github.com/jonclayden/soma,84787,5,2020-04-17T20:58:11Z,16957.4
SOMbrero,"The stochastic (also called on-line) version of the Self-Organising
             Map (SOM) algorithm is provided. Different versions of the
             algorithm are implemented, for numeric and relational data and for
             contingency tables as described, respectively, in Kohonen (2001)
             <isbn:3-540-67921-9>, Olteanu & Villa-Vialaneix (2005)
             <doi:10.1016/j.neucom.2013.11.047> and Cottrell et al (2004)
             <doi:10.1016/j.neunet.2004.07.010>. The package also contains many
             plotting features (to help the user interpret the results) and a
             graphical user interface based on 'shiny'.",2020-06-08,Nathalie Vialaneix,NA,TRUE,https://github.com/tuxette/sombrero,21274,12,2020-06-08T14:54:36Z,1772.8333333333333
SongEvo,"Simulates the cultural evolution of quantitative traits of bird song. 'SongEvo' is an individual- (agent-) based model. 'SongEvo' is spatially-explicit and can be parameterized with, and tested against, measured song data. Functions are available for model implementation, sensitivity analyses, parameter optimization, model validation, and hypothesis testing. ",2019-03-05,Raymond Danner,NA,TRUE,https://github.com/raydanner/songevo,4480,2,2020-01-31T21:47:34Z,2240
sorocs,"A Bayesian semiparametric Dirichlet process mixtures to estimate correlated receiver operating characteristic (ROC) surfaces and the associated volume under the surface (VUS) with stochastic order constraints. The reference paper is:Zhen Chen, Beom Seuk Hwang, (2018) ""A Bayesian semiparametric approach to correlated ROC surfaces with stochastic order constraints"". Biometrics, 75, 539-550. <doi:10.1111/biom.12997>. ",2020-03-13,Weimin Zhang,http://github.com/wzhang17/sorocs.git,TRUE,https://github.com/wzhang17/sorocs,1306,0,2020-03-05T15:53:50Z,NA
sortable,"Enables drag-and-drop behaviour in Shiny apps, by exposing the 
    functionality of the 'SortableJS' <https://sortablejs.github.io/Sortable/> 
    JavaScript library as an 'htmlwidget' <http://htmlwidgets.org>. 
    You can use this in Shiny apps and widgets, 'learnr' tutorials as well as 
    R Markdown. In addition, provides a custom 'learnr' question type - 
    'question_rank()' - that allows ranking questions with drag-and-drop.",2019-12-01,Andrie de Vries,"https://github.com/rstudio/sortable,
https://rstudio.github.io/sortable/",TRUE,https://github.com/rstudio/sortable,4499,82,2020-02-06T08:46:55Z,54.86585365853659
SortedEffects,"Implements the estimation and inference methods for sorted causal effects and 
    classification analysis as in Chernozhukov, Fernandez-Val and Luo (2018) <doi:10.3982/ECTA14415>.",2020-04-01,Shuowen Chen,https://github.com/yuqimemeda/SortedEffects,TRUE,https://github.com/yuqimemeda/sortedeffects,4650,0,2019-11-06T14:01:52Z,NA
sos4R,"A client for Sensor Observation Services (SOS, see
    <https://www.opengeospatial.org/standards/sos>) as specified by the
    Open Geospatial Consortium (OGC). With the package users can
    retrieve (meta)data from SOS instances and interactively
    create requests for near real-time observation
    data based on the available sensors, phenomena, observations etc.
    using thematic, temporal, and spatial filtering.",2020-04-29,Daniel Nuest,https://github.com/52North/sos4R,TRUE,https://github.com/52north/sos4r,14577,12,2020-06-07T12:59:56Z,1214.75
sotkanet,"Access data from the sotkanet open data portal
        <https://www.sotkanet.fi/sotkanet/fi/index>.",2017-05-16,Leo Lahti,https://github.com/ropengov/sotkanet,TRUE,https://github.com/ropengov/sotkanet,15378,5,2020-01-24T19:30:41Z,3075.6
SoupX,"Quantify, profile and remove ambient mRNA contamination (the ""soup"") from droplet based single cell RNA-seq experiments.  Implements the method described in Young et al. (2018) <doi:10.1101/303727>.",2020-05-26,Matthew Daniel Young,https://github.com/constantAmateur/SoupX,TRUE,https://github.com/constantamateur/soupx,174,52,2020-05-27T12:25:31Z,3.3461538461538463
sp,"Classes and methods for spatial
  data; the classes document where the spatial location information
  resides, for 2D or 3D data. Utility functions are provided, e.g. for
  plotting data as maps, spatial selection, as well as methods for
  retrieving coordinates, for subsetting, print, summary, etc.",2020-05-20,Edzer Pebesma,https://github.com/edzer/sp/ https://edzer.github.io/sp/,TRUE,https://github.com/edzer/sp,8477380,93,2020-05-21T09:43:32Z,91154.62365591398
SP2000,"A programmatic interface to <http://sp2000.org.cn>, re-written based on an accompanying 'Species 2000' API. Access tables describing catalogue of the Chinese known species of animals, plants, fungi, micro-organisms, and more. This package also supports access to catalogue of life global <http://catalogueoflife.org> and catalogue of life Taiwan <http://taibnet.sinica.edu.tw/home_eng.php?>. The development of 'SP2000' package were supported by Biodiversity Survey and Assessment Project of the Ministry of Ecology and Environment, China <No.2019HJ2096001006> and Yunnan University's Research Innovation Fund for Graduate Students <No.2019227>.",2020-06-07,Liuyong Ding,https://github.com/Otoliths/SP2000,TRUE,https://github.com/otoliths/sp2000,1554,4,2020-06-07T05:22:50Z,388.5
spacetime,"Classes and methods for spatio-temporal data, including space-time regular lattices, sparse lattices, irregular data, and trajectories; utility functions for plotting data as map sequences (lattice or animation) or multiple time series; methods for spatial and temporal selection and subsetting, as well as for spatial/temporal/spatio-temporal matching or aggregation, retrieving coordinates, print, summary, etc.",2020-01-21,Edzer Pebesma,http://github.com/edzer/spacetime,TRUE,https://github.com/edzer/spacetime,614388,50,2020-01-14T14:43:29Z,12287.76
spacey,"One of the remaining pain points in making beautiful maps via 
    packages like 'rayshader' is both obtaining and processing spatial data
    to build from. 'spacey' aims to make it easier to obtain and use this data
    for locations within the United States, providing utilities to download 
    'USGS' and 'ESRI' geospatial data and quickly turn it into maps.",2020-03-14,Michael Mahoney,"https://github.com/mikemahoney218/spacey,
https://mikemahoney218.github.io/spacey/",TRUE,https://github.com/mikemahoney218/spacey,1835,10,2020-03-14T18:13:23Z,183.5
spacyr,"An R wrapper to the 'Python' 'spaCy' 'NLP' library,
    from <http://spacy.io>.",2020-03-04,Kenneth Benoit,https://spacyr.quanteda.io,TRUE,https://github.com/quanteda/spacyr,243422,183,2020-03-04T10:10:54Z,1330.1748633879781
SpaDES,"Metapackage for implementing a variety of event-based models, with
    a focus on spatially explicit models. These include raster-based,
    event-based, and agent-based models. The core simulation components
    (provided by 'SpaDES.core') are built upon a discrete event simulation (DES;
    see Matloff (2011) ch 7.8.3 <https://nostarch.com/artofr.htm>)
    framework that facilitates modularity, and easily enables the user to
    include additional functionality by running user-built simulation modules
    (see also 'SpaDES.tools'). Included are numerous tools to visualize rasters
    and other maps (via 'quickPlot'), and caching methods for reproducible
    simulations (via 'reproducible'). Additional functionality is provided by
    the 'SpaDES.addins' and 'SpaDES.shiny' packages.",2019-09-17,Alex M Chubaty,"http://spades.predictiveecology.org,
https://github.com/PredictiveEcology/SpaDES",TRUE,https://github.com/predictiveecology/spades,22925,34,2019-12-06T15:47:00Z,674.2647058823529
SpaDES.core,"Provides the core framework for a discrete event system (DES) to 
    implement a complete data-to-decisions, reproducible workflow.
    The core DES components facilitate modularity, and easily enable the user
    to include additional functionality by running user-built modules.
    Includes conditional scheduling, restart after interruption, packaging of
    reusable modules, tools for developing arbitrary automated workflows,
    automated interweaving of modules of different temporal resolution,
    and tools for visualizing and understanding the DES project.",2020-05-15,Alex M Chubaty,"https://spades-core.predictiveecology.org/,
https://github.com/PredictiveEcology/SpaDES.core",TRUE,https://github.com/predictiveecology/spades.core,23298,5,2020-05-18T18:27:22Z,4659.6
SpaDES.tools,"Provides GIS and map utilities, plus additional modeling tools for
    developing cellular automata, dynamic raster models,  and agent based models
    in 'SpaDES'.
    Included are various methods for spatial spreading, spatial agents, GIS
    operations, random map generation, and others.
    See '?SpaDES.tools' for an categorized overview of these additional tools.",2020-05-15,Alex M Chubaty,"https://spades-tools.predictiveecology.org,
https://github.com/PredictiveEcology/SpaDES.tools",TRUE,https://github.com/predictiveecology/spades.tools,22583,2,2020-05-18T18:26:59Z,11291.5
spant,"Tools for reading, visualising and processing Magnetic Resonance
    Spectroscopy data. <https://martin3141.github.io/spant/>.",2020-06-05,Martin Wilson,NA,TRUE,https://github.com/martin3141/spant,14341,5,2020-06-05T12:59:43Z,2868.2
sparkavro,"Load Avro Files into 'Apache Spark' using 'sparklyr'. This
    allows to read files from 'Apache Avro' <https://avro.apache.org/>.",2020-01-10,Aki Ariga,NA,TRUE,https://github.com/chezou/sparkavro,48042,11,2020-06-04T04:32:26Z,4367.454545454545
sparkbq,"A 'sparklyr' extension package providing an integration with Google 'BigQuery'.
  It supports direct import/export where records are directly streamed from/to 'BigQuery'.
  In addition, data may be imported/exported via intermediate data extracts on Google 'Cloud Storage'.",2019-12-18,Martin Studer,"http://www.mirai-solutions.com,
https://github.com/miraisolutions/sparkbq",TRUE,https://github.com/miraisolutions/sparkbq,9349,12,2019-12-18T17:02:42Z,779.0833333333334
sparklyr,"R interface to Apache Spark, a fast and general engine for big data
    processing, see <http://spark.apache.org>. This package supports connecting to
    local and remote Apache Spark clusters, provides a 'dplyr' compatible back-end,
    and provides an interface to Spark's built-in machine learning algorithms.",2020-04-20,Yitao Li,http://spark.rstudio.com,TRUE,https://github.com/sparklyr/sparklyr,3702079,735,2020-06-05T16:42:26Z,5036.8421768707485
sparseIndexTracking,"Computation of sparse portfolios for financial index tracking, i.e., joint
    selection of a subset of the assets that compose the index and computation
    of their relative weights (capital allocation). The level of sparsity of the
    portfolios, i.e., the number of selected assets, is controlled through a
    regularization parameter. Different tracking measures are available, namely,
    the empirical tracking error (ETE), downside risk (DR), Huber empirical
    tracking error (HETE), and Huber downside risk (HDR). See vignette for a
    detailed documentation and comparison, with several illustrative examples.
    The package is based on the paper:
    K. Benidis, Y. Feng, and D. P. Palomar, ""Sparse Portfolios for High-Dimensional
    Financial Index Tracking,"" IEEE Trans. on Signal Processing, vol. 66, no. 1,
    pp. 155-170, Jan. 2018. <doi:10.1109/TSP.2017.2762286>.",2019-06-02,Daniel P. Palomar,"https://CRAN.R-project.org/package=sparseIndexTracking,
https://github.com/dppalomar/sparseIndexTracking,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2017.2762286",TRUE,https://github.com/dppalomar/sparseindextracking,7125,22,2019-06-13T06:59:22Z,323.8636363636364
sparsepp,"Provides interface to 'sparsepp' - fast, memory efficient hash map. 
    It is derived from Google's excellent 'sparsehash' implementation.
    We believe 'sparsepp' provides an unparalleled combination of performance and memory usage, 
    and will outperform your compiler's unordered_map on both counts. 
    Only Google's 'dense_hash_map' is consistently faster, at the cost of much greater 
    memory usage (especially when the final size of the map is not known in advance).",2018-09-22,Dmitriy Selivanov,"https://github.com/greg7mdp/sparsepp,
https://github.com/dselivanov/r-sparsepp",TRUE,https://github.com/greg7mdp/sparsepp,96151,965,2020-05-01T12:01:44Z,99.63834196891192
sparsevar,"A wrapper for sparse VAR/VECM time series models estimation
             using penalties like ENET (Elastic Net), SCAD (Smoothly Clipped 
             Absolute Deviation) and MCP (Minimax Concave Penalty). 
             Based on the work of Sumanta Basu and George Michailidis 
             <doi:10.1214/15-AOS1315>.",2019-08-19,Simone Vazzoler,http://github.com/svazzole/sparsevar,TRUE,https://github.com/svazzole/sparsevar,16503,8,2019-09-29T13:58:41Z,2062.875
sparsio,"Fast 'SVMlight' reader and writer. 
    'SVMlight' is most commonly used format for storing 
    sparse matrices (possibly with some target variable) on disk.
    For additional information about 'SVMlight' format see <http://svmlight.joachims.org/>.",2020-01-13,Dmitriy Selivanov,https://github.com/dselivanov/sparsio,TRUE,https://github.com/dselivanov/sparsio,9052,8,2020-01-13T07:08:24Z,1131.5
spatialEco,"Utilities to support spatial data manipulation, query, sampling
    and modelling. Functions include models for species population density, download
    utilities for climate and global deforestation spatial products, spatial
    smoothing, multivariate separability, point process model for creating pseudo-
    absences and sub-sampling, polygon and point-distance landscape metrics,
    auto-logistic model, sampling models, cluster optimization, statistical
    exploratory tools and raster-based metrics.",2020-06-04,Jeffrey S. Evans,https://github.com/jeffreyevans/spatialEco,TRUE,https://github.com/jeffreyevans/spatialeco,71616,26,2020-06-04T19:08:35Z,2754.4615384615386
SpatialKDE,"Calculate Kernel Density Estimation (KDE) for spatial data. 
  The algorithm is inspired by the tool 'Heatmap' from 'QGIS'. The method is described by:
  Hart, T., Zandbergen, P. (2014) <doi:10.1108/PIJPSM-04-2013-0039>, 
  Nelson, T. A., Boots, B. (2008) <doi:10.1111/j.0906-7590.2008.05548.x>,
  Chainey, S., Tompson, L., Uhlig, S.(2008) <doi:10.1057/palgrave.sj.8350066>.",2020-04-16,Jan Caha,"https://jancaha.github.io/SpatialKDE/index.html,
https://github.com/JanCaha/SpatialKDE",TRUE,https://github.com/jancaha/spatialkde,2581,1,2020-04-16T11:54:12Z,2581
SpatialPosition,"Computes spatial position models: Stewart potentials, Reilly
    catchment areas, Huff catchment areas.",2020-04-14,Timothée Giraud,https://github.com/Groupe-ElementR/SpatialPosition,TRUE,https://github.com/groupe-elementr/spatialposition,28774,26,2020-04-14T11:54:18Z,1106.6923076923076
spatialreg,"A collection of all the estimation functions for spatial cross-sectional models (on lattice/areal data using spatial weights matrices) contained up to now in 'spdep', 'sphet' and 'spse'. These model fitting functions include maximum likelihood methods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973, ISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially described by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The models are further described by 'Anselin' (1988) <doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and spatial general method of moment models initially proposed by 'Kelejian' and 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999) <doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC fitting methods proposed by 'LeSage' and 'Pace' (2009) <doi:10.1201/9781420064254> are implemented for the family of cross-sectional spatial regression models. Methods for fitting the log determinant term in maximum likelihood and MCMC fitting are compared by 'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting methods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both of these articles include extensive lists of references. 'spatialreg' >= 1.1-* correspond to 'spdep' >= 1.1-1, in which the model fitting functions are deprecated and pass through to 'spatialreg', but will mask those in 'spatialreg'. From versions 1.2-*, the functions will be made defunct in 'spdep'.",2019-12-01,Roger Bivand,"https://github.com/r-spatial/spatialreg/,
https://r-spatial.github.io/spatialreg/",TRUE,https://github.com/r-spatial/spatialreg,75148,14,2020-05-09T15:24:31Z,5367.714285714285
spatialrisk,"Methods for spatial risk calculations. It offers an efficient approach to determine the sum of all observations within a 
    circle of a certain radius. This might be beneficial for insurers who are required (by a recent European Commission regulation) to determine 
    the maximum value of insured fire risk policies of all buildings that are partly or fully located within a circle of a radius of 200m. ",2020-04-23,Martin Haringa,"https://github.com/mharinga/spatialrisk,
https://mharinga.github.io/spatialrisk/",TRUE,https://github.com/mharinga/spatialrisk,9127,1,2020-04-23T17:36:24Z,9127
spatialwarnings,Tools to compute and assess significance of early-warnings signals (EWS) of ecosystem degradation on raster data sets. EWS are metrics derived from the observed spatial structure of an ecosystem -- e.g. spatial autocorrelation -- that increase before an ecosystem undergoes a non-linear transition (Genin et al. (2018) <doi:10.1111/2041-210X.13058>).,2020-05-14,Alain Danet,https://github.com/spatial-ews/spatialwarnings,TRUE,https://github.com/spatial-ews/spatialwarnings,8930,5,2020-05-19T12:02:12Z,1786
SpatPCA,"Provide regularized principal component analysis incorporating smoothness, sparseness and orthogonality of eigenfunctions
  by using the alternating direction method of multipliers algorithm (Wang and Huang, 2017, <DOI:10.1080/10618600.2016.1157483>). The
  method can be applied to either regularly or irregularly spaced data, including 1D, 2D, and 3D.",2020-01-09,Wen-Ting Wang,https://github.com/egpivo/SpatPCA,TRUE,https://github.com/egpivo/spatpca,17177,9,2020-03-12T14:28:25Z,1908.5555555555557
spatsoc,"Detects spatial and temporal groups in GPS relocations. 
    It can be used to convert GPS relocations to 
    gambit-of-the-group format to build proximity-based social networks. 
    In addition, the randomizations function provides data-stream 
    randomization methods suitable for GPS data.",2020-03-28,Alec L. Robitaille,"https://docs.ropensci.org/spatsoc,
https://github.com/ropensci/spatsoc,
http://spatsoc.robitalec.ca",TRUE,https://github.com/ropensci/spatsoc,7780,19,2020-05-14T21:30:29Z,409.4736842105263
spatstat,"Comprehensive open-source toolbox for analysing Spatial Point Patterns. Focused mainly on two-dimensional point patterns, including multitype/marked points, in any spatial region. Also supports three-dimensional point patterns, space-time point patterns in any number of dimensions, point patterns on a linear network, and patterns of other geometrical objects. Supports spatial covariate data such as pixel images. 
	Contains over 2000 functions for plotting spatial data, exploratory data analysis, model-fitting, simulation, spatial sampling, model diagnostics, and formal inference. 
	Data types include point patterns, line segment patterns, spatial windows, pixel images, tessellations, and linear networks. 
	Exploratory methods include quadrat counts, K-functions and their simulation envelopes, nearest neighbour distance and empty space statistics, Fry plots, pair correlation function, kernel smoothed intensity, relative risk estimation with cross-validated bandwidth selection, mark correlation functions, segregation indices, mark dependence diagnostics, and kernel estimates of covariate effects. Formal hypothesis tests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.
	Parametric models can be fitted to point pattern data using the functions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs and Cox point processes, Neyman-Scott cluster processes, and determinantal point processes. Models may involve dependence on covariates, inter-point interaction, cluster formation and dependence on marks. Models are fitted by maximum likelihood, logistic regression, minimum contrast, and composite likelihood methods. 
	A model can be fitted to a list of point patterns (replicated point pattern data) using the function mppm(). The model can include random effects and fixed effects depending on the experimental design, in addition to all the features listed above.
	Fitted point process models can be simulated, automatically. Formal hypothesis tests of a fitted model are supported (likelihood ratio test, analysis of deviance, Monte Carlo tests) along with basic tools for model selection (stepwise(), AIC()) and variable selection (sdr). Tools for validating the fitted model include simulation envelopes, residuals, residual plots and Q-Q plots, leverage and influence diagnostics, partial residuals, and added variable plots.",2020-05-12,Adrian Baddeley,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat,873703,120,2020-05-25T00:58:18Z,7280.858333333334
spatstat.data,Contains all the datasets for the 'spatstat' package.,2020-01-26,Adrian Baddeley,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat.data,436960,5,2020-01-26T09:54:36Z,87392
spatstat.sparse,"Defines sparse three-dimensional arrays
	     and supports standard operations on them.
	     The package also includes utility functions for
	     matrix calculations that are common in
	     statistics, such as quadratic forms.",2020-06-04,Adrian Baddeley,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat.sparse,0,0,2020-06-02T01:36:37Z,NA
spatstat.utils,"Contains utility functions for the 'spatstat' package
             which may also be useful for other purposes.",2020-02-07,Adrian Baddeley,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat.utils,527821,4,2020-02-06T07:57:46Z,131955.25
spbabel,"Tools to convert from specific formats to more general forms of 
    spatial data. Using tables to store the actual entities present in spatial
    data provides flexibility, and the functions here deliberately 
    minimize the level of interpretation applied, leaving that for specific 
    applications. Includes support for simple features,  round-trip for 'Spatial' classes and long-form 
    tables, analogous to 'ggplot2::fortify'. There is also a more 'normal form' representation
    that decomposes simple features and their kin to tables of objects, parts, and unique coordinates. ",2020-04-07,Michael D. Sumner,https://mdsumner.github.io/spbabel,TRUE,https://github.com/mdsumner/spbabel,32305,19,2020-04-07T10:49:50Z,1700.2631578947369
spData,"Diverse spatial datasets for demonstrating, benchmarking and teaching spatial data analysis. 
    It includes R data of class sf (defined by the package 'sf'), Spatial ('sp'), and nb ('spdep').
    Unlike other spatial data packages such as 'rnaturalearth' and 'maps', 
    it also contains data stored in a range of file formats including GeoJSON, ESRI Shapefile and GeoPackage. 
    Some of the datasets are designed to illustrate specific analysis techniques.
    cycle_hire() and cycle_hire_osm(), for example, is designed to illustrate point pattern analysis techniques.",2020-04-06,Roger Bivand,https://nowosad.github.io/spData/,TRUE,https://github.com/nowosad/spdata,1154333,43,2020-04-18T10:06:16Z,26844.95348837209
spdep,"A collection of functions to create spatial weights matrix
  objects from polygon 'contiguities', from point patterns by distance and
  tessellations, for summarizing these objects, and for permitting their
  use in spatial data analysis, including regional aggregation by minimum
  spanning tree; a collection of tests for spatial 'autocorrelation',
  including global 'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord'
  (1973, ISBN: 0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel'
  general cross product statistic, Empirical Bayes estimates and
  'Assunção/Reis' (1999) <doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO;2-I> Index, 'Getis/Ord' G ('Getis' and 'Ord' 1992)
  <doi:10.1111/j.1538-4632.1992.tb00261.x> and multicoloured
  join count statistics, 'APLE' ('Li 'et al.' )
  <doi:10.1111/j.1538-4632.2007.00708.x>, local 'Moran's I'
  ('Anselin' 1995) <doi:10.1111/j.1538-4632.1995.tb00338.x> and
  'Getis/Ord' G ('Ord' and 'Getis' 1995)
  <doi:10.1111/j.1538-4632.1995.tb00912.x>,
  'saddlepoint' approximations ('Tiefelsdorf' 2002)
  <doi:10.1111/j.1538-4632.2002.tb01084.x> and exact tests
  for global and local 'Moran's I' ('Bivand et al.' 2009)
  <doi:10.1016/j.csda.2008.07.021> and 'LOSH' local indicators
  of spatial heteroscedasticity ('Ord' and 'Getis')
  <doi:10.1007/s00168-011-0492-y>. The implementation of most of
  the measures is described in 'Bivand' and 'Wong' (2018)
  <doi:10.1007/s11749-018-0599-x>.
  'spdep' >= 1.1-1 corresponds to 'spatialreg' >= 1.1-1, in which the model
  fitting functions are deprecated and pass through to 'spatialreg', but
  will mask those in 'spatialreg'. From versions 1.2-1, the functions will
  be made defunct in 'spdep'.
  For now 'spatialreg' only has functions from 'spdep', where they are shown
  as deprecated. 'spatialreg' only loads the namespace of 'spdep'; if you
  attach 'spdep', the same functions in the other package will be masked.
  Some feed through adequately, others do not.",2019-09-18,Roger Bivand,https://github.com/r-spatial/spdep/,TRUE,https://github.com/r-spatial/spdep,1493716,51,2020-05-06T09:40:03Z,29288.549019607843
spdplyr,"Methods for 'dplyr' verbs for 'sp' 'Spatial' classes. The basic 
    verbs that modify data attributes, remove or re-arrange rows are supported
    and provide complete 'Spatial' analogues of the input data. The group by
    and summarize work flow returns a non-topological spatial union. There is 
    limited support for joins, with left and inner to copy attributes from 
    another table. ",2020-05-12,Michael D. Sumner,https://github.com/mdsumner/spdplyr,TRUE,https://github.com/mdsumner/spdplyr,23839,39,2020-05-12T10:48:26Z,611.2564102564103
spduration,"An implementation of split-population duration regression models. 
    Unlike regular duration models, split-population duration models are
    mixture models that accommodate the presence of a sub-population that is 
    not at risk for failure, e.g. cancer patients who have been cured by 
    treatment. This package implements Weibull and Loglogistic forms for the 
    duration component, and focuses on data with time-varying covariates. 
    These models were originally formulated in Boag (1949) 
    <http://www.jstor.org/stable/2983694> and Berkson and Gage (1952) 
    <http://www.jstor.org/stable/2281318>, and extended in Schmidt and Witte 
    (1989) <doi:10.1016/0304-4076(89)90034-1>.",2018-05-04,Andreas Beger,"https://github.com/andybega/spduration,
https://andybeger.com/spduration",TRUE,https://github.com/andybega/spduration,15050,4,2019-08-29T12:34:14Z,3762.5
specklestar,A set of functions for obtaining positional parameters and magnitude difference between components of binary and multiple stellar systems from series of speckle images.,2018-02-08,Denis Rastegaev,https://drastega.github.io/docs/specklestar_vignette.html,TRUE,https://github.com/drastega/specklestar,6392,0,2020-05-17T09:31:34Z,NA
specr,"Provides utilities for conducting specification curve analyses (Simonsohn, Simmons & Nelson (2015, <doi: 10.2139/ssrn.2694998>) or multiverse analyses (Steegen, Tuerlinckx, Gelman & Vanpaemel, 2016, <doi: 10.1177/1745691616658637>) including functions to setup, run, evaluate, and plot all specifications.",2020-03-26,Philipp K. Masur,"https://masurp.github.io/specr/, https://github.com/masurp/specr",TRUE,https://github.com/masurp/specr,1038,25,2020-03-31T06:55:16Z,41.52
spectacles,"Stores and eases the manipulation of spectra and associated data,
    with dedicated classes for spatial and soil-related data.",2020-02-20,Pierre Roudier,https://github.com/pierreroudier/spectacles/,TRUE,https://github.com/pierreroudier/spectacles,8572,6,2020-02-20T03:30:11Z,1428.6666666666667
spectralGraphTopology,"In the era of big data and hyperconnectivity, learning
    high-dimensional structures such as graphs from data has become a prominent
    task in machine learning and has found applications in many fields such as
    finance, health care, and networks. 'spectralGraphTopology' is an open source,
    documented, and well-tested R package for learning graphs from data. It
    provides implementations of state of the art algorithms such as Combinatorial
    Graph Laplacian Learning (CGL), Spectral Graph Learning (SGL), Graph Estimation
    based on Majorization-Minimization (GLE-MM), and Graph Estimation based on
    Alternating Direction Method of Multipliers (GLE-ADMM). In addition, graph
    learning has been widely employed for clustering, where specific algorithms
    are available in the literature. To this end, we provide an implementation of
    the Constrained Laplacian Rank (CLR) algorithm.",2019-10-12,Ze Vinicius,"https://github.com/dppalomar/spectralGraphTopology,
https://mirca.github.io/spectralGraphTopology,
https://www.danielppalomar.com",TRUE,https://github.com/dppalomar/spectralgraphtopology,4855,12,2020-06-07T06:41:47Z,404.5833333333333
speech,"Converts the floor speeches of Uruguayan legislators, extracted from the 
    parliamentary minutes, to tidy data.frame where each observation is the intervention of a single legislator.",2019-12-22,Nicolas Schmidt,https://github.com/Nicolas-Schmidt/speech,TRUE,https://github.com/nicolas-schmidt/speech,1708,1,2020-04-26T03:24:59Z,1708
spef,"Functions for fitting semiparametric regression models for
        panel count survival data. An overview of the package can be found 
        in Wang and Yan (2011) <doi:10.1016/j.cmpb.2010.10.005> and
	Chiou et al. (2018) <doi:10.1111/insr.12271>.",2020-05-24,Sy Han (Steven) Chiou,http://github.com/stc04003/spef,TRUE,https://github.com/stc04003/spef,13420,1,2020-05-24T03:10:38Z,13420
sperrorest,"Implements spatial error estimation and
    permutation-based variable importance measures for predictive models
    using spatial cross-validation and spatial block bootstrap.",2020-05-26,Alexander Brenning,"https://giscience-fsu.github.io/sperrorest,
https://github.com/giscience-fsu/sperrorest",TRUE,https://github.com/giscience-fsu/sperrorest,24337,10,2020-05-26T06:54:02Z,2433.7
spex,"Functions to produce a fully fledged 'geo-spatial' object extent as a
    'SpatialPolygonsDataFrame'. Also included are functions to generate polygons
    from raster data using 'quadmesh' techniques, a round number buffered extent, and
    general spatial-extent and 'raster-like' extent helpers missing from the originating
    packages. Some latitude-based tools for polar maps are included. ",2019-06-02,Michael D. Sumner,https://mdsumner.github.io/spex/,TRUE,https://github.com/mdsumner/spex,17173,19,2020-05-13T16:42:47Z,903.8421052631579
spikeSlabGAM,"Bayesian variable selection, model choice, and regularized
    estimation for (spatial) generalized additive mixed regression models
    via stochastic search variable selection with spike-and-slab priors.",2020-02-21,Fabian Scheipl,https://github.com/fabian-s/spikeSlabGAM,TRUE,https://github.com/fabian-s/spikeslabgam,23810,7,2020-02-20T19:13:56Z,3401.4285714285716
spinBayes,"Many complex diseases are known to be affected by the interactions between 
   genetic variants and environmental exposures beyond the main genetic and environmental 
   effects. Existing Bayesian methods for gene-environment (G×E) interaction studies are 
   challenged by the high-dimensional nature of the study and the complexity of environmental 
   influences. We have developed a novel and powerful semi-parametric Bayesian variable 
   selection method that can accommodate linear and nonlinear G×E interactions simultaneously 
   (Ren et al. (2019) <arXiv:1906.01057>). Furthermore, the proposed method can conduct 
   structural identification by distinguishing nonlinear interactions from main effects only 
   case within Bayesian framework. Spike-and-slab priors are incorporated on both individual 
   and group level to shrink coefficients corresponding to irrelevant main and interaction 
   effects to zero exactly. The Markov chain Monte Carlo algorithms of the proposed and 
   alternative methods are  efficiently implemented in C++. ",2019-06-06,Jie Ren,https://github.com/jrhub/spinBayes,TRUE,https://github.com/jrhub/spinbayes,3420,0,2020-04-21T00:13:12Z,NA
spinifex,"Generates the path for manual tours
  ['Cook' & 'Buja' (1997) <doi:10.2307/1390747>]. Tours are generally available in the
  'tourr' package ['Wickham' 'et' 'al.' (2011) <doi:10.18637/jss.v040.i02>]. 
  The grand tour is an algorithm that shows all possible projections given sufficient time. 
  Guided uses projection pursuit to steer the tour towards interesting projections. 
  The 'spinifex' package implements manual control, where the contribution of a selected variable 
  can be adjusted between -1 to 1, to examine the sensitivity of structure in the data
  to that variable. 
  The result is an animation where the variable is toured into and out of the projection 
  completely, which can be rendered using the 'gganimate' and 'plotly' packages.",2019-04-09,Nicholas Spyrison,https://github.com/nspyrison/spinifex/,TRUE,https://github.com/nspyrison/spinifex,4437,0,2020-06-09T04:56:33Z,NA
spiritR,"Contains an R Markdown template for a clinical trial 
    protocol adhering to the SPIRIT statement. The SPIRIT (Standard Protocol 
    Items for Interventional Trials) statement outlines recommendations for a 
    minimum set of elements to be addressed in a  clinical trial protocol. 
    Also contains functions to create a xml document from the template and 
    upload it to clinicaltrials.gov<https://www.clinicaltrials.gov/> for 
    trial registration.",2019-08-19,Aaron Conway,https://github.com/awconway/spiritR,TRUE,https://github.com/awconway/spiritr,3809,2,2019-09-05T20:30:40Z,1904.5
splinetree,Builds regression trees and random forests for longitudinal or functional data using a spline projection method. Implements and extends the work of Yu and Lambert (1999) <doi:10.1080/10618600.1999.10474847>. This method allows trees and forests to be built while considering either level and shape or only shape of response trajectories. ,2019-07-18,Anna Neufeld,https://github.com/anna-neufeld/splinetree,TRUE,https://github.com/anna-neufeld/splinetree,6129,2,2019-08-26T18:38:00Z,3064.5
splithalf,"Estimate the internal consistency of your tasks with a permutation based split-half reliability approach.
    Unofficial release name: ""Kitten Mittens"".",2020-03-18,Sam Parsons,http://github.com/sdparsons/splithalf,TRUE,https://github.com/sdparsons/splithalf,10405,4,2020-03-23T22:30:37Z,2601.25
splitTools,"Fast, lightweight toolkit for data splitting. Data
    sets can be partitioned into disjoint groups (e.g. into training,
    validation, and test) or into (repeated) k-folds for subsequent
    cross-validation. Besides basic splits, the package supports
    stratified, grouped as well as blocked splitting. Furthermore,
    cross-validation folds for time series data can be created. See e.g.
    Hastie et al. (2001) <doi:10.1007/978-0-387-84858-7> for the basic
    background on data partitioning and cross-validation.",2020-04-18,Michael Mayer,https://github.com/mayer79/splitTools,TRUE,https://github.com/mayer79/splittools,2622,2,2020-04-18T15:23:51Z,1311
splot,"Automates common plotting tasks to ease data exploration.
  Makes density plots (potentially overlaid on histograms),
  scatter plots with prediction lines, or bar or line plots with error bars.
  For each type, y, or x and y variables can be plotted at levels of other variables,
  all with minimal specification.",2019-08-21,Micah Iserman,https://miserman.github.io/splot,TRUE,https://github.com/miserman/splot,10486,0,2020-04-25T03:24:53Z,NA
spMaps,"Build custom Europe SpatialPolygonsDataFrame, if you don't know what is
    a SpatialPolygonsDataFrame see SpatialPolygons() in 'sp', by example for mapLayout() in 'antaresViz'. 
    Antares is a powerful software developed by RTE to simulate and study electric power systems 
    (more information about 'Antares' here: <https://antares-simulator.org/>).",2019-11-27,Veronique Bachelier,https://github.com/rte-antares-rpackage/spMaps,TRUE,https://github.com/rte-antares-rpackage/spmaps,10143,0,2019-11-27T08:55:32Z,NA
spocc,"A programmatic interface to many species occurrence data sources,
    including Global Biodiversity Information Facility ('GBIF'), 'USGSs'
    Biodiversity Information Serving Our Nation ('BISON'), 'iNaturalist',
    Berkeley 'Ecoinformatics' Engine, 'eBird', Integrated Digitized
    'Biocollections' ('iDigBio'), 'VertNet', Ocean 'Biogeographic' Information
    System ('OBIS'), and Atlas of Living Australia ('ALA'). Includes
    functionality for retrieving species occurrence data, and combining
    those data.",2020-02-11,Scott Chamberlain,"https://github.com/ropensci/spocc (devel),
https://docs.ropensci.org/spocc/ (user manual)",TRUE,https://github.com/ropensci/spocc,57174,72,2020-02-11T18:59:46Z,794.0833333333334
spongebob,"Convert text (and text in R objects) to Mocking SpongeBob case 
             <https://knowyourmeme.com/memes/mocking-spongebob> and show them 
             off in fun ways. 
             CoNVErT TexT (AnD TeXt In r ObJeCtS) To MOCkINg SpoNgebOb CAsE
             <https://knowyourmeme.com/memes/mocking-spongebob> aND shOw tHem 
             OFf IN Fun WayS. ",2019-03-02,Jay Qi,https://github.com/jayqi/spongebob,TRUE,https://github.com/jayqi/spongebob,6379,12,2019-09-11T23:05:08Z,531.5833333333334
sport,"Calculates ratings for two-player or 
  multi-player challenges. Methods included in package such as are able to 
  estimate ratings (players strengths) and their evolution in time, also able to 
  predict output of challenge. Algorithms are based on Bayesian Approximation 
  Method, and they don't involve any matrix inversions nor likelihood estimation. 
  Parameters are updated sequentially, and computation doesn't require any 
  additional RAM to make estimation feasible. Additionally, base of the package 
  is written in C++ what makes sport computation even faster. Methods used in the 
  package refers to Mark E. Glickman (1999) 
  <http://www.glicko.net/research/glicko.pdf>; 
  Mark E. Glickman (2001) <doi:10.1080/02664760120059219>; 
  Ruby C. Weng, Chih-Jen Lin (2011) 
  <http://jmlr.csail.mit.edu/papers/volume12/weng11a/weng11a.pdf>; 
  W. Penny, Stephen J. Roberts (1999) <doi:10.1109/IJCNN.1999.832603>.",2020-01-07,Dawid Kałędkowski,https://github.com/gogonzo/sport,TRUE,https://github.com/gogonzo/sport,6711,6,2020-01-07T12:45:55Z,1118.5
spray,Sparse arrays interpreted as multivariate polynomials.,2020-05-17,Robin K. S. Hankin,https://github.com/RobinHankin/spray.git,TRUE,https://github.com/robinhankin/spray,20916,1,2020-05-17T00:48:11Z,20916
sprintr,"An implementation of a computationally efficient method to fit large-scale interaction models based on the reluctant interaction selection principle. The method and its properties are described in greater depth in Yu, G., Bien, J., and Tibshirani, R.J. (2019) ""Reluctant interaction modeling"", which is available at <arXiv:1907.08414>.",2019-08-24,Guo Yu,NA,TRUE,https://github.com/hugogogo/sprintr,3224,0,2020-03-04T07:34:37Z,NA
spsann,"Methods to optimize sample configurations using spatial simulated annealing. Multiple objective 
    functions are implemented for various purposes, such as variogram estimation, spatial trend estimation 
    and spatial interpolation. A general purpose spatial simulated annealing function enables the user to 
    define his/her own objective function. Solutions for augmenting existing sample configurations and solving
    multi-objective optimization problems are available as well.",2019-04-29,Alessandro Samuel-Rosa,https://github.com/samuel-rosa/spsann/,TRUE,https://github.com/samuel-rosa/spsann,18051,4,2019-10-01T14:18:25Z,4512.75
spsur,"A collection of functions to test and estimate Seemingly 
    Unrelated Regression (usually called SUR) models, with spatial structure, by maximum 
    likelihood and three-stage least squares. The package estimates the 
    most common spatial specifications, that is, SUR with Spatial Lag of 
    X regressors (called SUR-SLX), SUR with Spatial Lag Model (called SUR-SLM), 
    SUR with Spatial Error Model (called SUR-SEM), SUR with Spatial Durbin Model (called SUR-SDM), 
    SUR with Spatial Durbin Error Model (called SUR-SDEM), 
    SUR with Spatial Autoregressive terms and Spatial Autoregressive 
    Disturbances (called SUR-SARAR) and SUR with Spatially Independent Model (called SUR-SIM).
    The methodology of these models can be found in next references
    Mur, J., Lopez, F., and Herrera, M. (2010) <doi:10.1080/17421772.2010.516443> 
    Lopez, F.A., Mur, J., and Angulo, A. (2014) <doi:10.1007/s00168-014-0624-2>.",2020-04-07,Roman Minguez,http://github.com/rominsal/spsur,TRUE,https://github.com/rominsal/spsur,5581,7,2020-05-12T12:17:59Z,797.2857142857143
spsurv,"A set of reliable routines to ease semiparametric survival regression modeling based on Bernstein polynomials. 'spsurv' includes proportional hazards, proportional odds and accelerated failure time frameworks for right-censored data. RV Panaro (2020) <arXiv:2003.10548>.",2020-03-31,Renato Panaro  (<https://orcid.org/0000-0002-1903-2091>,NA,TRUE,https://github.com/rvpanaro/spsurv,1128,2,2020-06-05T14:00:08Z,564
spThin,"A set of functions that can be used to spatially thin
    species occurrence data. The resulting thinned data can be used in ecological
    modeling, such as ecological niche modeling.",2019-11-15,Matthew E. Aiello-Lammens,NA,TRUE,https://github.com/mlammens/spthin,30494,2,2019-11-15T17:49:16Z,15247
SPUTNIK,"A set of tools for the peak filtering of mass spectrometry
  imaging data (MSI or IMS) based on spatial distribution of signal. Given a 
  region-of-interest (ROI), representing the spatial region where the informative
  signal is expected to be localized, a series of filters determine which peak
  signals are characterized by an implausible spatial distribution. The filters
  reduce the dataset dimensionality and increase its information vs noise ratio,
  improving the quality of the unsupervised analysis results, reducing data
  dimensionality and simplifying the chemical interpretation.",2020-03-23,Paolo Inglese,https://github.com/paoloinglese/SPUTNIK,TRUE,https://github.com/paoloinglese/sputnik,9600,1,2020-03-22T12:51:50Z,9600
SqlRender,"A rendering tool for parameterized SQL that also translates into
  different SQL dialects.  These dialects include 'Microsoft Sql Server', 'Oracle', 
  'PostgreSql', 'Amazon RedShift', 'Apache Impala', 'IBM Netezza', 'Google BigQuery', 'Microsoft PDW', and 'SQLite'.",2020-05-19,Martijn Schuemie,"https://ohdsi.github.io/SqlRender,
https://github.com/OHDSI/SqlRender",TRUE,https://github.com/ohdsi/sqlrender,34270,35,2020-05-20T04:15:05Z,979.1428571428571
squash,"Functions for color-based visualization of multivariate data, i.e. colorgrams or heatmaps.  Lower-level functions  map numeric values to colors, display a matrix as an array of colors, and draw color keys.  Higher-level plotting functions generate a bivariate histogram, a dendrogram aligned with a color-coded matrix, a triangular distance matrix, and more.",2020-02-20,Aron C. Eklund,https://github.com/aroneklund/squash,TRUE,https://github.com/aroneklund/squash,36120,1,2020-02-19T21:13:57Z,36120
squashinformr,"Scrape SquashInfo <http://www.squashinfo.com/> for data on the Professional Squash Association World Tour and other squash events. 'squashinformr' functions scrape, parse, and clean data associated with players, tournaments, and rankings.",2020-05-01,Hayden MacDonald,https://github.com/HaydenMacDonald/squashinformr,TRUE,https://github.com/haydenmacdonald/squashinformr,638,1,2020-05-01T19:50:29Z,638
squid,"A simulation-based tool made to help researchers to become familiar with
    multilevel variations, and to build up sampling designs for their study. 
    This tool has two main objectives: First, it provides an educational tool useful for students, 
    teachers and researchers who want to learn to use mixed-effects models. 
    Users can experience how the mixed-effects model framework can be used to understand 
    distinct biological phenomena by interactively exploring simulated multilevel data. 
    Second, it offers research opportunities to those who are already familiar with 
    mixed-effects models, as it enables the generation of data sets that users may download 
    and use for a range of simulation-based statistical analyses such as power 
    and sensitivity analysis of multilevel and multivariate data [Allegue, H., Araya-Ajoy, Y.G., Dingemanse, 
    N.J., Dochtermann N.A., Garamszegi, L.Z., Nakagawa, S., Reale, D., Schielzeth, H. and Westneat, D.F. (2016) 
    <doi: 10.1111/2041-210X.12659>].",2019-08-06,Hassen Allegue,https://github.com/hallegue/squid,TRUE,https://github.com/hallegue/squid,10605,13,2019-10-08T17:11:18Z,815.7692307692307
srm,"
    Provides functionality for structural equation modeling for
    the social relations model (Kenny & La Voie, 1984;
    <doi:10.1016/S0065-2601(08)60144-6>; Warner, Kenny, & Soto, 1979,
    <doi:10.1037/0022-3514.37.10.1742>). Maximum likelihood
    estimation (Gill & Swartz, 2001, <doi:10.2307/3316080>;
    Nestler, 2018, <doi:10.3102/1076998617741106>) and
    least squares estimation is supported (Bond & Malloy, 2018,
    <doi:10.1016/B978-0-12-811967-9.00014-X>).",2019-12-15,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/srm,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/srm,3988,2,2020-04-24T16:05:14Z,1994
SRTtools,"Srt file is a common subtitle format for videos, it contains subtitle and when the subtitle showed.
    This package is for align time of srt file, and also change color, style and position of subtitle in videos,
	the srt file will be read as a vector into R, and can be write into srt file after modified using this package.",2019-07-18,Jim Chen,https://github.com/ChiHangChen/SRTtools,TRUE,https://github.com/chihangchen/srttools,3977,2,2019-07-18T05:36:45Z,1988.5
srvyr,"Use piping, verbs like 'group_by' and 'summarize', and other
    'dplyr' inspired syntactic style when calculating summary statistics on survey
    data using functions from the 'survey' package.",2020-05-26,Greg Freedman Ellis,"http://gdfe.co/srvyr, https://github.com/gergness/srvyr",TRUE,https://github.com/gergness/srvyr,61306,131,2020-06-09T21:34:28Z,467.98473282442745
ss3sim,"Develops a framework for fisheries stock assessment simulation
    testing with Stock Synthesis (SS) as described in Anderson et al.
    (2014) <doi:10.1371/journal.pone.0092725>.",2019-11-08,Kelli F. Johnson,https://github.com/ss3sim/ss3sim,TRUE,https://github.com/ss3sim/ss3sim,15593,21,2020-04-27T21:21:47Z,742.5238095238095
SSBtools,"Functions used by other packages from Statistics Norway are gathered. General data manipulation functions, and functions for hierarchical computations are included. The hierarchy specification functions are useful within statistical disclosure control.",2020-02-28,Øyvind Langsrud,https://github.com/statisticsnorway/SSBtools,TRUE,https://github.com/statisticsnorway/ssbtools,12526,1,2020-05-05T08:55:02Z,12526
ssc,"Provides a collection of self-labeled techniques for semi-supervised 
    classification. In semi-supervised classification, both labeled and unlabeled
    data are used to train a classifier. This learning paradigm has obtained promising
    results, specifically in the presence of a reduced set of labeled examples. 
    This package implements a collection of self-labeled techniques to construct a
    classification model. This family of techniques enlarges the original labeled set 
	using the most confident predictions to classify unlabeled data. The techniques 
	implemented can be applied to classification problems in several domains by the 
	specification of a supervised base classifier. At low ratios of labeled data, it 
	can be shown to perform better than classical supervised classifiers.",2019-12-15,Mabel González,https://github.com/mabelc/SSC,TRUE,https://github.com/mabelc/ssc,10899,5,2019-12-16T20:06:18Z,2179.8
SSDM,"Allows to map species richness and endemism based on stacked
    species distribution models (SSDM). Individuals SDMs can be created using a
    single or multiple algorithms (ensemble SDMs). For each species, an SDM can
    yield a habitat suitability map, a binary map, a between-algorithm variance
    map, and can assess variable importance, algorithm accuracy, and between-
    algorithm correlation. Methods to stack individual SDMs include summing
    individual probabilities and thresholding then summing. Thresholding can be
    based on a specific evaluation metric or by drawing repeatedly from a Bernoulli
    distribution. The SSDM package also provides a user-friendly interface.",2020-02-28,Sylvain Schmitt,https://github.com/sylvainschmitt/SSDM,TRUE,https://github.com/sylvainschmitt/ssdm,17238,26,2020-04-30T13:54:03Z,663
ssdtools,"Species sensitivity distributions are 
  cumulative probability distributions which are fitted to 
  toxicity concentrations for different species as described by
  Posthuma et al.(2001) <isbn:9781566705783>.
  The ssdtools package uses Maximum Likelihood to fit distributions 
  such as the log-normal, gamma, burr Type-III, log-logistic, 
  log-Gumbel, Gompertz and Weibull.
  The user can provide custom distributions.
  Multiple distributions can be averaged using Information Criteria.
  Confidence intervals on hazard concentrations and proportions are produced by 
  parametric bootstrapping.",2020-04-15,Joe Thorley,https://github.com/bcgov/ssdtools,TRUE,https://github.com/bcgov/ssdtools,7177,20,2020-06-03T00:34:03Z,358.85
ssMousetrack,"Estimates previously compiled state-space modeling for mouse-tracking experiments using the 'rstan' package, which provides the R interface to the Stan C++ library for Bayesian estimation. ",2019-01-16,Antonio Calcagnì,NA,TRUE,https://github.com/antcalcagni/ssmousetrack,5952,0,2020-04-26T08:16:49Z,NA
SSP,"Simulation-based sampling protocol (SSP) is an R package design to estimate sampling effort in studies of
    ecological communities based on the definition of pseudo-multivariate standard error (MultSE) (Anderson & Santana-Garcon, 2015) <doi:10.1111/ele.12385> and simulation
    of ecological data. The theoretical background is described in Guerra-Castro et al. (2020) <doi:10.1101/2020.03.19.996991>.",2020-03-28,Edlin Guerra-Castro,https://github.com/edlinguerra/SSP,TRUE,https://github.com/edlinguerra/ssp,940,2,2020-03-26T15:54:12Z,470
ssr,"An implementation of semi-supervised regression methods including self-learning and co-training by committee based on Hady, M. F. A., Schwenker, F., & Palm, G. (2009) <doi:10.1007/978-3-642-04274-4_13>. Users can define which set of regressors to use as base models from the 'caret' package, other packages, or custom functions.",2019-09-02,Enrique Garcia-Ceja,https://github.com/enriquegit/ssr,TRUE,https://github.com/enriquegit/ssr,2453,1,2019-09-05T12:14:10Z,2453
sss,"Tools to import survey files
    in the .sss (triple-s) format. The package provides the function
    read.sss() that reads the .asc (or .csv) and .sss files of a
    triple-s survey data file.",2017-04-01,Andrie de Vries,https://github.com/andrie/sss,TRUE,https://github.com/andrie/sss,16152,7,2019-07-31T13:49:57Z,2307.4285714285716
StabilizedRegression,"Contains an implementation of 'StabilizedRegression', a regression framework for heterogeneous data introduced in Pfister et al. (2019) <arXiv:1911.01850>. The procedure uses averaging to estimate a regression of a set of predictors X on a response variable Y by enforcing stability with respect to a given environment variable. The resulting regression leads to a variable selection procedure which allows to distinguish between stable and unstable predictors. The package further implements a visualization technique which illustrates the trade-off between stability and predictiveness of individual predictors.",2020-03-13,Niklas Pfister,NA,TRUE,https://github.com/niklaspfister/stabilizedregression-r,1313,1,2020-03-05T07:39:03Z,1313
stabm,"An implementation of many measures for the assessment of the stability
    of feature selection. Both simple measures and measures which take into account
    the similarities between features are available, see Bommert et al. (2017) <doi:10.1155/2017/7907163>.",2020-03-23,Andrea Bommert,https://github.com/bommert/stabm,TRUE,https://github.com/bommert/stabm,5207,2,2020-03-23T17:21:35Z,2603.5
stackoverflow,"Helper functions collected from StackOverflow.com, a
    question and answer site for professional and enthusiast programmers.",2020-01-10,Neal Fultz <nfultz@gmail.com> and the StackOverflow.com community,"https://github.com/nfultz/stackoverflow http://stackoverflow.com
http://stats.stackexchange.com/",TRUE,https://github.com/nfultz/stackoverflow,16791,14,2020-04-07T22:41:56Z,1199.357142857143
stagedtrees,"Creates and fits staged event tree probability models. 
             Staged event trees are probabilistic graphical models capable of 
             representing asymmetric conditional independence statements
             among categorical variables. 
             This package contains functions to create, plot and fit 
             staged event trees from data, moreover different structure learning 
             algorithms are available.
             References:
             Collazo R. A., Görgen C. and Smith J. Q. 
             (2018, ISBN:9781498729604).
             Görgen C., Bigatti A., Riccomagno E. and Smith J. Q. (2018) 
             <arXiv:1705.09457>.
             Thwaites P. A., Smith, J. Q. (2017) <arXiv:1510.00186>.
             Barclay L. M., Hutton J. L. and Smith J. Q. (2013) 
             <doi:10.1016/j.ijar.2013.05.006>.
             Smith J. Q. and Anderson P. E. (2008) 
             <doi:10.1016/j.artint.2007.05.004>.",2020-03-30,Gherardo Varando,https://github.com/gherardovarando/stagedtrees,TRUE,https://github.com/gherardovarando/stagedtrees,3370,1,2020-04-08T12:56:21Z,3370
stapler,"An implementation of Simultaneous Truth and 
    Performance Level Estimation (STAPLE) <doi:10.1109/TMI.2004.828354>.  This
    method is used when there are multiple raters for an object, typically an
    image, and this method fuses these ratings into one rating.  It uses an
    expectation-maximization method to estimate this rating and the individual
    specificity/sensitivity for each rater.",2020-01-09,John Muschelli,https://github.com/muschellij2/stapler,TRUE,https://github.com/muschellij2/stapler,8992,0,2020-05-15T01:49:29Z,NA
staplr,"Provides function to manipulate PDF files: 
    fill out PDF forms;
    merge multiple PDF files into one; 
    remove selected pages from a file;
    rename multiple files in a directory;
    rotate entire pdf document; 
    rotate selected pages of a pdf file;
    Select pages from a file;
    splits single input PDF document into individual pages;
    splits single input PDF document into parts from given points.",2019-02-13,Priyanga Dilini Talagala,NA,TRUE,https://github.com/pridiltal/staplr,15027,198,2019-07-23T03:34:04Z,75.89393939393939
staRdom,"This is a user-friendly way to run a parallel factor (PARAFAC) analysis (Harshman, 1971) <doi:10.1121/1.1977523> on excitation emission matrix (EEM) data from dissolved organic matter (DOM) samples (Murphy et al., 2013) <doi:10.1039/c3ay41160e>. The analysis includes profound methods for model validation. Some additional functions allow the calculation of absorbance slope parameters and create beautiful plots.",2020-04-23,Matthias Pucher,https://cran.r-project.org/package=staRdom,TRUE,https://github.com/matthiaspucher/stardom,10138,4,2020-04-23T08:46:43Z,2534.5
starnet,"Implements stacked elastic net regression (Rauschenberger 2020, <doi:10.1093/bioinformatics/btaa535>). The elastic net generalises ridge and lasso regularisation (Zou 2005, <doi:10.1111/j.1467-9868.2005.00503.x>). Instead of fixing or tuning the mixing parameter alpha, we combine multiple alpha by stacked generalisation (Wolpert 1992 <doi:10.1016/S0893-6080(05)80023-1>).",2020-06-08,Armin Rauschenberger,https://github.com/rauschenberger/starnet,TRUE,https://github.com/rauschenberger/starnet,0,1,2020-06-08T09:31:01Z,0
stars,"Reading, manipulating, writing and plotting
    spatiotemporal arrays (raster and vector data cubes) in 'R', using 'GDAL'
    bindings provided by 'sf', and 'NetCDF' bindings by 'ncmeta' and 'RNetCDF'.",2020-04-07,Edzer Pebesma,"https://r-spatial.github.io/stars/,
https://github.com/r-spatial/stars/",TRUE,https://github.com/r-spatial/stars,253940,311,2020-06-09T07:44:13Z,816.5273311897106
STARTS,"
    Contains functions for estimating the STARTS model of
    Kenny and Zautra (1995, 2001) <DOI:10.1037/0022-006X.63.1.52>,
    <DOI:10.1037/10409-008>. Penalized maximum likelihood
    estimation and Markov Chain Monte Carlo estimation are
    also provided, see Luedtke, Robitzsch and Wagner (2018) 
    <DOI:10.1037/met0000155>.",2019-11-04,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/STARTS,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/starts,12825,1,2019-11-04T15:07:57Z,12825
startup,Adds support for R startup configuration via '.Renviron.d' and '.Rprofile.d' directories in addition to '.Renviron' and '.Rprofile' files.  This makes it possible to keep private / secret environment variables separate from other environment variables.  It also makes it easier to share specific startup settings by simply copying a file to a directory.,2020-04-01,Henrik Bengtsson,https://github.com/HenrikBengtsson/startup,TRUE,https://github.com/henrikbengtsson/startup,18954,92,2020-04-27T00:03:34Z,206.02173913043478
starvars,"Allows the user to estimate a vector logistic smooth transition autoregressive model via maximum log-likelihood or nonlinear least squares. It further permits to test for linearity in the multivariate framework against a vector logistic smooth transition autoregressive model with a single transition variable. The estimation method is discussed in Terasvirta and Yang (2014, <doi:10.1108/S0731-9053(2013)0000031008>). Also, realized covariances can be constructed from stock market prices or returns, as explained in Andersen et al. (2001, <doi:10.1016/S0304-405X(01)00055-1>).",2020-05-04,Andrea Bucci,https://github.com/andbucci/starvars,TRUE,https://github.com/andbucci/starvars,514,0,2020-05-25T16:02:14Z,NA
statar,"A set of tools inspired by 'Stata' to explore data.frames ('summarize',
    'tabulate', 'xtile', 'pctile', 'binscatter', elapsed quarters/month, lead/lag).",2019-07-05,Matthieu Gomez,https://github.com/matthieugomez/statar,TRUE,https://github.com/matthieugomez/statar,31344,43,2020-01-23T20:06:55Z,728.9302325581396
statcanR,"An easy connection with R to Statistics Canada's Web Data Service. Open economic data (formerly known as CANSIM tables, now identified by Product IDs (PID)) are accessible as a data frame, directly in the user's R environment.
    Warin, Le Duc (2019) <doi:10.6084/m9.figshare.10544735>.",2019-12-13,Thierry Warin,http://github.com/warint/statcanR,TRUE,https://github.com/warint/statcanr,2439,3,2020-06-02T22:00:55Z,813
statebins,"Cartogram heatmaps are an alternative to choropleth maps for USA States
    and are based on work by the Washington Post graphics department in their report
    on ""The states most threatened by trade"". ""State bins"" preserve as much of the
    geographic placement of the states as possible but has the look and feel of a
    traditional heatmap. Functions are provided that allow for use of a binned,
    discrete scale, a continuous scale or manually specified colors depending on
    what is needed for the underlying data.",2015-12-21,Bob Rudis,http://github.com/hrbrmstr/statebins,TRUE,https://github.com/hrbrmstr/statebins,23384,98,2019-07-30T10:46:25Z,238.6122448979592
states,"Create panel data consisting of independent states from 1816 to
    the present. The package includes the Gleditsch & Ward (G&W) and Correlates
    of War (COW) lists of independent states, as well as helper functions for 
    working with state panel data and standardizing other data sources to 
    create country-year/month/etc. data. ",2019-01-11,Andreas Beger,"https://github.com/andybega/states, https://andybeger.com/states",TRUE,https://github.com/andybega/states,11114,11,2020-05-26T08:40:01Z,1010.3636363636364
statespacer,"A tool that makes estimating models in state space form 
    a breeze. See ""Time Series Analysis by State Space Methods"" by 
    Durbin and Koopman (2012, ISBN: 978-0-19-964117-8) for details 
    about the algorithms implemented.",2020-05-16,Dylan Beijers,"https://DylanB95.github.io/statespacer,
https://github.com/DylanB95/statespacer",TRUE,https://github.com/dylanb95/statespacer,342,1,2020-05-30T08:00:27Z,342
statgenGWAS,"Fast single trait Genome Wide Association Studies (GWAS) following 
    the method described in Kang et al. (2010), <doi:10.1038/ng.548>.        
    One of a series of statistical genetic packages for streamlining the 
    analysis of typical plant breeding experiments developed by Biometris.",2020-03-02,Bart-Jan van Rossum,https://github.com/Biometris/statgenGWAS/,TRUE,https://github.com/biometris/statgengwas,1950,1,2020-03-02T07:35:13Z,1950
statgenSTA,"Phenotypic analysis of field trials using mixed models with and 
    without spatial components. One of a series of statistical genetic packages 
    for streamlining the analysis of typical plant breeding experiments developed
    by Biometris.    
    Some functions have been created to be used in conjunction with the R 
    package 'asreml' for the 'ASReml' software, which can be obtained upon 
    purchase from 'VSN' international (<http://www.vsni.co.uk/software/asreml-r>). ",2020-03-23,Bart-Jan van Rossum,https://github.com/Biometris/statgenSTA/,TRUE,https://github.com/biometris/statgensta,2602,1,2020-03-23T08:57:13Z,2602
stationaRy,"Acquire hourly meteorological data from stations located all over
    the world. There is a wealth of data available, with historic weather data
    accessible from nearly 30,000 stations. The available data is automatically
    downloaded from a data repository and processed into a 'tibble' for the
    exact range of years requested. A relative humidity approximation is
    provided using the 'August-Roche-Magnus' formula, which was adapted from
    Alduchov and Eskridge (1996) <doi:10.1175%2F1520-0450%281996%29035%3C0601%3AIMFAOS%3E2.0.CO%3B2>.",2020-01-12,Richard Iannone,https://github.com/rich-iannone/stationaRy,TRUE,https://github.com/rich-iannone/stationary,12294,210,2020-05-04T16:36:00Z,58.542857142857144
statip,"A collection of miscellaneous statistical functions for 
    probability distributions: 'dbern()', 'pbern()', 'qbern()', 'rbern()' for 
    the Bernoulli distribution, and 'distr2name()', 'name2distr()' for 
    distribution names; 
    probability density estimation: 'densityfun()'; 
    most frequent value estimation: 'mfv()', 'mfv1()'; 
    other statistical measures of location: 'cv()' (coefficient of variation),
    'midhinge()', 'midrange()', 'trimean()'; 
    construction of histograms: 'histo()', 'find_breaks()'; 
    calculation of the Hellinger distance: 'hellinger()'; 
    use of classical kernels: 'kernelfun()', 'kernel_properties()'; 
    univariate piecewise-constant regression: 'picor()'. ",2019-11-17,Paul Poncet,https://github.com/paulponcet/statip,TRUE,https://github.com/paulponcet/statip,97242,0,2019-11-17T21:15:34Z,NA
statnet,"Statnet is a collection of packages for statistical network analysis that are 
  designed to work together because they share common data representations and 'API' 
  design.  They provide an integrated set of tools for the representation, 
  visualization, analysis, and simulation of many different forms of network data.  
  This package is designed to make it easy to install and load the 
  key 'statnet' packages in a single step.  Learn more about 'statnet' 
  at <http://www.statnet.org>.  Tutorials for many packages can be found 
  at <https://github.com/statnet/Workshops/wiki>.  For an introduction to functions in this package, 
  type help(package='statnet').",2019-06-14,Martina Morris,http://statnet.org,TRUE,https://github.com/statnet/statnet,194957,12,2019-06-16T04:14:27Z,16246.416666666666
statnet.common,Non-statistical utilities used by the software developed by the Statnet Project. They may also be of use to others.,2019-06-02,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/statnet.common,771158,5,2020-06-04T10:48:30Z,154231.6
statnipokladna,"Get programmatic access to data from the Czech public
    budgeting and accounting database, Státní pokladna
    <https://monitor.statnipokladna.cz/>.",2020-04-12,Petr Bouchal,https://github.com/petrbouchal/statnipokladna,TRUE,https://github.com/petrbouchal/statnipokladna,1114,2,2020-05-30T20:37:30Z,557
statquotes,"Generates a random quotation from a data base of quotes on topics
    in statistics, data visualization and science.",2017-08-29,Michael Friendly,NA,TRUE,https://github.com/friendly/statquotes,10019,5,2020-04-19T17:08:00Z,2003.8
stats19,"Tools to help download, process and analyse the UK road collision data collected using the
  'STATS19' form. The data are provided as 'CSV' files with detailed road safety data about the
  circumstances of car crashes and other incidents on the roads resulting in 
  casualties in Great Britain from 1979, the types
  (including make and model) of vehicles involved and the consequential casualties.  The
  statistics relate only to personal casualties on public roads that are reported
  to the police, and subsequently recorded, using the 'STATS19' accident reporting form. See
  the Department for Transport website 
  <https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data> for more
  information on these data.",2020-03-03,Robin Lovelace,"https://github.com/ropensci/stats19,
https://docs.ropensci.org/stats19/",TRUE,https://github.com/ropensci/stats19,20380,30,2020-06-01T23:42:42Z,679.3333333333334
statsExpressions,"Statistical processing backend for 'ggstatsplot',
    this package creates expressions with details from statistical tests.
    Currently, it supports only the most common types of statistical
    tests: parametric, nonparametric, robust, and Bayesian versions of
    t-test/ANOVA, correlation analyses, contingency table analysis, and
    meta-analysis.",2020-04-22,Indrajeet Patil,"https://indrajeetpatil.github.io/statsExpressions,
https://github.com/IndrajeetPatil/statsExpressions",TRUE,https://github.com/indrajeetpatil/statsexpressions,30290,71,2020-06-07T22:02:45Z,426.61971830985914
statsguRu,"Use this package to scrap Test Matches, One Day Internationals, Twenty-20 Internationals data of a player from ESPNCricinfo's Statsguru (<http://stats.espncricinfo.com/ci/engine/stats/index.html>) and then visualize their batting, bowling and fielding performances in the form of charts and graphs.",2019-05-17,Pranav Nagarajan,https://github.com/npranav10/statsguRu,TRUE,https://github.com/npranav10/statsguru,4071,0,2019-12-01T13:39:20Z,NA
statsr,"Data and functions to support Bayesian and frequentist inference and decision making 
            for the Coursera Specialization ""Statistics with R"".
            See <https://github.com/StatsWithR/statsr> for more information.",2020-05-05,Merlise Clyde,https://github.com/StatsWithR/statsr,TRUE,https://github.com/statswithr/statsr,56710,45,2020-05-31T22:51:52Z,1260.2222222222222
stcos,"Spatio-temporal change of support (STCOS) methods are designed for statistical inference
	on geographic and time domains which differ from those on which the data were observed. In
	particular, a parsimonious class of STCOS models supporting Gaussian outcomes was introduced
	by Bradley, Wikle, and Holan <doi:10.1002/sta4.94>. The 'stcos' package contains tools which
	facilitate use of STCOS models.",2020-05-27,Andrew M. Raim,https://github.com/holans/ST-COS,TRUE,https://github.com/holans/st-cos,4587,1,2020-06-03T14:36:03Z,4587
stevedore,"Work with containers over the Docker API.  Rather than
    using system calls to interact with a docker client, using the
    API directly means that we can receive richer information from
    docker.  The interface in the package is automatically generated
    using the 'OpenAPI' (a.k.a., 'swagger') specification, and all
    return values are checked in order to make them type stable.",2020-01-12,Rich FitzJohn,https://github.com/richfitz/stevedore,TRUE,https://github.com/richfitz/stevedore,12094,110,2020-01-14T07:07:35Z,109.94545454545455
stm,"The Structural Topic Model (STM) allows researchers 
  to estimate topic models with document-level covariates. 
  The package also includes tools for model selection, visualization,
  and estimation of topic-covariate regressions. Methods developed in
  Roberts et al (2014) <doi:10.1111/ajps.12103> and 
  Roberts et al (2016) <doi:10.1080/01621459.2016.1141684>. Vignette
  is Roberts et al (2019) <doi:10.18637/jss.v091.i02>.",2019-12-17,Brandon Stewart,http://structuraltopicmodel.com,TRUE,https://github.com/bstewart/stm,142914,257,2019-12-17T01:11:23Z,556.0856031128404
stminsights,"This app enables interactive validation, interpretation and visualization of structural topic models from the 'stm' package by Roberts and others (2014) <doi:10.1111/ajps.12103>. It also includes helper functions for model diagnostics and extracting data from effect estimates.",2018-11-24,Carsten Schwemmer,https://github.com/cschwem2er/stminsights,TRUE,https://github.com/cschwem2er/stminsights,10012,61,2020-06-08T12:37:21Z,164.13114754098362
StMoMo,"Implementation of the family of generalised age-period-cohort
    stochastic mortality models. This family of models encompasses many models
    proposed in the actuarial and demographic literature including the 
    Lee-Carter (1992) <doi:10.2307/2290201> and
    the Cairns-Blake-Dowd (2006) <doi:10.1111/j.1539-6975.2006.00195.x> models. 
    It includes functions for fitting mortality models, analysing their 
    goodness-of-fit and performing mortality projections and simulations.",2018-04-13,Andres Villegas,http://github.com/amvillegas/StMoMo,TRUE,https://github.com/amvillegas/stmomo,26796,5,2019-11-02T02:01:20Z,5359.2
stochQN,"Implementations of stochastic, limited-memory quasi-Newton optimizers,
	similar in spirit to the LBFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm,
	for smooth stochastic optimization. Implements the following methods:
	oLBFGS (online LBFGS) (Schraudolph, N.N., Yu, J. and Guenter, S., 2007 <http://proceedings.mlr.press/v2/schraudolph07a.html>),
	SQN (stochastic quasi-Newton) (Byrd, R.H., Hansen, S.L., Nocedal, J. and Singer, Y., 2016 <arXiv:1401.7020>),
	adaQN (adaptive quasi-Newton) (Keskar, N.S., Berahas, A.S., 2016, <arXiv:1511.01169>).
	Provides functions for easily creating R objects
	with partial_fit/predict methods from some given objective/gradient/predict functions.
	Includes an example stochastic logistic regression using these optimizers.
	Provides header files and registered C routines for using it directly from C/C++.",2019-09-05,David Cortes,https://github.com/david-cortes/stochQN,TRUE,https://github.com/david-cortes/stochqn,4906,9,2020-05-23T19:25:11Z,545.1111111111111
stokes,"Provides functionality for working with differentials,
           k-forms, wedge products, Stokes's theorem, and related concepts
	   from the exterior calculus.  Functionality for Grassman algebra
	   is provided.  The canonical reference would be:
	   M. Spivak (1965, ISBN:0-8053-9021-9) ""Calculus on Manifolds"".
	   The 'stokes' package was formerly known as the 'wedge' package.",2020-03-20,Robin K. S. Hankin,https://github.com/RobinHankin/stokes.git,TRUE,https://github.com/robinhankin/stokes,1197,2,2020-05-20T20:59:59Z,598.5
stopwords,"Provides multiple sources of stopwords, for use in text analysis and natural language processing.",2020-04-14,Kenneth Benoit,https://github.com/quanteda/stopwords,TRUE,https://github.com/quanteda/stopwords,733485,77,2020-04-15T07:40:59Z,9525.77922077922
stormwindmodel,"Allows users to input tracking data for a hurricane
    or other tropical storm, along with a data frame of grid points at which
    to model wind speeds. Functions in this package will then calculate wind
    speeds at each point based on wind model equations. This modeling framework
    is currently set up to model winds for North American locations with 
    Atlantic basin storms. This work was supported 
    in part by grants from the National Institute of Environmental Health 
    Sciences (R00ES022631), the National Science Foundation (1331399), and the 
    Department of Energy (DE-FG02-08ER64644).",2020-04-01,Brooke Anderson,https://github.com/geanders/stormwindmodel,TRUE,https://github.com/geanders/stormwindmodel,10367,6,2020-03-31T22:54:17Z,1727.8333333333333
storr,"Creates and manages simple key-value stores.  These can
    use a variety of approaches for storing the data.  This package
    implements the base methods and support for file system, in-memory
    and DBI-based database stores.",2018-10-18,Rich FitzJohn,https://github.com/richfitz/storr,TRUE,https://github.com/richfitz/storr,73430,90,2019-07-19T08:03:01Z,815.8888888888889
stplanr,"Tools for transport planning with an emphasis on spatial transport
    data and non-motorized modes. Enables common transport planning tasks including:
    downloading and cleaning transport datasets; creating geographic ""desire lines""
    from origin-destination (OD) data; route assignment, locally and via
    interfaces to routing services such as <http://cyclestreets.net/>;
    calculation of route segment attributes such as bearing and aggregate flow;
    and 'travel watershed' analysis.
    See Lovelace and Ellison (2018) <doi:10.32614/RJ-2018-053>.",2020-05-03,Robin Lovelace,"https://github.com/ropensci/stplanr,
https://docs.ropensci.org/stplanr/",TRUE,https://github.com/ropensci/stplanr,68927,195,2020-06-04T16:44:57Z,353.4717948717949
STRAH,"Searches for short tandem repeats (STR) in a specified region of any genome. This analysis can be expanded such that several regions (chromosomes) are studied. These STRs can be grouped into hotspot as well as flanking regions of user specified width. Hotspots are defined by the double strand break maps from Pratto et al. (2014) <doi:10.1126/science.1256442>. Moreover, the user can also search for a specified motif in a DNAStringSet-object, or a fasta-file, or a specified region of any genome. For an application of STR detections please see Heissl et al. (2018) <doi:10.1101/431841>. ",2019-04-09,Philipp Hermann,https://github.com/PhHermann/STRAH,TRUE,https://github.com/phhermann/strah,2992,0,2020-06-02T05:50:07Z,NA
strand,"Provides a framework for performing discrete (share-level) simulations of
  investment strategies. Simulated portfolios optimize exposure to an input signal subject
  to constraints such as position size and factor exposure.",2020-05-26,Jeff Enos,https://github.com/strand-tech/strand,TRUE,https://github.com/strand-tech/strand,329,3,2020-05-24T21:05:37Z,109.66666666666667
strapgod,"Create data frames with virtual groups that can be used with 
    'dplyr' to efficiently compute resampled statistics, generate the data for
    hypothetical outcome plots, and fit multiple models on resampled variations
    of the original data.",2019-09-20,Davis Vaughan,https://github.com/DavisVaughan/strapgod,TRUE,https://github.com/davisvaughan/strapgod,5825,60,2020-01-20T13:37:45Z,97.08333333333333
strataG,"A toolkit for analyzing stratified population genetic data. 
  Functions are provided for summarizing and checking loci 
  (haploid, diploid, and polyploid), single stranded DNA sequences,
  calculating most population subdivision metrics, and running external programs 
  such as structure and fastsimcoal. The package is further described in 
  Archer et al (2016) <doi:10.1111/1755-0998.12559>.",2020-02-28,Eric Archer,https://github.com/EricArcher/strataG,TRUE,https://github.com/ericarcher/stratag,25922,14,2020-06-05T22:55:22Z,1851.5714285714287
stratamatch,"A pilot matching design to automatically 
    stratify and match large datasets.  The manual_stratify() function allows
    users to manually stratify a dataset based on categorical variables of 
    interest, while the auto_stratify() function does automatically by
    allocating a held-aside (pilot) data set, fitting a prognostic score  
    (see Hansen (2008) <doi:10.1093/biomet/asn004>) on the pilot set, and stratifying the data set based
    on prognostic score quantiles.  The strata_match() function then does optimal
    matching of the data set in parallel within strata.",2020-04-09,Rachael C. Aikens,https://github.com/raikens1/stratamatch,TRUE,https://github.com/raikens1/stratamatch,4029,2,2020-04-09T00:19:31Z,2014.5
stratEst,"Variants of the strategy frequency estimation method by Dal Bo & Frechette (2011) <doi:10.1257/aer.101.1.411>, including the adaptation to estimate choice parameters of behavior strategies by Breitmoser (2015) <doi:10.1257/aer.20130675>, and the extension in the spirit of latent-class regression by Dvorak & Fehrler (2018) <doi:10.2139/ssrn.2986445>. ",2019-01-25,Fabian Dvorak,http://github.com/fdvorak/stratEst,TRUE,https://github.com/fdvorak/stratest,5658,3,2020-01-09T14:35:59Z,1886
StratifiedMedicine,"A toolkit for stratified medicine, subgroup identification, and precision medicine.
    Current tools include (1) filtering models (reduce covariate space), (2) patient-level estimate
    models (counterfactual patient-level quantities, for example the individual treatment effect), 
    (3) subgroup identification models (find subsets of patients with similar treatment effects), 
    and (4) parameter estimation and inference (for the overall population and discovered subgroups).
    These tools can directly feed into stratified medicine algorithms including PRISM 
    (patient response identifiers for stratified medicine; Jemielita and Mehrotra (2019) 
    <arXiv:1912.03337>. PRISM is a flexible and general framework which accepts 
    user-created models/functions. This package is in beta and will be continually updated.",2020-04-22,Thomas Jemielita,https://github.com/thomasjemielita/StratifiedMedicine,TRUE,https://github.com/thomasjemielita/stratifiedmedicine,4810,2,2020-04-19T23:18:46Z,2405
STraTUS,"For a single, known pathogen phylogeny, provides functions for enumeration of the set of compatible epidemic transmission trees, and for uniform sampling from that set. Optional arguments allow for incomplete sampling with a known number of missing individuals, multiple sampling, and known infection time limits. Always assumed are a complete transmission bottleneck and no superinfection or reinfection. See Hall and Colijn (2019) <doi:10.1093/molbev/msz058> for methodology.",2020-04-04,Matthew Hall,http://github.com/mdhall272/STraTUS/,TRUE,https://github.com/mdhall272/stratus,4078,2,2020-04-04T11:45:28Z,2039
stray,"
    This is a modification of 'HDoutliers' package. The 'HDoutliers' algorithm is a powerful 
    unsupervised algorithm for detecting anomalies in high-dimensional data, with a 
    strong theoretical foundation. However, it suffers from some limitations that 
    significantly hinder its performance level, under certain circumstances. This package 
    implements the algorithm proposed in Talagala, Hyndman and Smith-Miles (2019) 
    <arXiv:1908.04000>  for detecting anomalies in high-dimensional data
    that addresses these limitations of 'HDoutliers' algorithm. We define an anomaly as an observation that deviates markedly from the majority
    with a large distance gap. An approach based on extreme value theory is used 
    for the anomalous threshold calculation.",2019-12-17,Priyanga Dilini Talagala,NA,TRUE,https://github.com/pridiltal/stray,2716,38,2020-04-23T02:23:27Z,71.47368421052632
stream,A framework for data stream modeling and associated data mining tasks such as clustering and classification. The development of this package was supported in part by NSF IIS-0948893 and NIH R21HG005912. Hahsler et al (2017) <doi:10.18637/jss.v076.i14>.,2020-05-04,Michael Hahsler,https://github.com/mhahsler/stream,TRUE,https://github.com/mhahsler/stream,32649,25,2020-05-04T17:49:34Z,1305.96
streamDepletr,"Implementation of analytical models for estimating streamflow 
    depletion due to groundwater pumping, and other related tools. Functions
    are broadly split into two groups: (1) analytical streamflow depletion
    models, which estimate streamflow depletion for a single stream reach
    resulting from groundwater pumping; and (2) depletion apportionment 
    equations, which distribute estimated streamflow depletion among multiple
    stream reaches within a stream network. See Zipper et al. (2018) <doi:10.1029/2018WR022707>
    for more information on depletion apportionment equations and Zipper et
    al. (2019) <doi:10.1029/2018WR024403> for more information on analytical
    depletion functions, which combine analytical models and depletion apportionment
    equations.",2020-03-25,Samuel C. Zipper,https://github.com/FoundrySpatial/streamDepletr,TRUE,https://github.com/foundryspatial/streamdepletr,3677,2,2020-03-24T15:58:00Z,1838.5
streamMOA,"Interface for data stream clustering algorithms implemented in the MOA (Massive Online Analysis) framework (Albert Bifet, Geoff Holmes, Richard Kirkby, Bernhard Pfahringer (2010). MOA: Massive Online Analysis, Journal of Machine Learning Research 11: 1601-1604).",2019-05-15,Michael Hahsler,NA,TRUE,https://github.com/mhahsler/streammoa,19298,6,2020-04-03T19:41:43Z,3216.3333333333335
strex,"There are some things that I wish were easier with
    the 'stringr' or 'stringi' packages. The foremost of these is the
    extraction of numbers from strings. 'stringr' and 'stringi' make you
    figure out the regular expression for yourself; 'strex' takes care of
    this for you. There are many other handy functionalities in 'strex'.
    Contributions to this package are encouraged: it is intended as a
    miscellany of string manipulation functions that cannot be found in
    'stringi' or 'stringr'.",2019-09-13,Rory Nolan,"https://rorynolan.github.io/strex,
https://github.com/rorynolan/strex",TRUE,https://github.com/rorynolan/strex,76803,21,2019-08-21T15:52:07Z,3657.285714285714
strider,"The strided iterator adapts multidimensional buffers to work with 
  the C++ standard library and range-based for-loops. Given a pointer or iterator
  into a multidimensional data buffer, one can generate an iterator range using
  make_strided to construct strided versions of the standard library's begin and
  end. For constructing range-based for-loops, a strided_range class is provided.
  These help authors to avoid integer-based indexing, which in some cases can impede
  algorithm performance and introduce indexing errors. This library exists
  primarily to expose the header file to other R projects.",2020-06-03,Tim Keitt,https://github.com/thk686/strider,TRUE,https://github.com/thk686/strider,8595,3,2020-06-02T20:09:17Z,2865
stringb,"Base R already ships with string handling capabilities 'out-
    of-the-box' but lacks streamlined function names and workflow. The
    'stringi' ('stringr') package on the other hand has well named functions,
    extensive Unicode support and allows for a streamlined workflow. On the other
    hand it adds dependencies and regular expression interpretation between base R
    functions and 'stringi' functions might differ. This packages aims at providing
    a solution to the use case of unwanted dependencies on the one hand but the need
    for streamlined text processing on the other. The packages' functions are solely
    based on wrapping base R functions into 'stringr'/'stringi' like function names.
    Along the way it adds one or two extra functions and last but not least provides
    all functions as generics, therefore allowing for adding methods for other text
    structures besides plain character vectors.",2020-02-05,Peter Meissner,https://github.com/petermeissner/stringb,TRUE,https://github.com/petermeissner/stringb,12831,23,2020-02-05T20:31:27Z,557.8695652173913
stringdist,"Implements an approximate string matching version of R's native
    'match' function. Can calculate various string distances based on edits
    (Damerau-Levenshtein, Hamming, Levenshtein, optimal sting alignment), qgrams (q-
    gram, cosine, jaccard distance) or heuristic metrics (Jaro, Jaro-Winkler). An
    implementation of soundex is provided as well. Distances can be computed between
    character vectors while taking proper care of encoding or between integer
    vectors representing generic sequences. This package is built for speed and
    runs in parallel by using 'openMP'. An API for C or C++ is exposed as well.",2019-10-21,Mark van der Loo,https://github.com/markvanderloo/stringdist,TRUE,https://github.com/markvanderloo/stringdist,1503446,215,2019-11-03T20:28:26Z,6992.772093023255
stringfish,Provides an extendable and performant 'alt-string' implementation backed by 'C++' vectors and strings.,2020-06-05,Travers Ching,https://github.com/traversc/stringfish,TRUE,https://github.com/traversc/stringfish,112,16,2020-06-06T01:25:34Z,7
stringi,"Fast, correct, consistent, portable and convenient character
    string/text processing in every locale and any native encoding. 
    Owing to the use of the 'ICU' (International Components for Unicode) 
    library, the package provides 'R' users with platform-independent functions
    known to 'Java', 'Perl', 'Python', 'PHP' and 'Ruby' programmers. Available
    features include: pattern searching (e.g., with 'Java'-like regular
    expressions or the 'Unicode' collation algorithm), random string generation,
    case mapping, string transliteration, concatenation,
    Unicode normalization, date-time formatting and parsing and many more.",2020-02-17,Marek Gagolewski,"http://www.gagolewski.com/software/stringi/
http://site.icu-project.org/ http://www.unicode.org/",TRUE,https://github.com/gagolews/stringi,26898983,183,2020-03-22T22:55:58Z,146988.9781420765
stringr,"A consistent, simple and easy to use set of
    wrappers around the fantastic 'stringi' package. All function and
    argument names (and positions) are consistent, all functions deal with
    ""NA""'s and zero length vectors in the same way, and the output from
    one function is easy to feed into the input of another.",2019-02-10,Hadley Wickham,"http://stringr.tidyverse.org, https://github.com/tidyverse/stringr",TRUE,https://github.com/tidyverse/stringr,25365619,366,2020-06-01T13:37:23Z,69304.96994535519
striprtf,Extracts plain text from RTF (Rich Text Format) file.,2019-01-03,Kota Mori,https://github.com/kota7/striprtf,TRUE,https://github.com/kota7/striprtf,77636,12,2019-10-30T10:22:17Z,6469.666666666667
strvalidator,"An open source platform for validation and process control.
    Tools to analyze data from internal validation of forensic short tandem
    repeat (STR) kits are provided. The tools are developed to provide
    the necessary data to conform with guidelines for internal validation
    issued by the European Network of Forensic Science Institutes (ENFSI)
    DNA Working Group, and the Scientific Working Group on DNA Analysis Methods
    (SWGDAM). A front-end graphical user interface is provided.
    More information about each function can be found in the
    respective help documentation.",2019-03-22,Oskar Hansson,https://sites.google.com/site/forensicapps/strvalidator,TRUE,https://github.com/oskarhansson/strvalidator,21353,3,2020-06-07T18:47:37Z,7117.666666666667
studentlife,"Download, navigate and analyse the Student-Life dataset. 
    The Student-Life dataset contains passive and automatic sensing data 
    from the phones of a class of 48 Dartmouth college students. 
    It was collected over a 10 week term. Additionally, the dataset contains ecological 
    momentary assessment results along with pre-study and post-study mental  
    health surveys. The intended use is to assess 
    mental health, academic performance and behavioral trends. 
    The raw dataset and additional information is 
    available at <https://studentlife.cs.dartmouth.edu/>.",2019-05-31,Daniel Fryer,https://github.com/Frycast/studentlife,TRUE,https://github.com/frycast/studentlife,3926,3,2019-11-22T05:40:43Z,1308.6666666666667
styler,"Pretty-prints R code without changing the user's
    formatting intent.",2020-02-23,Lorenz Walthert,https://github.com/r-lib/styler,TRUE,https://github.com/r-lib/styler,387486,389,2020-06-06T12:29:27Z,996.107969151671
stylest,Estimates distinctiveness in speakers' (authors') style. Fits models that can be used for predicting speakers of new texts. Methods developed in Spirling et al (2018) <doi:10.2139/ssrn.3235506> (working paper).,2018-09-16,Leslie Huang,https://github.com/leslie-huang/stylest,TRUE,https://github.com/leslie-huang/stylest,5810,28,2020-04-14T23:34:33Z,207.5
stylo,"Supervised and unsupervised multivariate methods, supplemented by GUI and some visualizations, to perform various analyses in the field of computational stylistics, authorship attribution, etc. For further reference, see Eder et al. (2016), <https://journal.r-project.org/archive/2016/RJ-2016-007/index.html>. You are also encouraged to visit the Computational Stylistics Group's website <https://computationalstylistics.github.io/>, where a reasonable amount of information about the package and related projects are provided.",2020-04-20,Maciej Eder,https://github.com/computationalstylistics/stylo,TRUE,https://github.com/computationalstylistics/stylo,49265,86,2020-05-01T13:47:46Z,572.8488372093024
subformula,"A formula 'sub' is a subformula of 'formula' if all the terms
    on the right hand side of 'sub' are terms of 'formula' and their left hand 
    sides are identical. This package aids in the creation of subformulas.",2019-11-15,Jonas Moss,"https://github.com/JonasMoss/subformula,",TRUE,https://github.com/jonasmoss/subformula,2409,0,2019-11-07T07:23:50Z,NA
subgxe,"Classical methods for combining summary data from genome-wide
    association studies (GWAS) only use marginal genetic effects and power can
    be compromised in the presence of heterogeneity. 'subgxe' is a R package
    that implements p-value assisted subset testing for association (pASTA),
    a method developed by Yu et al. (2019) <doi:10.1159/000496867>. pASTA
    generalizes association analysis based on subsets by incorporating
    gene-environment interactions into the testing procedure.",2019-06-14,Alexander Rix,https://github.com/umich-cphds/subgxe,TRUE,https://github.com/umich-cphds/subgxe,3512,0,2019-08-14T14:42:20Z,NA
subniche,"Complementary indexes calculation to the Outlying Mean Index analysis to explore niche shift of a community and biological constraint within an Euclidean space, with graphical displays.",2020-04-03,Stephane Karasiewicz,NA,TRUE,https://github.com/karasiewiczstephane/witomi,12483,4,2020-03-28T14:30:22Z,3120.75
subplex,"The subplex algorithm for unconstrained optimization, developed by Tom Rowan <http://www.netlib.org/opt/subplex.tgz>.",2020-02-23,Aaron A. King,https://github.com/kingaa/subplex/,TRUE,https://github.com/kingaa/subplex,188564,2,2020-02-23T20:47:55Z,94282
SubtypeDrug,"A systematic biology tool was developed to prioritize cancer subtype-specific drugs by integrating genetic perturbation, drug action, biological pathway, and cancer subtype. 
    The capabilities of this tool include inferring patient-specific subpathway activity profiles in the context of gene expression profiles with subtype labels, calculating differentially 
    expressed subpathways based on cultured human cells treated with drugs in the 'cMap' (connectivity map) database, prioritizing cancer subtype specific drugs according to drug-disease 
    reverse association score based on subpathway, and visualization of results (Castelo (2013) <doi:10.1186/1471-2105-14-7>; Han et al (2019) <doi:10.1093/bioinformatics/btz894>; Lamb and Justin (2006) <DOI:10.1126/science.1132939>).",2020-05-16,Xudong Han,NA,TRUE,https://github.com/hanjunwei-lab/subtypedrug,239,0,2020-05-27T07:38:38Z,NA
suddengains,"Identify sudden gains based on the three criteria outlined by Tang and DeRubeis (1999) <doi:10.1037/0022-006X.67.6.894> to a selection of repeated measures. Sudden losses, defined as the opposite of sudden gains can also be identified. Two different datasets can be created, one including all sudden gains/losses and one including one selected sudden gain/loss for each case. It can extract scores around sudden gains/losses. It can plot the average change around sudden gains/losses and trajectories of individual cases.",2020-05-22,Milan Wiedemann,https://milanwiedemann.github.io/suddengains/,TRUE,https://github.com/milanwiedemann/suddengains,5784,3,2020-06-05T12:34:11Z,1928
sugarbag,"Create a hexagon tilegram from spatial polygons. Each polygon is
    represented by a hexagon tile, placed as close to it's original centroid
    as possible, with a focus on maintaining spatial relationship to a focal
    point. Developed to aid visualisation and analysis of spatial distributions
    across Australia, which can be challenging due to the concentration of the
    population on the coast and wide open interior.",2020-01-08,Stephanie Kobakian,"https://srkobakian.github.io/sugarbag/,
https://github.com/srkobakian/sugarbag",TRUE,https://github.com/srkobakian/sugarbag,4304,23,2020-03-03T03:49:02Z,187.1304347826087
sugrrants,"Provides 'ggplot2' graphics for analysing time
    series data. It aims to fit into the 'tidyverse' and grammar of
    graphics framework for handling temporal data.",2020-04-18,Earo Wang,https://pkg.earo.me/sugrrants,TRUE,https://github.com/earowang/sugrrants,23048,63,2020-04-18T02:55:41Z,365.8412698412698
summariser,"Functions to speed up the exploratory analysis of simple
    datasets using 'dplyr'. Functions are provided to do the 
    common tasks of calculating confidence intervals.",2020-03-30,Conor Neilson,https://github.com/condwanaland/summariser,TRUE,https://github.com/condwanaland/summariser,12478,0,2020-03-30T05:34:30Z,NA
summarytools,"Data frame summaries, cross-tabulations,
  weight-enabled frequency tables and common descriptive
  (univariate) statistics in concise tables available in a
  variety of formats (plain ASCII, Markdown and HTML). A good 
  point-of-entry for exploring data, both for experienced
  and new R users.",2020-03-02,Dominic Comtois,https://github.com/dcomtois/summarytools,TRUE,https://github.com/dcomtois/summarytools,185912,344,2020-06-09T18:07:55Z,540.4418604651163
SUMMER,"Provides methods for estimating, projecting, and plotting spatio-temporal 
  under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>
  and Li et al. (2019) <doi:10.1371/journal.pone.0210645>.",2019-10-23,Zehang R Li,https://github.com/bryandmartin/SUMMER,TRUE,https://github.com/bryandmartin/summer,9185,6,2020-06-03T13:47:36Z,1530.8333333333333
sunburstR,"Make interactive 'd3.js' sequence sunburst diagrams in R with the
    convenience and infrastructure of an 'htmlwidget'.",2019-11-05,Mike Bostock,https://github.com/timelyportfolio/sunburstR,TRUE,https://github.com/timelyportfolio/sunburstr,233187,155,2019-11-02T18:15:46Z,1504.4322580645162
sundialr,"Provides a way to call the functions in 'SUNDIALS' C ODE solving library (<https://computation.llnl.gov/projects/sundials>). Currently the serial version of ODE solver, 'CVODE', sensitivity calculator 'CVODES' and differential algebraic solver 'IDA' from the 'SUNDIALS' library are implemented. The package requires ODE to be written as an 'R' or 'Rcpp' function and does not require the 'SUNDIALS' library to be installed on the local machine.",2020-05-31,Satyaprakash Nayak,https://github.com/sn248/sundialr,TRUE,https://github.com/sn248/sundialr,7148,4,2020-05-31T18:50:56Z,1787
SuperExactTest,"Identification of sets of objects with shared features is a common operation in all disciplines. Analysis of intersections among multiple sets is fundamental for in-depth understanding of their complex relationships. This package implements a theoretical framework for efficient computation of statistical distributions of multi-set intersections based upon combinatorial theory, and provides multiple scalable techniques for visualizing the intersection statistics. The statistical algorithm behind this package was published in Wang et al. (2015) <doi:10.1038/srep16923>.",2019-06-21,Minghui Wang,https://github.com/mw201608/SuperExactTest/,TRUE,https://github.com/mw201608/superexacttest,16476,4,2019-06-25T16:58:54Z,4119
SuperLearner,"Implements the super learner prediction method and contains a
    library of prediction algorithms to be used in the super learner.",2019-12-10,Eric Polley,https://github.com/ecpolley/SuperLearner,TRUE,https://github.com/ecpolley/superlearner,71886,192,2020-03-06T18:06:38Z,374.40625
superml,"The idea is to provide a standard interface 
             to users who use both R and Python for building machine learning models. 
             This package provides a scikit-learn's fit, predict interface to 
             train machine learning models in R.    ",2020-04-28,Manish Saraswat,https://github.com/saraswatmks/superml,TRUE,https://github.com/saraswatmks/superml,9590,20,2020-06-01T19:36:17Z,479.5
supernova,"Produces ANOVA tables in the format used by Judd, McClelland, and Ryan (2017, ISBN: 978-1138819832) in their introductory textbook, Data Analysis. This includes proportional reduction in error and formatting to improve ease the transition between the book and R.",2019-09-26,Jim Stigler,https://github.com/UCLATALL/supernova,TRUE,https://github.com/uclatall/supernova,9360,2,2019-11-05T22:39:43Z,4680
Superpower,"Functions to perform simulations of ANOVA designs of up to three factors. Calculates the observed power and average observed effect size for all main effects and interactions in the ANOVA, and all simple comparisons between conditions. Includes functions for analytic power calculations and additional helper functions that compute effect sizes for ANOVA designs, observed error rates in the simulations, and functions to plot power curves. Please see Lakens, D., & Caldwell, A. R. (2019). ""Simulation-Based Power-Analysis for Factorial ANOVA Designs"". <doi:10.31234/osf.io/baxsf>.",2020-02-17,Aaron Caldwell,https://arcaldwell49.github.io/SuperpowerBook/,TRUE,https://github.com/arcaldwell49/superpower,2103,16,2020-05-03T13:30:12Z,131.4375
SupMZ,Calculates the sup MZ value to detect the unknown structural break points under Heteroskedasticity as given in Ahmed et al. (2017) (<DOI: 10.1080/03610926.2016.1235200>).,2020-01-16,Muhammad Yaseen,"https://github.com/myaseen208/SupMZ,
https://myaseen208.github.io/SupMZ/",TRUE,https://github.com/myaseen208/supmz,4073,0,2020-01-24T09:50:33Z,NA
suppdata,"Downloads data supplementary materials from manuscripts,
    using papers' DOIs as references. Facilitates open, reproducible
    research workflows: scientists re-analyzing published datasets can
    work with them as easily as if they were stored on their own
    computer, and others can track their analysis workflow
    painlessly. The main function suppdata() returns a (temporary)
    location on the user's computer where the file is stored, making
    it simple to use suppdata() with standard functions like
    read.csv().",2019-04-25,William D. Pearse,https://github.com/ropensci/suppdata,TRUE,https://github.com/ropensci/suppdata,4114,24,2020-02-17T17:06:07Z,171.41666666666666
surbayes,"Implementation of the direct Monte Carlo approach of 
             Zellner and Ando (2010) <doi:10.1016/j.jeconom.2010.04.005>
             to sample from posterior of 
             Seemingly Unrelated Regression (SUR) models. In 
             addition, a Gibbs sampler is implemented that allows 
             the user to analyze SUR models using the power prior.",2020-05-15,Ethan Alt,https://github.com/ethan-alt/surbayes,TRUE,https://github.com/ethan-alt/surbayes,552,0,2020-05-07T14:52:34Z,NA
sure,"An implementation of the surrogate approach to residuals and 
  diagnostics for ordinal and general regression models; for details, see Liu 
  and Zhang (2017) <doi:10.1080/01621459.2017.1292915>. These residuals can be 
  used to construct standard residual plots for model diagnostics (e.g., 
  residual-vs-fitted value plots, residual-vs-covariate plots, Q-Q plots, etc.). 
  The package also provides an 'autoplot' function for producing standard 
  diagnostic plots using 'ggplot2' graphics. The package currently supports 
  cumulative link models from packages 'MASS', 'ordinal', 'rms', and 'VGAM'. 
  Support for binary regression models using the standard 'glm' function is also 
  available.",2017-09-19,Brandon Greenwell,https://github.com/AFIT-R/sure,TRUE,https://github.com/afit-r/sure,9649,6,2020-02-04T19:14:35Z,1608.1666666666667
survELtest,"Computing the one-sided/two-sided integrated/maximally selected EL statistics for simultaneous testing, the one-sided/two-sided EL tests for pointwise testing, and an initial test that precedes one-sided testing to exclude the possibility of crossings or alternative orderings among the survival functions. ",2020-01-13,Hsin-wen Chang,https://github.com/news11/survELtest,TRUE,https://github.com/news11/surveltest,6204,0,2020-01-16T03:32:50Z,NA
surveydata,"Data obtained from surveys contains information not only about the
    survey responses, but also the survey metadata, e.g. the original survey
    questions and the answer options. The 'surveydata' package makes it easy to
    keep track of this metadata, and to easily extract columns with
    specific questions.",2020-04-21,Andrie de Vries,"https://github.com/andrie/surveydata,
https://andrie.github.io/surveydata",TRUE,https://github.com/andrie/surveydata,19294,16,2020-04-21T11:06:04Z,1205.875
surveyplanning,"Tools for sample survey planning, including sample size calculation, estimation of expected precision for the estimates of totals, and calculation of optimal sample size allocation.",2020-05-20,Juris Breidaks,https://csblatvia.github.io/surveyplanning/,TRUE,https://github.com/csblatvia/surveyplanning,21270,5,2020-05-20T10:50:25Z,4254
surveysd,Calculate point estimates and their standard errors in complex household surveys using bootstrap replicates. Bootstrapping considers survey design with a rotating panel. A comprehensive description of the methodology can be found under <https://statistikat.github.io/surveysd/articles/methodology.html>.,2020-02-05,Johannes Gussenbauer,https://github.com/statistikat/surveysd,TRUE,https://github.com/statistikat/surveysd,5681,4,2020-06-05T12:43:28Z,1420.25
survHE,"Contains a suite of functions for survival analysis in health economics. These can be used to run survival models under a frequentist (based on maximum likelihood) or a Bayesian approach (both based on Integrated Nested Laplace Approximation or Hamiltonian Monte Carlo). The user can specify a set of parametric models using a common notation and select the preferred mode of inference. The results can also be post-processed to produce probabilistic sensitivity analysis and can be used to export the output to an Excel file (e.g. for a Markov model, as often done by modellers and practitioners).",2018-11-09,Gianluca Baio,"https://github.com/giabaio/survHE,
http://www.statistica.it/gianluca",TRUE,https://github.com/giabaio/survhe,10845,21,2019-11-29T11:43:34Z,516.4285714285714
survival,"Contains the core survival analysis routines, including
	     definition of Surv objects, 
	     Kaplan-Meier and Aalen-Johansen (multi-state) curves, Cox models,
	     and parametric accelerated failure time models.",2020-04-10,Terry M Therneau,https://github.com/therneau/survival,TRUE,https://github.com/therneau/survival,5161656,143,2020-06-04T22:19:44Z,36095.496503496506
survminer,"Contains the function 'ggsurvplot()' for drawing easily beautiful
    and 'ready-to-publish' survival curves with the 'number at risk' table
    and 'censoring count plot'. Other functions are also available to plot 
    adjusted curves for `Cox` model and to visually examine 'Cox' model assumptions.",2020-05-28,Alboukadel Kassambara,http://www.sthda.com/english/rpkgs/survminer/,TRUE,https://github.com/kassambara/survminer,460439,275,2020-05-29T06:06:45Z,1674.3236363636363
survMisc,"A collection of functions to help in the analysis of
    right-censored survival data. These extend the methods available in
    package:survival.",2018-07-05,Chris Dardis,NA,TRUE,https://github.com/dardisco/survmisc,325078,2,2019-12-01T20:52:44Z,162539
survParamSim,"Perform survival simulation with parametric survival model generated from 'survreg' function in 'survival' package.
    In each simulation coefficients are resampled from variance-covariance matrix of parameter estimates to 
    capture uncertainty in model parameters.
    Prediction intervals of Kaplan-Meier estimates and hazard ratio of treatment effect can be further calculated using simulated survival data.",2020-05-12,Kenta Yoshida,https://github.com/yoshidk6/survParamSim,TRUE,https://github.com/yoshidk6/survparamsim,2318,1,2020-05-15T16:01:39Z,2318
survPen,"Fits hazard and excess hazard models with multidimensional penalized splines allowing for 
        time-dependent effects, non-linear effects and interactions between several continuous covariates. In survival and net survival analysis, in addition to modelling the effect of time (via the baseline hazard), one has often to deal with several continuous covariates and model their functional forms, their time-dependent effects, and their interactions. Model specification becomes therefore a complex problem and penalized regression splines represent an appealing solution to that problem as splines offer the required flexibility while penalization limits overfitting issues. Current implementations of penalized survival models can be slow or unstable and sometimes lack some key features like taking into account expected mortality to provide net survival and excess hazard estimates. In contrast, survPen provides an automated, fast, and stable implementation (thanks to explicit calculation of the derivatives of the likelihood) and offers a unified framework for 
        multidimensional penalized hazard and excess hazard models. survPen may be of interest to those who 1) analyse any kind of time-to-event data: mortality, disease relapse, machinery breakdown, unemployment, etc 2) wish to describe the associated hazard and to understand which predictors impact its dynamics. 
	See Fauvernier et al. (2019a) <doi:10.21105/joss.01434> for an overview of the package and Fauvernier et al. (2019b) <doi:10.1111/rssc.12368> for the method.",2020-05-25,Mathieu Fauvernier,https://github.com/fauvernierma/survPen,TRUE,https://github.com/fauvernierma/survpen,5451,1,2020-05-25T09:03:12Z,5451
survSens,"Performs a dual-parameter sensitivity analysis of treatment effect to unmeasured confounding in observational studies with either survival or competing risks outcomes. Huang, R., Xu, R. and Dulai, P.S.(2019) <arXiv:1908.01444>.",2020-04-29,Rong Huang,https://github.com/Rong0707/survSens,TRUE,https://github.com/rong0707/survsens,644,1,2020-04-23T20:22:09Z,644
survtmle,"Targeted estimates of marginal cumulative incidence in survival
    settings with and without competing risks, including estimators that respect
    bounds (Benkeser, Carone, and Gilbert. Statistics in Medicine, 2017.
    <doi:10.1002/sim.7337>).",2019-04-16,David Benkeser,https://github.com/benkeser/survtmle,TRUE,https://github.com/benkeser/survtmle,8588,14,2020-06-07T04:36:12Z,613.4285714285714
survxai,"Survival models may have very different structures. This package contains functions 
  for creating a unified representation of a survival models, which can be further processed by various 
  survival explainers. Tools implemented in 'survxai' help to understand how input variables are used in 
  the model and what impact do they have on the final model prediction. Currently, four explanation methods are implemented. 
  We can divide them into two groups: local and global.",2018-08-24,Aleksandra Grudziaz,https://mi2datalab.github.io/survxai/,TRUE,https://github.com/mi2datalab/survxai,6112,8,2019-07-02T07:22:28Z,764
svd,"R bindings to SVD and eigensolvers (PROPACK, nuTRLan).",2019-08-19,Anton Korobeynikov,http://github.com/asl/svd,TRUE,https://github.com/asl/svd,176871,21,2019-08-09T22:41:06Z,8422.42857142857
svDialogs,"Rapidly construct standard dialog boxes for your GUI, including 
  message boxes, input boxes, list, file or directory selection, ... In case R
  cannot display GUI dialog boxes, a simpler command line version of these
  interactive elements is also provided as fallback solution.",2018-04-26,Philippe Grosjean,"https://github.com/SciViews/svDialogs,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/svdialogs,74390,2,2020-05-04T10:21:49Z,37195
svglite,"A graphics device for R that produces 'Scalable Vector Graphics'.
  'svglite' is a fork of the older 'RSvgDevice' package.",2020-02-07,Thomas Lin Pedersen,https://github.com/r-lib/svglite,TRUE,https://github.com/r-lib/svglite,1129899,134,2020-06-09T15:14:18Z,8432.08208955224
svgPanZoom,"This 'htmlwidget' provides pan and zoom interactivity to R
    graphics, including 'base', 'lattice', and 'ggplot2'. The interactivity is
    provided through the 'svg-pan-zoom.js' library. Various options to the widget
    can tailor the pan and zoom experience to nearly any user desire.",2020-02-15,Anders Riutta et. al.,https://github.com/timelyportfolio/svgPanZoom,TRUE,https://github.com/timelyportfolio/svgpanzoom,28631,40,2020-02-15T14:12:49Z,715.775
svGUI,"The SciViews svGUI package eases the management of Graphical User
  Interfaces (GUI) in R. It is independent from any particular GUI widgets (Tk,
  Gtk2, native, ...). It centralizes info about GUI elements currently used,
  and it dispatches GUI calls to the particular toolkits in use in function of
  the context (is R run at the terminal, within a Tk application, a HTML page?).",2018-04-23,Philippe Grosjean,"https://github.com/SciViews/svGUI,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/svgui,73685,0,2020-05-04T10:28:35Z,NA
svMisc,"Miscellaneous functions for SciViews or general use: manage a
  temporary environment attached to the search path for temporary variables you
  do not want to save() or load(), test if Aqua, Mac, Win, ... Show progress
  bar, etc.",2018-06-30,Philippe Grosjean,"https://github.com/SciViews/svMisc,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/svmisc,65713,0,2020-05-02T13:39:19Z,NA
svSocket,Implements a socket server allowing to connect clients to R.,2020-05-10,Philippe Grosjean,https://github.com/SciViews/svSocket,TRUE,https://github.com/sciviews/svsocket,22610,1,2020-05-10T15:45:23Z,22610
svUnit,A complete unit test system and functions to implement its GUI part.,2020-04-20,Philippe Grosjean,"https://github.com/SciViews/svUnit,
https://www.sciviews.org/svUnit/",TRUE,https://github.com/sciviews/svunit,229971,1,2020-05-02T12:27:44Z,229971
sweep,"
    Tidies up the forecasting modeling and prediction work flow, 
    extends the 'broom' package 
    with 'sw_tidy', 'sw_glance', 'sw_augment', and 'sw_tidy_decomp' functions 
    for various forecasting models,
    and enables converting 'forecast' objects to 
    ""tidy"" data frames with 'sw_sweep'.",2019-10-08,Matt Dancho,https://github.com/business-science/sweep,TRUE,https://github.com/business-science/sweep,78321,130,2020-06-09T11:27:14Z,602.4692307692308
sweidnumbr,"Structural handling of identity numbers used in the Swedish
    administration such as personal identity numbers ('personnummer') and
    organizational identity numbers ('organisationsnummer').",2020-03-29,Mans Magnusson and Erik Bulow,https://github.com/rOpenGov/sweidnumbr/,TRUE,https://github.com/ropengov/sweidnumbr,17228,6,2020-03-29T15:23:54Z,2871.3333333333335
swephR,"The Swiss Ephemeris (version 2.08) is a high precision ephemeris based upon the
    DE431 ephemerides from NASA's JPL. It covers the time range 13201 BCE to
    17191 CE. This package uses the semi-analytic theory by Steve Moshier.
    For faster and more accurate calculations, the compressed Swiss Ephemeris
    data is available in the 'swephRdata' package. To access this data package,
    run 'install.packages(""swephRdata"", repos = ""https://rstub.github.io/drat/"",
    type = ""source"")'. The size of the 'swephRdata' package is approximately
    115 MB. The user can also use the original JPL DE431 data.",2019-08-28,Ralf Stubner,"https://github.com/rstub/swephR/, https://rstub.github.io/swephR/,
http://www.astro.com/swisseph/",TRUE,https://github.com/rstub/swephr,5555,3,2020-06-07T06:39:20Z,1851.6666666666667
swfscMisc,"Collection of conversion, analytical, geodesic, mapping, and
    plotting functions. Used to support packages and code written by
    researchers at the Southwest Fisheries Science Center of the National
    Oceanic and Atmospheric Administration.",2020-02-20,Eric Archer,https://github.com/EricArcher/swfscMisc,TRUE,https://github.com/ericarcher/swfscmisc,31833,0,2020-04-23T03:41:05Z,NA
SWIM,"An efficient sensitivity analysis for stochastic models based on 
    Monte Carlo samples. Provides weights on simulated scenarios from a 
    stochastic model, such that stressed random variables fulfil given 
    probabilistic constraints (e.g. specified values for risk measures), 
    under the new scenario weights. Scenario weights are selected by 
    constrained minimisation of the relative entropy to the baseline model. 
    The 'SWIM' package is based on Pesenti S.M, Millossovich P., Tsanakas A. 
    (2019) ""Reverse Sensitivity Testing: What does it take to break the model"", 
    <openaccess.city.ac.uk/id/eprint/18896/>.",2020-05-22,Silvana M. Pesenti,"https://github.com/spesenti/SWIM,
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3515274,
https://utstat.toronto.edu/pesenti/?page_id=138",TRUE,https://github.com/spesenti/swim,3898,0,2020-05-22T16:37:57Z,NA
swissdd,"Builds upon the real time data service as well as the archive for national votes <https://opendata.swiss/api/3/action/package_show?id=echtzeitdaten-am-abstimmungstag-zu-eidgenoessischen-abstimmungsvorlagen> and cantonal votes <https://opendata.swiss/api/3/action/package_show?id=echtzeitdaten-am-abstimmungstag-zu-kantonalen-abstimmungsvorlagen>. It brings the results of Swiss popular votes, aggregated at the geographical level of choice, into R. Additionally, it allows to retrieve data from the Swissvotes-Database, one of the most comprehensive data platforms on Swiss referendums and initiatives <https://swissvotes.ch/page/dataset/swissvotes_dataset.csv>. ",2020-05-15,Thomas Lo Russo,https://github.com/politanch/swissdd,TRUE,https://github.com/politanch/swissdd,3626,10,2020-05-15T21:34:25Z,362.6
swissparl,"Retrieves the most important data on parliamentary activities of the Swiss Federal Assembly via 
    an open, machine-readable interface (see <https://ws.parlament.ch/odata.svc/>). ",2020-04-14,David Zumbach,https://www.parlament.ch/en/services/open-data-webservices,TRUE,https://github.com/zumbov2/swissparl,2721,11,2020-04-09T21:05:01Z,247.36363636363637
switchcase,"Provides a switch-case construct for 'R', as it is known from other programming languages. It allows to test multiple, similar conditions in an efficient, easy-to-read manner, so nested if-else constructs can be avoided. The switch-case construct is designed as an 'R' function that allows to return values depending on which condition is met and lets the programmer flexibly decide whether or not to leave the switch-case construct after a case block has been executed.",2020-05-17,Joachim Zuckarelli,https://github.com/jsugarelli/switchcase/,TRUE,https://github.com/jsugarelli/switchcase,710,2,2020-05-17T16:53:30Z,355
switchr,"Provides an abstraction for managing, installing,
    and switching between sets of installed R packages. This allows users to
    maintain multiple package libraries simultaneously, e.g. to maintain
    strict, package-version-specific reproducibility of many analyses, or
    work within a development/production release paradigm. Introduces a
    generalized package installation process which supports multiple repository
    and non-repository sources and tracks package provenance.",2020-04-20,Gabriel Becker,https://github.com/gmbecker/switchr,TRUE,https://github.com/gmbecker/switchr,30127,43,2020-01-25T21:07:19Z,700.6279069767442
swmmr,"Functions to connect the widely used Storm Water Management Model (SWMM)
  of the United States Environmental Protection Agency (US EPA) 
  <https://www.epa.gov/water-research/storm-water-management-model-swmm> to R with
  currently two main goals: (1) Run a SWMM simulation from R and (2) provide fast 
  access to simulation results, i.e. SWMM's binary '.out'-files. High performance is achieved
  with help of Rcpp. Additionally, reading SWMM's '.inp' and '.rpt' files is supported to 
  glance model structures and to get direct access to simulation summaries.",2020-03-02,Dominik Leutnant,https://github.com/dleutnant/swmmr,TRUE,https://github.com/dleutnant/swmmr,15271,21,2020-05-18T20:33:20Z,727.1904761904761
SWMPr,"Tools for retrieving, organizing, and analyzing environmental
    data from the System Wide Monitoring Program of the National Estuarine
    Research Reserve System <http://cdmo.baruch.sc.edu/>. These tools
    address common challenges associated with continuous time series data
    for environmental decision making.",2019-05-30,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/swmpr,17650,9,2020-05-06T18:14:32Z,1961.111111111111
SWMPrExtension,"Tools for performing routine analysis and plotting tasks with environmental
    data from the System Wide Monitoring Program of the National Estuarine
    Research Reserve System <http://cdmo.baruch.sc.edu/>. This package builds
    on the functionality of the SWMPr package <https://cran.r-project.org/package=SWMPr>,
    which is used to retrieve and organize the data. The combined set of tools
    address common challenges associated with continuous time series data
    for environmental decision making, and are intended for use in annual reporting activities.
    References:
    Beck, Marcus W. (2016) <ISSN 2073-4859><https://journal.r-project.org/archive/2016-1/beck.pdf>
    Rudis, Bob (2014) <https://rud.is/b/2014/11/16/moving-the-earth-well-alaska-hawaii-with-r/>.
    United States Environmental Protection Agency (2015) <https://cfpub.epa.gov/si/si_public_record_Report.cfm?dirEntryId=327030>.
    United States Environmental Protection Agency (2012) <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.1973&rep=rep1&type=pdf>.",2020-05-30,Dave Eslinger,NA,TRUE,https://github.com/noaa-ocm/swmprextension,8024,4,2020-05-29T23:26:46Z,2006
sylcount,"An English language syllable counter, plus readability score
    measure-er. For readability, we support 'Flesch' Reading Ease and
    'Flesch-Kincaid' Grade Level ('Kincaid' 'et al'. 1975)
    <https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=1055&context=istlibrary>,
    Automated Readability Index ('Senter' and Smith 1967)
    <http://www.dtic.mil/cgi-bin/GetTRDoc?AD=AD0667273>,
    Simple Measure of Gobbledygook (McLaughlin 1969)
    <https://www.semanticscholar.org/paper/SMOG-Grading-A-New-Readability-Formula.-Laughlin/5fccb74c14769762b3de010c5e8a1a7ce700d17a>,
    and 'Coleman-Liau' (Coleman and 'Liau' 1975) <doi:10.1037/h0076540>. The
    package has been carefully optimized and should be very efficient, both in
    terms of run time performance and memory consumption. The main methods are
    'vectorized' by document, and scores for multiple documents are computed in
    parallel via 'OpenMP'.",2020-02-23,Drew Schmidt,https://github.com/wrathematics/sylcount,TRUE,https://github.com/wrathematics/sylcount,10377,6,2020-02-11T01:57:56Z,1729.5
symDMatrix,"A matrix-like class to represent a symmetric matrix partitioned
    into file-backed blocks.",2020-05-28,Alexander Grueneberg,https://github.com/QuantGen/symDMatrix,TRUE,https://github.com/quantgen/symdmatrix,10745,2,2020-05-22T21:25:42Z,5372.5
symengine,"
    Provides an R interface to 'SymEngine' <https://github.com/symengine/>,
    a standalone 'C++' library for fast symbolic manipulation. The package has functionalities
    for symbolic computation like calculating exact mathematical expressions, solving
    systems of linear equations and code generation.",2020-05-07,Jialin Ma,https://github.com/symengine/symengine.R,TRUE,https://github.com/symengine/symengine.r,1070,13,2020-05-20T06:39:48Z,82.3076923076923
syn,"Generates synonyms from a given word drawing from a synonym list
    from the 'moby' project <http://moby-thesaurus.org/>.",2019-12-20,Nicholas Tierney,"http://syn.njtierney.com/, https://github.com/ropenscilabs/syn",TRUE,https://github.com/ropenscilabs/syn,2314,42,2020-01-02T05:57:51Z,55.095238095238095
synchrony,"Methods for computing spatial, temporal, and spatiotemporal
    statistics as described in Gouhier and Guichard (2014) 
    <doi:10.1111/2041-210X.12188>. These methods include 
    empirical univariate, bivariate and multivariate
    variograms; fitting variogram models; phase locking and synchrony analysis;
    generating autocorrelated and cross-correlated matrices.",2019-12-05,Tarik C. Gouhier,http://github.com/tgouhier/synchrony,TRUE,https://github.com/tgouhier/synchrony,24304,5,2019-12-05T15:03:32Z,4860.8
synoptReg,Set of functions to compute different types of synoptic classification methods and for analysing their effect on environmental variables. More information about the methods used in Lemus-Canovas et al. 2019 <DOI:10.1016/j.atmosres.2019.01.018> and Martin-Vide et al. 2008 <DOI:10.5194/asr-2-99-2008>.,2020-03-23,Marc Lemus-Canovas,<https://lemuscanovas.github.io/synoptreg/ >,TRUE,https://github.com/lemuscanovas/synoptreg,7063,1,2020-03-23T15:05:07Z,7063
syntaxr,A set of functions for generating 'SPSS' syntax files from the R environment.,2019-04-06,Alix Lahuec,https://github.com/greenmeen/syntaxr,TRUE,https://github.com/greenmeen/syntaxr,4225,1,2020-01-14T05:30:03Z,4225
sys,"Drop-in replacements for the base system2() function with fine control
    and consistent behavior across platforms. Supports clean interruption, timeout, 
    background tasks, and streaming STDIN / STDOUT / STDERR over binary or text 
    connections. Arguments on Windows automatically get encoded and quoted to work 
    on different locales.",2019-08-21,Jeroen Ooms,https://github.com/jeroen/sys,TRUE,https://github.com/jeroen/sys,7223954,73,2019-10-28T10:58:51Z,98958.27397260274
sysfonts,"Loading system fonts and Google Fonts
    <https://fonts.google.com/> into R, in order to
    support other packages such as 'R2SWF' and 'showtext'.",2020-05-08,"Yixuan Qiu and authors/contributors of the
    included fonts. See file AUTHORS for details.",https://github.com/yixuan/sysfonts,TRUE,https://github.com/yixuan/sysfonts,223575,15,2020-05-08T14:49:59Z,14905
syslognet,"Send 'syslog' protocol messages to a remote 'syslog' server
    specified by host name and TCP network port.",2020-01-08,Panagiotis Cheilaris,https://github.com/philaris/syslognet,TRUE,https://github.com/philaris/syslognet,3052,0,2019-12-18T11:10:49Z,NA
systemfonts,"Provides system native access to the font catalogue. As font
    handling varies between systems it is difficult to correctly locate 
    installed fonts across different operating systems. The 'systemfonts' 
    package provides bindings to the native libraries on Windows, macOS and 
    Linux for finding font files that can then be used further by e.g. graphic
    devices. The main use is intended to be from compiled code but 'systemfonts'
    also provides access from R.",2020-06-09,Thomas Lin Pedersen,https://github.com/r-lib/systemfonts,TRUE,https://github.com/r-lib/systemfonts,1342855,42,2020-06-09T08:56:40Z,31972.738095238095
table.express,"A specialization of 'dplyr' data manipulation verbs that parse and build expressions
    which are ultimately evaluated by 'data.table', letting it handle all optimizations. A set of
    additional verbs is also provided to facilitate some common operations on a subset of the data.",2019-09-07,Alexis Sarda-Espinosa,"https://asardaes.github.io/table.express,
https://github.com/asardaes/table.express",TRUE,https://github.com/asardaes/table.express,4854,58,2019-09-15T20:39:14Z,83.6896551724138
table1,"Create HTML tables of descriptive statistics, as one would expect
    to see as the first table (i.e. ""Table 1"") in a medical/epidemiological journal
    article.",2020-03-23,Benjamin Rich,https://github.com/benjaminrich/table1,TRUE,https://github.com/benjaminrich/table1,36676,24,2020-03-22T20:43:06Z,1528.1666666666667
tableone,"Creates 'Table 1', i.e., description of baseline patient
    characteristics, which is essential in every medical research.
    Supports both continuous and categorical variables, as well as
    p-values and standardized mean differences. Weighted data are
    supported via the 'survey' package. See 'github' for a screen cast.
    'tableone' was inspired by descriptive statistics functions in
    'Deducer' , a Java-based GUI package by Ian Fellows. This package
    does not require GUI or Java, and intended for command-line users.",2020-03-08,Kazuki Yoshida,https://github.com/kaz-yos/tableone,TRUE,https://github.com/kaz-yos/tableone,163547,125,2020-05-14T08:19:48Z,1308.376
tablerDash,"'R' interface to the 'Tabler' HTML template. See more here <https://tabler.io>. 
    'tablerDash' is a light 'Bootstrap 4' dashboard template. There are different 
     layouts available such as a one page dashboard or a multi page template,
     where the navigation menu is contained in the navigation bar. A fancy example
     is available at <https://dgranjon.shinyapps.io/shinyMons/>.",2019-03-08,David Granjon,"https://rinterface.github.io/tablerDash/,
https://github.com/RinteRface/tablerDash/",TRUE,https://github.com/rinterface/tablerdash,23996,44,2019-10-14T06:40:38Z,545.3636363636364
tableschema.r,"Allows to work with 'Table Schema' (<http://specs.frictionlessdata.io/table-schema/>). 'Table Schema' is well suited for use cases around handling and validating tabular data in text formats such as 'csv', but its utility extends well beyond this core usage, towards a range of applications where data benefits from a portable schema format. The 'tableschema.r' package can load and validate any table schema descriptor, allow the creation and modification of descriptors, expose methods for reading and streaming data that conforms to a 'Table Schema' via the 'Tabular Data Resource' abstraction.",2020-03-12,Kleanthis Koupidis,https://github.com/frictionlessdata/tableschema-r,TRUE,https://github.com/frictionlessdata/tableschema-r,6357,13,2020-05-06T19:35:35Z,489
tabr,"Provides a music notation syntax and a collection of music programming functions for generating, manipulating, organizing and analyzing musical information in R. 
    The music notation framework facilitates creating and analyzing music data in notation form.
    Music data can be viewed, manipulated and analyzed while in different forms of representation based around different data structures: strings and data frames.
    Each representation offers advantages over the other for different use cases.
    Music syntax can be entered directly and represented in character strings to minimize the formatting overhead of data entry by using simple data structures, for example when wanting to quickly enter and transcribe short pieces of music to sheet music or tablature.
    The package contains functions for directly performing various mathematical, logical and organizational operations and musical transformations on special object classes that facilitate working with music data and notation.
    The same music data can also be organized in tidy data frames, allowing for a more familiar and powerful approach to the analysis of large amounts of structured music data.
    Functions are available for mapping seamlessly between these data structures and their representations of musical information.
    The package also provides API wrapper functions for transcribing musical representations in R into guitar tablature (""tabs"") and basic sheet music using the 'LilyPond' backend (<http://lilypond.org>).
    'LilyPond' is open source music engraving software for generating high quality sheet music based on markup syntax. 
    The package generates 'LilyPond' files from R code and can pass them to 'LilyPond' to be rendered into sheet music pdf files.
    The package offers nominal MIDI file output support in conjunction with rendering sheet music. 
    The package can read MIDI files and attempts to structure the MIDI data to integrate as best as possible with the data structures and functionality found throughout the package.",2020-05-05,Matthew Leonawicz,https://github.com/leonawicz/tabr,TRUE,https://github.com/leonawicz/tabr,8501,65,2020-05-05T00:34:12Z,130.7846153846154
tabshiftr,"Helps the user to build and register schema descriptions of 
    disorganised (messy) tables. Disorganised tables are tables that are 
    not in a topologically coherent form, where packages such as 'tidyr' could 
    be used for reshaping. The schema description documents the arrangement of 
    input tables and is used to reshape them into a standardised (tidy) output 
    format.",2020-05-13,Steffen Ehrmann,https://github.com/EhrmannS/tabshiftr,TRUE,https://github.com/ehrmanns/tabshiftr,394,1,2020-05-19T18:10:03Z,394
tabula,"An easy way to examine archaeological count data. This package 
    provides a convenient and reproducible toolkit for relative and absolute 
    dating and analysis of (chronological) patterns. It includes functions for 
    matrix seriation (reciprocal ranking, CA-based seriation), chronological 
    modeling and dating of archaeological assemblages and/or objects. 
    Beyond these, the package provides several tests and measures of diversity: 
    heterogeneity and evenness (Brillouin, Shannon, Simpson, etc.), 
    richness and rarefaction (Chao1, Chao2, ACE, ICE, etc.), 
    turnover and similarity (Brainerd-Robinson, etc.). 
    The package make it easy to visualize count data and statistical thresholds: 
    rank vs. abundance plots, heatmaps, Ford (1962) and Bertin (1977) diagrams.",2020-03-19,Nicolas Frerebeau,"http://tabula.archaeo.science,
http://github.com/nfrerebeau/tabula,
https://cran.r-project.org/package=tabula",TRUE,https://github.com/nfrerebeau/tabula,7232,10,2020-05-23T11:39:15Z,723.2
tabularaster,"Facilities to work with vector and raster data in efficient 
 repeatable and systematic work flow. Missing functionality in existing packages 
 is included here to allow extraction from raster data with 'simple features' and 
 'Spatial' types and to make extraction consistent and straightforward. Extract cell 
 numbers from raster data and  return the cells as a data frame 
 rather than as lists of matrices or vectors. The functions here allow spatial data 
 to be used without special handling for the format currently in use. ",2020-04-10,Michael D. Sumner,https://github.com/hypertidy/tabularaster,TRUE,https://github.com/hypertidy/tabularaster,12684,41,2020-05-03T22:22:29Z,309.3658536585366
tabulizer,"Bindings for the 'Tabula' <http://tabula.technology/> 'Java'
    library, which can extract tables from PDF documents. The 'tabulizerjars'
    package <https://github.com/ropensci/tabulizerjars> provides versioned
    'Java' .jar files, including all dependencies, aligned to releases of
    'Tabula'.",2018-06-07,Thomas J. Leeper,https://github.com/ropensci/tabulizer,TRUE,https://github.com/ropensci/tabulizer,82343,380,2019-08-26T08:35:33Z,216.69210526315788
tacmagic,"To facilitate the analysis of positron emission tomography (PET) 
    time activity curve (TAC) data, and to encourage open science and 
    replicability, this package supports data loading and analysis of multiple 
    TAC file formats. Functions are available to analyze loaded TAC data for 
    individual participants or in batches. Major functionality includes weighted
    TAC merging by region of interest (ROI), calculating models including 
    standardized uptake value ratio (SUVR) and distribution volume ratio (DVR, 
    Logan et al. 1996 <doi:10.1097/00004647-199609000-00008>), basic plotting 
    functions and calculation of cut-off values (Aizenstein et al. 2008
    <doi:10.1001/archneur.65.11.1509>). Please see the walkthrough vignette for
    a detailed overview of 'tacmagic' functions.",2019-06-07,Eric Brown,https://github.com/ropensci/tacmagic,TRUE,https://github.com/ropensci/tacmagic,4601,2,2020-02-05T20:19:20Z,2300.5
tadaatoolbox,"A teaching project for the display of statistical
    tests as well as some convenience functions for data cleanup. The
    primary components are the functions prefixed with 'tadaa_', which are
    built to work in an interactive environment, but also print markdown
    tables powered by 'pixiedust' for the creation of 'RMarkdown' reports.
    This package is no longer actively developed.",2020-06-01,Lukas Burk,https://github.com/tadaadata/tadaatoolbox,TRUE,https://github.com/tadaadata/tadaatoolbox,16871,4,2020-06-01T16:28:06Z,4217.75
taipan,"A tool to help create shiny apps for selecting and annotating 
    elements of images. Users must supply images, questions, and answer
    choices. The user interface is a dynamic shiny app, that displays the images
    and questions and answer choices. The data generated can be saved to a
    file that can be used for subsequent analysis. The original purpose was to
    annotate still images from tennis video for face recognition and emotion 
    detection purposes.",2018-09-27,Stephanie Kobakian,https://github.com/srkobakian/taipan,TRUE,https://github.com/srkobakian/taipan,6020,31,2019-10-30T03:51:03Z,194.19354838709677
TAM,"
    Includes marginal maximum likelihood estimation and joint maximum
    likelihood estimation for unidimensional and multidimensional 
    item response models. The package functionality covers the 
    Rasch model, 2PL model, 3PL model, generalized partial credit model, 
    multi-faceted Rasch model, nominal item response model, 
    structured latent class model, mixture distribution IRT models, 
    and located latent class models. Latent regression models and 
    plausible value imputation are also supported. For details see
    Adams, Wilson and Wang, 1997 <doi:10.1177/0146621697211001>,
    Adams, Wilson and Wu, 1997 <doi:10.3102/10769986022001047>,
    Formann, 1982 <doi:10.1002/bimj.4710240209>,
    Formann, 1992 <doi:10.1080/01621459.1992.10475229>.",2020-05-06,Alexander Robitzsch,"http://www.edmeasurementsurveys.com/TAM/Tutorials/,
https://github.com/alexanderrobitzsch/TAM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/tam,162790,9,2020-05-06T11:20:20Z,18087.777777777777
tanaka,"The Tanaka method enhances the representation of topography on a map using shaded contour lines. In this simplified implementation of the method, north-west white contours represent illuminated topography and south-east black contours represent shaded topography. See Tanaka (1950) <doi:10.2307/211219>.",2020-04-14,Timothée Giraud,https://github.com/rcarto/tanaka/,TRUE,https://github.com/rcarto/tanaka,5347,49,2020-04-14T11:32:54Z,109.12244897959184
tangram,"Provides an extensible formula system to quickly and easily create
    production quality tables. The steps of the process are formula parser,
    statistical content generation from data, to rendering. Each step of the process
    is separate and user definable thus creating a set of building blocks for
    highly extensible table generation. A user is not limited by any of the 
    choices of the package creator other than the formula grammar. For example,
    one could chose to add a different S3 rendering function and output a format
    not provided in the default package. Or possibly one would rather have Gini
    coefficients for their statistical content. Routines to achieve New England
    Journal of Medicine style, Lancet style and Hmisc::summaryM() statistics are
    provided. The package contains rendering for HTML5, Rmarkdown and an indexing
    format for use in tracing and tracking are provided.",2020-04-29,Shawn Garbett,https://github.com/spgarbet/tangram,TRUE,https://github.com/spgarbet/tangram,10659,50,2020-05-29T18:42:52Z,213.18
targeted,"Various methods for targeted and semiparametric inference including
	     augmented inverse probability weighted estimators for missing data and
	     causal inference (Bang and Robins (2005) <doi:10.1111/j.1541-0420.2005.00377.x>)
	     and estimators for risk differences and relative risks (Richardson et al. (2017)
	     <doi:10.1080/01621459.2016.1192546>).",2020-05-15,Klaus K. Holst,https://kkholst.github.io/targeted/,TRUE,https://github.com/kkholst/targeted,508,1,2020-05-24T11:18:14Z,508
TargomoR,"Functions to provide an intuitive interface for retrieving travel time data from the
    'Targomo' API (see <https://targomo.com/developers/> for details). Provides support for retrieving
    isochrone polygons, travel routes, times and distances. Also includes functions for easily adding
    the data to 'leaflet' maps, and functions for using the 'Targomo' map tiles.",2019-12-06,Chris Mason-Thom,https://cwthom.github.io/TargomoR,TRUE,https://github.com/cwthom/targomor,2425,6,2019-12-18T10:55:34Z,404.1666666666667
tauturri,"'Tautulli' (<http://tautulli.com>) is a monitoring application for 'Plex' Media Servers 
  (<https://www.plex.tv>) which collects a lot of data about media items and server 
  usage such as play counts. This package interacts with the 'Tautulli' API of any 
  specified server to get said data into R. The 'Tautulli' API documentation is available
  at <https://github.com/Tautulli/Tautulli/blob/master/API.md>.",2018-07-11,Lukas Burk,https://github.com/jemus42/tauturri,TRUE,https://github.com/jemus42/tauturri,6644,1,2020-03-04T00:31:41Z,6644
taxa,"Provides taxonomic classes for
    groupings of taxonomic names without data, and those
    with data. Methods provided are ""taxonomically aware"", in
    that they know about ordering of ranks, and methods that
    filter based on taxonomy also filter associated data. 
    This package is described in the publication: ""Taxa: An R 
    package implementing data standards and methods for 
    taxonomic data"", Zachary S.L. Foster, Scott Chamberlain,  
    Niklaus J. Grünwald (2018) <doi:10.12688/f1000research.14013.2>.",2020-04-29,Scott Chamberlain,"https://docs.ropensci.org/taxa, https://github.com/ropensci/taxa",TRUE,https://github.com/ropensci/taxa,21785,37,2020-04-29T18:46:37Z,588.7837837837837
taxadb,"Creates a local database of many commonly used taxonomic authorities
             and provides functions that can quickly query this data.",2020-02-19,Carl Boettiger,"https://docs.ropensci.org/taxadb,
https://github.com/ropensci/taxadb",TRUE,https://github.com/ropensci/taxadb,2562,20,2020-02-20T19:11:39Z,128.1
taxize,"Interacts with a suite of web 'APIs' for taxonomic tasks,
    such as getting database specific taxonomic identifiers, verifying
    species names, getting taxonomic hierarchies, fetching downstream and
    upstream taxonomic names, getting taxonomic synonyms, converting
    scientific to common names and vice versa, and more.",2020-06-09,Scott Chamberlain,"https://docs.ropensci.org/taxize (website),
https://github.com/ropensci/taxize (devel), https://taxize.dev
(user manual)",TRUE,https://github.com/ropensci/taxize,167823,192,2020-06-09T15:27:20Z,874.078125
taxizedb,"Tools for working with 'taxonomic' databases, including
    utilities for downloading databases, loading them into various
    'SQL' databases, cleaning up files, and providing a 'SQL' connection
    that can be used to do 'SQL' queries directly or used in 'dplyr'.",2017-06-20,Scott Chamberlain,https://github.com/ropensci/taxizedb,TRUE,https://github.com/ropensci/taxizedb,9608,15,2020-03-17T17:32:57Z,640.5333333333333
taxlist,"Handling taxonomic lists through objects of class 'taxlist'.
    This package provides functions to import species lists from 'Turboveg'
    (<https://www.synbiosys.alterra.nl/turboveg>) and the possibility to create
    backups from resulting R-objects.
    Also quick displays are implemented as summary-methods.",2020-05-31,Miguel Alvarez,"https://cran.r-project.org/package=taxlist,
https://github.com/kamapu/taxlist",TRUE,https://github.com/kamapu/taxlist,11299,4,2020-06-01T13:35:25Z,2824.75
taxotools,Some tools to work with taxonomic name lists. ,2020-03-08,Vijay Barve,NA,TRUE,https://github.com/vijaybarve/taxotools,8277,3,2020-03-19T21:37:19Z,2759
tbl2xts,"Facilitate the movement between data frames to 'xts'. Particularly
    useful when moving from 'tidyverse' to the widely used 'xts' package, which is
    the input format of choice to various other packages. It also allows the user 
    to use a 'spread_by' argument for a character column 'xts' conversion.",2019-08-01,Nico Katzke,http://tbl2xts.nfkatzke.com,TRUE,https://github.com/nicktz/tbl2xts,13114,1,2019-08-01T12:52:18Z,13114
tbrf,"Provides rolling statistical functions based
    on date and time windows instead of n-lagged observations.",2020-04-09,Michael Schramm,https://mps9506.github.io/tbrf/,TRUE,https://github.com/mps9506/tbrf,9569,3,2020-05-18T19:34:04Z,3189.6666666666665
TCA,"Tensor Composition Analysis (TCA) allows the deconvolution of two-dimensional data (features by observations) coming from a mixture of sources into a three-dimensional matrix of signals (features by observations by sources). TCA further allows to test the features in the data for different statistical relations with an outcome of interest while modeling source-specific effects (TCA regression); particularly, it allows to look for statistical relations between source-specific signals and an outcome. For example, TCA can deconvolve bulk tissue-level DNA methylation data (methylation sites by individuals) into a tensor of cell-type-specific methylation levels for each individual (methylation sites by individuals by cell types) and it allows to detect cell-type-specific relations (associations) with an outcome of interest. For more details see Rahmani et al. (2018) <DOI:10.1101/437368>.",2019-11-16,Elior Rahmani,https://www.nature.com/articles/s41467-019-11052-9,TRUE,https://github.com/cozygene/tca,4123,8,2020-03-27T18:57:54Z,515.375
tcensReg,"Maximum likelihood estimation (MLE) of parameters assuming an underlying left truncated normal distribution with left censoring described in Williams, J, Kim, H, and Crespi, C. (2019) <arXiv:1911.11221>. Censoring is assumed to occur above the truncation threshold meaning that only censored observations are observed. Additional maximum likelihood estimation procedures are implemented to solve left censored only and left truncated only problems.",2020-03-27,Justin Williams,https://github.com/williazo/tcensReg,TRUE,https://github.com/williazo/tcensreg,2754,0,2020-03-27T22:28:31Z,NA
TcGSA,"Implementation of Time-course Gene Set Analysis (TcGSA), a method for 
	analyzing longitudinal gene-expression data at the gene set level. Method is
	detailed in: Hejblum, Skinner & Thiebaut (2015) <doi: 10.1371/journal.pcbi.1004310>.",2020-01-23,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/tcgsa,16237,3,2020-02-06T11:06:53Z,5412.333333333333
tcgsaseq,"Analyze RNA-seq data with variance component score test accounting 
    for data heteroscedasticity through precision weights. Perform both gene-wise and gene set
    analyses, and can deal with longitudinal data. Method is detailed in: Agniel D & Hejblum BP (2017) 
    Variance component score test for time-course gene set analysis of longitudinal RNA-seq data, 
    Biostatistics, 18(4):589-604.",2018-12-07,Boris P. Hejblum,NA,TRUE,https://github.com/denisagniel/tcgsaseq,13119,2,2019-12-11T11:31:43Z,6559.5
tcpl,"A set of tools for processing and modeling high-throughput and
    high-content chemical screening data. The package was developed for the
    the chemical screening data generated by the US EPA ToxCast program, but
    can be used for diverse chemical screening efforts.",2019-07-26,Richard S Judson,https://github.com/USEPA/CompTox-ToxCast-tcpl,TRUE,https://github.com/usepa/comptox-toxcast-tcpl,14014,4,2020-03-10T15:10:55Z,3503.5
tcR,"Platform for the advanced analysis of T cell receptor and
    Immunoglobulin repertoires data and visualisation of the analysis results.
    Publication: Nazarov et al. (2015) <doi:10.1186/s12859-015-0613-1>.",2020-06-09,Vadim Nazarov,"https://immunarch.com/, http://imminfo.github.io/tcr/",TRUE,https://github.com/immunomind/immunarch,27015,53,2020-05-13T10:03:22Z,509.7169811320755
TDAstats,"A comprehensive toolset for any
    useR conducting topological data analysis, specifically via the
    calculation of persistent homology in a Vietoris-Rips complex.
    The tools this package currently provides can be conveniently split
    into three main sections: (1) calculating persistent homology; (2)
    conducting statistical inference on persistent homology calculations;
    (3) visualizing persistent homology and statistical inference.
    The published form of TDAstats can be found in Wadhwa et al. (2018)
    <doi:10.21105/joss.00860>.   
    For a general background on computing persistent homology for
    topological data analysis, see Otter et al. (2017)
    <doi:10.1140/epjds/s13688-017-0109-5>.
    To learn more about how the permutation test is used for
    nonparametric statistical inference in topological data analysis,
    read Robinson & Turner (2017) <doi:10.1007/s41468-017-0008-7>.
    To learn more about how TDAstats calculates persistent homology,
    you can visit the GitHub repository for Ripser, the software that
    works behind the scenes at <https://github.com/Ripser/ripser>.
    This package has been published as Wadhwa et al. (2018)
    <doi:10.21105/joss.00860>.",2019-12-12,Raoul Wadhwa,https://github.com/rrrlw/TDAstats,TRUE,https://github.com/rrrlw/tdastats,9242,22,2020-05-12T16:36:27Z,420.09090909090907
tdthap,"Functions and examples are provided for Transmission/disequilibrium tests
             for extended marker haplotypes, as in
             Clayton, D. and Jones, H. (1999) ""Transmission/disequilibrium tests
             for extended marker haplotypes"". Amer. J. Hum. Genet., 65:1161-1169,
             <doi:10.1086/302566>.",2019-08-22,David Clayton,https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,19450,5,2020-04-28T11:28:17Z,3890
teachingApps,"Contains apps and gadgets for teaching data analysis and 
    statistics concepts along with how to implement them in R.  Includes 
    tools to make app development easier and faster by nesting apps together.",2020-05-13,Jason Freels,https://github.com/Auburngrads/teachingApps,TRUE,https://github.com/auburngrads/teachingapps,10220,9,2019-08-01T18:42:33Z,1135.5555555555557
teamcolors,"Provides color palettes corresponding to professional and amateur, 
    sports teams. These can be useful in creating data graphics that are themed 
    for particular teams. ",2020-01-22,Benjamin S. Baumer,http://github.com/beanumber/teamcolors,TRUE,https://github.com/beanumber/teamcolors,10895,38,2020-04-10T20:42:02Z,286.7105263157895
teamr,"Package of wrapper functions using R6 class to send requests to 
  Microsoft 'Teams' <https://products.office.com/en-us/microsoft-teams/group-chat-software> through webhooks.
  When you need to share information or data from R to 'Teams', rather than copying/pasting, you
  can use this package to send well-formatted output from multiple R objects.",2019-07-18,Michael Yan,https://github.com/wwwjk366/teamr,TRUE,https://github.com/wwwjk366/teamr,3608,23,2019-07-22T16:25:10Z,156.8695652173913
telegram,"R wrapper around the Telegram Bot API (http://core.telegram.org/bots/api) to access Telegram's messaging facilities with ease (e.g. you send messages, images, files from R to your smartphone).",2016-09-17,Luca Braglia,http://github.com/lbraglia/telegram,TRUE,https://github.com/lbraglia/telegram,20376,42,2020-06-01T10:04:25Z,485.14285714285717
telegram.bot,"Provides a pure interface for the 'Telegram Bot API'
    <http://core.telegram.org/bots/api>. In addition to the pure API
    implementation, it features a number of tools to make the development of
    'Telegram' bots with R easy and straightforward, providing an easy-to-use
    interface that takes some work off the programmer.",2019-10-19,Ernest Benedito,http://github.com/ebeneditos/telegram.bot,TRUE,https://github.com/ebeneditos/telegram.bot,18360,45,2019-10-19T20:47:11Z,408
tempdisagg,"Temporal disaggregation methods are used to disaggregate and
    interpolate a low frequency time series to a higher frequency series, where
    either the sum, the mean, the first or the last value of the resulting
    high frequency series is consistent with the low frequency series. Temporal
    disaggregation can be performed with or without one or more high frequency
    indicator series. Contains the methods of Chow-Lin, Santos-Silva-Cardoso,
    Fernandez, Litterman, Denton and Denton-Cholette, summarized in Sax and
    Steiner (2013) <doi:10.32614/RJ-2013-028>. Supports most R time series
    classes.",2020-02-07,Christoph Sax,https://journal.r-project.org/archive/2013-2/sax-steiner.pdf,TRUE,https://github.com/christophsax/tempdisagg,192607,22,2020-02-07T12:48:56Z,8754.863636363636
Tendril,"Compute the coordinates to produce a tendril plot. 
    In the tendril plot, each tendril (branch) represents a type of events, 
    and the direction of the tendril is dictated by on which treatment arm the 
    event is occurring. If an event is occurring on the first of the two 
    specified treatment arms, the tendril bends in a clockwise direction. 
    If an event is occurring on the second of the treatment arms, the
    tendril bends in an anti-clockwise direction. 
    Ref: Karpefors, M and Weatherall, J., ""The Tendril Plot - a novel visual summary 
    of the incidence, significance and temporal aspects of adverse events in 
    clinical trials"" - JAMIA 2018; 25(8): 1069-1073 <doi:10.1093/jamia/ocy016>.",2020-02-11,Martin Karpefors,https://github.com/Karpefors/Tendril,TRUE,https://github.com/karpefors/tendril,1681,5,2020-01-31T17:59:48Z,336.2
tensorflow,"Interface to 'TensorFlow' <https://www.tensorflow.org/>, 
  an open source software library for numerical computation using data
  flow graphs. Nodes in the graph represent mathematical operations, 
  while the graph edges represent the multidimensional data arrays 
  (tensors) communicated between them. The flexible architecture allows
  you to deploy computation to one or more 'CPUs' or 'GPUs' in a desktop, 
  server, or mobile device with a single 'API'. 'TensorFlow' was originally
  developed by researchers and engineers working on the Google Brain Team 
  within Google's Machine Intelligence research organization for the 
  purposes of conducting machine learning and deep neural networks research,
  but the system is general enough to be applicable in a wide variety
  of other domains as well.",2020-05-11,Daniel Falbel [ctb,https://github.com/rstudio/tensorflow,TRUE,https://github.com/rstudio/tensorflow,579740,1185,2020-05-21T14:14:06Z,489.2320675105485
tergm,An integrated set of extensions to the 'ergm' package to analyze and simulate network evolution based on exponential-family random graph models (ERGM). 'tergm' is a part of the 'statnet' suite of packages for network analysis.,2019-06-12,Pavel N. Krivitsky,http://www.statnet.org,TRUE,https://github.com/statnet/tergm,201448,6,2020-06-03T03:18:53Z,33574.666666666664
term,"Creates, manipulates, queries and repairs vectors of parameter terms.
    Parameter terms are the labels used to reference values in vectors, matrices 
    and arrays. They represent the names in coefficient tables and 
    the column names in 'mcmc' and 'mcmc.list' objects.",2020-01-15,Joe Thorley,https://github.com/poissonconsulting/term,TRUE,https://github.com/poissonconsulting/term,3048,3,2020-06-09T22:01:56Z,1016
Ternary,"Plots ternary diagrams using the standard graphics functions.  
  An alternative to 'ggtern', which uses the 'ggplot2' family of plotting functions.",2020-02-27,Martin R. Smith,"https://ms609.github.io/Ternary/,
https://github.com/ms609/Ternary/",TRUE,https://github.com/ms609/ternary,18146,10,2020-06-01T10:33:33Z,1814.6
terra,"Methods for spatial data analysis, especially raster data. Methods allow for low-level data manipulation as well as high-level global, local, zonal, and focal computation. The predict and interpolate methods facilitate the use of regression type (interpolation, machine learning) models for spatial prediction. Processing of very large files is supported. See the manual and tutorials on <https://rspatial.org/terra/> to get started. The package is similar to the 'raster' package; but it is simpler and faster. ",2020-05-19,Robert J. Hijmans,https://rspatial.org/terra,TRUE,https://github.com/rspatial/terra,2974,151,2020-06-08T16:32:18Z,19.695364238410598
tesseract,"Bindings to 'Tesseract' <https://opensource.google.com/projects/tesseract>: 
     a powerful optical character recognition (OCR) engine that supports over 100 languages.
     The engine is highly configurable in order to tune the detection algorithms and
     obtain the best possible results.",2019-07-25,Jeroen Ooms,https://github.com/ropensci/tesseract,TRUE,https://github.com/ropensci/tesseract,281511,177,2020-05-24T12:03:00Z,1590.457627118644
TestDesign,"Use the optimal test design approach by Birnbaum (1968, ISBN:9781593119348) and
    van der Linden (2018) <doi:10.1201/9781315117430> in constructing fixed and adaptive tests. Supports the following
    mixed-integer programming (MIP) solver packages: 'lpsymphony', 'Rsymphony', 'gurobi', 'lpSolve', and 'Rglpk'. The 'gurobi' package
    is not available from CRAN; see <https://www.gurobi.com/downloads>. See vignette for installing 'Rsymphony' package
    on Mac systems.",2020-02-06,Seung W. Choi,https://github.com/choi-phd/TestDesign,TRUE,https://github.com/choi-phd/testdesign,4375,0,2020-02-20T00:04:50Z,NA
TestDimorph,"Provides two approaches of comparison; the univariate and the multivariate analysis in two or more populations. Since the main obstacle of performing systematic comparisons in anthropological studies is the absence of raw data, the current package offer a solution for this problem by allowing the use of published summary statistics of metric data (mean, standard deviation and sex specific sample size) as illustrated by the works of  Greene, D. L. (1989) <doi:10.1002/ajpa.1330790113> and Konigsberg, L. W. (1991) <doi:10.1002/ajpa.1330840110>.",2020-04-23,Bassam A. Abulnoor,https://github.com/bassam-abulnoor/TestDimorph,TRUE,https://github.com/bassam-abulnoor/testdimorph,4811,0,2020-04-26T03:28:29Z,NA
testextra,"A collection of testing enhancements and utilities.
    Including utilities for extracting inline test blocks from 
    package source files.",2019-12-18,Andrew Redd,https://github.com/RDocTaskForce/testextra,TRUE,https://github.com/rdoctaskforce/testextra,11556,2,2020-01-31T19:57:52Z,5778
testit,"Provides two convenience functions assert() and test_pkg() to
    facilitate testing R packages.",2019-11-12,Yihui Xie,https://github.com/yihui/testit,TRUE,https://github.com/yihui/testit,321284,35,2019-11-18T05:08:31Z,9179.542857142857
testthat,"Software testing is important, but, in part because it is 
    frustrating and boring, many of us avoid it. 'testthat' is a testing framework 
    for R that is easy to learn and use, and integrates with your existing 'workflow'.",2020-03-02,Hadley Wickham,"http://testthat.r-lib.org, https://github.com/r-lib/testthat",TRUE,https://github.com/r-lib/testthat,10772846,663,2020-05-05T18:53:44Z,16248.636500754148
testthis,"Utility functions and 'RStudio' addins for writing,
    running and organizing automated tests. Integrates tightly with the
    packages 'testthat', 'devtools' and 'usethis'.  Hotkeys can be
    assigned to the 'RStudio' addins for running tests in a single file or
    to switch between a source file and the associated test file. In
    addition, testthis provides function to manage and run tests in
    subdirectories of the test/testthat directory.",2020-04-12,Stefan Fleck,https://s-fleck.github.io/testthis,TRUE,https://github.com/s-fleck/testthis,15182,29,2020-05-06T07:01:37Z,523.5172413793103
texmex,"Statistical extreme value modelling of threshold excesses, maxima
    and multivariate extremes. Univariate models for threshold excesses and maxima
    are the Generalised Pareto, and Generalised Extreme Value model respectively.
    These models may be fitted by using maximum (optionally penalised-)likelihood,
    or Bayesian estimation, and both classes of models may be fitted with covariates
    in any/all model parameters. Model diagnostics support the fitting process.
    Graphical output for visualising fitted models and return level estimates is
    provided. For serially dependent sequences, the intervals declustering algorithm
    of Ferro and Segers (2003) <doi:10.1111/1467-9868.00401> is provided, with
    diagnostic support to aid selection of threshold and declustering horizon.
    Multivariate modelling is performed via the conditional approach of Heffernan
    and Tawn (2004) <doi:10.1111/j.1467-9868.2004.02050.x>, with graphical tools for
    threshold selection and to diagnose estimation convergence.",2020-04-02,Harry Southworth,https://github.com/harrysouthworth/texmex,TRUE,https://github.com/harrysouthworth/texmex,22561,4,2020-06-09T06:41:43Z,5640.25
texPreview,"Compile snippets of 'LaTeX' directly into images
    from the R console to view in the 'RStudio' viewer pane, Shiny apps
    and 'RMarkdown' documents.",2020-02-16,Jonathan Sidi,https://github.com/metrumresearchgroup/texPreview,TRUE,https://github.com/metrumresearchgroup/texpreview,20200,38,2020-05-12T11:00:38Z,531.578947368421
texreg,"Converts coefficients, standard errors, significance stars, and goodness-of-fit statistics of statistical models into LaTeX tables or HTML tables/MS Word documents or to nicely formatted screen output for the R console for easy model comparison. A list of several models can be combined in a single table. The output is highly customizable. New model types can be easily implemented. (If the Zelig package, which this package enhances, cannot be found on CRAN, you can find it at <https://github.com/IQSS/Zelig>.)",2020-05-29,Philip Leifeld,http://github.com/leifeld/texreg/,TRUE,https://github.com/leifeld/texreg,309783,71,2020-05-29T20:30:14Z,4363.140845070423
text2speech,"Unifies different text to speech engines, such as
    Google, Microsoft, and Amazon.  Text synthesis can be done
    in any engine with a simple switch of an argument denoting
    the service requested.  The 'aws.polly' package has been
    orphaned and can be found from the CRAN archives.",2020-02-13,John Muschelli,https://github.com/muschellij2/text2speech,TRUE,https://github.com/muschellij2/text2speech,7074,7,2020-05-04T05:40:25Z,1010.5714285714286
text2vec,"Fast and memory-friendly tools for text vectorization, topic
    modeling (LDA, LSA), word embeddings (GloVe), similarities. This package
    provides a source-agnostic streaming API, which allows researchers to perform
    analysis of collections of documents which are larger than available RAM. All
    core functions are parallelized to benefit from multicore machines.",2020-02-18,Dmitriy Selivanov,http://text2vec.org,TRUE,https://github.com/dselivanov/text2vec,167728,676,2020-04-18T05:57:22Z,248.11834319526628
textclean,"Tools to clean and process text.  Tools are geared at checking for substrings that
          are not optimal for analysis and replacing or removing them (normalizing) with more
          analysis friendly substrings (see Sproat, Black, Chen, Kumar, Ostendorf, & Richards
          (2001) <doi:10.1006/csla.2001.0169>) or extracting them into new variables. For
          example, emoticons are often used in text but not always easily handled by analysis
          algorithms.  The replace_emoticon() function replaces emoticons with word
          equivalents.",2018-07-23,Tyler Rinker,https://github.com/trinker/textclean,TRUE,https://github.com/trinker/textclean,157984,124,2020-04-21T13:17:04Z,1274.0645161290322
textdata,"Provides a framework to download, parse, and store text datasets
    on the disk and load them when needed. Includes various sentiment lexicons
    and labeled text data sets for classification and analysis.",2020-05-04,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/textdata,TRUE,https://github.com/emilhvitfeldt/textdata,73949,53,2020-05-03T17:17:23Z,1395.2641509433963
textfeatures,"A tool for extracting some generic features (e.g., number of
    words, line breaks, characters per word, URLs, lower case, upper case,
    commas, periods, exclamation points, etc.) from strings of text.",2019-09-03,Michael W. Kearney,https://github.com/mkearney/textfeatures,TRUE,https://github.com/mkearney/textfeatures,13934,137,2019-09-03T16:37:42Z,101.7080291970803
TextForecast,"Provides functionalities based on the paper ""Time Varying Dictionary and the Predictive Power of FED Minutes"" (Lima, 2018) <doi:10.2139/ssrn.3312483>. It selects the most predictive terms, that we call time-varying dictionary using supervised machine learning techniques as lasso and elastic net.     ",2019-09-20,Lucas Godeiro,https://github.com/lucasgodeiro/TextForecast,TRUE,https://github.com/lucasgodeiro/textforecast,5544,10,2019-09-18T12:56:16Z,554.4
textmineR,"An aid for text mining in R, with a syntax that
    should be familiar to experienced R users. Provides a wrapper for several 
    topic models that take similarly-formatted input and give similarly-formatted
    output. Has additional functionality for analyzing and diagnostics for
    topic models.",2019-04-18,Tommy Jones,https://www.rtextminer.com/,TRUE,https://github.com/tommyjones/textminer,45886,85,2019-11-17T03:23:37Z,539.8352941176471
textplot,"Visualise complex relations in texts. This is done by providing functionalities for displaying 
    text co-occurrence networks, text correlation networks, dependency relationships as well as text clustering. 
    Feel free to join the effort of providing interesting text visualisations.",2020-05-23,Jan Wijffels,https://github.com/bnosac/textplot,TRUE,https://github.com/bnosac/textplot,1183,34,2020-05-23T09:59:05Z,34.794117647058826
textreadr,A small collection of convenience tools for reading text documents into R.,2018-09-28,Tyler Rinker,https://github.com/trinker/textreadr,TRUE,https://github.com/trinker/textreadr,38469,48,2020-04-28T17:20:01Z,801.4375
textrecipes,"Converting text to numerical features requires
    specifically created procedures, which are implemented as steps
    according to the 'recipes' package. These steps allows for
    tokenization, filtering, counting (tf and tfidf) and feature hashing.",2020-05-22,Emil Hvitfeldt,"https://github.com/tidymodels/textrecipes,
https://textrecipes.tidymodels.org",TRUE,https://github.com/tidymodels/textrecipes,9917,83,2020-05-25T00:58:53Z,119.48192771084338
textreuse,"Tools for measuring similarity among documents and detecting
    passages which have been reused. Implements shingled n-gram, skip n-gram,
    and other tokenizers; similarity/dissimilarity functions; pairwise
    comparisons; minhash and locality sensitive hashing algorithms; and a
    version of the Smith-Waterman local alignment algorithm suitable for
    natural language.",2020-05-15,Lincoln Mullen,"https://docs.ropensci.org/textreuse,
https://github.com/ropensci/textreuse",TRUE,https://github.com/ropensci/textreuse,29164,144,2020-05-15T14:42:19Z,202.52777777777777
textshape,Tools that can be used to reshape and restructure text data.,2020-04-17,Tyler Rinker,http://github.com/trinker/textshape,TRUE,https://github.com/trinker/textshape,244494,30,2020-04-16T22:07:39Z,8149.8
textTinyR,"It offers functions for splitting, parsing, tokenizing and creating a vocabulary for big text data files. Moreover, it includes functions for building a document-term matrix and extracting information from those (term-associations, most frequent terms). It also embodies functions for calculating token statistics (collocations, look-up tables, string dissimilarities) and functions to work with sparse matrices. Lastly, it includes functions for Word Vector Representations (i.e. 'GloVe', 'fasttext') and incorporates functions for the calculation of (pairwise) text document dissimilarities. The source code is based on 'C++11' and exported in R through the 'Rcpp', 'RcppArmadillo' and 'BH' packages.",2019-04-14,Lampros Mouselimis,https://github.com/mlampros/textTinyR,TRUE,https://github.com/mlampros/texttinyr,17137,27,2020-02-06T13:16:51Z,634.7037037037037
textutils,"Utilities for handling character vectors
  that store human-readable text (either plain or with
  markup, such as HTML or LaTeX). The package provides,
  in particular, functions that help with the
  preparation of plain-text reports, e.g. for expanding
  and aligning strings that form the lines of such
  reports. The package also provides generic functions for
  transforming R objects to HTML and to plain text.",2020-01-07,Enrico Schumann,"http://enricoschumann.net/R/packages/textutils/,
https://github.com/enricoschumann/textutils",TRUE,https://github.com/enricoschumann/textutils,18117,2,2019-12-31T07:25:03Z,9058.5
tfaddons,"'TensorFlow SIG Addons' <https://www.tensorflow.org/addons> is a repository 
             of community contributions that conform to well-established API patterns, 
             but implement new functionality not available in core 'TensorFlow'. 
             'TensorFlow' natively supports a large number of operators, layers, metrics, 
             losses, optimizers, and more. However, in a fast moving field like Machine Learning, 
             there are many interesting new developments that cannot be integrated into 
             core 'TensorFlow' (because their broad applicability is not yet clear, or 
             it is mostly used by a smaller subset of the community).",2020-06-02,Turgut Abdullayev,https://github.com/henry090/tfaddons,TRUE,https://github.com/henry090/tfaddons,0,11,2020-06-09T18:34:28Z,0
tfautograph,Translate R control flow expressions into 'Tensorflow' graphs.,2020-01-08,Tomasz Kalinowski,https://t-kalinowski.github.io/tfautograph/,TRUE,https://github.com/t-kalinowski/tfautograph,3397,11,2020-02-20T01:34:49Z,308.8181818181818
tfdatasets,"Interface to 'TensorFlow' Datasets, a high-level library for 
    building complex input pipelines from simple, re-usable pieces. 
    See <https://www.tensorflow.org/programmers_guide/datasets> for additional
    details.",2020-05-25,Daniel Falbel [ctb,https://github.com/rstudio/tfdatasets,TRUE,https://github.com/rstudio/tfdatasets,37921,24,2020-05-25T15:26:10Z,1580.0416666666667
tfhub,"'TensorFlow' Hub is a library for the publication, discovery, and
    consumption of reusable parts of machine learning models. A module is a 
    self-contained piece of a 'TensorFlow' graph, along with its weights and 
    assets, that can be reused across different tasks in a process known as
    transfer learning. Transfer learning train a model with a smaller dataset,
    improve generalization, and speed up training.",2020-05-22,Daniel Falbel,https://github.com/rstudio/tfhub,TRUE,https://github.com/rstudio/tfhub,3035,25,2020-05-23T02:37:41Z,121.4
tfio,"Interface to 'TensorFlow IO', Datasets and filesystem extensions maintained by `TensorFlow SIG-IO` <https://github.com/tensorflow/community/blob/master/sigs/io/CHARTER.md>.",2019-12-19,TensorFlow IO Contributors,https://github.com/tensorflow/io,TRUE,https://github.com/tensorflow/io,5288,328,2020-06-09T04:33:00Z,16.121951219512194
tfprobability,"Interface to 'TensorFlow Probability', a 'Python' library built on 'TensorFlow'
    that makes it easy to combine probabilistic models and deep learning on modern hardware ('TPU', 'GPU').
    'TensorFlow Probability' includes a wide selection of probability distributions and bijectors, probabilistic layers,
    variational inference, Markov chain Monte Carlo, and optimizers such as Nelder-Mead, BFGS, and SGLD.",2020-05-19,Sigrid Keydana,https://github.com/rstudio/tfprobability,TRUE,https://github.com/rstudio/tfprobability,4416,40,2020-05-20T06:44:06Z,110.4
tfruns,"Create and manage unique directories for each 'TensorFlow' 
  training run. Provides a unique, time stamped directory for each run
  along with functions to retrieve the directory of the latest run or 
  latest several runs. ",2018-08-25,JJ Allaire,https://github.com/rstudio/tfruns,TRUE,https://github.com/rstudio/tfruns,464925,29,2019-08-26T12:36:39Z,16031.896551724138
tfse,"A collection of useful tools for programming and writing-scripts. 
    Several functions are simple wrappers around base R functions that extend 
    their functionality while also providing some convenient properties–regular
    expression functions that automatically detect look-ahead and look-behind 
    statements, a read-line function that suppresses incomplete-final-line 
    warnings and automatically opens and closes connections, a version of 
    substrings that starts from the end of strings, etc. Other functions are 
    useful for checking whether packages are installed, omitting 
    missing data, and showing in-use connections.",2019-02-11,Michael W. Kearney,https://tfse.mikewk.com,TRUE,https://github.com/mkearney/tfse,11708,18,2019-07-04T16:31:45Z,650.4444444444445
TGS,"Rapid advancements in high-throughput gene sequencing
    technologies have resulted in genome-scale time-series datasets. 
    Uncovering the underlying temporal sequence of gene regulatory events 
    in the form of time-varying gene regulatory networks demands 
    accurate and computationally efficient algorithms. Such an
    algorithm is 'TGS'. It is proposed in Saptarshi Pyne, Alok Ranjan 
    Kumar, and Ashish Anand. Rapid reconstruction of time-varying 
    gene regulatory networks. IEEE/ACM Transactions on Computational 
    Biology and Bioinformatics, 17(1):278{291, Jan-Feb 2020. The TGS 
    algorithm is shown to consume only 29 minutes for a microarray 
    dataset with 4028 genes. This package provides an implementation 
    of the TGS algorithm and its variants.",2020-05-07,Saptarshi Pyne,"https://www.biorxiv.org/content/early/2018/06/14/272484,
https://github.com/sap01/TGS",TRUE,https://github.com/sap01/tgs,5419,0,2020-05-22T14:04:41Z,NA
theiaR,"Provides a simple interface to search available data provided by
    Theia (<https://theia.cnes.fr>), download it, and manage it. Data can be downloaded
    based on a search result or from a cart file downloaded from Theia website.",2020-01-20,Xavier Laviron,https://github.com/norival/theiaR,TRUE,https://github.com/norival/theiar,4749,0,2020-01-20T15:30:38Z,NA
themetagenomics,"A means to explore the structure of 16S rRNA surveys using a Structural 
  Topic Model coupled with functional prediction. The user provides an abundance 
  table, sample metadata, and taxonomy information, and themetagenomics infers 
  associations between topics and sample features, as well as topics and predicted 
  functional content. Functional prediction can be accomplished via Tax4Fun (for 
  Silva references) and PICRUSt (for GreenGeenes references). See 
  <doi:10.1371/journal.pone.0219235>.",2020-04-30,Stephen Woloszynek,http://github.com/EESI/themetagenomics,TRUE,https://github.com/eesi/themetagenomics,10218,17,2020-04-30T15:29:04Z,601.0588235294117
themis,"A dataset with an uneven number of cases in each
    class is said to be unbalanced. Many models produce a subpar
    performance on unbalanced datasets. A dataset can be balanced by
    increasing the number of minority cases using SMOTE 2011
    <arXiv:1106.1813>, BorderlineSMOTE 2005 <doi:10.1007/11538059_91> and
    ADASYN 2008 <https://ieeexplore.ieee.org/document/4633969>. Or by
    decreasing the number of majority cases using NearMiss 2003
    <https://www.site.uottawa.ca/~nat/Workshop2003/jzhang.pdf> or Tomek
    link removal 1976 <https://ieeexplore.ieee.org/document/4309452>.",2020-05-17,Emil Hvitfeldt,https://github.com/tidymodels/themis,TRUE,https://github.com/tidymodels/themis,3201,44,2020-05-17T07:34:04Z,72.75
Thermimage,"A collection of functions and routines for inputting thermal
    image video files, plotting and converting binary raw data into estimates of
    temperature.  First published 2015-03-26.  Written primarily for research purposes
    in biological applications of thermal images.  v1 included the base calculations 
    for converting thermal image binary values to temperatures. v2 included additional
    equations for providing heat transfer calculations and an import function for thermal
    image files (v2.2.3 fixed error importing thermal image to windows OS). v3. Added numerous
    functions for converting thermal image, videos, rewriting and exporting.  
    v3.1. Added new functions to convert files. v3.2.  Fixed the various functions related to finding frame times.
    v4.0. fixed an error in atmospheric attenuation constants, affecting raw2temp and temp2raw functions.
    Recommend update for use with long distance calculations.",2019-11-30,Glenn J. Tattersall,"https://cran.r-project.org/package=Thermimage,
https://github.com/gtatters/Thermimage",TRUE,https://github.com/gtatters/thermimage,22031,72,2019-12-21T16:36:48Z,305.9861111111111
thief,"Methods and tools for generating forecasts at different temporal
    frequencies using a hierarchical time series approach.",2018-01-24,Rob Hyndman,"http://pkg.robjhyndman.com/thief,
https://github.com/robjhyndman/thief",TRUE,https://github.com/robjhyndman/thief,82635,39,2020-02-05T02:17:36Z,2118.846153846154
thor,"Key-value store, implemented as a wrapper around 'LMDB';
    the ""lightning memory-mapped database"" <https://symas.com/lmdb/>.
    'LMDB' is a transactional key value store that uses a memory map
    for efficient access.  This package wraps the entire 'LMDB'
    interface (except duplicated keys), and provides objects for
    transactions and cursors.",2020-05-15,Rich FitzJohn,https://github.com/richfitz/thor,TRUE,https://github.com/richfitz/thor,7160,37,2020-05-15T12:47:34Z,193.51351351351352
threeBrain,"In neuroscience, 'AFNI/SUMA' is a great tool to visualize 3D brain. 
    However, it takes efforts to interact and share the viewer to others. In 
    addition, 'AFNI/SUMA' doesn't support Windows platform. In the 'EEG/iEEG' 
    field, it's hard to have multiple cortical electrodes mapped to a template 
    brain for group analysis. Therefore this package is written aimed at 
    providing a fast, stable, interactive and easy to share tool based on 'Three.js', 
    a 'WebGL' engine to render 3D objects in the web browser such that we can 
    display brain surfaces on webpage interactively. This package translates R 
    objects to JavaScript objects via 'JSON' format, and provides 'R-Shiny' interface
    to manipulate geometries interactively. The visualizations can also serve as 
    standalone widgets that can be easily shared across different platforms. 
    Along with 'rave', another package developed by Beauchamp's lab at Baylor 
    College Medicine, this package provides solutions to easily map surface 
    electrodes from multiple subjects to one template 141 brain.",2020-05-12,Zhengjia Wang,https://github.com/dipterix/threeBrain,TRUE,https://github.com/dipterix/threebrain,4714,5,2020-06-09T10:08:27Z,942.8
threejs,"Create interactive 3D scatter plots, network plots, and
    globes using the 'three.js' visualization library (<https://threejs.org>).",2020-01-21,B. W. Lewis,https://bwlewis.github.io/rthreejs,TRUE,https://github.com/bwlewis/rthreejs,426497,236,2020-02-12T16:06:32Z,1807.1906779661017
threshr,"Provides functions for the selection of thresholds for use in 
    extreme value models, based mainly on the methodology in 
    Northrop, Attalides and Jonathan (2017) <doi:10.1111/rssc.12159>.
    It also performs predictive inferences about future extreme values, 
    based either on a single threshold or on a weighted average of inferences 
    from multiple thresholds, using the 'revdbayes' package 
    <https://cran.r-project.org/package=revdbayes>.   
    At the moment only the case where the data can be treated as 
    independent identically distributed observations is considered.",2019-03-01,Paul J. Northrop,http://github.com/paulnorthrop/threshr,TRUE,https://github.com/paulnorthrop/threshr,9081,3,2019-09-16T09:02:08Z,3027
thurstonianIRT,"Fit Thurstonian Item Response Theory (IRT) models in R. This 
  package supports fitting Thurstonian IRT models and its extensions using 
  'Stan', 'lavaan', or 'Mplus' for the model estimation. Functionality for 
  extracting results and simulating data is provided as well. References: 
  Brown & Maydeu-Olivares (2011) <doi:10.1177/0013164410375112>;
  Bürkner et al. (2019) <doi:10.1177/0013164419832063>.",2019-08-09,Paul-Christian Bürkner,https://github.com/paul-buerkner/thurstonianIRT,TRUE,https://github.com/paul-buerkner/thurstonianirt,3233,13,2020-04-03T06:34:19Z,248.69230769230768
tibble,"Provides a 'tbl_df' class (the 'tibble') that
    provides stricter checking and better formatting than the traditional
    data frame.",2020-04-20,Kirill Müller,"https://tibble.tidyverse.org/, https://github.com/tidyverse/tibble",TRUE,https://github.com/tidyverse/tibble,26759887,316,2020-06-09T12:54:51Z,84683.18670886075
tibbletime,"Built on top of the 'tibble' package, 'tibbletime' is an extension
  that allows for the creation of time aware tibbles. Some immediate
  advantages of this include: the ability to perform time-based subsetting
  on tibbles, quickly summarising and aggregating results by time periods,
  and creating columns that can be used as 'dplyr' time-based groups.",2020-05-26,Davis Vaughan,https://github.com/business-science/tibbletime,TRUE,https://github.com/business-science/tibbletime,122383,162,2020-05-26T21:02:31Z,755.4506172839506
tidybayes,"Compose data for and extract, manipulate, and visualize posterior draws from Bayesian models
    ('JAGS', 'Stan', 'rstanarm', 'brms', 'MCMCglmm', 'coda', ...) in a tidy data format. Functions are provided
    to help extract tidy data frames of draws from Bayesian models and that generate point
    summaries and intervals in a tidy format. In addition, 'ggplot2' 'geoms' and 'stats' are provided for
    common visualization primitives like points with multiple uncertainty intervals, eye plots (intervals plus
    densities), and fit curves with multiple, arbitrary uncertainty bands.",2020-04-04,Matthew Kay,"http://mjskay.github.io/tidybayes,
https://github.com/mjskay/tidybayes",TRUE,https://github.com/mjskay/tidybayes,35799,464,2020-06-03T04:44:55Z,77.15301724137932
tidyBF,"Provides helper functions that make it easy to run
    'BayesFactor' package tests on a data which is in a tidy format.
    Additionally, it provides a more consistent syntax and by default
    returns a dataframe with rich details. These functions can also return
    expressions containing results from Bayes Factor tests that can then
    be displayed on custom plots.",2020-04-11,Indrajeet Patil,"https://indrajeetpatil.github.io/tidyBF/,
https://github.com/IndrajeetPatil/tidyBF",TRUE,https://github.com/indrajeetpatil/tidybf,7655,6,2020-05-28T17:18:12Z,1275.8333333333333
tidyboot,"Compute arbitrary non-parametric bootstrap statistics on data in
    tidy data frames.",2018-03-14,Mika Braginsky,https://github.com/langcog/tidyboot,TRUE,https://github.com/langcog/tidyboot,8234,14,2020-04-28T01:30:45Z,588.1428571428571
tidycat,Create additional rows and columns on broom::tidy() output to allow for easier control on categorical parameter estimates. ,2020-06-05,Guy J. Abel,https://github.com/guyabel/tidycat,TRUE,https://github.com/guyabel/tidycat,0,0,2020-05-30T06:20:43Z,NA
tidycensus,"An integrated R interface to the decennial US Census and American Community Survey APIs and
    the US Census Bureau's geographic boundary files.  Allows R users to return Census and ACS data as
    tidyverse-ready data frames, and optionally returns a list-column with feature geometry for many 
    geographies. ",2020-04-03,Kyle Walker,https://github.com/walkerke/tidycensus,TRUE,https://github.com/walkerke/tidycensus,77924,355,2020-04-20T16:07:23Z,219.50422535211268
tidycode,"Analyze lines of R code using tidy principles. This allows you to 
    input lines of R code and output a data frame with one row per function 
    included. Additionally, it facilitates code classification via included lexicons.",2019-12-10,Lucy DAgostino McGowan,https://github.com/LucyMcGowan/tidycode,TRUE,https://github.com/lucymcgowan/tidycode,4463,22,2019-12-10T15:31:00Z,202.86363636363637
tidycomm,"Provides convenience functions for common data
    modification and analysis tasks in communication research. This
    includes functions for univariate and bivariate data analysis, index
    generation and reliability computation, and intercoder reliability
    tests. All functions follow the style and syntax of the tidyverse, and
    are construed to perform their computations on multiple variables at
    once. Functions for univariate and bivariate data analysis comprise
    summary statistics for continuous and categorical variables, as well
    as several tests of bivariate association including effect sizes.
    Functions for data modification comprise index generation and
    automated reliability analysis of index variables. Functions for
    intercoder reliability comprise tests of several intercoder
    reliability estimates, including simple and mean pairwise percent
    agreement, Krippendorff's Alpha (Krippendorff 2004, ISBN:
    9780761915454), and various Kappa coefficients (Brennan & Prediger
    1981 <doi: 10.1177/001316448104100307>; Cohen 1960 <doi:
    10.1177/001316446002000104>; Fleiss 1971 <doi: 10.1037/h0031619>).",2019-09-22,Julian Unkel,https://github.com/joon-e/tidycomm,TRUE,https://github.com/joon-e/tidycomm,3349,5,2020-02-12T17:34:51Z,669.8
tidycwl,"The Common Workflow Language <https://www.commonwl.org/> is an
    open standard for describing data analysis workflows. This package takes
    the raw Common Workflow Language workflows encoded in JSON or 'YAML'
    and turns the workflow elements into tidy data frames or lists.
    A graph representation for the workflow can be constructed and visualized
    with the parsed workflow inputs, outputs, and steps. Users can embed the
    visualizations in their 'Shiny' applications, and export them
    as HTML files or static images.",2019-12-07,Nan Xiao,"https://sbg.github.io/tidycwl/, https://github.com/sbg/tidycwl",TRUE,https://github.com/sbg/tidycwl,2577,4,2020-04-23T15:59:24Z,644.25
tidydice,"Utils for basic statistical experiments, that can be used for teaching 
    introductory statistics. Each experiment generates a tibble.
    Dice rolls and coin flips are simulated using sample().
    The properties of the dice can be changed, like the number of sides.
    A coin flip is simulated using a two sided dice.
    Experiments can be combined with the pipe-operator.",2020-01-09,Roland Krasser,http://github.com/rolkra/tidydice,TRUE,https://github.com/rolkra/tidydice,2992,2,2020-01-07T09:18:34Z,1496
tidyfst,"A toolkit of tidy data manipulation verbs with 'data.table' as the backend.
  Combining the merits of syntax elegance from 'dplyr' and computing performance from 'data.table', 
  'tidyfst' intends to provide users with state-of-the-art data manipulation tools with least pain.
  This package is an extension of 'data.table'. While enjoying a tidy syntax, 
  it also wraps combinations of efficient functions to facilitate frequently-used data operations.  ",2020-05-28,Tian-Yuan Huang,"https://github.com/hope-data-science/tidyfst,
https://hope-data-science.github.io/tidyfst/",TRUE,https://github.com/hope-data-science/tidyfst,3032,25,2020-06-03T01:43:25Z,121.28
tidyft,"Tidy syntax for 'data.table', using modification by reference whenever possible.
 This toolkit is designed for big data analysis in high-performance desktop or laptop computers.
 The syntax of the package is similar or identical to 'tidyverse'.
 It is user friendly, memory efficient and time saving. For more information,
 check its ancestor package 'tidyfst'.",2020-04-10,Tian-Yuan Huang,"https://github.com/hope-data-science/tidyft,
https://hope-data-science.github.io/tidyft/",TRUE,https://github.com/hope-data-science/tidyft,835,8,2020-05-02T23:07:22Z,104.375
tidygapminder,"A toolset that allows you to easily import and tidy data sheets retrieved
    from Gapminder data web tools. It will therefore contribute to reduce the time
    used in data cleaning of Gapminder indicator data sheets as they are very messy.",2020-02-04,Anicet Ebou,https://ebedthan.github.io/tidygapminder,TRUE,https://github.com/ebedthan/tidygapminder,2701,0,2020-05-26T13:14:13Z,NA
tidygenomics,"Handle genomic data within data frames just as you would with 'GRanges'.
    This packages provides method to deal with genomic intervals the ""tidy-way"" which makes
    it simpler to integrate in the the general data munging process. The API is inspired by the
    popular 'bedtools' and the genome_join() method from the 'fuzzyjoin' package.",2019-08-08,Constantin Ahlmann-Eltze,https://github.com/const-ae/tidygenomics,TRUE,https://github.com/const-ae/tidygenomics,10692,89,2019-08-08T11:41:27Z,120.13483146067416
tidygeocoder,An intuitive tidyverse-style interface for geocoding. Obtains latitude and longitude coordinates in tibble format from addresses. The currently supported services are the US Census geocoder and Nominatim (OSM). ,2020-03-22,Jesse Cambon,https://github.com/jessecambon/tidygeocoder,TRUE,https://github.com/jessecambon/tidygeocoder,4888,25,2020-05-16T13:04:28Z,195.52
tidygraph,"A graph, while not ""tidy"" in itself, can be thought of as two tidy
    data frames describing node and edge data respectively. 'tidygraph'
    provides an approach to manipulate these two virtual data frames using the
    API defined in the 'dplyr' package, as well as provides tidy interfaces to 
    a lot of common graph algorithms.",2020-05-12,Thomas Lin Pedersen,"https://tidygraph.data-imaginist.com,
https://github.com/thomasp85/tidygraph",TRUE,https://github.com/thomasp85/tidygraph,402991,353,2020-05-13T18:04:33Z,1141.6175637393767
tidyHeatmap,"This is a tidy implementation for heatmap.  At the
    moment it is based on the (great) package 'ComplexHeatmap'.  The goal
    of this package is to interface a tidy data frame with this powerful
    tool.  Some of the advantages are: Row and/or columns colour
    annotations are easy to integrate just specifying one parameter
    (column names).  Custom grouping of rows is easy to specify providing
    a grouped tbl. For example: df %>% group_by(...).  Labels size
    adjusted by row and column total number.  Default use of Brewer and
    Viridis palettes.",2020-05-07,Stefano Mangiola,"https://www.r-project.org,
https://github.com/stemangiola/tidyHeatmap",TRUE,https://github.com/stemangiola/tidyheatmap,2114,80,2020-06-04T04:37:33Z,26.425
tidyhydat,"Provides functions to access historical and real-time national 'hydrometric'
    data from Water Survey of Canada data sources (<http://dd.weather.gc.ca/hydrometric/csv/> and
    <http://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/>) and then applies tidy data principles.",2019-12-02,Sam Albers,https://docs.ropensci.org/tidyhydat/,TRUE,https://github.com/ropensci/tidyhydat,11965,52,2020-06-10T01:58:44Z,230.09615384615384
tidyjson,Turn complex 'JSON' data into tidy data frames.,2020-05-31,Cole Arendt,https://github.com/colearendt/tidyjson,TRUE,https://github.com/colearendt/tidyjson,41197,103,2020-06-01T02:58:23Z,399.97087378640776
tidylo,"How can we measure how the usage or frequency of some feature, such 
    as words, differs across some group or set, such as documents? One option is 
    to use the log odds ratio, but the log odds ratio alone does not account for 
    sampling variability; we haven't counted every feature the same number of 
    times so how do we know which differences are meaningful? Enter the weighted 
    log odds, which 'tidylo' provides an implementation for, using tidy data 
    principles. In particular, here we use the method outlined in Monroe, 
    Colaresi, and Quinn (2008) <doi:10.1093/pan/mpn018> to weight the log odds 
    ratio by a prior. By default, the prior is estimated from the data itself, 
    an empirical Bayes approach, but an uninformative prior is also available.",2020-05-25,Julia Silge,http://github.com/juliasilge/tidylo,TRUE,https://github.com/juliasilge/tidylo,240,50,2020-05-25T23:22:15Z,4.8
tidylog,Provides feedback about 'dplyr' and 'tidyr' operations.,2020-04-17,Benjamin Elbers,https://github.com/elbersb/tidylog/,TRUE,https://github.com/elbersb/tidylog,40586,375,2020-04-02T12:40:08Z,108.22933333333333
tidyLPA,"An interface to the 'mclust' package to easily
    carry out latent profile analysis (""LPA""). Provides functionality to
    estimate commonly-specified models. Follows a tidy approach, in that
    output is in the form of a data frame that can subsequently be
    computed on. Also has functions to interface to the commercial 'MPlus'
    software via the 'MplusAutomation' package.",2020-05-13,Joshua M Rosenberg,https://data-edu.github.io/tidyLPA/,TRUE,https://github.com/data-edu/tidylpa,17930,29,2020-05-13T12:14:23Z,618.2758620689655
tidyMicro,"A reliable alternative to popular microbiome analysis R packages. We provide standard tools as well as novel extensions on standard analyses to improve interpretability and the analyst’s ability to communicate results, all while maintaining object malleability to encourage open source collaboration.",2020-03-28,Charlie Carpenter,NA,TRUE,https://github.com/charliecarpenter/tidymicro,1087,0,2020-03-18T19:20:57Z,NA
tidymodels,"The tidy modeling ""verse"" is a collection of packages for 
    modeling and statistical analysis that share the underlying design
    philosophy, grammar, and data structures of the tidyverse.",2020-02-16,Max Kuhn,https://github.com/tidymodels/tidymodels,TRUE,https://github.com/tidymodels/tidymodels,110410,324,2020-05-29T23:13:42Z,340.7716049382716
tidymv,"Provides functions for visualising generalised
    additive models and getting predicted values using tidy tools from the 'tidyverse' packages.",2020-04-25,Stefano Coretta,https://github.com/stefanocoretta/tidymv,TRUE,https://github.com/stefanocoretta/tidymv,8848,21,2020-04-24T06:58:08Z,421.3333333333333
tidync,"Tidy tools for 'NetCDF' data sources. Explore the contents of a 
 'NetCDF' source (file or URL) presented as variables organized by grid with a 
 database-like interface. The hyper_filter() interactive function translates the 
 filter value or index expressions to array-slicing form. No data is read until 
 explicitly requested, as a data frame or list of arrays via hyper_tibble() or 
 hyper_array(). ",2020-05-12,Michael Sumner,https://docs.ropensci.org/tidync/,TRUE,https://github.com/ropensci/tidync,23445,70,2020-05-12T07:27:51Z,334.92857142857144
tidypmc,"Parse XML documents from the Open Access subset of Europe PubMed Central <https://europepmc.org>
    including section paragraphs, tables, captions and references.",2019-08-01,Chris Stubben,https://github.com/cstubben/tidypmc,TRUE,https://github.com/cstubben/tidypmc,3370,14,2019-12-09T19:35:01Z,240.71428571428572
tidyposterior,"Bayesian analysis used here to answer the question: ""when looking at resampling results, are the differences between models 'real'?"" To answer this, a model can be created were the performance statistic is the resampling statistics (e.g. accuracy or RMSE). These values are explained by the model types. In doing this, we can get parameter estimates for each model's affect on performance and make statistical (and practical) comparisons between models. The methods included here are similar to Benavoli et al (2017) <http://jmlr.org/papers/v18/16-305.html>.",2018-11-15,Max Kuhn,https://tidymodels.github.io/tidyposterior,TRUE,https://github.com/tidymodels/tidyposterior,98231,74,2020-05-13T14:18:51Z,1327.445945945946
tidypredict,"It parses a fitted 'R' model object, and returns a formula
    in 'Tidy Eval' code that calculates the predictions.
    It works with several databases back-ends because it leverages 'dplyr'
    and 'dbplyr' for the final 'SQL' translation of the algorithm. It currently
    supports lm(), glm(), randomForest(), ranger(), earth(), xgb.Booster.complete(),
    cubist(), and ctree() models. ",2020-02-10,Max Kuhn,https://tidymodels.github.io/tidypredict,TRUE,https://github.com/tidymodels/tidypredict,61304,184,2020-05-13T14:20:00Z,333.17391304347825
tidyquant,"Bringing business and financial analysis to the 'tidyverse'. The 'tidyquant' 
    package provides a convenient wrapper to various 'xts', 'zoo', 'quantmod', 'TTR' 
    and 'PerformanceAnalytics' package 
    functions and returns the objects in the tidy 'tibble' format. The main 
    advantage is being able to use quantitative functions with the 'tidyverse'
    functions including 'purrr', 'dplyr', 'tidyr', 'ggplot2', 'lubridate', etc. See 
    the 'tidyquant' website for more information, documentation and examples.",2020-03-04,Matt Dancho,https://github.com/business-science/tidyquant,TRUE,https://github.com/business-science/tidyquant,301687,539,2020-06-09T19:31:55Z,559.7161410018552
tidyquery,Use 'SQL' 'SELECT' statements to query 'R' data frames.,2020-05-09,Ian Cook,https://github.com/ianmcook/tidyquery,TRUE,https://github.com/ianmcook/tidyquery,3804,87,2020-05-09T21:20:35Z,43.724137931034484
tidyqwi,"The purpose of this package is to access the 
    United States Census Bureau's Quarterly Workforce Indicator data. Additionally, 
    the data will be retrieved in a tidy format for further manipulation with full variable
    descriptions added if desired. Information about the United States Census Bureau's 
    Quarterly Workforce Indicator is available at 
    <https://www.census.gov/data/developers/data-sets/qwi.html>.",2020-05-04,Michael DeWitt,NA,TRUE,https://github.com/medewitt/tidyqwi,5368,0,2020-05-04T09:56:53Z,NA
tidyr,"Tools to help to create tidy data, where each column is a 
    variable, each row is an observation, and each cell contains a single value.  
    'tidyr' contains tools for changing the shape (pivoting) and hierarchy
    (nesting and 'unnesting') of a dataset, turning deeply nested lists
    into rectangular data frames ('rectangling'), and extracting values out 
    of string columns. It also includes tools for working with missing values 
    (both implicit and explicit).",2020-05-20,Hadley Wickham,"https://tidyr.tidyverse.org, https://github.com/tidyverse/tidyr",TRUE,https://github.com/tidyverse/tidyr,17982104,892,2020-05-26T17:35:17Z,20159.30941704036
tidyREDCap,"
    Helper functions for processing REDCap data in R. 'REDCap' (Research
    Electronic Data CAPture; <https://projectredcap.org>) is a web-enabled
    application for building and managing surveys and databases developed at
    Vanderbilt University.",2020-02-10,Raymond Balise,https://raymondbalise.github.io/tidyREDCap/index.html,TRUE,https://github.com/raymondbalise/tidyredcap,2318,0,2020-02-10T19:56:08Z,NA
tidyRSS,"
    With the objective of including data from RSS feeds into your analysis, 
    'tidyRSS' parses RSS, Atom and JSON feeds and returns a tidy data frame.",2020-06-01,Robert Myles McDonnell,https://github.com/RobertMyles/tidyrss,TRUE,https://github.com/robertmyles/tidyrss,25479,38,2020-06-01T20:25:49Z,670.5
tidyrules,"Utility to convert text based summary of rule based models to a tidy dataframe (where each row represents a rule) with related metrics such as support, confidence and lift. Rule based models from these packages are supported: 'C5.0', 'rpart' and 'Cubist'.",2020-06-04,Srikanth Komala Sheshachala,https://github.com/talegari/tidyrules,TRUE,https://github.com/talegari/tidyrules,7571,7,2020-06-04T12:07:46Z,1081.5714285714287
tidyselect,"A backend for the selecting functions of the 'tidyverse'.
    It makes it easy to implement select-like functions in your own
    packages in a way that is consistent with other 'tidyverse'
    interfaces for selection.",2020-05-11,Lionel Henry,"https://tidyselect.r-lib.org, https://github.com/r-lib/tidyselect",TRUE,https://github.com/r-lib/tidyselect,13823795,78,2020-05-15T17:29:08Z,177228.14102564103
tidytable,"Tidy interface to 'data.table'. 'rlang' compatible, which allows the user to build custom functions much like they would in the tidyverse.",2020-05-29,Mark Fairbanks,https://github.com/markfairbanks/tidytable,TRUE,https://github.com/markfairbanks/tidytable,3473,132,2020-06-09T20:31:18Z,26.310606060606062
tidytext,"Text mining for word processing and sentiment analysis using
    'dplyr', 'ggplot2', and other tidy tools.",2020-04-17,Julia Silge,http://github.com/juliasilge/tidytext,TRUE,https://github.com/juliasilge/tidytext,1012315,888,2020-05-25T19:24:25Z,1139.9943693693695
tidytransit,Read General Transit Feed Specification (GTFS) zipfiles into a list of R dataframes. Perform validation of the data structure against the specification. Analyze the headways and frequencies at routes and stops. Create maps and perform spatial analysis on the routes and stops. Please see the GTFS documentation here for more detail: <http://gtfs.org/>.,2020-04-17,Tom Buckley,https://github.com/r-transit/tidytransit,TRUE,https://github.com/r-transit/tidytransit,11613,72,2020-04-20T08:12:02Z,161.29166666666666
tidytree,"Phylogenetic tree generally contains multiple components including node, edge, branch and associated data. 'tidytree' provides an approach to convert tree object to tidy data frame as well as provides tidy interfaces to manipulate tree data.",2020-04-02,Guangchuang Yu,https://yulab-smu.github.io/treedata-book/,TRUE,https://github.com/yulab-smu/tidytree,72901,26,2020-04-09T08:59:02Z,2803.8846153846152
tidyUSDA,"Provides a consistent API to pull United States
    Department of Agriculture census and survey data from the National
    Agricultural Statistics Service (NASS) QuickStats service
    <https://quickstats.nass.usda.gov>.",2020-03-30,Brad Lindblad,"https://bradlindblad.github.io/tidyUSDA,
https://github.com/bradlindblad/tidyUSDA",TRUE,https://github.com/bradlindblad/tidyusda,4727,22,2020-03-30T01:42:03Z,214.86363636363637
tidyverse,"The 'tidyverse' is a set of packages that work in
    harmony because they share common data representations and 'API'
    design. This package is designed to make it easy to install and load
    multiple 'tidyverse' packages in a single step. Learn more about the
    'tidyverse' at <https://tidyverse.org>.",2019-11-21,Hadley Wickham,"http://tidyverse.tidyverse.org,
https://github.com/tidyverse/tidyverse",TRUE,https://github.com/tidyverse/tidyverse,22725931,870,2020-06-01T21:07:02Z,26121.759770114943
tidyvpc,"Perform a Visual Predictive Check (VPC), while accounting for 
    stratification, censoring, and prediction correction. Using piping from 
    'magrittr', the intuitive syntax gives users a flexible and powerful method 
    to generate VPCs using both traditional binning and a new binless approach 
    Jamsen et al. (2018) <doi:10.1002/psp4.12319> with Additive Quantile 
    Regression (AQR) and Locally Estimated Scatterplot Smoothing (LOESS) 
    prediction correction. ",2020-03-26,James Craig,https://github.com/jameswcraig/tidyvpc,TRUE,https://github.com/jameswcraig/tidyvpc,1012,0,2020-06-09T17:49:41Z,NA
tidyxl,"Imports non-tabular from Excel files into R.  Exposes cell content,
    position and formatting in a tidy structure for further manipulation.
    Tokenizes Excel formulas.  Supports '.xlsx' and '.xlsm' via the embedded
    'RapidXML' C++ library <http://rapidxml.sourceforge.net>.  Does not support
    '.xlsb' or '.xls'.",2020-05-09,Duncan Garmonsway,https://github.com/nacnudus/tidyxl,TRUE,https://github.com/nacnudus/tidyxl,26790,171,2020-05-09T12:12:24Z,156.66666666666666
tigris,"Download TIGER/Line shapefiles from the United States Census Bureau 
    (<https://www.census.gov/geo/maps-data/data/tiger-line.html>) and load into R as 'SpatialDataFrame' or 'sf' objects.",2020-04-01,Kyle Walker,https://github.com/walkerke/tigris,TRUE,https://github.com/walkerke/tigris,216589,179,2020-05-26T02:00:09Z,1209.9944134078212
tikzDevice,"Provides a graphics output device for R that records plots
        in a LaTeX-friendly format. The device transforms plotting
        commands issued by R functions into LaTeX code blocks. When
        included in a LaTeX document, these blocks are interpreted with
        the help of 'TikZ'---a graphics package for TeX and friends
        written by Till Tantau. Using the 'tikzDevice', the text of R
        plots can contain LaTeX commands such as mathematical formula.
        The device also allows arbitrary LaTeX code to be inserted into
        the output stream.",2019-08-07,Ralf Stubner,https://github.com/daqana/tikzDevice,TRUE,https://github.com/daqana/tikzdevice,231620,103,2020-01-12T20:29:57Z,2248.73786407767
tiler,"Creates geographic map tiles from geospatial map files or non-geographic map tiles from simple image files. 
    This package provides a tile generator function for creating map tile sets for use with packages such as 'leaflet'. 
    In addition to generating map tiles based on a common raster layer source, it also handles the non-geographic edge case, producing map tiles from arbitrary images.
    These map tiles, which have a non-geographic, simple coordinate reference system (CRS), can also be used with 'leaflet' when applying the simple CRS option.
    Map tiles can be created from an input file with any of the following extensions: tif, grd and nc for spatial maps and png, jpg and bmp for basic images.
    This package requires 'Python' and the 'gdal' library for 'Python'. 
    'Windows' users are recommended to install 'OSGeo4W' (<https://trac.osgeo.org/osgeo4w/>) as an easy way to obtain the required 'gdal' support for 'Python'.",2019-11-26,Matthew Leonawicz,https://github.com/ropensci/tiler,TRUE,https://github.com/ropensci/tiler,9988,48,2019-12-09T19:35:54Z,208.08333333333334
timechange,"Efficient routines for manipulation of date-time objects while
   accounting for time-zones and daylight saving times. The package includes
   utilities for updating of date-time components (year, month, day etc.),
   modification of time-zones, rounding of date-times, period addition and
   subtraction etc. Parts of the 'CCTZ' source code, released under the Apache
   2.0 License, are included in this package. See
   <https://github.com/google/cctz> for more details.",2018-04-26,Vitalie Spinu,https://github.com/vspinu/timechange/,TRUE,https://github.com/vspinu/timechange,7267,13,2019-12-09T12:04:01Z,559
timeperiodsR,"Simple definition of time intervals for the current, previous, and next week, month, quarter and year.",2020-04-03,Alexey Seleznev,"https://selesnow.github.io/timeperiodsR, https://t.me/R4marketing,
https://www.youtube.com/playlist?list=PLD2LDq8edf4qed2KVKfXmKdh0OQcdj9gw",TRUE,https://github.com/selesnow/timeperiodsr,3859,0,2020-05-08T14:59:25Z,NA
timeR,"Provides a 'timeR' class that makes timing codes easier. One can create 'timeR' objects and use them to record all timings, and extract recordings as data frame for later use.",2019-06-12,Yifu Yan,https://github.com/yusuzech/timeR,TRUE,https://github.com/yusuzech/timer,8461,2,2020-03-03T16:17:14Z,4230.5
timereg,"Programs for Martinussen and Scheike (2006), `Dynamic Regression
    Models for Survival Data', Springer Verlag.  Plus more recent developments.
    Additive survival model, semiparametric proportional odds model, fast
    cumulative residuals, excess risk models and more. Flexible competing risks
    regression including GOF-tests. Two-stage frailty modelling. PLS for the
    additive risk model. Lasso in the 'ahaz' package.",2020-05-27,Thomas Scheike with contributions from Torben Martinussen,https://github.com/scheike/timereg.git,TRUE,https://github.com/scheike/timereg,172950,18,2020-05-29T13:26:43Z,9608.333333333334
TimeSeries.OBeu,"Estimate and return the needed parameters for visualizations designed for 'OpenBudgets.eu' <http://openbudgets.eu/> time series data. Calculate time series model and forecast parameters in budget time series data of municipalities across Europe, according to the 'OpenBudgets.eu' data model. There are functions for measuring deterministic and stochastic trend of the input time series data with 'ACF', 'PACF', 'Phillips Perron' test, 'Augmented Dickey Fuller (ADF)' test, 'Kwiatkowski-Phillips-Schmidt-Shin (KPSS)' test, 'Mann Kendall' test for monotonic trend and 'Cox and Stuart' trend test, decomposing with local regression models or 'stl' decomposition, fitting the appropriate 'arima' model and provide forecasts for the input 'OpenBudgets.eu' time series fiscal data. Also, can be used generally to extract visualization parameters convert them to 'JSON' format and use them as input in a different graphical interface.",2019-12-17,Kleanthis Koupidis,https://github.com/okgreece/TimeSeries.OBeu,TRUE,https://github.com/okgreece/timeseries.obeu,8699,1,2019-12-17T14:31:38Z,8699
timeseriesdb,"Archive and manage times series data from official statistics. The 'timeseriesdb' package was designed to manage a large catalog of time series from official statistics which are typically published on a monthly, quarterly or yearly basis. Thus timeseriesdb is optimized to handle updates caused by data revision as well as elaborate, multi-lingual meta information. ",2018-08-06,Matthias Bannert,https://github.com/mbannert/timeseriesdb,TRUE,https://github.com/mbannert/timeseriesdb,17083,11,2020-02-12T13:52:22Z,1553
timetk,"
    Easy visualization, wrangling, and preprocessing of time series data for 
    forecasting and machine learning prediction. 
    Methods discussed herein are commonplace in machine learning, and have been cited 
    in various literature. Refer to ""Calendar Effects"" in papers such as 
    Taieb, Souhaib Ben. ""Machine learning strategies for multi-step-ahead time series 
    forecasting."" Universit Libre de Bruxelles, Belgium (2014): 75-86. 
    <http://souhaib-bentaieb.com/pdf/2014_phd.pdf>.",2020-05-31,Matt Dancho,https://github.com/business-science/timetk,TRUE,https://github.com/business-science/timetk,420330,234,2020-06-09T20:03:57Z,1796.2820512820513
timevis,"Create rich and fully interactive timeline visualizations.
    Timelines can be included in Shiny apps and R markdown documents, or viewed
    from the R console and 'RStudio' Viewer. 'timevis' includes an extensive API
    to manipulate a timeline after creation, and supports getting data out of
    the visualization into R. Based on the 'vis.js' Timeline module and the
    'htmlwidgets' R package.",2019-01-16,Dean Attali,"https://github.com/daattali/timevis,
http://daattali.com/shiny/timevis-demo/",TRUE,https://github.com/daattali/timevis,66332,396,2020-06-09T04:12:22Z,167.5050505050505
tint,"A 'tufte'-alike style for 'rmarkdown'.
 A modern take on the 'Tufte' design for pdf and html vignettes,
 building on the 'tufte' package with additional contributions
 from the 'knitr' and 'ggtufte' package, and also acknowledging
 the key influence of 'envisioned css'.",2019-04-19,Dirk Eddelbuettel and Jonathan Gilligan,http://dirk.eddelbuettel.com/code/tint.html,TRUE,https://github.com/eddelbuettel/tint,18740,196,2020-05-02T12:27:50Z,95.61224489795919
tinter,"Generate a palette of tints, shades or both from a single colour.",2020-04-17,Sebastian Dalgarno,https://github.com/poissonconsulting/tinter,TRUE,https://github.com/poissonconsulting/tinter,4828,30,2020-05-08T01:30:49Z,160.93333333333334
tinytest,"Provides a lightweight (zero-dependency) and easy to use 
    unit testing framework. Main features: install tests with 
    the package. Test results are treated as data that can be stored and 
    manipulated. Test files are R scripts interspersed with test commands, that
    can be programmed over. Fully automated build-install-test sequence for 
    packages. Skip tests when not run locally (e.g. on CRAN). Flexible and 
    configurable output printing. Compare computed output with output stored 
    with the package. Run tests in parallel. Extensible by other packages.
    Report side effects.",2020-05-18,Mark van der Loo,https://github.com/markvanderloo/tinytest,TRUE,https://github.com/markvanderloo/tinytest,74952,108,2020-06-09T10:54:40Z,694
tinytex,"Helper functions to install and maintain the 'LaTeX' distribution
  named 'TinyTeX' (<https://yihui.org/tinytex/>), a lightweight, cross-platform,
  portable, and easy-to-maintain version of 'TeX Live'. This package also
  contains helper functions to compile 'LaTeX' documents, and install missing
  'LaTeX' packages automatically.",2020-05-19,Yihui Xie,https://github.com/yihui/tinytex,TRUE,https://github.com/yihui/tinytex,10499314,490,2020-06-01T14:58:00Z,21427.17142857143
tippy,'Htmlwidget' of 'Tippyjs' to add tooltips to 'Shiny' apps and 'R markdown' documents.,2018-07-01,John Coene,http://tippy.john-coene.com/,TRUE,https://github.com/johncoene/tippy,7851,34,2019-12-17T08:05:37Z,230.91176470588235
tm.plugin.factiva,"Provides a 'tm' Source to create corpora from
  articles exported from the Dow Jones 'Factiva' content provider as
  XML or HTML files. It is able to read both text content and meta-data
  information (including source, date, title, author, subject,
  geographical coverage, company, industry, and various
  provider-specific fields).",2019-10-19,Milan Bouchet-Valat,https://github.com/nalimilan/R.TeMiS,TRUE,https://github.com/nalimilan/r.temis,25478,17,2020-04-01T16:31:45Z,1498.7058823529412
tm.plugin.lexisnexis,"Provides a 'tm' Source to create corpora from
  articles exported from the 'LexisNexis' content provider as
  HTML files. It is able to read both text content and meta-data
  information (including source, date, title, author and pages).
  Note that the file format is highly unstable: there is no warranty
  that this package will work for your corpus, and you may have
  to adjust the code to adapt it to your particular format.",2019-10-19,Milan Bouchet-Valat,https://github.com/nalimilan/R.TeMiS,TRUE,https://github.com/nalimilan/r.temis,24190,17,2020-04-01T16:31:45Z,1422.9411764705883
tmap,"Thematic maps are geographical maps in which spatial data distributions are visualized. This package offers a flexible, layer-based, and easy to use approach to create thematic maps, such as choropleths and bubble maps.",2020-04-09,Martijn Tennekes,https://github.com/mtennekes/tmap,TRUE,https://github.com/mtennekes/tmap,539002,415,2020-06-05T20:21:14Z,1298.8
tmaptools,"Set of tools for reading and processing spatial data. The aim is to supply the workflow to create thematic maps. This package also facilitates 'tmap', the package for visualizing thematic maps.",2020-03-30,Martijn Tennekes,https://github.com/mtennekes/tmaptools,TRUE,https://github.com/mtennekes/tmaptools,398769,25,2020-06-05T20:21:44Z,15950.76
TMB,"With this tool, a user should be able to quickly implement
    complex random effect models through simple C++ templates. The package combines
    'CppAD' (C++ automatic differentiation), 'Eigen' (templated matrix-vector
    library) and 'CHOLMOD' (sparse matrix routines available from R) to obtain
    an efficient implementation of the applied Laplace approximation with exact
    derivatives. Key features are: Automatic sparseness detection, parallelism
    through 'BLAS' and parallel user templates.",2020-01-15,Kasper Kristensen,http://tmb-project.org,TRUE,https://github.com/kaskr/adcomp,461895,111,2020-05-25T18:25:13Z,4161.216216216216
tmbstan,"Enables all 'rstan' functionality for a 'TMB' model object, in particular MCMC sampling and chain visualization. Sampling can be performed with or without Laplace approximation for the random effects.",2019-05-18,Kasper Kristensen,NA,TRUE,https://github.com/kaskr/tmbstan,9568,15,2019-09-13T07:47:27Z,637.8666666666667
Tmisc,"Miscellaneous utility functions for data manipulation,
    data tidying, and working with gene expression data.",2019-12-05,Stephen Turner,"https://github.com/stephenturner/Tmisc,
http://stephenturner.github.io/Tmisc",TRUE,https://github.com/stephenturner/tmisc,22048,7,2019-12-05T14:25:48Z,3149.714285714286
tmt,"Provides conditional maximum likelihood (CML) estimation of item parameters in multistage designs (Zwitser & Maris, 2013, <doi:10.1007/s11336-013-9369-6>) and CML estimation for conventional designs. Additional features are the likelihood ratio test (Andersen, 1973, <doi:10.1007/BF02291180>) and simulation of multistage designs. ",2019-07-05,Jan Steinfeld,https://jansteinfeld.github.io/tmt,TRUE,https://github.com/jansteinfeld/tmt,4544,2,2019-10-10T15:36:50Z,2272
tmuxr,"Create, control, and capture 'tmux' sessions, windows, and panes
    using a pipeable API.",2020-05-22,Jeroen Janssens,"https://datascienceworkshops.github.io/tmuxr,
https://github.com/datascienceworkshops/tmuxr",TRUE,https://github.com/datascienceworkshops/tmuxr,588,24,2020-05-22T09:16:58Z,24.5
TOC,"Construction of the Total Operating Characteristic (TOC) Curve and the Receiver (aka Relative) Operating Characteristic (ROC) Curve for spatial and non-spatial data. The TOC method is a modification of the ROC method which measures the ability of an index variable to diagnose either presence or absence of a characteristic. The diagnosis depends on whether the value of an index variable is above a threshold. Each threshold generates a two-by-two contingency table, which contains four entries: hits (H), misses (M), false alarms (FA), and correct rejections (CR). While ROC shows for each threshold only two ratios, H/(H + M) and FA/(FA + CR), TOC reveals the size of every entry in the contingency table for each threshold (Pontius Jr., R.G., Si, K. 2014. <doi:10.1080/13658816.2013.862623>). ",2020-05-06,Robert G. Pontius,https://github.com/amsantac/TOC,TRUE,https://github.com/amsantac/toc,14789,2,2020-05-10T04:24:06Z,7394.5
togglr,Use the <http://toggl.com> time tracker api through R.,2018-08-13,Vincent Guyader,https://github.com/ThinkR-open/togglr,TRUE,https://github.com/thinkr-open/togglr,8159,25,2019-10-29T08:40:52Z,326.36
tokenizers,"Convert natural language text into tokens. Includes tokenizers for
    shingled n-grams, skip n-grams, words, word stems, sentences, paragraphs,
    characters, shingled characters, lines, tweets, Penn Treebank, regular
    expressions, as well as functions for counting characters, words, and sentences,
    and a function for splitting longer texts into separate documents, each with
    the same number of words.  The tokenizers have a consistent interface, and
    the package is built on the 'stringi' and 'Rcpp' packages for  fast
    yet correct tokenization in 'UTF-8'. ",2018-03-29,Lincoln Mullen,https://lincolnmullen.com/software/tokenizers/,TRUE,https://github.com/ropensci/tokenizers,1651932,149,2019-12-16T20:05:37Z,11086.791946308726
tokenizers.bpe,Unsupervised text tokenizer focused on computational efficiency. Wraps the 'YouTokenToMe' library <https://github.com/VKCOM/YouTokenToMe> which is an implementation of fast Byte Pair Encoding (BPE) <https://www.aclweb.org/anthology/P16-1162>.,2019-08-02,Jan Wijffels,https://github.com/bnosac/tokenizers.bpe,TRUE,https://github.com/bnosac/tokenizers.bpe,3444,8,2019-07-31T21:00:14Z,430.5
topicdoc,"Calculates topic-specific diagnostics (e.g. mean token length, exclusivity) for 
    Latent Dirichlet Allocation and Correlated Topic Models fit using the 'topicmodels' package.
    For more details, see Chapter 12 in Airoldi et al. (2014, ISBN:9781466504080), 
    pp 262-272 Mimno et al. (2011, ISBN:9781937284114), and Bischof et al. (2014) <arXiv:1206.4631v1>.",2019-10-18,Doug Friedman,https://github.com/doug-friedman/topicdoc,TRUE,https://github.com/doug-friedman/topicdoc,2824,8,2019-10-22T00:42:08Z,353
tor,"The goal of tor (to-R) is to help you to import
    multiple files from a single directory at once, and to do so as
    quickly, flexibly, and simply as possible.",2020-03-07,Mauro Lepore,https://github.com/maurolepore/tor,TRUE,https://github.com/maurolepore/tor,6103,19,2020-03-09T12:24:55Z,321.2105263157895
tosca,"A framework for statistical analysis in content analysis. In addition to a pipeline for preprocessing text corpora and linking to the latent Dirichlet allocation from the 'lda' package, plots are offered for the descriptive analysis of text corpora and topic models. In addition, an implementation of Chang's intruder words and intruder topics is provided.",2020-03-10,Lars Koppers,"https://github.com/Docma-TU/tosca,
https://doi.org/10.5281/zenodo.3591068",TRUE,https://github.com/docma-tu/tosca,7430,12,2020-03-10T14:51:49Z,619.1666666666666
totalcensus,"Download summary files from Census Bureau <https://www2.census.gov/> 
    and extract data, in particular high resolution data at 
    block, block group, and tract level, from decennial census and 
    American Community Survey 1-year and 5-year estimates.",2020-01-08,Guanglai Li,https://github.com/GL-Li/totalcensus,TRUE,https://github.com/gl-li/totalcensus,37791,29,2020-01-08T21:38:37Z,1303.1379310344828
touch,"R implementation of the software tools developed in the H-CUP
    (Healthcare Cost and Utilization Project) <https://www.hcup-us.ahrq.gov>
    and AHRQ (Agency for Healthcare Research and Quality)
    <https://www.ahrq.gov>.  It currently contains functions for mapping ICD-9
    codes to the AHRQ comorbidity measures and translating ICD-9
    (resp. ICD-10) codes to ICD-10 (resp. ICD-9) codes based on GEM (General
    Equivalence Mappings) from CMS (Centers for Medicare and Medicaid
    Services).",2019-11-17,Wenjie Wang,https://github.com/wenjie2wang/touch,TRUE,https://github.com/wenjie2wang/touch,9814,2,2019-11-18T02:28:28Z,4907
TouRnament,Contains two functions related to sports competitions. One to create league tables and one to create a match schedule.,2019-10-05,Tobias Wolfanger,NA,TRUE,https://github.com/captaincaracho/tournament,2759,0,2019-09-30T20:09:04Z,NA
tourr,"Implements geodesic interpolation and basis
    generation functions that allow you to create new tour
    methods from R.",2019-02-12,Di Cook,https://github.com/ggobi/tourr,TRUE,https://github.com/ggobi/tourr,27839,35,2020-05-26T10:35:13Z,795.4
toxEval,"Data analysis package for estimating potential biological effects from chemical concentrations in environmental samples. Included are a set of functions to analyze, visualize, and organize measured concentration data as it relates to user-selected chemical-biological interaction benchmark data such as water quality criteria. The intent of these analyses is to develop a better understanding of the potential biological relevance of environmental chemistry data. Results can be used to prioritize which chemicals at which sites may be of greatest concern. These methods are meant to be used as a screening technique to predict potential for biological influence from chemicals that ultimately need to be validated with direct biological assays. A description of the analysis can be found in Blackwell et al. (2017) <doi:10.1021/acs.est.7b01613>.",2019-11-26,Laura DeCicco,NA,TRUE,https://github.com/usgs-r/toxeval,5098,8,2020-05-15T22:30:29Z,637.25
TR8,"Plant ecologists often need to collect ""traits"" data
    about plant species which are often scattered among various
    databases: TR8 contains a set of tools which take care of
    automatically retrieving some of those functional traits data
    for plant species from publicly available databases (Biolflor,
    The Ecological Flora of the British Isles, LEDA traitbase, Ellenberg
    values for Italian Flora, Mycorrhizal intensity databases, Catminat, BROT,
    PLANTS, Jepson Flora Project).
    The TR8 name, inspired by ""car plates"" jokes, was chosen since
    it both reminds of the main object of the package and is
    extremely short to type.",2020-05-17,Gionata Bocci,https://github.com/GioBo/TR8,TRUE,https://github.com/giobo/tr8,18465,11,2020-05-17T12:49:08Z,1678.6363636363637
tracerer,"'BEAST2' (<https://www.beast2.org>) is a widely used
  Bayesian phylogenetic tool, that uses DNA/RNA/protein data
  and many model priors to create a posterior of jointly estimated 
  phylogenies and parameters.
  'Tracer' (<http://tree.bio.ed.ac.uk/software/tracer/>) is a GUI tool 
  to parse and analyze the files generated by 'BEAST2'.
  This package provides a way to parse and analyze 'BEAST2' input
  files without active user input, but using
  R function calls instead.",2020-05-06,Richèl J.C. Bilderbeek,"https://docs.ropensci.org/tracerer,
https://github.com/ropensci/tracerer",TRUE,https://github.com/ropensci/tracerer,7492,6,2020-04-27T13:47:34Z,1248.6666666666667
trackdem,"Obtain population density and body size structure, using video material or image sequences as input. Functions assist in the creation of image sequences from videos, background detection and subtraction, particle identification and tracking. An artificial neural network can be trained for noise filtering. The goal is to supply accurate estimates of population size, structure and/or individual behavior, for use in  evolutionary and ecological studies.",2020-02-27,Marjolein Bruijning,https://github.com/marjoleinbruijning/trackdem,TRUE,https://github.com/marjoleinbruijning/trackdem,12882,5,2020-02-10T20:48:08Z,2576.4
trackdf,"Data frame class for storing collective movement data (e.g. fish
    schools, ungulate herds, baboon troops) collected from GPS trackers or
    computer vision tracking software. ",2019-08-04,Simon Garnier,"https://swarm-lab.github.io/trackdf/,
https://github.com/swarm-lab/trackdf",TRUE,https://github.com/swarm-lab/trackdf,3911,2,2020-04-28T18:06:04Z,1955.5
trackeRapp,"Provides an integrated user interface and workflow for
             the analysis of running, cycling and swimming data from GPS-enabled
             tracking devices through the 'trackeR' <https://CRAN.R-project.org/package=trackeR> R package.",2020-05-03,Ioannis Kosmidis,https://github.com/trackerproject/trackeRapp,TRUE,https://github.com/trackerproject/trackerapp,4318,17,2020-05-04T11:27:44Z,254
tractor.base,"Functions for working with magnetic resonance images. Reading and
    writing of popular file formats (DICOM, Analyze, NIfTI-1, NIfTI-2, MGH);
    interactive and non-interactive visualisation; flexible image manipulation;
    metadata and sparse image handling.",2019-06-10,Jon Clayden,"http://www.tractor-mri.org.uk, https://github.com/tractor/tractor",TRUE,https://github.com/tractor/tractor,31594,21,2020-05-14T13:15:25Z,1504.4761904761904
tradestatistics,Access 'Open Trade Statistics' API from R to download international trade data.,2020-04-03,Mauricio Vargas,https://docs.ropensci.org/tradestatistics/,TRUE,https://github.com/ropensci/tradestatistics,7044,47,2020-04-03T18:08:04Z,149.87234042553192
TrafficBDE,"Estimate and return either the traffic speed or the car entries in the city of Thessaloniki using historical traffic data. It's used in transport pilot <http://trafficstatusprediction.imet.gr/> of the 'BigDataEurope' project <https://www.big-data-europe.eu/>. There are functions for processing these data, training a neural network, select the most appropriate model and predict the traffic speed or the car entries for a selected time date.",2018-03-01,Aikaterini Chatzopoulou,https://github.com/okgreece/TrafficBDE,TRUE,https://github.com/okgreece/trafficbde,6470,0,2019-07-06T22:23:55Z,NA
traipse,"A collection of commonly used tools for animal movement and other tracking 
 data. Variously distance, angle, bearing, distance-to, bearing-to and speed are 
 provided for geographic data that can be used directly or within 'tidyverse' 
 syntax. Distances and bearings are calculated using modern geodesic methods as 
 provided by Charles F. F. Karney (2013) <doi:10.1007/s00190-012-0578-z> 
 via the 'geodist' and 'geosphere' packages. ",2019-07-02,Michael Sumner,https://github.com/Trackage/traipse,TRUE,https://github.com/trackage/traipse,3496,13,2019-09-16T20:19:13Z,268.9230769230769
traitdataform,"Assistance for handling ecological trait data and applying the 
    Ecological Trait-Data Standard terminology (Schneider et al. 2019
    <doi:10.1111/2041-210X.13288>). There are two major use cases: (1) preparation of
    own trait datasets for upload into public data bases, and (2) harmonizing
    trait datasets from different sources by re-formatting them into a unified
    format. See 'traitdataform' website for full documentation. ",2020-04-05,Florian D. Schneider,"https://EcologicalTraitData.github.io/traitdataform,
https://github.com/EcologicalTraitData/traitdataform",TRUE,https://github.com/ecologicaltraitdata/traitdataform,6113,16,2020-04-04T22:14:45Z,382.0625
traits,"Species trait data from many different sources, including
    sequence data from 'NCBI', plant trait data from 'BETYdb', plant data
    from the USDA plants database, data from 'EOL' 'Traitbank', 
    Coral traits data (<https://coraltraits.org>), 'Birdlife' International, 
    and more.",2019-06-29,Scott Chamberlain,https://github.com/ropensci/traits,TRUE,https://github.com/ropensci/traits,26832,37,2019-12-09T19:39:38Z,725.1891891891892
trajectories,"Classes and methods for trajectory data, with support for nesting individual Track objects in track sets (Tracks) and track sets for different entities in collections of Tracks. Methods include selection, generalization, aggregation, intersection, simulation, and plotting.",2018-12-06,Edzer Pebesma,http://github.com/edzer/trajectories,TRUE,https://github.com/edzer/trajectories,22729,25,2019-11-21T21:45:27Z,909.16
trajr,"A toolbox to assist with statistical analysis of 2-dimensional animal trajectories.
    It provides simple access to algorithms for calculating and assessing a variety of 
    characteristics such as speed and acceleration, as well as multiple measures of 
    straightness or tortuosity. McLean & Skowron Volponi (2018) <doi:10.1111/eth.12739>.",2019-06-10,Jim McLean,https://github.com/JimMcL/trajr,TRUE,https://github.com/jimmcl/trajr,11132,12,2020-05-20T01:48:22Z,927.6666666666666
TRAMPR,"Matching terminal restriction fragment length
        polymorphism ('TRFLP') profiles between unknown samples and a
        database of known samples.  'TRAMPR' facilitates analysis of
        many unknown profiles at once, and provides tools for working
        directly with electrophoresis output through to generating
        summaries suitable for community analyses with R's rich set of
        statistical functions.  'TRAMPR' also resolves the issues of
        multiple 'TRFLP' profiles within a species, and shared 'TRFLP'
        profiles across species.",2020-02-28,Rich FitzJohn & Ian Dickie,https://github.com/richfitz/TRAMPR,TRUE,https://github.com/richfitz/trampr,17784,0,2020-02-28T15:35:52Z,NA
transmem,"Treatment and visualization of membrane (selective) transport 
    data. Transport profiles involving up to three species are produced as
    publication-ready plots and several membrane performance parameters 
    (e.g. separation factors as defined in Koros et al. (1996) 
    <doi:10.1351/pac199668071479> and non-linear regression parameters
    for the equations described in Rodriguez de San Miguel et al. (2014)
    <doi:10.1016/j.jhazmat.2014.03.052>) can be obtained. Many widely used 
    experimental setups (e.g. membrane physical aging) can be easily studied
    through the package's graphical representations. ",2020-06-05,Cristhian Paredes,https://CRAN.R-project.org/package=transmem,TRUE,https://github.com/crparedes/transmem,710,0,2020-06-06T21:36:40Z,NA
transplantr,"A set of vectorised functions to calculate medical equations used in transplantation, 
    focused mainly on transplantation of abdominal organs. These functions include donor and recipient
    risk indices as used by NHS Blood & Transplant, OPTN/UNOS and Eurotransplant, tools for 
    quantifying HLA mismatches, functions for calculating estimated glomerular filtration rate (eGFR), 
    a function to calculate the APRI (AST to platelet ratio) score used in initial screening of suitability to receive a 
    transplant from a hepatitis C seropositive donor and some biochemical unit converter functions. 
    All functions are designed to work with either US or international units.
    References for the equations are provided in the vignettes and function documentation.",2020-02-28,John Asher,"https://transplantr.txtools.net,
https://github.com/johnasher/transplantr",TRUE,https://github.com/johnasher/transplantr,2342,0,2020-02-28T00:20:18Z,NA
tranSurv,"A structural transformation model for a latent, quasi-independent truncation time as a function of the observed dependent truncation time and the event time, and an unknown dependence parameter. The dependence parameter is chosen to minimize the conditional Kendall's tau (Martin and Betensky, 2005) <doi:10.1198/016214504000001538>. The marginal distribution for the truncation time and the event time are completely left unspecified.",2019-05-24,Sy Han (Steven) Chiou,http://github.com/stc04003/tranSurv,TRUE,https://github.com/stc04003/transurv,8778,0,2020-06-07T06:15:39Z,NA
tree.interpreter,"An R re-implementation of the 'treeinterpreter' package on PyPI
        <https://pypi.org/project/treeinterpreter/>. Each prediction can be
        decomposed as 'prediction = bias + feature_1_contribution + ... +
        feature_n_contribution'. This decomposition is then used to calculate
        the Mean Decrease Impurity (MDI) and Mean Decrease Impurity using
        out-of-bag samples (MDI-oob) feature importance measures based on the
        work of Li et al. (2019) <arXiv:1906.10845>.",2020-02-05,Qingyao Sun,https://github.com/nalzok/tree.interpreter,TRUE,https://github.com/nalzok/tree.interpreter,2975,10,2020-01-28T21:42:14Z,297.5
treebase,"Interface to the API for 'TreeBASE' <http://treebase.org>
    from 'R.' 'TreeBASE' is a repository of user-submitted phylogenetic
    trees (of species, population, or genes) and the data used to create
    them.",2017-02-06,Carl Boettiger,https://github.com/ropensci/treebase,TRUE,https://github.com/ropensci/treebase,28365,8,2019-12-09T19:39:55Z,3545.625
TreeBUGS,"User-friendly analysis of hierarchical multinomial processing tree (MPT) 
    models that are often used in cognitive psychology. Implements the latent-trait 
    MPT approach (Klauer, 2010) <DOI:10.1007/s11336-009-9141-0> and the beta-MPT 
    approach (Smith & Batchelder, 2010) <DOI:10.1016/j.jmp.2009.06.007> to model 
    heterogeneity of participants. MPT models are conveniently specified by an
    .eqn-file as used by other MPT software and data are provided by a .csv-file 
    or directly in R. Models are either fitted by calling JAGS or by an MPT-tailored 
    Gibbs sampler in C++ (only for nonhierarchical and beta MPT models). Provides 
    tests of heterogeneity and MPT-tailored summaries and plotting functions.
    A detailed documentation is available in Heck, Arnold, & Arnold (2018) 
    <DOI:10.3758/s13428-017-0869-7>.",2020-05-31,Daniel W. Heck,https://github.com/denis-arnold/TreeBUGS,TRUE,https://github.com/denis-arnold/treebugs,17090,7,2020-05-30T19:29:58Z,2441.4285714285716
treefit,"Perform two types of analysis: 1) checking the
    goodness-of-fit of tree models to your single-cell gene expression
    data; and 2) deciding which tree best fits your data.",2020-03-10,Momoko Hayamizu,"https://hayamizu-lab.github.io/treefit-r/,
https://github.com/hayamizu-lab/treefit-r/",TRUE,https://github.com/hayamizu-lab/treefit-r,1371,1,2020-05-06T02:36:27Z,1371
treemapify,Provides 'ggplot2' geoms for drawing treemaps.,2019-01-30,David Wilkins,https://github.com/wilkox/treemapify,TRUE,https://github.com/wilkox/treemapify,86187,175,2020-05-03T00:27:39Z,492.4971428571429
treenomial,"Provides functionality for creation and comparison of polynomials that uniquely
  describe trees as introduced in Liu (2019, <arXiv:1904.03332>). The core method
  converts rooted unlabeled phylo objects from 'ape' to the tree defining polynomials 
  described with coefficient matrices. Additionally, a conversion for rooted binary trees 
  with binary trait labels is also provided. Once the polynomials of trees are calculated 
  there are functions to calculate distances, distance matrices and plot different distance 
  trees from a target tree. Manipulation and conversion to the tree defining polynomials is 
  implemented in C++ with 'Rcpp' and 'RcppArmadillo'. Furthermore, parallel programming with 
  'RcppThread' is used to improve performance converting to polynomials and calculating distances. ",2020-02-13,Matthew Gould,https://github.com/mattgou1d/treenomial,TRUE,https://github.com/mattgou1d/treenomial,2714,1,2020-01-04T01:30:19Z,2714
treeplyr,"Matches phylogenetic trees and trait data, and
    allows simultaneous manipulation of the tree and data using 'dplyr'.",2019-07-25,Josef Uyeda,https://github.com/uyedaj/treeplyr,TRUE,https://github.com/uyedaj/treeplyr,15518,30,2020-06-04T17:22:16Z,517.2666666666667
TreeSearch,"Searches for phylogenetic trees that are optimal using a 
  user-defined criterion. 
  Handles inapplicable data using the algorithm of 
  Brazeau, Guillerme and Smith (2019) <doi:10.1093/sysbio/syy083>.
  Implements Profile Parsimony (Faith and Trueman, 2001) 
  <doi:10.1080/10635150118627>, and Successive Approximations (Farris, 1969) 
  <doi:10.2307/2412182>.",2020-06-09,Martin R. Smith,"https://ms609.github.io/TreeSearch,
https://github.com/ms609/TreeSearch",TRUE,https://github.com/ms609/treesearch,11074,0,2020-06-09T08:35:55Z,NA
treespace,"Tools for the exploration of distributions of phylogenetic trees.
    This package includes a 'shiny' interface which can be started from R using
    treespaceServer(). 
    For further details see Jombart et al. (2017) <DOI:10.1111/1755-0998.12676>.",2019-12-08,Michelle Kendall,"https://cran.r-project.org/package=treespace,
https://github.com/thibautjombart/treespace",TRUE,https://github.com/thibautjombart/treespace,12873,16,2020-03-02T12:07:54Z,804.5625
treestartr,"Combine a list of taxa with a phylogeny to generate a starting tree for use in
    total evidence dating analyses.",2019-01-09,April Wright,https://ropensci.github.io/treeStartR/,TRUE,https://github.com/ropensci/treestartr,4964,7,2019-12-05T19:03:31Z,709.1428571428571
TreeTools,"Efficient implementations of functions for the creation, 
  modification and analysis of phylogenetic trees.
  Applications include: generation of trees with specified shapes;
  rooting of trees and extraction of subtrees;
  calculation and depiction of node support;
  calculation of ancestor-descendant relationships;
  import and export of trees from Newick, Nexus (Maddison et al. 1997)
  <doi:10.1093/sysbio/46.4.590>,
  and TNT <http://www.lillo.org.ar/phylogeny/tnt/> formats;
  and
  analysis of partitions and cladistic information.",2020-06-08,Martin R. Smith,"https://ms609.github.io/TreeTools/,
https://github.com/ms609/TreeTools/",TRUE,https://github.com/ms609/treetools,3962,3,2020-06-08T10:36:44Z,1320.6666666666667
trekcolors,"Provides a dataset of predefined color palettes based on the Star Trek science fiction series, associated color palette functions, 
    and additional functions for generating customized palettes that are on theme. The package also offers functions for applying 
    the palettes to plots made using the 'ggplot2' package.",2019-10-16,Matthew Leonawicz,https://github.com/leonawicz/trekcolors,TRUE,https://github.com/leonawicz/trekcolors,2755,5,2020-01-18T19:25:10Z,551
trekfont,Provides a collection of true type and open type Star Trek-themed fonts.,2018-11-12,Matthew Leonawicz,https://github.com/leonawicz/trekfont,TRUE,https://github.com/leonawicz/trekfont,7410,7,2020-01-18T19:26:09Z,1058.5714285714287
trelliscopejs,"Trelliscope is a scalable, flexible, interactive approach to visualizing data (Hafen, 2013 <doi:10.1109/LDAV.2013.6675164>). This package provides methods that make it easy to create a Trelliscope display specification for TrelliscopeJS. High-level functions are provided for creating displays from within 'tidyverse' or 'ggplot2' workflows. Low-level functions are also provided for creating new interfaces.",2020-05-28,Ryan Hafen,https://github.com/hafen/trelliscopejs,TRUE,https://github.com/hafen/trelliscopejs,13565,193,2020-05-27T20:16:44Z,70.28497409326425
trelloR,"Provides access to Trello API (<https://developers.trello.com/>).
    A family of GET functions make it easy to retrieve cards, labels, members,
    teams and other data from both public and private boards. Server responses
    are formatted upon retrieval. Automated paging allows for large requests
    that exceed server limit. See <https://github.com/jchrom/trelloR> for more
    information.",2016-09-23,Jakub Chromec,https://github.com/jchrom/trelloR,TRUE,https://github.com/jchrom/trellor,10676,20,2020-05-14T19:55:34Z,533.8
TRES,"Provides three estimators for tensor response regression (TRR) and tensor predictor regression (TPR) models with tensor envelope structure. The three types of estimation approaches are generic and can be applied to any envelope estimation problems. The full Grassmannian (FG) optimization is often associated with likelihood-based estimation but requires heavy computation and good initialization; the one-directional optimization approaches (1D and ECD algorithms) are faster, stable and does not require carefully chosen initial values; the SIMPLS-type is motivated by the partial least squares regression and is computationally the least expensive. For details of TRR, see Li L, Zhang X (2017) <doi:10.1080/01621459.2016.1193022>. For details of TPR, see Zhang X, Li L (2017) <doi:10.1080/00401706.2016.1272495>. For details of 1D algorithm, see Cook RD, Zhang X (2016) <doi:10.1080/10618600.2015.1029577>. For details of ECD algorithm, see Cook RD, Zhang X (2018) <doi:10.5705/ss.202016.0037>.",2020-02-05,Jing Zeng,https://github.com/jerryfsu3333/TRES,TRUE,https://github.com/jerryfsu3333/tres,5380,0,2020-02-05T16:21:31Z,NA
trialr,"A collection of clinical trial designs and methods, implemented in 
    'rstan' and R, including: the Continual Reassessment Method by O'Quigley et 
    al. (1990) <doi:10.2307/2531628>; EffTox by Thall & Cook (2004) 
    <doi:10.1111/j.0006-341X.2004.00218.x>; and the Augmented Binary method by 
    Wason & Seaman (2013) <doi:10.1002/sim.5867>; and more. We provide functions 
    to aid model-fitting and analysis. The 'rstan' implementations may also 
    serve as a cookbook to anyone looking to extend or embellish these models. 
    We hope that this package encourages the use of Bayesian methods in clinical 
    trials. There is a preponderance of early phase trial designs because this 
    is where Bayesian methods are used most. If there is a method you would like 
    implemented, please get in touch.",2020-04-06,Kristian Brock,https://github.com/brockk/trialr,TRUE,https://github.com/brockk/trialr,11563,30,2020-04-06T11:45:01Z,385.43333333333334
triangle,"Provides the ""r, q, p, and d"" distribution functions for the triangle distribution.",2019-02-14,Rob Carnell,https://bertcarnell.github.io/triangle/,TRUE,https://github.com/bertcarnell/triangle,121691,1,2020-05-29T19:55:08Z,121691
tribe,"Functions to make manipulation of object attributes easier. 
    It also contains a few functions that extend the 'dplyr' package for data 
    manipulation, and it provides new pipe operators, including the pipe '%@>%' 
    similar to the 'magrittr' '%>%', but with the additional functionality to 
    enable attributes propagation. ",2019-11-23,Paul Poncet,https://github.com/paulponcet/tribe,TRUE,https://github.com/paulponcet/tribe,8577,3,2019-11-23T22:29:40Z,2859
trip,"Functions for accessing and manipulating spatial data for animal
    tracking, with straightforward coercion from and to other formats. Filter
    for speed and create time spent maps from animal track data. There are
    coercion methods to convert between 'trip' and 'ltraj' from 'adehabitatLT', 
    and between 'trip' and 'psp' and 'ppp' from 'spatstat'. Trip objects
    can be created from raw or grouped data frames, and from types in the 'sp', 
    'sf', 'amt', 'trackeR', 'mousetrap', and other packages. ",2019-04-15,Michael D. Sumner,https://github.com/mdsumner/trip,TRUE,https://github.com/mdsumner/trip,34746,6,2020-06-04T15:20:07Z,5791
tripEstimation,"Data handling and estimation functions for animal movement
    estimation from archival or satellite tags. Helper functions are included
    for making image summaries binned by time interval from Markov Chain Monte Carlo
    simulations. ",2016-01-31,Michael D. Sumner,https://github.com/mdsumner/tripEstimation,TRUE,https://github.com/mdsumner/tripestimation,25873,4,2019-09-24T23:12:04Z,6468.25
triplot,"Tools for exploring effects of correlated features in predictive 
    models. The predict_triplot() function delivers instance-level explanations 
    that calculate the importance of the groups of explanatory variables. The 
    model_triplot() function delivers data-level explanations. The generic plot 
    function visualises in a concise way importance of hierarchical groups of 
    predictors. All of the the tools are model agnostic, therefore works for any
    predictive machine learning models. Find more details in Biecek (2018) 
    <arXiv:1806.08915>.",2020-06-09,Katarzyna Pekala,https://github.com/ModelOriented/triplot,TRUE,https://github.com/modeloriented/triplot,0,4,2020-06-05T11:15:32Z,0
tripsAndDipR,"Uses read counts for biallelic single nucleotide polymorphisms (SNPs)
    to compare the likelihoods for the observed read counts given that a sample is 
    either diploid or triploid. It allows parameters to be specified to account for 
    sequencing error rates and allelic bias. For details of the algorithm, please see
    Delomas (2019) <doi:10.1111/1755-0998.13073>.",2019-08-28,Thomas Delomas,https://github.com/delomast/tripsAndDipR,TRUE,https://github.com/delomast/tripsanddipr,4666,0,2020-05-19T22:20:30Z,NA
TropFishR,"A compilation of fish stock assessment methods for the
    analysis of length-frequency data in the context of data-poor
    fisheries. Includes methods and examples included in the FAO
    Manual by P. Sparre and S.C. Venema (1998), ""Introduction to tropical fish
    stock assessment""
    (<http://www.fao.org/documents/card/en/c/9bb12a06-2f05-5dcb-a6ca-2d6dd3080f65/>),
    as well as other more recent methods.",2020-01-28,Tobias K. Mildenberger,https://github.com/tokami/TropFishR,TRUE,https://github.com/tokami/tropfishr,23815,8,2020-01-28T15:52:16Z,2976.875
tRophicPosition,"Estimates the trophic position of a consumer relative 
    to a baseline species. It implements a Bayesian approach which combines an 
    interface to the 'JAGS' MCMC library of 'rjags' and stable isotopes. Users are
    encouraged to test the package and send bugs and/or errors to
    trophicposition-support@googlegroups.com.",2019-04-06,Claudio Quezada-Romegialli,https://github.com/clquezada/tRophicPosition,TRUE,https://github.com/clquezada/trophicposition,10145,9,2019-06-16T00:20:16Z,1127.2222222222222
truelies,"Implements Bayesian methods, described in
    Hugh-Jones (2019) <doi:10.1007/s40881-019-00069-x>, for estimating the
    proportion of liars in coin flip-style experiments, where subjects
    report a random outcome and are paid for reporting a ""good"" outcome.",2019-08-26,David Hugh-Jones,https://github.com/hughjonesd/truelies,TRUE,https://github.com/hughjonesd/truelies,3789,0,2019-08-26T20:29:10Z,NA
TruncatedNormal,"A collection of functions to deal with the truncated univariate and multivariate normal and Student distributions, described in Botev (2017) <doi:10.1111/rssb.12162> and Botev and L'Ecuyer (2015) <doi:10.1109/WSC.2015.7408180>.",2020-05-17,Zdravko Botev,NA,TRUE,https://github.com/lbelzile/truncatednormal,24737,2,2020-05-17T11:54:39Z,12368.5
trustedtimestamping,"Trusted Timestamps (tts) are created by incorporating a hash of a file or dataset into a transaction on the decentralized blockchain (Stellar network). 
    The package makes use of a free service provided by <https://stellarapi.io>.",2019-07-30,Peter Muller,NA,TRUE,https://github.com/ttspackage/tts,3383,3,2019-07-31T09:25:38Z,1127.6666666666667
tryCatchLog,"Advanced tryCatch() and try() functions for better error handling
             (logging, stack trace with source code references and support for post-mortem analysis via dump files).",2019-11-06,Juergen Altfeld,https://github.com/aryoda/tryCatchLog,TRUE,https://github.com/aryoda/trycatchlog,12110,27,2020-04-29T16:29:57Z,448.51851851851853
tsbox,"Time series toolkit with identical behavior for all
  time series classes: 'ts','xts', 'data.frame', 'data.table', 'tibble', 'zoo',
  'timeSeries', 'tsibble', 'tis' or 'irts'. Also converts reliably between these classes.",2020-04-29,Christoph Sax,https://www.tsbox.help,TRUE,https://github.com/christophsax/tsbox,38723,110,2020-05-01T13:02:55Z,352.0272727272727
tsdb,"A terribly-simple data base for numeric
  time series, written purely in R, so no external
  database-software is needed. Series are stored in
  plain-text files (the most-portable and enduring file
  type) in CSV format. Timestamps are encoded using R's
  native numeric representation for 'Date'/'POSIXct',
  which makes them fast to parse, but keeps them
  accessible with other software. The package provides
  tools for saving and updating series in this
  standardised format, for retrieving and joining data,
  for summarising files and directories, and for
  coercing series from and to other data types (such as
  'zoo' series).",2019-08-29,Enrico Schumann,"http://enricoschumann.net/R/packages/tsdb,
https://github.com/enricoschumann/tsdb,
https://gitlab.com/enricoschumann/tsdb",TRUE,https://github.com/enricoschumann/tsdb,4641,1,2020-02-28T13:10:01Z,4641
tsfeatures,"Methods for extracting various features from time series data. The features provided are those from Hyndman, Wang and Laptev (2013) <doi:10.1109/ICDMW.2015.104>, Kang, Hyndman and Smith-Miles (2017) <doi:10.1016/j.ijforecast.2016.09.004> and from Fulcher, Little and Jones (2013) <doi:10.1098/rsif.2013.0048>. Features include spectral entropy, autocorrelations, measures of the strength of seasonality and trend, and so on. Users can also define their own feature functions.",2020-06-07,Rob Hyndman,https://pkg.robjhyndman.com/tsfeatures/,TRUE,https://github.com/robjhyndman/tsfeatures,22581,168,2020-06-07T00:13:52Z,134.41071428571428
tsfgrnn,"A general regression neural network (GRNN) is a variant of a
    Radial Basis Function Network characterized by a fast single-pass learning.
    'tsfgrnn' allows you to forecast time series using a GRNN model Francisco 
    Martinez et al. (2019) <doi:10.1007/978-3-030-20521-8_17> and Weizhong Yan
    (2012) <doi:10.1109/TNNLS.2012.2198074>. When the forecasting horizon
    is higher than 1, two multi-step ahead forecasting strategies can be used.
    The model built is autoregressive, that is, it is only based on the 
    observations of the time series. You can consult and plot how the
    prediction was done. It is also possible to assess the forecasting accuracy
    of the model using rolling origin evaluation.",2019-11-25,Francisco Martinez,https://github.com/franciscomartinezdelrio/tsfgrnn,TRUE,https://github.com/franciscomartinezdelrio/tsfgrnn,2508,3,2020-06-05T10:43:54Z,836
tsfknn,"Allows to forecast time series using nearest neighbors regression
    Francisco Martinez, Maria P. Frias, Maria D. Perez-Godoy and Antonio J.
    Rivera (2017) <doi:10.1007/s10462-017-9593-z>. When the forecasting horizon
    is higher than 1, two multi-step ahead forecasting strategies can be used.
    The model built is autoregressive, that is, it is only based on the 
    observations of the time series. The nearest neighbors used in a prediction
    can be consulted and plotted.",2020-06-04,Francisco Martinez,https://github.com/franciscomartinezdelrio/tsfknn,TRUE,https://github.com/franciscomartinezdelrio/tsfknn,11173,7,2020-06-04T08:25:37Z,1596.142857142857
tsibble,"Provides a 'tbl_ts' class (the 'tsibble') for
    temporal data in an data- and model-oriented format. The 'tsibble'
    provides tools to easily manipulate and analyse temporal data, such as
    filling in time gaps and aggregating over calendar periods.",2020-06-04,Earo Wang,https://tsibble.tidyverts.org,TRUE,https://github.com/tidyverts/tsibble,140074,322,2020-06-03T09:16:30Z,435.0124223602484
tsibbledata,"Provides diverse datasets in the 'tsibble' data structure. These datasets are useful for learning and demonstrating how tidy temporal data can tidied, visualised, and forecasted.",2020-06-04,Mitchell OHara-Wild,"http://tsibbledata.tidyverts.org/,
https://github.com/tidyverts/tsibbledata/",TRUE,https://github.com/tidyverts/tsibbledata,15644,13,2020-06-05T11:34:39Z,1203.3846153846155
tsmp,"A toolkit implementing the Matrix Profile concept
    that was created by CS-UCR
    <http://www.cs.ucr.edu/~eamonn/MatrixProfile.html>.",2020-04-06,Francisco Bischoff,https://github.com/matrix-profile-foundation/tsmp,TRUE,https://github.com/matrix-profile-foundation/tsmp,9151,37,2020-05-24T00:35:47Z,247.32432432432432
tsne,"A ""pure R"" implementation of the t-SNE algorithm.",2016-07-15,Justin Donaldson,https://github.com/jdonaldson/rtsne/,TRUE,https://github.com/jdonaldson/rtsne,227887,49,2019-08-27T17:50:58Z,4650.755102040816
TSP,"Basic infrastructure and some algorithms for the traveling
    salesperson problem (also traveling salesman problem; TSP).
    The package provides some simple algorithms and
    an interface to the Concorde TSP solver and its implementation of the
    Chained-Lin-Kernighan heuristic. The code for Concorde
    itself is not included in the package and has to be obtained separately.
    Hahsler and Hornik (2007) <doi:10.18637/jss.v023.i02>.",2020-04-17,Michael Hahsler,https://github.com/mhahsler/TSP,TRUE,https://github.com/mhahsler/tsp,953954,38,2020-04-17T15:03:22Z,25104.052631578947
tsPI,"Prediction intervals for ARIMA and structural time series
    models using importance sampling approach with uninformative priors for model
    parameters, leading to more accurate coverage probabilities in frequentist
    sense. Instead of sampling the future observations and hidden states of the
    state space representation of the model, only model parameters are sampled,
    and the method is based solving the equations corresponding to the conditional
    coverage probability of the prediction intervals. This makes method relatively
    fast compared to for example MCMC methods, and standard errors of prediction
    limits can also be computed straightforwardly.",2019-12-05,Jouni Helske,NA,TRUE,https://github.com/helske/tspi,17572,8,2019-12-05T09:07:05Z,2196.5
TSrepr,"Methods for representations (i.e. dimensionality reduction, preprocessing, feature extraction) of time series to help more accurate and effective time series data mining.
    Non-data adaptive, data adaptive, model-based and data dictated (clipped) representation methods are implemented. Also min-max and z-score normalisations, and forecasting accuracy measures are implemented.",2020-03-25,Peter Laurinec,"https://petolau.github.io/package/,
https://github.com/PetoLau/TSrepr/",TRUE,https://github.com/petolau/tsrepr,16184,66,2020-04-22T16:06:20Z,245.21212121212122
TSstudio,Provides a set of tools for descriptive and predictive analysis of time series data. That includes functions for interactive visualization of time series objects and as well utility functions for automation time series forecasting.,2020-01-21,Rami Krispin,https://github.com/RamiKrispin/TSstudio,TRUE,https://github.com/ramikrispin/tsstudio,27159,236,2020-02-25T21:47:25Z,115.08050847457628
tsutils,"Includes: (i) tests and visualisations that can help the modeller explore time series components and perform decomposition; (ii) modelling shortcuts, such as functions to construct lagmatrices and seasonal dummy variables of various forms; (iii) an implementation of the Theta method; (iv) tools to facilitate the design of the forecasting process, such as ABC-XYZ analyses; and (v) ""quality of life"" functions, such as treating time series for trailing and leading values.",2020-02-06,Nikolaos Kourentzes,https://github.com/trnnick/tsutils/,TRUE,https://github.com/trnnick/tsutils,31492,7,2020-02-06T05:17:09Z,4498.857142857143
tsviz,An 'RStudio' add-in to visualize time series. Time series are searched in the global environment as data.frame objects with a column of type date and a column of type numeric. Interactive charts are produced using 'plotly' package.,2019-07-26,Emanuele Fabbiani,https://github.com/donlelef/tsviz,TRUE,https://github.com/donlelef/tsviz,3652,22,2019-07-28T16:51:25Z,166
TTR,Functions and data to construct technical trading rules with R.,2019-12-15,Joshua Ulrich,https://github.com/joshuaulrich/TTR,TRUE,https://github.com/joshuaulrich/ttr,5451215,210,2020-04-08T19:33:08Z,25958.166666666668
tuber,"Get comments posted on YouTube videos, information on how many 
    times a video has been liked, search for videos with particular content, and 
    much more. You can also scrape captions from a few videos. To learn more about
    the YouTube API, see <https://developers.google.com/youtube/v3/>.",2019-06-26,Gaurav Sood,http://github.com/soodoku/tuber,TRUE,https://github.com/soodoku/tuber,37159,127,2020-06-05T18:56:23Z,292.59055118110234
tufte,Provides R Markdown output formats to use Tufte styles for PDF and HTML output.,2020-05-08,Yihui Xie,https://github.com/rstudio/tufte,TRUE,https://github.com/rstudio/tufte,196862,223,2020-05-08T14:55:41Z,882.7892376681615
tune,"The ability to tune models is important. 'tune' contains functions and
    classes to be used in conjunction with other 'tidymodels' packages for 
    finding reasonable values of hyper-parameters in models, pre-processing
    methods, and post-processing steps. ",2020-04-02,Max Kuhn,https://github.com/tidymodels/tune,TRUE,https://github.com/tidymodels/tune,39464,79,2020-06-09T22:08:17Z,499.54430379746833
tvR,"Provides tools for denoising noisy signal and images via
    Total Variation Regularization. Reducing the total variation of
    the given signal is known to remove spurious detail while preserving
    essential structural details. For the seminal work on the topic,
    see Rudin et al (1992) <doi:10.1016/0167-2789(92)90242-F>.",2019-10-27,Kisung You,http://github.com/kyoustat/tvR,TRUE,https://github.com/kyoustat/tvr,8964,1,2019-11-15T04:07:55Z,8964
tvReg,"Fitting time-varying coefficient models both for single and multi-equation regressions, using kernel smoothing techniques.",2020-04-30,Isabel Casas,http://github.com/icasas/tvReg,TRUE,https://github.com/icasas/tvreg,11714,3,2020-04-21T19:13:21Z,3904.6666666666665
tvthemes,"Contains various 'ggplot2' themes and color palettes based on TV shows 
    such as 'Game of Thrones', 'Brooklyn Nine-Nine', 'Avatar: The Last Airbender',
    'Spongebob Squarepants', and more.",2019-10-31,Ryo Nakagawara,https://github.com/Ryo-N7/tvthemes,TRUE,https://github.com/ryo-n7/tvthemes,3549,75,2019-11-17T03:36:53Z,47.32
TwitterAutomatedTrading,"Provides an integration to the 'metatrader 5'. 
    The functionalities carry out automated trading using
    sentiment indexes computed from 'twitter' and/or 'stockwits'. 
    The sentiment indexes are based on the ph.d. dissertation 
    ""Essays on Economic Forecasting Models"" (Godeiro,2018) <https://repositorio.ufpb.br/jspui/handle/123456789/15198>
    The integration between the 'R' and the 'metatrader 5' allows sending buy/sell orders to the brokerage. ",2020-05-31,Lucas Godeiro,https://github.com/lucasgodeiro/TwitterAutomatedTrading,TRUE,https://github.com/lucasgodeiro/twitterautomatedtrading,9,1,2020-06-06T16:29:08Z,9
twitterwidget,"Include the Twitter status widgets in HTML pages created
  using R markdown. The package uses the Twitter javascript APIs to
  embed in your document Twitter cards associated to specific statuses.
  The main targets are regular HTML pages or dashboards.",2019-07-10,Guido Volpi,https://github.com/guivo/twitterwidget,TRUE,https://github.com/guivo/twitterwidget,3599,2,2019-07-10T13:26:19Z,1799.5
TwoRegression,"Application of two-regression algorithms for wearable
    research devices. It provides an easy way for users to read in
    device data files and apply an appropriate two-regression
    algorithm. More information is available from
    Hibbing PR, LaMunion SR, Kaplan AS, & Crouter SE (2017)
    <doi:10.1249/MSS.0000000000001532>.",2018-03-19,Paul R. Hibbing,https://github.com/paulhibbing/TwoRegression,TRUE,https://github.com/paulhibbing/tworegression,6537,0,2019-12-09T08:25:15Z,NA
twoway,"Carries out analyses of two-way tables with one observation per cell, together with graphical displays 
    for an additive fit and
    a diagnostic plot for removable 'non-additivity' via a power transformation of the response.
    It implements Tukey's Exploratory Data Analysis methods, including a 
    1-degree-of-freedom test for row*column 'non-additivity', linear in the row and column effects.",2018-08-24,Michael Friendly,https://github.com/friendly/twoway,TRUE,https://github.com/friendly/twoway,5793,2,2019-11-20T14:29:37Z,2896.5
txtq,"This queue is a data structure that lets
  parallel processes send and receive messages,
  and it can help coordinate the work
  of complicated parallel tasks.
  Processes can push new messages to the queue,
  pop old messages, and obtain a
  log of all the messages ever pushed. File locking
  preserves the integrity of the data even when
  multiple processes access the queue simultaneously.",2019-10-15,William Michael Landau,https://github.com/wlandau/txtq,TRUE,https://github.com/wlandau/txtq,31950,18,2020-04-14T17:51:18Z,1775
ubiquity,"Complete work flow for the analysis of pharmacokinetic pharmacodynamic (PKPD), physiologically-based pharmacokinetic (PBPK) and systems pharmacology models including: creation of ordinary differential equation-based models, pooled parameter estimation, individual/population based simulations, rule-based simulations for clinical trial design and modeling assays, deployment with a customizable 'Shiny' app, and non-compartmental analysis. System-specific analysis templates can be generated and each element includes integrated reporting with 'PowerPoint' and 'Word'. ",2020-01-21,John Harrold,https://r.ubiquity.tools/,TRUE,https://github.com/john-harrold/ubiquity,3116,6,2020-06-09T16:04:11Z,519.3333333333334
UCSCXenaShiny,"Provides a web app for downloading, analyzing and
    visualizing datasets from UCSC Xena (<http://xena.ucsc.edu/>), which is a collection of
    UCSC-hosted public databases such as TCGA, ICGC, TARGET, GTEx, CCLE,
    and others.",2020-06-03,Shixiang Wang,https://github.com/openbiox/XenaShiny,TRUE,https://github.com/openbiox/xenashiny,4770,18,2020-06-03T13:22:33Z,265
UCSCXenaTools,"Download and explore datasets from UCSC Xena data hubs, which are
    a collection of UCSC-hosted public databases such as TCGA, ICGC, TARGET, GTEx, CCLE, and others.
    Databases are normalized so they can be combined, linked, filtered, explored and downloaded.",2020-03-18,Shixiang Wang,"https://docs.ropensci.org/UCSCXenaTools,
https://github.com/ropensci/UCSCXenaTools",TRUE,https://github.com/ropensci/ucscxenatools,15784,36,2020-03-18T09:12:49Z,438.44444444444446
udpipe,"This natural language processing toolkit provides language-agnostic
    'tokenization', 'parts of speech tagging', 'lemmatization' and 'dependency
    parsing' of raw text. Next to text parsing, the package also allows you to train
    annotation models based on data of 'treebanks' in 'CoNLL-U' format as provided
    at <http://universaldependencies.org/format.html>. The techniques are explained
    in detail in the paper: 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0
    with UDPipe', available at <doi:10.18653/v1/K17-3009>.",2019-07-05,Jan Wijffels,"https://bnosac.github.io/udpipe/en/index.html,
https://github.com/bnosac/udpipe",TRUE,https://github.com/bnosac/udpipe,66635,145,2020-04-27T13:01:49Z,459.55172413793105
uiucthemes,"A set of custom 'R' 'Markdown' templates for documents and
   presentations with the University of Illinois at Urbana-Champaign (UIUC)
   color scheme and identity standards.",2019-10-02,James Balamuta,"https://github.com/illinois-r/uiucthemes,
http://thecoatlessprofessor.com/projects/uiucthemes/",TRUE,https://github.com/illinois-r/uiucthemes,10805,34,2020-06-07T13:54:16Z,317.79411764705884
ukbabynames,"Full listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994.",2017-06-20,Thomas J. Leeper,http://github.com/leeper/ukbabynames,TRUE,https://github.com/leeper/ukbabynames,10155,9,2019-06-20T21:39:15Z,1128.3333333333333
ukgasapi,Allows users to access live UK gas market information via National Grid's API.,2019-11-14,Timothy Wong,NA,TRUE,https://github.com/timothy-wong/ukgasapi,13497,0,2019-11-14T20:54:01Z,NA
UKgrid,A time series of the national grid demand (high-voltage electric power transmission network) in the UK since 2011.,2019-12-10,Rami Krispin,https://github.com/RamiKrispin/UKgrid,TRUE,https://github.com/ramikrispin/ukgrid,7097,23,2019-12-10T18:30:22Z,308.5652173913044
uklr,"Access data from Land Registry Open Data
    <http://landregistry.data.gov.uk/> through 'SPARQL' queries. 'uklr'
    supports the house price index, transaction and price paid data.",2020-04-14,Kostas Vasilopoulos,https://github.com/kvasilopoulos/uklr,TRUE,https://github.com/kvasilopoulos/uklr,2468,0,2020-04-19T17:50:47Z,NA
ukpolice,"Downloads data from the 'UK Police' public data API, 
    the full docs of which are available at <https://data.police.uk/docs/>. 
    Includes data on police forces and police force areas, crime reports, 
    and the use of stop-and-search powers.",2020-05-31,Evan Odell,"https://github.com/EvanOdell/ukpolice/,
https://docs.evanodell.com/ukpolice",TRUE,https://github.com/evanodell/ukpolice,4924,4,2020-05-30T14:42:15Z,1231
umap,"Uniform manifold approximation and projection is a technique
    for dimension reduction. The algorithm was described by McInnes and
    Healy (2018) in <arXiv:1802.03426>. This package provides an interface
    for two implementations. One is written from scratch, including components
    for nearest-neighbor search and for embedding. The second implementation
    is a wrapper for 'python' package 'umap-learn' (requires separate
    installation, see vignette for more details).",2020-03-09,Tomasz Konopka,https://github.com/tkonopka/umap,TRUE,https://github.com/tkonopka/umap,85075,92,2020-06-06T06:47:12Z,924.7282608695652
umx,"Quickly create, run, and report structural equation and twin models.
    See '?umx' for help, and umx_open_CRAN_page(""umx"") for NEWS.",2020-05-25,Timothy C. Bates,https://github.com/tbates/umx,TRUE,https://github.com/tbates/umx,31553,18,2020-06-08T11:59:01Z,1752.9444444444443
UncertainInterval,"Functions for the determination of an uncertain interval, that is, a
    range of test scores that is inconclusive and does not allow a classification other
    than 'Uncertain' (Reference: J.A. Landsheer (2016) <doi:10.1371/journal.pone.0166007>).",2020-04-16,Hans Landsheer,https://github.com/HansLandsheer/UncertainInterval,TRUE,https://github.com/hanslandsheer/uncertaininterval,10612,0,2020-04-16T15:58:35Z,NA
uncmbb,Dataset contains select attributes for each match result since 1949-1950 season for UNC men's basketball team.,2019-10-28,Jay Lee,http://github.com/joongsup/uncmbb,TRUE,https://github.com/joongsup/uncmbb,8734,1,2019-10-28T20:37:38Z,8734
ungroup,"Versatile method for ungrouping histograms (binned count data) 
 assuming that counts are Poisson distributed and that the underlying sequence 
 on a fine grid to be estimated is smooth. The method is based on the composite 
 link model and estimation is achieved by maximizing a penalized likelihood. 
 Smooth detailed sequences of counts and rates are so estimated from the binned 
 counts. Ungrouping binned data can be desirable for many reasons: Bins can be 
 too coarse to allow for accurate analysis; comparisons can be hindered when 
 different grouping approaches are used in different histograms; and the last 
 interval is often wide and open-ended and, thus, covers a lot of information 
 in the tail area. Age-at-death distributions grouped in age classes and 
 abridged life tables are examples of binned data. Because of modest assumptions, 
 the approach is suitable for many demographic and epidemiological applications. 
 For a detailed description of the method and applications see 
 Rizzi et al. (2015) <doi:10.1093/aje/kwv020>.",2019-12-11,Marius D. Pascariu,https://github.com/mpascariu/ungroup,TRUE,https://github.com/mpascariu/ungroup,7945,9,2020-01-13T19:57:11Z,882.7777777777778
unheadr,"Verb-like functions to work with messy data, often derived from 
             spreadsheets or parsed PDF tables. Includes functions for unwrapping 
             values broken up across rows, relocating embedded grouping values, 
             and to annotate meaningful formatting in spreadsheet files.",2020-03-04,Luis D. Verde Arregoitia,"https://github.com/luisDVA/unheadr, https://unheadr.liomys.mx/",TRUE,https://github.com/luisdva/unheadr,1987,31,2020-05-26T20:28:57Z,64.09677419354838
unikn,"Define and use graphical elements of corporate design manuals in R. The 'unikn' package provides color functions (by defining dedicated colors and color palettes, and commands for changing, viewing, and using them) and styled text elements (e.g., for marking, underlining, or plotting colored titles). The pre-defined range of colors and text functions is based on the corporate design of the University of Konstanz <https://www.uni-konstanz.de/>, but can be adapted and extended for other institutions and purposes. ",2019-09-25,Hansjoerg Neth,https://CRAN.R-project.org/package=unikn,TRUE,https://github.com/hneth/unikn,5547,2,2020-05-31T16:24:57Z,2773.5
UniprotR,"Connect to Uniprot <https://www.uniprot.org/> to retrieve information about proteins using their accession number such information could be name or taxonomy information, For detailed information kindly read the publication <https://www.sciencedirect.com/science/article/pii/S1874391919303859>.",2020-05-26,Mohamed Soudy,https://github.com/Proteomicslab57357/UniprotR,TRUE,https://github.com/proteomicslab57357/uniprotr,5724,6,2020-06-08T01:28:22Z,954
unisensR,Provides the ability to read 'Unisens' data into R. 'Unisens' is a universal data format for multi sensor data.,2020-04-29,Martin Penzel [ctb,http://unisens.org/,TRUE,https://github.com/unisens/unisensr,1916,2,2020-04-22T17:22:31Z,958
unitizer,"Simplifies regression tests by comparing objects produced by test
    code with earlier versions of those same objects.  If objects are unchanged
    the tests pass, otherwise execution stops with error details.  If in
    interactive mode, tests can be reviewed through the provided interactive
    environment.",2020-05-12,Brodie Gaslam,https://github.com/brodieG/unitizer,TRUE,https://github.com/brodieg/unitizer,24885,34,2020-05-13T01:07:44Z,731.9117647058823
units,"Support for measurement units in R vectors, matrices
	and arrays: automatic propagation, conversion, derivation
	and simplification of units; raising errors in case of unit
	incompatibility. Compatible with the POSIXct, Date and difftime 
	classes. Uses the UNIDATA udunits library and unit database for 
	unit compatibility checking and conversion.
	Documentation about 'units' is provided in the paper by Pebesma, Mailund &
  Hiebert (2016, <doi:10.32614/RJ-2016-061>), included in this package as a
  vignette; see 'citation(""units"")' for details.",2020-03-16,Edzer Pebesma,https://github.com/r-quantities/units/,TRUE,https://github.com/r-quantities/units,3952221,98,2020-05-24T20:15:40Z,40328.78571428572
unittest,"
    Concise TAP <http://testanything.org/> compliant unit testing package. Authored tests can be run using CMD check with minimal implementation overhead.",2019-11-21,Jamie Lentin,NA,TRUE,https://github.com/ravingmantis/unittest,16735,3,2019-11-19T10:55:48Z,5578.333333333333
univariateML,"User-friendly maximum likelihood estimation (Fisher (1921) 
    <doi:10.1098/rsta.1922.0009>) of univariate densities.",2019-12-18,Jonas Moss,"https://github.com/JonasMoss/univariateML,
https://univariateml.netlify.com/",TRUE,https://github.com/jonasmoss/univariateml,2643,5,2019-12-18T15:50:32Z,528.6
universals,"Provides S3 generic methods and some default implementations
    for Bayesian analyses that generate Markov Chain Monte Carlo (MCMC) samples.
    The purpose of 'universals' is to reduce package dependencies and conflicts. 
    The 'nlist' package implements all the methods for its 'nlists' class.",2020-05-31,Joe Thorley,https://github.com/poissonconsulting/universals,TRUE,https://github.com/poissonconsulting/universals,6,3,2020-06-09T23:45:59Z,2
univOutl,"Well known outlier detection techniques in the univariate case. Methods to deal with skewed distribution are included too. The Hidiroglou-Berthelot (1986) method to search for outliers in ratios of historical data is implemented as well. When available, survey weights can be used in outliers detection.",2020-04-27,Marcello DOrazio,https://github.com/marcellodo/univOutl,TRUE,https://github.com/marcellodo/univoutl,42854,1,2020-04-27T17:51:21Z,42854
unix,"Bindings to system utilities found in most Unix systems such as
    POSIX functions which are not part of the Standard C Library.",2020-01-31,Jeroen Ooms,https://github.com/jeroen/unix,TRUE,https://github.com/jeroen/unix,13712,15,2020-01-31T13:24:32Z,914.1333333333333
unjoin,"Separate a data frame in two based on key columns. The function
 unjoin() provides an inside-out version of a nested data frame. This is used
 to identify duplication and normalize it (in the database sense) by linking
 two tables with the redundancy removed. This is a basic requirement for
 detecting topology within spatial structures that has motivated the need for
 this package as a building block for workflows within more applied projects.",2020-05-13,Michael D. Sumner,https://github.com/hypertidy/unjoin,TRUE,https://github.com/hypertidy/unjoin,10764,10,2020-05-09T01:01:30Z,1076.4
unpivotr,"Tools for converting data from complex or irregular layouts to a
    columnar structure.  For example, tables with multilevel column or row
    headers, or spreadsheets.  Header and data cells are selected by their
    contents and position, as well as formatting and comments where available,
    and are associated with one other by their proximity in given directions.
    Functions for data frames and HTML tables are provided.",2020-05-08,Duncan Garmonsway,https://github.com/nacnudus/unpivotr,TRUE,https://github.com/nacnudus/unpivotr,15979,136,2020-05-09T09:28:20Z,117.49264705882354
updog,"Implements empirical Bayes approaches to genotype
       polyploids from next generation sequencing data while
       accounting for allelic bias, overdispersion, and sequencing
       error. The main functions are flexdog() and multidog(), 
       which allow the specification
       of many different genotype distributions. An experimental
       function that takes into account varying levels of relatedness
       is implemented in mupdog(). Also provided are functions to
       simulate genotypes, rgeno(), and read-counts, rflexdog(), as well as
       functions to calculate oracle genotyping error rates, oracle_mis(), and
       correlation with the true genotypes, oracle_cor(). These latter two
       functions are useful for read depth calculations. Run
       browseVignettes(package = ""updog"") in R for example usage. See
       Gerard et al. (2018) <doi:10.1534/genetics.118.301468> and
       Gerard and Ferrao (2019) <doi:10.1093/bioinformatics/btz852> for details 
       on the implemented methods.",2020-01-28,David Gerard,NA,TRUE,https://github.com/dcgerard/updog,7634,6,2020-02-27T18:55:33Z,1272.3333333333333
uplifteval,"Provides a variety of plots and metrics to evaluate
    uplift models including the 'R uplift' package's Qini metric and Qini plot,
    a port of the 'python pylift' module's plotting function, and
    an alternative plot (in beta) useful for continuous outcomes.
    Background: Radcliffe (2007) <https://pdfs.semanticscholar.org/147b/32f3d56566c8654a9999c5477dded233328e.pdf>.",2019-06-15,Roland Stevenson,https://github.com/ras44/uplifteval,TRUE,https://github.com/ras44/uplifteval,3740,4,2019-07-09T11:25:02Z,935
upsetjs,"'UpSet.js' is a re-implementation of 'UpSetR' to create interactive set visualizations for more than three sets.
  This is a 'htmlwidget' wrapper around the 'JavaScript' library 'UpSet.js'.",2020-05-25,Samuel Gratzl,https://github.com/upsetjs/upsetjs_r/,TRUE,https://github.com/upsetjs/upsetjs_r,153,12,2020-05-14T10:55:10Z,12.75
uptasticsearch,"
    'Elasticsearch' is an open-source, distributed, document-based datastore
    (<https://www.elastic.co/products/elasticsearch>).
    It provides an 'HTTP' 'API' for querying the database and extracting datasets, but that
    'API' was not designed for common data science workflows like pulling large batches of
    records and normalizing those documents into a data frame that can be used as a training
    dataset for statistical models. 'uptasticsearch' provides an interface for 'Elasticsearch'
    that is explicitly designed to make these data science workflows easy and fun.",2019-09-11,James Lamb,https://github.com/uptake/uptasticsearch,TRUE,https://github.com/uptake/uptasticsearch,31065,45,2020-05-12T17:12:03Z,690.3333333333334
urlshorteneR,"Allows using two URL shortening services, which also provide
    expanding and analytic functions. Specifically developed for 'Bit.ly' (which requires OAuth2) and 'is.gd' (no API key).",2019-09-07,John Malc,https://github.com/dmpe/urlshorteneR,TRUE,https://github.com/dmpe/urlshortener,14883,18,2019-09-07T16:59:30Z,826.8333333333334
urltools,"A toolkit for all URL-handling needs, including encoding and decoding,
    parsing, parameter extraction and modification. All functions are
    designed to be both fast and entirely vectorised. It is intended to be
    useful for people dealing with web-related datasets, such as server-side
    logs, although may be useful for other situations involving large sets of
    URLs.",2019-04-14,Os Keyes,https://github.com/Ironholds/urltools/,TRUE,https://github.com/ironholds/urltools,652615,115,2020-05-02T03:39:34Z,5674.913043478261
ursa,"S3 classes and methods for manipulation with georeferenced raster data: reading/writing, processing, multi-panel visualization.",2020-03-29,Nikita Platonov,https://github.com/nplatonov/ursa,TRUE,https://github.com/nplatonov/ursa,2257,5,2020-06-09T17:37:02Z,451.4
usa,"Updated versions of the 1970's ""US State Facts and
    Figures"" objects from the 'datasets' package included with R. The new
    data is compiled from a number of sources, primarily from United
    States Census Bureau or the relevant federal agency.",2020-02-23,Kiernan Nicholls,https://kiernann.com/usa https://github.com/kiernann/usa,TRUE,https://github.com/kiernann/usa,1708,0,2020-05-14T14:21:39Z,NA
usdarnass,"An alternative for downloading various United States Department of
    Agriculture (USDA) data from <https://quickstats.nass.usda.gov/> through R. 
    You must sign up for an API token from the mentioned website in order for 
    this package to work.",2019-06-21,Robert Dinterman,https://github.com/rdinter/usdarnass,TRUE,https://github.com/rdinter/usdarnass,3685,6,2020-02-10T15:22:18Z,614.1666666666666
usefun,"A set of general functions that I have used in various 
  projects and in other R packages. They support some miscellaneous operations 
  on data frames, matrices and vectors like adding a row on a ternary (3-value)
  data.frame based on positive and negative vector-indicators, rearranging a 
  list of data.frames by rownames, pruning rows or columns of a data.frame 
  that contain only one specific value given by the user,
  pruning and reordering a vector according to the common elements between its 
  names and elements of another given vector, finding the non-common elements 
  between two vectors (outer-section), 
  normalization of a vector, matrix or data.frame's numeric values in a specified range, 
  pretty printing of vector names and values in an R Markdown document.
  Also included is a function that returns the statistics needed for plotting a ROC curve.",2020-05-29,John Zobolas,https://github.com/bblodfon/usefun,TRUE,https://github.com/bblodfon/usefun,3485,0,2020-05-29T17:40:56Z,NA
usethis,"Automate package and project setup tasks that are otherwise
    performed manually. This includes setting up unit testing, test 
    coverage, continuous integration, Git, 'GitHub', licenses, 'Rcpp', 'RStudio' 
    projects, and more.",2020-04-29,Hadley Wickham,"https://usethis.r-lib.org, https://github.com/r-lib/usethis",TRUE,https://github.com/r-lib/usethis,8023056,524,2020-06-03T23:19:36Z,15311.175572519083
USgrid,"Provides a set of regular time-series datasets, describing the US electricity grid. That includes the total demand and supply, and as well as the demand by energy source (coal, solar, wind, etc.). Source: US Energy Information Administration (Dec 2019) <https://www.eia.gov/>.",2020-01-24,Rami Krispin,https://github.com/RamiKrispin/USgrid,TRUE,https://github.com/ramikrispin/usgrid,1941,10,2020-01-16T16:42:28Z,194.1
ushr,"Analyzes longitudinal data of HIV decline in patients on antiretroviral therapy using the canonical biphasic exponential decay model (pioneered, for example, by work in Perelson et al. (1997) <doi:10.1038/387188a0>; and Wu and Ding (1999) <doi:10.1111/j.0006-341X.1999.00410.x>). Model fitting and parameter estimation are performed, with additional options to calculate the time to viral suppression. Plotting and summary tools are also provided for fast assessment of model results.",2020-04-21,Sinead E. Morris,https://github.com/SineadMorris/ushr,TRUE,https://github.com/sineadmorris/ushr,3947,1,2020-04-21T17:08:31Z,3947
usl,"The Universal Scalability Law (Gunther 2007)
    <doi:10.1007/978-3-540-31010-5> is a model to predict hardware and
    software scalability. It uses system capacity as a function of load to
    forecast the scalability for the system.",2020-03-02,Stefan Moeding,NA,TRUE,https://github.com/smoeding/usl,17736,25,2020-02-29T12:29:49Z,709.44
usmap,"Obtain United States map data frames of varying region types (e.g. county, 
    state). The map data frames include Alaska and Hawaii conveniently placed to the
    bottom left, as they appear in most maps of the US. Convenience functions for plotting
    choropleths and working with FIPS codes are also provided.",2019-09-12,Paolo Di Lorenzo,https://dilorenzo.pl/pkgs/usmap,TRUE,https://github.com/pdil/usmap,89599,27,2020-01-07T20:57:58Z,3318.4814814814813
ustyc,"Forms a query to submit for US Treasury yield curve data, posting
    this query to the US Treasury web site's data feed service.  By default the
    download includes data yield data for 12 products from January 1, 1990,
    some of which are NA during this span.  The caller can pass parameters to
    limit the query to a certain year or year and month, but the full download
    is not especially large.  The download data from the service is in XML
    format.  The package's main function transforms that XML data into a numeric 
    data frame with treasury product items (constant maturity yields for 12 kinds 
    of bills, notes, and bonds) as columns and dates as row names. The function 
    returns a list which includes an item for this data frame as well as query-related
    values for reference and the update date from the service.",2014-06-12,Matt Barry,https://github.com/mrbcuda/ustyc,TRUE,https://github.com/mrbcuda/ustyc,15452,7,2020-05-27T22:26:45Z,2207.4285714285716
utile.tables,A collection of functions to make building customized ready-to-export tables for publication purposes easier and creating summaries of large datasets for review a breeze.,2020-05-01,Eric Finnesgard,https://github.com/efinite/utile.tables,TRUE,https://github.com/efinite/utile.tables,4907,1,2020-06-04T18:34:31Z,4907
utile.tools,"A set of tools for preparing and summarizing data for publication purposes. Includes functions for tabulating models, means to produce human-readable summary statistics from raw data, macros for calculating duration of time, and simplistic hypothesis testing tools.",2020-06-04,Eric Finnesgard,https://github.com/efinite/utile.tools,TRUE,https://github.com/efinite/utile.tools,5588,1,2020-06-04T18:40:03Z,5588
utile.visuals,A small set of functions for making visuals for publication in ggplot2. Includes minimalist themes with transparent backgrounds and a suite of tools for building Kaplan-Meier curves with risk tables.,2020-05-01,Eric Finnesgard,https://github.com/efinite/utile.visuals,TRUE,https://github.com/efinite/utile.visuals,4805,0,2020-05-14T20:56:15Z,NA
utiml,"Multi-label learning strategies and others procedures to support multi-
  label classification in R. The package provides a set of multi-label procedures such as
  sampling methods, transformation strategies, threshold functions, pre-processing 
  techniques and evaluation metrics. A complete overview of the matter can be seen in
  Zhang, M. and Zhou, Z. (2014) <doi:10.1109/TKDE.2013.39> and Gibaja, E. and 
  Ventura, S. (2015) A Tutorial on Multi-label Learning.",2020-02-07,Adriano Rivolli,https://github.com/rivolli/utiml,TRUE,https://github.com/rivolli/utiml,15487,20,2020-05-29T18:08:34Z,774.35
uwot,"An implementation of the Uniform Manifold Approximation and 
    Projection dimensionality reduction by McInnes et al. (2018) 
    <arXiv:1802.03426>. It also provides means to transform new data and to 
    carry out supervised dimensionality reduction. An implementation of the 
    related LargeVis method of Tang et al. (2016) <arXiv:1602.00370> is also 
    provided. This is a complete re-implementation in R (and C++, via the 'Rcpp'
    package): no Python installation is required. See the uwot website 
    (<https://github.com/jlmelville/uwot>) for more documentation and examples.",2020-03-16,James Melville,https://github.com/jlmelville/uwot,TRUE,https://github.com/jlmelville/uwot,125560,207,2020-04-14T03:23:28Z,606.5700483091788
V8,"An R interface to V8: Google's open source JavaScript and WebAssembly 
    engine. This package can be compiled either with V8 version 6 and up, a NodeJS
    shared library, or the legacy 3.14/3.15 branch of V8.",2020-05-29,Jeroen Ooms,"https://jeroen.cran.dev/V8 (docs) https://github.com/jeroen/v8
(devel) https://v8.dev (upstream)",TRUE,https://github.com/jeroen/v8,989187,136,2020-06-02T10:02:21Z,7273.433823529412
validate,"Declare data validation rules and data quality indicators;
        confront data with them and analyze or visualize the results.
        The package supports rules that are per-field, in-record,
        cross-record or cross-dataset. Rules can be automatically
        analyzed for rule type and connectivity. See also Van der Loo
        and De Jonge (2018) <doi:10.1002/9781118897126>,
        chapter 6.",2019-12-16,Mark van der Loo,https://github.com/data-cleaning/validate,TRUE,https://github.com/data-cleaning/validate,47416,217,2020-05-19T14:35:34Z,218.50691244239633
validatetools,"Rule sets with validation rules may contain redundancies or contradictions. 
  Functions for finding redundancies and problematic rules are provided, 
  given a set a rules formulated with 'validate'.",2020-02-06,Edwin de Jonge,https://github.com/data-cleaning/validatetools,TRUE,https://github.com/data-cleaning/validatetools,10629,8,2020-02-06T08:46:31Z,1328.625
valr,"Read and manipulate genome intervals and signals. Provides
             functionality similar to command-line tool suites within R,
             enabling interactive analysis and visualization of genome-scale data. 
             Riemondy et al. (2017) <doi:10.12688/f1000research.11997.1>.",2020-05-08,Jay Hesselberth,"http://github.com/rnabioco/valr, http://rnabioco.github.io/valr",TRUE,https://github.com/rnabioco/valr,15776,53,2020-05-08T16:23:42Z,297.66037735849056
VancouvR,"Wrapper around the 'City of Vancouver' Open Data API <https://opendata.vancouver.ca/api/v2/console> to simplify and standardize access to 'City of Vancouver' open data. 
  Functionality to list the data catalogue and access data and geographic records.",2019-11-15,Jens von Bergmann,"https://github.com/mountainMath/VancouvR,
https://mountainmath.github.io/VancouvR/",TRUE,https://github.com/mountainmath/vancouvr,2661,9,2019-11-15T17:13:32Z,295.6666666666667
vanddraabe,"Identify and analyze conserved waters within crystallographic 
  protein structures and molecular dynamics simulation trajectories. Statistical 
  parameters for each water cluster, informative graphs, and a PyMOL session 
  file to visually explore the conserved waters and protein are returned. 
  Hydrophilicity is the propensity of waters to congregate near specific protein 
  atoms and is related to conserved waters. An informatics derived set of 
  hydrophilicity values are provided based on a large, high-quality X-ray 
  protein structure dataset.",2019-06-07,Emilio Xavier Esposito,"http://vanddraabe.com, https://github.com/exeResearch/vanddraabe/",TRUE,https://github.com/exeresearch/vanddraabe,5766,0,2019-06-14T15:19:30Z,NA
vapour,"Provides low-level access to 'GDAL' functionality for R packages. The aim is to minimize
  the level of interpretation put on the 'GDAL' facilities, to enable direct use of it for a variety of purposes. 
  'GDAL' is the 'Geospatial Data Abstraction Library' a translator for raster and vector geospatial data formats 
  that presents a single raster abstract data model and single vector abstract data model to the calling application 
  for all supported formats <http://gdal.org/>. Other available packages 'rgdal' and 'sf' also provide access to 
  the 'GDAL' library, but neither can be used for these lower level tasks, and both do many other tasks. ",2020-01-30,Michael Sumner,https://github.com/hypertidy/vapour,TRUE,https://github.com/hypertidy/vapour,7389,36,2020-05-26T01:35:47Z,205.25
vardpoor,"Generation of domain variables, linearization of several nonlinear population statistics (the ratio of two totals, weighted income percentile, relative median income ratio, at-risk-of-poverty rate, at-risk-of-poverty threshold, Gini coefficient, gender pay gap, the aggregate replacement ratio, the relative median income ratio, median income below at-risk-of-poverty gap, income quintile share ratio, relative median at-risk-of-poverty gap), computation of regression residuals in case of weight calibration, variance estimation of sample surveys by the ultimate cluster method (Hansen, Hurwitz and Madow,Theory, vol. I: Methods and Applications; vol. II: Theory. 1953, New York: John Wiley and Sons), variance estimation for longitudinal, cross-sectional measures and measures of change for single and multistage stage cluster sampling designs (Berger, Y. G., 2015, <doi:10.1111/rssa.12116>). Several other precision measures are derived - standard error, the coefficient of variation, the margin of error, confidence interval, design effect.",2020-05-20,Juris Breidaks,https://csblatvia.github.io/vardpoor/,TRUE,https://github.com/csblatvia/vardpoor,39646,4,2020-05-20T07:45:50Z,9911.5
varian,"Uses a Bayesian model to
    estimate the variability in a repeated
    measure outcome and use that as an outcome or a predictor
    in a second stage model.",2016-02-28,Joshua F. Wiley,https://github.com/ElkhartGroup/varian,TRUE,https://github.com/elkhartgroup/varian,13160,7,2019-07-14T03:52:18Z,1880
VARshrink,"
    Vector autoregressive (VAR) model is a fundamental and effective approach
    for multivariate time series analysis. Shrinkage estimation methods can be
    applied to high-dimensional VAR models with dimensionality greater than
    the number of observations, contrary to the standard ordinary least squares
    method. This package is an integrative package delivering nonparametric,
    parametric, and semiparametric methods in a unified and consistent manner,
    such as the multivariate ridge regression in Golub, Heath, and Wahba (1979)
    <doi:10.2307/1268518>, a James-Stein type nonparametric shrinkage method in
    Opgen-Rhein and Strimmer (2007) <doi:10.1186/1471-2105-8-S2-S3>, and
    Bayesian estimation methods using noninformative and informative priors
    in Lee, Choi, and S.-H. Kim (2016) <doi:10.1016/j.csda.2016.03.007> and
    Ni and Sun (2005) <doi:10.1198/073500104000000622>.",2019-10-09,Namgil Lee,https://github.com/namgillee/VARshrink/,TRUE,https://github.com/namgillee/varshrink,3209,0,2020-03-09T16:47:57Z,NA
varTestnlme,"An implementation of the Likelihood ratio Test (LRT) for testing that,
    in a (non)linear mixed effects model, the variances of a subset of the random
    effects are equal to zero. There is no restriction on the subset of variances
    that can be tested: for example, it is possible to test that all the variances
    are equal to zero. Note that the implemented test is asymptotic.
    This package should be used on model fits from packages 'nlme', 'lmer', and 'saemix'.
    Charlotte Baey, Paul-Henry Cournède and Estelle Kuhn (2019) <doi:10.1016/j.csda.2019.01.014>.",2020-01-10,Charlotte Baey,http://github.com/baeyc/varTestnlme/,TRUE,https://github.com/baeyc/vartestnlme,2041,0,2020-01-20T09:46:19Z,NA
varycoef,"Implements a maximum likelihood estimation (MLE)
    method for estimation and prediction in spatially varying coefficient
    (SVC) models (Dambon et al. (2020) <arXiv:2001.08089>). Covariance
    tapering (Furrer et al. (2006) <doi:10.1198/106186006X132178>) can be
    applied such that the method scales to large data.",2020-04-14,Jakob A. Dambon,https://github.com/jakobdambon/varycoef,TRUE,https://github.com/jakobdambon/varycoef,3336,2,2020-03-05T14:19:52Z,1668
vaultr,"Provides an interface to a 'HashiCorp' vault server over
  its http API (typically these are self-hosted; see
  <https://www.vaultproject.io>).  This allows for secure storage and
  retrieval of secrets over a network, such as tokens, passwords and
  certificates.  Authentication with vault is supported through
  several backends including user name/password and authentication via
  'GitHub'.",2019-05-16,Rich FitzJohn,https://github.com/vimc/vaultr,TRUE,https://github.com/vimc/vaultr,4198,15,2020-02-14T17:17:38Z,279.8666666666667
VC2copula,"Provides new classes for (rotated) BB1, BB6, BB7, BB8, and 
  Tawn copulas, extends the existing Gumbel and Clayton families with 
  rotations, and allows to set up a vine copula model using the 'copula' API.
  Corresponding objects from the 'VineCopula' API can easily be converted.",2019-12-15,Thomas Nagler,https://github.com/tnagler/VC2copula,TRUE,https://github.com/tnagler/vc2copula,2681,2,2019-12-07T11:59:48Z,1340.5
vcdExtra,"Provides additional data sets, methods and documentation to complement the 'vcd' package for Visualizing Categorical Data
    and the 'gnm' package for Generalized Nonlinear Models.
	In particular, 'vcdExtra' extends mosaic, assoc and sieve plots from 'vcd' to handle 'glm()' and 'gnm()' models and
	adds a 3D version in 'mosaic3d'.  Additionally, methods are provided for comparing and visualizing lists of
	'glm' and 'loglm' objects. This package is now a support package for the book, ""Discrete Data Analysis with R"" by
  Michael Friendly and David Meyer.",2017-09-29,Michael Friendly,https://CRAN.R-project.org/package=vcdExtra,TRUE,https://github.com/friendly/vcdextra,202150,8,2019-09-25T21:18:24Z,25268.75
vcfR,"Facilitates easy manipulation of variant call format (VCF) data.
    Functions are provided to rapidly read from and write to VCF files. Once
    VCF data is read into R a parser function extracts matrices of data. This
    information can then be used for quality control or other purposes. Additional
    functions provide visualization of genomic data. Once processing is complete
    data may be written to a VCF file (*.vcf.gz). It also may be converted into
    other popular R objects (e.g., genlight, DNAbin). VcfR provides a link between
    VCF data and familiar R software.",2020-06-05,Brian J. Knaus,"https://github.com/knausb/vcfR,
https://knausb.github.io/vcfR_documentation/",TRUE,https://github.com/knausb/vcfr,88414,123,2020-06-05T22:26:52Z,718.8130081300814
vcr,"Record test suite 'HTTP' requests and replays them during
    future runs. A port of the Ruby gem of the same name
    (<https://github.com/vcr/vcr/>). Works by hooking into the 'webmockr'
    R package for matching 'HTTP' requests by various rules ('HTTP' method,
    'URL', query parameters, headers, body, etc.), and then caching
    real 'HTTP' responses on disk in 'cassettes'. Subsequent 'HTTP' requests
    matching any previous requests in the same 'cassette' use a cached
    'HTTP' response.",2020-03-31,Scott Chamberlain,"https://github.com/ropensci/vcr/ (devel)
https://books.ropensci.org/http-testing/ (user manual)",TRUE,https://github.com/ropensci/vcr,24779,45,2020-06-09T17:57:20Z,550.6444444444444
vctrs,"Defines new notions of prototype and size that are
    used to provide tools for consistent and well-founded type-coercion
    and size-recycling, and are in turn connected to ideas of type- and
    size-stability useful for analysing function interfaces.",2020-06-05,Lionel Henry,https://vctrs.r-lib.org/,TRUE,https://github.com/r-lib/vctrs,12325870,179,2020-06-08T16:38:41Z,68859.60893854749
vdiffr,"An extension to the 'testthat' package that makes it easy
    to add graphical unit tests. It provides a Shiny application to
    manage the test cases.",2020-06-06,Lionel Henry,https://github.com/r-lib/vdiffr,TRUE,https://github.com/r-lib/vdiffr,2116306,125,2020-06-06T09:33:02Z,16930.448
vegan,"Ordination methods, diversity analysis and other
  functions for community and vegetation ecologists.",2019-09-01,Jari Oksanen,"https://cran.r-project.org, https://github.com/vegandevs/vegan",TRUE,https://github.com/vegandevs/vegan,1887604,211,2020-05-13T08:28:19Z,8945.990521327014
vegawidget,"'Vega' and 'Vega-Lite' parse text in 'JSON' notation to render 
  chart-specifications into 'HTML'. This package is used to facilitate the 
  rendering. It also provides a means to interact with signals, events,
  and datasets in a 'Vega' chart using 'JavaScript' or 'Shiny'.",2020-01-22,Ian Lyttle,https://github.com/vegawidget/vegawidget,TRUE,https://github.com/vegawidget/vegawidget,12425,41,2020-02-22T13:26:09Z,303.0487804878049
vegperiod,"Collection of common methods to determine growing season length in
  a simple manner. Start and end dates of the vegetation periods are calculated
  solely based on daily mean temperatures and the day of the year.",2019-08-04,Robert Nuske,https://github.com/rnuske/vegperiod,TRUE,https://github.com/rnuske/vegperiod,6213,2,2020-02-27T10:41:22Z,3106.5
vegtable,"Import and handling data from vegetation-plot databases, especially
    data stored in 'Turboveg' (<https://www.synbiosys.alterra.nl/turboveg>).
    Also import/export routines for exchange of data with 'Juice'
    (<http://www.sci.muni.cz/botany/juice>) are implemented.",2020-04-30,Miguel Alvarez,https://github.com/kamapu/vegtable,TRUE,https://github.com/kamapu/vegtable,9340,2,2020-04-29T21:17:44Z,4670
vein,"Elaboration of vehicular emissions inventories,
    consisting in four stages, pre-processing activity data, preparing 
    emissions factors, estimating the emissions and post-processing of emissions 
    in maps and databases. More details in Ibarra-Espinosa et al (2018) <doi:10.5194/gmd-11-2209-2018>.
    Before using VEIN you need to know the vehicular composition of your study area, in other words,
    the combination of of type of vehicles, size and fuel of the fleet. Then, it is recommended to
    start with the function inventory to create a structure of directories and template scripts.",2020-03-17,Sergio Ibarra-Espinosa,https://atmoschem.github.io/vein/,TRUE,https://github.com/atmoschem/vein,13557,22,2020-05-27T15:10:24Z,616.2272727272727
vembedr,"A set of functions for generating HTML to
    embed hosted video in your R Markdown documents or Shiny applications.",2017-07-16,Ian Lyttle,https://github.com/ijlyttle/vembedr,TRUE,https://github.com/ijlyttle/vembedr,14373,36,2019-08-16T14:05:02Z,399.25
vennLasso,"Provides variable selection and estimation routines for models
    with main effects stratified on multiple binary factors. The 'vennLasso' package
    is an implementation of the method introduced in Huling, et al. (2017) <doi:10.1111/biom.12769>.",2020-06-03,Jared Huling,https://github.com/jaredhuling/vennLasso,TRUE,https://github.com/jaredhuling/vennlasso,7568,3,2020-06-04T17:21:55Z,2522.6666666666665
vetr,"Declarative template-based framework for verifying that objects
  meet structural requirements, and auto-composing error messages when they do
  not.",2020-05-13,Brodie Gaslam,https://github.com/brodieG/vetr,TRUE,https://github.com/brodieg/vetr,11951,54,2020-03-10T15:40:18Z,221.3148148148148
viafr,"Provides direct access to linked names for the same entity across the world's major name authority files, including national and regional variations in language, character set, and spelling. For more information go to <https://viaf.org/>.",2020-04-22,Stefanie Schneider,https://github.com/stefanieschneider/viafr,TRUE,https://github.com/stefanieschneider/viafr,3609,2,2020-04-05T17:29:02Z,1804.5
vici,"A shiny app for accurate estimation of vaccine induced immunogenicity 
    with bivariate linear modeling. Method is detailed in: Lhomme E, Hejblum BP, Lacabaratz C, 
    Wiedemann A, Lelièvre J-D, Levy Y, Thiebaut R & Richert L (2019). Submitted.",2019-08-21,Boris Hejblum,NA,TRUE,https://github.com/borishejblum/vici,3191,0,2020-04-09T08:07:40Z,NA
VIM,"New tools for the visualization of missing and/or imputed values
    are introduced, which can be used for exploring the data and the structure of
    the missing and/or imputed values. Depending on this structure of the missing
    values, the corresponding methods may help to identify the mechanism generating
    the missing values and allows to explore the data including missing values.
    In addition, the quality of imputation can be visually explored using various
    univariate, bivariate, multiple and multivariate plot methods. A graphical user
    interface available in the separate package VIMGUI allows an easy handling of
    the implemented plot methods.",2020-05-08,Matthias Templ,https://github.com/statistikat/VIM,TRUE,https://github.com/statistikat/vim,732334,50,2020-05-08T09:33:55Z,14646.68
vimp,"Calculate point estimates of and valid confidence intervals for
    nonparametric, algorithm-agnostic variable importance measures in high and low dimensions,
    using flexible estimators of the underlying regression functions. For more information
    about the methods, please see Williamson et al. (Biometrics, 2020) and Williamson et al. (arXiv, 2020+) <arXiv:2004.03683>.",2020-04-27,Brian D. Williamson,https://github.com/bdwilliamson/vimp,TRUE,https://github.com/bdwilliamson/vimp,8107,6,2020-04-25T17:50:22Z,1351.1666666666667
VineCopula,"Provides tools for the statistical analysis of vine copula models.
    The package includes tools for parameter estimation, model selection,
    simulation, goodness-of-fit tests, and visualization. Tools for estimation,
    selection and exploratory data analysis of bivariate copula models are also
    provided.",2019-11-26,Thomas Nagler,https://github.com/tnagler/VineCopula,TRUE,https://github.com/tnagler/vinecopula,123417,32,2020-03-03T14:16:17Z,3856.78125
vinereg,"
  Implements D-vine quantile regression models with
  parametric or nonparametric pair-copulas. See 
  Kraus and Czado (2017) <doi:10.1016/j.csda.2016.12.009> and
  Schallhorn et al. (2017) <arXiv:1705.08310>.",2019-12-02,Thomas Nagler,https://tnagler.github.io/vinereg,TRUE,https://github.com/tnagler/vinereg,7193,2,2019-12-02T18:07:27Z,3596.5
vioplot,A violin plot is a combination of a box plot and a kernel density plot. This package allows extensive customisation of violin plots. ,2019-11-29,S. Thomas Kelly,https://github.com/TomKellyGenetics/vioplot,TRUE,https://github.com/tomkellygenetics/vioplot,283994,13,2020-03-17T01:10:41Z,21845.69230769231
vip,"A general framework for constructing variable importance plots from 
  various types of machine learning models in R. Aside from some standard model-
  specific variable importance measures, this package also provides model-
  agnostic approaches that can be applied to any supervised learning algorithm.
  These include 1) an efficient permutation-based variable importance measure, 
  2) variable importance based on Shapley values (Strumbelj and Kononenko, 
  2014) <doi:10.1007/s10115-013-0679-x>, and 3) the variance-based 
  approach described in Greenwell et al. (2018) <arXiv:1805.04755>. A 
  variance-based method for quantifying the relative strength of interaction 
  effects is also included (see the previous reference for details).",2020-04-06,Brandon Greenwell,https://github.com/koalaverse/vip/,TRUE,https://github.com/koalaverse/vip,55359,96,2020-05-21T15:57:58Z,576.65625
viridisLite,"Implementation of the 'viridis' - the default -, 'magma', 'plasma', 
    'inferno', and 'cividis' color maps for 'R'. 'viridis', 'magma', 'plasma', 
    and 'inferno' are ported from 'matplotlib' <http://matplotlib.org/>, a 
    popular plotting library for 'python'. 'cividis', was developed by Jamie R. 
    Nuñez and Sean M. Colby. These color maps are designed in such a way that 
    they will analytically be perfectly perceptually-uniform, both in regular 
    form and also when converted to black-and-white. They are also designed to 
    be perceived by readers with the most common form of color blindness (all 
    color maps in this package) and color vision deficiency ('cividis' only). 
    This is the 'lite' version of the more complete 'viridis' package that can 
    be found at <https://cran.r-project.org/package=viridis>.",2018-02-01,Simon Garnier,https://github.com/sjmgarnier/viridisLite,TRUE,https://github.com/sjmgarnier/viridislite,13000511,41,2019-11-07T14:08:43Z,317085.6341463415
visdat,"Create preliminary exploratory data visualisations of an entire 
    dataset to identify problems or unexpected features using 'ggplot2'.",2019-02-15,Nicholas Tierney,"http://visdat.njtierney.com/, https://github.com/ropensci/visdat",TRUE,https://github.com/ropensci/visdat,173286,350,2019-12-20T03:07:22Z,495.10285714285715
ViSiElse,"A graphical R package designed to visualize behavioral observations over time. Based on raw time data extracted from video recorded sessions of experimental observations, ViSiElse grants a global overview of a process by combining the visualization of multiple actions timestamps for all participants in a single graph. Individuals and/or group behavior can easily be assessed. Supplementary features allow users to further inspect their data by adding summary statistics (mean, standard deviation, quantile or statistical test) and/or time constraints to assess the accuracy of the realized actions.",2019-10-24,Elodie Garnier,https://github.com/Re2SimLab/ViSiElse,TRUE,https://github.com/re2simlab/visielse,10833,0,2019-10-21T12:32:07Z,NA
visNetwork,"Provides an R interface to the 'vis.js' JavaScript charting
    library. It allows an interactive visualization of networks.",2019-12-06,Almende B.V.,http://datastorm-open.github.io/visNetwork/,TRUE,https://github.com/datastorm-open/visnetwork,1386470,359,2020-06-09T09:02:08Z,3862.033426183844
vistime,"A library for creating time based charts, like Gantt or timelines. Possible outputs 
  include 'ggplot' diagrams, 'Plotly' graphs and 'data.frame's. Results can be used in the 'RStudio' viewer 
  pane, in 'RMarkdown' documents or in 'Shiny' apps. In the interactive 'Plotly' output, you can 
  hover the mouse pointer over a point or task to show details or drag a rectangle to zoom in. ",2020-04-17,Sandro Raabe,https://shosaco.github.io/vistime/,TRUE,https://github.com/shosaco/vistime,20750,84,2020-05-19T15:24:14Z,247.02380952380952
vistributions,"Visualize and compute percentiles/probabilities of normal, t, f, chi square 
    and binomial distributions.",2019-03-07,Aravind Hebbali,"https://github.com/rsquaredacademy/vistributions,
https://vistributions.rsquaredacademy.com",TRUE,https://github.com/rsquaredacademy/vistributions,16959,5,2019-11-22T01:55:55Z,3391.8
visualize,"Graphs the pdf or pmf and highlights what area or probability is
    present in user defined locations. Visualize is able to provide lower tail,
    bounded, upper tail, and two tail calculations. Supports strict and equal
    to inequalities.  Also provided on the graph is the mean and variance of
    the distribution. ",2020-01-08,James Balamuta,"https://github.com/coatless/visualize,
http://thecoatlessprofessor.com/projects/visualize/",TRUE,https://github.com/coatless/visualize,27069,4,2020-01-07T20:02:32Z,6767.25
Visualize.CRAN.Downloads,Visualize the trends and historical downloads from packages in the 'CRAN' repository. Data is obtained by using the 'API' to query the database from the 'RStudio' 'CRAN' mirror.,2020-03-21,Marcelo Ponce,https://github.com/mponce0/Visualize.CRAN.Downloads,TRUE,https://github.com/mponce0/visualize.cran.downloads,1268,2,2020-04-12T23:42:05Z,634
vitae,Provides templates and functions to simplify the production and maintenance of curriculum vitae.,2020-04-27,Mitchell OHara-Wild,"https://pkg.mitchelloharawild.com/vitae/,
https://github.com/mitchelloharawild/vitae",TRUE,https://github.com/mitchelloharawild/vitae,16171,486,2020-05-25T13:21:02Z,33.27366255144033
vivo,"Provides an easy to calculate variable importance measure based on 
  Ceteris Paribus plot and is calculated in eight variants. We obtain eight 
  variants measure through the possible combinations of three parameters such as 
  absolute_deviation, point and density.",2020-02-27,Anna Kozak,https://github.com/ModelOriented/vivo,TRUE,https://github.com/modeloriented/vivo,4230,10,2020-02-27T10:35:47Z,423
vizdraws,"Interactive visualization for Bayesian prior and posterior distributions. 
             When both distributions are provided the animation shows a transition from 
             prior to posterior. Finally, the animation splits the distribution using the provided 
             'breaks' into bars that show the probability for each region. 
             If no 'breaks' are providers it will use zero by default.",2020-04-28,Ignacio Martinez,"http://github.com/ignacio82/vizdraws,
http://ignacio82.github.io/vizdraws",TRUE,https://github.com/ignacio82/vizdraws,673,6,2020-05-24T02:02:59Z,112.16666666666667
vlad,"Contains functions to set up risk-adjusted quality control charts
    in health care. For the variable life adjusted display (VLAD) proposed by 
    Lovegrove et al. (1997) <doi:10.1016/S0140-6736(97)06507-0> signaling rules
    derived in Wittenberg et al. (2018) <doi: 10.1002/sim.7647> are implemented. 
    Additionally, for the risk-adjusted cumulative sum chart based on log-likelihood
    ratio statistic introduced by Steiner et al. (2000) <doi:10.1093/biostatistics/1.4.441>
    average run length and control limits can be computed.",2018-12-06,Philipp Wittenberg,NA,TRUE,https://github.com/wittenberg/vlad,6670,4,2019-11-01T21:53:50Z,1667.5
VLTimeCausality,"A framework to infer causality on a pair of time series of real numbers based on variable-lag Granger causality and transfer entropy. Typically, Granger causality and transfer entropy have an assumption of a fixed and constant time delay between the cause and effect. However, for a non-stationary time series, this assumption is not true. For example, considering two time series of velocity of person A and person B where B follows A. At some time, B stops tying his shoes, then running to catch up A. The fixed-lag assumption is not true in this case. We propose a framework that allows variable-lags between cause and effect in Granger causality and transfer entropy to allow them to deal with variable-lag non-stationary time series. Please see Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Berger-Wolf (2019) <arXiv:1912.10829> when referring to this package in publications.  ",2020-05-17,Chainarong Amornbunchornvej,https://github.com/DarkEyes/VLTimeSeriesCausality,TRUE,https://github.com/darkeyes/vltimeseriescausality,2551,9,2020-05-17T09:43:40Z,283.44444444444446
volcano3D,"Differential expression (DE) analysis can be used to discover quantitative changes in expression levels between experimental groups. Such results are typically visualised using volcano plots, however in cases where more than two experimental groups are involved, visualising results can become convoluted and it quickly becomes difficult to see the wood for the trees. This package provides easy-to-use functions to extract and visualise outputs from DE between three groups (primarily aimed at 'limma' and 'DESeq2' outputs). We present novel methods to map DE results into polar coordinates to enable users to combine and simultaneously view three sets of results. These graphics also possess optional 'plotly' outputs for interactive and three-dimensional functionality, as seen in Lewis et. al. (2019) <doi:10.1016/j.celrep.2019.07.091>.",2020-06-04,Katriona Goldmann,https://github.com/KatrionaGoldmann/volcano3D,TRUE,https://github.com/katrionagoldmann/volcano3d,0,0,2020-06-09T22:28:28Z,NA
volesti,"Provides an R interface for 'volesti' C++ package. 'volesti' computes estimations of volume 
             of polytopes given by (i) a set of points, (ii) linear inequalities or (iii) Minkowski sum of segments 
             (a.k.a. zonotopes). There are three algorithms for volume estimation as well as algorithms 
             for sampling, rounding and rotating polytopes. Moreover, 'volesti' provides algorithms for 
             estimating copulas useful in computational finance.",2020-05-31,Vissarion Fisikopoulos,NA,TRUE,https://github.com/geomscale/volume_approximation,4120,43,2020-06-04T14:21:42Z,95.81395348837209
voronoiTreemap,"The d3.js framework with the plugins d3-voronoi-map, d3-voronoi-treemap and d3-weighted-voronoi
        are used to generate Voronoi treemaps in R and in a shiny application.
        The computation of the Voronoi treemaps are based on Nocaj and Brandes (2012)
        <doi:10.1111/j.1467-8659.2012.03078.x>.",2019-01-11,Alexander Kowarik,https://github.com/uRosConf/voronoiTreemap,TRUE,https://github.com/urosconf/voronoitreemap,5196,26,2019-07-02T15:19:35Z,199.84615384615384
vortexR,"Facilitate Post Vortex Simulation Analysis by offering
    tools to collate multiple Vortex (v10) output files into one R object, and
    analyse the collated output statistically. Vortex is a software for
    the development of individual-based model for population dynamic simulation
    (see <https://scti.tools/vortex/>).",2020-04-10,Carlo Pacioni,https://github.com/carlopacioni/vortexR/,TRUE,https://github.com/carlopacioni/vortexr,10938,3,2020-04-21T13:30:45Z,3646
VOSONDash,"A 'Shiny' application for the interactive visualisation and
    analysis of networks that also provides a web interface for collecting
    social media data using 'vosonSML'.",2020-05-20,Bryan Gertzel,https://github.com/vosonlab/VOSONDash,TRUE,https://github.com/vosonlab/vosondash,4234,26,2020-05-20T11:31:36Z,162.84615384615384
vosonSML,"A suite of tools for collecting and constructing networks from social media data.
    Provides easy-to-use functions for collecting data across popular platforms (Twitter, YouTube
    and Reddit) and generating different types of networks for analysis.",2020-04-25,Timothy Graham,https://github.com/vosonlab/vosonSML,TRUE,https://github.com/vosonlab/vosonsml,13042,22,2020-05-23T02:01:58Z,592.8181818181819
vov,"A wrapper around a CSS library called 'vov.css', intended for use 
  in 'shiny' applications. Simply wrap a UI element in one of the animation 
  functions to see it move.",2019-12-20,Tyler Littlefield,https://github.com/tyluRp/vov,TRUE,https://github.com/tylurp/vov,2374,18,2020-01-11T20:41:33Z,131.88888888888889
voxel,Functions for the mass-univariate voxelwise analysis of medical imaging data that follows the NIfTI <http://nifti.nimh.nih.gov> format. ,2018-06-26,Angel Garcia de la Garza,https://github.com/angelgar/voxel,TRUE,https://github.com/angelgar/voxel,13653,4,2019-12-20T20:17:10Z,3413.25
vpc,"Visual predictive checks are a commonly used diagnostic plot in pharmacometrics, showing how certain statistics (percentiles) for observed data compare to those same statistics for data simulated from a model. The package can generate VPCs for continuous, categorical, censored, and (repeated) time-to-event data.",2020-06-02,Ron Keizer,https://github.com/ronkeizer/vpc,TRUE,https://github.com/ronkeizer/vpc,16623,25,2020-05-29T22:05:59Z,664.92
vroom,"The goal of 'vroom' is to read and write data (like
    'csv', 'tsv' and 'fwf') quickly. When reading it uses a quick initial
    indexing step, then reads the values lazily , so only the data you
    actually use needs to be read.  The writer formats the data in
    parallel and writes to disk asynchronously from formatting.",2020-05-12,Jim Hester,"https://vroom.r-lib.org, https://github.com/r-lib/vroom",TRUE,https://github.com/r-lib/vroom,49692,390,2020-05-19T15:27:07Z,127.41538461538461
VSURF,"Three steps variable selection procedure based on random forests.
    Initially developed to handle high dimensional data (for which number of
    variables largely exceeds number of observations), the package is very
    versatile and can treat most dimensions of data, for regression and
    supervised classification problems. First step is dedicated to eliminate
    irrelevant variables from the dataset. Second step aims to select all
    variables related to the response for interpretation purpose. Third step
    refines the selection by eliminating redundancy in the set of variables
    selected by the second step, for prediction purpose.
    Genuer, R. Poggi, J.-M. and Tuleau-Malot, C. (2015)
    <https://journal.r-project.org/archive/2015-2/genuer-poggi-tuleaumalot.pdf>.",2019-07-18,Robin Genuer,https://github.com/robingenuer/VSURF,TRUE,https://github.com/robingenuer/vsurf,32875,16,2020-04-17T10:33:49Z,2054.6875
vtreat,"A 'data.frame' processor/conditioner that prepares real-world data for predictive modeling in a statistically sound manner.
    'vtreat' prepares variables so that data has fewer exceptional cases, making
    it easier to safely use models in production. Common problems 'vtreat' defends
    against: 'Inf', 'NA', too many categorical levels, rare categorical levels, and new
    categorical levels (levels seen during application, but not during training). Reference: 
    ""'vtreat': a data.frame Processor for Predictive Modeling"", Zumel, Mount, 2016, <DOI:10.5281/zenodo.1173313>.",2020-03-11,John Mount,"https://github.com/WinVector/vtreat/,
https://winvector.github.io/vtreat/",TRUE,https://github.com/winvector/vtreat,71150,265,2020-06-01T20:17:27Z,268.49056603773585
vwline,"Provides R functions to draw lines and curves with the width
             of the curve allowed to vary along the length of the curve.",2019-07-25,Paul Murrell,"https://github.com/pmur002/vwline,
https://stattech.wordpress.fos.auckland.ac.nz/2017/05/19/2017-01-variable-width-lines-in-r/,
https://stattech.wordpress.fos.auckland.ac.nz/2017/06/07/2017-02-variable-width-line-ends-and-line-joins/,
https://stattech.wordpress.fos.auckland.ac.nz/2017/06/15/2017-03-offset-curves-for-variable-width-x-splines/,
https://stattech.wordpress.fos.auckland.ac.nz/2018/11/02/2018-11-variable-width-bezier-splines-in-r/",TRUE,https://github.com/pmur002/vwline,5015,18,2019-07-22T03:24:47Z,278.6111111111111
wactor,"A user-friendly factor-like interface for converting strings of
    text into numeric vectors and rectangular data structures.",2019-12-18,Michael W. Kearney,https://github.com/mkearney/wactor,TRUE,https://github.com/mkearney/wactor,2468,29,2019-12-13T05:39:34Z,85.10344827586206
waldo,"Compare complex R objects and reveal the key
    differences.  Designed particularly for use in testing packages where
    being able to quickly isolate key differences makes understanding test
    failures much easier.",2020-04-16,Hadley Wickham,https://github.com/r-lib/waldo,TRUE,https://github.com/r-lib/waldo,1708,72,2020-04-27T14:46:08Z,23.72222222222222
walker,"Bayesian generalized linear models with time-varying coefficients. 
    Gaussian, Poisson, and binomial observations are supported. 
    The Markov chain Monte Carlo computations are done using 
    Hamiltonian Monte Carlo provided by Stan, using a state space representation 
    of the model in order to marginalise over the coefficients for efficient sampling. 
    For non-Gaussian models, the package uses the importance sampling type estimators based on 
    approximate marginal MCMC as in Vihola, Helske, Franks (2017, <arXiv:1609.02541>).",2020-05-15,Jouni Helske,https://github.com/helske/walker,TRUE,https://github.com/helske/walker,13065,24,2020-05-19T05:50:28Z,544.375
walmartAPI,"Provides API access to the Walmart Open API <https://developer.walmartlabs.com/>, 
    that contains data about stores, Value of the day and products which 
    includes names, sale prices, shipping rates and taxonomies.",2018-01-05,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/walmartAPI,TRUE,https://github.com/emilhvitfeldt/walmartapi,7469,15,2020-04-19T18:26:38Z,497.93333333333334
WaMaSim,"The outcome of various rehabilitation strategies for water distribution systems can be modeled with the Water Management Simulator (WaMaSim). Pipe breaks and the corresponding damage and rehabilitation costs are simulated. It is mainly intended to be used as educational tool for the Water Infrastructure Experimental and Computer Laboratory at ETH Zurich, Switzerland.",2019-05-03,Christian Foerster,https://github.com/scheidan/WaMaSim,TRUE,https://github.com/scheidan/wamasim,3881,1,2020-04-28T18:02:41Z,3881
warbleR,"Functions aiming to facilitate the analysis of the structure of animal acoustic signals in 'R'. Users can collect open-access avian recordings or enter their own data into a workflow that facilitates spectrographic visualization and measurement of acoustic parameters. 'warbleR' makes use of the basic sound analysis tools from the package 'seewave', and offers new tools for acoustic structure analysis. The main features of the package are the use of loops to apply tasks through acoustic signals referenced in a selection (annotation) table and the production of spectrograms in image files that allow to organize data and verify acoustic analyzes. The package offers functions to explore, organize and manipulate multiple sound files, explore and download 'Xeno-Canto' recordings, detect signals automatically, create spectrograms of complete recordings or individual signals, run different measures of acoustic signal structure, evaluate the performance of measurement methods, catalog signals, characterize different structural levels in acoustic signals, run statistical analysis of duet coordination and consolidate databases and annotation tables, among others.",2020-03-10,Marcelo Araya-Salas,https://marce10.github.io/warbleR,TRUE,https://github.com/marce10/warbler,36159,33,2020-06-05T22:01:51Z,1095.7272727272727
warp,"Tooling to group dates by a variety of periods
    including: yearly, monthly, by second, by week of the month, and more.
    The groups are defined in such a way that they also represent the
    distance between dates in terms of the period. This extracts valuable
    information that can be used in further calculations that rely on a
    specific temporal spacing between observations.",2020-01-14,Davis Vaughan,https://github.com/DavisVaughan/warp,TRUE,https://github.com/davisvaughan/warp,55530,19,2020-03-06T20:55:27Z,2922.6315789473683
WaterML,"Lets you connect to any of the 'Consortium of Universities for the Advancement of Hydrological Science, Inc.' 
    ('CUAHSI') Water Data Center 'WaterOneFlow' web services
    and read any 'WaterML' time series data file. To see list of available
    web services, see <http://hiscentral.cuahsi.org>. All versions of 'WaterML'
    (1.0, 1.1 and 2.0) and both types of the web service protocol ('SOAP' and 'REST') are supported.
    The package has six data download functions: GetServices(): show all public web
    services from the HIS Central Catalog. HISCentral_GetSites() and HISCentral_GetSeriesCatalog():
    search for sites or time series from the HIS Central catalog based on geographic bounding box,
    server, or keyword. GetVariables(): Show a data.frame with all variables on the server.
    GetSites(): Show a data.frame with all sites on the server. GetSiteInfo(): Show what variables,
    methods and quality control levels are available at the specific site. GetValues(): Given a site
    code, variable code, start time and end time, fetch a data.frame of all the observation time
    series data values. The GetValues() function can also parse 'WaterML' data from a custom URL or
    from a local file.",2020-02-12,Jiri Kadlec,https://github.com/jirikadlec2/waterml,TRUE,https://github.com/jirikadlec2/waterml,15248,7,2020-02-12T00:09:44Z,2178.285714285714
WaveSampling,"Spatial data are generally auto-correlated, meaning that if two 
  units selected are close to each other, then it is likely that they share the
  same properties. For this reason, when sampling in the population it is often
  needed that the sample is well spread over space. A new method to draw a sample
  from a population with spatial coordinates is proposed. This method is called
  wave (Weakly Associated Vectors) sampling. It uses the less correlated vector
  to a spatial weights matrix to update the inclusion probabilities vector
  into a sample. For more details see Raphaël Jauslin and Yves Tillé (2019) <arXiv:1910.13152>.",2020-01-30,Raphaël Jauslin,https://github.com/RJauslin/WaveSampling,TRUE,https://github.com/rjauslin/wavesampling,2963,1,2020-01-30T09:50:29Z,2963
wbstats,"Tools for searching and downloading data and statistics from
  the World Bank Data API (<http://data.worldbank.org/developers/api-overview>)
  and the World Bank Data Catalog API (<http://data.worldbank.org/developers/data-catalog-api>).",2018-01-03,Jesse Piburn,https://github.com/GIST-ORNL/wbstats,TRUE,https://github.com/gist-ornl/wbstats,118580,70,2020-02-28T15:51:30Z,1694
wdman,"There are a number of binary files associated with the
    'Webdriver'/'Selenium' project (see <http://www.seleniumhq.org/download/>,
    <https://sites.google.com/a/chromium.org/chromedriver/>,
    <https://github.com/mozilla/geckodriver>,
    <http://phantomjs.org/download.html> and
    <https://github.com/SeleniumHQ/selenium/wiki/InternetExplorerDriver> for
    more information). This package provides functions to download these
    binaries and to manage processes involving them.",2020-01-31,John Harrison,"https://docs.ropensci.org/wdman, https://github.com/ropensci/wdman",TRUE,https://github.com/ropensci/wdman,145496,25,2020-01-31T21:52:54Z,5819.84
wdpar,"Fetch and clean data from the World Database on Protected
    Areas (WDPA). Data is obtained from Protected Planet
    <http://protectedplanet.net>.",2020-04-15,Jeffrey O Hanson,"https://prioritizr.github.io/wdpar,
https://github.com/prioritizr/wdpar",TRUE,https://github.com/prioritizr/wdpar,7072,16,2020-06-04T05:26:08Z,442
weathercan,"Provides means for downloading historical weather data from 
    the Environment and Climate Change Canada website 
    (<http://climate.weather.gc.ca/historical_data/search_historic_data_e.html>). 
    Data can be downloaded from multiple stations and over large date ranges 
    and automatically processed into a single dataset. Tools are also provided 
    to identify stations either by name or proximity to a location.",2020-04-17,Steffi LaZerte,"https://docs.ropensci.org/weathercan,
https://github.com/ropensci/weathercan",TRUE,https://github.com/ropensci/weathercan,11720,57,2020-04-16T19:22:16Z,205.6140350877193
webchem,"Chemical information from around the web. This package interacts 
    with a suite of web services for chemical information. Sources include: Alan
    Wood's Compendium of Pesticide Common Names, Chemical Identifier Resolver,
    ChEBI, Chemical Translation Service, ChemIDplus, ChemSpider, ETOX,
    Flavornet, NIST Chemistry WebBook, OPSIN, PAN Pesticide Database, PubChem,
    SRS, Wikidata.",2020-05-28,Eduard Szöcs,"https://docs.ropensci.org/webchem,
https://github.com/ropensci/webchem",TRUE,https://github.com/ropensci/webchem,26185,81,2020-05-28T19:53:33Z,323.2716049382716
webdriver,"A client for the 'WebDriver' 'API'. It allows driving a
    (probably headless) web browser, and can be used to test web
    applications, including 'Shiny' apps. In theory it works with any
    'WebDriver' implementation, but it was only tested with 'PhantomJS'.",2018-04-11,Ariya Hidayat,https://github.com/rstudio/webdriver,TRUE,https://github.com/rstudio/webdriver,94164,47,2020-03-07T10:13:54Z,2003.4893617021276
webex,"Functions for easily creating interactive web pages using
    'R Markdown' that students can use in self-guided learning.",2019-05-03,Dale Barr,https://github.com/psyteachr/webex,TRUE,https://github.com/psyteachr/webex,4086,30,2019-09-06T08:58:20Z,136.2
WebGestaltR,"The web version WebGestalt <http://www.webgestalt.org> supports 12 organisms, 354 gene identifiers and 321,251 function categories. Users can upload the data and functional categories with their own gene identifiers. In addition to the Over-Representation Analysis, WebGestalt also supports Gene Set Enrichment Analysis and Network Topology Analysis. The user-friendly output report allows interactive and efficient exploration of enrichment results. The WebGestaltR package not only supports all above functions but also can be integrated into other pipeline or simultaneously analyze multiple gene lists.",2020-01-16,Yuxing Liao,https://github.com/bzhanglab/WebGestaltR,TRUE,https://github.com/bzhanglab/webgestaltr,17538,7,2020-01-16T20:24:04Z,2505.4285714285716
webmockr,"Stubbing and setting expectations on 'HTTP' requests.
    Includes tools for stubbing 'HTTP' requests, including expected
    request conditions and response conditions. Match on
    'HTTP' method, query parameters, request body, headers and
    more. Can be used for unit tests or outside of a testing 
    context.",2020-03-24,Scott Chamberlain,"https://github.com/ropensci/webmockr (devel),
https://books.ropensci.org/http-testing (user manual)",TRUE,https://github.com/ropensci/webmockr,33927,32,2020-06-05T05:38:38Z,1060.21875
webr,"Several analysis-related functions for the book entitled
    ""Web-based Analysis without R in Your Computer""(written in Korean, ISBN 978-89-5566-185-9)
    by Keon-Woong Moon. The main function plot.htest() shows the distribution of statistic for
    the object of class 'htest'.",2020-01-26,Keon-Woong Moon,https://github.com/cardiomoon/webr,TRUE,https://github.com/cardiomoon/webr,8751,11,2020-05-10T02:33:40Z,795.5454545454545
websearchr,Functions that allow for accessing domains and a number of search engines.,2018-10-23,Florian S. Schaffner,https://github.com/fschaff/websearchr,TRUE,https://github.com/fschaff/websearchr,8757,10,2019-09-27T16:25:59Z,875.7
webshot,"Takes screenshots of web pages, including Shiny applications and R
    Markdown documents.",2019-11-22,Winston Chang,https://github.com/wch/webshot/,TRUE,https://github.com/wch/webshot,2518816,176,2019-12-13T20:57:39Z,14311.454545454546
webTRISr,"Provides functions to query data from the 'WebTRIS' Traffic Flow API (from Highways England) into tidy data frames.
    The API documentation is available here: <http://webtris.highwaysengland.co.uk/api/swagger/ui/index>.",2019-08-07,Ivo Wengraf,https://github.com/RACFoundation/webTRISr,TRUE,https://github.com/racfoundation/webtrisr,9003,9,2020-05-12T15:41:00Z,1000.3333333333334
webutils,"Parses http request data in application/json, multipart/form-data, 
    or application/x-www-form-urlencoded format. Includes example of hosting
    and parsing html form data in R using either 'httpuv' or 'Rhttpd'.",2020-04-28,Jeroen Ooms,https://github.com/jeroen/webutils,TRUE,https://github.com/jeroen/webutils,134650,20,2020-04-28T20:16:05Z,6732.5
wedge,"Provides functionality for working with differentials,
           k-forms, wedge products, Stokes's theorem, and related concepts
	   from the exterior calculus.  The canonical reference would be:
	   M. Spivak (1965, ISBN:0-8053-9021-9). ""Calculus on Manifolds"",
	   Benjamin Cummings.",2019-09-04,Robin K. S. Hankin,https://github.com/RobinHankin/wedge.git,TRUE,https://github.com/robinhankin/wedge,4567,2,2020-05-20T20:59:59Z,2283.5
weibullness,"Performs a goodness-of-fit test of Weibull distribution (weibullness test) and provides the maximum likelihood estimates of the three-parameter Weibull distribution. Note that the threshold parameter is estimated based on the correlation from the Weibull plot. For more details, see Park (2018) <doi:10.1155/2018/6056975>. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (No. NRF-2017R1A2B4004169).",2019-08-19,Chanseok Park,https://github.com/AppliedStat/R,TRUE,https://github.com/appliedstat/r,8187,1,2020-03-01T08:04:50Z,8187
WeightedROC,"Fast computation of
 Receiver Operating Characteristic (ROC) curves
 and Area Under the Curve (AUC)
 for weighted binary classification problems
 (weights are example-specific cost values).",2020-02-01,Toby Dylan Hocking,https://github.com/tdhock/WeightedROC,TRUE,https://github.com/tdhock/weightedroc,10647,18,2020-01-31T16:18:04Z,591.5
WeightIt,"Generates weights to form equivalent groups in observational studies with point or longitudinal treatments by easing and extending the functionality of the R packages 'twang' for generalized boosted modeling (McCaffrey, Ridgeway & Morral, 2004) <doi:10.1037/1082-989X.9.4.403>, 'CBPS' for covariate balancing propensity score weighting (Imai & Ratkovic, 2014) <doi:10.1111/rssb.12027>, 'ebal' for entropy balancing (Hainmueller, 2012) <doi:10.1093/pan/mpr025>, 'optweight' for optimization-based weights (Zubizarreta, 2015) <doi:10.1080/01621459.2015.1023805>, 'ATE' for empirical balancing calibration weighting (Chan, Yam, & Zhang, 2016) <doi:10.1111/rssb.12129>, and 'SuperLearner' for stacked machine learning-based propensity scores (Pirracchio, Petersen, & van der Laan, 2015) <doi:10.1093/aje/kwu253>. Also allows for assessment of weights and checking of covariate balance by interfacing directly with 'cobalt'.",2020-02-11,Noah Greifer,https://github.com/ngreifer/WeightIt,TRUE,https://github.com/ngreifer/weightit,17741,23,2020-06-08T22:10:45Z,771.3478260869565
WeightSVM,"Functions for subject/instance weighted support vector machines (SVM). 
    It uses a modified version of 'libsvm' and is compatible with package 'e1071'. ",2020-05-28,Tianchen Xu,https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances,TRUE,https://github.com/zjph602xtc/wsvm,1101,1,2020-05-28T00:47:51Z,1101
wellknown,"Convert 'WKT' to 'GeoJSON' and 'GeoJSON' to 'WKT'. Functions
    included for converting between 'GeoJSON' to 'WKT', creating both
    'GeoJSON' features, and non-features, creating 'WKT' from R objects
    (e.g., lists, data.frames, vectors), and linting 'WKT'.",2020-01-10,Scott Chamberlain,"https://docs.ropensci.org/wellknown,
https://github.com/ropensci/wellknown",TRUE,https://github.com/ropensci/wellknown,23030,15,2020-05-08T18:16:14Z,1535.3333333333333
wfe,"Provides a computationally efficient way of fitting
	     weighted linear fixed effects estimators for causal
	     inference with various weighting schemes. Weighted linear
	     fixed effects estimators can be used to estimate the
	     average treatment effects under different identification
	     strategies. This includes stratified randomized
	     experiments, matching and stratification for
	     observational studies, first differencing, and
	     difference-in-differences. The package implements methods
	     described in Imai and Kim (2017) ""When should We Use
	     Linear Fixed Effects Regression Models for Causal
	     Inference with Longitudinal Data?"", available at
	     <https://imai.fas.harvard.edu/research/FEmatch.html>.",2019-04-17,In Song Kim,NA,TRUE,https://github.com/insongkim/wfe,18425,12,2020-03-19T15:32:31Z,1535.4166666666667
whatr,"Scrape the fan-made J! Archive <https://www.j-archive.com/> 
    for Jeopardy episode contestants, categories, clues, answers, and scores.",2020-03-19,Kiernan Nicholls,https://github.com/kiernann/whatr,TRUE,https://github.com/kiernann/whatr,1272,3,2020-03-11T23:23:51Z,424
whereami,"Robust and reliable functions to return informative outputs to 
        console with the run or source location of a command. This can be from
        the  'RScript'/R terminal commands or 'RStudio' console, source editor, 
        'Rmarkdown' document and a Shiny application.",2019-11-07,Jonathan Sidi,https://github.com/yonicd/whereami,TRUE,https://github.com/yonicd/whereami,4132,29,2019-11-06T04:54:59Z,142.48275862068965
whisker,Implements 'Mustache' logicless templating.,2019-08-28,Edwin de Jonge,http://github.com/edwindj/whisker,TRUE,https://github.com/edwindj/whisker,8802227,155,2019-08-23T13:28:56Z,56788.56129032258
whitestrap,"Formal implementation of White test of heteroskedasticity and a bootstrapped version of it, developed under the methodology of Jeong, J., Lee, K. (1999) <https://yonsei.pure.elsevier.com/en/publications/bootstrapped-whites-test-for-heteroskedasticity-in-regression-mod>.",2020-06-04,Jorge Lopez Perez,NA,TRUE,https://github.com/jlopezper/whitestrap,0,0,2020-06-01T23:14:10Z,NA
WhiteStripe,"Shinohara (2014) <DOI:10.1016/j.nicl.2014.08.008>
    introduced 'WhiteStripe', an intensity-based normalization of T1 
    and T2 images, where normal 
    appearing white matter performs well, but requires segmentation.
    This method performs white matter mean and standard deviation
    estimates on data that has been rigidly-registered to the 'MNI'
    template and uses histogram-based methods.",2019-10-01,R. Taki Shinohara,NA,TRUE,https://github.com/muschellij2/whitestripe,19682,3,2020-04-20T17:13:45Z,6560.666666666667
wicket,"Utilities to generate bounding boxes from 'WKT' (Well-Known Text) objects and R data types, validate
             'WKT' objects and convert object types from the 'sp' package into 'WKT' representations.",2017-11-19,Oliver Keyes,https://github.com/ropensci/wicket,TRUE,https://github.com/ropensci/wicket,59261,9,2019-12-09T19:45:30Z,6584.555555555556
widyr,"Encapsulates the pattern of untidying data into a wide matrix,
  performing some processing, then turning it back into a tidy form. This
  is useful for several operations such as co-occurrence counts,
  correlations, or clustering that are mathematically convenient on wide matrices.",2020-04-12,David Robinson,http://github.com/dgrtwo/widyr,TRUE,https://github.com/dgrtwo/widyr,142251,239,2020-04-11T23:55:41Z,595.1924686192468
wiesbaden,Retrieve and import data from different databases of the Federal Statistical Office of Germany (DESTATIS) using their SOAP XML web service. ,2020-02-15,Moritz Marbach,https://github.com/sumtxt/wiesbaden/,TRUE,https://github.com/sumtxt/wiesbaden,3328,24,2020-03-29T09:58:15Z,138.66666666666666
WikidataQueryServiceR,"An API client for the 'Wikidata Query Service'
    <https://query.wikidata.org/>.",2017-04-28,Mikhail Popov,https://github.com/bearloga/WikidataQueryServiceR,TRUE,https://github.com/bearloga/wikidataqueryservicer,10890,18,2020-03-06T17:43:44Z,605
wikilake,Scrape lake metadata tables from Wikipedia <http://www.wikipedia.org>. ,2018-06-07,Joseph Stachelek,https://github.com/jsta/wikilake,TRUE,https://github.com/jsta/wikilake,9780,7,2019-09-19T13:08:57Z,1397.142857142857
wikipediatrend,"A convenience wrapper for the Wikipedia page access statistics API 
  binding the 'pageviews' package and using an additional self composed data 
  source thus covering a time span from very late 2007 up to the present for 
  daily page views. ",2020-06-03,Peter Meissner,NA,TRUE,https://github.com/petermeissner/wikipediatrend,27586,68,2020-06-03T14:18:28Z,405.6764705882353
wikisourcer,"Download public domain works from Wikisource <https://wikisource.org/>, a free library from the Wikimedia Foundation project.",2019-04-04,Félix Luginbuhl,https://github.com/lgnbhl/wikisourcer,TRUE,https://github.com/lgnbhl/wikisourcer,6539,0,2020-02-19T16:53:45Z,NA
wikitaxa,"'Taxonomic' information from 'Wikipedia', 'Wikicommons',
    'Wikispecies', and 'Wikidata'. Functions included for getting
    taxonomic information from each of the sources just listed, as
    well performing taxonomic search.",2018-10-19,Scott Chamberlain,https://github.com/ropensci/wikitaxa,TRUE,https://github.com/ropensci/wikitaxa,80308,14,2019-12-09T19:48:38Z,5736.285714285715
wilson,"Tool-set of modules for creating web-based applications that use plot based strategies to visualize and analyze multi-omics data.
    This package utilizes the 'shiny' and 'plotly' frameworks to provide a user friendly dashboard for interactive plotting.",2020-05-26,Hendrik Schultheis,https://github.com/loosolab/wilson/,TRUE,https://github.com/loosolab/wilson,7406,2,2020-05-26T08:10:03Z,3703
windfarmGA,"The genetic algorithm is designed to optimize wind farms of any shape. It requires a predefined amount of turbines, a unified rotor radius and an average wind speed value for each incoming wind direction. A terrain effect model can be included that downloads an 'SRTM' elevation model and loads a Corine Land Cover raster to approximate surface roughness.",2019-12-16,Sebastian Gatscha,https://ysosirius.github.io/windfarmGA/index.html,TRUE,https://github.com/ysosirius/windfarmga,11920,13,2019-12-16T18:01:42Z,916.9230769230769
wiqid,"Provides simple, fast functions for maximum likelihood and Bayesian estimates of wildlife population parameters, suitable for use with simulated data or bootstraps. Early versions were indeed quick and dirty, but optional error-checking routines and meaningful error messages have been added. Includes single and multi-season occupancy, closed capture population estimation, survival, species richness and distance measures.",2020-01-08,Mike Meredith,NA,TRUE,https://github.com/mikemeredith/wiqid,16452,0,2020-06-10T00:57:54Z,NA
wk,"Provides a minimal R and C++ API for parsing
  well-known binary and well-known text representation of
  geometries to and from R-native formats. 
  Well-known binary is compact
  and fast to parse; well-known text is human-readable
  and is useful for writing tests. These formats are only
  useful in R if the information they contain can be 
  accessed in R, for which high-performance functions 
  are provided here.",2020-05-11,Dewey Dunnington,https://github.com/paleolimbot/wk,TRUE,https://github.com/paleolimbot/wk,383,16,2020-06-08T00:55:10Z,23.9375
wkb,"Utility functions to convert between the 'Spatial' classes
  specified by the package 'sp', and the well-known binary '(WKB)'
  representation for geometry specified by the 'Open Geospatial Consortium'.
  Supports 'Spatial' objects of class 'SpatialPoints',
  'SpatialPointsDataFrame', 'SpatialLines', 'SpatialLinesDataFrame',
  'SpatialPolygons', and 'SpatialPolygonsDataFrame'. Supports 'WKB' geometry
  types 'Point', 'LineString', 'Polygon', 'MultiPoint', 'MultiLineString', and
  'MultiPolygon'. Includes extensions to enable creation of maps with
  'TIBCO Spotfire'.",2019-12-05,TIBCO Software Inc.,NA,TRUE,https://github.com/ianmcook/wkb,28645,4,2019-12-05T19:03:05Z,7161.25
wmm,"Calculate magnetic field at a given location and time according to 
  the World Magnetic Model (WMM). Both the main field and secular variation 
  components are returned. This functionality is useful for physicists and 
  geophysicists who need orthogonal components from WMM. Currently, this package 
  supports annualized time inputs between 2000 and 2020. If desired, users can
  specify which WMM version to use, e.g., the original WMM2015 release or the 
  recent out-of-cycle WMM2015 release. Methods used to implement WMM, including 
  the Gauss coefficients for each release, are described in the following 
  publications: Chulliat et al (2019) <doi:10.25921/xhr3-0t19>, 
  Chulliat et al (2015) <doi:10.7289/V5TB14V7>, 
  Maus et al (2010) <https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/WMM2010_Report.pdf>, 
  McLean et al (2004) <https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/TRWMM_2005.pdf>,
  and Macmillian et al (2000) <https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/wmm2000.pdf>.",2019-11-22,Will Frierson,https://github.com/wfrierson/wmm,TRUE,https://github.com/wfrierson/wmm,2408,1,2019-12-27T20:19:03Z,2408
WMWssp,"Calculates the minimal sample size for the Wilcoxon-Mann-Whitney test
    that is needed for a given power and two sided type I error rate. The method works for metric data with and without
    ties, count data, ordered categorical data, and even dichotomous data.
    But data is needed for the reference group to generate synthetic data for the treatment group based on a relevant effect.
    For details, see Brunner, E., Bathke A. C. and Konietschke, F: Rank- and Pseudo-Rank Procedures in Factorial Designs - Using R and SAS, Springer Verlag, to appear.",2019-07-09,Martin Happ,http://github.com/happma/WMWssp,TRUE,https://github.com/happma/wmwssp,8035,1,2019-07-09T09:04:56Z,8035
worcs,"Create reproducible and transparent research projects in 'R', with
    a minimal amount of code. This package is based on the Workflow for Open
    Reproducible Code in Science (WORCS), a step-by-step procedure based on best
    practices for
    Open Science. It includes an 'RStudio' project template, several
    convenience functions, and all dependencies required to make your project
    reproducible and transparent. WORCS is explained in the tutorial paper
    by Van Lissa, Brandmaier, Brinkman, Lamprecht, Struiksma, & Vreede (2020).
    <doi:10.17605/OSF.IO/ZCVBS>.",2020-05-30,Caspar J. van Lissa,https://github.com/cjvanlissa/worcs,TRUE,https://github.com/cjvanlissa/worcs,267,28,2020-06-05T14:14:14Z,9.535714285714286
word2vec,"Learn vector representations of words by continuous bag of words and skip-gram implementations of the 'word2vec' algorithm. 
    The techniques are detailed in the paper ""Distributed Representations of Words and Phrases and their Compositionality"" by Mikolov et al. (2013), available at <arXiv:1310.4546>.",2020-06-04,Jan Wijffels,https://github.com/bnosac/word2vec,TRUE,https://github.com/bnosac/word2vec,0,10,2020-06-09T21:55:13Z,0
wordbankr,"Tools for connecting to Wordbank, an open repository for
    developmental vocabulary data.",2018-03-14,Mika Braginsky,https://github.com/langcog/wordbankr,TRUE,https://github.com/langcog/wordbankr,12434,10,2019-09-25T17:19:05Z,1243.4
workflowr,"Provides a workflow for your analysis projects by combining
  literate programming ('knitr' and 'rmarkdown') and version control
  ('Git', via 'git2r') to generate a website containing time-stamped,
  versioned, and documented results.",2020-04-30,John Blischak,https://github.com/jdblischak/workflowr,TRUE,https://github.com/jdblischak/workflowr,15400,457,2020-06-09T01:59:40Z,33.69803063457331
workflows,"Managing both a 'parsnip' model and a preprocessor, such as a
    model formula or recipe from 'recipes', can often be challenging. The goal
    of 'workflows' is to streamline this process by bundling the model alongside
    the preprocessor, all within the same object.",2020-03-17,Davis Vaughan,https://github.com/tidymodels/workflows,TRUE,https://github.com/tidymodels/workflows,42263,55,2020-06-04T15:41:13Z,768.4181818181818
worldmet,"Functions to import data from more than 30,000 surface
    meteorological sites around the world managed by the National Oceanic and Atmospheric Administration (NOAA) Integrated Surface
    Database (ISD, see <https://www.ncdc.noaa.gov/isd>).",2020-02-12,David Carslaw,http://github.com/davidcarslaw/worldmet,TRUE,https://github.com/davidcarslaw/worldmet,14449,21,2020-02-12T12:04:51Z,688.047619047619
worrms,"Client for World Register of Marine Species
    (<http://www.marinespecies.org/>). Includes functions for each
    of the API methods, including searching for names by name, date and
    common names, searching using external identifiers, fetching
    synonyms, as well as fetching taxonomic children and
    taxonomic classification.",2019-06-28,Scott Chamberlain,https://github.com/ropensci/worrms,TRUE,https://github.com/ropensci/worrms,98505,10,2020-05-05T18:56:03Z,9850.5
wosr,"R clients to the 'Web of Science' and 'InCites' 
  <https://clarivate.com/products/data-integration/> APIs, which 
  allow you to programmatically download publication and citation data
  indexed in the 'Web of Science' and 'InCites' databases.",2018-11-02,Christopher Baker,https://vt-arc.github.io/wosr/index.html,TRUE,https://github.com/vt-arc/wosr,9835,15,2019-11-18T23:43:37Z,655.6666666666666
wql,"Functions to assist in the processing and
    exploration of data from environmental monitoring programs.
    The package name stands for ""water quality"" and reflects the
    original focus on time series data for physical and chemical
    properties of water, as well as the biota. Intended for
    programs that sample approximately monthly, quarterly or
    annually at discrete stations, a feature of many legacy data
    sets. Most of the functions should be useful for analysis of
    similar-frequency time series regardless of the subject
    matter.",2017-07-04,Alan Jassby,https://github.com/jsta/wql,TRUE,https://github.com/jsta/wql,9762,3,2020-02-28T19:23:52Z,3254
wrapr,"Tools for writing and debugging R code. Provides: 
    '%.>%' dot-pipe (an 'S3' configurable pipe), unpack/to (R style multiple assignment/return),
    'build_frame()'/'draw_frame()' ('data.frame' example tools),
    'qc()' (quoting concatenate), 
    ':=' (named map builder), 'let()' (converts non-standard evaluation interfaces to parametric standard
    evaluation interfaces, inspired by 'gtools::strmacro()' and 'base::bquote()'), and more.",2020-03-28,John Mount,"https://github.com/WinVector/wrapr,
http://winvector.github.io/wrapr/",TRUE,https://github.com/winvector/wrapr,198228,117,2020-04-08T17:30:17Z,1694.2564102564102
wrassp,"A wrapper around Michel Scheffers's 'libassp' (<http://libassp.sourceforge.net/>). 
    The 'libassp' (Advanced Speech Signal Processor) library aims at providing
    functionality for handling speech signal files in most common audio formats
    and for performing analyses common in phonetic science/speech science. This
    includes the calculation of formants, fundamental frequency, root mean
    square, auto correlation, a variety of spectral analyses, zero crossing
    rate, filtering etc. This wrapper provides R with a large subset of
    'libassp's signal processing functions and provides them to the user in a
    (hopefully) user-friendly manner.",2020-02-15,Raphael Winkelmann,https://github.com/IPS-LMU/wrassp,TRUE,https://github.com/ips-lmu/wrassp,21295,16,2020-02-17T11:20:49Z,1330.9375
WriteXLS,"Cross-platform Perl based R function to create Excel 2003 (XLS) and Excel 2007 (XLSX)
             files from one or more data frames. Each data frame will be
             written to a separate named worksheet in the Excel spreadsheet.
             The worksheet name will be the name of the data frame it contains
             or can be specified by the user. ",2019-05-25,Marc Schwartz <marc_schwartz@me.com> and various authors for Perl modules listed in each .pm file.,https://github.com/marcschwartz/WriteXLS,TRUE,https://github.com/marcschwartz/writexls,196824,17,2019-09-24T22:37:46Z,11577.882352941177
WRTDStidal,"An adaptation for estuaries (tidal waters) of weighted regression
    on time, discharge, and season to evaluate trends in water quality time series.",2019-11-17,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/wtreg_for_estuaries,11026,0,2019-11-18T13:47:43Z,NA
wskm,"Entropy weighted k-means (ewkm) by Liping Jing, Michael
        K. Ng and Joshua Zhexue Huang (2007)
        <doi:10.1109/TKDE.2007.1048> is a weighted subspace clustering
        algorithm that is well suited to very high dimensional data.
        Weights are calculated as the importance of a variable with
        regard to cluster membership.  The two-level variable
        weighting clustering algorithm tw-k-means (twkm) by Xiaojun
        Chen, Xiaofei Xu, Joshua Zhexue Huang and Yunming Ye (2013)
        <doi:10.1109/TKDE.2011.262> introduces two types of weights,
        the weights on individual variables and the weights on
        variable groups, and they are calculated during the clustering
        process.  The feature group weighted k-means (fgkm) by Xiaojun
        Chen, Yunminng Ye, Xiaofei Xu and Joshua Zhexue Huang (2012)
        <doi:10.1016/j.patcog.2011.06.004> extends this concept by
        grouping features and weighting the group in addition to
        weighting individual features.",2020-04-05,He Zhao,"https://github.com/SimonYansenZhao/wskm,
http://english.siat.cas.cn/",TRUE,https://github.com/simonyansenzhao/wskm,59111,8,2020-04-04T01:19:50Z,7388.875
WufooR,"Allows form managers to download entries from their respondents
    using Wufoo JSON API (<https://www.wufoo.com>). Additionally, the Wufoo reports - when public - can be
    also acquired programmatically. Note that building new forms within this package
    is not supported.",2020-04-11,John Malc,https://github.com/dmpe/wufoor,TRUE,https://github.com/dmpe/wufoor,15403,0,2020-04-09T21:05:26Z,NA
wv,"Provides a series of tools to compute and plot quantities related to classical and robust wavelet variance for time series and regular lattices. More details can be found, for example, in Serroukh, A., Walden, A.T., & Percival, D.B. (2000) <doi:10.2307/2669537> and Guerrier, S. & Molinari, R. (2016) <arXiv:1607.05858>.  ",2020-01-16,Stéphane Guerrier,https://github.com/SMAC-Group/wv,TRUE,https://github.com/smac-group/wv,3430,5,2020-01-16T17:39:57Z,686
WVPlots,"Select data analysis plots, under a standardized calling interface implemented on top of 'ggplot2' and 'plotly'.  
   Plots of interest include: 'ROC', gain curve, scatter plot with marginal distributions, 
   conditioned scatter plot with marginal densities,
   box and stem with matching theoretical distribution, and density with matching theoretical distribution.",2020-05-01,John Mount,"https://github.com/WinVector/WVPlots,
https://winvector.github.io/WVPlots/",TRUE,https://github.com/winvector/wvplots,40107,76,2020-05-01T15:40:44Z,527.7236842105264
wwntests,"Provides an array of white noise hypothesis tests for functional data and related visualizations. 
  These include tests based on the norms of autocovariance operators that are built under both strong and weak 
  white noise assumptions. Additionally, tests based on the spectral density operator and on principal component
  dimensional reduction are included, which are built under strong white noise assumptions. These methods are
  described in Kokoszka et al. (2017) <doi:10.1016/j.jmva.2017.08.004>, Characiejus and Rice (2019) 
  <doi:10.1016/j.ecosta.2019.01.003>, and Gabrys and Kokoszka (2007) <doi:10.1198/016214507000001111>, 
  respectively.",2020-05-18,Daniel Petoukhov,NA,TRUE,https://github.com/jimthemadmanlahey/wwntests,4527,0,2020-01-02T19:21:08Z,NA
x12,The 'X13-ARIMA-SEATS' <https://www.census.gov/srd/www/x13as/> methodology and software is a widely used software and developed by the US Census Bureau. It can be accessed from 'R' with this package and 'X13-ARIMA-SEATS' binaries are provided by the 'R' package 'x13binary'.,2017-12-05,Alexander Kowarik,https://github.com/statistikat/x12,TRUE,https://github.com/statistikat/x12,40532,13,2020-02-27T09:31:07Z,3117.846153846154
x3ptools,"The x3p file format  is specified in ISO standard 5436:2000 to 
    describe 3d surface measurements. 'x3ptools' allows reading, writing and 
    basic modifications to the 3D surface measurements.",2019-03-27,Heike Hofmann,https://github.com/heike/x3ptools,TRUE,https://github.com/heike/x3ptools,6534,4,2020-03-13T23:01:40Z,1633.5
xaringan,"Create HTML5 slides with R Markdown and the JavaScript library
    'remark.js' (<https://remarkjs.com>).",2020-03-31,Yihui Xie,https://github.com/yihui/xaringan,TRUE,https://github.com/yihui/xaringan,84917,962,2020-03-31T14:33:00Z,88.27130977130977
xaringanthemer,"Create beautifully color-coordinated and customized
    themes for your 'xaringan' slides, without writing any CSS. Complete
    your slide theme with 'ggplot2' themes that match the font and colors
    used in your slides.  Customized styles can be created directly in
    your slides' 'R Markdown' source file or in a separate external
    script.",2020-05-04,Garrick Aden-Buie,"https://pkg.garrickadenbuie.com/xaringanthemer,
https://github.com/gadenbuie/xaringanthemer",TRUE,https://github.com/gadenbuie/xaringanthemer,1129,271,2020-05-08T03:47:37Z,4.166051660516605
xergm.common,Datasets and definitions of generic functions used in dependencies of the 'xergm' package.,2020-04-07,Philip Leifeld,http://github.com/leifeld/xergm.common,TRUE,https://github.com/leifeld/xergm.common,103034,1,2020-04-06T19:08:29Z,103034
xfun,Miscellaneous functions commonly used in other packages maintained by 'Yihui Xie'.,2020-05-20,Yihui Xie,https://github.com/yihui/xfun,TRUE,https://github.com/yihui/xfun,11563643,54,2020-06-04T21:42:52Z,214141.53703703705
xlink,"The expression of X-chromosome undergoes three possible biological processes: X-chromosome
             inactivation (XCI), escape of the X-chromosome inactivation (XCI-E),and skewed X-chromosome                    
             inactivation (XCI-S). To analyze the X-linked genetic association for phenotype such as                         
             continuous, binary, and time-to-event outcomes with the actual process unknown, we propose a unified            
             approach of maximizing the likelihood or partial likelihood over all of the potential biological             
             processes. The methods are described in Wei Xu, Meiling Hao (2017) <doi:10.1002/gepi.22097>. And 
             also see Dongxiao Han, Meiling Hao, Lianqiang Qu, Wei Xu (2019) <doi:10.1177/0962280219859037>.",2019-08-20,Yi Zhu,https://github.com/qiuanzhu/xlink,TRUE,https://github.com/qiuanzhu/xlink,3733,0,2019-08-14T02:19:42Z,NA
xlsx,Provide R functions to read/write/format Excel 2007 and Excel 97/2000/XP/2003 file formats.,2020-02-28,Cole Arendt,https://github.com/colearendt/xlsx,TRUE,https://github.com/colearendt/xlsx,4603674,61,2020-04-21T00:20:57Z,75470.0655737705
xml2,"Work with XML files using a simple, consistent
    interface. Built on top of the 'libxml2' C library.",2020-04-23,Jim Hester,"https://xml2.r-lib.org/, https://github.com/r-lib/xml2",TRUE,https://github.com/r-lib/xml2,12746961,171,2020-05-28T14:00:52Z,74543.63157894737
xml2relational,"Import an XML document with nested object structures and convert
    it into a relational data model. The result is a set of R dataframes 
    with foreign key relationships. The data model and the data can be exported as
    SQL code of different SQL flavors.",2020-05-11,Joachim Zuckarelli,https://github.com/jsugarelli/xml2relational/,TRUE,https://github.com/jsugarelli/xml2relational,425,3,2020-05-13T21:35:47Z,141.66666666666666
xmlr,"'XML' package for creating and reading and manipulating 'XML', with an object model based on 'Reference Classes'.",2020-05-12,Per Nyfelt,https://github.com/Alipsa/xmlr,TRUE,https://github.com/alipsa/xmlr,383,7,2020-05-28T17:18:48Z,54.714285714285715
xmrr,XMRs combine X-Bar control charts and Moving Range control charts. These functions also will recalculate the reference lines when significant change has occurred. ,2020-06-08,Alex Zanidean,NA,TRUE,https://github.com/zanidean/xmrr,8130,1,2020-06-08T21:06:37Z,8130
xnet,"Fit a two-step kernel ridge regression model for
        predicting edges in networks, and carry out cross-validation
        using shortcuts for swift and accurate performance assessment
        (Stock et al, 2018 <doi:10.1093/bib/bby095> ).",2020-02-03,Joris Meys,https://github.com/CenterForStatistics-UGent/xnet,TRUE,https://github.com/centerforstatistics-ugent/xnet,2327,8,2020-02-03T16:53:30Z,290.875
xoi,"Analysis of crossover interference in experimental crosses,
    particularly regarding the gamma model. See, for example,
    Broman and Weber (2000) <doi:10.1086/302923>.",2020-02-26,Karl W Broman,https://github.com/kbroman/xoi,TRUE,https://github.com/kbroman/xoi,16007,3,2020-05-30T13:17:50Z,5335.666666666667
xpectr,"Helps systematize and ease the process of 
    building unit tests with the 'testthat' package by providing 
    tools for generating expectations.",2020-03-31,Ludvig Renbo Olsen,https://github.com/ludvigolsen/xpectr,TRUE,https://github.com/ludvigolsen/xpectr,2281,27,2020-04-01T00:15:08Z,84.48148148148148
xplorerr,"Tools for interactive data exploration built using 'shiny'. Includes apps for descriptive 
    statistics, visualizing probability distributions, inferential statistics, linear regression, 
    logistic regression and RFM analysis.",2019-02-28,Aravind Hebbali,"https://github.com/rsquaredacademy/xplorerr,
https://xplorerr.rsquaredacademy.com/",TRUE,https://github.com/rsquaredacademy/xplorerr,24782,7,2019-09-25T07:28:09Z,3540.285714285714
xpose,"Diagnostics for non-linear mixed-effects (population) 
    models from 'NONMEM' <https://www.iconplc.com/innovation/nonmem/>. 
    'xpose' facilitates data import, creation of numerical run summary 
    and provide 'ggplot2'-based graphics for data exploration and model 
    diagnostics.",2020-06-08,Benjamin Guiastrennec,https://github.com/UUPharmacometrics/xpose,TRUE,https://github.com/uupharmacometrics/xpose,14998,34,2020-06-07T22:13:01Z,441.11764705882354
xrf,"An implementation of the RuleFit algorithm as described in Friedman & Popescu 
  (2008) <doi:10.1214/07-AOAS148>. eXtreme Gradient Boosting ('XGBoost') is used 
  to build rules, and 'glmnet' is used to fit a sparse linear model on the raw and rule features. The result
  is a model that learns similarly to a tree ensemble, while often offering improved interpretability
  and achieving improved scoring runtime in live applications. Several algorithms for
  reducing rule complexity are provided, most notably hyperrectangle de-overlapping. All algorithms scale to 
  several million rows and support sparse representations to handle tens of thousands of dimensions.",2020-05-03,Karl Holub,https://github.com/holub008/xrf,TRUE,https://github.com/holub008/xrf,5179,32,2020-05-03T19:37:20Z,161.84375
xrnet,"Fits hierarchical regularized regression models
    to incorporate potentially informative external data, Weaver and Lewinger (2019) <doi:10.21105/joss.01761>. 
    Utilizes coordinate descent to efficiently fit regularized regression models both with and without
    external information with the most common penalties used in practice (i.e. ridge, lasso, elastic net). 
    Support for standard R matrices, sparse matrices and big.matrix objects.",2020-03-01,Garrett Weaver,https://github.com/USCbiostats/xrnet,TRUE,https://github.com/uscbiostats/xrnet,1564,10,2020-03-05T02:47:01Z,156.4
xspliner,"Builds generalized linear model with automatic data transformation. 
  The 'xspliner' helps to build simple, interpretable models that inherits informations provided by more complicated ones.
  The resulting model may be treated as explanation of provided black box, that was supplied prior to the algorithm.",2019-09-25,Krystian Igras,https://ModelOriented.github.io/xspliner/,TRUE,https://github.com/modeloriented/xspliner,5677,14,2019-10-04T22:36:25Z,405.5
xts,"Provide for uniform handling of R's different time-based data classes by extending zoo, maximizing native format information preservation and allowing for user level customization and extension, while simplifying cross-class interoperability.",2020-01-19,Joshua M. Ulrich,https://github.com/joshuaulrich/xts,TRUE,https://github.com/joshuaulrich/xts,7392170,168,2020-05-10T13:19:12Z,44001.01190476191
yager,"Another implementation of general regression neural network in R
    based on Specht (1991) <DOI:10.1109/72.97934>. It is applicable to the 
    functional approximation or the classification. ",2020-01-14,WenSui Liu,https://github.com/statcompute/yager,TRUE,https://github.com/statcompute/yager,1628,10,2020-01-14T19:05:14Z,162.8
yaml,"Implements the 'libyaml' 'YAML' 1.1 parser and emitter
  (<http://pyyaml.org/wiki/LibYAML>) for R.",2020-02-01,Jeremy Stephens,https://github.com/viking/r-yaml/,TRUE,https://github.com/viking/r-yaml,19491933,88,2020-03-19T21:37:44Z,221499.23863636365
yap,"Another implementation of probabilistic neural network in R
    based on Specht (1990) <DOI:10.1016/0893-6080(90)90049-Q>. It is applicable to the 
    pattern recognition with a N-level response, where N > 2.",2020-01-15,WenSui Liu,https://github.com/statcompute/yap,TRUE,https://github.com/statcompute/yap,1603,7,2019-12-28T16:11:14Z,229
yardstick,"Tidy tools for quantifying how well model fits to a data set such as confusion matrices, class probability curve summaries, and regression metrics (e.g., RMSE). ",2020-03-17,Davis Vaughan,https://github.com/tidymodels/yardstick,TRUE,https://github.com/tidymodels/yardstick,169119,187,2020-05-13T14:22:23Z,904.379679144385
yarr,"A parser and a writer for 'WEKA' Attribute-Relation File Format
    <https://waikato.github.io/weka-wiki/arff_stable/> in pure R, with no dependencies. 
    As opposed to other R implementations, this package can read standard
    (dense) as well as sparse files, i.e. those where each row does only contain 
    nonzero components. Unlike 'RWeka', 'yarr' does not require any 'Java' installation
    nor is dependent on external software. This implementation is generalized from 
    those in packages 'mldr' and 'mldr.datasets'.",2019-08-10,David Charte,https://github.com/fdavidcl/yarr,TRUE,https://github.com/fdavidcl/yarr,4708,0,2019-08-10T12:31:36Z,NA
yatah,"Provides functions to manage taxonomy when lineages
    are described with strings and ranks separated with special patterns
    like ""|*__"" or "";*__"".",2020-03-01,Antoine Bichat,"https://github.com/abichat/yatah, https://abichat.github.io/yatah",TRUE,https://github.com/abichat/yatah,3749,6,2020-04-01T09:29:58Z,624.8333333333334
yesno,Asks Yes-No questions with variable or custom responses.,2020-03-04,Joe Thorley,https://github.com/poissonconsulting/yesno,TRUE,https://github.com/poissonconsulting/yesno,31284,5,2020-05-08T01:18:35Z,6256.8
yll,"Compute the standard expected years of life lost (YLL),
    as developed by the Global Burden of Disease Study
    (Murray, C.J., Lopez, A.D. and World Health Organization, 1996).
    The YLL is based on comparing the age of death to an external standard life
    expectancy curve. It also computes the average YLL, which highlights premature
    causes of death and brings attention to preventable deaths
    (Aragon et al., 2008).",2018-11-02,Antoine Soetewey,https://github.com/AntoineSoetewey/yll,TRUE,https://github.com/antoinesoetewey/yll,5406,2,2020-06-08T08:46:47Z,2703
ymlthis,"Write 'YAML' front matter for R Markdown and related
    documents. yml_*() functions write 'YAML' and use_*() functions let
    you write the resulting 'YAML' to your clipboard or to .yml files
    related to your project.",2020-02-03,Malcolm Barrett,"https://ymlthis.r-lib.org, https://github.com/r-lib/ymlthis",TRUE,https://github.com/r-lib/ymlthis,5036,118,2020-04-03T18:02:58Z,42.67796610169491
yonder,"Build 'shiny' applications with the latest Bootstrap components
    and design utilities. Includes refreshed reactive inputs and outputs.
    Use responsive layouts to design and construct applications for devices
    of all sizes.",2020-01-10,Nathan Teetor,https://nteetor.github.io/yonder,TRUE,https://github.com/nteetor/yonder,4404,117,2020-03-14T03:31:42Z,37.64102564102564
yorkr,"Analyzing performances of cricketers and cricket teams
             based on 'yaml' match data from Cricsheet <http://cricsheet.org>.",2020-05-15,Tinniam V Ganesh,https://github.com/tvganesh/yorkr,TRUE,https://github.com/tvganesh/yorkr,12830,12,2020-05-13T07:36:19Z,1069.1666666666667
youtubecaption,"Although there exist some R packages tailored for YouTube API (e.g., 'tuber'), downloading YouTube video subtitle (i.e., caption) in a tidy form has never been a low-hanging fruit. Using 'youtube-transcript-api Python package' under the hood, this R package provides users with a convenient way of parsing and converting a desired YouTube caption into a handy 'tibble' data_frame object. Furthermore, users can easily save a desired YouTube caption data as a tidy Excel file without advanced programming background knowledge.",2020-05-15,JooYoung Seo,https://github.com/jooyoungseo/youtubecaption,TRUE,https://github.com/jooyoungseo/youtubecaption,5197,7,2020-05-15T14:13:47Z,742.4285714285714
YPPE,Semiparametric modeling of lifetime data with crossing survival curves via Yang and Prentice model with piecewise exponential baseline distribution. Details about the model can be found in Demarqui and Mayrink (2019) <arXiv:1910.02406>. Model fitting carried out via likelihood-based and Bayesian approaches. The package also provides point and interval estimation for the crossing survival times.,2020-01-09,Fabio Demarqui,https://github.com/fndemarqui/YPPE,TRUE,https://github.com/fndemarqui/yppe,2955,2,2020-01-05T12:09:37Z,1477.5
ypr,"An implementation of equilibrium-based yield per recruit methods.
    Yield per recruit methods can used to estimate the optimal yield for a fish population
    as described by Walters and Martell (2004) <isbn:0-691-11544-3>.
    The yield can be based on the number of fish caught (or harvested) or 
    biomass caught for all fish or just large (trophy) individuals.",2020-03-18,Joe Thorley,https://github.com/poissonconsulting/ypr,TRUE,https://github.com/poissonconsulting/ypr,5948,2,2020-05-08T01:19:25Z,2974
zbank,"Interface to the 'ZooBank' API (<http://zoobank.org/Api>) client.
    'ZooBank' (<http://zoobank.org/>) is the official registry of zoological 
    nomenclature. Methods are provided for using each of the API endpoints, 
    including for querying by author, querying for publications, get 
    statistics on 'ZooBank' activity, and more.",2018-10-30,Scott Chamberlain,https://github.com/ropenscilabs/zbank,TRUE,https://github.com/ropenscilabs/zbank,5434,2,2019-12-09T21:38:35Z,2717
zeallot,"Provides a %<-% operator to perform multiple,
    unpacking, and destructuring assignment in R. The 
    operator unpacks the right-hand side of an assignment
    into multiple values and assigns these values to 
    variables on the left-hand side of the assignment.",2018-01-28,Nathan Teetor,https://github.com/nteetor/zeallot,TRUE,https://github.com/nteetor/zeallot,6340636,184,2020-03-12T00:52:18Z,34459.97826086957
zeitgebr,"Use behavioural variables to compute period, rhythmicity and other circadian parameters.
  Methods include computation of chi square periodograms (Sokolove and Bushell (1978) <DOI:10.1016/0022-5193(78)90022-X>),
  Lomb-Scargle periodograms (Lomb (1976) <DOI:10.1007/BF00648343>, Scargle (1982) <DOI:10.1086/160554>, Ruf (1999) <DOI:10.1076/brhm.30.2.178.1422>),
  and autocorrelation-based periodograms.",2020-04-25,Quentin Geissmann,https://github.com/rethomics/zeitgebr,TRUE,https://github.com/rethomics/zeitgebr,7985,4,2020-06-09T18:24:24Z,1996.25
zen4R,"Provides an Interface to 'Zenodo' (<https://zenodo.org>) REST API, 
  including management of depositions, attribution of DOIs by 'Zenodo' and 
  upload of files.",2019-08-27,Emmanuel Blondel,https://github.com/eblondel/zen4R,TRUE,https://github.com/eblondel/zen4r,4420,9,2020-04-22T17:32:17Z,491.1111111111111
zFactor,"Computational algorithms to solve equations and find the
    'compressibility' factor `z` of hydrocarbon gases. Correlations available: 
    'Hall-Yarborough', 'Dranchuk-AbuKassem', 'Dranchuk-Purvis-Robinson', 'Beggs-Brill', 
    'Papp', Shell and an Artificial Neural Network correlation (Ann10) by 'Kamyab' 
    'et al'. The package uses the original 'Standing-Katz' chart for statistical 
    comparison and plotting. Applicable to sweet hydrocarbon gases for now.",2019-08-01,Alfonso R. Reyes,https://github.com/f0nzie/zFactor,TRUE,https://github.com/f0nzie/zfactor,7017,9,2019-08-01T23:32:46Z,779.6666666666666
ZIM,"Analyze count time series with excess zeros. 
    Two types of statistical models are supported: Markov regression by Yang et al.
    (2013) <doi:10.1016/j.stamet.2013.02.001> and state-space models by Yang et al. 
    (2015) <doi:10.1177/1471082X14535530>. They are also known as observation-driven and 
    parameter-driven models respectively in the time series literature. The functions used for 
    Markov regression or observation-driven models can also be used to fit ordinary regression models 
    with independent data under the zero-inflated Poisson (ZIP) or zero-inflated negative binomial (ZINB) 
    assumption. Besides, the package contains some miscellaneous functions to compute density, distribution, 
    quantile, and generate random numbers from ZIP and ZINB distributions.",2018-08-28,Ming Yang,https://github.com/biostatstudio/ZIM,TRUE,https://github.com/biostatstudio/zim,25553,5,2019-09-07T04:36:34Z,5110.6
zipangu,"Some data treated by the Japanese R user require
    unique operations and processing. These are caused by address, Kanji,
    and traditional year representations.  'zipangu' transforms specific
    to Japan into something more general one.",2020-01-10,Shinya Uryu,"https://uribo.github.io/zipangu, https://github.com/uribo/zipangu",TRUE,https://github.com/uribo/zipangu,2967,24,2020-05-03T20:09:01Z,123.625
ZIPFA,"Estimation methods for zero-inflated Poisson factor analysis (ZIPFA) on sparse data. 
    It provides estimates of coefficients in a new type of zero-inflated regression. 
    It provides a cross-validation method to determine the potential rank of the data in the ZIPFA 
    and conducts zero-inflated Poisson factor analysis based on the determined rank.",2020-03-31,Tianchen Xu,"https://zjph602xtc.github.io/ZIPFA/,
https://arxiv.org/abs/1910.11985",TRUE,https://github.com/zjph602xtc/zipfa,2882,1,2020-03-17T04:44:14Z,2882
zipfextR,"Implementation of four extensions of the Zipf distribution: the Marshall-Olkin 
  Extended Zipf (MOEZipf) Pérez-Casany, M., & Casellas, A. (2013) <arXiv:1304.4540>, the Zipf-Poisson Extreme (Zipf-PE), the 
  Zipf-Poisson Stopped Sum (Zipf-PSS) and the Zipf-Polylog distributions. 
  In log-log scale, the two first extensions allow for top-concavity 
  and top-convexity while the third one only allows for top-concavity. 
  All the extensions maintain the linearity associated with the Zipf model in the tail.",2019-09-18,Ariel Duarte-López,https://github.com/ardlop/zipfextR,TRUE,https://github.com/ardlop/zipfextr,8134,0,2020-05-07T10:20:49Z,NA
zoltr,"'Zoltar' <https://www.zoltardata.com/> is a website that provides a repository of model forecast results
    in a standardized format and a central location. It supports storing, retrieving, comparing, and analyzing time
    series forecasts for prediction challenges of interest to the modeling community. This package provides functions
    for working with the 'Zoltar' API, including connecting and authenticating, getting information about projects,
    models, and forecasts, deleting and uploading forecast data, and downloading scores.",2020-04-15,Matthew Cornell,"https://github.com/reichlab/zoltr , http://reichlab.io/zoltr/",TRUE,https://github.com/reichlab/zoltr,4127,0,2020-06-09T17:08:36Z,NA
zonator,"Create new analysis setups and deal with results of 
    Zonation conservation prioritization software <https://github.com/cbig/zonation-core>. 
    This package uses data available in the 'zdat' (7.7 MB) package 
    for building the vignettes.",2020-05-18,Joona Lehtomaki,https://cbig.github.io/zonator/,TRUE,https://github.com/cbig/zonator,4054,9,2020-05-18T18:29:08Z,450.44444444444446
zoom,"zm(), called with any active plot allow to enter an
    interactive session to zoom/navigate any plot. The development
    version, as well as binary releases can be found at
    https://github.com/cbarbu/R-package-zoom",2013-10-15,Corentin M Barbu,https://github.com/cbarbu/R-package-zoom,TRUE,https://github.com/cbarbu/r-package-zoom,60644,5,2020-06-04T14:40:38Z,12128.8
zoon,"Reproducible and remixable species distribution modelling.
    The package reads user submitted modules from an online repository, runs
    full species distribution modelling workflows and returns output that is
    fully reproducible. For examples and detailed discussion refer to: N.Golding
    et al. (2017) 'The zoon r package for reproducible and shareable species
    distribution modelling'. Methods in Ecology and Evolution.
    <doi:10.1111/2041-210X.12858>. The package 'SDMTools' is used for testing
    and, though this package is archived, you can access it here if 
    needed, <https://cran.r-project.org/src/contrib/Archive/SDMTools/>. ",2020-02-28,Tom August,https://github.com/zoonproject/zoon,TRUE,https://github.com/zoonproject/zoon,13199,54,2020-02-28T12:37:41Z,244.42592592592592
zscorer,"A tool for calculating z-scores and centiles for weight-for-age, 
    length/height-for-age, weight-for-length/height, BMI-for-age, 
    head circumference-for-age, age circumference-for-age, 
    subscapular skinfold-for-age, triceps skinfold-for-age based on the 
    WHO Child Growth Standards. ",2019-10-19,Mark Myatt,https://github.com/nutriverse/zscorer,TRUE,https://github.com/nutriverse/zscorer,9394,5,2019-10-19T19:00:40Z,1878.8
zzlite,"A minor collection of HTTP wrappers for the 'Zamzar File Conversion'
    API. The wrappers makes it easy to utilize the API and thus convert
    between more than 100 different file formats (ranging from audio files,
    images, movie formats, etc., etc.) through an R session.  
    For specifics regarding the API, please see <https://developers.zamzar.com/>.",2020-03-18,Frederik Kok Hansen,NA,TRUE,https://github.com/fkoh111/zzlite,1832,0,2020-03-18T16:56:49Z,NA
