name,description,published,author,url,github_ind,github_url,downloads,stars,last_commit,downloads_per_star
AATtools,"Compute approach bias scores using different scoring algorithms,
    compute bootstrapped and exact split-half reliability estimates,
    and compute confidence intervals for individual participant scores.",2020-06-14,Sercan Kahveci,NA,TRUE,https://github.com/spiritspeak/aattools,11870,0,2022-05-27T16:25:22Z,NA
abbreviate,"Strings are abbreviated to at least ""minlength"" characters, such that they remain unique 
    (if they were). The abbreviations should be recognisable.",2021-12-14,Sigbert Klinke,https://github.com/sigbertklinke/abbreviate (development version),TRUE,https://github.com/sigbertklinke/abbreviate,5999,5,2021-12-14T09:46:57Z,1199.8
abclass,"Multi-category angle-based large-margin classifiers.
    See Zhang and Liu (2014) <doi:10.1093/biomet/asu017> for details.",2022-05-28,Wenjie Wang,"https://wwenjie.org/abclass,
https://github.com/wenjie2wang/abclass",TRUE,https://github.com/wenjie2wang/abclass,1977,2,2022-06-23T18:23:05Z,988.5
abess,"Extremely efficient toolkit for solving the best subset selection problem <arXiv:2110.09697>. This package is its R interface. The package implements and generalizes algorithms designed in <doi:10.1073/pnas.2014241117> that exploits a novel sequencing-and-splicing technique to guarantee exact support recovery and globally optimal solution in polynomial times for linear model. It also supports best subset selection for logistic regression, Poisson regression, Cox proportional hazard model, Gamma regression, multiple-response regression, multinomial logistic regression, ordinal regression, (sequential) principal component analysis, and robust principal component analysis. The other valuable features such as the best subset of group selection <arXiv:2104.12576> and sure independence screening <doi:10.1111/j.1467-9868.2008.00674.x> are also provided.  ",2022-03-22,Jin Zhu,"https://github.com/abess-team/abess,
https://abess-team.github.io/abess/,
https://abess.readthedocs.io",TRUE,https://github.com/abess-team/abess,9703,270,2022-06-19T14:22:39Z,35.93703703703704
abjutils,"The Brazilian Jurimetrics Association (ABJ in Portuguese, see
    <https://abj.org.br/> for more information) is a non-profit
    organization which aims to investigate and promote the use of
    statistics and probability in the study of Law and its institutions.
    This package implements general purpose tools used by ABJ, such as
    functions for sampling and basic manipulation of Brazilian lawsuits
    identification number. It also implements functions for text cleaning,
    such as accentuation removal.",2022-02-01,Caio Lente,https://github.com/abjur/abjutils,TRUE,https://github.com/abjur/abjutils,28351,42,2022-02-01T17:09:47Z,675.0238095238095
abstr,"Provides functions to convert origin-destination data,
    represented as straight 'desire lines' in the 'sf' Simple Features
    class system, into JSON files that can be directly imported into
    A/B Street <https://www.abstreet.org>, a free and open source tool
    for simulating urban transport systems and scenarios of change
    <doi:10.1007/s10109-020-00342-2>.",2021-11-30,Nathanael Sheehan,"https://github.com/a-b-street/abstr,
https://a-b-street.github.io/abstr/",TRUE,https://github.com/a-b-street/abstr,4620,30,2022-04-18T10:50:23Z,154
academictwitteR,"Package to query the Twitter Academic Research Product Track,
    providing access to full-archive search and other v2 API endpoints. Functions
    are written with academic research in mind. They provide flexibility in how 
    the user wishes to store collected data, and encourage regular storage of data
    to mitigate loss when collecting large volumes of tweets. They also provide
    workarounds to manage and reshape the format in which data is provided on
    the client side.",2022-02-16,Christopher Barrie,https://github.com/cjbarrie/academictwitteR,TRUE,https://github.com/cjbarrie/academictwitter,17547,222,2022-06-05T22:17:19Z,79.04054054054055
accessibility,"A set of fast and convenient functions to calculate multiple 
             transport accessibility measures. Given a pre-computed travel cost 
             matrix in long format combined with land-use  data (e.g. location 
             of  jobs, healthcare, population), the package  allows one to 
             calculate active and passive accessibility levels using multiple 
             accessibility metrics such as: cumulative opportunity measure 
             (using either travel time cutoff or interval), minimum travel cost 
             to closest N number of activities, gravitational measures and 
             different floating catchment area methods.",2022-06-30,Rafael H. M. Pereira,https://github.com/ipeaGIT/accessibility,TRUE,https://github.com/ipeagit/accessibility,142,17,2022-07-07T21:08:09Z,8.352941176470589
accrualPlot,"Tracking accrual in clinical trials is important for trial success. 
    If accrual is too slow, the trial will take too long and be too expensive. If
    accrual is much faster than expected, time sensitive tasks such as the writing 
    of statistical analysis plans might need to be rushed. 'accrualPlot' provides 
    functions to aid the tracking of accrual and predict when a trial will reach 
    it's intended sample size.",2022-05-09,Lukas Bütikofer,https://github.com/CTU-Bern/accrualPlot,TRUE,https://github.com/ctu-bern/accrualplot,651,1,2022-06-22T08:05:04Z,651
accucor,"An isotope natural abundance correction algorithm that
  is needed especially for high resolution mass spectrometers. Supports
  correction for 13C, 2H and 15N. Su X, Lu W and Rabinowitz J (2017)
  <doi:10.1021/acs.analchem.7b00396>.",2021-11-17,Xiaoyang Su,https://github.com/XiaoyangSu/AccuCor,TRUE,https://github.com/xiaoyangsu/accucor,7312,11,2021-11-17T01:32:29Z,664.7272727272727
ACDC,"Features tools for exploring congruent phylogenetic birth-death models. It can construct the pulled speciation- and net-diversification rates from a reference model. Given alternative speciation- or extinction rates, it can construct new models that are congruent with the reference model. Functionality is included to sample new rate functions, and to visualize the distribution of one congruence class. See also Louca & Pennell (2020) <doi:10.1038/s41586-020-2176-1>.",2022-01-12,Bjørn Tore Kopperud,https://github.com/afmagee/ACDC,TRUE,https://github.com/afmagee/acdc,2299,3,2022-06-17T13:28:23Z,766.3333333333334
acdcR,"The functions are designed to calculate the most widely-used county-level variables in 
  agricultural production or agricultural-climatic and weather analyses. To operate some functions 
  in this package needs download of the bulk PRISM raster. See the examples, testing versions and 
  more details from: <https://github.com/ysd2004/acdcR>.",2022-06-27,Seong D. Yun,https://github.com/ysd2004/acdcR,TRUE,https://github.com/ysd2004/acdcr,186,0,2022-06-27T12:15:09Z,NA
acnr,"Provides SNP array data from different types of
    copy-number regions. These regions were identified manually by the authors
    of the package and may be used to generate realistic data sets with known
    truth.",2017-04-18,Morgane Pierre-Jean,https://github.com/mpierrejean/acnr,TRUE,https://github.com/mpierrejean/acnr,21307,1,2021-11-18T07:46:06Z,21307
act,"The Aligned Corpus Toolkit (act) is designed for linguists that work with time aligned transcription data. It offers functions to import and export various annotation file formats ('ELAN' .eaf, 'EXMARaLDA .exb and 'Praat' .TextGrid files), create print transcripts in the style of conversation analysis, search transcripts (span searches across multiple annotations, search in normalized annotations, make concordances etc.), export and re-import search results (.csv and 'Excel' .xlsx format), create cuts for the search results (print transcripts, audio/video cuts using 'FFmpeg' and video sub titles in 'Subrib title' .srt format), modify the data in a corpus (search/replace, delete, filter etc.), interact with 'Praat' using 'Praat'-scripts, and exchange data with the 'rPraat' package. The package is itself written in R and may be expanded by other users.",2021-09-26,Oliver Ehmer,"http://www.oliverehmer.de, https://github.com/oliverehmer/act",TRUE,https://github.com/oliverehmer/act,10732,3,2021-09-26T17:13:58Z,3577.3333333333335
ActCR,"Circadian rhythms are rhythms that oscillate about every 24 h, which has been observed in multiple physiological processes including core body temperature, hormone secretion, heart rate, blood pressure, and many others. Measuring circadian rhythm with wearables is based on a principle that there is increased movement during wake periods and reduced movement during sleep periods, and has been shown to be reliable and valid. This package can be used to extract nonparametric circadian metrics like intradaily variability (IV), interdaily stability (IS), and relative amplitude (RA); and parametric cosinor model and extended cosinor model coefficient. Details can be found in Junrui Di et al (2019) <doi:10.1007/s12561-019-09236-4>.",2022-05-11,Junrui Di,https://github.com/junruidi/ActCR,TRUE,https://github.com/junruidi/actcr,12108,1,2022-05-11T05:01:10Z,12108
actel,"Designed for studies where animals tagged with acoustic tags are expected
    to move through receiver arrays. This package combines the advantages of automatic sorting and checking 
    of animal movements with the possibility for user intervention on tags that deviate from expected 
    behaviour. The three analysis functions (explore(), migration() and residency()) 
    allow the users to analyse their data in a systematic way, making it easy to compare results from 
    different studies.
    CJS calculations are based on Perry et al. (2012) <https://www.researchgate.net/publication/256443823_Using_mark-recapture_models_to_estimate_survival_from_telemetry_data>.",2021-01-05,Hugo Flávio,https://github.com/hugomflavio/actel,TRUE,https://github.com/hugomflavio/actel,16351,21,2022-04-14T19:44:37Z,778.6190476190476
ActivePathways,"Framework for analysing multiple omics datasets in the context of molecular pathways, biological processes and other types of gene sets. The package uses p-value merging to combine gene- or protein-level signals, followed by ranked hypergeometric tests to determine enriched pathways and processes. This approach allows researchers to interpret a series of omics datasets in the context of known biology and gene function, and discover associations that are only apparent when several datasets are combined. The package is part of the following publication: Integrative Pathway Enrichment Analysis of Multivariate Omics Data. Paczkowska M^, Barenboim J^, Sintupisut N, Fox NS, Zhu H, Abd-Rabbo D, Mee MW, Boutros PC, PCAWG Drivers and Functional Interpretation Working Group; Reimand J, PCAWG Consortium. Nature Communications (2020) <doi:10.1038/s41467-019-13983-9>.",2022-07-08,Juri Reimand,NA,TRUE,https://github.com/reimandlab/activepathways,15021,65,2022-07-01T17:10:36Z,231.09230769230768
activityCounts,"ActiLife software generates activity counts from data collected by Actigraph accelerometers <https://s3.amazonaws.com/actigraphcorp.com/wp-content/uploads/2017/11/26205758/ActiGraph-White-Paper_What-is-a-Count_.pdf>.
  Actigraph is one of the most common research-grade accelerometers. There is considerable research
  validating and developing algorithms for human activity using ActiLife counts. Unfortunately,
  ActiLife counts are proprietary and difficult to implement if researchers use different accelerometer brands.
  The code  creates ActiLife counts from raw acceleration data for different accelerometer brands and it is developed
  based on the study done by Brond and others (2017) <doi:10.1249/MSS.0000000000001344>.",2019-07-31,SeyedJavad KhataeiPour,"https://github.com/walkabillylab/activityCounts,
https://github.com/jbrond/ActigraphCounts",TRUE,https://github.com/walkabillylab/activitycounts,18099,4,2022-03-29T20:12:32Z,4524.75
ACWR,"Functions for calculating the acute chronic workload ratio using three 
            different methods: exponentially weighted moving average (EWMA), rolling 
            average coupled (RAC) and rolling averaged uncoupled (RAU). Examples of this 
            methods can be found in Williams et al. (2017) <doi:10.1136/bjsports-2016-096589>
            for EWMA and Windt & Gabbet (2018) for RAC and RAU <doi: 10.1136/bjsports-2017-098925>.",2022-03-01,Jorge R Fernandez-Santos,https://github.com/JorgeDelro/ACWR,TRUE,https://github.com/jorgedelro/acwr,1426,0,2022-02-24T14:41:17Z,NA
adaHuber,"Huber-type estimation for mean, covariance and (regularized) regression. For all the methods, the robustification parameter tau is chosen by a tuning-free principle.",2022-03-09,Xiaoou Pan,https://github.com/XiaoouPan/adaHuber,TRUE,https://github.com/xiaooupan/adahuber,1365,6,2022-03-12T06:12:39Z,227.5
adaptDiag,"Simulate clinical trials for diagnostic test devices and evaluate 
    the operating characteristics under an adaptive design with futility
    assessment determined via the posterior predictive probabilities.",2021-08-17,Graeme L. Hickey,https://github.com/graemeleehickey/adaptDiag,TRUE,https://github.com/graemeleehickey/adaptdiag,4607,3,2021-08-16T16:39:26Z,1535.6666666666667
adaptr,"Package that simulates adaptive clinical trials using adaptive
    stopping, adaptive arm dropping, and/or adaptive randomisation.
    Developed as part of the INCEPT (Intensive Care Platform Trial) project
    (<https://incept.dk/>), which is primarily supported by a grant
    from Sygeforsikringen ""danmark"" (<https://www.sygeforsikring.dk/>).",2022-06-17,Anders Granholm,"https://incept.dk/, https://github.com/INCEPTdk/adaptr/,
https://inceptdk.github.io/adaptr/",TRUE,https://github.com/inceptdk/adaptr,1409,2,2022-06-20T11:35:56Z,704.5
adass,Implements the adaptive smoothing spline estimator for the function-on-function linear regression model described in Centofanti et al. (2020) <arXiv:2011.12036>.,2021-11-18,Fabio Centofanti,https://github.com/unina-sfere/adass,TRUE,https://github.com/unina-sfere/adass,2764,1,2021-11-18T15:24:40Z,2764
addinslist,"Browse through a continuously updated list of existing RStudio 
    addins and install/uninstall their corresponding packages.",2021-01-10,Dean Attali,https://github.com/daattali/addinslist,TRUE,https://github.com/daattali/addinslist,35197,722,2022-02-23T07:05:55Z,48.74930747922438
additive,"Fit Generalized Additive Models (GAM) using 'mgcv' with 'parsnip'/'tidymodels'
    via 'additive' <doi:10.5281/zenodo.6654298>. 'tidymodels' is a collection of
    packages for machine learning; see Kuhn and Wickham (2020) <https://www.tidymodels.org>).
    The technical details of 'mgcv' are described in Wood (2017)
    <doi:10.1201/9781315370279>.",2022-06-16,Hamada S. Badr,"https://hsbadr.github.io/additive/,
https://github.com/hsbadr/additive",TRUE,https://github.com/hsbadr/additive,7396,2,2022-07-08T14:44:10Z,3698
ade4,"Tools for multivariate data analysis. Several methods are provided for the analysis (i.e., ordination) of one-table (e.g., principal component analysis, correspondence analysis), two-table (e.g., coinertia analysis, redundancy analysis), three-table (e.g., RLQ analysis) and K-table (e.g., STATIS, multiple coinertia analysis). The philosophy of the package is described in Dray and Dufour (2007) <doi:10.18637/jss.v022.i04>.",2022-04-19,Stéphane Dray,http://pbil.univ-lyon1.fr/ADE-4/,TRUE,https://github.com/sdray/ade4,1399166,21,2022-06-29T13:18:09Z,66626.95238095238
ade4TkGUI,A Tcl/Tk GUI for some basic functions in the 'ade4' package.,2020-12-03,Jean Thioulouse,"http://pbil.univ-lyon1.fr/ade4TkGUI/, Mailing list:
https://listes.univ-lyon1.fr/sympa/info/adelist",TRUE,https://github.com/aursiber/ade4tkgui,75036,0,2021-11-24T12:57:11Z,NA
adegenet,"Toolset for the exploration of genetic and genomic
    data. Adegenet provides formal (S4) classes for storing and handling
    various genetic data, including genetic markers with varying ploidy
    and hierarchical population structure ('genind' class), alleles counts
    by populations ('genpop'), and genome-wide SNP data ('genlight'). It
    also implements original multivariate methods (DAPC, sPCA), graphics,
    statistical tests, simulation tools, distance and similarity measures,
    and several spatial methods. A range of both empirical and simulated
    datasets is also provided to illustrate various methods.",2022-06-06,Thibaut Jombart,https://github.com/thibautjombart/adegenet,TRUE,https://github.com/thibautjombart/adegenet,298024,148,2022-06-07T16:41:03Z,2013.6756756756756
adegraphics,Graphical functionalities for the representation of multivariate data. It is a complete re-implementation of the functions available in the 'ade4' package.,2021-09-16,Stéphane Dray,"http://pbil.univ-lyon1.fr/ADE-4/, Mailing list:
https://listes.univ-lyon1.fr/sympa/info/adelist",TRUE,https://github.com/sdray/adegraphics,120699,6,2021-11-23T09:28:43Z,20116.5
adespatial,"Tools for the multiscale spatial analysis of multivariate data.
    Several methods are based on the use of a spatial weighting matrix and its
    eigenvector decomposition (Moran's Eigenvectors Maps, MEM). 
    Several approaches are described in the review Dray et al (2012)
    <doi:10.1890/11-1183.1>.",2022-03-31,Stéphane Dray,https://github.com/sdray/adespatial,TRUE,https://github.com/sdray/adespatial,85384,22,2022-04-01T21:59:39Z,3881.090909090909
adfExplorer,"Amiga Disk Files (ADF) are virtual
    representations of 3.5 inch floppy disks for the
    Commodore Amiga. Most disk drives from other systems
    (including modern drives) are not able to read these
    disks. To be able to emulate this system, the ADF
    format was created. This package enables you to read
    ADF files and import and export files from and to such
    virtual DOS-formatted disks.",2021-09-05,Pepijn de Vries,https://github.com/pepijn-devries/adfExplorer,TRUE,https://github.com/pepijn-devries/adfexplorer,22830,2,2021-09-05T11:28:10Z,11415
AdhereR,"Computation of adherence to medications from Electronic Health care 
    Data and visualization of individual medication histories and adherence 
    patterns. The package implements a set of S3 classes and
    functions consistent with current adherence guidelines and definitions. 
    It allows the computation of different measures of
    adherence (as defined in the literature, but also several original ones), 
    their publication-quality plotting,
    the estimation of event duration and time to initiation,
    the interactive exploration of patient medication history and 
    the real-time estimation of adherence given various parameter settings.
    It scales from very small datasets stored in flat CSV files to very large 
    databases and from single-thread processing on mid-range consumer
    laptops to parallel processing on large heterogeneous computing clusters.
    It exposes a standardized interface allowing it to be used from other
    programming languages and platforms, such as Python.",2022-07-05,Dan Dediu,https://github.com/ddediu/AdhereR,TRUE,https://github.com/ddediu/adherer,25586,21,2022-07-06T12:19:17Z,1218.3809523809523
AdhereRViz,"Interactive graphical user interface (GUI) for the package 
    'AdhereR', allowing the user to access different data sources, to explore 
    the patterns of medication use therein, and the computation of various  
    measures of adherence. It is implemented using Shiny and HTML/CSS/JavaScript. ",2022-06-24,Dan Dediu,https://github.com/ddediu/AdhereR,TRUE,https://github.com/ddediu/adherer,12023,21,2022-07-06T12:19:17Z,572.5238095238095
adjclust,"Implements a constrained version of hierarchical agglomerative 
    clustering, in which each observation is associated to a position, and 
    only adjacent clusters can be merged. Typical application fields in 
    bioinformatics include Genome-Wide Association Studies or Hi-C data 
    analysis, where the similarity between items is a decreasing function of 
    their genomic distance. Taking advantage of this feature, the implemented 
    algorithm is time and memory efficient. This algorithm is described in 
    Ambroise et al (2019) <https://almob.biomedcentral.com/articles/10.1186/s13015-019-0157-4>.",2022-03-31,Pierre Neuvial,https://pneuvial.github.io/adjclust/,TRUE,https://github.com/pneuvial/adjclust,20864,15,2022-03-31T12:38:50Z,1390.9333333333334
adjROC,"For a binary classification the adjusted sensitivity and specificity are measured for a given fixed threshold. If the threshold for either sensitivity or specificity is not given, the crossing point between the sensitivity and specificity curves are returned.",2022-03-23,E. F. Haghish,"https://github.com/haghish/adjROC,
https://www.sv.uio.no/psi/english/people/aca/haghish/",TRUE,https://github.com/haghish/adjroc,1264,0,2022-05-03T17:58:31Z,NA
admiral,"A toolbox for programming Clinical Data Standards Interchange Consortium
    (CDISC) compliant Analysis Data Model (ADaM) datasets in R. ADaM datasets are a
    mandatory part of any New Drug or Biologics License Application submitted to the
    United States Food and Drug Administration (FDA). Analysis derivations are
    implemented in accordance with the ""Analysis Data Model Implementation Guide""
    (CDISC Analysis Data Model Team, 2021, <https://www.cdisc.org/standards/foundational/adam/adamig-v1-3-release-package>).",2022-05-31,Thomas Neitmann,"https://pharmaverse.github.io/admiral/index.html,
https://github.com/pharmaverse/admiral/",TRUE,https://github.com/pharmaverse/admiral,2170,89,2022-06-01T14:35:38Z,24.382022471910112
admisc,"Contains functions used across packages 'DDIwR', 'QCA' and 'venn'.
    Interprets and translates, factorizes and negates SOP - Sum of Products
    expressions, for both binary and multi-value crisp sets, and extracts
    information (set names, set values) from those expressions. Other functions
    perform various other checks if possibly numeric (even if all numbers reside
    in a character vector) and coerce to numeric, or check if the numbers are
    whole. It also offers, among many others, a highly versatile recoding
    routine and a more flexible alternative to the base function 'with()'.
    Some of the functions in this package use related functions from package
    'QCA'. Users are encouraged to install that package despite not being listed
    in the Imports field, due to circular dependency issues.",2022-06-20,Adrian Dusa,https://github.com/dusadrian/admisc,TRUE,https://github.com/dusadrian/admisc,214802,0,2022-06-20T17:09:23Z,NA
AdMit,"Provides functions to perform the fitting of an adaptive mixture
    of Student-t distributions to a target density through its kernel function as described in
    Ardia et al. (2009) <doi:10.18637/jss.v029.i03>. The
    mixture approximation can then be used as the importance density in importance
    sampling or as the candidate density in the Metropolis-Hastings algorithm to
    obtain quantities of interest for the target density itself. ",2022-02-08,David Ardia,https://github.com/ArdiaD/AdMit,TRUE,https://github.com/ardiad/admit,31008,3,2022-02-07T23:48:37Z,10336
admix,"Implements several methods to estimate the unknown quantities related 
    to two-component admixture models, where the two components can belong to any
    distribution (note that in the case of multinomial mixtures, the two components
    must belong to the same family). Estimation methods depend on the assumptions 
    made on the unknown component density (see Bordes and Vandekerkhove (2010) <doi:10.3103/S1066530710010023>; 
    Patra and Sen (2016) <doi:10.1111/rssb.12148>); Milhaud, Pommeret, Salhi and Vandekerkhove 
    (2021) <doi:10.1016/j.jspi.2021.05.010>). In practice, one can estimate both the 
    mixture weight and the unknown component density in a wide variety of frameworks.
    On top of that, hypothesis tests can be performed in one and two-samples contexts 
    to test the unknown component density. Finally, clustering of unknown
    mixture components is also feasible in a K-samples setting.",2022-03-24,Xavier Milhaud,https://github.com/XavierMilhaud/admix,TRUE,https://github.com/xaviermilhaud/admix,5459,1,2022-03-24T11:16:29Z,5459
admixr,"An interface for performing all stages of 'ADMIXTOOLS' analyses
    (<https://reich.hms.harvard.edu/software>) entirely from R. Wrapper functions
    (D, f4, f3, etc.) completely automate the generation of intermediate
    configuration files, run 'ADMIXTOOLS' programs on the command-line, and
    parse output files to extract values of interest. This allows users to focus
    on the analysis itself instead of worrying about low-level technical details.
    A set of complementary functions for processing and filtering of data in
    the 'EIGENSTRAT' format is also provided.",2020-07-03,Martin Petr,https://github.com/bodkan/admixr,TRUE,https://github.com/bodkan/admixr,10715,20,2022-02-20T20:10:13Z,535.75
adobeanalyticsr,"Connect to the 'Adobe Analytics' API v2.0 <https://github.com/AdobeDocs/analytics-2.0-apis>
             which powers 'Analysis Workspace'. The package was developed
             with the analyst in mind, and it will continue to be
             developed with the guiding principles of iterative,
             repeatable, timely analysis.",2022-04-05,Ben Woodard,https://github.com/benrwoodard/adobeanalyticsr,TRUE,https://github.com/benrwoodard/adobeanalyticsr,8688,13,2022-05-21T03:31:02Z,668.3076923076923
ADPclust,"An implementation of ADPclust clustering procedures (Fast
    Clustering Using Adaptive Density Peak Detection). The work is built and
    improved upon the idea of Rodriguez and Laio (2014)<DOI:10.1126/science.1242072>. 
    ADPclust clusters data by finding density peaks in a density-distance plot 
    generated from local multivariate Gaussian density estimation. It includes 
    an automatic centroids selection and parameter optimization algorithm, which 
    finds the number of clusters and cluster centroids by comparing average 
    silhouettes on a grid of testing clustering results; It also includes a user 
    interactive algorithm that allows the user to manually selects cluster 
    centroids from a two dimensional ""density-distance plot"". Here is the 
    research article associated with this package: ""Wang, Xiao-Feng, and 
    Yifan Xu (2015)<DOI:10.1177/0962280215609948> Fast clustering using adaptive 
    density peak detection."" Statistical methods in medical research"". url:
    http://smm.sagepub.com/content/early/2015/10/15/0962280215609948.abstract. ",2016-10-15,Yifan (Ethan) Xu,https://github.com/ethanyxu/ADPclust,TRUE,https://github.com/ethanyxu/adpclust,21808,8,2022-05-28T02:40:05Z,2726
AEenrich,"We extend existing gene enrichment tests to perform adverse
    event enrichment analysis. Unlike the continuous gene expression data,
    adverse event data are counts. Therefore, adverse event data has many zeros
    and ties. We propose two enrichment tests. One is a modified Fisher's exact
    test based on pre-selected significant adverse events, while the other is
    based on a modified Kolmogorov-Smirnov statistic. We add Covariate
    adjustment to improve the analysis.""Adverse event enrichment tests using
    VAERS"" Shuoran Li, Lili Zhao (2020) <arXiv:2007.02266>.",2021-11-01,Michael Kleinsasser,https://github.com/umich-biostatistics/AEenrich,TRUE,https://github.com/umich-biostatistics/aeenrich,10635,2,2021-10-02T18:15:36Z,5317.5
afex,"Convenience functions for analyzing factorial experiments using ANOVA or
         mixed models. aov_ez(), aov_car(), and aov_4() allow specification of
         between, within (i.e., repeated-measures), or mixed (i.e., split-plot) 
         ANOVAs for data in long format (i.e., one observation per row),
         automatically aggregating multiple observations per individual and cell 
         of the design. mixed() fits mixed models using lme4::lmer() and computes 
         p-values for all fixed effects using either Kenward-Roger or Satterthwaite 
         approximation for degrees of freedom (LMM only), parametric bootstrap 
         (LMMs and GLMMs), or likelihood ratio tests (LMMs and GLMMs). 
         afex_plot() provides a high-level interface for interaction or one-way 
         plots using ggplot2, combining raw data and model estimates. afex uses 
         type 3 sums of squares as default (imitating commercial statistical software).",2022-04-29,Henrik Singmann,"https://afex.singmann.science/, https://github.com/singmann/afex",TRUE,https://github.com/singmann/afex,351377,106,2022-05-21T18:56:31Z,3314.877358490566
aftgee,"A collection of methods for both the rank-based estimates and least-square estimates to the Accelerated Failure Time (AFT) model. For rank-based estimation, it provides approaches that include the computationally efficient Gehan's weight and the general's weight such as the logrank weight. Details of the rank-based estimation can be found in Chiou et al. (2014) <doi:10.1007/s11222-013-9388-2> and Chiou et al. (2015) <doi:10.1002/sim.6415>. For the least-square estimation, the estimating equation is solved with generalized estimating equations (GEE). Moreover, in multivariate cases, the dependence working correlation structure can be specified in GEE's setting. Details on the least-squares estimation can be found in Chiou et al. (2014) <doi:10.1007/s10985-014-9292-x>.",2021-07-12,Sy Han Chiou,https://github.com/stc04003/aftgee,TRUE,https://github.com/stc04003/aftgee,22136,2,2022-07-04T16:50:01Z,11068
AGHmatrix,"Computation of A (pedigree), G (genomic-base), and H (A corrected
    by G) relationship matrices for diploid and autopolyploid species. Several methods
    are implemented considering additive and non-additive models.",2021-09-14,Rodrigo Amadeu,https://github.com/rramadeu/AGHmatrix,TRUE,https://github.com/rramadeu/aghmatrix,24548,6,2021-12-02T16:36:10Z,4091.3333333333335
agop,"Tools supporting multi-criteria and group decision making,
    including variable number of criteria, by means of
    aggregation operators, spread measures,
    fuzzy logic connectives, fusion functions,
    and preordered sets. Possible applications include,
    but are not limited to, quality management, scientometrics,
    software engineering, etc.",2020-01-08,Marek Gagolewski,http://www.gagolewski.com/software/,TRUE,https://github.com/gagolews/agop,21343,5,2022-02-09T01:02:20Z,4268.6
agricolaeplotr,"Visualization of Design of Experiments from the 'agricolae' package with 'ggplot2' framework
    The user provides an experiment design from the 'agricolae' package, calls the corresponding function and will receive a 
    visualization with 'ggplot2' based functions that are specific for each design. As there are many different designs, each design is tested on its type.
    The output can be modified with standard 'ggplot2' commands or with other packages with 'ggplot2' function extensions.",2021-07-20,Jens Harbers,https://github.com/jensharbers/agricolaeplotr,TRUE,https://github.com/jensharbers/agricolaeplotr,6788,0,2022-06-21T15:32:13Z,NA
agridat,"Datasets from books, papers, and websites related to agriculture.
    Example graphics and analyses are included. Data come from small-plot trials,
    multi-environment trials, uniformity trials, yield monitors, and more.",2022-06-15,Kevin Wright,https://kwstat.github.io/agridat/,TRUE,https://github.com/kwstat/agridat,62296,82,2022-05-19T14:18:12Z,759.7073170731708
agua,"Create and evaluate models using 'tidymodels' and 'h2o' <https://h2o.ai/>. The
    package enables users to specify 'h2o' as an engine for several
    modeling methods.",2022-06-02,Max Kuhn,"https://agua.tidymodels.org/, https://github.com/tidymodels/agua",TRUE,https://github.com/tidymodels/agua,389,4,2022-06-22T19:50:04Z,97.25
agvgd,"'Align-GVGD' ('A-GVGD') is a method to predict the impact of
    'missense' substitutions based on the properties of amino acid side
    chains and protein multiple sequence alignments
    <doi:10.1136/jmg.2005.033878>. 'A-GVGD' is an extension of the original
    'Grantham' distance to multiple sequence alignments. This package
    provides an alternative R implementation to the web version found on
    <http://agvgd.hci.utah.edu/>.",2022-02-03,Ramiro Magno,"https://maialab.org/agvgd/, https://github.com/maialab/agvgd",TRUE,https://github.com/maialab/agvgd,2193,1,2022-05-26T22:32:23Z,2193
AHMbook,"Provides functions to simulate data sets from hierarchical ecological models, including all the simulations described in the two volume publication 'Applied Hierarchical Modeling in Ecology: Analysis of distribution, abundance and species richness in R and BUGS' by Marc Kéry and Andy Royle: volume 1 (2016, ISBN: 978-0-12-801378-6) and volume 2 (2021, ISBN: 978-0-12-809585-0), <https://www.mbr-pwrc.usgs.gov/pubanalysis/keryroylebook/>. It also has all the utility functions and data sets needed to replicate the analyses shown in the books.",2022-06-14,Mike Meredith,https://sites.google.com/site/appliedhierarchicalmodeling/home,TRUE,https://github.com/mikemeredith/ahmbook,24639,24,2022-05-05T23:11:51Z,1026.625
AIPW,"The 'AIPW' pacakge implements the augmented inverse probability weighting, a doubly robust estimator, for average causal effect estimation with user-defined stacked machine learning algorithms. To cite the 'AIPW' package, please use: ""Yongqi Zhong, Edward H. Kennedy, Lisa M. Bodnar, Ashley I. Naimi (2021, In Press). AIPW: An R Package for Augmented Inverse Probability Weighted Estimation of Average Causal Effects. American Journal of Epidemiology"". Visit: <https://yqzhong7.github.io/AIPW/> for more information.",2021-06-11,Yongqi Zhong,https://github.com/yqzhong7/AIPW,TRUE,https://github.com/yqzhong7/aipw,5861,13,2021-09-15T00:30:44Z,450.84615384615387
aire.zmvm,"Tools for downloading hourly averages, daily maximums and minimums from each of the 
    pollution, wind, and temperature measuring stations or geographic zones in the Mexico City 
    metro area. The package also includes the locations of each of the stations and zones. See 
    <http://aire.cdmx.gob.mx/> for more information.",2019-03-30,Diego Valle-Jones,"https://hoyodesmog.diegovalle.net/aire.zmvm/,
https://github.com/diegovalle/aire.zmvm",TRUE,https://github.com/diegovalle/aire.zmvm,19600,10,2021-08-13T20:52:14Z,1960
AirMonitor,"Utilities for working with hourly air quality monitoring data
    with a focus on small particulates (PM2.5). A compact data model is 
    structured as a list with two dataframes. A 'meta' dataframe contains 
    spatial and measuring device metadata associated with deployments at known 
    locations. A 'data' dataframe contains a 'datetime' column followed by 
    columns of measurements associated with each ""device-deployment"".
    Algorithms to calculate NowCast and the associated Air Quality Index (AQI)
    are defined at the US Environmental Projection Agency AirNow program:
    <https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf>.",2022-03-31,Jonathan Callahan,https://github.com/MazamaScience/AirMonitor,TRUE,https://github.com/mazamascience/airmonitor,1171,3,2022-06-22T19:23:31Z,390.3333333333333
airports,"Geographic, use, and property related data on airports.",2020-06-29,Mine Çetinkaya-Rundel,https://github.com/OpenIntroStat/airports,TRUE,https://github.com/openintrostat/airports,126394,1,2021-12-15T04:29:42Z,126394
airr,"Schema definitions and read, write and validation tools for data 
    formatted in accordance with the AIRR Data Representation schemas defined 
    by the AIRR Community <http://docs.airr-community.org>.",2020-05-27,Jason Vander Heiden,http://docs.airr-community.org,TRUE,https://github.com/airr-community/airr-standards,36939,33,2022-05-27T17:13:01Z,1119.3636363636363
akc,"A tidy framework for automatic knowledge classification and visualization. Currently, the core functionality of the framework is mainly supported by modularity-based clustering (community detection) in keyword co-occurrence network, and focuses on co-word analysis of bibliometric research. However, the designed functions in 'akc' are general, and could be extended to solve other tasks in text mining as well.",2022-03-24,Tian-Yuan Huang,https://github.com/hope-data-science/akc,TRUE,https://github.com/hope-data-science/akc,18850,11,2022-03-24T07:44:06Z,1713.6363636363637
akmedoids,"Advances a novel adaptation of longitudinal k-means clustering 
    technique (Genolini et al. (2015) <doi:10.18637/jss.v065.i04>) 
    for grouping trajectories based on the similarities of their 
    long-term trends and determines the optimal solution based 
    on either the average silhouette width (Rousseeuw P. J. 1987) 
    or the Calinski-Harabatz criterion (Calinski and Harabatz (1974) 
    <doi:10.1080/03610927408827101>). Includes functions to extract 
    descriptive statistics and generate a visualisation of the 
    resulting groups, drawing methods from the 'ggplot2' library (Wickham H. (2016) 
    <doi:10.1007/978-3-319-24277-4>). The package also includes a number of 
    other useful functions for exploring and manipulating longitudinal 
    data prior to the clustering process.",2021-04-13,Monsuru Adepeju,https://cran.r-project.org/package=akmedoids,TRUE,https://github.com/manalytics/akmedoids,19660,1,2021-08-25T17:15:00Z,19660
aldvmm,"The goal of the package 'aldvmm' is to fit adjusted limited 
    dependent variable mixture models of health state utilities. Adjusted 
    limited dependent variable mixture models are finite mixtures of normal 
    distributions with an accumulation of density mass at the limits, and a gap 
    between 100% quality of life and the next smaller utility value. The 
    package 'aldvmm' uses the likelihood and expected value functions proposed 
    by Hernandez Alava and Wailoo (2015) <doi:10.1177/1536867X1501500307> using 
    normal component distributions and a multinomial logit model of 
    probabilities of component membership.",2021-07-19,Mark Pletscher,https://github.com/pletschm/aldvmm/,TRUE,https://github.com/pletschm/aldvmm,5806,1,2021-07-18T12:34:07Z,5806
alfred,"Provides direct access to the ALFRED (<https://alfred.stlouisfed.org>) and FRED (<https://fred.stlouisfed.org>) databases.
    Its functions return tidy data frames for different releases of the specified time series. 
    Note that this product uses the FRED© API but is not endorsed or certified by the Federal Reserve Bank of St. Louis.",2021-07-26,Onno Kleen,https://github.com/onnokleen/alfred/,TRUE,https://github.com/onnokleen/alfred,28936,14,2021-07-30T14:25:43Z,2066.8571428571427
AlgDesign,"Algorithmic experimental designs. Calculates exact and
        approximate theory experimental designs for D,A, and I
        criteria. Very large designs may be created. Experimental
        designs may be blocked or blocked designs created from a
        candidate list, using several criteria.  The blocking can be
        done when whole and within plot factors interact.",2022-05-25,Bob Wheeler,https://github.com/jvbraun/AlgDesign,TRUE,https://github.com/jvbraun/algdesign,840373,8,2022-05-24T05:31:36Z,105046.625
allcontributors,"Acknowledge all contributors to a project via a
    single function call. The function appends to a 'README' or other
    specified file(s) a table with names of all individuals who
    contributed via code or repository issues.  The package also includes
    several additional functions to extract and quantify contributions to
    any repository.",2020-12-02,Mark Padgham,https://github.com/ropenscilabs/allcontributors,TRUE,https://github.com/ropenscilabs/allcontributors,8255,15,2022-03-23T15:02:18Z,550.3333333333334
alluvial,"Creating alluvial diagrams (also known as parallel sets plots) for multivariate
  and time series-like data.",2016-09-09,Michal Bojanowski,https://github.com/mbojan/alluvial,TRUE,https://github.com/mbojan/alluvial,80191,130,2021-12-13T21:36:49Z,616.8538461538461
alookr,"A collection of tools that support data splitting, predictive modeling, and model evaluation. 
    A typical function is to split a dataset into a training dataset and a test dataset. 
    Then compare the data distribution of the two datasets.
    Another feature is to support the development of predictive models and to compare the performance of several predictive models, 
    helping to select the best model. ",2022-06-12,Choonghyun Ryu,NA,TRUE,https://github.com/choonghyunryu/alookr,17132,8,2022-06-21T22:26:17Z,2141.5
alpaca,"Provides a routine to partial out factors with many levels during the
  optimization of the log-likelihood function of the corresponding generalized linear model (glm).
  The package is based on the algorithm described in Stammann (2018) <arXiv:1707.01815> and is
  restricted to glm's that are based on maximum likelihood estimation and non-linear. It also offers
  an efficient algorithm to recover estimates of the fixed effects in a post-estimation routine and 
  includes robust and multi-way clustered standard errors. Further the package provides analytical 
  bias corrections for binary choice models (logit and probit) derived by Fernandez-Val 
  and Weidner (2016) <doi:10.1016/j.jeconom.2015.12.014> and Hinz, Stammann, and Wanner (2020) 
  <arXiv:2004.12655>.",2020-10-30,Amrei Stammann,https://github.com/amrei-stammann/alpaca,TRUE,https://github.com/amrei-stammann/alpaca,61922,36,2021-07-18T16:35:36Z,1720.0555555555557
AlphaSimR,"The successor to the 'AlphaSim' software for breeding program 
  simulation [Faux et al. (2016) <doi:10.3835/plantgenome2016.02.0013>]. 
  Used for stochastic simulations of breeding programs to the level of DNA 
  sequence for every individual. Contained is a wide range of functions for 
  modeling common tasks in a breeding program, such as selection and crossing. 
  These functions allow for constructing simulations of highly complex plant and 
  animal breeding programs via scripting in the R software environment. Such 
  simulations can be used to evaluate overall breeding program performance and 
  conduct research into breeding program design, such as implementation of 
  genomic selection. Included is the 'Markovian Coalescent Simulator' ('MaCS') 
  for fast simulation of biallelic sequences according to a population 
  demographic history [Chen et al. (2009) <doi:10.1101/gr.083634.108>].",2022-07-05,Chris Gaynor,https://github.com/gaynorr/AlphaSimR,TRUE,https://github.com/gaynorr/alphasimr,29307,11,2022-07-06T02:54:39Z,2664.2727272727275
altair,"Interface to 'Altair' <https://altair-viz.github.io>, which itself 
  is a 'Python' interface to 'Vega-Lite' <https://vega.github.io/vega-lite/>.
  This package uses the 'Reticulate' framework 
  <https://rstudio.github.io/reticulate/> to manage the interface between R
  and 'Python'.",2022-02-14,Ian Lyttle,https://github.com/vegawidget/altair,TRUE,https://github.com/vegawidget/altair,18696,81,2022-02-14T14:41:05Z,230.8148148148148
altR2,"Provides alternatives to the normal adjusted R-squared estimator for the estimation of the multiple squared correlation in regression models, 
              as fitted by the lm() function. The alternative estimators are described in Karch (2016) <DOI:10.31234/osf.io/v8dz5>.",2019-09-23,Julian Karch,https://github.com/karchjd/altR2,TRUE,https://github.com/karchjd/altr2,14613,0,2022-02-22T13:44:46Z,NA
ALUES,"Evaluates land suitability for different crops production. 
  The package is based on the Food and Agriculture Organization (FAO) and the 
  International Rice Research Institute (IRRI) methodology for land evaluation. 
  Development of ALUES is inspired by similar tool for land evaluation, Land Use 
  Suitability Evaluation Tool (LUSET). The package uses fuzzy logic approach to evaluate 
  land suitability of a particular area based on inputs such as rainfall, temperature, 
  topography, and soil properties. The membership functions used for fuzzy modeling are 
  the following: Triangular, Trapezoidal and Gaussian. The methods for computing the 
  overall suitability of a particular area are also included, and these are the Minimum, 
  Maximum and Average. Finally, ALUES is a highly optimized library with core algorithms 
  written in C++.",2022-01-12,Al-Ahmadgaid B. Asaad,https://github.com/alstat/ALUES/,TRUE,https://github.com/alstat/alues,1844,10,2022-06-11T03:57:26Z,184.4
amanida,"Combination of results for meta-analysis using significance
    and effect size only. P-values and fold-change are combined to obtain
    a global significance on each metabolite. Produces a volcano plot
    summarising the relevant results from meta-analysis. Vote-counting
    reports for metabolites. And explore plot to detect discrepancies
    between studies at a first glance. Methodology is described in the
    Llambrich et al. (2021) <doi:10.1093/bioinformatics/btab591>.  ",2022-03-30,Maria Llambrich,https://github.com/mariallr/amanida,TRUE,https://github.com/mariallr/amanida,7069,2,2022-03-29T11:53:06Z,3534.5
AMAPVox,"Read, manipulate and write voxel spaces. Voxel spaces are
    read from text-based output files of the 'AMAPVox' software. 'AMAPVox'
    is a LiDAR point cloud voxelisation software that aims at estimating
    leaf area through several theoretical/numerical approaches. See more
    in the article Vincent et al. (2017) <doi:10.23708/1AJNMP> and the
    technical note Vincent et al. (2021) <doi:10.23708/1AJNMP>.",2022-04-20,Philippe Verley,https://amapvox.org,TRUE,https://github.com/umr-amap/amapvox,5361,3,2022-04-21T13:57:06Z,1787
ambient,"Generation of natural looking noise has many application within 
    simulation, procedural generation, and art, to name a few. The 'ambient' 
    package provides an interface to the 'FastNoise' C++ library and allows for
    efficient generation of perlin, simplex, worley, cubic, value, and white 
    noise with optional pertubation in either 2, 3, or 4 (in case of simplex and
    white noise) dimensions.",2020-03-21,Thomas Lin Pedersen,"https://ambient.data-imaginist.com,
https://github.com/thomasp85/ambient",TRUE,https://github.com/thomasp85/ambient,23517,76,2021-12-03T14:10:18Z,309.4342105263158
ambiorix,"A web framework inspired by 'express.js' to build
  any web service from multi-page websites to 'RESTful' 
  application programming interfaces.",2022-04-06,John Coene,"https://github.com/devOpifex/ambiorix, https://ambiorix.dev",TRUE,https://github.com/devopifex/ambiorix,8141,155,2022-06-01T17:37:17Z,52.52258064516129
amerifluxr,"Programmatic interface to the 'AmeriFlux' database
    (<https://ameriflux.lbl.gov/>). Provide query, download,
    and data summary tools.",2022-02-08,Housen Chu,https://github.com/chuhousen/amerifluxr,TRUE,https://github.com/chuhousen/amerifluxr,1850,6,2022-06-02T05:19:09Z,308.3333333333333
amp,"A testing framework for testing the multivariate point null hypothesis. 
    A testing framework described in Elder et al. (2022) <arXiv:2203.01897> to test the multivariate point null hypothesis.  After the user selects a parameter of interest and defines the assumed data generating mechanism, this information should be encoded in functions for the parameter estimator and its corresponding influence curve. Some parameter and data generating mechanism combinations have codings in this package, and are explained in detail in the article.",2022-04-06,Adam Elder,NA,TRUE,https://github.com/adam-s-elder/amp,1071,0,2022-04-05T19:43:54Z,NA
AmpGram,"Predicts antimicrobial peptides using random forests trained on the
    n-gram encoded peptides. The implemented algorithm can be accessed from
    both the command line and shiny-based GUI. The AmpGram model is too large 
    for CRAN and it has to be downloaded separately from the repository:
    <https://github.com/michbur/AmpGramModel>.",2020-05-31,Michal Burdukiewicz,https://github.com/michbur/AmpGram,TRUE,https://github.com/michbur/ampgram,9696,2,2022-02-28T21:10:46Z,4848
AMR,"Functions to simplify and standardise antimicrobial resistance (AMR)
    data analysis and to work with microbial and antimicrobial properties by
    using evidence-based methods and reliable reference data such as LPSN
    <doi:10.1099/ijsem.0.004332>.",2022-03-24,Matthijs S. Berends,"https://msberends.github.io/AMR/, https://github.com/msberends/AMR",TRUE,https://github.com/msberends/amr,48448,41,2022-05-16T10:52:50Z,1181.658536585366
amt,"Manage and analyze animal movement data. The functionality of 'amt' includes methods to calculate home ranges, track statistics (e.g. step lengths, speed, or turning angles), prepare data for fitting habitat selection analyses, and simulation of space-use from fitted step-selection functions.",2022-02-23,Johannes Signer,https://github.com/jmsigner/amt,TRUE,https://github.com/jmsigner/amt,32887,25,2022-06-21T06:22:21Z,1315.48
analogsea,"Provides a set of functions for interacting with the 'Digital
    Ocean' API <https://www.digitalocean.com/>, including
    creating images, destroying them, rebooting, getting details on regions, and
    available images.",2022-05-08,Bryce Mecum [ctb,"https://github.com/pachadotdev/analogsea (devel)
https://pacha.dev/analogsea/ (docs)",TRUE,https://github.com/pachadotdev/analogsea,67368,138,2022-06-28T17:28:45Z,488.17391304347825
Andromeda,"Storing very large data objects on a local drive, while still making it possible to manipulate the data in an efficient manner.",2022-05-24,Adam Black,https://github.com/OHDSI/Andromeda,TRUE,https://github.com/ohdsi/andromeda,40682,7,2022-05-24T20:03:27Z,5811.714285714285
animation,"Provides functions for animations in statistics, covering topics
    in probability theory, mathematical statistics, multivariate statistics,
    non-parametric statistics, sampling survey, linear models, time series,
    computational statistics, data mining and machine learning. These functions
    may be helpful in teaching statistics and data analysis. Also provided in this
    package are a series of functions to save animations to various formats, e.g.
    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted
    into 'Sweave' / 'knitr' easily.",2021-10-07,Yihui Xie,https://yihui.org/animation/,TRUE,https://github.com/yihui/animation,332710,190,2021-10-07T12:51:43Z,1751.1052631578948
animint2,"Functions are provided for defining animated,
 interactive data visualizations in R code, and rendering
 on a web page. The 2018 Journal of Computational and 
 Graphical Statistics paper,
 <doi:10.1080/10618600.2018.1513367>
 describes the concepts implemented.",2022-01-26,Toby Hocking,https://github.com/tdhock/animint2,TRUE,https://github.com/tdhock/animint2,14932,44,2022-06-24T20:29:17Z,339.3636363636364
anndata,"A 'reticulate' wrapper for the Python package 'anndata'.
    Provides a scalable way of keeping track of data and learned
    annotations.  Used to read from and write to the h5ad file format.",2021-09-10,Philipp Angerer [ccp (<https://orcid.org/0000-0002-0369-2888>,"https://anndata.dynverse.org, https://github.com/dynverse/anndata",TRUE,https://github.com/dynverse/anndata,23142,20,2022-06-02T21:10:30Z,1157.1
annotater,"Provides non-invasive annotation of package load calls 
    such as \code{library()}, \code{p_load()}, and \code{require()} so that we can have an idea of what 
    the packages we are loading are meant for.",2022-06-15,Luis D. Verde Arregoitia,"https://github.com/luisDVA/annotater, https://annotater.liomys.mx",TRUE,https://github.com/luisdva/annotater,362,76,2022-07-02T02:10:42Z,4.7631578947368425
anscombiser,"Anscombe's quartet are a set of four two-variable datasets that 
    have several common summary statistics but which have very different joint 
    distributions.  This becomes apparent when the data are plotted, which 
    illustrates the importance of using graphical displays in Statistics.  This
    package enables the creation of datasets that have identical marginal sample
    means and sample variances, sample correlation, least squares regression 
    coefficients and coefficient of determination.  The user supplies an initial 
    dataset, which is shifted, scaled and rotated in order to achieve target 
    summary statistics.  The general shape of the initial dataset is retained. 
    The target statistics can be supplied directly or calculated based on a 
    user-supplied dataset.  The 'datasauRus' package 
    <https://cran.r-project.org/package=datasauRus> provides further examples 
    of datasets that have markedly different scatter plots but share many 
    sample summary statistics.",2020-10-11,Paul J. Northrop,"https://paulnorthrop.github.io/anscombiser/,
https://github.com/paulnorthrop/anscombiser",TRUE,https://github.com/paulnorthrop/anscombiser,8575,10,2022-06-07T20:35:18Z,857.5
antaresEditObject,"Edit an 'Antares' simulation before running it : create new areas, links, thermal
    clusters or binding constraints or edit existing ones. Update 'Antares' general & optimization settings.
    'Antares' is an open source power system generator, more information available here : <https://antares-simulator.org/>.",2021-11-08,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresEditObject,TRUE,https://github.com/rte-antares-rpackage/antareseditobject,18459,5,2022-06-28T15:19:28Z,3691.8
antaresProcessing,"
    Process results generated by 'Antares', a powerful open source software developed by
    RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems (more information about
    'Antares' here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>).
    This package provides functions to create new columns like net load, load factors, upward and
    downward margins or to compute aggregated statistics like economic surpluses
    of consumers, producers and sectors.",2021-11-07,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresProcessing,TRUE,https://github.com/rte-antares-rpackage/antaresprocessing,22729,8,2021-11-05T10:12:10Z,2841.125
antaresRead,"Import, manipulate and explore results generated by 'Antares', a 
    powerful open source software developed by RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems
    (more information about 'Antares' here : <https://antares-simulator.org/>).",2022-03-01,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresRead,TRUE,https://github.com/rte-antares-rpackage/antaresread,26586,10,2022-06-01T09:48:46Z,2658.6
antaresViz,"Visualize results generated by Antares, a powerful open source software
    developed by RTE to simulate and study electric power systems
    (more information about 'Antares' here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>).
    This package provides functions that create interactive charts to help
    'Antares' users visually explore the results of their simulations.",2021-11-24,Veronique Bachelier,https://github.com/rte-antares-rpackage/antaresViz,TRUE,https://github.com/rte-antares-rpackage/antaresviz,22655,18,2021-11-24T08:12:39Z,1258.611111111111
anthro,"Provides WHO Child Growth Standards (z-scores) with
             confidence intervals and standard errors around the
             prevalence estimates, taking into account complex sample designs.
             More information on the methods is
             available online:
             <https://www.who.int/tools/child-growth-standards>.",2021-11-18,Dirk Schumacher,https://github.com/worldhealthorganization/anthro,TRUE,https://github.com/worldhealthorganization/anthro,24168,20,2021-11-18T18:01:29Z,1208.4
anticlust,"The method of anticlustering partitions a pool of elements
    into groups (i.e., anticlusters) with the goal of maximizing
    between-group similarity or within-group heterogeneity. 
    The anticlustering approach thereby reverses the logic
    of cluster analysis that strives for high within-group homogeneity and
    low similarity of the different groups. Computationally,
    anticlustering is accomplished by maximizing instead of minimizing a
    clustering objective function, such as the intra-cluster variance
    (used in k-means clustering) or the sum of pairwise distances within
    clusters.  The function anticlustering() implements exact and
    heuristic anticlustering algorithms as described in Papenberg and Klau
    (2021; <doi:10.1037/met0000301>). The exact algorithms require that
    the GNU linear programming kit
    (<https://www.gnu.org/software/glpk/glpk.html>) is available and the R
    package 'Rglpk' (<https://cran.R-project.org/package=Rglpk>) is
    installed. A bicriterion anticlustering method proposed by Brusco et al. 
    (2020; <doi:10.1111/bmsp.12186>) is available through the function
    bicriterion_anticlustering(). Some other functions are available to
    solve classical clustering problems. The function
    balanced_clustering() applies a cluster analysis under size
    constraints, i.e., creates equal-sized clusters. The function
    matching() can be used for (unrestricted, bipartite, or K-partite)
    matching. The function wce() can be used optimally solve the
    (weighted) cluster editing problem, also known as correlation
    clustering, clique partitioning problem or transitivity clustering.",2021-12-07,Martin Papenberg,https://github.com/m-Py/anticlust,TRUE,https://github.com/m-py/anticlust,16099,13,2022-01-28T12:29:39Z,1238.3846153846155
antitrust,"A collection of tools for antitrust practitioners, including the ability to calibrate different consumer demand systems and simulate the effects of mergers under different competitive regimes.",2021-05-06,Charles Taragin and Michael Sandfort,https://github.com/luciu5/antitrust,TRUE,https://github.com/luciu5/antitrust,22011,3,2021-12-07T22:17:35Z,7337
antiword,"Wraps the 'AntiWord' utility to extract text from Microsoft
    Word documents. The utility only supports the old 'doc' format, not the 
    new xml based 'docx' format. Use the 'xml2' package to read the latter.",2022-03-21,Jeroen Ooms,"https://docs.ropensci.org/antiword/ (website),
https://github.com/ropensci/antiword (devel)
http://www.winfield.demon.nl (upstream)",TRUE,https://github.com/ropensci/antiword,211889,47,2022-04-03T22:25:14Z,4508.276595744681
AntMAN,"Fits finite Bayesian mixture models with a random number of components. The MCMC algorithm implemented is based on point processes as proposed by Argiento and De Iorio (2019) <arXiv:1904.09733> and offers a more computationally efficient alternative to reversible jump. Different mixture kernels can be specified: univariate Gaussian, multivariate Gaussian, univariate Poisson, and multivariate Bernoulli (latent class analysis). For the parameters characterising the mixture kernel, we specify conjugate priors, with possibly user specified hyper-parameters. We allow for different choices for the prior on the number of components: shifted Poisson, negative binomial, and point masses (i.e. mixtures with fixed number of components).",2021-07-23,Bruno Bodin,https://github.com/bbodin/AntMAN,TRUE,https://github.com/bbodin/antman,8240,2,2021-07-23T08:12:45Z,4120
ANTs,"How animals interact and develop social relationships in face of sociodemographic and ecological pressures is of great interest. New methodologies, in particular Social Network Analysis (SNA), allow us to elucidate these types of questions. However, the different methodologies developed to that end and the speed at which they emerge make their use difficult. Moreover, the lack of communication between the different software developed to provide an answer to the same/different research questions is a source of confusion. The R package Animal Network Toolkit 'ANTs' was developed with the aim of implementing in one package the different social network analysis techniques currently used in the study of animal social networks. Hence, ANT is a toolkit for animal research allowing among other things to: 1) measure global, dyadic and nodal networks metrics; 2) perform data randomization: pre- and post-network (node and link permutations); 3) perform statistical permutation tests as correlation test (<doi:10.2307/2332226>), t-test (<doi:10.1037/h0041412>), General Linear Model (<doi:10.2307/2346786>), General Linear Mixed Model (<doi:10.2307/2346786>), deletion simulation (<doi:10.1098/rsbl.2003.0057>), 'Matrix TauKr correlations' (<doi:10.1016/S0022-5193(05)80036-0>). The package is partially coded in C++ using the R package 'Rcpp' for an optimal coding speed. The package gives researchers a workflow from the raw data to the achievement of statistical analyses, allowing for a multilevel approach (<doi:10.1007/978-3-319-47829-6_1882-1>): from the individual's position and role within the network, to the identification of interaction patterns, and the study of the overall network properties. Furthermore, ANT also provides a guideline on the SNA techniques used: 1) from the appropriate randomization technique according to the data collected; 2) to the choice, the meaning, the limitations and advantages of the network metrics to apply, 3) and the type of statistical tests to run. The ANT project is multi-collaborative, aiming to provide access to advanced social network analysis techniques and to create new ones that meet researchers' needs in future versions.    The ANT project is multi-collaborative, aiming to provide access to advanced social network analysis techniques and to create new ones that meet researchers' needs in future versions.",2022-07-02,Sosa Sebastian,www.s-sosa.com/softwares or https://github.com/SebastianSosa/ANTs,TRUE,https://github.com/sebastiansosa/ants,2668,6,2022-01-19T13:06:30Z,444.6666666666667
anyflights,"Supplies a set of functions to query air travel data for user-
    specified years and airports. Datasets include on-time flights, airlines,
    airports, planes, and weather.",2021-11-24,Simon P. Couch,https://github.com/simonpcouch/anyflights,TRUE,https://github.com/simonpcouch/anyflights,13483,37,2021-11-24T15:20:46Z,364.4054054054054
anytime,"Convert input in any one of character, integer, numeric, factor,
 or ordered type into 'POSIXct' (or 'Date') objects, using one of a number of
 predefined formats, and relying on Boost facilities for date and time parsing.",2020-08-27,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/anytime.html,TRUE,https://github.com/eddelbuettel/anytime,2979451,148,2022-01-26T02:56:40Z,20131.425675675677
ao,"Alternating optimization of (high-dimensional) functions is an 
    iterative procedure for minimizing (or maximizing) jointly over all 
    parameters by alternately optimizing parameter subsets. For a reference, 
    see Bezdek and Hathaway (2002) ""Some Notes on Alternating Optimization"" 
    <doi:10.1007/3-540-45631-7_39>. ",2022-01-04,Lennart Oelschläger,https://loelschlaeger.github.io/ao/,TRUE,https://github.com/loelschlaeger/ao,9700,1,2022-02-10T18:44:28Z,9700
APAtree,"Maps of the 'area potentially available' (APA) of trees is calculated from
  mapped forest stands using the approach from Gspaltl et al. (2012) <doi:10.1093/forestry/cps052>.
  This is done by computing a rasterized version of
  'weighted voronoi diagrams' using a an approximation of the trees competitive
  ability (e.g., crown radius, leaf area) as weight. The main output are 'Raster*'-
  objects from the 'raster' package that are stored together with the raw data in
  apa_list's, the main class of the 'APAtree' package. Aggregation functions are
  provided to calculate stand characteristics based on APA-maps such as relative
  proportions according to APA-size and the neighborhood diversity index NDiv
  (Glatthorn (2021) <doi:10.1016/j.ecolind.2021.108073>).",2021-08-17,Jonas Glatthorn,https://github.com/JonasGlatthorn/APAtree/,TRUE,https://github.com/jonasglatthorn/apatree,4211,0,2021-08-20T13:01:47Z,NA
apcf,"The adapted pair correlation function transfers the concept of the
  pair correlation function from point patterns to patterns of objects of 
  finite size and irregular shape (e.g. lakes within a country). This is a 
  reimplementation of the method suggested by Nuske et al. (2009) 
  <doi:10.1016/j.foreco.2009.09.050> using the library 'GEOS'. ",2022-03-30,Robert Nuske,"https://rnuske.github.io/apcf/, https://github.com/rnuske/apcf",TRUE,https://github.com/rnuske/apcf,18559,5,2022-03-30T16:11:34Z,3711.8
APCtools,"Age-Period-Cohort (APC) analyses are used to differentiate relevant drivers for long-term developments.
    The 'APCtools' package offers visualization techniques and general routines to simplify the workflow of an APC analysis.
    Sophisticated functions are available both for descriptive and regression model-based analyses.
    For the former, we use density (or ridgeline) matrices and (hexagonally binned) heatmaps as innovative visualization
    techniques building on the concept of Lexis diagrams.
    Model-based analyses build on the separation of the temporal dimensions based on generalized additive models,
    where a tensor product interaction surface (usually between age and period) is utilized
    to represent the third dimension (usually cohort) on its diagonal.
    Such tensor product surfaces can also be estimated while accounting for
    further covariates in the regression model.
    See Weigert et al. (2021) <doi:10.1177/1354816620987198> for methodological details.",2022-01-11,Alexander Bauer,https://bauer-alex.github.io/APCtools/,TRUE,https://github.com/bauer-alex/apctools,2018,5,2022-05-04T16:49:38Z,403.6
apexcharter,"Provides an 'htmlwidgets' interface to 'apexcharts.js'. 
  'Apexcharts' is a modern JavaScript charting library to build interactive charts and visualizations with simple API.
  'Apexcharts' examples and documentation are available here: <https://apexcharts.com/>.",2022-02-27,Victor Perrier,"https://github.com/dreamRs/apexcharter,
https://dreamrs.github.io/apexcharter/",TRUE,https://github.com/dreamrs/apexcharter,41889,108,2022-04-02T16:34:43Z,387.8611111111111
aphylo,"Implements a parsimonious evolutionary model to analyze and
  predict gene-functional annotations in phylogenetic trees as described in Vega
  Yon et al. (2021) <doi:10.1371/journal.pcbi.1007948>. With a focus on
  computational efficiency, 'aphylo' makes it possible to estimate pooled
  phylogenetic models, including thousands (hundreds) of annotations (trees) in
  the same run. The package also provides the tools for visualization of
  annotated phylogenies, calculation of posterior probabilities (prediction,)
  and goodness-of-fit assessment featured in Vega Yon et al. (2021).",2022-01-21,George Vega Yon,https://github.com/USCbiostats/aphylo,TRUE,https://github.com/uscbiostats/aphylo,1968,6,2022-03-08T17:35:57Z,328
aplot,"For many times, we are not just aligning plots as what 'cowplot' and 'patchwork' did. Users would like to align associated information that requires axes to be exactly matched in subplots, e.g. hierarchical clustering with a heatmap. This package provides utilities to aligns associated subplots to a main plot at different sides (left, right, top and bottom) with axes exactly matched. ",2022-06-03,Guangchuang Yu,https://github.com/YuLab-SMU/aplot,TRUE,https://github.com/yulab-smu/aplot,260946,57,2022-06-03T07:35:45Z,4578
appler,"Using 'Apple App Store' <https://www.apple.com/app-store/> web scraping and 'iTunes' API 
    <https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/>
    to extract content information, app ratings and reviews.",2022-03-28,Ashley Baldry,"https://github.com/ashbaldry/appler,
https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/",TRUE,https://github.com/ashbaldry/appler,7876,9,2022-03-26T17:18:15Z,875.1111111111111
applicable,"A modeling package compiling applicability domain methods in R.
    It combines different methods to measure the amount of extrapolation new
    samples can have from the training set. See Netzeva et al (2005) 
    <doi:10.1177/026119290503300209> for an overview of applicability domains. ",2020-07-12,Marly Gotti,"https://github.com/tidymodels/applicable,
https://applicable.tidymodels.org",TRUE,https://github.com/tidymodels/applicable,12830,37,2022-03-04T23:15:23Z,346.7567567567568
approxOT,"R and C++ functions to perform exact and 
  approximate optimal transport. All C++ methods are linkable 
  to other R packages via their header files. ",2022-03-17,Eric Dunipace,NA,TRUE,https://github.com/ericdunipace/approxot,2384,1,2022-03-18T21:11:49Z,2384
apsimx,"The functions in this package inspect, read, edit and run files for 'APSIM' ""Next Generation"" ('JSON')
             and 'APSIM' ""Classic"" ('XML'). The files with an 'apsim' extension correspond to
	     'APSIM' Classic (7.x) - Windows only - and the ones with an 'apsimx' extension correspond to 'APSIM' ""Next Generation"".
	     For more information about 'APSIM' see (<https://www.apsim.info/>) and for 'APSIM'
	     next generation (<https://apsimnextgeneration.netlify.app/>). ",2022-01-04,Fernando Miguez,NA,TRUE,https://github.com/femiguez/apsimx,18099,26,2022-07-07T15:44:46Z,696.1153846153846
AQEval,"Developed for use by those tasked with the routine detection,
        characterisation and quantification of discrete changes in air
        quality time-series, such as identifying the impacts of air quality
        policy interventions. The main functions use signal isolation then
        break-point/segment (BP/S) methods based on 'strucchange' and 
        'segmented' methods detect and quantify change events (Ropkins & 
        Tate, 2021, <doi:10.1016/j.scitotenv.2020.142374>).",2022-04-14,Karl Ropkins,"https://github.com/karlropkins/AQEval,
https://karlropkins.github.io/AQEval/",TRUE,https://github.com/karlropkins/aqeval,944,2,2022-04-26T16:41:52Z,472
aqp,"The Algorithms for Quantitative Pedology (AQP) project was started in 2009 to organize a loosely-related set of concepts and source code on the topic of soil profile visualization, aggregation, and classification into this package (aqp). Over the past 8 years, the project has grown into a suite of related R packages that enhance and simplify the quantitative analysis of soil profile data. Central to the AQP project is a new vocabulary of specialized functions and data structures that can accommodate the inherent complexity of soil profile information; freeing the scientist to focus on ideas rather than boilerplate data processing tasks <doi:10.1016/j.cageo.2012.10.020>. These functions and data structures have been extensively tested and documented, applied to projects involving hundreds of thousands of soil profiles, and deeply integrated into widely used tools such as SoilWeb <https://casoilresource.lawr.ucdavis.edu/soilweb-apps/>. Components of the AQP project (aqp, soilDB, sharpshootR, soilReports packages) serve an important role in routine data analysis within the USDA-NRCS Soil Science Division. The AQP suite of R packages offer a convenient platform for bridging the gap between pedometric theory and practice.",2022-04-11,Dylan Beaudette,https://github.com/ncss-tech/aqp,TRUE,https://github.com/ncss-tech/aqp,102139,36,2022-06-25T23:47:58Z,2837.1944444444443
aquodom,"The Aquo Standard is the Dutch Standard for the exchange of 
    data in water management. With *aquodom* (short for aquo domaintables) 
    it is easy to exploit the API (<https://www.aquo.nl/index.php/Hoofdpagina>) to download domaintables 
    of the Aquo Standard and use them in R.",2022-02-12,Johan van Tent,https://redtent.github.io/aquodom/,TRUE,https://github.com/redtent/aquodom,6353,0,2022-03-08T11:56:16Z,NA
arabic2kansuji,"Simple functions to convert given Arabic numerals to Kansuji  
    numerical figures that represent numbers written in Chinese characters.",2022-06-21,Mao Kobayashi,https://github.com/indenkun/arabic2kansuji,TRUE,https://github.com/indenkun/arabic2kansuji,10267,2,2022-06-21T06:43:16Z,5133.5
ArchaeoPhases,"Provides a list of functions for the statistical analysis of archaeological dates and groups of dates. It is based on the post-processing of the Markov Chains whose stationary distribution is the posterior distribution of a series of dates. Such output can be simulated by different applications as for instance 'ChronoModel' (see <https://chronomodel.com/>), 'Oxcal' (see <https://c14.arch.ox.ac.uk/oxcal.html>) or 'BCal' (see <https://bcal.shef.ac.uk/>). The only requirement is to have a csv file containing a sample from the posterior distribution.  Note that this package interacts with data available through the 'ArchaeoPhases.dataset' package which is available in a separate repository.  The size of the 'ArchaeoPhases.dataset' package is approximately 4 MB.",2022-06-21,Anne Philippe,NA,TRUE,https://github.com/archaeostat/archaeophases,23093,6,2022-06-21T00:35:26Z,3848.8333333333335
archeofrag,"Methods to analyse fragmented objects in archaeology using refitting relationships between fragments scattered in archaeological spatial units (e.g. stratigraphic layers). Graphs and graph theory are used to model archaeological observations. The package is mainly based on the 'igraph' package for graph analysis. Functions can: 1) create, manipulate, and simulate fragmentation graphs, 2) measure the cohesion and admixture of archaeological spatial units, and 3) characterise the topology of a specific set of refitting relationships. An empirical dataset is also provided as an example.",2022-03-09,Sebastien Plutniak,https://github.com/sebastien-plutniak/archeofrag,TRUE,https://github.com/sebastien-plutniak/archeofrag,8357,10,2022-04-26T08:51:14Z,835.7
aRchi,"Provides a set of tools to make quantitative structural model of trees (i.e the so-called 'QSM') from LiDAR point cloud, to manipulate and visualize the QSMs as well as to compute metrics from them. It can be used in various context of forest ecology (i.e biomass estimation) and tree architecture (i.e architectural metrics), see Martin-Ducup et al. (2020) <doi:10.1111/1365-2435.13678>. The package is based on a new S4 class called 'aRchi'.",2022-04-12,Olivier Martin and Bastien Lecigne,https://github.com/umr-amap/aRchi,TRUE,https://github.com/umr-amap/archi,6494,7,2022-07-04T13:51:01Z,927.7142857142857
archive,"Bindings to 'libarchive' <http://www.libarchive.org> the
    Multi-format archive and compression library. Offers R connections and
    direct extraction for many archive formats including 'tar', 'ZIP',
    '7-zip', 'RAR', 'CAB' and compression formats including 'gzip',
    'bzip2', 'compress', 'lzma' and 'xz'.",2022-05-06,Jim Hester,"https://archive.r-lib.org/, https://github.com/r-lib/archive",TRUE,https://github.com/r-lib/archive,29051,128,2022-05-06T11:49:02Z,226.9609375
archiveRetriever,"Scraping content from archived web pages stored in
    the 'Internet Archive' (<https://archive.org>) using a systematic
    workflow.  Get an overview of the mementos available from the
    respective homepage, retrieve the Urls and links of the page and
    finally scrape the content. The final output is stored in tibbles,
    which can be then easily used for further analysis.",2022-06-21,Konstantin Gavras,https://github.com/liserman/archiveRetriever/,TRUE,https://github.com/liserman/archiveretriever,7789,8,2022-06-21T14:54:37Z,973.625
ARCokrig,"For emulating multifidelity computer models. The major methods include univariate autoregressive cokriging and multivariate autoregressive cokriging. The autoregressive cokriging methods are implemented for both hierarchically nested design and non-nested design. For hierarchically nested design, the model parameters are estimated via standard optimization algorithms; For non-nested design, the model parameters are estimated via Monte Carlo expectation-maximization (MCEM) algorithms. In both cases, the priors are chosen such that the posterior distributions are proper. Notice that the uniform priors on range parameters in the correlation function lead to improper posteriors. This should be avoided when Bayesian analysis is adopted. The development of objective priors for autoregressive cokriging models can be found in Pulong Ma (2020) <DOI:10.1137/19M1289893>. The development of the multivariate autoregressive cokriging models with possibly non-nested design can be found in Pulong Ma, Georgios Karagiannis, Bledar A Konomi, Taylor G Asher, Gabriel R Toro, and Andrew T Cox (2019) <arXiv:1909.01836>.",2021-12-02,Pulong Ma,https://CRAN.R-project.org/package=ARCokrig,TRUE,https://github.com/pulongma/arcokrig,9558,0,2021-09-23T13:08:40Z,NA
ARDL,"Creates complex autoregressive distributed lag (ARDL) models and 
    constructs the underlying unrestricted and restricted error correction 
    model (ECM) automatically, just by providing the order. It also performs
    the bounds-test for cointegration as described in Pesaran et al. (2001) 
    <doi:10.1002/jae.616> and provides the multipliers and the cointegrating
    equation. The validity and the accuracy of this package have been verified 
    by successfully replicating the results of Pesaran et al. (2001) in 
    Natsiopoulos and Tzeremes (2022) <doi:10.1002/jae.2919>.",2022-06-29,Kleanthis Natsiopoulos,https://github.com/Natsiopoulos/ARDL,TRUE,https://github.com/natsiopoulos/ardl,23821,10,2022-06-28T17:06:00Z,2382.1
areal,"A pipeable, transparent implementation of areal weighted interpolation
    with support for interpolating multiple variables in a single function call.
    These tools provide a full-featured workflow for validation and estimation
    that fits into both modern data management (e.g. tidyverse) and spatial 
    data (e.g. sf) frameworks.",2022-05-31,Christopher Prener,https://chris-prener.github.io/areal/,TRUE,https://github.com/chris-prener/areal,23884,77,2022-05-30T23:28:06Z,310.1818181818182
argoFloats,"Supports the analysis of oceanographic data recorded by Argo autonomous drifting profiling floats. Functions are provided to (a) download and cache data files, (b) subset data in various ways, (c) handle quality-control flags and (d) plot the results according to oceanographic conventions. A shiny app is provided for easy exploration of datasets. The package is designed to work well with the 'oce' package, providing a wide range of processing capabilities that are particular to oceanographic analysis. See Kelley, Harbin, and Richards (2021) <doi:10.3389/fmars.2021.635922> for more on the scientific context and applications.",2022-02-17,Dan Kelley,https://github.com/ArgoCanada/argoFloats,TRUE,https://github.com/argocanada/argofloats,4769,12,2022-07-04T15:47:25Z,397.4166666666667
argon2,"Utilities for secure password hashing via the argon2 algorithm.
    It is a relatively new hashing algorithm and is believed to be very secure.
    The 'argon2' implementation included in the package is the reference
    implementation.  The package also includes some utilities that should be
    useful for digest authentication, including a wrapper of 'blake2b'.  For
    similar R packages, see sodium and 'bcrypt'.  See
    <https://en.wikipedia.org/wiki/Argon2> or
    <https://eprint.iacr.org/2015/430.pdf> for more information.",2021-10-30,Drew Schmidt,https://github.com/wrathematics/argon2,TRUE,https://github.com/wrathematics/argon2,64264,8,2021-10-30T18:50:09Z,8033
argonDash,"Create awesome 'Bootstrap 4' dashboards powered by 'Argon'.
   See more here <https://rinterface.github.io/argonDash/>.",2019-11-27,David Granjon,https://github.com/RinteRface/argonDash,TRUE,https://github.com/rinterface/argondash,80267,122,2021-11-18T17:25:09Z,657.9262295081967
argonR,"R wrapper around the argon HTML library.
    More at <https://demos.creative-tim.com/argon-design-system/>.",2019-11-27,David Granjon,https://github.com/RinteRface/argonR,TRUE,https://github.com/rinterface/argonr,81628,50,2021-11-18T17:25:35Z,1632.56
argparse,"A command line parser to
    be used with Rscript to write ""#!"" shebang scripts that gracefully
    accept positional and optional arguments and automatically generate usage.",2022-04-20,Trevor L Davis,https://github.com/trevorld/r-argparse,TRUE,https://github.com/trevorld/r-argparse,104814,77,2022-04-20T20:30:07Z,1361.2207792207791
ari,"Create videos from 'R Markdown' documents, or images and audio
    files. These images can come from image files or HTML slides, and the audio
    files can be provided by the user or computer voice narration can be created
    using 'Amazon Polly'. The purpose of this package is to allow users to create
    accessible, translatable, and reproducible lecture videos. See
    <https://aws.amazon.com/polly/> for more information.",2020-02-08,Sean Kross,http://github.com/seankross/ari,TRUE,https://github.com/seankross/ari,26826,133,2022-03-04T12:46:03Z,201.69924812030075
arkdb,"Flat text files provide a robust, compressible, and portable
  way to store tables from databases.  This package provides convenient
  functions for exporting tables from relational database connections
  into compressed text files and streaming those text files back into
  a database without requiring the whole table to fit in working memory.",2022-02-15,Carl Boettiger,https://github.com/ropensci/arkdb,TRUE,https://github.com/ropensci/arkdb,37519,72,2022-02-14T23:00:21Z,521.0972222222222
arkhe,"A collection of classes that represent
    archaeological data. This package provides a set of S4 classes that
    represent different special types of matrix (absolute/relative
    frequency, presence/absence data, co-occurrence matrix, etc.) upon
    which package developers can build subclasses. It also provides a set
    of generic methods (mutators and coercion mechanisms) and functions
    (e.g. summary statistics, predicates). In addition, a few classes of 
    general interest (e.g. that represent stratigraphic relationships) 
    are implemented.",2022-06-15,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>,"https://packages.tesselle.org/arkhe/,
https://github.com/tesselle/arkhe",TRUE,https://github.com/tesselle/arkhe,22074,9,2022-06-15T17:13:03Z,2452.6666666666665
arm,"Functions to accompany A. Gelman and J. Hill, Data Analysis Using Regression and Multilevel/Hierarchical Models, Cambridge University Press, 2007.",2021-10-15,Yu-Sung Su,https://CRAN.R-project.org/package=arm,TRUE,https://github.com/suyusung/arm,1516473,18,2021-10-15T14:41:15Z,84248.5
aroma.cn,"Methods for analyzing DNA copy-number data.  Specifically,
  this package implements the multi-source copy-number normalization (MSCN)
  method for normalizing copy-number data obtained on various platforms and
  technologies.  It also implements the TumorBoost method for normalizing
  paired tumor-normal SNP data.",2015-10-28,Henrik Bengtsson,"http://www.aroma-project.org/,
https://github.com/HenrikBengtsson/aroma.cn",TRUE,https://github.com/henrikbengtsson/aroma.cn,22860,1,2022-03-09T19:48:31Z,22860
aroma.core,"Core methods and classes used by higher-level 'aroma.*' packages
        part of the Aroma Project, e.g. 'aroma.affymetrix' and 'aroma.cn'.",2021-01-05,Henrik Bengtsson,"https://github.com/HenrikBengtsson/aroma.core,
https://www.aroma-project.org/",TRUE,https://github.com/henrikbengtsson/aroma.core,48050,1,2021-10-21T21:09:58Z,48050
arpr,"Provides convenience functions for programming with
    'magrittr' pipes. Conditional pipes, a string prefixer and a function
    to pipe the given object into a specific argument given by character
    name are currently supported. It is named after the dadaist Hans Arp,
    a friend of Rene Magritte.",2021-08-02,Sébastien Rochette,https://github.com/statnmap/arpr,TRUE,https://github.com/statnmap/arpr,25209,5,2021-08-01T12:10:57Z,5041.8
arrangements,"Fast generators and iterators for permutations, combinations,
    integer partitions and compositions. The arrangements are in
    lexicographical order and generated iteratively in a memory efficient manner. 
    It has been demonstrated that 'arrangements' outperforms most existing
    packages of similar kind. Benchmarks could be found at
    <https://randy3k.github.io/arrangements/articles/benchmark.html>.",2020-09-13,Randy Lai,https://github.com/randy3k/arrangements,TRUE,https://github.com/randy3k/arrangements,95049,39,2021-11-09T17:20:59Z,2437.153846153846
arsenal,"An Arsenal of 'R' functions for large-scale statistical summaries,
  which are streamlined to work within the latest reporting tools in 'R' and
  'RStudio' and which use formulas and versatile summary statistics for summary
  tables and models. The primary functions include tableby(), a Table-1-like
  summary of multiple variable types 'by' the levels of one or more categorical
  variables; paired(), a Table-1-like summary of multiple variable types paired across
  two time points; modelsum(), which performs simple model fits on one or more endpoints
  for many variables (univariate or adjusted for covariates);
  freqlist(), a powerful frequency table across many categorical variables;
  comparedf(), a function for comparing data.frames; and
  write2(), a function to output tables to a document.",2021-06-04,Ethan Heinzen,"https://github.com/mayoverse/arsenal,
https://cran.r-project.org/package=arsenal,
https://mayoverse.github.io/arsenal/",TRUE,https://github.com/mayoverse/arsenal,178472,204,2022-04-01T18:45:06Z,874.8627450980392
arthistory,"Data from Gardner and Janson art history textbooks about both the artists featured in these books as well as their works.
    See Helen Gardner (""Art through the ages; an introduction to its history and significance,"" 1926, <https://find.library.duke.edu/catalog/DUKE000104481>.
    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (""Gardner’s Art through the ages,"" 1980, ISBN: 0155037587).
    Fred S. Kleiner (""Gardner’s art through the ages: a global history,"" 2020, ISBN: 9781337630702).
    Horst de la Croix and Richard G. Tansey (""Gardner's art through the ages,"" 1986, ISBN: 0155037633).
    Helen Gardner (""Art through the ages; an introduction to its history and significance,"" 1936, <https://find.library.duke.edu/catalog/DUKE001199463>).
    Helen Gardner (""Art through the ages,"" 1948, <https://find.library.duke.edu/catalog/DUKE001199466>).
    Helen Gardner, revised under the editorship of Sumner M. Crosby (""Art through the ages,"" 1959, <https://find.library.duke.edu/catalog/DUKE001199469>).
    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (""Gardner’s Art through the ages,"" 1975, ISBN: 0155037560).
    Fred S. Kleiner (""Gardner’s Art through the ages: a global history,"" 2013, ISBN: 9780495915423.
    Fred S. Kleiner, Christin J. Mamiya, Richard G. Tansey (""Gardner’s art through the ages,"" 2001, ISBN: 0155083155).
    Fred S. Kleiner (""Gardner’s Art through the ages: a global history,"" 2016, ISBN: 9781285837840).
    Fred S. Kleiner, Christin J. Mamiya (""Gardner’s art through the ages,"" 2005, ISBN: 0534640958).
    Helen Gardner, revised by Horst de la Croix and Richard G. Tansey (""Gardner’s Art through the ages,"" 1970, ISBN: 0155037528).
    Helen Gardner, Richard G. Tansey, Fred S. Kleiner (""Gardner’s Art through the ages,"" 1996, ISBN: 0155011413).
    Helen Gardner, Horst de la Croix, Richard G. Tansey, Diane Kirkpatrick (""Gardner’s Art through the ages,"" 1991, ISBN: 0155037692).
    Helen Gardner, Fred S. Kleiner (""Gardner’s Art through the ages: a global history,"" 2009, ISBN: 9780495093077).
    Davies, Penelope J.E., Walter B. Denny, Frima Fox Hofrichter, Joseph F. Jacobs, Ann S. Roberts, David L. Simon (""Janson’s history of art: the western tradition,"" 2007, ISBN: 0131934554).
    Davies, Penelope J.E., Walter B. Denny, Frima Fox Hofrichter, Joseph F. Jacobs, Ann S. Roberts, David L. Simon (""Janson’s history of art: the western tradition,"" 2011, ISBN: 9780205685172).
    H. W. Janson, Anthony F. Janson (""History of Art,"" 2001, ISBN: 0810934469).
    H. W. Janson, revised and expanded by Anthony F. Janson (""History of art,"" 1986, ISBN: 013389388).
    H. W. Janson, Dora Jane Janson (""History of art: a survey of the major visual arts from the dawn of history to present day,"" 1977, ISBN: 0810910527).
    H. W. Janson, Dora Jane Janson (""History of art: a survey of the major visual arts from the dawn of history to present day,"" 1969, <https://find.library.duke.edu/catalog/DUKE000005734>).
    H. W. Janson, Dora Jane Janson (""History of art: a survey of the major visual arts from the dawn of history to present day,"" 1963, <https://find.library.duke.edu/catalog/DUKE001521852>).
    H. W. Janson, revised and expanded by Anthony F. Janson (""History of art,"" 1991, ISBN: 0810934019).
    H. W. Janson, revised and expanded by Anthony F. Janson (""History of art,"" 1995, ISBN: 0810934213).",2022-05-03,Sara Lemus,"https://github.com/saralemus7/arthistory,
https://saralemus7.github.io/arthistory/",TRUE,https://github.com/saralemus7/arthistory,610,0,2022-06-01T03:33:42Z,NA
ARTool,"The aligned rank transform for nonparametric
    factorial ANOVAs as described by Wobbrock,
    Findlater, Gergle, and Higgins (2011) <doi:10.1145/1978942.1978963>. 
    Also supports aligned rank transform contrasts as described
    by Elkin, Kay, Higgins, and Wobbrock (2021)
    <doi:10.1145/3472749.3474784>.",2021-10-13,Matthew Kay,https://github.com/mjskay/ARTool/,TRUE,https://github.com/mjskay/artool,39897,36,2021-10-13T04:03:25Z,1108.25
aRtsy,Provides algorithms for creating artworks in the 'ggplot2' language that incorporate some form of randomness.,2022-05-13,Koen Derks,"https://koenderks.github.io/aRtsy/,
https://github.com/koenderks/aRtsy,
https://twitter.com/aRtsy_package",TRUE,https://github.com/koenderks/artsy,8341,118,2022-07-10T02:00:37Z,70.6864406779661
arules,"Provides the infrastructure for representing, manipulating and analyzing 
  transaction data and patterns (frequent itemsets and association rules). 
  Also provides C implementations of the association mining algorithms Apriori and Eclat. 
  Hahsler, Gruen and Hornik (2005) <doi:10.18637/jss.v014.i15>.",2022-01-09,Michael Hahsler,https://github.com/mhahsler/arules,TRUE,https://github.com/mhahsler/arules,1959018,158,2022-06-26T23:29:29Z,12398.848101265823
arulesCBA,"Provides the infrastructure for association rule-based classification including the algorithms 
  CBA, CMAR, CPAR, C4.5, FOIL, PART, PRM, RCAR, and RIPPER to build associative classifiers.",2022-05-30,Michael Hahsler,https://github.com/mhahsler/arulesCBA,TRUE,https://github.com/mhahsler/arulescba,55410,1,2022-06-26T23:31:18Z,55410
arulesNBMiner,NBMiner is an implementation of the model-based mining algorithm for mining NB-frequent itemsets and NB-precise rules. Michael Hahsler (2006) <doi:10.1007/s10618-005-0026-2>. ,2021-09-07,Michael Hahsler,https://github.com/mhahsler/arulesNBMiner,TRUE,https://github.com/mhahsler/arulesnbminer,21721,5,2022-06-26T23:40:02Z,4344.2
arulesViz,Extends package 'arules' with various visualization techniques for association rules and itemsets. The package also includes several interactive visualizations for rule exploration. Michael Hahsler (2017) <doi:10.32614/RJ-2017-047>.,2021-11-19,Michael Hahsler,https://github.com/mhahsler/arulesViz,TRUE,https://github.com/mhahsler/arulesviz,550349,46,2022-06-10T18:51:05Z,11964.108695652174
aRxiv,"An interface to the API for 'arXiv',
    a repository of electronic preprints for
    computer science, mathematics, physics, quantitative biology,
    quantitative finance, and statistics.",2021-12-06,Karthik Ram,"https://docs.ropensci.org/aRxiv/,
https://github.com/ropensci/aRxiv",TRUE,https://github.com/ropensci/arxiv,30649,55,2021-12-06T17:10:04Z,557.2545454545455
ascotraceR,"A spatiotemporal model that simulates the spread of Ascochyta
    blight in chickpea fields based on location-specific weather conditions.
    This model is adapted from a model developed by Diggle et al. (2002)
   <doi:10.1094/PHYTO.2002.92.10.1110> for simulating the spread of anthracnose
   in a lupin field.",2021-12-20,Ihsanul Khaliq,https://github.com/IhsanKhaliq/ascotraceR,TRUE,https://github.com/ihsankhaliq/ascotracer,2205,2,2022-05-15T03:16:31Z,1102.5
ashr,"The R package 'ashr' implements an Empirical Bayes
    approach for large-scale hypothesis testing and false discovery
    rate (FDR) estimation based on the methods proposed in
    M. Stephens, 2016, ""False discovery rates: a new deal"",
    <DOI:10.1093/biostatistics/kxw041>. These methods can be applied
    whenever two sets of summary statistics---estimated effects and
    standard errors---are available, just as 'qvalue' can be applied
    to previously computed p-values. Two main interfaces are
    provided: ash(), which is more user-friendly; and ash.workhorse(),
    which has more options and is geared toward advanced users. The
    ash() and ash.workhorse() also provides a flexible modeling
    interface that can accommodate a variety of likelihoods (e.g.,
    normal, Poisson) and mixture priors (e.g., uniform, normal).",2022-02-22,Peter Carbonetto,https://github.com/stephens999/ashr,TRUE,https://github.com/stephens999/ashr,96149,73,2022-05-12T22:47:37Z,1317.109589041096
AsioHeaders,"'Asio' is a cross-platform C++ library for network and low-level
 I/O programming that provides developers with a consistent asynchronous model
 using a modern C++ approach. It is also included in Boost but requires linking
 when used with Boost. Standalone it can be used header-only (provided a recent
 compiler). 'Asio' is written and maintained by Christopher M. Kohlhoff, and
 released under the 'Boost Software License', Version 1.0.",2022-06-14,Dirk Eddelbuettel,"https://github.com/eddelbuettel/asioheaders,
https://dirk.eddelbuettel.com/code/asioheaders.html",TRUE,https://github.com/eddelbuettel/asioheaders,304358,11,2022-06-14T17:43:42Z,27668.909090909092
aslib,"Provides an interface to the algorithm selection benchmark library
    at <http://www.aslib.net> and the 'LLAMA' package
    (<https://cran.r-project.org/package=llama>) for building
    algorithm selection models; see Bischl et al. (2016)
    <doi:10.1016/j.artint.2016.04.003>.",2020-05-24,Bernd Bischl,https://github.com/coseal/aslib-r/,TRUE,https://github.com/coseal/aslib-r,14718,6,2021-10-17T17:34:53Z,2453
aspline,"Perform one-dimensional spline regression with automatic knot selection.
      This package uses a penalized approach to select the most relevant knots.
      B-splines of any degree can be fitted. More details in 'Goepp et al. (2018)',
      ""Spline Regression with Automatic Knot Selection"", <arXiv:1808.01770>.",2022-06-09,Vivien Goepp,https://github.com/goepp/aspline,TRUE,https://github.com/goepp/aspline,1432,2,2022-06-15T15:06:28Z,716
assemblerr,"Construct pharmacometric nonlinear mixed effect models by combining 
    predefined model components and automatically generate model code for NONMEM. 
    Models are created by combining parameter and observation models, algebraic 
    relationships, compartments, and flows. Pharmacokinetic models can be assembled
    from the higher-order components: absorption, distribution, and elimination. 
    The generated code is optimized for performance by recognizing, for example,
    linear differential equations or differential equations with an analytic 
    solution.",2022-01-12,Sebastian Ueckert,https://github.com/UUPharmacometrics/assemblerr,TRUE,https://github.com/uupharmacometrics/assemblerr,4988,8,2022-01-13T19:54:04Z,623.5
AssetAllocation,"Easy and quick testing of customizable asset allocation strategies.
    Users can rely on their own data, or have the package automatically
    download data from Yahoo Finance (<https://finance.yahoo.com/>). Several 
    pre-loaded portfolios with data are available, including some which are 
    discussed in Faber (2015, ISBN:9780988679924). ",2022-04-25,Alexandre Rubesam,https://github.com/rubetron/AssetAllocation,TRUE,https://github.com/rubetron/assetallocation,1259,17,2022-05-06T09:10:34Z,74.05882352941177
assignPOP,"Use Monte-Carlo and K-fold cross-validation coupled with machine-
    learning classification algorithms to perform population assignment, with
    functionalities of evaluating discriminatory power of independent training
    samples, identifying informative loci, reducing data dimensionality for genomic
    data, integrating genetic and non-genetic data, and visualizing results.",2021-10-27,Kuan-Yu (Alex) Chen,https://github.com/alexkychen/assignPOP,TRUE,https://github.com/alexkychen/assignpop,23793,15,2021-10-27T19:09:48Z,1586.2
ast2ast,Enable translation of a tiny subset of R to C++. The user has to define a R function which gets translated. For a full list of possible functions check the documentation. After translation an external pointer to the C++ function is returned to the user. The intention of the package is to generate fast functions which can be used as ode-system or during optimization. ,2022-03-14,Krämer Konrad,https://github.com/Konrad1991/ast2ast,TRUE,https://github.com/konrad1991/ast2ast,1230,9,2022-06-21T05:46:25Z,136.66666666666666
astsa,"Data sets and scripts to accompany Time Series Analysis and Its Applications: With R Examples (4th ed), by R.H. Shumway and D.S. Stoffer. Springer Texts in Statistics, 2017, <DOI:10.1007/978-3-319-52452-8>, and Time Series: A Data Analysis Approach Using R. Chapman-Hall, 2019, <DOI:10.1201/9780429273285>.",2022-05-09,David Stoffer,"https://github.com/nickpoison/astsa/,
https://www.stat.pitt.edu/stoffer/tsa4/,
https://www.stat.pitt.edu/stoffer/tsda/",TRUE,https://github.com/nickpoison/astsa,299047,78,2022-07-07T04:48:51Z,3833.9358974358975
asylum,"Data on Asylum and Resettlement for the UK,
    provided by the Home Office <https://www.gov.uk/government/statistics/immigration-statistics-year-ending-june-2021>.",2021-09-06,Matthew Gwynfryn Thomas,https://github.com/britishredcrosssociety/asylum,TRUE,https://github.com/britishredcrosssociety/asylum,8786,0,2022-03-08T17:37:27Z,NA
async,"Write sequential-looking code that pauses and resumes.
             gen() creates a generator, an iterator that returns a
             value and pauses each time it reaches a yield() call.
             async() creates a promise, which runs until it reaches
             a call to await(), then resumes when information is available.
             These work similarly to generator and async constructs
             from 'Python' or 'JavaScript'. Objects produced are
             compatible with the 'iterators' and 'promises' packages.",2022-05-26,Peter Meilstrup,"https://crowding.github.io/async/,
https://github.com/crowding/async/",TRUE,https://github.com/crowding/async,458,36,2022-05-25T00:26:59Z,12.722222222222221
ATAforecasting,"The Ata method (Yapar et al. (2019) <doi:10.15672/hujms.461032>), an alternative to exponential smoothing (described in Yapar (2016) <doi:10.15672/HJMS.201614320580>, 
	Yapar et al. (2017) <doi:10.15672/HJMS.2017.493>), is a new univariate time series forecasting method which provides innovative solutions to issues faced during the 
	initialization and optimization stages of existing forecasting methods. Forecasting performance of the Ata method is superior to existing methods both in terms of easy 
	implementation and accurate forecasting. It can be applied to non-seasonal or seasonal time series which can be decomposed into four components (remainder, level, trend 
	and seasonal). This methodology performed well on the M3 and M4-competition data. This package was written based on Ali Sabri Taylan’s PhD dissertation.",2022-04-22,Ali Sabri Taylan,"https://github.com/alsabtay/ATAforecasting,
https://atamethod.wordpress.com/",TRUE,https://github.com/alsabtay/ataforecasting,8116,2,2022-04-27T09:17:23Z,4058
ATbounds,"Estimation and inference methods for bounding average treatment effects (on the treated) that are valid under an unconfoundedness assumption. 
    The bounds are designed to be robust in challenging situations, for example, when the conditioning variables take on a large number of different values in the observed sample, or when the overlap condition is violated. 
    This robustness is achieved by only using limited ""pooling"" of information across observations. 
    For more details, see the paper by Lee and Weidner (2021), ""Bounding Treatment Effects by Pooling Limited Information across Observations,"" <arXiv:2111.05243>.",2021-11-24,Sokbae Lee,https://github.com/ATbounds/ATbounds-r/,TRUE,https://github.com/atbounds/atbounds-r,2399,3,2021-11-30T14:39:48Z,799.6666666666666
AtmChile,Download air quality and meteorological information of Chile from  the National Air Quality System (S.I.N.C.A.)<https://sinca.mma.gob.cl/> dependent on the Ministry of the Environment and the Meteorological Directorate of Chile (D.M.C.)<http://www.meteochile.gob.cl/> dependent on the Directorate General of Civil Aeronautics.,2022-04-21,Francisco Catalan Meyer,https://github.com/franciscoxaxo/AtmChile,TRUE,https://github.com/franciscoxaxo/atmchile,7372,1,2022-04-18T18:22:22Z,7372
atom4R,"Provides tools to read/write/publish metadata based on the 'Atom' XML syndication format. This includes
 support of 'Dublin Core' XML implementation, and a client to API(s) implementing the 'AtomPub' 'SWORD' API specification.",2022-06-29,Emmanuel Blondel,https://github.com/eblondel/atom4R,TRUE,https://github.com/eblondel/atom4r,3784,4,2022-06-29T15:12:04Z,946
attachment,"Tools to help manage dependencies during package
    development.  This can retrieve all dependencies that are used in R
    files in the ""R"" directory, in Rmd files in ""vignettes"" directory and
    in 'roxygen2' documentation of functions. There is a function to
    update the Description file of your package and a function to create a
    file with the R commands to install all dependencies of your package.
    All functions to retrieve dependencies of R scripts and Rmd files can
    be used independently of a package development.",2022-05-15,Sébastien Rochette,"https://thinkr-open.github.io/attachment/,
https://github.com/Thinkr-open/attachment",TRUE,https://github.com/thinkr-open/attachment,62164,86,2022-05-15T20:46:57Z,722.8372093023256
auditor,"Provides an easy to use unified interface for creating validation plots for any model. 
  The 'auditor' helps to avoid repetitive work consisting of writing code needed to create residual plots. 
  This visualizations allow to asses and compare the goodness of fit, performance, and similarity of models. ",2021-07-26,Alicja Gosiewska,https://github.com/ModelOriented/auditor,TRUE,https://github.com/modeloriented/auditor,23917,56,2021-08-25T10:38:01Z,427.0892857142857
audubon,"A collection of Japanese text processing tools for filling
    Japanese iteration marks, Japanese character type conversions,
    segmentation by phrase, and text normalization which is based on rules
    for the 'Sudachi' morphological analyzer and the 'NEologd' (Neologism
    dictionary for 'MeCab').  These features are specific to Japanese and
    are not implemented in 'ICU' (International Components for Unicode).",2022-05-24,Akiru Kato,"https://github.com/paithiov909/audubon,
https://paithiov909.github.io/audubon/",TRUE,https://github.com/paithiov909/audubon,1951,3,2022-07-09T22:52:43Z,650.3333333333334
auk,"Extract and process bird sightings records from
    eBird (<http://ebird.org>), an online tool for recording bird
    observations.  Public access to the full eBird database is via the
    eBird Basic Dataset (EBD; see <http://ebird.org/ebird/data/download>
    for access), a downloadable text file. This package is an interface to
    AWK for extracting data from the EBD based on taxonomic, spatial, or
    temporal filters, to produce a manageable file size that can be
    imported into R.",2021-10-27,Matthew Strimas-Mackey,"https://github.com/CornellLabofOrnithology/auk,
https://cornelllabofornithology.github.io/auk/",TRUE,https://github.com/cornelllabofornithology/auk,30839,101,2022-03-01T15:57:55Z,305.33663366336634
aum,"Standard template library sort is
 used to implement an efficient  
 algorithm <arXiv:2107.01285> for computing Area Under Minimum and
 directional derivatives.",2022-02-08,Toby Dylan Hocking,https://github.com/tdhock/aum,TRUE,https://github.com/tdhock/aum,1529,1,2022-02-21T22:58:06Z,1529
aurin,"'AURIN' <https://aurin.org.au/resources/aurin-apis/> is ""Australia's single
    largest resource for accessing clean, integrated, spatially enabled and research-ready
    data on issues surrounding health and wellbeing, socio-economic metrics, transportation,
    and land-use."". This package provides functions to download and search datasets from
    the AURIN API (it's free to use!).",2022-02-01,Amarin Siripanich,https://github.com/asiripanich/aurin,TRUE,https://github.com/asiripanich/aurin,2429,13,2022-04-29T06:28:53Z,186.84615384615384
AustralianPoliticians,"Provides access to biographical and political data about Australian 
    federal politicians who served between 1901 and 2021. This enhances how 
    reproducible research is that uses this data.",2021-11-30,Rohan Alexander,https://github.com/RohanAlexander/AustralianPoliticians,TRUE,https://github.com/rohanalexander/australianpoliticians,2501,6,2021-12-01T15:57:25Z,416.8333333333333
autoCovariateSelection,"Contains functions to implement automated covariate selection using methods described in the
             high-dimensional propensity score (HDPS) algorithm by Schneeweiss et.al. Covariate adjustment in real-world-observational-data (RWD) is important for
             for estimating adjusted outcomes and this can be done by using methods such as, but not limited to, propensity score 
             matching, propensity score weighting and regression analysis. While these methods strive to statistically adjust for 
             confounding, the major challenge is in selecting the potential covariates that can bias the outcomes comparison estimates 
             in observational RWD (Real-World-Data). This is where the utility of automated covariate selection comes in. 
             The functions in this package help to implement the three major steps of automated covariate selection as described by
             Schneeweiss et. al elsewhere. These three functions, in order of the steps required to execute automated covariate 
             selection are, get_candidate_covariates(), get_recurrence_covariates() and get_prioritised_covariates(). 
             In addition to these functions, a sample real-world-data from publicly available de-identified medical claims data is 
             also available for running examples and also for further exploration. The original article where the algorithm is described 
             by Schneeweiss et.al. (2009) <doi:10.1097/EDE.0b013e3181a663cc> .",2020-12-14,Dennis Robert,https://github.com/technOslerphile/autoCovariateSelection,TRUE,https://github.com/technoslerphile/autocovariateselection,7245,2,2021-11-25T14:38:57Z,3622.5
autoFC,"Forced-choice (FC) response has gained increasing popularity and interest for its resistance to faking when well-designed (Cao & Drasgow, 2019 <doi:10.1037/apl0000414>). To established well-designed FC scales, typically each item within a block should measure different trait and have similar level of social desirability (Zhang et al., 2020 <doi:10.1177/1094428119836486>). Recent study also suggests the importance of high inter-item agreement of social desirability between items within a block (Pavlov et al., 2021 <doi:10.31234/osf.io/hmnrc>). In addition to this, FC developers may also need to maximize factor loading differences (Brown & Maydeu-Olivares, 2011 <doi:10.1177/0013164410375112>) or minimize item location differences (Cao & Drasgow, 2019 <doi:10.1037/apl0000414>) depending on scoring models. Decision of which items should be assigned to the same block, termed item pairing, is thus critical to the quality of an FC test. This pairing process is essentially an optimization process which is currently carried out manually. However, given that we often need to simultaneously meet multiple objectives, manual pairing becomes impractical or even not feasible once the number of latent traits and/or number of items per trait are relatively large. To address these problems, autoFC is developed as a practical tool for facilitating the automatic construction of FC tests, essentially exempting users from the burden of manual item pairing and reducing the computational costs and biases induced by simple ranking methods. Given characteristics of each item (and item responses), FC tests can be automatically constructed based on user-defined pairing criteria and weights as well as customized optimization behavior. Users can also construct parallel forms of the same test following the same pairing rules.",2021-06-07,Mengtong Li,https://github.com/tspsyched/autoFC,TRUE,https://github.com/tspsyched/autofc,5208,1,2022-05-12T20:11:17Z,5208
autoMrP,"A tool that improves the prediction performance of multilevel
    regression with post-stratification (MrP) by combining a number of machine
    learning methods. For information on the method, please refer to Broniecki, 
	Wüest, Leemann (2020) ''Improving Multilevel Regression with 
	Post-Stratification Through Machine Learning (autoMrP)'' forthcoming in 
	'Journal of Politics'. Final pre-print version: 
	<https://lucasleemann.files.wordpress.com/2020/07/automrp-r2pa.pdf>.",2022-04-04,Reto Wüest,https://github.com/retowuest/autoMrP,TRUE,https://github.com/retowuest/automrp,8524,23,2022-04-04T16:10:17Z,370.60869565217394
autoReg,"Make summary tables for descriptive statistics and select explanatory variables 
    automatically in various regression models. Support linear models, generalized linear 
    models and cox-proportional hazard models. Generate publication-ready tables summarizing 
    result of regression analysis and plots. The tables and plots can be exported in ""HTML"", 
    ""pdf('LaTex')"", ""docx('MS Word')"" and ""pptx('MS Powerpoint')"" documents.",2022-04-05,Keon-Woong Moon,"https://github.com/cardiomoon/autoReg,
https://cardiomoon.github.io/autoReg/",TRUE,https://github.com/cardiomoon/autoreg,2733,6,2022-06-14T05:02:30Z,455.5
AutoScore,"A novel interpretable machine learning-based framework to automate the development of a clinical scoring model for predefined outcomes. Our novel framework consists of six modules: variable ranking with machine learning, variable transformation, score derivation, model selection, domain knowledge-based score fine-tuning, and performance evaluation.The details are described in our research paper<doi:10.2196/21798>. Users or clinicians could seamlessly generate parsimonious sparse-score risk models (i.e., risk scores), which can be easily implemented and validated in clinical practice. We hope to see its application in various medical case studies.",2022-04-08,Feng Xie,https://github.com/nliulab/AutoScore,TRUE,https://github.com/nliulab/autoscore,5705,16,2022-05-07T03:51:23Z,356.5625
autostats,"Automatically do statistical exploration. Create formulas using 'tidyselect' syntax, and then determine cross-validated model accuracy and variable contributions using 'glm' and 'xgboost'. Contains additional helper functions to create and modify formulas. Has a flagship function to quickly determine relationships between categorical and continuous variables in the data set.",2022-02-09,Harrison Tietze,"https://harrison4192.github.io/autostats/,
https://github.com/Harrison4192/autostats",TRUE,https://github.com/harrison4192/autostats,4146,5,2022-06-23T05:20:59Z,829.2
av,"Bindings to 'FFmpeg' <http://www.ffmpeg.org/> AV library for working with 
    audio and video in R. Generates high quality video from images or R graphics with 
    custom audio. Also offers high performance tools for reading raw audio, creating
    'spectrograms', and converting between countless audio / video formats. This package 
    interfaces directly to the C API and does not require any command line utilities.",2022-02-08,Jeroen Ooms,"https://docs.ropensci.org/av/ (website),
https://github.com/ropensci/av (devel)",TRUE,https://github.com/ropensci/av,399544,76,2022-06-19T18:49:36Z,5257.1578947368425
available,"Check if a given package name is available to use. It checks the
  name's validity. Checks if it is used on 'GitHub', 'CRAN' and 'Bioconductor'. Checks
  for unintended meanings by querying Urban Dictionary, 'Wiktionary' and Wikipedia.",2021-11-30,Gábor Csárdi,https://github.com/r-lib/available,TRUE,https://github.com/r-lib/available,31938,129,2021-12-03T19:02:42Z,247.58139534883722
avar,"Implements the allan variance and allan variance linear regression estimator for latent time series models. More details about the method can be found, for example, in Guerrier, S., Molinari, R., & Stebler, Y. (2016) <doi:10.1109/LSP.2016.2541867>. ",2020-01-15,Stéphane Guerrier,https://github.com/SMAC-Group/avar,TRUE,https://github.com/smac-group/avar,14619,2,2022-07-04T13:07:42Z,7309.5
AvInertia,"
    Tools to compute the center of gravity and moment of inertia tensor of any 
    flying bird. The tools function by modeling a bird as a composite structure 
    of simple geometric objects. This requires detailed morphological 
    measurements of bird specimens although those obtained for the associated 
    paper have been included in the package for use. Refer to the vignettes and 
    supplementary material for detailed information on the package function.",2022-03-24,Christina Harvey,https://github.com/charvey23/AvInertia,TRUE,https://github.com/charvey23/avinertia,4957,4,2022-03-24T15:06:53Z,1239.25
aws.ecx,"
    Providing the functions for communicating with Amazon Web Services(AWS)
    Elastic Compute Cloud(EC2) and Elastic Container Service(ECS).
    The functions will have the prefix 'ecs_' or 'ec2_' depending on the class 
    of the API. The request will be sent via the REST API and the parameters are
    given by the function argument. The credentials can be set via 'aws_set_credentials'.
    The EC2 documentation can be found at <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/Welcome.html>
    and ECS can be found at <https://docs.aws.amazon.com/AmazonECS/latest/APIReference/Welcome.html>.",2022-01-26,Jiefei Wang,https://github.com/Jiefei-Wang/aws.ecx,TRUE,https://github.com/jiefei-wang/aws.ecx,11596,1,2022-01-26T03:49:47Z,11596
aws.polly,"A client for AWS Polly <http://aws.amazon.com/documentation/polly>, a speech synthesis service.",2020-03-11,Thomas J. Leeper,https://github.com/cloudyr/aws.polly,TRUE,https://github.com/cloudyr/aws.polly,19729,23,2022-06-08T10:28:26Z,857.7826086956521
aws.signature,"Generates version 2 and version 4 request signatures for Amazon Web Services ('AWS') <https://aws.amazon.com/> Application Programming Interfaces ('APIs') and provides a mechanism for retrieving credentials from environment variables, 'AWS' credentials files, and 'EC2' instance metadata. For use on 'EC2' instances, users will need to install the suggested package 'aws.ec2metadata' <https://cran.r-project.org/package=aws.ec2metadata>.",2020-06-01,Thomas J. Leeper,https://github.com/cloudyr/aws.signature,TRUE,https://github.com/cloudyr/aws.signature,2045875,28,2022-02-22T15:19:19Z,73066.96428571429
AzureAppInsights,"Imports Azure Application Insights for web pages into Shiny apps
    via Microsoft's JavaScript snippet. 
    Allows app developers to submit page tracking and submit events.",2021-10-01,Stefan McKinnon Høj-Edwards,NA,TRUE,https://github.com/stefanedwards/azureappinsights,3953,0,2021-09-10T09:14:11Z,NA
AzureAuth,"Provides Azure Active Directory (AAD) authentication functionality for R users of Microsoft's 'Azure' cloud <https://azure.microsoft.com/>. Use this package to obtain 'OAuth' 2.0 tokens for services including Azure Resource Manager, Azure Storage and others. It supports both AAD v1.0 and v2.0, as well as multiple authentication methods, including device code and resource owner grant. Tokens are cached in a user-specific directory obtained using the 'rappdirs' package. The interface is based on the 'OAuth' framework in the 'httr' package, but customised and streamlined for Azure. Part of the 'AzureR' family of packages.",2021-09-13,Hong Ooi,https://github.com/Azure/AzureAuth https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azureauth,1339722,32,2021-09-11T22:52:26Z,41866.3125
azuremlsdk,"Interface to the 'Azure Machine Learning' Software Development Kit
    ('SDK'). Data scientists can use the 'SDK' to train, deploy, automate, and
    manage machine learning models on the 'Azure Machine Learning' service. To
    learn more about 'Azure Machine Learning' visit the website:
    <https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml>.",2020-09-22,Diondra Peck,https://github.com/azure/azureml-sdk-for-r,TRUE,https://github.com/azure/azureml-sdk-for-r,69766,101,2022-02-14T17:08:07Z,690.7524752475248
AzureRMR,"A lightweight but powerful R interface to the 'Azure Resource Manager' REST API. The package exposes a comprehensive class framework and related tools for creating, updating and deleting 'Azure' resource groups, resources and templates. While 'AzureRMR' can be used to manage any 'Azure' service, it can also be extended by other packages to provide extra functionality for specific services. Part of the 'AzureR' family of packages.",2021-10-23,Hong Ooi,https://github.com/Azure/AzureRMR https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azurermr,1333351,16,2021-10-23T04:49:53Z,83334.4375
AzureStor,"Manage storage in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/en-us/product-categories/storage/>. On the admin side, 'AzureStor' includes features to create, modify and delete storage accounts. On the client side, it includes an interface to blob storage, file storage, and 'Azure Data Lake Storage Gen2': upload and download files and blobs; list containers and files/blobs; create containers; and so on. Authenticated access to storage is supported, via either a shared access key or a shared access signature (SAS). Part of the 'AzureR' family of packages.",2022-05-25,Hong Ooi,https://github.com/Azure/AzureStor https://github.com/Azure/AzureR,TRUE,https://github.com/azure/azurestor,952175,53,2022-05-24T20:11:25Z,17965.56603773585
babelgene,"Genomic analysis of model organisms frequently requires the
    use of databases based on human data or making comparisons to
    patient-derived resources. This requires harmonization of gene names
    into the same gene space. The 'babelgene' R package converts between
    human and non-human gene orthologs/homologs. The package integrates
    orthology assertion predictions sourced from multiple databases as
    compiled by the HGNC Comparison of Orthology Predictions (HCOP)
    (Wright et al. 2005 <doi:10.1007/s00335-005-0103-2>, Eyre et al. 2007
    <doi:10.1093/bib/bbl030>, Seal et al. 2011 <doi:10.1093/nar/gkq892>).",2022-03-30,Igor Dolgalev,https://igordot.github.io/babelgene/,TRUE,https://github.com/igordot/babelgene,58294,4,2022-06-15T20:21:08Z,14573.5
babelwhale,"Provides a unified interface to interact with
    'docker' and 'singularity' containers.  You can execute a command
    inside a container, mount a volume or copy a file.",2021-06-25,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,https://github.com/dynverse/babelwhale,TRUE,https://github.com/dynverse/babelwhale,28513,17,2022-04-26T03:42:45Z,1677.235294117647
BacArena,"Can be used for simulation of organisms living in
    communities (Bauer and Zimmermann (2017) <doi:10.1371/journal.pcbi.1005544>). 
    Each organism is represented individually and genome scale
    metabolic models determine the uptake and release of compounds. Biological
    processes such as movement, diffusion, chemotaxis and kinetics are available
    along with data analysis techniques.",2020-05-20,Johannes Zimmermann,https://BacArena.github.io/,TRUE,https://github.com/euba/bacarena,18679,22,2022-06-10T07:33:58Z,849.0454545454545
backbone,"An implementation of methods for extracting an unweighted unipartite
   graph (i.e. a backbone) from an unweighted unipartite graph, a weighted unipartite
   graph, the projection of an unweighted bipartite graph , or the projection
   of a weighted bipartite graph (Neal, 2022 <doi:10.1371/journal.pone.0269137>).",2022-06-01,Zachary Neal,"https://www.zacharyneal.com/backbone,
https://github.com/zpneal/backbone",TRUE,https://github.com/zpneal/backbone,23474,30,2022-06-03T11:45:18Z,782.4666666666667
backports,"
    Functions introduced or changed since R v3.0.0 are re-implemented in this
    package. The backports are conditionally exported in order to let R resolve
    the function name to either the implemented backport, or the respective base
    version, if available. Package developers can make use of new functions or
    arguments by selectively importing specific backports to
    support older installations.",2021-12-13,Michel Lang,https://github.com/r-lib/backports,TRUE,https://github.com/r-lib/backports,17674748,59,2022-03-22T08:12:02Z,299572
badger,Query information and generate badge for using in README and GitHub Pages.,2022-05-31,Guangchuang Yu,https://github.com/GuangchuangYu/badger,TRUE,https://github.com/guangchuangyu/badger,29728,159,2022-05-22T16:18:53Z,186.9685534591195
bagged.outliertrees,"Bagged OutlierTrees is an explainable unsupervised outlier detection method based on an ensemble implementation of the existing OutlierTree procedure (Cortes, 2020). This implementation takes advantage of bootstrap aggregating (bagging) to improve robustness by reducing the possible masking effect and subsequent high variance (similarly to Isolation Forest), hence the name ""Bagged OutlierTrees"". To learn more about the base procedure OutlierTree (Cortes, 2020), please refer to <arXiv:2001.00636>.",2021-07-06,Rafael Santos,https://github.com/RafaJPSantos/bagged.outliertrees,TRUE,https://github.com/rafajpsantos/bagged.outliertrees,4874,5,2021-07-10T14:07:01Z,974.8
baggr,"Running and comparing meta-analyses of data with hierarchical 
    Bayesian models in Stan, including convenience functions for formatting
    data, plotting and pooling measures specific to meta-analysis. This implements many models
    from Meager (2019) <doi:10.1257/app.20170299>.",2022-03-15,Witold Wiecek,https://github.com/wwiecek/baggr,TRUE,https://github.com/wwiecek/baggr,19609,39,2022-03-16T09:14:42Z,502.79487179487177
baguette,"Tree- and rule-based models can be bagged
    (<doi:10.1007/BF00058655>) using this package and their predictions
    equations are stored in an efficient format to reduce the model
    objects size and speed.",2022-06-17,Max Kuhn,"https://baguette.tidymodels.org,
https://github.com/tidymodels/baguette",TRUE,https://github.com/tidymodels/baguette,39591,18,2022-06-17T19:31:28Z,2199.5
bain,"Computes approximated adjusted fractional Bayes factors for
    equality, inequality, and about equality constrained hypotheses.
    For a tutorial on this method, see Hoijtink, Mulder, van Lissa, & Gu,
    (2019) <doi:10.31234/osf.io/v3shc>. For applications in structural equation
    modeling, see: Van Lissa, Gu, Mulder, Rosseel, Van Zundert, &
    Hoijtink, (2021) <doi:10.1080/10705511.2020.1745644>. For the statistical
    underpinnings, see Gu, Mulder, and Hoijtink (2018) <doi:10.1111/bmsp.12110>;
    Hoijtink, Gu, & Mulder, J. (2019) <doi:10.1111/bmsp.12145>; Hoijtink, Gu, 
    Mulder, & Rosseel, (2019) <doi:10.31234/osf.io/q6h5w>.",2021-12-06,Caspar J van Lissa,https://informative-hypotheses.sites.uu.nl/software/bain/,TRUE,https://github.com/cjvanlissa/bain,34260,5,2022-06-27T14:23:37Z,6852
Ball,"Hypothesis tests and sure independence screening (SIS) procedure based on ball statistics, including ball divergence <doi:10.1214/17-AOS1579>, ball covariance <doi:10.1080/01621459.2018.1543600>, and ball correlation <doi:10.1080/01621459.2018.1462709>, are developed to analyze complex data in metric spaces, e.g, shape, directional, compositional and symmetric positive definite matrix data. The ball divergence and ball covariance based distribution-free tests are implemented to detecting distribution difference and association in metric spaces <doi:10.18637/jss.v097.i06>. Furthermore, several generic non-parametric feature selection procedures based on ball correlation, BCor-SIS and all of its variants, are implemented to tackle the challenge in the context of ultra high dimensional data. A fast implementation for large-scale multiple K-sample testing with ball divergence <doi: 10.1002/gepi.22423> is supported, which is particularly helpful for genome-wide association study.",2021-09-20,Jin Zhu,"https://mamba413.github.io/Ball/, https://github.com/Mamba413/Ball",TRUE,https://github.com/mamba413/ball,22959,20,2022-01-13T02:07:48Z,1147.95
bama,"Perform mediation analysis in the presence of high-dimensional
    mediators based on the potential outcome framework. Bayesian Mediation
    Analysis (BAMA), developed by Song et al (2019) <doi:10.1111/biom.13189> and
    Song et al (2020) <arXiv:2009.11409>,
    relies on two Bayesian sparse linear mixed models to simultaneously analyze
    a relatively large number of mediators for a continuous exposure and outcome
    assuming a small number of mediators are truly active. This sparsity
    assumption also allows the extension of univariate mediator analysis by
    casting the identification of active mediators as a variable selection
    problem and applying Bayesian methods with continuous shrinkage priors on
    the effects.",2021-01-21,Mike Kleinsasser,https://github.com/umich-cphds/bama,TRUE,https://github.com/umich-cphds/bama,16006,0,2021-09-13T17:27:17Z,NA
BAMBI,Fit (using Bayesian methods) and simulate mixtures of univariate and bivariate angular distributions. Chakraborty and Wong (2021) <doi:10.18637/jss.v099.i11>.,2021-10-02,Saptarshi Chakraborty,https://doi.org/10.18637/jss.v099.i11,TRUE,https://github.com/c7rishi/bambi,22486,1,2021-10-01T20:06:37Z,22486
bambooHR,"Enables a user to consume the 'BambooHR' API endpoints using R. The
  actual URL of the API will depend on your company domain, and will be handled
  by the package automatically once you setup the config file. The API documentation
  can be found here <https://documentation.bamboohr.com/docs>.",2022-03-15,Tom Bowling,https://mangothecat.github.io/bambooHR/,TRUE,https://github.com/mangothecat/bamboohr,1162,0,2022-03-16T11:16:21Z,NA
bamp,"Bayesian Age-Period-Cohort Modeling and Prediction using efficient Markov Chain Monte Carlo Methods. This is the R version of the previous BAMP software as described in Volker Schmid and Leonhard Held (2007) <DOI:10.18637/jss.v021.i08> Bayesian Age-Period-Cohort Modeling and Prediction - BAMP, Journal of Statistical Software 21:8. This package includes checks of convergence using Gelman's R.",2022-05-05,Volker Schmid,https://volkerschmid.github.io/bamp/,TRUE,https://github.com/volkerschmid/bamp,17180,5,2022-05-28T10:49:08Z,3436
bang,"Provides functions for the Bayesian analysis of some simple 
    commonly-used models, without using Markov Chain Monte Carlo (MCMC) 
    methods such as Gibbs sampling.  The 'rust' package
    <https://cran.r-project.org/package=rust> is used to simulate a random 
    sample from the required posterior distribution, using the generalized 
    ratio-of-uniforms method.  See Wakefield, Gelfand and Smith (1991) 
    <DOI:10.1007/BF01889987> for details. At the moment three conjugate 
    hierarchical models are available: beta-binomial, gamma-Poisson and a 1-way 
    analysis of variance (ANOVA).",2020-02-24,Paul J. Northrop,"https://paulnorthrop.github.io/bang/,
http://github.com/paulnorthrop/bang",TRUE,https://github.com/paulnorthrop/bang,26417,3,2022-04-11T21:48:24Z,8805.666666666666
BARIS,"Allows the user to access and import data from the rich French open data portal through the provided free API <https://doc.data.gouv.fr/api/reference/>. 
    The portal is free, and no credential is required for extracting datasets. ",2022-04-03,Mohamed El Fodil Ihaddaden,https://github.com/feddelegrand7/BARIS,TRUE,https://github.com/feddelegrand7/baris,14623,21,2022-04-03T09:49:39Z,696.3333333333334
Barnard,Barnard's unconditional test for 2x2 contingency tables.,2016-10-20,Kamil Erguler,https://github.com/kerguler/Barnard,TRUE,https://github.com/kerguler/barnard,25047,4,2021-11-02T08:17:50Z,6261.75
bartCause,Contains a variety of methods to generate typical causal inference estimates using Bayesian Additive Regression Trees (BART) as the underlying regression model (Hill (2012) <doi:10.1198/jcgs.2010.08162>).,2020-08-10,Vincent Dorie,https://github.com/vdorie/bartCause,TRUE,https://github.com/vdorie/bartcause,34194,54,2022-06-07T22:03:15Z,633.2222222222222
baRulho,"Intended to facilitate acoustic analysis of (animal) sound transmission experiments, which typically aim to quantify changes in signal structure when transmitted in a given habitat by broadcasting and re-recording animal sounds at increasing distances. The package offers a workflow with functions to prepare the data set for analysis as well as to calculate and visualize several degradation metrics, including blur ratio, signal-to-noise ratio, excess attenuation and envelope correlation among others (Dabelsteen et al 1993 <doi:10.1121/1.406682>).",2022-03-01,Marcelo Araya-Salas,https://github.com/maRce10/baRulho,TRUE,https://github.com/marce10/barulho,15805,1,2022-07-09T02:03:05Z,15805
BAS,"Package for Bayesian Variable Selection and  Model Averaging 
    in linear models and generalized linear models using stochastic or
    deterministic sampling without replacement from posterior
    distributions.  Prior distributions on coefficients are
    from Zellner's g-prior or mixtures of g-priors
    corresponding to the Zellner-Siow Cauchy Priors or the
    mixture of g-priors from Liang et al (2008)
    <DOI:10.1198/016214507000001337>
    for linear models or mixtures of g-priors from  Li and Clyde
    (2019) <DOI:10.1080/01621459.2018.1469992> in generalized linear models.
    Other model selection criteria include AIC, BIC and Empirical Bayes 
    estimates of g. Sampling probabilities may be updated based on the sampled
    models using sampling w/out replacement or an efficient MCMC algorithm which
    samples models using a tree structure of the model space 
    as an efficient hash table.  See  Clyde, Ghosh and Littman (2010) 
    <DOI:10.1198/jcgs.2010.09049> for  details on the sampling algorithms.
    Uniform priors over all models or beta-binomial prior distributions on
    model size are allowed, and for large p truncated priors on the model
    space may be used to enforce sampling models that are full rank.  
    The user may force variables to always be included in addition to imposing
    constraints that higher order interactions are included only if their 
    parents are included in the model.
    This material is based upon work supported by the National Science
    Foundation under Division of Mathematical Sciences grant 1106891.
    Any opinions, findings, and
    conclusions or recommendations expressed in this material are those of
    the author(s) and do not necessarily reflect the views of the
    National Science Foundation.",2022-04-26,Merlise Clyde,"https://www.r-project.org, https://github.com/merliseclyde/BAS",TRUE,https://github.com/merliseclyde/bas,56640,36,2022-05-05T21:42:57Z,1573.3333333333333
baseballr,"Provides numerous utilities for acquiring and analyzing
    baseball data from online sources such as Baseball Reference <https://www.baseball-reference.com/>,
    FanGraphs <https://www.fangraphs.com/>, and the MLB Stats API <https://www.mlb.com/>.",2022-04-25,Saiem Gilani,"https://billpetti.github.io/baseballr/,
https://github.com/BillPetti/baseballr",TRUE,https://github.com/billpetti/baseballr,1786,292,2022-06-17T02:56:02Z,6.116438356164384
basecamb,"Provides functions streamlining the data analysis workflow: 
  Outsourcing data import, renaming and type casting to a *.csv.
  Manipulating imputed datasets and fitting models on them. Summarizing models.",2022-02-06,J. Peter Marquardt,"https://CRAN.R-project.org/package=basecamb,
https://github.com/codeblue-team/basecamb",TRUE,https://github.com/codeblue-team/basecamb,5580,3,2022-02-06T20:23:40Z,1860
baseline,"Collection of baseline correction algorithms, along with a framework and a Tcl/Tk enabled GUI for optimising baseline algorithm parameters. Typical use of the package is for removing background effects from spectra originating from various types of spectroscopy and spectrometry, possibly optimizing this with regard to regression or classification results. Correction methods include polynomial fitting, weighted local smoothers and many more.",2022-07-06,Kristian Hovde Liland,https://github.com/khliland/baseline/,TRUE,https://github.com/khliland/baseline,47379,3,2022-07-06T20:37:29Z,15793
basemaps,"A lightweight package to access spatial basemaps from open sources such as OpenStreetMap, Carto, Mapbox and others in R.",2021-05-19,Jakob Schwalb-Willmann,NA,TRUE,https://github.com/16eagle/basemaps,7729,36,2022-04-11T13:45:11Z,214.69444444444446
basf,"Resurrects the standard plot for shapes established by the
 'base' and 'graphics' packages. This is suited to workflows that require
 plotting using the established and traditional idioms of plotting spatially
 coincident data where it belongs. This package depends on 'sf' and only replaces 
 the plot method. ",2020-12-09,Michael Sumner,https://github.com/mdsumner/basf,TRUE,https://github.com/mdsumner/basf,12646,1,2022-05-08T12:13:53Z,12646
basket,"Implementation of multisource exchangeability models for Bayesian analyses of prespecified subgroups arising in the context of basket trial design and monitoring.  The R 'basket' package facilitates implementation of the binary, symmetric multi-source exchangeability model (MEM) with posterior inference arising from both exact computation and Markov chain Monte Carlo sampling. Analysis output includes full posterior samples as well as posterior probabilities, highest posterior density (HPD) interval boundaries, effective sample sizes (ESS), mean and median estimations, posterior exchangeability probability matrices, and maximum a posteriori MEMs. In addition to providing ""basketwise"" analyses, the package includes similar calculations for ""clusterwise"" analyses for which subgroups are combined into meta-baskets, or clusters, using graphical clustering algorithms that treat the posterior exchangeability probabilities as edge weights. In addition plotting tools are provided to visualize basket and cluster densities as well as their exchangeability.  References include Hyman, D.M., Puzanov, I., Subbiah, V., Faris, J.E., Chau, I., Blay, J.Y., Wolf, J., Raje, N.S., Diamond, E.L., Hollebecque, A. and Gervais, R (2015) <doi:10.1056/NEJMoa1502309>; Hobbs, B.P. and Landin, R. (2018) <doi:10.1002/sim.7893>; Hobbs, B.P., Kane, M.J., Hong, D.S. and Landin, R. (2018) <doi:10.1093/annonc/mdy457>; and Kaizer, A.M., Koopmeiners, J.S. and Hobbs, B.P. (2017) <doi:10.1093/biostatistics/kxx031>.",2021-10-16,Michael J. Kane,https://github.com/kaneplusplus/basket,TRUE,https://github.com/kaneplusplus/basket,14026,4,2021-09-29T14:38:19Z,3506.5
BasketballAnalyzeR,"Contains data and code to accompany  the book 
             P. Zuccolotto and M. Manisera (2020) Basketball Data Science. Applications with R. CRC Press. ISBN 9781138600799.",2020-06-26,Marco Sandri,https://github.com/sndmrc/BasketballAnalyzeR,TRUE,https://github.com/sndmrc/basketballanalyzer,12330,26,2022-05-20T22:58:07Z,474.2307692307692
baskexact,"Calculates the exact operating characteristics of a single-stage
    basket trial with the design of
	Fujikawa, K., Teramukai, S., Yokota, I., & Daimon, T. (2020). <doi:10.1002/bimj.201800404>.",2021-09-15,Lukas Baumann,https://github.com/lbau7/baskexact,TRUE,https://github.com/lbau7/baskexact,3867,0,2022-06-21T14:18:59Z,NA
BatchExperiments,"Extends the BatchJobs package to run statistical experiments on
    batch computing clusters. For further details see the project web page.",2022-03-21,Bernd Bischl,https://github.com/tudo-r/BatchExperiments,TRUE,https://github.com/tudo-r/batchexperiments,24378,16,2022-03-21T19:27:05Z,1523.625
BatchJobs,"Provides Map, Reduce and Filter variants to generate jobs on batch
    computing systems like PBS/Torque, LSF, SLURM and Sun Grid Engine.
    Multicore and SSH systems are also supported. For further details see the
    project web page.",2022-03-21,Bernd Bischl,https://github.com/tudo-r/BatchJobs,TRUE,https://github.com/tudo-r/batchjobs,79651,84,2022-03-21T19:26:31Z,948.2261904761905
batchmix,"Semi-supervised and unsupervised Bayesian mixture models that
  simultaneously infer the cluster/class structure and a batch correction.
  Densities available are the multivariate normal and the multivariate t.
  The model sampler is implemented in C++. This package is aimed at analysis of
  low-dimensional data generated across several batches. See Coleman et al.
  (2022) <doi:10.1101/2022.01.14.476352> for details of the model.",2022-06-21,Stephen Coleman,https://github.com/stcolema/batchmix,TRUE,https://github.com/stcolema/batchmix,200,0,2022-06-15T16:38:10Z,NA
batchtma,"Different adjustment methods for batch effects in biomarker data,
  such as from tissue microarrays. Some methods attempt to retain differences 
  between batches that may be due to between-batch differences in ""biological""
  factors that influence biomarker values.",2021-12-06,Konrad Stopsack,"https://stopsack.github.io/batchtma/,
https://github.com/stopsack/batchtma",TRUE,https://github.com/stopsack/batchtma,2368,0,2021-12-04T23:35:40Z,NA
batchtools,"As a successor of the packages 'BatchJobs' and 'BatchExperiments',
    this package provides a parallel implementation of the Map function for high
    performance computing systems managed by schedulers 'IBM Spectrum LSF'
    (<https://www.ibm.com/products/hpc-workload-management>),
    'OpenLava' (<https://www.openlava.org/>), 'Univa Grid Engine'/'Oracle Grid
    Engine' (<https://www.univa.com/>), 'Slurm' (<https://slurm.schedmd.com/>),
    'TORQUE/PBS'
    (<https://adaptivecomputing.com/cherry-services/torque-resource-manager/>),
    or 'Docker Swarm' (<https://docs.docker.com/engine/swarm/>).
    A multicore and socket mode allow the parallelization on a local machines,
    and multiple machines can be hooked up via SSH to create a makeshift
    cluster. Moreover, the package provides an abstraction mechanism to define
    large-scale computer experiments in a well-organized and reproducible way.",2021-01-11,Michel Lang,https://github.com/mllg/batchtools,TRUE,https://github.com/mllg/batchtools,128805,145,2021-08-05T12:09:19Z,888.3103448275862
bate,"Compute bounds for the treatment effect 
    after adjusting for the presence of omitted variables in linear  
    econometric models, according to the method of Basu (2022) <arXiv:2203.12431>. 
    You supply the data, identify the outcome and 
    treatment variables and additional regressors. The main functions
    will compute bounds for the bias-adjusted treatment effect. Many
    plot functions allow easy visualization of results.",2022-03-28,Deepankar Basu,"https://github.com/dbasu-umass/bate/,
https://rpubs.com/dbasu/bate/",TRUE,https://github.com/dbasu-umass/bate,1094,0,2022-03-25T01:48:09Z,NA
bayefdr,"
    Implements the Bayesian FDR control described by 
    Newton et al. (2004), <doi:10.1093/biostatistics/5.2.155>.
    Allows optimisation and visualisation of expected error rates based on
    tail posterior probability tests.
    Based on code written by Catalina Vallejos for BASiCS, see
    Beyond comparisons of means: understanding changes in gene expression at the
    single-cell level Vallejos et al. (2016) <doi:10.1186/s13059-016-0930-3>.",2021-09-29,Alan OCallaghan,NA,TRUE,https://github.com/vallejosgroup/bayefdr,10044,0,2021-09-29T16:05:02Z,NA
bayes4psy,Contains several Bayesian models for data analysis of psychological tests. A user friendly interface for these models should enable students and researchers to perform professional level Bayesian data analysis without advanced knowledge in programming and Bayesian statistics. This package is based on the Stan platform (Carpenter et el. 2017 <doi:10.18637/jss.v076.i01>).,2021-09-27,Jure Demšar,https://github.com/bstatcomp/bayes4psy,TRUE,https://github.com/bstatcomp/bayes4psy,18931,14,2021-09-27T08:47:24Z,1352.2142857142858
bayesassurance,"Computes Bayesian assurance under various 
    settings characterized by different assumptions and objectives, including 
    precision-based conditions, credible intervals, and goal functions. 
    All simulation-based functions included in this package rely on a two-stage 
    Bayesian method that assigns two distinct priors to evaluate the 
    probability of observing a positive outcome, which addresses subtle 
    limitations that take place when using the standard single-prior approach. 
    For more information, please refer to Pan and Banerjee (2021)
    <arXiv:2112.03509>.",2022-06-17,Jane Pan,https://github.com/jpan928/bayesassurance_rpackage,TRUE,https://github.com/jpan928/bayesassurance_rpackage,265,0,2022-06-17T04:05:20Z,NA
bayesbr,"Applies the Beta regression model in the Bayesian statistical view with the possibility of adding a spatial effect in the parameters, the Beta regression is used when the response variable is a proportion variable, that is, it only accepts values between 0 and 1.
    The package 'bayesbr' uses 'rstan' package to build the Bayesian statistical models. The main function of the package receives as a parameter a form informing the independent variable and the co-variables of the model to be made, as output it returns a list with the results of the model. For more details see Ferrari and Cribari-Neto (2004) <doi:10.1080/0266476042000214501> and Hoffman and Gelman (2014) <arXiv:1111.4246>.",2021-07-16,Joao Melo,https://github.com/pjoao266/bayesbr,TRUE,https://github.com/pjoao266/bayesbr,10183,0,2021-07-16T19:24:53Z,NA
BayesCTDesign,"A set of functions to help clinical trial researchers calculate power and sample size for two-arm Bayesian randomized clinical trials that do or do not incorporate historical control data.  At some point during the design process, a clinical trial researcher who is designing a basic two-arm Bayesian randomized clinical trial needs to make decisions about power and sample size within the context of hypothesized treatment effects.  Through simulation, the simple_sim() function will estimate power and other user specified clinical trial characteristics at user specified sample sizes given user defined scenarios about treatment effect,control group characteristics, and outcome.  If the clinical trial researcher has access to historical control data, then the researcher can design a two-arm Bayesian randomized clinical trial that incorporates the historical data.  In such a case, the researcher needs to work through the potential consequences of historical and randomized control differences on trial characteristics, in addition to working through issues regarding power in the context of sample size, treatment effect size, and outcome.  If a researcher designs a clinical trial that will incorporate historical control data, the researcher needs the randomized controls to be from the same population as the historical controls.  What if this is not the case when the designed trial is implemented?  During the design phase, the researcher needs to investigate the negative effects of possible historic/randomized control differences on power, type one error, and other trial characteristics.  Using this information, the researcher should design the trial to mitigate these negative effects.  Through simulation, the historic_sim() function will estimate power and other user specified clinical trial characteristics at user specified sample sizes given user defined scenarios about historical and randomized control differences as well as treatment effects and outcomes.  The results from historic_sim() and simple_sim() can be printed with print_table() and graphed with plot_table() methods.  Outcomes considered are Gaussian, Poisson, Bernoulli, Lognormal, Weibull, and Piecewise Exponential.  The methods are described in Eggleston et al. (2021) <doi:10.18637/jss.v100.i21>.  ",2021-11-30,Barry Eggleston,https://github.com/begglest/BayesCTDesign,TRUE,https://github.com/begglest/bayesctdesign,15216,0,2021-11-28T07:12:31Z,NA
bayesDccGarch,"Bayesian estimation of dynamic conditional correlation GARCH model for multivariate time series volatility (Fioruci, J.A., Ehlers, R.S. and Andrade-Filho, M.G., (2014). <doi:10.1080/02664763.2013.839635>.",2021-10-05,Jose Augusto Fiorucci,https://ui.adsabs.harvard.edu/abs/2014arXiv1412.2967F/abstract,TRUE,https://github.com/jafiorucci/bayesdccgarch,14531,1,2021-10-02T20:36:36Z,14531
bayesdfa,"Implements Bayesian dynamic factor analysis with 'Stan'. Dynamic 
    factor analysis is a dimension reduction tool for multivariate time series.
    'bayesdfa' extends conventional dynamic factor models in several ways. 
    First, extreme events may be estimated in the latent trend by modeling
    process error with a student-t distribution. Second, alternative constraints
    (including proportions are allowed). Third, the estimated
    dynamic factors can be analyzed with hidden Markov models to evaluate
    support for latent regimes.",2021-09-28,Eric J. Ward,https://fate-ewi.github.io/bayesdfa/,TRUE,https://github.com/fate-ewi/bayesdfa,26594,23,2021-11-30T14:13:52Z,1156.2608695652175
bayesDP,"Functions for data augmentation using the Bayesian discount prior 
    method for single arm and two-arm clinical trials, as described in Haddad 
    et al. (2017) <doi:10.1080/10543406.2017.1300907>. The discount power prior 
    methodology was developed in collaboration with the The Medical Device 
    Innovation Consortium (MDIC) Computer Modeling & Simulation Working Group.",2022-01-30,Graeme L. Hickey,https://github.com/graemeleehickey/bayesDP,TRUE,https://github.com/graemeleehickey/bayesdp,20796,0,2022-01-30T22:01:40Z,NA
BayesFactor,"A suite of functions for computing
    various Bayes factors for simple designs, including contingency tables,
    one- and two-sample designs, one-way designs, general ANOVA designs, and
    linear regression.",2022-07-05,Richard D. Morey,https://richarddmorey.github.io/BayesFactor/,TRUE,https://github.com/richarddmorey/bayesfactor,432473,119,2022-07-04T16:52:28Z,3634.2268907563025
bayesian,"Fit Bayesian models using 'brms'/'Stan' with 'parsnip'/'tidymodels'
    via 'bayesian' <doi:10.5281/zenodo.6654386>. 'tidymodels' is a collection of
    packages for machine learning; see Kuhn and Wickham (2020) <https://www.tidymodels.org>).
    The technical details of 'brms' and 'Stan' are described in Bürkner (2017)
    <doi:10.18637/jss.v080.i01>, Bürkner (2018) <doi:10.32614/RJ-2018-017>,
    and Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",2022-06-16,Hamada S. Badr,"https://hsbadr.github.io/bayesian/,
https://github.com/hsbadr/bayesian",TRUE,https://github.com/hsbadr/bayesian,10356,31,2022-07-08T14:47:19Z,334.06451612903226
BayesianLaterality,"Functional differences between the cerebral hemispheres 
    are a fundamental characteristic of the human brain. Researchers 
    interested in studying these differences often infer underlying 
    hemispheric dominance for a certain function (e.g., language) from 
    laterality indices calculated from observed performance or brain 
    activation measures . However, any inference from observed measures 
    to latent (unobserved) classes has to consider the prior probability 
    of class membership in the population. The provided functions 
    implement a Bayesian model for predicting hemispheric dominance from
    observed laterality indices (Sorensen and Westerhausen, Laterality: 
    Asymmetries of Body, Brain and Cognition, 2020, <doi:10.1080/1357650X.2020.1769124>).",2021-08-08,Oystein Sorensen,https://github.com/LCBC-UiO/BayesianLaterality,TRUE,https://github.com/lcbc-uio/bayesianlaterality,9373,0,2021-08-08T20:06:05Z,NA
BayesianReasoning,"Functions to plot and help understand positive and negative
    predictive values (PPV and NPV), and their relationship with
    sensitivity, specificity, and prevalence. See Akobeng, A.K. (2007)
    <doi:10.1111/j.1651-2227.2006.00180.x> for a theoretical overview of
    the technical concepts and Navarrete et al. (2015) for a practical
    explanation about the importance of their understanding
    <doi:10.3389/fpsyg.2015.01327>.",2022-01-07,Gorka Navarrete,https://github.com/gorkang/BayesianReasoning,TRUE,https://github.com/gorkang/bayesianreasoning,10474,8,2022-01-03T13:02:31Z,1309.25
BayesianTools,"General-purpose MCMC and SMC samplers, as well as plot and
    diagnostic functions for Bayesian statistics, with a particular focus on
    calibrating complex system models. Implemented samplers include various
    Metropolis MCMC variants (including adaptive and/or delayed rejection MH), the
    T-walk, two differential evolution MCMCs, two DREAM MCMCs, and a sequential
    Monte Carlo (SMC) particle filter.",2019-12-09,Florian Hartig,https://github.com/florianhartig/BayesianTools,TRUE,https://github.com/florianhartig/bayesiantools,32046,86,2022-03-08T14:46:19Z,372.6279069767442
bayeslincom,"Computes point estimates, standard deviations, and credible intervals 
             for linear combinations of posterior samples. Optionally performs region
             practical equivalence (ROPE) tests as described in 
             Kruschke and Liddell (2018) <doi:10.3758/s13423-016-1221-4>.",2021-09-08,Josue E. Rodriguez,NA,TRUE,https://github.com/josue-rodriguez/bayeslincom,9001,2,2021-09-08T14:23:52Z,4500.5
bayeslm,"Efficient sampling for Gaussian linear regression with arbitrary priors, Hahn, He and Lopes (2018) <arXiv:1806.05738>.",2022-06-27,Jingyu He,https://github.com/JingyuHe/bayeslm,TRUE,https://github.com/jingyuhe/bayeslm,11576,7,2022-06-26T14:34:02Z,1653.7142857142858
BayesMallows,"An implementation of the Bayesian version of the Mallows rank model
    (Vitelli et al., Journal of Machine Learning Research, 2018 <https://jmlr.org/papers/v18/15-481.html>;
    Crispino et al., Annals of Applied Statistics, 2019 <doi:10.1214/18-AOAS1203>). Both Metropolis-Hastings 
    and sequential Monte Carlo algorithms for estimating the models are available. Cayley, footrule,
    Hamming, Kendall, Spearman, and Ulam distances are supported in the models. The rank data to be
    analyzed can be in the form of complete rankings, top-k rankings, partially missing rankings, as well
    as consistent and inconsistent pairwise preferences. Several functions for plotting and studying the
    posterior distributions of parameters are provided. The package also provides functions for estimating
    the partition function (normalizing constant) of the Mallows rank model, both with the importance
    sampling algorithm of Vitelli et al. and asymptotic approximation with the IPFP algorithm
    (Mukherjee, Annals of Statistics, 2016 <doi:10.1214/15-AOS1389>).",2022-05-24,Oystein Sorensen,https://github.com/ocbe-uio/BayesMallows,TRUE,https://github.com/ocbe-uio/bayesmallows,23534,13,2022-05-24T12:25:50Z,1810.3076923076924
BayesMassBal,"Bayesian tools that can be used to reconcile, or mass balance, mass flow rate data collected from chemical or particulate separation processes aided by constraints governed by the conservation of mass.
    Functions included in the package aid the user in organizing and constraining data, using Markov chain Monte Carlo methods to obtain samples from Bayesian models, and in computation of the marginal likelihood of the data, given a particular model, for model selection.  Marginal likelihood is approximated by methods in Chib S (1995) <doi:10.2307/2291521>.",2022-06-17,Scott Koermer,https://github.com/skoermer/BayesMassBal,TRUE,https://github.com/skoermer/bayesmassbal,9928,2,2022-06-17T21:20:09Z,4964
bayesmove,"Methods for assessing animal movement from telemetry and biologging
    data using non-parametric Bayesian methods. This includes features for pre-
    processing and analysis of data, as well as the visualization of results
    from the models. This framework does not rely on standard parametric density
    functions, which provides flexibility during model fitting. Further details 
    regarding part of this framework can be found in Cullen et al. (2021) <doi:10.1101/2020.11.05.369702>.",2021-10-22,Joshua Cullen,"https://github.com/joshcullen/bayesmove,
https://joshcullen.github.io/bayesmove/",TRUE,https://github.com/joshcullen/bayesmove,9917,3,2022-06-21T17:43:20Z,3305.6666666666665
BayesMRA,Software for fitting sparse Bayesian multi-resolution spatial models using Markov Chain Monte Carlo.,2020-08-18,John Tipton,https://github.com/jtipton25/BayesMRA,TRUE,https://github.com/jtipton25/bayesmra,8908,2,2022-07-04T02:37:11Z,4454
bayesnec,"Implementation of No-Effect-Concentration estimation that uses 'brms' (see Burkner (2017)<doi:10.18637/jss.v080.i01>; Burkner (2018)<doi:10.32614/RJ-2018-017>; Carpenter 'et al.' (2017)<doi:10.18637/jss.v076.i01> to fit concentration(dose)-response data using Bayesian methods for the purpose of estimating 'ECX' values, but more particularly 'NEC' (see Fox (2010)<doi:10.1016/j.ecoenv.2009.09.012>. This package expands and supersedes an original version implemented in R2jags, see Fisher, Ricardo and Fox (2020)<doi:10.5281/ZENODO.3966864>.",2022-04-21,Rebecca Fisher,https://open-aims.github.io/bayesnec/,TRUE,https://github.com/open-aims/bayesnec,5580,4,2022-05-03T01:38:56Z,1395
BayesNetBP,"Belief propagation methods in Bayesian Networks to propagate evidence through the network. The implementation of these methods are based on the article: Cowell, RG (2005). Local Propagation in Conditional Gaussian Bayesian Networks <https://www.jmlr.org/papers/v6/cowell05a.html>. For details please see Yu et. al. (2020) BayesNetBP: An R Package for Probabilistic Reasoning in Bayesian Networks <doi:10.18637/jss.v094.i03>. The optional 'cyjShiny' package for running the Shiny app is available at <https://github.com/cytoscape/cyjShiny>. Please see the example in the documentation of 'runBayesNetApp' function for installing 'cyjShiny' package from GitHub. ",2022-05-08,Han Yu,NA,TRUE,https://github.com/hyu-ub/bayesnetbp,20324,15,2022-05-08T14:44:41Z,1354.9333333333334
bayesplot,"Plotting functions for posterior analysis, MCMC diagnostics,
    prior and posterior predictive checks, and other visualizations
    to support the applied Bayesian workflow advocated in
    Gabry, Simpson, Vehtari, Betancourt, and Gelman (2019) <doi:10.1111/rssa.12378>.
    The package is designed not only to provide convenient functionality
    for users, but also a common set of functions that can be easily used by
    developers working on a variety of R packages for Bayesian modeling,
    particularly (but not exclusively) packages interfacing with 'Stan'.",2022-03-10,Jonah Gabry,https://mc-stan.org/bayesplot/,TRUE,https://github.com/stan-dev/bayesplot,681486,352,2022-06-21T14:30:37Z,1936.0397727272727
BayesPostEst,"An implementation of functions to generate and plot postestimation quantities after estimating Bayesian regression models using Markov chain Monte Carlo (MCMC). Functionality includes the estimation of the Precision-Recall curves (see Beger, 2016 <doi:10.2139/ssrn.2765419>), the implementation of the observed values method of calculating predicted probabilities by Hanmer and Kalkan (2013) <doi:10.1111/j.1540-5907.2012.00602.x>, the implementation of the average value method of calculating predicted probabilities (see King, Tomz, and Wittenberg, 2000 <doi:10.2307/2669316>), and the generation and plotting of first differences to summarize typical effects across covariates (see Long 1997, ISBN:9780803973749; King, Tomz, and Wittenberg, 2000 <doi:10.2307/2669316>). This package can be used with MCMC output generated by any Bayesian estimation tool including 'JAGS', 'BUGS', 'MCMCpack', and 'Stan'.",2021-11-11,Johannes Karreth,https://github.com/ShanaScogin/BayesPostEst,TRUE,https://github.com/shanascogin/bayespostest,16663,10,2022-05-11T22:52:56Z,1666.3
Bayesrel,"Functionality for reliability estimates. For 'unidimensional' tests:
    Coefficient alpha, 'Guttman's' lambda-2/-4/-6, the Greatest lower
    bound and coefficient omega_u ('unidimensional') in a Bayesian and a frequentist version. 
    For multidimensional tests: omega_t (total) and omega_h (hierarchical). 
    The results include confidence and credible intervals, the 
    probability of a coefficient being larger than a cutoff, 
    and a check for the factor models, necessary for the omega coefficients. 
    The method for the Bayesian 'unidimensional' estimates, except for omega_u, 
    is sampling from the posterior inverse 'Wishart' for the 
    covariance matrix based measures (see 'Murphy', 2007, 
    <https://groups.seas.harvard.edu/courses/cs281/papers/murphy-2007.pdf>. 
    The Bayesian omegas (u, t, and h) are obtained by 
    'Gibbs' sampling from the conditional posterior distributions of 
    (1) the single factor model and (2) the second-order factor model
    ('Lee', 2007, <https://onlinelibrary.wiley.com/doi/book/10.1002/9780470024737>). ",2022-06-27,Julius M. Pfadt,https://github.com/juliuspf/Bayesrel,TRUE,https://github.com/juliuspf/bayesrel,19873,0,2022-06-27T10:03:37Z,NA
bayesrules,"Provides datasets and functions used for analysis 
  and visualizations in the Bayes Rules! book (<https://www.bayesrulesbook.com>). 
  The package contains a set of functions that summarize and plot Bayesian models from some conjugate families 
  and another set of functions for evaluation of some Bayesian models.",2021-09-25,Mine Dogucu,"https://bayes-rules.github.io/bayesrules/docs/,
https://github.com/bayes-rules/bayesrules/",TRUE,https://github.com/bayes-rules/bayesrules,11279,49,2022-04-21T04:23:08Z,230.18367346938774
BayesSenMC,"Generates different posterior distributions of adjusted odds ratio under different priors of sensitivity and specificity, and plots the models for comparison. It also provides estimations for the specifications of the models using diagnostics of exposure status with a non-linear mixed effects model. It implements the methods that are first proposed in <doi:10.1016/j.annepidem.2006.04.001> and <doi:10.1177/0272989X09353452>.",2021-10-05,Jinhui Yang,https://github.com/formidify/BayesSenMC,TRUE,https://github.com/formidify/bayessenmc,12112,0,2021-08-23T20:06:07Z,NA
BayesSPsurv,"Parametric spatial split-population (SP) survival models for clustered 
    event processes. The models account for structural and spatial heterogeneity among 
    “at risk” and “immune” populations, and incorporate time-varying covariates. 
    This package currently implements Weibull, Exponential and Log-logistic forms for 
    the duration component. It also includes functions for a series of diagnostic 
    tests and plots to easily visualize spatial autocorrelation, convergence, and spatial effects. Users can 
    create their own spatial weights matrix based on their units and adjacencies of 
    interest, making the use of these models flexible and broadly applicable to a 
    variety of research areas. Joo et al. (2020) <https://github.com/Nicolas-Schmidt/BayesSPsurv/blob/master/man/figures/SPcure.pdf> describe 
    the estimators included in this package. ",2021-09-13,Nicolas Schmidt,https://nicolas-schmidt.github.io/BayesSPsurv/,TRUE,https://github.com/nicolas-schmidt/bayesspsurv,9887,4,2021-09-13T01:51:52Z,2471.75
bayestestR,"Provides utilities to describe posterior
    distributions and Bayesian models. It includes point-estimates such as
    Maximum A Posteriori (MAP), measures of dispersion (Highest Density
    Interval - HDI; Kruschke, 2015 <doi:10.1016/C2012-0-00477-2>) and
    indices used for null-hypothesis testing (such as ROPE percentage, pd
    and Bayes factors).",2022-05-02,Dominique Makowski  (<https://orcid.org/0000-0001-5375-9967>,https://easystats.github.io/bayestestR/,TRUE,https://github.com/easystats/bayestestr,1144919,489,2022-07-04T22:09:23Z,2341.347648261759
BayesTools,"Provides tools for conducting Bayesian analyses. The package contains 
    functions for creating a wide range of prior distribution objects, mixing posterior 
    samples from 'JAGS' and 'Stan' models, plotting posterior distributions, and etc...
    The tools for working with prior distribution span from visualization, generating 'JAGS' 
    and 'bridgesampling' syntax to basic functions such as rng, quantile, and distribution functions. ",2022-06-15,František Bartoš,https://fbartos.github.io/BayesTools/,TRUE,https://github.com/fbartos/bayestools,9111,1,2022-07-09T20:52:59Z,9111
BayesVarSel,"Conceived to calculate Bayes factors in Linear models and then to provide a formal Bayesian answer to testing and variable selection problems. From a theoretical side, the emphasis in this package is placed on the prior distributions and it allows a wide range of them: Jeffreys (1961); Zellner and Siow(1980)<DOI:10.1007/bf02888369>; Zellner and Siow(1984); Zellner (1986)<DOI:10.2307/2233941>; Fernandez et al. (2001)<DOI:10.1016/s0304-4076(00)00076-2>; Liang et al. (2008)<DOI:10.1198/016214507000001337>  and Bayarri et al. (2012)<DOI:10.1214/12-aos1013>. The interaction with the package is through a friendly interface that syntactically mimics the well-known lm() command of R. The resulting objects can be easily explored providing the user very valuable information (like marginal, joint and conditional inclusion probabilities of potential variables; the highest posterior probability model, HPM; the median probability model, MPM) about the structure of the true -data generating- model. Additionally, this package incorporates abilities to handle problems with a large number of potential explanatory variables through parallel and heuristic versions of the main commands, Garcia-Donato and Martinez-Beneito (2013)<DOI:10.1080/01621459.2012.742443>. It also allows problems with p>n and p>>n and also incorporates routines to handle problems with variable selection with factors.",2020-02-18,Anabel Forte,https://github.com/comodin19/BayesVarSel,TRUE,https://github.com/comodin19/bayesvarsel,23671,6,2022-05-05T11:15:16Z,3945.1666666666665
bayesvl,"Provides users with its associated functions for pedagogical purposes in visually learning Bayesian networks and Markov chain Monte Carlo (MCMC) computations. It enables users to: a) Create and examine the (starting) graphical structure of Bayesian networks; b) Create random Bayesian networks using a dataset with customized constraints; c) Generate 'Stan' code for structures of Bayesian networks for sampling the data and learning parameters; d) Plot the network graphs; e) Perform Markov chain Monte Carlo computations and produce graphs for posteriors checks. The package refers to one reference item, which describes the methods and algorithms: Vuong, Quan-Hoang and La, Viet-Phuong (2019) <doi:10.31219/osf.io/w5dx6> The 'bayesvl' R package. Open Science Framework (May 18).",2019-05-24,Viet-Phuong La,https://github.com/sshpa/bayesvl,TRUE,https://github.com/sshpa/bayesvl,14304,16,2022-05-25T04:26:49Z,894
bayfoxr,"A Bayesian, global planktic foraminifera core top calibration to 
    modern sea-surface temperatures. Includes four calibration models, 
    considering species-specific calibration parameters and seasonality.",2019-02-06,Steven Malevich,https://github.com/brews/bayfoxr/,TRUE,https://github.com/brews/bayfoxr,13992,4,2022-06-23T00:27:43Z,3498
BayLum,"Bayesian analysis of luminescence data and C-14 age estimates. Bayesian models are based on the following publications: Combes, B. & Philippe, A. (2017) <doi:10.1016/j.quageo.2017.02.003> and Combes et al (2015) <doi:10.1016/j.quageo.2015.04.001>. This includes, amongst others, data import, export, application of age models and palaeodose model.",2022-02-21,Anne Philippe,https://CRAN.r-project.org/package=BayLum,TRUE,https://github.com/crp2a/baylum,18854,8,2022-06-09T11:25:10Z,2356.75
baymedr,"BAYesian inference for MEDical designs in R. Functions for the 
    computation of Bayes factors for common biomedical research designs. 
    Implemented are functions to test the equivalence (equiv_bf), 
    non-inferiority (infer_bf), and superiority (super_bf) of an experimental 
    group compared to a control group on a continuous outcome measure. Bayes 
    factors for these three tests can be computed based on raw data (x, y) or 
    summary statistics (n_x, n_y, mean_x, mean_y, sd_x, sd_y [or ci_margin 
    and ci_level]).",2021-03-28,Maximilian Linde,https://github.com/maxlinde/baymedr,TRUE,https://github.com/maxlinde/baymedr,14533,2,2022-07-05T15:13:33Z,7266.5
baytrends,"Enable users to evaluate long-term trends using a Generalized 
    Additive Modeling (GAM) approach. The model development includes selecting a 
    GAM structure to describe nonlinear seasonally-varying changes over time, 
    incorporation of hydrologic variability via either a river flow or salinity, 
    the use of an intervention to deal with method or laboratory changes 
    suspected to impact data values, and representation of left- and 
    interval-censored data. The approach has been applied to water quality data 
    in the Chesapeake Bay, a major estuary on the east coast of the United 
    States to provide insights to a range of management- and research-focused 
    questions.  Methodology described in Murphy (2019) 
    <doi:10.1016/j.envsoft.2019.03.027>.",2022-05-05,Rebecca Murphy,https://github.com/tetratech/baytrends,TRUE,https://github.com/tetratech/baytrends,18100,8,2022-05-05T20:36:48Z,2262.5
bbknnR,"A fast and intuitive batch effect removal tool for single-cell data. BBKNN is originally used in the 'scanpy' python package, and now can be used with 'Seurat' seamlessly.",2022-05-27,Yuchen Li,"https://github.com/ycli1995/bbknnR,
https://github.com/Teichlab/bbknn,
https://bbknn.readthedocs.io/en/latest/",TRUE,https://github.com/ycli1995/bbknnr,395,1,2022-05-28T00:57:29Z,395
BBmisc,"Miscellaneous helper functions for and from B. Bischl and
    some other guys, mainly for package development.",2022-03-10,Bernd Bischl,https://github.com/berndbischl/BBmisc,TRUE,https://github.com/berndbischl/bbmisc,899339,17,2022-03-14T08:23:38Z,52902.294117647056
bbmle,Methods and functions for fitting maximum likelihood models in R. This package modifies and extends the 'mle' classes in the 'stats4' package.,2022-05-11,Ben Bolker,https://github.com/bbolker/bbmle,TRUE,https://github.com/bbolker/bbmle,475541,22,2022-05-06T22:22:47Z,21615.5
bbotk,"Provides a common framework for optimization of black-box
    functions for other packages, e.g. 'mlr3tuning' or 'mlr3fselect'. It
    offers various optimization methods e.g. grid search, random search,
    generalized simulated annealing and iterated racing.",2022-05-04,Marc Becker,"https://bbotk.mlr-org.com, https://github.com/mlr-org/bbotk",TRUE,https://github.com/mlr-org/bbotk,62135,16,2022-05-09T16:02:49Z,3883.4375
bbw,"The blocked weighted bootstrap (BBW) is an estimation technique 
    for use with data from two-stage cluster sampled surveys in which either 
    prior weighting (e.g. population-proportional sampling or PPS as used in 
    Standardized Monitoring and Assessment of Relief and Transitions or SMART 
    surveys) or posterior weighting (e.g. as used in rapid assessment method or
    RAM and simple spatial sampling method or S3M surveys) is implemented. See 
    Cameron et al (2008) <doi:10.1162/rest.90.3.414> for application of 
    bootstrap to cluster samples. See Aaron et al (2016) 
    <doi:10.1371/journal.pone.0163176> and Aaron et al (2016) 
    <doi:10.1371/journal.pone.0162462> for application of the blocked weighted 
    bootstrap to estimate indicators from two-stage cluster sampled surveys.",2022-05-30,Ernest Guevarra,"https://github.com/rapidsurveys/bbw, https://rapidsurveys.io/bbw/",TRUE,https://github.com/rapidsurveys/bbw,15179,3,2022-05-30T09:18:26Z,5059.666666666667
bcdata,"Search, query, and download tabular and
    'geospatial' data from the British Columbia Data Catalogue
    (<https://catalogue.data.gov.bc.ca/>).  Search catalogue data records
    based on keywords, data licence, sector, data format, and B.C.
    government organization. View metadata directly in R, download many
    data formats, and query 'geospatial' data available via the B.C.
    government Web Feature Service ('WFS') using 'dplyr' syntax.",2022-07-06,Andy Teucher,"https://bcgov.github.io/bcdata/,
https://catalogue.data.gov.bc.ca/,
https://github.com/bcgov/bcdata/",TRUE,https://github.com/bcgov/bcdata,22417,68,2022-07-05T20:53:42Z,329.6617647058824
Bchron,"Enables quick calibration of radiocarbon dates under various 
  calibration curves (including user generated ones); age-depth modelling 
  as per the algorithm of Haslett and Parnell (2008) <DOI:10.1111/j.1467-9876.2008.00623.x>; Relative sea level 
  rate estimation incorporating time uncertainty in polynomial regression 
  models (Parnell and Gehrels 2015) <DOI:10.1002/9781118452547.ch32>; non-parametric phase modelling via 
  Gaussian mixtures as a means to determine the activity of a site 
  (and as an alternative to the Oxcal function SUM; currently 
  unpublished), and reverse calibration of dates from calibrated into 
  un-calibrated years (also unpublished).",2021-06-10,Andrew Parnell,https://andrewcparnell.github.io/Bchron/,TRUE,https://github.com/andrewcparnell/bchron,40677,31,2022-04-07T11:23:51Z,1312.1612903225807
bcmaps,"Provides access to various spatial layers for B.C., such as 
    administrative boundaries, natural resource management boundaries, etc. 
    Most layers are imported from the 'bcdata' package as 'sf' or 'Spatial' objects
    through function calls in this package. ",2021-03-09,Andy Teucher,https://github.com/bcgov/bcmaps,TRUE,https://github.com/bcgov/bcmaps,20104,53,2022-03-02T05:00:46Z,379.3207547169811
bcputility,Provides functions to utilize a command line utility that does bulk inserts and exports from SQL Server databases. ,2022-02-20,Thomas Roh,"https://bcputility.roh.engineering,
https://github.com/tomroh/bcputility",TRUE,https://github.com/tomroh/bcputility,5546,12,2022-02-20T21:40:32Z,462.1666666666667
bcrm,"Implements a wide variety of one- and two-parameter Bayesian CRM
    designs. The program can run interactively, allowing the user to enter outcomes
    after each cohort has been recruited, or via simulation to assess operating
    characteristics. See Sweeting et al. (2013): <doi:10.18637/jss.v054.i13>.",2019-08-23,Graham Wheeler,https://github.com/mikesweeting/bcrm,TRUE,https://github.com/mikesweeting/bcrm,23169,1,2022-02-17T13:00:08Z,23169
bcTSNE,"Implements the projected t-SNE method for batch correction of 
  high-dimensional data. Please see Aliverti et al. (2020) 
  <doi:10.1093/bioinformatics/btaa189> for more information.",2021-12-01,Dayne L Filer,https://github.com/emanuelealiverti/BC_tSNE,TRUE,https://github.com/emanuelealiverti/bc_tsne,9750,5,2021-11-30T18:19:16Z,1950
bdchecks,Supplies a Shiny app and a set of functions to perform and managing data checks for biodiversity data. ,2019-02-18,Povilas Gibas,https://github.com/bd-R/bdchecks,TRUE,https://github.com/bd-r/bdchecks,14977,1,2021-10-03T23:22:35Z,14977
bdclean,"Provides features to manage the complete workflow for biodiversity data cleaning. Uploading data, gathering input from users (in order to adjust cleaning procedures), cleaning data and finally, generating various reports and several versions of the data. Facilitates user-level data cleaning, designed for the inexperienced R user. T Gueta et al (2018) <doi:10.3897/biss.2.25564>. T Gueta et al (2017) <doi:10.3897/tdwgproceedings.1.20311>.",2019-04-11,Thiloshon Nagarajah,"https://github.com/bd-R/bdclean,
https://bd-r.github.io/The-bdverse/index.html",TRUE,https://github.com/bd-r/bdclean,14661,7,2021-10-03T23:22:39Z,2094.4285714285716
bdl,"Interface to Local Data Bank ('Bank Danych Lokalnych' - 'bdl') API 
    <https://api.stat.gov.pl/Home/BdlApi?lang=en> with set of useful tools like 
    quick plotting and map generating using data from bank. ",2022-02-01,Marzena Szpadel,https://statisticspoland.github.io/R_Package_to_API_BDL/,TRUE,https://github.com/statisticspoland/r_package_to_api_bdl,14847,15,2022-02-01T00:48:51Z,989.8
bdots,"Analyze differences among time series curves with p-value
        adjustment for multiple comparisons introduced in Oleson et al
        (2015) <DOI:10.1177/0962280215607411>.",2022-05-31,Collin Nolte,https://github.com/collinn/bdots,TRUE,https://github.com/collinn/bdots,17863,2,2022-06-29T20:16:49Z,8931.5
bdpar,"
        Provide a tool to easily build customized data flows to pre-process large volumes 
    of information from different sources. To this end, 'bdpar' allows to (i) easily use and 
    create new functionalities and (ii) develop new data source extractors according to the 
    user needs. Additionally, the package provides by default a predefined data flow 
    to extract and pre-process the most relevant information (tokens, dates, ... ) from some textual 
    sources (SMS, Email, tweets, YouTube comments).",2022-05-18,Miguel Ferreiro-Díaz,https://github.com/miferreiro/bdpar,TRUE,https://github.com/miferreiro/bdpar,16967,4,2022-05-18T08:37:56Z,4241.75
bdrc,Fits a discharge rating curve based on the power-law and the generalized power-law from data on paired stage and discharge measurements in a given river using a Bayesian hierarchical model as described in Hrafnkelsson et al. (2020) <arXiv:2010.04769>.,2021-07-28,Birgir Hrafnkelsson,NA,TRUE,https://github.com/sor16/bdrc,4548,5,2022-07-08T08:34:23Z,909.6
bdvis,"Provides a set of functions to create basic visualizations to quickly
    preview different aspects of biodiversity information such as inventory 
    completeness, extent of coverage (taxonomic, temporal and geographic), gaps
    and biases. Barve & Otegui (2016) <DOI:10.1093/bioinformatics/btw333>.",2022-06-09,Vijay Barve,NA,TRUE,https://github.com/vijaybarve/bdvis,20875,25,2022-06-09T03:45:28Z,835
beakr,"A minimalist web framework for developing application programming 
    interfaces in R that provides a flexible framework for handling common 
    HTTP-requests, errors, logging, and an ability to integrate any R code as 
    server middle-ware.",2021-04-06,Jonathan Callahan,https://github.com/MazamaScience/beakr,TRUE,https://github.com/mazamascience/beakr,15018,82,2022-05-09T21:00:20Z,183.14634146341464
BED,"An interface for the 'Neo4j' database providing
    mapping between different identifiers of biological entities.
    This Biological Entity Dictionary (BED)
    has been developed to address three main challenges.
    The first one is related to the completeness of identifier mappings.
    Indeed, direct mapping information provided by the different systems
    are not always complete and can be enriched by mappings provided by other
    resources.
    More interestingly, direct mappings not identified by any of these
    resources can be indirectly inferred by using mappings to a third reference.
    For example, many human Ensembl gene ID are not directly mapped to any
    Entrez gene ID but such mappings can be inferred using respective mappings
    to HGNC ID. The second challenge is related to the mapping of deprecated
    identifiers. Indeed, entity identifiers can change from one resource
    release to another. The identifier history is provided by some resources,
    such as Ensembl or the NCBI, but it is generally not used by mapping tools.
    The third challenge is related to the automation of the mapping process
    according to the relationships between the biological entities of interest.
    Indeed, mapping between gene and protein ID scopes should not be done
    the same way than between two scopes regarding gene ID.
    Also, converting identifiers from different organisms should be possible
    using gene orthologs information.
    A ready to use database is provided as
    a 'Docker' image <https://hub.docker.com/r/patzaw/bed-ucb-human/>.
    The method has been published by
    Godard and van Eyll (2018) <doi:10.12688/f1000research.13925.3>.",2022-04-26,Patrice Godard,https://github.com/patzaw/BED,TRUE,https://github.com/patzaw/bed,7439,8,2022-06-30T14:55:29Z,929.875
beeswarm,"The bee swarm plot is a one-dimensional scatter plot like
    ""stripchart"", but with closely-packed, non-overlapping points. ",2021-06-01,Aron Eklund,https://github.com/aroneklund/beeswarm,TRUE,https://github.com/aroneklund/beeswarm,503845,34,2022-01-11T11:09:28Z,14818.970588235294
belg,"Calculates the Boltzmann entropy of a landscape gradient.
    This package uses the analytical method created by Gao, P., Zhang, H.
    and Li, Z., 2018 (<doi:10.1111/tgis.12315>) and by Gao, P. and Li, Z., 2019
    (<doi:10.1007/s10980-019-00854-3>). It also extend the original ideas by
    allowing calculations on data with missing values.",2022-05-01,Jakub Nowosad,https://r-spatialecology.github.io/belg/,TRUE,https://github.com/r-spatialecology/belg,17132,14,2022-04-29T11:04:25Z,1223.7142857142858
bellreg,Bell regression models for count data with overdispersion. The implemented models account for ordinary and zero-inflated regression models under both frequentist and Bayesian approaches. Theoretical details regarding the models implemented in the package can be found in Castellares et al. (2018) <doi:10.1016/j.apm.2017.12.014> and Lemonte et al. (2020) <doi:10.1080/02664763.2019.1636940>.,2020-06-26,Fabio Demarqui,https://github.com/fndemarqui/bellreg,TRUE,https://github.com/fndemarqui/bellreg,8546,1,2022-05-05T17:38:56Z,8546
bench,"Tools to accurately benchmark and analyze execution times for
    R expressions.",2021-11-30,Davis Vaughan,"https://bench.r-lib.org/, https://github.com/r-lib/bench",TRUE,https://github.com/r-lib/bench,460197,213,2021-11-30T14:16:41Z,2160.549295774648
benchmarkme,"Benchmark your CPU and compare against other CPUs.  Also
    provides functions for obtaining system specifications, such as RAM,
    CPU type, and R version.",2022-06-12,Colin Gillespie,https://github.com/csgillespie/benchmarkme,TRUE,https://github.com/csgillespie/benchmarkme,86425,35,2022-06-15T08:55:35Z,2469.285714285714
berryFunctions,"Draw horizontal histograms, color scattered points by 3rd dimension,
    enhance date- and log-axis plots, zoom in X11 graphics, trace errors and warnings, 
    use the unit hydrograph in a linear storage cascade, convert lists to data.frames and arrays, 
    fit multiple functions.",2022-05-13,Berry Boessenkool,https://github.com/brry/berryFunctions,TRUE,https://github.com/brry/berryfunctions,69711,10,2022-06-07T10:53:31Z,6971.1
BEST,"An alternative to t-tests, producing posterior estimates for group means and standard deviations and their differences and effect sizes. It implements the method of Kruschke (2013) Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2):573-603 <doi: 10.1037/a0029146>.",2021-10-13,Mike Meredith,NA,TRUE,https://github.com/mikemeredith/best,40036,27,2021-10-13T05:15:26Z,1482.8148148148148
bestNormalize,"Estimate a suite of normalizing transformations, including 
    a new adaptation of a technique based on ranks which can guarantee 
    normally distributed transformed data if there are no ties: ordered 
    quantile normalization (ORQ). ORQ normalization combines a rank-mapping
    approach with a shifted logit approximation that allows
    the transformation to work on data outside the original domain. It is 
    also able to handle new data within the original domain via linear 
    interpolation. The package is built to estimate the best normalizing 
    transformation for a vector consistently and accurately. It implements 
    the Box-Cox transformation, the Yeo-Johnson transformation, three types 
    of Lambert WxF transformations, and the ordered quantile normalization 
    transformation. It estimates the normalization efficacy of other
    commonly used transformations, and it allows users to specify 
    custom transformations or normalization statistics. Finally, functionality
    can be integrated into a machine learning workflow via recipes. ",2022-06-13,Ryan Andrew Peterson,"https://petersonr.github.io/bestNormalize/,
https://github.com/petersonR/bestNormalize",TRUE,https://github.com/petersonr/bestnormalize,129417,27,2022-06-14T02:02:09Z,4793.222222222223
bettermc,"Drop-in replacement for 'parallel::mclapply()' adding e.g.
    tracebacks, crash dumps, retries, condition handling, improved seeding,
    progress bars and faster inter process communication. Some of the internal
    functions are also exported for other use: 'etry()' (extended try),
    'copy2shm()/allocate_from_shm()' (copy to and allocate from POSIX shared
    memory), 'char_map/map2char()' (split a character vector into its unique
    elements and a mapping on these) and various semaphore related functions.",2021-08-02,Andreas Kersting,https://github.com/gfkse/bettermc,TRUE,https://github.com/gfkse/bettermc,14063,14,2022-02-16T15:47:22Z,1004.5
bfast,"Decomposition of time series into
    trend, seasonal, and remainder components with methods for detecting and
    characterizing abrupt changes within the trend and seasonal components. 'BFAST'
    can be used to analyze different types of satellite image time series and can
    be applied to other disciplines dealing with seasonal or non-seasonal time
    series, such as hydrology, climatology, and econometrics. The algorithm can be
    extended to label detected changes with information on the parameters of the
    fitted piecewise linear models. 'BFAST' monitoring functionality is described
    in Verbesselt et al. (2010) <doi:10.1016/j.rse.2009.08.014>. 'BFAST monitor'
    provides functionality to detect disturbance in near real-time based on 'BFAST'-
    type models, and is described in Verbesselt et al. (2012) <doi:10.1016/j.rse.2012.02.022>.
    'BFAST Lite' approach is a flexible approach that handles missing data
    without interpolation, and will be described in an upcoming paper.
    Furthermore, different models can now be used to fit the
    time series data and detect structural changes (breaks).",2021-05-10,Dainius Masiliunas,https://bfast2.github.io/,TRUE,https://github.com/bfast2/bfast,43770,24,2021-10-06T15:57:01Z,1823.75
BFpack,"Implementation of various default Bayes factors
    for testing statistical hypotheses. The package is
    intended for applied quantitative researchers in the
    social and behavioral sciences, medical research,
    and related fields. The Bayes factor tests can be
    executed for statistical models such as 
    univariate and multivariate normal linear models,
    generalized linear models, special cases of 
    linear mixed models, survival models, relational
    event models. Parameters that can be tested are
    location parameters (e.g., group means, regression coefficients),
    variances (e.g., group variances), and measures of 
    association (e.g,. bivariate correlations), among others.
    The statistical underpinnings are
    described in 
    Mulder, Hoijtink, and Xin (2019) <arXiv:1904.00679>,
    Mulder and Gelissen (2019) <arXiv:1807.05819>,
    Mulder (2016) <DOI:10.1016/j.jmp.2014.09.004>,
    Mulder and Fox (2019) <DOI:10.1214/18-BA1115>,
    Mulder and Fox (2013) <DOI:10.1007/s11222-011-9295-3>,
    Boeing-Messing, van Assen, Hofman, Hoijtink, and Mulder (2017) <DOI:10.1037/met0000116>,
    Hoijtink, Mulder, van Lissa, and Gu, (2018) <DOI:10.31234/osf.io/v3shc>,
    Gu, Mulder, and Hoijtink, (2018) <DOI:10.1111/bmsp.12110>,
    Hoijtink, Gu, and Mulder, (2018) <DOI:10.1111/bmsp.12145>, and
    Hoijtink, Gu, Mulder, and Rosseel, (2018) <DOI:10.1037/met0000187>. When using the
    packages, please refer to Mulder et al. (2021) <DOI:10.18637/jss.v100.i18>.",2021-11-26,Joris Mulder,https://github.com/jomulder/BFpack,TRUE,https://github.com/jomulder/bfpack,30752,12,2022-05-25T12:39:01Z,2562.6666666666665
bfsl,"How to fit a straight line through a set of points with errors in
  both coordinates? The 'bfsl' package implements the York regression 
  (York, 2004 <doi:10.1119/1.1632486>). It provides unbiased estimates of the 
  intercept, slope and standard errors for the best-fit straight line to 
  independent points with (possibly correlated) normally distributed errors in 
  both x and y. Other commonly used errors-in-variables methods, such as 
  orthogonal distance regression, geometric mean regression or Deming regression
  are special cases of the 'bfsl' solution.",2021-09-23,Patrick Sturm,https://github.com/pasturm/bfsl,TRUE,https://github.com/pasturm/bfsl,14552,1,2021-11-24T07:52:20Z,14552
bfw,"Derived from the work of Kruschke (2015,
    <ISBN:9780124058880>), the present package aims to provide a framework
    for conducting Bayesian analysis using Markov chain Monte Carlo (MCMC)
    sampling utilizing the Just Another Gibbs Sampler ('JAGS', Plummer,
    2003, <https://mcmc-jags.sourceforge.io>).  The initial version
    includes several modules for conducting Bayesian equivalents of
    chi-squared tests, analysis of variance (ANOVA), multiple
    (hierarchical) regression, softmax regression, and for fitting data
    (e.g., structural equation modeling).",2022-02-22,Øystein Olav Skaar,https://github.com/oeysan/bfw/,TRUE,https://github.com/oeysan/bfw,16159,10,2022-02-22T10:50:27Z,1615.9
BGData,"An umbrella package providing a phenotype/genotype data structure
    and scalable and efficient computational methods for large genomic datasets
    in combination with several other packages: 'BEDMatrix', 'LinkedMatrix',
    and 'symDMatrix'.",2021-12-08,Alexander Grueneberg,https://github.com/QuantGen/BGData,TRUE,https://github.com/quantgen/bgdata,20832,25,2021-12-08T14:14:20Z,833.28
bggAnalytics,"Tools for analysing board game data. Mainly focused on providing 
    an interface for BoardGameGeek's XML API2 through R6 class system objects.
    More details about the BoardGameGeek's API can be obtained here
    <https://boardgamegeek.com/wiki/page/BGG_XML_API2>.",2021-09-23,Jakub Bujnowicz,https://github.com/JakubBujnowicz/bggAnalytics,TRUE,https://github.com/jakubbujnowicz/bgganalytics,6686,4,2022-06-27T08:34:30Z,1671.5
BGGM,"Fit Bayesian Gaussian graphical models. The methods are separated into 
    two Bayesian approaches for inference: hypothesis testing and estimation. There are 
    extensions for confirmatory hypothesis testing, comparing Gaussian graphical models, 
    and node wise predictability. These methods were recently introduced in the Gaussian 
    graphical model literature, including 
    Williams (2019) <doi:10.31234/osf.io/x8dpr>, 
    Williams and Mulder (2019) <doi:10.31234/osf.io/ypxd8>,
    Williams, Rast, Pericchi, and Mulder (2019) <doi:10.31234/osf.io/yt386>.",2021-08-20,Donald Williams,NA,TRUE,https://github.com/donaldrwilliams/bggm,29801,46,2021-11-17T01:58:34Z,647.8478260869565
BGVAR,"Estimation of Bayesian Global Vector Autoregressions (BGVAR) with different prior setups and the possibility to introduce stochastic volatility. Built-in priors include the Minnesota, the stochastic search variable selection and Normal-Gamma (NG) prior. For a reference see also Crespo Cuaresma, J., Feldkircher, M. and F. Huber (2016) ""Forecasting with Global Vector Autoregressive Models: a Bayesian Approach"", Journal of Applied Econometrics, Vol. 31(7), pp. 1371-1391 <doi:10.1002/jae.2504>. Post-processing functions allow for doing predictions, structurally identify the model with short-run or sign-restrictions and compute impulse response functions, historical decompositions and forecast error variance decompositions. Plotting functions are also available.",2022-05-02,Maximilian Boeck,https://github.com/mboeck11/BGVAR,TRUE,https://github.com/mboeck11/bgvar,18132,13,2022-05-02T09:14:58Z,1394.7692307692307
BH,"Boost provides free peer-reviewed portable C++ source 
 libraries.  A large part of Boost is provided as C++ template code
 which is resolved entirely at compile-time without linking.  This 
 package aims to provide the most useful subset of Boost libraries 
 for template use among CRAN packages. By placing these libraries in 
 this package, we offer a more efficient distribution system for CRAN 
 as replication of this code in the sources of other packages is 
 avoided. As of release 1.78.0-0, the following Boost libraries are
 included: 'accumulators' 'algorithm' 'align' 'any' 'atomic' 'beast'
 'bimap' 'bind' 'circular_buffer' 'compute' 'concept' 'config'
 'container' 'date_time' 'detail' 'dynamic_bitset' 'exception'
 'flyweight' 'foreach' 'functional' 'fusion' 'geometry' 'graph' 'heap'
 'icl' 'integer' 'interprocess' 'intrusive' 'io' 'iostreams'
 'iterator' 'lambda2' 'math' 'move' 'mp11' 'mpl' 'multiprecision'
 'numeric' 'pending' 'phoenix' 'polygon' 'preprocessor' 'process'
 'propery_tree' 'random' 'range' 'scope_exit' 'smart_ptr' 'sort'
 'spirit' 'tuple' 'type_traits' 'typeof' 'unordered' 'utility' 'uuid'.",2021-12-15,Dirk Eddelbuettel,"https://github.com/eddelbuettel/bh,
https://dirk.eddelbuettel.com/code/bh.html",TRUE,https://github.com/eddelbuettel/bh,13969803,75,2021-12-15T13:34:17Z,186264.04
BiasCorrector,"A GUI to correct measurement bias in DNA methylation
    analyses. The 'BiasCorrector' package just wraps the functions
    implemented in the 'R' package 'rBiasCorrection' into a shiny web
    application in order to make them more easily accessible. Publication:
    Kapsner et al. (2021) <doi:10.1002/ijc.33681>.",2022-06-20,Lorenz A. Kapsner,https://github.com/kapsner/BiasCorrector,TRUE,https://github.com/kapsner/biascorrector,10014,1,2022-06-21T08:29:39Z,10014
biblio,Reading and writing BibTeX files using data frames in R sessions.,2021-12-17,Miguel Alvarez,https://github.com/kamapu/biblio,TRUE,https://github.com/kamapu/biblio,3547,0,2022-06-07T06:20:52Z,NA
bibliometrix,"Tool for quantitative research in scientometrics and bibliometrics.
    It provides various routines for importing bibliographic data from 'SCOPUS',
    'Clarivate Analytics Web of Science' (<https://www.webofknowledge.com/>), 'Digital Science Dimensions' 
	(<https://www.dimensions.ai/>), 'Cochrane Library' (<https://www.cochranelibrary.com/>), 'Lens' (<https://lens.org>), 
	and 'PubMed' (<https://pubmed.ncbi.nlm.nih.gov/>) databases, performing bibliometric analysis 
    and building networks for co-citation, coupling, scientific collaboration and co-word analysis.",2022-06-15,Massimo Aria,"https://www.bibliometrix.org,
https://github.com/massimoaria/bibliometrix,
https://www.k-synth.com",TRUE,https://github.com/massimoaria/bibliometrix,216190,309,2022-07-04T10:30:29Z,699.6440129449838
bibtex,Utility to parse a bibtex file. ,2020-09-19,Romain Francois,https://github.com/romainfrancois/bibtex,TRUE,https://github.com/romainfrancois/bibtex,817440,30,2022-01-13T17:32:44Z,27248
BiCausality,"A framework to infer causality on binary data using techniques in frequent pattern mining and estimation statistics. Given a set of individual vectors S={x} where x(i) is a realization value of binary variable i, the framework infers empirical causal relations of binary variables i,j from S in a form of causal graph G=(V,E) where V is a set of nodes representing binary variables and there is an edge from i to j in E if the variable i causes j. The framework determines dependency among variables as well as analyzing confounding factors before deciding whether i causes j.  The publication of this package is at <arXiv:2205.06131>.",2022-05-26,Chainarong Amornbunchornvej,https://github.com/DarkEyes/BiCausality,TRUE,https://github.com/darkeyes/bicausality,386,2,2022-05-26T03:53:20Z,193
bidask,"Implements an efficient estimation procedure of bid-ask spreads from open, high, low, and close prices
  as described in Ardia-Guidotti-Kroencke <https://www.ssrn.com/abstract=3892335>. 
  Moreover, it provides an implementation of the estimators proposed in 
  Roll (1984) <doi:10.1111/j.1540-6261.1984.tb03897.x>, 
  Corwin-Schultz (2012) <doi:10.1111/j.1540-6261.2012.01729.x>,
  and Abdi-Ranaldo (2017) <doi:10.1093/rfs/hhx084>.",2022-05-10,Emanuele Guidotti,https://github.com/eguidotti/bidask,TRUE,https://github.com/eguidotti/bidask,5759,37,2022-06-29T21:47:06Z,155.64864864864865
BiDimRegression,Calculates the bidimensional regression between two 2D configurations following the approach by Tobler (1965).,2022-02-17,Claus-Christian Carbon,"https://CRAN.R-project.org/package=BiDimRegression/,
https://github.com/alexander-pastukhov/bidim-regression/,
https://alexander-pastukhov.github.io/bidim-regression/",TRUE,https://github.com/alexander-pastukhov/bidim-regression,18339,0,2022-02-17T12:04:48Z,NA
BifactorIndicesCalculator,"The calculator computes bifactor indices such as explained common variance (ECV), hierarchical Omega (OmegaH), percentage of uncontaminated correlations (PUC), item explained common variance (I-ECV), and more. This package is an R version of the 'Excel' based 'Bifactor Indices Calculator' (Dueber, 2017)  <doi:10.13023/edp.tool.01> with added convenience features for directly utilizing output from several programs that can fit confirmatory factor analysis or item response models.",2021-05-12,David Dueber,https://github.com/ddueber/BifactorIndicesCalculator,TRUE,https://github.com/ddueber/bifactorindicescalculator,13961,5,2022-01-19T17:24:44Z,2792.2
BIFIEsurvey,"
    Contains tools for survey statistics (especially in educational
    assessment) for datasets with replication designs (jackknife, 
    bootstrap, replicate weights; see Kolenikov, 2010;
    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,
    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, 
    <doi:10.1080/02331889708802523>). 
    Descriptive statistics, linear and logistic regression, 
    path models for manifest variables with measurement error 
    correction and two-level hierarchical regressions for weighted 
    samples are included. Statistical inference can be conducted for 
    multiply imputed datasets and nested multiply imputed datasets
    and is in particularly suited for the analysis of plausible values
    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; 
    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &
    Yanagida, 2016). The package development was supported by BIFIE 
    (Federal Institute for Educational Research, Innovation and Development 
    of the Austrian School System; Salzburg, Austria).",2022-04-04,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/BIFIEsurvey,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/bifiesurvey,73952,3,2022-04-05T10:15:01Z,24650.666666666668
bigalgebra,"Provides arithmetic functions for R matrix and 'big.matrix' objects as well as functions for QR factorization, Cholesky factorization, General eigenvalue, and Singular value decomposition (SVD). A method matrix multiplication and an arithmetic method -for matrix addition, matrix difference- allows for mixed type operation -a matrix class object and a big.matrix class object- and pure type operation for two big.matrix class objects.",2022-04-08,Frederic Bertrand,"https://fbertran.github.io/bigalgebra/,
https://github.com/fbertran/bigalgebra/",TRUE,https://github.com/fbertran/bigalgebra,10934,3,2022-04-28T06:21:45Z,3644.6666666666665
BIGDAWG,"Data sets and functions for chi-squared Hardy-Weinberg and case-control association tests of highly polymorphic genetic data [e.g., human leukocyte antigen (HLA) data]. Performs association tests at multiple levels of polymorphism (haplotype, locus and HLA amino-acids) as described in Pappas DJ, Marin W, Hollenbach JA, Mack SJ (2016) <doi:10.1016/j.humimm.2015.12.006>. Combines rare variants to a common class to account for sparse cells in tables as described by Hollenbach JA, Mack SJ, Thomson G, Gourraud PA (2012) <doi:10.1007/978-1-61779-842-9_14>.",2021-11-17,Derek Pappas,"http://tools.immunogenomics.org/,
https://github.com/IgDAWG/BIGDAWG",TRUE,https://github.com/igdawg/bigdawg,22634,0,2021-11-16T18:12:47Z,NA
bigDM,"Implements several spatial and spatio-temporal scalable disease mapping models for high-dimensional count data using the INLA technique for approximate Bayesian inference in latent Gaussian models (Orozco-Acosta et al., 2021 <doi:10.1016/j.spasta.2021.100496> and Orozco-Acosta et al., 2022 <arXiv:2201.08323>). The creation and develpment of this package has been supported by Project MTM2017-82553-R (AEI/FEDER, UE) and Project PID2020-113125RB-I00/MCIN/AEI/10.13039/501100011033. It has also been partially funded by the Public University of Navarra (project PJUPNA2001).",2022-06-27,Aritz Adin,https://github.com/spatialstatisticsupna/bigDM,TRUE,https://github.com/spatialstatisticsupna/bigdm,1608,6,2022-06-27T08:36:20Z,268
BIGL,"Response surface methods for drug synergy analysis. Available
    methods include generalized and classical Loewe formulations as well as Highest
    Single Agent methodology. Response surfaces can be plotted in an interactive
    3-D plot and formal statistical tests for presence of synergistic effects are
    available. Implemented methods and tests are described in the article 
    ""BIGL: Biochemically Intuitive Generalized Loewe null model for prediction 
    of the expected combined effect compatible with partial agonism and antagonism""
    by Koen Van der Borght, Annelies Tourny, Rytis Bagdziunas, Olivier Thas, 
    Maxim Nazarov, Heather Turner, Bie Verbist & Hugo Ceulemans (2017) 
    <doi:10.1038/s41598-017-18068-5>.",2022-05-05,Heather Turner,https://github.com/openanalytics/BIGL,TRUE,https://github.com/openanalytics/bigl,26144,7,2021-10-26T15:51:02Z,3734.8571428571427
biglasso,"Extend lasso and elastic-net model fitting for ultrahigh-dimensional, 
    multi-gigabyte data sets that cannot be loaded into memory. It's much more 
    memory- and computation-efficient as compared to existing lasso-fitting packages 
    like 'glmnet' and 'ncvreg', thus allowing for very powerful big data analysis 
    even with an ordinary laptop.",2022-03-09,Yaohui Zeng,"https://github.com/YaohuiZeng/biglasso,
https://arxiv.org/abs/1701.05936",TRUE,https://github.com/yaohuizeng/biglasso,72260,99,2022-03-04T23:00:38Z,729.89898989899
bigmds,"MDS is a statistic tool for reduction of dimensionality, using as input a distance
    matrix of dimensions n × n. When n is large, classical algorithms suffer from
    computational problems and MDS configuration can not be obtained.
    With this package, we address these problems by means of three algorithms:
        - Divide-and-conquer MDS proposed by Delicado P. and C. Pachón-García (2021)
        <arXiv:2007.11919>.
        - Interpolation MDS, also proposed by Delicado P. and C. Pachón-García (2021)
        <arXiv:2007.11919>, which uses Gower's interpolation formula as described in
        Gower, J. C. and D. J. Hand (1995).
        - Fast MDS, which is an implementation of the algorithm proposed by 
        Yang, T., J. Liu, L. McMillan, and W. Wang (2006).
    The main idea of these algorithms is based on partitioning the data set into small 
    pieces, where classical methods can work. In order to align all the solutions, 
    Procrustes formula is used as described in Borg, I. and P. Groenen (2005).",2021-10-05,Cristian Pachón García,https://github.com/pachoning/bigmds,TRUE,https://github.com/pachoning/bigmds,7477,7,2021-10-04T15:23:48Z,1068.142857142857
bigmemory,"Create, store, access, and manipulate massive matrices.
    Matrices are allocated to shared memory and may use memory-mapped
    files.  Packages 'biganalytics', 'bigtabulate', 'synchronicity', and
    'bigalgebra' provide advanced functionality.",2022-05-02,Michael J. Kane,https://github.com/kaneplusplus/bigmemory,TRUE,https://github.com/kaneplusplus/bigmemory,435208,113,2022-05-02T14:48:10Z,3851.3982300884954
bignum,"Classes for storing and manipulating arbitrary-precision
    integer vectors and high-precision floating-point vectors. These
    extend the range and precision of the 'integer' and 'double' data
    types found in R. This package utilizes the 'Boost.Multiprecision' C++
    library. It is specifically designed to work well with the 'tidyverse'
    collection of R packages.",2021-10-15,David Hall,"https://davidchall.github.io/bignum/,
https://github.com/davidchall/bignum",TRUE,https://github.com/davidchall/bignum,6675,10,2021-11-16T20:04:40Z,667.5
bigparallelr,"Utility functions for easy parallelism in R. Include some reexports
    from other packages, utility functions for splitting and parallelizing over
    blocks, and choosing and setting the number of cores used.",2021-10-02,Florian Privé,https://github.com/privefl/bigparallelr,TRUE,https://github.com/privefl/bigparallelr,85554,3,2021-10-02T07:56:25Z,28518
bigQF,"A computationally-efficient leading-eigenvalue approximation to tail probabilities and quantiles of large quadratic forms, in particular for the Sequence Kernel Association Test (SKAT) used in genomics <doi:10.1002/gepi.22136>. Also provides stochastic singular value decomposition for dense or sparse matrices.",2021-11-23,Thomas Lumley,https://github.com/tslumley/bigQF,TRUE,https://github.com/tslumley/bigqf,2736,7,2021-11-23T02:38:57Z,390.85714285714283
bigrquery,Easily talk to Google's 'BigQuery' database from R.,2021-08-05,Hadley Wickham,"https://bigrquery.r-dbi.org, https://github.com/r-dbi/bigrquery",TRUE,https://github.com/r-dbi/bigrquery,297214,475,2021-09-28T16:01:24Z,625.7136842105264
bigsnpr,"Easy-to-use, efficient, flexible and scalable tools for analyzing 
    massive SNP arrays. Privé et al. (2018) <doi:10.1093/bioinformatics/bty185>.",2022-07-09,Florian Privé,https://privefl.github.io/bigsnpr/,TRUE,https://github.com/privefl/bigsnpr,26119,127,2022-07-09T08:35:07Z,205.66141732283464
bigsparser,"Provide a sparse matrix format with data stored on disk, to be
    used in both R and C++. This is intended for more efficient use of sparse 
    data in C++ and also when parallelizing, since data on disk does not need
    copying. Only a limited number of features will be implemented. For now,
    conversion can be performed from a 'dgCMatrix' or a 'dsCMatrix' from R 
    package 'Matrix'. A new compact format is also now available.",2022-06-07,Florian Privé,https://github.com/privefl/bigsparser,TRUE,https://github.com/privefl/bigsparser,24800,8,2022-06-01T07:23:05Z,3100
bigstatsr,"Easy-to-use, efficient, flexible and scalable statistical tools.
  Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping.
  It provides for instance matrix operations, Principal Component Analysis,
  sparse linear supervised models, utility functions and more
  <doi:10.1093/bioinformatics/bty185>.",2022-02-03,Florian Privé,https://privefl.github.io/bigstatsr/,TRUE,https://github.com/privefl/bigstatsr,70288,153,2022-04-12T12:47:23Z,459.39869281045753
bigtime,"Estimation of large Vector AutoRegressive (VAR), Vector AutoRegressive with Exogenous Variables X (VARX) and Vector AutoRegressive Moving Average (VARMA) Models with Structured Lasso Penalties, see Nicholson, Wilms, Bien and Matteson (2020) <https://jmlr.org/papers/v21/19-777.html> and Wilms, Basu, Bien and Matteson (2021) <doi:10.1080/01621459.2021.1942013>.",2021-08-09,Ines Wilms,https://github.com/ineswilms/bigtime,TRUE,https://github.com/ineswilms/bigtime,21847,22,2022-01-27T14:11:04Z,993.0454545454545
BigVAR,Estimates VAR and VARX models with Structured Penalties using the methods developed by Nicholson et al (2017)<doi:10.1016/j.ijforecast.2017.01.003> and Nicholson et al (2020) <doi:10.48550/arXiv.1412.5250>.,2022-03-22,Will Nicholson,https://github.com/wbnicholson/BigVAR,TRUE,https://github.com/wbnicholson/bigvar,25147,48,2022-06-17T01:39:04Z,523.8958333333334
billboarder,"Provides an 'htmlwidgets' interface to 'billboard.js', 
    a re-usable easy interface JavaScript chart library, based on D3 v4+.
    Chart types include line charts, scatterplots, bar/lollipop charts, histogram/density plots, pie/donut charts and gauge charts.
    All charts are interactive, and a proxy method is implemented to smoothly update a chart without rendering it again in 'shiny' apps. ",2021-03-27,Victor Perrier,https://github.com/dreamRs/billboarder,TRUE,https://github.com/dreamrs/billboarder,112329,167,2022-03-31T08:03:24Z,672.6287425149701
bimets,"Time series analysis, (dis)aggregation and manipulation, e.g. time series extension, merge, projection, lag, lead, delta, moving and cumulative average and product, selection by index, date and year-period, conversion to daily, monthly, quarterly, (semi)annually. Simultaneous equation models definition, estimation, simulation and forecasting with coefficient restrictions, error autocorrelation, exogenization, add-factors, impact and interim multipliers analysis, conditional equation evaluation, endogenous targeting and model renormalization, structural stability, stochastic simulation and forecast, optimal control.",2022-06-15,Andrea Luciani,https://github.com/andrea-luciani/bimets,TRUE,https://github.com/andrea-luciani/bimets,28600,3,2022-06-15T15:31:13Z,9533.333333333334
binb,"A collection of 'LaTeX' styles using 'Beamer' customization for
 pdf-based presentation slides in 'RMarkdown'. At present it contains
 'RMarkdown' adaptations of the LaTeX themes 'Metropolis' (formerly 'mtheme')
 theme by Matthias Vogelgesang and others (now included in 'TeXLive'), the
 'IQSS' by Ista Zahn (which is included here), and the 'Monash' theme by
 Rob J Hyndman. Additional (free) fonts may be needed: 'Metropolis' prefers
 'Fira', and 'IQSS' requires 'Libertinus'.",2020-06-10,Dirk Eddelbuettel,https://github.com/eddelbuettel/binb,TRUE,https://github.com/eddelbuettel/binb,20132,184,2021-11-06T00:06:40Z,109.41304347826087
binman,"Tools and functions for managing the download of binary files.
    Binary repositories are defined in 'YAML' format. Defining new 
    pre-download, download and post-download templates allow additional 
    repositories to be added.",2020-10-02,John Harrison,"https://docs.ropensci.org/binman/,
https://github.com/ropensci/binman",TRUE,https://github.com/ropensci/binman,150961,13,2022-02-17T22:33:32Z,11612.384615384615
binsegRcpp,"Standard template library 
 containers are used to implement an efficient binary segmentation
 algorithm, which is log-linear on average and quadratic in the
 worst case.",2022-01-26,Toby Dylan Hocking,https://github.com/tdhock/binsegRcpp,TRUE,https://github.com/tdhock/binsegrcpp,8848,4,2022-05-12T20:54:08Z,2212
bioacoustics,"Contains all the necessary tools to process audio recordings of
             various formats (e.g., WAV, WAC, MP3, ZC), filter noisy files, 
             display audio signals, detect and extract automatically acoustic
             features for further analysis such as classification.",2022-02-08,Jean Marchal,https://github.com/wavx/bioacoustics/,TRUE,https://github.com/wavx/bioacoustics,27335,37,2022-02-08T14:49:59Z,738.7837837837837
BiocManager,A convenient tool to install and update Bioconductor packages.,2022-05-18,Martin Morgan,NA,TRUE,https://github.com/bioconductor/biocmanager,4105626,56,2022-05-18T20:19:42Z,73314.75
biocompute,"Tools to create, validate, and export BioCompute Objects
    described in King et al. (2019) <doi:10.17605/osf.io/h59uh>.
    Users can encode information in data frames, and compose
    BioCompute Objects from the domains defined by the standard.
    A checksum validator and a JSON schema validator are provided.
    This package also supports exporting BioCompute Objects as JSON,
    PDF, HTML, or 'Word' documents, and exporting to cloud-based platforms.",2022-05-03,Soner Koc,"https://sbg.github.io/biocompute/,
https://github.com/sbg/biocompute",TRUE,https://github.com/sbg/biocompute,16401,3,2022-03-29T18:11:06Z,5467
biodosetools,"A tool to perform all different statistical tests and calculations 
    needed by Biological Dosimetry Laboratories.",2022-01-27,Alfredo Hernández,"https://biodosetools-team.github.io/biodosetools/,
https://github.com/biodosetools-team/biodosetools/",TRUE,https://github.com/biodosetools-team/biodosetools,1829,2,2022-06-15T20:50:25Z,914.5
biogram,"Tools for extraction and analysis of various
    n-grams (k-mers) derived from biological sequences (proteins
    or nucleic acids). Contains QuiPT (quick permutation test) for fast
    feature-filtering of the n-gram data.",2020-03-31,Michal Burdukiewicz,https://github.com/michbur/biogram,TRUE,https://github.com/michbur/biogram,22138,8,2022-04-13T14:58:00Z,2767.25
bioimagetools,"Tools for 3D imaging, mostly for biology/microscopy. 
    Read and write TIFF stacks. Functions for segmentation, filtering and analyzing 3D point patterns.",2022-05-28,Volker Schmid,https://bioimaginggroup.github.io/bioimagetools/,TRUE,https://github.com/bioimaginggroup/bioimagetools,21339,3,2022-05-28T10:43:16Z,7113
biokNN,"The bi-objective k-nearest neighbors method (biokNN) is an imputation method designed to estimate missing values on data with a multilevel structure. The original algorithm is an extension of the k-nearest neighbors method proposed by Bertsimas et al. (2017) (<https://jmlr.org/papers/v18/17-073.html>) using a bi-objective approach.  A brief description of the method can be found in Cubillos (2021) (<https://pure.au.dk/portal/files/214627979/biokNN.pdf>). The 'biokNN' package provides an R implementation of the method for datasets with continuous variables (e.g. employee productivity, student grades) and a categorical class variable (e.g. department, school). Given an incomplete dataset with such structure, this package produces complete datasets using both single and multiple imputation, including visualization tools to better understand the pattern of the missing values. ",2021-04-22,Maximiliano Cubillos,https://github.com/mcubillos3/biokNN,TRUE,https://github.com/mcubillos3/bioknn,5281,0,2021-12-03T11:25:02Z,NA
biomartr,"Perform large scale genomic data retrieval and functional annotation retrieval. This package aims to provide users with a standardized
                way to automate genome, proteome, 'RNA', coding sequence ('CDS'), 'GFF', and metagenome
                retrieval from 'NCBI RefSeq', 'NCBI Genbank', 'ENSEMBL', 
                and 'UniProt' databases. Furthermore, an interface to the 'BioMart' database
                (Smedley et al. (2009) <doi:10.1186/1471-2164-10-22>) allows users to retrieve
                functional annotation for genomic loci. In addition, users can download entire databases such
                as 'NCBI RefSeq' (Pruitt et al. (2007) <doi:10.1093/nar/gkl842>), 'NCBI nr',
                'NCBI nt', 'NCBI Genbank' (Benson et al. (2013) <doi:10.1093/nar/gks1195>), etc. with only one command.",2022-02-23,Hajk-Georg Drost,"https://docs.ropensci.org/biomartr/,
https://github.com/ropensci/biomartr",TRUE,https://github.com/ropensci/biomartr,46711,162,2022-04-30T15:32:55Z,288.3395061728395
BIOMASS,"Contains functions to estimate aboveground biomass/carbon and its uncertainty in tropical forests. 
	These functions allow to (1) retrieve and to correct taxonomy, (2) estimate wood density and its uncertainty, 
	(3) construct height-diameter models, (4) manage tree and plot coordinates, 
	(5) estimate the aboveground biomass/carbon at the stand level with associated uncertainty. 
	To cite 'BIOMASS', please use citation(""BIOMASS""). 
	See more in the article of Réjou-Méchain et al. (2017) <https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12753>.",2022-04-07,Maxime Réjou-Méchain,https://github.com/umr-amap/BIOMASS,TRUE,https://github.com/umr-amap/biomass,26821,15,2022-04-04T13:03:54Z,1788.0666666666666
biometryassist,"Provides functions to aid in the design and analysis of
    agronomic and agricultural experiments through easy access to
    documentation and helper functions, especially for users who are
    learning these concepts.",2022-04-14,Sam Rogers,https://biometryhub.github.io/biometryassist/,TRUE,https://github.com/biometryhub/biometryassist,2257,1,2022-04-14T23:14:24Z,2257
bioRad,"Extract, visualize and summarize aerial movements of birds and
    insects from weather radar data. See <doi:10.1111/ecog.04028>
    for a software paper describing package and methodologies.",2022-05-09,Adriaan M. Dokter,"https://github.com/adokter/bioRad/,
https://adriaandokter.com/bioRad/",TRUE,https://github.com/adokter/biorad,15317,19,2022-05-09T19:47:35Z,806.1578947368421
BioRssay,A robust framework for analyzing mortality data from bioassays for one or several strains/lines/populations.,2022-05-26,Piyal Karunarathne,https://milesilab.github.io/BioRssay/,TRUE,https://github.com/milesilab/biorssay,331,1,2022-06-28T13:15:01Z,331
bioseq,"Classes and functions to work with biological sequences (DNA, RNA and amino acid sequences).
    Implements S3 infrastructure to work with biological sequences as described in Keck (2020) <doi:10.1111/2041-210X.13490>.
    Provides a collection of functions to perform biological conversion among classes
    (transcription, translation) and basic operations on sequences
    (detection, selection and replacement based on positions or patterns).
    The package also provides functions to import and export sequences from and to other package formats.",2021-09-03,Francois Keck,https://fkeck.github.io/bioseq/,TRUE,https://github.com/fkeck/bioseq,12118,16,2021-10-01T14:38:34Z,757.375
biosurvey,"A collection of tools that allows users to plan systems of sampling 
    sites, increasing the efficiency of biodiversity monitoring by considering  
    the relationship between environmental and geographic conditions in a  
    region. The options for selecting sampling sites included here differ from 
    other implementations in that they consider the environmental and geographic 
    conditions of a region to suggest sampling sites that could increase the 
    efficiency of efforts dedicated to monitoring biodiversity. The methods 
    proposed here are new in the sense that they combine various criteria and 
    points previously made in related literature; some of the theoretical and 
    methodological bases considered are described in:
    Arita et al. (2011) <doi:10.1111/j.1466-8238.2011.00662.x>,
    Soberón and Cavner (2015) <doi:10.17161/bi.v10i0.4801>, and Soberón et al. 
    (2021).",2021-09-15,Claudia Nuñez-Penichet,https://github.com/claununez/biosurvey,TRUE,https://github.com/claununez/biosurvey,3614,5,2021-09-15T15:48:07Z,722.8
biotic,"Calculates a range of UK freshwater invertebrate biotic indices
    including BMWP, Whalley, WHPT, Habitat-specific BMWP, AWIC, LIFE and PSI.",2016-04-20,Dr Rob Briers,https://github.com/robbriers/biotic,TRUE,https://github.com/robbriers/biotic,17212,0,2022-04-18T14:10:03Z,NA
biotools,"Tools designed to perform and evaluate cluster analysis (including Tocher's algorithm), 
	discriminant analysis and path analysis (standard and under collinearity), as well as some 
	useful miscellaneous tools for dealing with sample size and optimum plot size calculations. 
	A test for seed sample heterogeneity is now available. Mantel's permutation test can be found in this package. 
	A new approach for calculating its power is implemented. biotools also contains tests for genetic covariance components.
	Heuristic approaches for performing non-parametric spatial predictions of generic response variables and 
	spatial gene diversity are implemented.",2021-08-07,Anderson Rodrigo da Silva,https://arsilva87.github.io/biotools/,TRUE,https://github.com/arsilva87/biotools,67731,0,2021-10-15T12:29:20Z,NA
bipartite,"Functions to visualise webs and calculate a series of indices commonly used to describe pattern in (ecological) webs. It focuses on webs consisting of only two levels (bipartite), e.g. pollination webs or predator-prey-webs. Visualisation is important to get an idea of what we are actually looking at, while the indices summarise different aspects of the web's topology. ",2022-04-20,Carsten F. Dormann,https://github.com/biometry/bipartite,TRUE,https://github.com/biometry/bipartite,84793,26,2022-06-24T08:50:11Z,3261.269230769231
BiplotML,"Logistic Biplot is a method that allows representing multivariate binary data on a subspace of low dimension, where each individual is represented by a point and each variable as vectors directed through the origin. The orthogonal projection of individuals onto these vectors predicts the expected probability that the characteristic occurs. The package contains new techniques to estimate the model parameters and constructs in each case the 'Logistic-Biplot'. References can be found in the help of each procedure.",2022-04-22,Jose Giovany Babativa-Marquez,https://github.com/jgbabativam/BiplotML,TRUE,https://github.com/jgbabativam/biplotml,3622,0,2022-06-09T18:04:54Z,NA
biscale,"Provides a 'ggplot2' centric approach to bivariate mapping. This is a 
    technique that maps two quantities simultaneously rather than the single value 
    that most thematic maps display. The package provides a suite of tools 
    for calculating breaks using multiple different approaches, a selection of 
    palettes appropriate for bivariate mapping and scale functions for 'ggplot2' 
    calls that adds those palettes to maps. Tools for creating bivariate legends 
    are also included.",2022-05-27,Christopher Prener,https://chris-prener.github.io/biscale/,TRUE,https://github.com/chris-prener/biscale,19835,100,2022-06-02T21:02:46Z,198.35
BISdata,"Functions for downloading data from the Bank for
     International Settlements (BIS; <https://www.bis.org/>) in
     Basel.  Supported are only full datasets in (typically) CSV
     format.  The package is lightweight and without dependencies;
     suggested packages are used only if data is to be transformed
     into particular data structures, for instance into 'zoo'
     objects. Downloaded data can optionally be cached, to avoid
     repeated downloads of the same files.",2022-03-09,Enrico Schumann,"http://enricoschumann.net/R/packages/BISdata/,
https://github.com/enricoschumann/BISdata",TRUE,https://github.com/enricoschumann/bisdata,1209,0,2022-06-20T15:01:50Z,NA
bistablehistory,"Estimates cumulative history for time-series for continuously
    viewed bistable perceptual rivalry displays. Computes cumulative history
    via a homogeneous first order differential process. I.e., it assumes
    exponential growth/decay of the history as a function time and perceptually
    dominant state, Pastukhov & Braun (2011) <doi:10.1167/11.10.12>.
    Supports Gamma, log normal, and normal distribution families.
    Provides a method to compute history directly and example of using the
    computation on a custom Stan code.",2022-03-22,Alexander Pastukhov,"https://github.com/alexander-pastukhov/bistablehistory/,
https://alexander-pastukhov.github.io/bistablehistory/",TRUE,https://github.com/alexander-pastukhov/bistablehistory,4244,0,2022-03-22T12:55:34Z,NA
bittermelon,Provides functions for creating and modifying bitmaps with special emphasis on bitmap fonts and their glyphs.  Provides native read/write support for the 'hex' and 'yaff' bitmap font formats and if 'Python' is installed can also read/write several more bitmap font formats using an embedded version of 'monobit'.,2021-11-01,Trevor L Davis,https://trevorldavis.com/R/bittermelon/,TRUE,https://github.com/trevorld/bittermelon,3972,3,2021-12-02T05:51:01Z,1324
bizdays,"Business days calculations based on a list of holidays and
    nonworking weekdays. Quite useful for fixed income and derivatives pricing.",2022-06-22,Wilson Freitas,https://github.com/wilsonfreitas/R-bizdays,TRUE,https://github.com/wilsonfreitas/r-bizdays,550454,42,2022-06-20T17:47:01Z,13106.047619047618
bizicount,"Maximum likelihood estimation of copula-based zero-inflated 
    (and non-inflated) Poisson and negative binomial count models. Supports Frank 
    and Gaussian copulas. Allows for mixed margins (e.g., one margin Poisson, the 
    other zero-inflated negative binomial), and several marginal link functions. 
    Built-in methods for publication-quality tables using 'texreg', and post-estimation 
    diagnostics using 'DHARMa'. For information on copula regression for count data, 
    see Genest and Nešlehová (2007) <doi:10.1017/S0515036100014963> as well as 
    Nikoloulopoulos (2013) <doi:10.1007/978-3-642-35407-6_11>. For information on zero-inflated
    count regression generally, see Lambert (1992) <https:www.jstor.org/stable/1269547?origin=crossref>. The author 
    acknowledges support by NSF DMS-1925119 and DMS-212324.",2022-07-03,John Niehaus,https://github.com/jmniehaus/bizicount,TRUE,https://github.com/jmniehaus/bizicount,1145,0,2022-07-04T17:13:41Z,NA
bkmr,"Implementation of a statistical approach 
  for estimating the joint health effects of multiple 
  concurrent exposures, as described in Bobb et al (2015) 
  <doi:10.1093/biostatistics/kxu058>.",2022-03-28,Jennifer F. Bobb,https://github.com/jenfb/bkmr,TRUE,https://github.com/jenfb/bkmr,25592,25,2022-03-25T03:10:53Z,1023.68
BlanketStatsments,Build and compare nested statistical models with sets of equal and different independent variables. An analysis using this package is Marquardt et al. (2021) <https://github.com/p-mq/Percentile_based_averaging>.,2021-08-02,J. Peter Marquardt,https://github.com/p-mq/BlanketStatsments,TRUE,https://github.com/p-mq/blanketstatsments,3669,1,2021-07-29T15:59:09Z,3669
blaster,"Implementation of an efficient BLAST-like sequence
             comparison algorithm, written in C++11 and using
             native R datatypes. Blaster is based on 'nsearch' -
             Schmid et al 2018; <doi:10.1101/399782>.",2021-10-27,Manu Tamminen,https://github.com/manutamminen/blaster,TRUE,https://github.com/manutamminen/blaster,7100,9,2021-12-30T14:11:03Z,788.8888888888889
bliss,"A method for the Bayesian functional linear regression model (scalar-on-function),
  including two estimators of the coefficient function and an estimator of its support.
  A representation of the posterior distribution is also available. Grollemund P-M., Abraham C., 
  Baragatti M., Pudlo P. (2019) <doi:10.1214/18-BA1095>.",2022-02-16,Paul-Marie Grollemund,https://github.com/pmgrollemund/bliss,TRUE,https://github.com/pmgrollemund/bliss,8132,2,2022-04-11T07:05:56Z,4066
blob,"R's raw vector is useful for storing a single binary object.
    What if you want to put a vector of them in a data frame? The 'blob'
    package provides the blob object, a list of raw vectors, suitable for
    use as a column in data frame.",2022-04-10,Kirill Müller,"https://blob.tidyverse.org, https://github.com/tidyverse/blob",TRUE,https://github.com/tidyverse/blob,9523838,39,2022-05-14T02:31:36Z,244200.97435897434
blockCV,"Creating spatially or environmentally separated folds for cross-validation to provide a robust error estimation in spatially structured environments; Investigating and visualising the effective range of spatial autocorrelation in continuous raster covariates to find an initial realistic distance band to separate training and testing datasets spatially described in Valavi, R. et al. (2019) <doi:10.1111/2041-210X.13107>.",2021-06-17,Roozbeh Valavi,https://github.com/rvalavi/blockCV,TRUE,https://github.com/rvalavi/blockcv,30519,77,2022-01-26T11:16:47Z,396.35064935064935
blocklength,"A set of functions to select the optimal block-length for a 
    dependent bootstrap (block-bootstrap). Includes the Hall, Horowitz, and Jing
    (1995) <doi:10.1093/biomet/82.3.561> cross-validation method and the 
    Politis and White (2004) <doi:10.1081/ETC-120028836> Spectral Density 
    Plug-in method, including the Patton, Politis, and White (2009)
    <doi:10.1080/07474930802459016> correction with a corresponding set of S3
    plot methods.",2022-03-02,Alec Stashevsky,"https://alecstashevsky.com/r/blocklength,
https://github.com/Alec-Stashevsky/blocklength",TRUE,https://github.com/alec-stashevsky/blocklength,8363,3,2022-03-03T20:21:11Z,2787.6666666666665
blogdown,"Write blog posts and web pages in R Markdown. This package
    supports the static site generator 'Hugo' (<https://gohugo.io>) best,
    and it also supports 'Jekyll' (<https://jekyllrb.com>) and 'Hexo'
    (<https://hexo.io>).",2022-05-10,Yihui Xie,"https://github.com/rstudio/blogdown,
https://pkgs.rstudio.com/blogdown/",TRUE,https://github.com/rstudio/blogdown,251576,1525,2022-07-08T18:33:53Z,164.96786885245902
blsR,"Implements v2 of the B.L.S. API for requests of survey information
  and time series data through 3-tiered API that allows users to interact with
  the raw API directly, create queries through a functional interface, and
  re-shape the data structures returned to fit common uses. The API definition 
  is located at: <https://www.bls.gov/developers/api_signature_v2.htm>.",2022-04-11,Guillermo Roditi Dominguez,https://github.com/groditi/blsR,TRUE,https://github.com/groditi/blsr,6523,5,2022-04-18T00:59:30Z,1304.6
BMA,"Package for Bayesian model averaging and variable selection for linear models,
        generalized linear models and survival models (cox
        regression).",2022-04-22,Adrian Raftery,"http://stats.research.att.com/volinsky/bma.html,
https://github.com/hanase/BMA",TRUE,https://github.com/hanase/bma,209581,16,2022-04-22T21:28:45Z,13098.8125
bmabasket,"An implementation of the Bayesian model averaging method 
    of Psioda and others (2019) <doi:10.1093/biostatistics/kxz014> for basket trials. 
    Contains a user-friendly wrapper for simulating basket trials under conditions 
    and analyzing them with a Bayesian model averaging approach.",2022-02-24,Matt Psioda,https://github.com/ethan-alt/bmabasket,TRUE,https://github.com/ethan-alt/bmabasket,6974,0,2022-02-24T17:21:02Z,NA
bmgarch,"Fit Bayesian multivariate GARCH models using 'Stan' for full Bayesian inference. Generate (weighted) forecasts for means, variances (volatility) and correlations. Currently DCC(P,Q), CCC(P,Q), pdBEKK(P,Q), and BEKK(P,Q) parameterizations are implemented, based either on a multivariate gaussian normal or student-t distribution. DCC and CCC models are based on Engle (2002) <doi:10.1198/073500102288618487> and Bollerslev (1990). The BEKK parameterization follows Engle and Kroner (1995) <doi:10.1017/S0266466600009063> while the pdBEKK as well as the estimation approach for this package is described in Rast et al. (2020) <doi:10.31234/osf.io/j57pk>. The fitted models contain 'rstan' objects and can be examined with 'rstan' functions.  ",2021-12-14,Philippe Rast,NA,TRUE,https://github.com/ph-rast/bmgarch,9844,11,2021-12-13T19:25:55Z,894.9090909090909
bmggum,"Full Bayesian estimation of Multidimensional Generalized Graded Unfolding Model (MGGUM) using 'rstan' (See Stan Development Team (2020) <https://mc-stan.org/>).
    Functions are provided for estimation, result extraction, model fit statistics, and plottings.",2021-04-09,Naidan Tu,https://github.com/Naidantu/bmggum,TRUE,https://github.com/naidantu/bmggum,5272,4,2021-12-18T07:33:26Z,1318
bmlm,Easy estimation of Bayesian multilevel mediation models with Stan.,2021-09-29,Matti Vuorre,https://github.com/mvuorre/bmlm/,TRUE,https://github.com/mvuorre/bmlm,22152,32,2021-09-28T13:22:30Z,692.25
bnclassify,"State-of-the art algorithms for learning discrete Bayesian network classifiers from data, including a number of those described in Bielza & Larranaga (2014) <doi:10.1145/2576868>, with functions for prediction, model evaluation and inspection.",2021-10-29,Mihaljevic Bojan,https://github.com/bmihaljevic/bnclassify,TRUE,https://github.com/bmihaljevic/bnclassify,25992,16,2021-10-27T22:26:47Z,1624.5
bnmonitor,"An implementation of sensitivity and robustness methods in Bayesian networks in R. It includes methods to perform parameter variations via a variety of co-variation schemes, to compute sensitivity functions and to quantify the dissimilarity of two Bayesian networks via distances and divergences. It further includes diagnostic methods to assess the goodness of fit of a Bayesian networks to data, including global, node and parent-child monitors. References: H. Chan, A. Darwiche (2002) <doi:10.1613/jair.967>; C. Goergen, M. Leonelli (2020) <ArXiv:1809.10794>; M. Leonelli, R. Ramanathan, R.L. Wilkerson (2021) <ArXiv:2107.11785>. ",2022-04-20,Manuele Leonelli,"https://manueleleonelli.github.io/bnmonitor/,
https://github.com/manueleleonelli/bnmonitor",TRUE,https://github.com/manueleleonelli/bnmonitor,7587,1,2022-04-20T07:51:54Z,7587
bnpsd,"The Pritchard-Stephens-Donnelly (PSD) admixture model has k intermediate subpopulations from which n individuals draw their alleles dictated by their individual-specific admixture proportions.  The BN-PSD model additionally imposes the Balding-Nichols (BN) allele frequency model to the intermediate populations, which therefore evolved independently from a common ancestral population T with subpopulation-specific FST (Wright's fixation index) parameters.  The BN-PSD model can be used to yield complex population structures.  This simulation approach is now extended to subpopulations related by a tree.  Method described in Ochoa and Storey (2021) <doi:10.1371/journal.pgen.1009241>.",2021-08-25,Alejandro Ochoa,https://github.com/StoreyLab/bnpsd/,TRUE,https://github.com/storeylab/bnpsd,16872,9,2021-08-09T19:43:36Z,1874.6666666666667
Bolstad2,"A set of R functions and data sets for the book ""Understanding Computational Bayesian Statistics."" This book was written by Bill (WM) Bolstad and published in 2009 by John Wiley & Sons (ISBN 978-0470046098).",2022-04-11,James Curran,https://github.com/jmcurran/Bolstad2,TRUE,https://github.com/jmcurran/bolstad2,27198,0,2022-04-11T05:55:42Z,NA
bonsai,"Bindings for additional tree-based model engines for use with
    the 'parsnip' package. Models include gradient boosted decision trees
    with 'LightGBM' (Ke et al, 2017.) and
    conditional inference trees and conditional random forests with
    'partykit' (Hothorn and Zeileis, 2015. and
    Hothorn et al, 2006. <doi:10.1198/106186006X133933>).",2022-06-23,Roel M. Hogervorst,"https://bonsai.tidymodels.org/,
https://github.com/tidymodels/bonsai",TRUE,https://github.com/tidymodels/bonsai,319,18,2022-06-23T11:32:16Z,17.72222222222222
bookdown,Output formats and utilities for authoring books and technical documents with R Markdown.,2022-06-14,Yihui Xie,"https://github.com/rstudio/bookdown,
https://pkgs.rstudio.com/bookdown/",TRUE,https://github.com/rstudio/bookdown,1110820,2995,2022-07-06T14:43:42Z,370.8914858096828
bookdownplus,"A collection and selector of R 'bookdown' templates. 'bookdownplus' helps you write academic journal articles, guitar books, chemical equations, mails, calendars, and diaries. R 'bookdownplus' extends the features of 'bookdown', and simplifies the procedure. Users only have to choose a template, clarify the book title and author name, and then focus on writing the text. No need to struggle in 'YAML' and 'LaTeX'.",2020-02-26,Peng Zhao,https://github.com/pzhaonet/bookdownplus,TRUE,https://github.com/pzhaonet/bookdownplus,28741,235,2021-12-31T03:36:32Z,122.30212765957447
boomer,"Provides debugging tools that let you inspect the
    intermediate results of a call. The output looks as if we explode a call
    into its parts hence the package name.",2021-07-20,Antoine Fabri,https://github.com/moodymudskipper/boomer,TRUE,https://github.com/moodymudskipper/boomer,4470,119,2022-07-08T09:36:36Z,37.563025210084035
boot.heterogeneity,"Implements a bootstrap-based heterogeneity test for standardized mean differences (d), Fisher-transformed Pearson's correlations (r), and natural-logarithm-transformed odds ratio (or) in meta-analysis studies. Depending on the presence of moderators, this Monte Carlo based test can be implemented in the random- or mixed-effects model. This package uses rma() function from the R package 'metafor' to obtain parameter estimates and likelihoods, so installation of R package 'metafor' is required. This approach refers to the studies of Anscombe (1956) <doi:10.2307/2332926>, Haldane (1940) <doi:10.2307/2332614>, Hedges (1981) <doi:10.3102/10769986006002107>, Hedges & Olkin (1985, ISBN:978-0123363800), Silagy, Lancaster, Stead, Mant, & Fowler (2004) <doi:10.1002/14651858.CD000146.pub2>, Viechtbauer (2010) <doi:10.18637/jss.v036.i03>, and Zuckerman (1994, ISBN:978-0521432009). ",2021-10-23,Ge Jiang,https://github.com/gabriellajg/boot.heterogeneity/,TRUE,https://github.com/gabriellajg/boot.heterogeneity,12041,0,2021-10-18T19:23:55Z,NA
bootf2,"Compare dissolution profiles with confidence interval of similarity
  factor f2 using bootstrap methodology as described in the literature, such as 
  Efron and Tibshirani (1993, ISBN:9780412042317), Davison and Hinkley (1997,
  ISBN:9780521573917), and Shah et al. (1998) <doi:10.1023/A:1011976615750>. 
  The package can also be used to simulate dissolution profiles based on 
  mathematical modelling and multivariate normal distribution.",2021-08-25,Zhengguo Xu,https://github.com/zhengguoxu/bootf2,TRUE,https://github.com/zhengguoxu/bootf2,3695,0,2021-11-11T21:19:09Z,NA
bootGOF,"Bootstrap based goodness-of-fit tests. It allows
    to perform rigorous statistical tests to check if a chosen
    model family is correct based on the marked empirical
    process. The implemented algorithms are described in
    (Dikta and Scheer (2021) <doi:10.1007/978-3-030-73480-0>)
    and can be applied
    to generalized linear models without any further implementation
    effort. As far as certain linearity conditions are fulfilled
    the resampling scheme are also applicable beyond generalized
    linear models. This is reflected in the software architecture
    which allows to reuse the resampling scheme by implementing
    only certain interfaces for models that are not supported
    natively by the package.",2021-06-24,Marsel Scheer,https://github.com/MarselScheer/bootGOF,TRUE,https://github.com/marselscheer/bootgof,4756,1,2021-09-07T18:30:44Z,4756
bootPLS,"Several implementations of non-parametric stable bootstrap-based techniques to determine the numbers of components for Partial Least Squares linear or generalized linear regression models as well as and sparse Partial Least Squares linear or generalized linear regression models. The package collects techniques that were published in a book chapter (Magnanensi et al. 2016, 'The Multiple Facets of Partial Least Squares and Related Methods', <doi:10.1007/978-3-319-40643-5_18>) and two articles (Magnanensi et al. 2017, 'Statistics and Computing', <doi:10.1007/s11222-016-9651-4>) and (Magnanensi et al. 2021, 'Frontiers in Applied Mathematics and Statistics', accepted.).",2021-07-15,Frederic Bertrand,"https://fbertran.github.io/bootPLS/,
https://github.com/fbertran/bootPLS/",TRUE,https://github.com/fbertran/bootpls,4542,1,2021-07-15T09:05:42Z,4542
bootUR,"Set of functions to perform various bootstrap unit root tests for both individual time series
  (including augmented Dickey-Fuller test and union tests), multiple time series and panel data; see
  Palm, Smeekes and Urbain (2008) <doi:10.1111/j.1467-9892.2007.00565.x>,
  Palm, Smeekes and Urbain (2011) <doi:10.1016/j.jeconom.2010.11.010>, 
  Moon and Perron (2012) <doi:10.1016/j.jeconom.2012.01.008>, 
  Smeekes and Taylor (2012) <doi:10.1017/S0266466611000387> and 
  Smeekes (2015) <doi:10.1111/jtsa.12110> for key references. ",2021-11-25,Stephan Smeekes,https://github.com/smeekes/bootUR,TRUE,https://github.com/smeekes/bootur,14377,2,2022-06-27T15:45:09Z,7188.5
box,"A modern module system for R. Organise code into hierarchical,
    composable, reusable modules, and use it effortlessly across projects via a
    flexible, declarative dependency loading syntax.",2022-05-11,Konrad Rudolph,"https://klmr.me/box/, https://github.com/klmr/box",TRUE,https://github.com/klmr/box,14610,618,2022-05-12T14:41:56Z,23.640776699029125
boxr,"An R interface for the remote file hosting service 'Box'
    (<https://www.box.com/>). In addition to uploading and downloading files,
    this package includes functions which mirror base R operations for local
    files, (e.g. box_load(), box_save(), box_read(), box_setwd(), etc.), as well
    as 'git' style functions for entire directories (e.g. box_fetch(),
    box_push()).",2021-01-19,Ian Lyttle,https://github.com/r-box/boxr/,TRUE,https://github.com/r-box/boxr,38282,57,2022-04-06T19:13:18Z,671.6140350877193
bp,A comprehensive package to aid in the analysis of blood pressure data of all forms by providing both descriptive and visualization tools for researchers.,2022-05-10,John Schwenck,https://github.com/johnschwenck/bp,TRUE,https://github.com/johnschwenck/bp,8385,13,2022-05-10T15:15:25Z,645
bpbounds,"Implementation of the nonparametric bounds for the average causal 
    effect under an instrumental variable model by Balke and Pearl (Bounds on 
    Treatment Effects from Studies with Imperfect Compliance, JASA, 1997, 92, 
    439, 1171-1176). The package can calculate bounds for a binary outcome, a 
    binary treatment/phenotype, and an instrument with either 2 or 3 
    categories. The package implements bounds for situations where these 3 
    variables are measured in the same dataset (trivariate data) or where the 
    outcome and instrument are measured in one study and the 
    treatment/phenotype and instrument are measured in another study 
    (bivariate data).",2020-01-21,Tom Palmer,https://github.com/remlapmot/bpbounds,TRUE,https://github.com/remlapmot/bpbounds,14631,0,2022-06-28T12:40:14Z,NA
bpcs,"Models for the analysis of paired comparison data using Stan. The models include Bayesian versions of the Bradley-Terry model, including random effects (1 level), generalized model for predictors, order effect (home advantage) and the  variations for the Davidson (1970) model to handle ties. Additionally, we provide a number of functions to facilitate inference and obtaining results with these models. References: Bradley and Terry (1952) <doi:10.2307/2334029>; Davidson (1970) <doi:10.1080/01621459.1970.10481082>; Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>. ",2020-12-09,David Issa Mattos,"https://github.com/davidissamattos/bpcs,
https://davidissamattos.github.io/bpcs/",TRUE,https://github.com/davidissamattos/bpcs,5693,8,2021-11-11T06:29:25Z,711.625
bpnreg,"Fitting Bayesian multiple and mixed-effect regression models for 
    circular data based on the projected normal distribution. Both continuous 
    and categorical predictors can be included. Sampling from the posterior is 
    performed via an MCMC algorithm. Posterior descriptives of all parameters, 
    model fit statistics and Bayes factors for hypothesis tests for inequality 
    constrained hypotheses are provided. See Cremers, Mulder & Klugkist (2018) 
    <doi:10.1111/bmsp.12108> and Nuñez-Antonio & Guttiérez-Peña (2014) 
    <doi:10.1016/j.csda.2012.07.025>.",2021-08-06,Jolien Cremers,https://github.com/joliencremers/bpnreg,TRUE,https://github.com/joliencremers/bpnreg,17618,8,2021-08-10T12:47:12Z,2202.25
bqror,"Package provides functions for estimating Bayesian quantile regression with ordinal outcomes, 
        computing the covariate effects, model comparison measures, and inefficiency factor. The generic 
        ordinal model with 3 or more outcomes (labeled OR1 model) is estimated by a combination of Gibbs 
        sampling and Metropolis-Hastings algorithm. Whereas an ordinal model with exactly 3 outcomes 
        (labeled OR2 model) is estimated using Gibbs sampling only. For each model framework, there is a 
        specific function for estimation. The summary output produces estimates for regression quantiles 
        and two measures of model comparison — log of marginal likelihood and Deviance Information Criterion 
        (DIC). The package also has specific functions for computing the covariate effects and other functions 
        that aids either the estimation or inference in quantile ordinal models.
        Rahman, M. A. (2016).“Bayesian Quantile Regression for Ordinal Models.” Bayesian 
        Analysis, II(I): 1-24 <doi: 10.1214/15-BA939>.
        Yu, K., and Moyeed, R. A. (2001). “Bayesian Quantile Regression.” Statistics and 
        Probability Letters, 54(4): 437–447 <doi: 10.1016/S0167-7152(01)00124-9>.
        Koenker, R., and Bassett, G. (1978).“Regression Quantiles.” Econometrica, 
        46(1): 33-50 <doi: 10.2307/1913643>.
        Chib, S. (1995). “Marginal likelihood from the Gibbs output.” Journal of 
        the American Statistical Association, 90(432):1313–1321, 1995. <doi: 10.1080/01621459.1995.10476635>.
        Chib, S., and Jeliazkov, I. (2001). “Marginal likelihood from the 
        Metropolis-Hastings output.” Journal of the American Statistical Association, 96(453):270–281, 2001. <doi: 10.1198/016214501750332848>.",2022-07-06,Prajual Maheshwari,https://github.com/prajual/bqror,TRUE,https://github.com/prajual/bqror,20463,0,2022-07-06T12:51:09Z,NA
bRacatus,"Automated assessment of accuracy and geographical status of georeferenced biological data. The methods rely on reference regions, namely checklists and range maps. Includes functions to obtain data from the Global Biodiversity Information Facility <https://www.gbif.org/> and from the Global Inventory of Floras and Traits <https://gift.uni-goettingen.de/home>. Alternatively, the user can input their own data. Furthermore, provides easy visualisation of the data and the results through the plotting functions. Especially suited for large datasets. The reference for the methodology is: Arlé et al. (under review).",2021-12-08,Eduardo Arlé,https://github.com/EduardoArle/bRacatus,TRUE,https://github.com/eduardoarle/bracatus,10000,7,2021-12-09T12:34:27Z,1428.5714285714287
BrailleR,"Blind users do not have access to the graphical output from R
    without printing the content of graphics windows to an embosser of some kind. This
    is not as immediate as is required for efficient access to statistical output.
    The functions here are created so that blind people can make even better use
    of R. This includes the text descriptions of graphs, convenience functions
    to replace the functionality offered in many GUI front ends, and experimental
    functionality for optimising graphical content to prepare it for embossing as
    tactile images.",2021-10-22,A. Jonathan R. Godfrey,https://github.com/ajrgodfrey/BrailleR,TRUE,https://github.com/ajrgodfrey/brailler,14484,105,2022-07-10T07:15:13Z,137.94285714285715
BranchGLM,"Performs efficient and scalable glm best 
	subset selection using a novel implementation of a branch and bound algorithm.
	To speed up the model fitting process, a range of optimization
	methods are implemented in 'RcppArmadillo'. Parallel computation 
	is available using 'OpenMP'.",2022-06-30,Jacob Seedorff,https://github.com/JacobSeedorff21/BranchGLM,TRUE,https://github.com/jacobseedorff21/branchglm,740,1,2022-06-29T23:40:32Z,740
bread,"A simple set of wrapper functions for data.table::fread() that allows subsetting or
    filtering rows and selecting columns of table-formatted files too large for the available RAM.
    'b stands for 'big files'. The package is using Unix commands like grep, cut and sed 
    through (hopefully) intuitive parameters.
    bread makes heavy use of Unix commands like grep, sed, wc and cut. They are available 
    by default in all Unix environments.
    For Windows, you need to install those commands externally in order to simulate a 
    Unix environment and make sure that the executables are in the Windows PATH variable.
    To my knowledge, the simplest ways are to install RTools, Git or Cygwin. If they have been 
    correctly installed (with the expected registry entries), they should be detected on loading
    the package and the correct directories will be added automatically to the PATH.",2022-01-19,Vincent Guegan,https://github.com/MagicHead99/bread/,TRUE,https://github.com/magichead99/bread,1977,0,2022-05-24T07:48:10Z,NA
breakaway,"Understanding the drivers of microbial diversity is an important frontier of microbial ecology, and investigating the diversity of samples from microbial ecosystems is a common step in any microbiome analysis. 'breakaway' is the premier package for statistical analysis of microbial diversity. 'breakaway' implements the latest and greatest estimates of species richness, as well as the most commonly used estimates. Methods uniquely available in this package include objective Bayes estimators described in Barger and Bunge (2010) <doi:10.1214/10-BA527>, frequency-ratio-based estimators described in Willis and Bunge (2015) <doi:10.1111/biom.12332>, and as described in Willis, Whitman, and Bunge (2016) <doi:10.1111/rssc.12206>, a linear modeling approach for detecting changes in diversity.",2022-03-09,Amy Willis,https://adw96.github.io/breakaway/,TRUE,https://github.com/adw96/breakaway,9086,59,2022-01-04T19:16:51Z,154
breathtestcore,"Reads several formats of 13C data (IRIS/Wagner,
    BreathID) and CSV.  Creates artificial sample data for testing.  Fits
    Maes/Ghoos, Bluck-Coward self-correcting formula using 'nls', 'nlme'.
    Methods to fit breath test curves with Bayesian Stan methods are
    refactored to package 'breathteststan'. For a Shiny GUI, see package
    'dmenne/breathtestshiny' on github.",2022-04-07,Dieter Menne,https://github.com/dmenne/breathtestcore,TRUE,https://github.com/dmenne/breathtestcore,15791,2,2022-05-09T08:23:51Z,7895.5
breathteststan,"Stan-based curve-fitting function
  for use with package 'breathtestcore' by the same author.
  Stan functions are refactored here for easier testing.",2022-04-07,Dieter Menne,https://github.com/dmenne/breathteststan,TRUE,https://github.com/dmenne/breathteststan,15749,3,2022-05-09T07:42:09Z,5249.666666666667
brglm2,"Estimation and inference from generalized linear models based on various methods for bias reduction and maximum penalized likelihood with powers of the Jeffreys prior as penalty. The 'brglmFit' fitting method can achieve reduction of estimation bias by solving either the mean bias-reducing adjusted score equations in Firth (1993) <doi:10.1093/biomet/80.1.27> and Kosmidis and Firth (2009) <doi:10.1093/biomet/asp055>, or the median bias-reduction adjusted score equations in Kenne et al. (2017) <doi:10.1093/biomet/asx046>, or through the direct subtraction of an estimate of the bias of the maximum likelihood estimator from the maximum likelihood estimates as in Cordeiro and McCullagh (1991) <https://www.jstor.org/stable/2345592>. See Kosmidis et al (2020) <doi:10.1007/s11222-019-09860-6> for more details. Estimation in all cases takes place via a quasi Fisher scoring algorithm, and S3 methods for the construction of of confidence intervals for the reduced-bias estimates are provided. In the special case of generalized linear models for binomial and multinomial responses (both ordinal and nominal), the adjusted score approaches to mean and media bias reduction have been found to return estimates with improved frequentist properties, that are also always finite, even in cases where the maximum likelihood estimates are infinite (e.g. complete and quasi-complete separation; see Kosmidis and Firth, 2020 <doi:10.1093/biomet/asaa052>, for a proof for mean bias reduction in logistic regression). ",2021-11-21,Ioannis Kosmidis,https://github.com/ikosmidis/brglm2,TRUE,https://github.com/ikosmidis/brglm2,84396,18,2021-12-05T15:38:47Z,4688.666666666667
bridgedist,"An implementation of the bridge distribution with logit-link in
    R. In Wang and Louis (2003) <DOI:10.1093/biomet/90.4.765>, such a univariate
    bridge distribution was derived as the distribution of the random intercept that
    'bridged' a marginal logistic regression and a conditional logistic regression.
    The conditional and marginal regression coefficients are a scalar multiple
    of each other. Such is not the case if the random intercept distribution was
    Gaussian.",2022-03-02,Bruce Swihart,https://github.com/swihart/bridgedist,TRUE,https://github.com/swihart/bridgedist,17720,0,2022-03-02T13:43:48Z,NA
bridger,"Produce bridge hands, allowing parameters for hands to offer specific for bidding sequences.",2021-08-24,Jason Kaplan,https://github.com/CommoditiesAI/bridger,TRUE,https://github.com/commoditiesai/bridger,4043,1,2021-10-20T17:29:13Z,4043
BRINDA,"Inflammation can affect many micronutrient biomarkers and can thus lead to incorrect diagnosis of individuals and to over- or under-estimate the prevalence of deficiency in a population. Biomarkers Reflecting Inflammation and Nutritional Determinants of Anemia (BRINDA) is a multi-agency and multi-country partnership designed to improve the interpretation of nutrient biomarkers in settings of inflammation and to generate context-specific estimates of risk factors for anemia (Suchdev (2016) <doi:10.3945/an.115.010215>). In the past few years, BRINDA published a series of papers to provide guidance on how to adjust micronutrient biomarkers, retinol binding protein, serum retinol, serum ferritin by Namaste (2020), soluble transferrin receptor (sTfR), serum zinc, serum and Red Blood Cell (RBC) folate, and serum B-12, using inflammation markers, alpha-1-acid glycoprotein (AGP) and/or C-Reactive Protein (CRP) by Namaste (2020) <doi:10.1093/ajcn/nqaa141>, Rohner (2017) <doi:10.3945/ajcn.116.142232>, McDonald (2020) <doi:10.1093/ajcn/nqz304>, and Young (2020) <doi:10.1093/ajcn/nqz303>. The BRINDA inflammation adjustment method mainly focuses on Women of Reproductive Age (WRA) and Preschool-age Children (PSC); however, the general principle of the BRINDA method might apply to other population groups. The BRINDA R package is a user-friendly all-in-one R package that uses a series of functions to implement BRINDA adjustment method, as described above. The BRINDA R package will first carry out rigorous checks and provides users guidance to correct data or input errors (if they occur) prior to inflammation adjustments. After no errors are detected, the package implements the BRINDA inflammation adjustment for up to five micronutrient biomarkers, namely retinol-binding-protein, serum retinol, serum ferritin, sTfR, and serum zinc (when appropriate), using inflammation indicators of AGP and/or CRP for various population groups. Of note, adjustment for serum and RBC folate and serum B-12 is not included in the R package, since evidence shows that no adjustment is needed for these micronutrient biomarkers in either WRA or PSC groups (Young (2020) <doi:10.1093/ajcn/nqz303>).",2022-04-12,Hanqi Luo,https://github.com/hanqiluo/BRINDA,TRUE,https://github.com/hanqiluo/brinda,1818,1,2022-04-08T18:34:17Z,1818
brio,"Functions to handle basic input output, these functions
    always read and write UTF-8 (8-bit Unicode Transformation Format)
    files and provide more explicit control over line endings.",2021-11-30,Jim Hester,"https://brio.r-lib.org, https://github.com/r-lib/brio",TRUE,https://github.com/r-lib/brio,9519509,45,2022-03-15T13:42:43Z,211544.64444444445
brms,"Fit Bayesian generalized (non-)linear multivariate multilevel models
    using 'Stan' for full Bayesian inference. A wide range of distributions
    and link functions are supported, allowing users to fit -- among others --
    linear, robust linear, count data, survival, response times, ordinal,
    zero-inflated, hurdle, and even self-defined mixture models all in a
    multilevel context. Further modeling options include non-linear and
    smooth terms, auto-correlation structures, censored data, meta-analytic
    standard errors, and quite a few more. In addition, all parameters of the
    response distribution can be predicted in order to perform distributional
    regression. Prior specifications are flexible and explicitly encourage
    users to apply prior distributions that actually reflect their beliefs.
    Model fit can easily be assessed and compared with posterior predictive
    checks and leave-one-out cross-validation. References: Bürkner (2017)
    <doi:10.18637/jss.v080.i01>; Bürkner (2018) <doi:10.32614/RJ-2018-017>;
    Bürkner (2021) <doi:10.18637/jss.v100.i05>; Carpenter et al. (2017)
    <doi:10.18637/jss.v076.i01>.",2022-04-13,Paul-Christian Bürkner,"https://github.com/paul-buerkner/brms,
https://discourse.mc-stan.org/",TRUE,https://github.com/paul-buerkner/brms,610858,1030,2022-07-07T08:15:33Z,593.0660194174757
brmsmargins,"Calculate Bayesian marginal effects, average marginal effects, and marginal coefficients (also called population averaged coefficients) for models fit using the 'brms' package including fixed effects, mixed effects, and location scale models. These are based on marginal predictions that integrate out random effects if necessary (see for example <doi:10.1186/s12874-015-0046-6> and <doi:10.1111/biom.12707>).",2022-05-18,Joshua F. Wiley,"https://joshuawiley.com/brmsmargins/,
https://github.com/JWiley/brmsmargins",TRUE,https://github.com/jwiley/brmsmargins,4316,17,2022-05-18T19:49:20Z,253.88235294117646
Brobdingnag,"Very large numbers in R.  Real numbers are held
        using their natural logarithms, plus a logical flag indicating
        sign.  Functionality for complex numbers is also provided.  The
        package includes a vignette that gives a step-by-step
        introduction to using S4 methods.",2022-02-03,Robin K. S. Hankin,https://github.com/RobinHankin/Brobdingnag,TRUE,https://github.com/robinhankin/brobdingnag,369740,1,2022-03-29T03:39:20Z,369740
brokenstick,"The broken stick model describes a set of individual curves by a
    linear mixed model using a second-order linear B-spline. The main use of the model
    is to align irregularly observed data to a user-specified grid of break ages.
    All fitting can done in the Z-score scale, so non-linearity and irregular data
    can be treated as separate problems. This package contains functions for fitting
    a broken stick model to data, for predicting broken stick curves in new data,
    and for plotting the broken stick estimates. For additional documentation on 
    background, methodology and applications see
    <https://stefvanbuuren.name/publications/2021_brokenstick_JSS_manuscript.pdf>.",2022-03-30,Stef van Buuren,"https://github.com/growthcharts/brokenstick,
https://growthcharts.org/brokenstick/",TRUE,https://github.com/growthcharts/brokenstick,9112,5,2022-03-31T10:08:04Z,1822.4
brolgar,"Provides a framework of tools to summarise, visualise, and explore 
  longitudinal data. It builds upon the tidy time series data frames used in the
  'tsibble' package, and is designed to integrate within the 'tidyverse', and
  'tidyverts' (for time series) ecosystems. The methods implemented include 
  calculating features for understanding longitudinal data, including 
  calculating summary statistics such as quantiles, medians, and numeric ranges,
  sampling individual series, identifying individual series representative of a 
  group, and extending the facet system  in 'ggplot2' to facilitate exploration of samples of data. These methods are
  fully described in the paper ""brolgar: An R package to Browse Over 
  Longitudinal Data Graphically and Analytically in R"", Nicholas Tierney, 
  Dianne Cook, Tania Prvan (2020) <arXiv:2012.01619>.",2021-08-25,Nicholas Tierney,https://github.com/njtierney/brolgar,TRUE,https://github.com/njtierney/brolgar,8827,101,2021-08-11T01:55:56Z,87.39603960396039
broman,"Miscellaneous R functions, including functions related to
    graphics (mostly for base graphics), permutation tests, running
    mean/median, and general utilities.",2022-07-08,Karl W Broman,https://github.com/kbroman/broman,TRUE,https://github.com/kbroman/broman,34885,172,2022-07-08T14:52:48Z,202.81976744186048
broom,"Summarizes key information about statistical
    objects in tidy tibbles. This makes it easy to report results, create
    plots and consistently work with large numbers of models at once.
    Broom provides three verbs that each provide different types of
    information about a model. tidy() summarizes information about model
    components such as coefficients of a regression. glance() reports
    information about an entire model, such as goodness of fit measures
    like AIC and BIC. augment() adds information about individual
    observations to a dataset, such as fitted values or influence
    measures.",2022-07-01,Alex Hayes,"https://broom.tidymodels.org/, https://github.com/tidymodels/broom",TRUE,https://github.com/tidymodels/broom,22716373,1289,2022-07-01T11:46:35Z,17623.252909231964
broom.helpers,"Provides suite of functions to work with regression model
    'broom::tidy()' tibbles.  The suite includes functions to group
    regression model terms by variable, insert reference and header rows
    for categorical variables, add variable labels, and more.",2022-07-05,Joseph Larmarange,https://larmarange.github.io/broom.helpers/,TRUE,https://github.com/larmarange/broom.helpers,208345,9,2022-07-06T10:53:15Z,23149.444444444445
broom.mixed,"Convert fitted objects from various R mixed-model packages
    into tidy data frames along the lines of the 'broom' package.
    The package provides three
    S3 generics for each model: tidy(), which summarizes a model's statistical findings such as
    coefficients of a regression; augment(), which adds columns to the original
    data such as predictions, residuals and cluster assignments; and glance(), which
    provides a one-row summary of model-level statistics.",2022-04-17,Ben Bolker,https://github.com/bbolker/broom.mixed,TRUE,https://github.com/bbolker/broom.mixed,391931,204,2022-06-18T01:45:20Z,1921.2303921568628
bruceR,"
  Broadly useful convenient and efficient R functions
  that bring users concise and elegant R data analyses.
  This package includes easy-to-use functions for
  (1) basic R programming
  (e.g., set working directory to the path of currently opened file;
  import/export data from/to files in any format;
  print tables to Microsoft Word);
  (2) multivariate computation
  (e.g., compute scale sums/means/... with reverse scoring);
  (3) reliability analyses and factor analyses;
  (4) descriptive statistics and correlation analyses;
  (5) t-test, multi-factor analysis of variance (ANOVA),
  simple-effect analysis, and post-hoc multiple comparison;
  (6) tidy report of statistical models
  (to R Console and Microsoft Word);
  (7) mediation and moderation analyses (PROCESS);
  and (8) additional toolbox for statistics and graphics.",2022-06-27,Han-Wu-Shuang Bao,https://psychbruce.github.io/bruceR/,TRUE,https://github.com/psychbruce/brucer,18251,97,2022-06-27T05:05:04Z,188.15463917525773
brulee,"Provides high-level modeling functions to define and train
    models using the 'torch' R package. Models include linear, logistic, and 
    multinomial regression as well as multilayer perceptrons.",2022-02-02,Max Kuhn,"https://github.com/tidymodels/brulee,
https://tidymodels.github.io/brulee/",TRUE,https://github.com/tidymodels/brulee,2826,41,2022-02-02T18:52:36Z,68.92682926829268
bs4cards,"Allows the user to generate bootstrap cards within
    R markdown documents. Intended for use in conjunction with
    R markdown HTML outputs and other formats that support the 
    bootstrap 4 library.",2021-11-30,Danielle Navarro,https://github.com/djnavarro/bs4cards,TRUE,https://github.com/djnavarro/bs4cards,3981,41,2021-11-30T03:25:36Z,97.09756097560975
bs4Dash,"Make 'Bootstrap 4' Shiny dashboards. Use the full power
    of 'AdminLTE3', a dashboard template built on top of 'Bootstrap 4' 
    <https://github.com/ColorlibHQ/AdminLTE>.",2022-05-05,David Granjon,"https://rinterface.github.io/bs4Dash/index.html,
https://github.com/RinteRface/bs4Dash",TRUE,https://github.com/rinterface/bs4dash,136240,348,2022-05-09T12:53:31Z,391.4942528735632
BSBT,"An implementation of the Bayesian Spatial Bradley--Terry (BSBT) model. It can be used to investigate data sets where judges compared different spatial areas. It constructs a network to describe how the areas are connected, and then places a correlated prior distribution on the quality parameter for each area, based on the network. The package includes MCMC algorithms to estimate the quality parameters. The methodology is published in Seymour et. al. (2020) <arXiv:2010.14128>.  ",2021-12-21,Rowland Seymour,https://github.com/rowlandseymour/BSBT,TRUE,https://github.com/rowlandseymour/bsbt,8020,0,2021-12-21T13:18:07Z,NA
BSDA,"Data sets for book ""Basic Statistics and Data Analysis"" by
    Larry J. Kitchens.",2021-09-05,Alan T. Arnholt,"https://github.com/alanarnholt/BSDA,
https://alanarnholt.github.io/BSDA/",TRUE,https://github.com/alanarnholt/bsda,253353,2,2022-05-14T23:58:15Z,126676.5
bSims,"A highly scientific and utterly addictive 
  bird point count simulator 
  to test statistical assumptions, aid survey design,
  and have fun while doing it.
  The simulations follow time-removal and distance sampling models 
  based on Matsuoka et al. (2012) <doi:10.1525/auk.2012.11190>,
  Solymos et al. (2013) <doi:10.1111/2041-210X.12106>,
  and Solymos et al. (2018) <doi:10.1650/CONDOR-18-32.1>,
  and sound attenuation experiments by 
  Yip et al. (2017) <doi:10.1650/CONDOR-16-93.1>.",2021-10-07,Peter Solymos,https://github.com/psolymos/bSims,TRUE,https://github.com/psolymos/bsims,14061,3,2021-10-06T18:04:43Z,4687
bslib,Simplifies custom 'CSS' styling of both 'shiny' and 'rmarkdown' via 'Bootstrap' 'Sass'. Supports both 'Bootstrap' 3 and 4 as well as their various 'Bootswatch' themes. An interactive widget is also provided for previewing themes in real time.,2021-10-06,Carson Sievert,"https://rstudio.github.io/bslib/, https://github.com/rstudio/bslib",TRUE,https://github.com/rstudio/bslib,7419248,265,2022-06-15T15:59:30Z,27997.162264150942
bspline,"Build and use B-splines for interpolation and regression.
  In case of regression, equality constraints as well as monotonicity
  and/or positivity of B-spline weights can be imposed. Moreover, 
  knot positions (not only spline weights) can be part of 
  optimized parameters too. For this end, 'bspline' is able to calculate
  Jacobian of basis vectors as function of knot positions. User is provided with 
  functions calculating spline values at arbitrary points. These 
  functions can be differentiated and integrated to obtain B-splines calculating 
  derivatives/integrals at any point. B-splines of this package can 
  simultaneously operate on a series of curves sharing the same set of 
  knots. 'bspline' is written with concern about computing 
  performance that's why the basis and Jacobian calculation is implemented in C++.
  The rest is implemented in R but without notable impact on computing speed.",2022-04-19,Serguei Sokol,https://github.com/MathsCell/bspline,TRUE,https://github.com/mathscell/bspline,1543,2,2022-06-17T15:13:11Z,771.5
bsplus,"The Bootstrap framework lets you add some JavaScript functionality to your web site by
  adding attributes to your HTML tags - Bootstrap takes care of the JavaScript
  <https://getbootstrap.com/docs/3.3/javascript/>. If you are using R Markdown or Shiny, you can
  use these functions to create collapsible sections, accordion panels, modals, tooltips,
  popovers, and an accordion sidebar framework (not described at Bootstrap site).
  Please note this package was designed for Bootstrap 3.3.",2021-10-05,Ian Lyttle,https://github.com/ijlyttle/bsplus,TRUE,https://github.com/ijlyttle/bsplus,99038,135,2021-10-10T20:50:14Z,733.6148148148148
bspm,"Enables binary package installations on Linux distributions.
    Provides functions to manage packages via the distribution's package
    manager. Also provides transparent integration with R's install.packages()
    and a fallback mechanism. When installed as a system package, interacts
    with the system's package manager without requiring administrative
    privileges via an integrated D-Bus service; otherwise, uses sudo.
    Currently, the following backends are supported: DNF, APT, ALPM.",2022-01-04,Iñaki Ucar,https://github.com/Enchufa2/bspm,TRUE,https://github.com/enchufa2/bspm,10885,49,2022-05-04T15:14:07Z,222.14285714285714
bssm,"Efficient methods for Bayesian inference of state space models 
    via Markov chain Monte Carlo (MCMC) based on parallel 
    importance sampling type weighted estimators 
    (Vihola, Helske, and Franks, 2020, <doi:10.1111/sjos.12492>), 
    particle MCMC, and its delayed acceptance version. 
    Gaussian, Poisson, binomial, negative binomial, and Gamma
    observation densities and basic stochastic volatility models 
    with linear-Gaussian state dynamics, as well as general non-linear Gaussian 
    models and discretised diffusion models are supported. 
    See Helske and Vihola (2021, <doi:10.32614/RJ-2021-103>) for details.",2022-05-03,Jouni Helske,https://github.com/helske/bssm,TRUE,https://github.com/helske/bssm,70592,33,2022-07-06T10:20:30Z,2139.151515151515
bsub,"It submits R code/R scripts/shell commands to 'LSF cluster' 
  (<https://en.wikipedia.org/wiki/Platform_LSF>, the 'bsub' system) without 
  leaving R. There is also an interactive 'shiny' app for monitoring the job status.",2021-07-01,Zuguang Gu,https://github.com/jokergoo/bsub,TRUE,https://github.com/jokergoo/bsub,9825,13,2022-07-05T13:38:11Z,755.7692307692307
btergm,"Temporal Exponential Random Graph Models (TERGM) estimated by maximum pseudolikelihood with bootstrapped confidence intervals or Markov Chain Monte Carlo maximum likelihood. Goodness of fit assessment for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs. As described in Leifeld, Cranmer and Desmarais (2018), JStatSoft <doi:10.18637/jss.v083.i06>.",2022-04-02,Philip Leifeld,https://github.com/leifeld/btergm,TRUE,https://github.com/leifeld/btergm,94927,13,2022-05-14T10:52:25Z,7302.076923076923
BTSPAS,"Provides advanced Bayesian methods to estimate
	     abundance and run-timing from temporally-stratified
	     Petersen mark-recapture experiments. Methods include
	     hierarchical modelling of the capture probabilities
  	     and spline smoothing of the daily run size. Theory
  	     described in Bonner and Schwarz (2011)
         <doi:10.1111/j.1541-0420.2011.01599.x>.",2021-10-25,Carl J Schwarz,https://github.com/cschwarz-stat-sfu-ca/BTSPAS,TRUE,https://github.com/cschwarz-stat-sfu-ca/btspas,22740,0,2022-01-09T04:58:25Z,NA
BTYD,"Functions for data preparation, parameter estimation, scoring, and plotting for the 
    BG/BB (Fader, Hardie, and Shang 2010 <doi:10.1287/mksc.1100.0580>), 
    BG/NBD (Fader, Hardie, and Lee 2005 <doi:10.1287/mksc.1040.0098>) and 
    Pareto/NBD and Gamma/Gamma (Fader, Hardie, and Lee 2005 <doi:10.1509/jmkr.2005.42.4.415>) models.",2021-11-17,Lukasz Dziurzynski,NA,TRUE,https://github.com/ghuiber/btyd,236616,2,2022-03-28T22:43:08Z,118308
bucky,"Provides functions for various statistical techniques commonly used in the social sciences, including functions to compute clustered robust standard errors, combine results across multiply-imputed data sets, and simplify the addition of robust and clustered robust standard errors.",2022-03-25,Alexander Tahk,https://github.com/atahk/bucky,TRUE,https://github.com/atahk/bucky,18050,6,2022-03-25T18:33:38Z,3008.3333333333335
buffeRs,Generates non-circular simple feature geometries e.g. for the use as buffers in model-building.,2021-08-22,Tilman Leo Hohenberger,https://github.com/tlhenvironment/buffeRs,TRUE,https://github.com/tlhenvironment/buffers,7097,0,2021-08-22T06:23:21Z,NA
buildmer,"Finds the largest possible regression model that will still converge
    for various types of regression analyses (including mixed models and generalized
    additive models) and then optionally performs stepwise elimination similar to the
    forward and backward effect-selection methods in SAS, based on the change in
    log-likelihood or its significance, Akaike's Information Criterion, the Bayesian
    Information Criterion, the explained deviance, or the F-test of the change in R².",2022-06-14,Cesko C. Voeten,NA,TRUE,https://github.com/cvoeten/buildmer,99768,6,2022-06-14T15:39:04Z,16628
buildr,"Working with reproducible reports or any other
    similar projects often require to run the script that builds the
    output file in a specified way. 'buildr' can help you organize, modify
    and comfortably run those scripts. The package provides a set of
    functions that interactively guides you through the process and that
    are available as 'RStudio' Addin, meaning you can set up the keyboard
    shortcuts, enabling you to choose and run the desired build script
    with one keystroke anywhere anytime.",2021-01-10,Jan Netik,https://netique.github.io/buildr/,TRUE,https://github.com/netique/buildr,12353,3,2021-12-10T10:29:31Z,4117.666666666667
bulkAnalyseR,"Given an expression matrix from a bulk sequencing experiment,
        pre-processes it and creates a shiny app for interactive data 
        analysis and visualisation. The app contains quality checks,
        differential expression analysis, volcano and cross plots,
        enrichment analysis and gene regulatory network inference,
        and can be customised to contain more panels by the user.",2022-04-07,Ilias Moutsopoulos,https://github.com/Core-Bioinformatics/bulkAnalyseR,TRUE,https://github.com/core-bioinformatics/bulkanalyser,1580,7,2022-06-09T11:02:11Z,225.71428571428572
bumbl,"Bumblebee colonies grow during worker production, then decline after switching to production of reproductive individuals (drones and gynes).  This package provides tools for modeling and visualizing this pattern by identifying a switchpoint with a growth rate before and a decline rate after the switchpoint. The mathematical models fit by bumbl are described in Crone and Williams (2016) <doi:10.1111/ele.12581>.",2022-05-13,Eric R. Scott,https://github.com/Aariq/bumbl,TRUE,https://github.com/aariq/bumbl,5941,2,2022-05-13T15:01:55Z,2970.5
bumblebee,"A simple tool to quantify the amount of transmission
   of an infectious disease of interest occurring within and between 
   population groups. 'bumblebee' uses counts of observed directed 
   transmission pairs, identified phylogenetically from deep-sequence data or 
   from epidemiological contacts, to quantify transmission flows within and 
   between population groups accounting for sampling heterogeneity. Population 
   groups might include: geographical areas (e.g. communities, regions), 
   demographic groups (e.g. age, gender) or arms of a randomized clinical 
   trial. See the 'bumblebee' website for statistical theory, documentation 
   and examples <https://magosil86.github.io/bumblebee/>.",2021-05-11,Lerato E Magosi,https://magosil86.github.io/bumblebee/,TRUE,https://github.com/magosil86/bumblebee,5375,0,2022-02-27T21:36:35Z,NA
bupaR,"Comprehensive Business Process Analysis toolkit. Creates S3-class for event log objects, and related handler functions. Imports related packages for filtering event data, computation of descriptive statistics, handling of 'Petri Net' objects and visualization of process maps. See also packages 'edeaR','processmapR', 'eventdataR' and 'processmonitR'.",2022-07-05,Gert Janssenswillen,"https://bupar.net/, https://github.com/bupaverse/bupaR/",TRUE,https://github.com/bupaverse/bupar,123285,37,2022-07-05T14:00:15Z,3332.027027027027
burnr,"Tools to read, write, parse, and analyze forest fire history data (e.g. FHX). Described in Malevich et al. (2018) <doi:10.1016/j.dendro.2018.02.005>.",2022-03-01,Steven Malevich,https://github.com/ltrr-arizona-edu/burnr/,TRUE,https://github.com/ltrr-arizona-edu/burnr,20791,11,2022-05-20T23:08:51Z,1890.090909090909
butcher,"Provides a set of S3 generics to axe components of fitted
    model objects and help reduce the size of model objects saved to disk.",2022-06-14,Joyce Cahoon,"https://butcher.tidymodels.org/,
https://github.com/tidymodels/butcher",TRUE,https://github.com/tidymodels/butcher,95195,117,2022-06-14T19:26:17Z,813.6324786324786
BuyseTest,"Implementation of the Generalized Pairwise Comparisons (GPC)
             as defined in Buyse (2010) <doi:10.1002/sim.3923> for complete observations,
             and extended in Peron (2018) <doi:10.1177/0962280216658320> to deal with right-censoring.        
             GPC compare two groups of observations (intervention vs. control group)
			 regarding several prioritized endpoints to estimate the probability that a random observation drawn from
			 one group performs better than a random observation drawn from the other group (Mann-Whitney parameter).
			 The net benefit and win ratio statistics,
			 i.e. the difference and ratio between the probabilities relative to the intervention and control groups,
			 can then also be estimated. Confidence intervals and p-values are obtained based on asymptotic results (Ozenne 2021 <doi:10.1177/09622802211037067>),
			 non-parametric bootstrap, or permutations.
			 The software enables the use of thresholds of minimal importance difference,
			 stratification, non-prioritized endpoints (O Brien test), and can handle right-censoring and competing-risks.",2022-03-28,Brice Ozenne,https://github.com/bozenne/BuyseTest,TRUE,https://github.com/bozenne/buysetest,23999,3,2022-05-09T11:35:06Z,7999.666666666667
BVAR,"Estimation of hierarchical Bayesian vector autoregressive models
    following Kuschnig & Vashold (2021) <doi:10.18637/jss.v100.i14>.
    Implements hierarchical prior selection for conjugate priors in the fashion
    of Giannone, Lenza & Primiceri (2015) <doi:10.1162/REST_a_00483>.
    Functions to compute and identify impulse responses, calculate forecasts,
    forecast error variance decompositions and scenarios are available.
    Several methods to print, plot and summarise results facilitate analysis.",2022-02-25,Nikolas Kuschnig,https://github.com/nk027/bvar,TRUE,https://github.com/nk027/bvar,27084,33,2022-02-25T14:21:03Z,820.7272727272727
bvartools,"Assists in the set-up of algorithms for Bayesian inference of vector autoregressive (VAR) and error correction (VEC) models. Functions for posterior simulation, forecasting, impulse response analysis and forecast error variance decomposition are largely based on the introductory texts of Chan, Koop, Poirier and Tobias (2019, ISBN: 9781108437493), Koop and Korobilis (2010) <doi:10.1561/0800000013> and Luetkepohl (2006, ISBN: 9783540262398).",2022-01-22,Franz X. Mohr,https://github.com/franzmohr/bvartools,TRUE,https://github.com/franzmohr/bvartools,23490,19,2022-01-21T22:46:20Z,1236.3157894736842
BWGS,"Package for Breed Wheat Genomic Selection Pipeline. 
    The R package 'BWGS' is developed by Louis Gautier Tran <louis.gautier.tran@gmail.com> and Gilles Charmet <gilles.charmet@inra.fr>.
    This repository is forked from original repository <https://forgemia.inra.fr/umr-gdec/bwgs>
    and modified as a R package.",2021-09-23,Bangyou Zheng,https://github.com/byzheng/BWGS,TRUE,https://github.com/byzheng/bwgs,10158,0,2021-09-26T22:31:33Z,NA
c060,"The c060 package provides additional functions to perform stability selection, model validation and parameter tuning for glmnet models.",2022-03-03,Martin Sill,"https://github.com/fbertran/c060/,
https://fbertran.github.io/c060/",TRUE,https://github.com/fbertran/c060,19787,1,2022-03-03T13:04:25Z,19787
C50,"C5.0 decision trees and rule-based models for pattern recognition that extend the work of Quinlan (1993, ISBN:1-55860-238-0).",2022-02-05,Max Kuhn,https://topepo.github.io/C5.0/,TRUE,https://github.com/topepo/c5.0,381769,46,2022-02-07T00:38:21Z,8299.326086956522
cache,"Easily cache and retrieve computation results. The package works seamlessly across interactive R sessions, R scripts and Rmarkdown documents.",2022-03-26,Olivier Binette,https://github.com/OlivierBinette/cache,TRUE,https://github.com/olivierbinette/cache,5325,3,2022-03-26T21:19:01Z,1775
cachem,"Key-value stores with automatic pruning. Caches can limit
    either their total size or the age of the oldest object (or both),
    automatically pruning objects to maintain the constraints.",2021-08-19,Winston Chang,"https://cachem.r-lib.org/, https://github.com/r-lib/cachem",TRUE,https://github.com/r-lib/cachem,7094128,41,2022-06-03T18:59:12Z,173027.51219512196
CACIMAR,A toolkit to perform cross-species analysis based on scRNA-seq data. This package contains 5 main features. (1) identify Markers in each cluster. (2) Cell type annotation (3) identify conserved markers. (4) identify conserved cell types. (5) identify conserved modules of regulatory networks.,2022-05-18,Junyao Jiang,https://github.com/jiang-junyao/CACIMAR,TRUE,https://github.com/jiang-junyao/cacimar,424,2,2022-06-20T09:54:45Z,212
CALANGO,"A first-principle, phylogeny-aware comparative genomics tool for 
             investigating associations between terms used to annotate genomic
             components (e.g., Pfam IDs, Gene Ontology terms,) with quantitative 
             or rank variables such as number of cell types, genome size, or 
             density of specific genomic elements. See the project website for 
             more information, documentation and examples.",2022-03-12,Felipe Campelo,https://labpackages.github.io/CALANGO/,TRUE,https://github.com/fcampelo/calango,5534,1,2022-03-12T15:51:17Z,5534
calculus,"Efficient C++ optimized functions for numerical and symbolic calculus as described in Guidotti (2020) <arXiv:2101.00086>. It includes basic arithmetic, tensor calculus, Einstein summing convention, fast computation of the Levi-Civita symbol and generalized Kronecker delta, Taylor series expansion, multivariate Hermite polynomials, high-order derivatives, ordinary differential equations, differential operators (Gradient, Jacobian, Hessian, Divergence, Curl, Laplacian) and numerical integration in arbitrary orthogonal coordinate systems: cartesian, polar, spherical, cylindrical, parabolic or user defined by custom scale factors. ",2022-01-22,Emanuele Guidotti,https://calculus.guidotti.dev,TRUE,https://github.com/eguidotti/calculus,30608,31,2022-01-22T18:30:35Z,987.3548387096774
calibrar,"Automated parameter estimation for complex (ecological) models in R. 
  This package allows the parameter estimation or calibration of complex models, 
  including stochastic ones. It is a generic tool that can be used for fitting 
  any type of models, especially those with non-differentiable objective functions. 
  It supports multiple phases and constrained optimization. 
  It implements maximum likelihood estimation methods and automated construction 
  of the objective function from simulated model outputs. 
  See <http://roliveros-ramos.github.io/calibrar> for more details.",2016-02-17,Ricardo Oliveros-Ramos,http://roliveros-ramos.github.io/calibrar,TRUE,https://github.com/roliveros-ramos/calibrar,15904,6,2022-03-29T06:53:52Z,2650.6666666666665
calmate,"The CalMaTe method calibrates preprocessed allele-specific copy number estimates (ASCNs) from DNA microarrays by controlling for single-nucleotide polymorphism-specific allelic crosstalk. The resulting ASCNs are on average more accurate, which increases the power of segmentation methods for detecting changes between copy number states in tumor studies including copy neutral loss of heterozygosity. CalMaTe applies to any ASCNs regardless of preprocessing method and microarray technology, e.g. Affymetrix and Illumina.",2022-03-08,Henrik Bengtsson,https://github.com/HenrikBengtsson/calmate/,TRUE,https://github.com/henrikbengtsson/calmate,19245,1,2022-03-08T23:11:13Z,19245
camerondata,"Quick and easy access to datasets that let you replicate the
    empirical examples in Cameron and Trivedi (2005) ""Microeconometrics: Methods and
    Applications"" (ISBN: 9780521848053).The data are available as soon as you install
    and load the package (lazy-loading) as data frames. The documentation includes
    reference to chapter sections and page numbers where the datasets are used. ",2022-03-21,Juliana Vega-Lacorte,https://github.com/juvlac/camerondata,TRUE,https://github.com/juvlac/camerondata,1257,0,2022-03-28T13:44:09Z,NA
campfin,"Explore and normalize American campaign finance
    data. Created by the Investigative Reporting Workshop to facilitate
    work on The Accountability Project, an effort to collect public data
    into a central, standard database that is more easily searched:
    <https://publicaccountability.org/>.",2022-05-24,Kiernan Nicholls,"https://github.com/irworkshop/campfin,
https://irworkshop.github.io/campfin/",TRUE,https://github.com/irworkshop/campfin,9755,13,2022-05-24T14:47:04Z,750.3846153846154
campsis,"A generic, easy-to-use and intuitive
    pharmacokinetic/pharmacodynamic (PK/PD) simulation platform based on R
    packages 'rxode2', 'RxODE' and 'mrgsolve'. CAMPSIS provides an
    abstraction layer over the underlying processes of writing a PK/PD
    model, assembling a custom dataset and running a simulation. CAMPSIS
    has a strong dependency to the R package 'campsismod', which allows to
    read/write a model from/to files and adapt it further on the fly in
    the R environment. Package 'campsis' allows the user to assemble a
    dataset in an intuitive manner. Once the user’s dataset is ready, the
    package is in charge of preparing the simulation, calling 'rxode2',
    'RxODE' or 'mrgsolve' (at the user's choice) and returning the
    results, for the given model, dataset and desired simulation settings.",2022-06-01,Nicolas Luyckx,"https://github.com/Calvagone/campsis, https://calvagone.github.io/",TRUE,https://github.com/calvagone/campsis,1532,5,2022-06-02T07:02:30Z,306.4
campsismod,"A generic, easy-to-use and expandable implementation of a
    pharmacokinetic (PK) / pharmacodynamic (PD) model based on the S4
    class system. This package allows the user to read/write a
    pharmacometric model from/to files and adapt it further on the fly in
    the R environment. For this purpose, this package provides an
    intuitive API to add, modify or delete equations, ordinary
    differential equations (ODE's), model parameters or compartment
    properties (like infusion duration or rate, bioavailability and
    initial values). Finally, this package also provides a useful export
    of the model for use with simulation packages 'RxODE' and 'mrgsolve'.
    This package is designed and intended to be used with package
    'campsis', a PK/PD simulation platform built on top of 'RxODE' and
    'mrgsolve'.",2022-06-17,Nicolas Luyckx,"https://github.com/Calvagone/campsismod,
https://calvagone.github.io/",TRUE,https://github.com/calvagone/campsismod,1704,3,2022-06-17T13:42:42Z,568
camtrapR,"Management of and data extraction from camera trap data in wildlife studies. The package provides a workflow for storing and sorting camera trap photos (and videos), tabulates records of species and individuals, and creates detection/non-detection matrices for occupancy and spatial capture-recapture analyses with great flexibility. In addition, it can visualise species activity data and provides simple mapping functions with GIS export.",2022-05-11,Juergen Niedballa,"https://github.com/jniedballa/camtrapR,
https://jniedballa.github.io/camtrapR/,
https://groups.google.com/forum/#!forum/camtrapr",TRUE,https://github.com/jniedballa/camtrapr,39633,14,2022-07-01T08:24:20Z,2830.9285714285716
canadacovid,"Provides R functions to GET data from the Canadian COVID-19 tracker
    API <https://api.covid19tracker.ca>.",2022-02-07,Taylor Dunn,"https://github.com/taylordunn/canadacovid,
https://taylordunn.github.io/canadacovid/",TRUE,https://github.com/taylordunn/canadacovid,1871,0,2022-06-16T18:38:05Z,NA
canadamaps,"Terrestrial maps with simplified topologies for Census Divisions,
    Agricultural Regions, Economic Regions, Federal Electoral Divisions and
    Provinces.",2021-11-29,Mauricio Vargas Sepulveda,https://github.com/pachadotdev/canadamaps/,TRUE,https://github.com/pachadotdev/canadamaps,2341,0,2021-11-29T02:31:28Z,NA
cancensus,"Integrated, convenient, and uniform access to Canadian
    Census data and geography retrieved using the 'CensusMapper' API. This package produces analysis-ready 
    tidy data frames and spatial data in multiple formats, as well as convenience functions
    for working with Census variables, variable hierarchies, and region selection. API
    keys are freely available with free registration at <https://censusmapper.ca/api>.
    Census data and boundary geometries are reproduced and distributed on an ""as
    is"" basis with the permission of Statistics Canada (Statistics Canada 2001; 2006;
    2011; 2016).",2022-02-08,Jens von Bergmann,"https://github.com/mountainMath/cancensus,
https://mountainmath.github.io/cancensus/,
https://censusmapper.ca/api",TRUE,https://github.com/mountainmath/cancensus,31055,64,2022-02-16T07:40:09Z,485.234375
candisc,"Functions for computing and visualizing 
	generalized canonical discriminant analyses and canonical correlation analysis
	for a multivariate linear model.
	Traditional canonical discriminant analysis is restricted to a one-way 'MANOVA'
	design and is equivalent to canonical correlation analysis between a set of quantitative
	response variables and a set of dummy variables coded from the factor variable.
	The 'candisc' package generalizes this to higher-way 'MANOVA' designs
	for all factors in a multivariate linear model,
	computing canonical scores and vectors for each term. The graphic functions provide low-rank (1D, 2D, 3D) 
	visualizations of terms in an 'mlm' via the 'plot.candisc' and 'heplot.candisc' methods. Related plots are
	now provided for canonical correlation analysis when all predictors are quantitative.",2021-10-07,Michael Friendly,NA,TRUE,https://github.com/friendly/candisc,141965,10,2022-02-18T21:57:13Z,14196.5
Canopy,"A statistical framework and computational procedure for identifying
  the sub-populations within a tumor, determining the mutation profiles of each 
  subpopulation, and inferring the tumor's phylogenetic history. The input are 
  variant allele frequencies (VAFs) of somatic single nucleotide alterations 
  (SNAs) along with allele-specific coverage ratios between the tumor and matched
  normal sample for somatic copy number alterations (CNAs). These quantities can
  be directly taken from the output of existing software. Canopy provides a 
  general mathematical framework for pooling data across samples and sites to 
  infer the underlying parameters. For SNAs that fall within CNA regions, Canopy
  infers their temporal ordering and resolves their phase.  When there are 
  multiple evolutionary configurations consistent with the data, Canopy outputs 
  all configurations along with their confidence assessment.",2017-12-18,Yuchao Jiang,https://github.com/yuchaojiang/Canopy,TRUE,https://github.com/yuchaojiang/canopy,16862,62,2021-08-22T14:14:55Z,271.96774193548384
canprot,"Chemical metrics of differentially expressed proteins in cancer
  and cell culture proteomics experiments. Data files in the package have amino
  acid compositions of proteins obtained from UniProt and >250 published lists of
  up- and down-regulated proteins in different cancer types and laboratory
  experiments. Functions are provided to calculate chemical metrics including
  protein length, grand average of hydropathicity (GRAVY), isoelectric point
  (pI), carbon oxidation state, and stoichiometric hydration state; the latter
  two are described in Dick et al. (2020) <doi:10.5194/bg-17-6145-2020>. The
  vignettes visualize differences of chemical metrics between up- and
  down-regulated proteins and list literature references for all datasets.",2022-01-17,Jeffrey Dick,https://github.com/jedick/canprot,TRUE,https://github.com/jedick/canprot,18852,2,2022-06-23T11:32:41Z,9426
cansim,"Searches for, accesses, and retrieves new-format and old-format Statistics Canada data 
    tables, as well as individual vectors, as tidy data frames. This package deals with encoding issues, allows for 
    bilingual English or French language data retrieval, and bundles convenience functions 
    to make it easier to work with retrieved table data. Optional caching features are provided.",2022-05-10,Jens von Bergmann,"https://github.com/mountainMath/cansim,
https://mountainmath.github.io/cansim/,
https://www.statcan.gc.ca/",TRUE,https://github.com/mountainmath/cansim,27681,32,2022-05-10T05:02:44Z,865.03125
canvasXpress,"Enables creation of visualizations using the CanvasXpress framework
    in R. CanvasXpress is a standalone JavaScript library for reproducible research
    with complete tracking of data and end-user modifications stored in a single
    PNG image that can be played back. See <https://www.canvasxpress.org> for more
    information.",2022-02-09,Connie Brett,https://github.com/neuhausi/canvasXpress,TRUE,https://github.com/neuhausi/canvasxpress,35605,251,2022-07-08T22:24:36Z,141.85258964143426
capl,"A toolkit for computing and visualizing CAPL-2
    (Canadian Assessment of Physical Literacy, Second Edition;
    <https://www.capl-eclp.ca>) scores and interpretations from raw data.",2022-04-08,Joel Barnes,https://github.com/barnzilla/capl,TRUE,https://github.com/barnzilla/capl,5714,1,2022-03-26T03:26:57Z,5714
caracas,"Computer algebra via the 'SymPy' library (<https://www.sympy.org/>). 
  This makes it possible to solve equations symbolically, 
  find symbolic integrals, symbolic sums and other important quantities. ",2022-02-11,Mikkel Meyer Andersen,https://github.com/r-cas/caracas,TRUE,https://github.com/r-cas/caracas,16327,15,2022-07-05T10:01:55Z,1088.4666666666667
caRamel,"Multi-objective optimizer initially developed for the calibration of hydrological models.
     The algorithm is a hybrid of the MEAS algorithm (Efstratiadis and Koutsoyiannis (2005) <doi:10.13140/RG.2.2.32963.81446>) by using the directional search method based on the simplexes of the objective space
     and the epsilon-NGSA-II algorithm with the method of classification of the parameter vectors archiving management by epsilon-dominance (Reed and Devireddy <doi:10.1142/9789812567796_0004>).",2022-02-25,Fabrice Zaoui,https://github.com/fzao/caRamel,TRUE,https://github.com/fzao/caramel,17777,10,2022-02-01T19:14:28Z,1777.7
CARBayes,"Implements a class of univariate and multivariate spatial generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, multinomial, Poisson or zero-inflated Poisson (ZIP), and spatial autocorrelation is modelled by a set of random effects that are assigned a conditional autoregressive (CAR) prior distribution. A number of different models are available for univariate spatial data, including models with no random effects as well as random effects modelled by different types of CAR prior, including the BYM model (Besag et al., 1991, <doi:10.1007/BF00116466>) and Leroux model (Leroux et al., 2000, <doi:10.1007/978-1-4612-1284-3_4>). Additionally,  a multivariate CAR (MCAR) model for multivariate spatial data is available, as is a two-level hierarchical model for modelling data relating to individuals within areas. Full details are given in the vignette accompanying this package. The initial creation of this package was supported by the Economic and Social Research Council (ESRC) grant RES-000-22-4256, and on-going development has been supported by the Engineering and Physical Science Research Council (EPSRC) grant EP/J017442/1, ESRC grant ES/K006460/1, Innovate UK / Natural Environment Research Council (NERC) grant NE/N007352/1 and the TB Alliance. ",2022-05-12,Duncan Lee,https://github.com/duncanplee/CARBayes,TRUE,https://github.com/duncanplee/carbayes,43971,7,2021-09-30T07:17:26Z,6281.571428571428
carbonate,"Create beautiful images of source code using
    'carbon.js'<https://carbon.now.sh/about>.",2020-02-07,Jonathan Sidi,https://github.com/yonicd/carbonate,TRUE,https://github.com/yonicd/carbonate,17460,194,2022-04-27T02:23:04Z,90
card,"Tools that can aid in the assessment of the autonomic regulation 
		of cardiovascular physiology. The aims of this package are to: 1) study 
		electrocardiography (both intervals and morphology) as extensions 
		of signal processing, 2) study circadian rhythms and how it effects 
		autonomic physiology, 3) assess clinical risk of autonomic dysfunction on 
		cardiovascular health through the perspective of epidemiology and causality.
		The analysis of circadian rhythms through cosinor analysis are built upon 
		the methods by Cornelissen (2014) <doi:10.1186/1742-4682-11-16> and 
		Refinetti, Cornelissen, Halberg (2014) <doi:10.1080/09291010600903692>.",2020-09-03,Anish S. Shah,https://github.com/asshah4/card,TRUE,https://github.com/asshah4/card,9366,2,2021-08-18T16:26:34Z,4683
caret,"Misc functions for training and plotting classification and
    regression models.",2022-04-19,Max Kuhn,https://github.com/topepo/caret/,TRUE,https://github.com/topepo/caret,6390798,1445,2022-03-11T23:08:33Z,4422.697577854671
caretForecast,"Recursive time series forecast using Caret infrastructure. 
    The models are selected based on time series cross-validation and 
    forecasting is done recursively.",2022-05-02,Resul Akay,https://github.com/Akai01/caretForecast,TRUE,https://github.com/akai01/caretforecast,2230,3,2022-05-02T22:11:09Z,743.3333333333334
cargo,"A framework is provided to develop R packages using 'Rust' <https://www.rust-lang.org/> with
 minimal overhead, and more wrappers are easily added. Help is provided to run 'Cargo' <https://doc.rust-lang.org/cargo/> in a manner
 consistent with CRAN policies. Rust code can also be embedded directly in an R script. The package is not official, affiliated with,
 nor endorsed by the Rust project.",2022-07-01,David B. Dahl,"https://github.com/dbdahl/cargo-framework (repository),
https://raw.githubusercontent.com/dbdahl/cargo-framework/main/cargo/inst/doc/Writing_R_Extensions_in_Rust.pdf
(paper)",TRUE,https://github.com/dbdahl/cargo-framework,13138,33,2022-07-01T21:02:21Z,398.1212121212121
CARlasso,Algorithms to fit Bayesian Conditional Autoregressive LASSO with automatic and adaptive shrinkage described in Shen and Solis-Lemus (2020) <arXiv:2012.08397>.,2021-08-11,Yunyi Shen,https://github.com/YunyiShen/CAR-LASSO,TRUE,https://github.com/yunyishen/car-lasso,4798,10,2021-08-17T16:28:11Z,479.8
Carlson,"Evaluation of the Carlson elliptic integrals and the
    incomplete elliptic integrals with complex arguments. The
    implementations use Carlson's algorithms <doi:10.1007/BF02198293>.
    Applications of elliptic integrals include probability distributions,
    geometry, physics, mechanics, electrodynamics, statistical mechanics,
    astronomy, geodesy, geodesics on conics, and magnetic field
    calculations.",2022-06-28,Stéphane Laurent,https://github.com/stla/Carlson,TRUE,https://github.com/stla/carlson,13952,0,2022-06-28T13:28:57Z,NA
carrier,"Sending functions to remote processes can be wasteful of
    resources because they carry their environments with them. With
    the carrier package, it is easy to create functions that are
    isolated from their environment. These isolated functions, also
    called crates, print at the console with their total size and can
    be easily tested locally before being sent to a remote.",2018-10-16,Lionel Henry,https://github.com/r-lib/carrier,TRUE,https://github.com/r-lib/carrier,376282,44,2022-03-03T10:08:37Z,8551.863636363636
cartograflow,"Functions to prepare and filter an origin-destination matrix for thematic flow mapping purposes.   
             This comes after Bahoken, Francoise (2016), Mapping flow matrix a contribution, PhD in Geography - Territorial sciences. See Bahoken (2017) <doi:10.4000/netcom.2565>.",2020-07-19,Sylvain Blondeau,https://github.com/fbahoken/cartogRaflow,TRUE,https://github.com/fbahoken/cartograflow,16478,13,2021-10-14T11:50:15Z,1267.5384615384614
cartography,"Create and integrate maps in your R workflow. This package helps 
    to design cartographic representations such as proportional symbols, 
    choropleth, typology, flows or discontinuities maps. It also offers several 
    features that improve the graphic presentation of maps, for instance, map 
    palettes, layout elements (scale, north arrow, title...), labels or legends. 
    See Giraud and Lambert (2017) <doi:10.1007/978-3-319-57336-6_13>.",2021-10-07,Timothée Giraud,https://github.com/riatelab/cartography/,TRUE,https://github.com/riatelab/cartography,91118,380,2021-10-07T12:51:32Z,239.7842105263158
cascadess,"Apply styles to tag elements directly or with the
  .style pronoun. Using the pronoun, styles are created within
  the context of a tag element. Change borders, background colors,
  margins, layouts, and more.",2020-11-30,Nathan Teetor,https://github.com/nteetor/cascadess,TRUE,https://github.com/nteetor/cascadess,6834,18,2022-05-22T12:16:55Z,379.6666666666667
casebase,"Fit flexible and fully parametric hazard regression models to survival data with single event type or multiple 
    competing causes via logistic and multinomial regression. Our formulation allows for arbitrary functional forms 
    of time and its interactions with other predictors for time-dependent hazards and hazard ratios. From the 
    fitted hazard model, we provide functions to readily calculate and plot cumulative incidence and survival 
    curves for a given covariate profile. This approach accommodates any log-linear hazard function of 
    prognostic time, treatment, and covariates, and readily allows for non-proportionality. We also provide 
    a plot method for visualizing incidence density via population time plots. Based on the case-base sampling 
    approach of Hanley and Miettinen (2009) <DOI:10.2202/1557-4679.1125>, Saarela and Arjas (2015) <DOI:10.1111/sjos.12125>, 
    and Saarela (2015) <DOI:10.1007/s10985-015-9352-x>.",2021-10-20,Sahir Bhatnagar,http://sahirbhatnagar.com/casebase/,TRUE,https://github.com/sahirbhatnagar/casebase,46519,5,2021-10-20T15:11:04Z,9303.8
casen,"Funciones para realizar estadistica descriptiva e inferencia con el
 disenio complejo de la Encuesta CASEN (Encuesta de Caracterizacion 
 Socio-Economica). Incluye datasets que permiten armonizar los codigos de 
 comunas que cambian entre anios y permite convertir a los codigos oficiales de 
 SUBDERE.
 (Functions to compute descriptive and inferential statistics with CASEN
 Survey [Socio-Economic Characterization Survey] complex design. Includes 
 datasets to harmonize commune codes that change across years and allows to 
 convert to official SUBDERE codes.)",2022-06-21,Mauricio Vargas,https://pacha.dev/casen/,TRUE,https://github.com/pachadotdev/casen,14743,7,2022-06-21T06:34:47Z,2106.1428571428573
CAST,"Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. CAST includes functions to improve spatial or spatial-temporal modelling tasks using 'caret'. To decrease spatial overfitting and to improve model performances, the package implements a forward feature selection that selects suitable predictor variables in view to their contribution to spatial or spatial-temporal model performance. CAST further includes functionality to estimate the (spatial) area of applicability of prediction models. Methods are described in Meyer et al. (2018) <doi:10.1016/j.envsoft.2017.12.001>; Meyer et al. (2019) <doi:10.1016/j.ecolmodel.2019.108815>; Meyer and Pebesma (2021) <doi:10.1111/2041-210X.13650>.",2022-03-17,Hanna Meyer,"https://github.com/HannaMeyer/CAST,
https://hannameyer.github.io/CAST/",TRUE,https://github.com/hannameyer/cast,30372,65,2022-06-24T11:47:52Z,467.26153846153846
cat2cat,"
  There are offered automatic methods to map a categorical variable according to a specific mappings across different time points. 
  The main rule is to replicate the observation if it could be assign to a few categories.
  Then using simple frequencies or statistical methods to approximate probabilities of being assign to each of them.
  This algorithm was invented and implemented in the paper by (Nasinski, Majchrowska and Broniatowska (2020) <doi:10.24425/cejeme.2020.134747>).",2022-06-08,Maciej Nasinski,"https://github.com/Polkas/cat2cat,
https://polkas.github.io/cat2cat/",TRUE,https://github.com/polkas/cat2cat,15036,2,2022-06-09T09:58:19Z,7518
CatastRo,"Access public spatial data available under the 'INSPIRE'
    directive. Tools for downloading references and addresses of
    properties, as well as map images.",2022-05-27,Ángel Delgado Panadero,"https://ropenspain.github.io/CatastRo/,
https://github.com/rOpenSpain/CatastRo",TRUE,https://github.com/ropenspain/catastro,1730,11,2022-07-04T16:28:43Z,157.27272727272728
categoryEncodings,"Simple, fast, and automatic encodings for category data using 
             a data.table backend. Most of the methods are an implementation 
             of ""Sufficient Representation for Categorical Variables"" by
             Johannemann, Hadad, Athey, Wager (2019) <arXiv:1908.09874>,
             particularly their mean, sparse principal component analysis, 
             low rank representation, and multinomial logit encodings.",2020-03-02,Juraj Szitas,https://github.com/JSzitas/categoryEncodings,TRUE,https://github.com/jszitas/categoryencodings,12203,3,2021-09-25T22:23:28Z,4067.6666666666665
cati,"Detect and quantify community assembly processes using trait values of individuals or populations, the T-statistics and other metrics, and dedicated null models.",2022-02-25,Adrien Taudiere,https://github.com/adrientaudiere/cati,TRUE,https://github.com/adrientaudiere/cati,16235,8,2022-04-09T12:36:21Z,2029.375
catIrt,"Functions designed to simulate data that conform to basic
          unidimensional IRT models (for now 3-parameter binary response models
          and graded response models) along with Post-Hoc CAT simulations of
          those models given various item selection methods, ability estimation
          methods, and termination criteria. See
          Wainer (2000) <doi:10.4324/9781410605931>,
          van der Linden & Pashley (2010) <doi:10.1007/978-0-387-85461-8_1>,
          and Eggen (1999) <doi:10.1177/01466219922031365> for more details.",2022-05-25,Steven Nydick,https://github.com/swnydick/catIrt,TRUE,https://github.com/swnydick/catirt,18162,1,2022-05-25T22:16:42Z,18162
catmaply,"Methods and plotting functions for displaying categorical data on an 
             interactive heatmap using 'plotly'. Provides functionality for strictly 
             categorical heatmaps, heatmaps illustrating categorized continuous data 
             and annotated heatmaps. Also, there are various options to interact with the x-axis
             to prevent overlapping axis labels, e.g. via simple sliders or range sliders. 
             Besides the viewer pane, resulting plots can be saved as a standalone HTML file, 
             embedded in 'R Markdown' documents or in a 'Shiny' app.",2020-09-07,Yves Mauron,https://github.com/VerkehrsbetriebeZuerich/catmaply,TRUE,https://github.com/verkehrsbetriebezuerich/catmaply,9074,14,2022-02-23T16:36:40Z,648.1428571428571
catSurv,"Provides methods of computerized adaptive testing for survey researchers.  See Montgomery and Rossiter (2020) <doi:10.1093/jssam/smz027>. Includes functionality for data fit with the classic item response methods including the latent trait model, Birnbaum`s three parameter model, the graded response, and the generalized partial credit model.  Additionally, includes several ability parameter estimation and item selection routines.  During item selection, all calculations are done in compiled C++ code.",2021-09-24,Erin Rossiter,NA,TRUE,https://github.com/erossiter/catsurv,17167,8,2021-10-20T16:02:31Z,2145.875
causact,"Accelerate Bayesian analytics workflows in 'R' through interactive modelling,
    visualization, and inference. Define probabilistic graphical models using directed
    acyclic graphs (DAGs) as a unifying language for business stakeholders, statisticians, 
    and programmers. This package relies on the sleek and elegant 'greta' package for 
    Bayesian inference. 'greta', in turn, is an interface into 'TensorFlow' from 'R'. 
    Install 'greta' using instructions available here: <https://www.causact.com/install-tensorflow-greta-and-causact.html>.
    See <https://github.com/flyaflya/causact> or <https://www.causact.com/> for more documentation.",2022-06-14,Adam Fleischhacker,"https://github.com/flyaflya/causact, https://www.causact.com/",TRUE,https://github.com/flyaflya/causact,13880,25,2022-06-14T16:06:56Z,555.2
causaldata,"Example data sets to run the example
    problems from causal inference textbooks. Currently, contains data
    sets for Huntington-Klein, Nick (2021) ""The Effect"" <https://theeffectbook.net>,
    Cunningham, Scott (2021, ISBN-13: 978-0-300-25168-5) ""Causal Inference: The Mixtape"", 
    and Hernán, Miguel and James Robins (2020) ""Causal Inference: What If"" 
    <https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/>.",2021-12-01,Nick Huntington-Klein,https://github.com/NickCH-K/causaldata,TRUE,https://github.com/nickch-k/causaldata,8175,92,2022-03-03T07:44:17Z,88.8586956521739
causalDisco,"Various tools for inferring causal models from observational data. The package 
    includes an implementation of the temporal Peter-Clark (TPC) algorithm. Petersen, Osler 
    and Ekstrøm (2021) <doi:10.1093/aje/kwab087>. It also includes general tools
    for evaluating differences in adjacency matrices, which can be used for evaluating
    performance of causal discovery procedures. ",2022-05-12,Anne Helby Petersen,https://github.com/annennenne/causalDisco,TRUE,https://github.com/annennenne/causaldisco,489,10,2022-06-27T10:15:17Z,48.9
causaleffect,"Functions for identification and transportation of causal effects.
 Provides a conditional causal effect identification algorithm (IDC) by
 Shpitser, I. and Pearl, J. (2006)
 <http://ftp.cs.ucla.edu/pub/stat_ser/r329-uai.pdf>, an algorithm for
 transportability from multiple domains with limited experiments by
 Bareinboim, E. and Pearl, J. (2014)
 <http://ftp.cs.ucla.edu/pub/stat_ser/r443.pdf> and a selection bias recovery
 algorithm by Bareinboim, E. and Tian, J. (2015)
 <http://ftp.cs.ucla.edu/pub/stat_ser/r445.pdf>. All of the previously mentioned
 algorithms are based on a causal effect identification algorithm by
 Tian , J. (2002) <http://ftp.cs.ucla.edu/pub/stat_ser/r309.pdf>.",2021-06-14,Santtu Tikka,https://github.com/santikka/causaleffect/,TRUE,https://github.com/santikka/causaleffect,24332,21,2021-11-10T14:46:05Z,1158.6666666666667
CausalGPS,"Provides a framework for estimating causal effects of a continuous 
    exposure using observational data, and implementing matching and weighting 
    on the generalized propensity score.
    Wu, X., Mealli, F., Kioumourtzoglou, M.A., Dominici, F. and Braun, D., 
    2018. Matching on generalized propensity scores with continuous exposures. 
    arXiv preprint <arXiv:1812.06575>.",2022-06-22,Naeem Khoshnevis  (<https://orcid.org/0000-0003-4315-1426>,https://github.com/fasrc/CausalGPS,TRUE,https://github.com/fasrc/causalgps,4773,16,2022-06-23T00:20:20Z,298.3125
CausalMBSTS,"Infers the causal effect of an intervention on a multivariate response through the use of Multivariate 
    Bayesian Structural Time Series models (MBSTS) as described in Menchetti & Bojinov (2020) <arXiv:2006.12269>. 
    The package also includes functions for model building and forecasting.  ",2021-10-05,Fiammetta Menchetti,NA,TRUE,https://github.com/fmenchetti/causalmbsts,7900,14,2021-09-26T14:11:30Z,564.2857142857143
CausalModels,"
  Provides an array of statistical models common in causal inference such as 
  standardization, IP weighting, propensity matching, outcome regression, and doubly-robust 
  estimators. Estimates of the average treatment effects from each model are given with the 
  standard error and a 95% Wald confidence interval (Hernan, Robins (2020) <https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/>).",2022-05-30,Joshua Anderson,https://github.com/ander428/CausalModels,TRUE,https://github.com/ander428/causalmodels,314,5,2022-05-27T20:45:07Z,62.8
causaloptim,"When causal quantities are not identifiable from the observed data, it still may be possible 
            to bound these quantities using the observed data. We outline a class of problems for which the 
            derivation of tight bounds is always a linear programming problem and can therefore, at least 
            theoretically, be solved using a symbolic linear optimizer. We extend and generalize the 
            approach of Balke and Pearl (1994) <doi:10.1016/B978-1-55860-332-5.50011-0> and we provide 
            a user friendly graphical interface for setting up such problems via directed acyclic 
            graphs (DAG), which only allow for problems within this class to be depicted. The user can 
            then define linear constraints to further refine their assumptions to meet their specific 
            problem, and then specify a causal query using a text interface. The program converts this 
            user defined DAG, query, and constraints, and returns tight bounds. The bounds can be 
            converted to R functions to evaluate them for specific datasets, and to latex code for 
            publication. The methods and proofs of tightness and validity of the bounds are described in
            a preprint by Sachs, Gabriel, and Sjölander (2021) 
            <https://sachsmc.github.io/causaloptim/articles/CausalBoundsMethods.pdf>.",2022-03-25,Michael C Sachs,https://github.com/sachsmc/causaloptim,TRUE,https://github.com/sachsmc/causaloptim,14871,12,2022-06-30T09:11:20Z,1239.25
causalPAF,"Calculates population attributable fraction causal effects.
    The 'causalPAF' package contains a suite of functions for causal
    analysis calculations of population attributable fractions (PAF) given
    a causal diagram which apply both: Pathway-specific population
    attributable fractions (PS-PAFs) O’Connell and Ferguson (2020) 
    <doi:10.1101/2020.10.15.20212845> and Sequential population
    attributable fractions Ferguson, O’Connell, and O’Donnell (2020) 
    <doi:10.1186/s13690-020-00442-x>. 
    Results are presentable in both table and plot format.",2021-10-26,Maurice OConnell,https://github.com/MauriceOConnell/causalPAF,TRUE,https://github.com/mauriceoconnell/causalpaf,3119,0,2021-10-26T13:22:29Z,NA
CausCor,"This tool performs pairwise correlation analysis and estimate causality.
    Particularly, it is useful for detecting the metabolites that would be altered by the gut bacteria.",2022-05-24,Tomomi Sugiyama,https://github.com/sugym/CausCor,TRUE,https://github.com/sugym/causcor,601,1,2022-05-24T08:16:13Z,601
CBDA,"Classification performed on Big Data. It uses concepts from compressive sensing, and implements ensemble predictor (i.e., 'SuperLearner') and knockoff filtering as the main machine learning and feature mining engines.",2018-04-16,Simeone Marino,https://github.com/SOCR/CBDA,TRUE,https://github.com/socr/cbda,13292,14,2022-01-31T15:56:26Z,949.4285714285714
cbl,"Methods for learning causal relationships among a set of
    foreground variables X based on signals from a (potentially much
    larger) set of background variables Z, which are known non-descendants
    of X. The confounder blanket learner (CBL) uses sparse regression
    techniques to simultaneously perform many conditional independence
    tests, with complementary pairs stability selection to guarantee
    finite sample error control. CBL is sound and complete with respect to
    a so-called ""lazy oracle"", and works with both linear and nonlinear
    systems. For details, see Watson & Silva (2022) <arXiv:2205.05715>.",2022-06-17,David Watson,https://github.com/dswatson/cbl,TRUE,https://github.com/dswatson/cbl,316,1,2022-06-17T09:20:20Z,316
CCAMLRGIS,"Loads and creates spatial data, including layers and tools that are relevant
    to the activities of the Commission for the Conservation of Antarctic Marine Living
    Resources. Provides two categories of functions: load functions and create functions.
    Load functions are used to import existing spatial layers from the online CCAMLR GIS
    such as the ASD boundaries. Create functions are used to create layers from user data
    such as polygons and grids.",2022-05-10,Stephane Thanassekos,https://github.com/ccamlr/CCAMLRGIS,TRUE,https://github.com/ccamlr/ccamlrgis,16513,5,2022-05-10T02:40:19Z,3302.6
ccdf,"Complex hypothesis testing through conditional cumulative distribution function estimation.
             Method is detailed in: Gauthier M, Agniel D, Thiebaut R & Hejblum BP (2020). 
             ""Distribution-free complex hypothesis testing for single-cell RNA-seq differential expression analysis"", BioRxiv <doi:10.1101/2021.05.21.445165>.",2021-09-24,Marine Gauthier,NA,TRUE,https://github.com/mgauth/ccdf,3535,1,2021-12-06T17:04:45Z,3535
cchsflow,"Supporting the use of the Canadian Community Health Survey 
             (CCHS) by transforming variables from each cycle into harmonized, 
             consistent versions that span survey cycles (currently, 2001 to 
             2018). CCHS data used in this library is accessed and adapted in 
             accordance to the Statistics Canada Open Licence Agreement. This 
             package uses rec_with_table(), which was developed from 'sjmisc' 
             rec(). Lüdecke D (2018). ""sjmisc: Data and Variable Transformation 
             Functions"". Journal of Open Source Software, 3(26), 754. 
             <doi:10.21105/joss.00754>.",2022-05-26,Kitty Chen,https://github.com/Big-Life-Lab/cchsflow,TRUE,https://github.com/big-life-lab/cchsflow,15743,10,2022-05-26T13:06:59Z,1574.3
ccmEstimator,"Functions to perform comparative causal mediation analysis to compare the mediation effects of different treatments via a common mediator. Results contain the estimates and confidence intervals for the two comparative causal mediation analysis estimands, as well as the ATE and ACME for each treatment. Functions provided in the package will automatically assess the comparative causal mediation analysis scope conditions (i.e. for each comparative causal mediation estimand, a numerator and denominator that are both estimated with the desired statistical significance and of the same sign). Results will be returned for each comparative causal mediation estimand only if scope conditions are met for it. See details in Bansak(2020)<doi:10.1017/pan.2019.31>.",2021-09-28,Xiaohan Wu,https://github.com/xiw021/ccmEstimator,TRUE,https://github.com/xiw021/ccmestimator,3505,0,2021-09-14T16:29:05Z,NA
ccrtm,"A set of radiative transfer models to quantitatively describe the absorption, reflectance and transmission of solar energy in vegetation, and model remotely sensed spectral signatures of vegetation at distinct spatial scales (leaf,canopy and stand). The main principle behind ccrtm is that many radiative transfer models can form a coupled chain, basically models that feed into each other in a linked chain (from leaf, to canopy, to stand, to atmosphere). It allows the simulation of spectral datasets in the solar spectrum (400-2500nm) using leaf models as PROSPECT5, 5b, and D which can be coupled with canopy models as 'FLIM', 'SAIL' and 'SAIL2'. Currently, only a simple atmospheric model ('skyl') is implemented. Jacquemoud et al 2008 provide the most comprehensive overview of these models <doi:10.1016/j.rse.2008.01.026>. ",2021-02-26,Marco D. Visser,https://github.com/MarcoDVisser/ccrtm,TRUE,https://github.com/marcodvisser/ccrtm,5591,7,2021-12-09T09:41:08Z,798.7142857142857
ccTensor,"CUR/CX decomposition factorizes a matrix into two factor matrices and Multidimensional CX Decomposition factorizes a tensor into a core tensor and some factor matrices. See the reference section of GitHub README.md <https://github.com/rikenbit/ccTensor>, for details of the methods.",2021-08-12,Koki Tsuyuzaki,https://github.com/rikenbit/ccTensor,TRUE,https://github.com/rikenbit/cctensor,3511,0,2021-08-02T04:59:36Z,NA
CDatanet,"Likelihood-based estimation and data generation from a class of models used to estimate peer effects on count data by controlling for the network endogeneity. This class includes count data models with social interactions (Houndetoungan 2022; <doi:10.2139/ssrn.3721250>), spatial tobit models (Xu and Lee 2015; <doi:10.1016/j.jeconom.2015.05.004>), and spatial linear-in-means models (Lee 2004; <doi:10.1111/j.1468-0262.2004.00558.x>).  ",2022-04-05,Elysée Aristide Houndetoungan,https://github.com/ahoundetoungan/CDatanet,TRUE,https://github.com/ahoundetoungan/cdatanet,6148,0,2022-04-05T00:34:16Z,NA
cdcatR,"Provides a set of functions for conducting cognitive diagnostic computerized adaptive testing applications (Chen, 2009) <DOI:10.1007/s11336-009-9123-2>). It includes different item selection rules such us the global discrimination index (Kaplan, de la Torre, and Barrada (2015) <DOI:10.1177/0146621614554650>) and the nonparametric selection method (Chang, Chiu, and Tsai (2019) <DOI:10.1177/0146621618813113>), as well as several stopping rules. Functions for generating item banks and responses are also provided. To guide item bank calibration, model comparison at the item level can be conducted using the two-step likelihood ratio test statistic by Sorrel, de la Torre, Abad and Olea (2017) <DOI:10.1027/1614-2241/a000131>.",2022-05-25,Miguel A. Sorrel,https://github.com/miguel-sorrel/cdcatR,TRUE,https://github.com/miguel-sorrel/cdcatr,11127,4,2022-05-25T09:42:52Z,2781.75
cdcsis,"Conditional distance correlation <doi:10.1080/01621459.2014.993081> is a novel conditional dependence measurement of two multivariate random variables given a confounding variable. This package provides conditional distance correlation, performs the conditional distance correlation sure independence screening procedure for ultrahigh dimensional data <http://www3.stat.sinica.edu.tw/statistica/J28N1/J28N114/J28N114.html>, and conducts conditional distance covariance test for conditional independence assumption of two multivariate variable.",2019-07-10,Wenhao Hu,https://github.com/Mamba413/cdcsis,TRUE,https://github.com/mamba413/cdcsis,17248,5,2022-01-10T14:18:29Z,3449.6
CDM,"
    Functions for cognitive diagnosis modeling and multidimensional item response modeling 
    for dichotomous and polytomous item responses. This package enables the estimation of 
    the DINA and DINO model (Junker & Sijtsma, 2001, <doi:10.1177/01466210122032064>),
    the multiple group (polytomous) GDINA model (de la Torre, 2011, 
    <doi:10.1007/s11336-011-9207-7>), the multiple choice DINA model (de la Torre, 2009, 
    <doi:10.1177/0146621608320523>), the general diagnostic model (GDM; von Davier, 2008, 
    <doi:10.1348/000711007X193957>), the structured latent class model (SLCA; Formann, 1992, 
    <doi:10.1080/01621459.1992.10475229>) and regularized latent class analysis 
    (Chen, Li, Liu, & Ying, 2017, <doi:10.1007/s11336-016-9545-6>). 
    See George, Robitzsch, Kiefer, Gross, and Uenlue (2017) <doi:10.18637/jss.v074.i02> 
    or Robitzsch and George (2019, <doi:10.1007/978-3-030-05584-4_26>)     
    for further details on estimation and the package structure.
    For tutorials on how to use the CDM package see 
    George and Robitzsch (2015, <doi:10.20982/tqmp.11.3.p189>) as well as
    Ravand and Robitzsch (2015).",2022-05-13,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/CDM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/cdm,124818,18,2022-05-13T16:26:42Z,6934.333333333333
cdmTools,"Provides useful tools for cognitive diagnosis modeling (CDM). The package includes functions for empirical Q-matrix estimation and validation, such as the Hull method (Nájera, Sorrel, de la Torre, & Abad, 2021, <doi:10.1111/bmsp.12228>) and the discrete factor loading method (Wang, Song, & Ding, 2018, <doi:10.1007/978-3-319-77249-3_29>). It also contains dimensionality assessment procedures for CDM, including parallel analysis and automated fit comparison as explored in Nájera, Abad, and Sorrel (2021, <doi:10.3389/fpsyg.2021.614470>). Other relevant methods and features for CDM applications, such as the general nonparametric classification method (Chiu et al., 2018; <doi:10.1007/s11336-017-9595-4>) and corrected estimation of the classification accuracy via multiple imputation (Kreitchmann et al., 2022) are also available. Lastly, the package provides some useful functions for CDM simulation studies, such as random Q-matrix generation and detection of complete/identified Q-matrices.",2022-05-24,Pablo Nájera,https://github.com/pablo-najera/cdmTools,TRUE,https://github.com/pablo-najera/cdmtools,4497,2,2022-07-06T10:36:27Z,2248.5
CEDARS,"Streamlined annotation pipeline for collection and aggregation of time-to-event data in retrospective clinical studies. 'CEDARS' aims to systematize and accelerate the review of electronic health record (EHR) corpora. It accomplishes those goals by deploying natural language processing as a tool to assist detection and characterization of clinical events by human abstractors. The online user manual presents the necessary steps to install 'CEDARS', process EHR corpora and obtain clinical event dates: <https://cedars.io>.",2021-02-07,Simon Mantha,"https://cedars.io (main) https://github.com/simon-hans/CEDARS
(devel)",TRUE,https://github.com/simon-hans/cedars,8461,3,2021-10-22T21:06:39Z,2820.3333333333335
cellpypes,"Annotate single-cell RNA sequencing data manually based on
    marker gene thresholds.
    Find cell type rules (gene+threshold) through exploration,
    use the popular piping operator '%>%' to reconstruct complex
    cell type hierarchies.
    'cellpypes' models technical noise to find positive and negative cells for
    a given expression threshold and returns cell type labels or pseudobulks.
    Cite this package as Frauhammer (2022) <doi:10.5281/zenodo.6555728> and
    visit <https://github.com/FelixTheStudent/cellpypes> for tutorials and newest
    features.",2022-05-19,Felix Frauhammer,https://github.com/FelixTheStudent/cellpypes,TRUE,https://github.com/felixthestudent/cellpypes,419,33,2022-06-29T22:25:07Z,12.696969696969697
censable,"Creates a common framework for organizing, naming, and gathering population, age, race, and ethnicity data from the Census Bureau. Accesses the API <https://www.census.gov/data/developers/data-sets.html> via the package tidycensus. Provides tools for adding information to existing data to line up with Census data.",2021-10-05,Christopher T. Kenny,"https://www.christophertkenny.com/censable/,
https://github.com/christopherkenny/censable",TRUE,https://github.com/christopherkenny/censable,5272,6,2022-05-05T14:40:33Z,878.6666666666666
censo2017,"Provee un acceso conveniente a mas de 17 millones de registros
    de la base de datos del Censo 2017. Los datos fueron importados desde
    el DVD oficial del INE usando el Convertidor REDATAM creado por Pablo De
    Grande. Esta paquete esta documentado intencionalmente en castellano
    asciificado para que funcione sin problema en diferentes plataformas.
    (Provides convenient access to more than 17 million records from the
    Chilean Census 2017 database. The datasets were imported from the official
    DVD provided by the Chilean National Bureau of Statistics by using the
    REDATAM converter created by Pablo De Grande and in addition it includes the
    maps accompanying these datasets.)",2021-08-16,Mauricio Vargas,https://docs.ropensci.org/censo2017/,TRUE,https://github.com/ropensci/censo2017,8048,23,2022-06-20T04:13:27Z,349.9130434782609
censored,"Engines for survival models from the 'parsnip' package. These 
    include parametric models (e.g., Jackson (2016) <doi:10.18637/jss.v070.i08>),
    semi-parametric (e.g., Simon et al (2011) <doi:10.18637/jss.v039.i05>), and
    tree-based models (e.g., Buehlmann and Hothorn (2007) <doi:10.1214/07-STS242>).",2022-06-22,Emil Hvitfeldt,https://github.com/tidymodels/censored,TRUE,https://github.com/tidymodels/censored,322,85,2022-06-22T21:57:23Z,3.788235294117647
censusapi,"A wrapper for the U.S. Census Bureau APIs that returns data frames of 
	Census data and metadata. Available datasets include the 
	Decennial Census, American Community Survey, Small Area Health Insurance Estimates,
	Small Area Income and Poverty Estimates, Population Estimates and Projections, and more.",2020-10-14,Hannah Recht,https://github.com/hrecht/censusapi,TRUE,https://github.com/hrecht/censusapi,58860,131,2022-01-23T01:28:56Z,449.31297709923666
censusxy,"Provides access to the U.S. Census Bureau's A.P.I for matching American
    street addresses with their longitude and latitude. This includes both single address matching
    as well as batch functionality for multiple addresses. Census geographies can be appended to 
    addresses if desired, and reverse geocoding of point locations to census geographies is also 
    supported. ",2022-05-30,Christopher Prener,https://chris-prener.github.io/censusxy/,TRUE,https://github.com/chris-prener/censusxy,21039,15,2022-05-31T00:51:48Z,1402.6
CEOdata,"Easy and convenient access to the datasets of the
  ""Centre d'Estudis d'Opinio"", the Catalan institution for polling and public
  opinion. The package uses the data stored in the servers of the CEO and returns
  it in a tidy format.",2022-05-17,Xavier Fernández-i-Marín,"https://ceo.gencat.cat/ca/inici/,
https://github.com/ceopinio/CEOdata/",TRUE,https://github.com/ceopinio/ceodata,1516,1,2022-05-18T10:00:56Z,1516
cepreader,"Read Condensed Cornell Ecology Program ('CEP') and legacy
    'CANOCO' files into R data frames.",2022-03-30,Jari Oksanen,"https://cran.r-project.org/,
https://github.com/vegandevs/cepreader/",TRUE,https://github.com/vegandevs/cepreader,17756,0,2021-12-14T12:23:22Z,NA
Certara.R,"A convenient set of wrapper functions to install
    pharmacometric packages and Shiny applications developed by Certara
    PMX and Integrated Drug Development (iDD). The functions ensure the
    successful installation of packages from non-standard repositories.",2022-02-11,James Craig,https://github.com/certara/R-Certara,TRUE,https://github.com/certara/r-certara,1622,4,2022-07-07T17:41:35Z,405.5
cesR,"Makes accessing and loading the Canadian Election Study (<http://www.ces-eec.ca/>, <https://ces-eec.arts.ubc.ca/>, <https://search1.odesi.ca/#/>) surveys into the R workspace more efficient by 
  downloading a requested survey and loading it as a data object. This removes the need to locate, download, load, 
  and change working directories when working with the Canadian Election Study surveys.",2021-11-23,Paul A. Hodgetts,https://hodgettsp.github.io/cesR/,TRUE,https://github.com/hodgettsp/cesr,2261,1,2021-11-24T19:02:31Z,2261
cfbfastR,"A utility to quickly obtain clean and tidy college football
    data. Serves as a wrapper around the
    <https://collegefootballdata.com/> API and provides functions to
    access live play by play and box score data from ESPN
    <https://www.espn.com> when available. It provides users the
    capability to access a plethora of endpoints, and supplement that data
    with additional information (Expected Points Added/Win Probability
    added).",2022-06-13,Saiem Gilani,"https://cfbfastR.sportsdataverse.org/,
https://github.com/sportsdataverse/cfbfastR",TRUE,https://github.com/sportsdataverse/cfbfastr,4106,27,2022-06-10T19:07:03Z,152.07407407407408
cfda,"Package for the analysis of categorical functional data. 
  The main purpose is to compute an encoding (real functional variable) for each state <doi:10.3390/math9233074>. 
  It also provides functions to perform basic statistical analysis on categorical functional data. ",2022-03-07,Quentin Grimonprez,https://modal-inria.github.io/cfda/,TRUE,https://github.com/modal-inria/cfda,6875,1,2022-07-03T14:01:24Z,6875
cffr,"The Citation File Format version 1.2.0
    <doi:10.5281/zenodo.5171937> is a human and machine readable file
    format which provides citation metadata for software. This package
    provides core utilities to generate and validate this metadata.",2022-04-08,Diego Hernangómez,"https://docs.ropensci.org/cffr/, https://github.com/ropensci/cffr",TRUE,https://github.com/ropensci/cffr,4052,15,2022-06-09T22:01:47Z,270.1333333333333
cfid,"Facilitates the identification of counterfactual queries in
 structural causal models via the ID* and IDC* algorithms
 by Shpitser, I. and Pearl, J. (2008)
 <https://jmlr.org/papers/v9/shpitser08a.html>. Provides a simple interface
 for defining causal graphs and counterfactual conjunctions. Construction
 of parallel worlds graphs and counterfactual graphs is done automatically
 based on the counterfactual query and the causal graph.",2021-06-10,Santtu Tikka,https://github.com/santikka/cfid,TRUE,https://github.com/santikka/cfid,3383,1,2021-08-18T15:12:05Z,3383
ch,"The solution to some common problems is proposed, 
     as well as a summary of some small functions. In particular, 
     it provides a useful function for some problems in chemistry.
     For example, monoa(), monob() and mono() function can be used 
     to calculate The pH of weak acid/base. 
     The ggpng() function can save the PNG format with transparent background. 
     The period_table() function will show the periodic table. Also the
     show_ruler() function will show the ruler.
     The show_color() function is funny and easier to show colors.
      I also provide the symb() function to generate multiple symbols at once.
     The csv2vcf() function provides an easy method to generate a file.
     The sym2poly() and sym2coef() function can extract coefficients from 
     polynomials.",2021-07-09,Hailong Chai [aut],https://github.com/tsiamut/ch,TRUE,https://github.com/tsiamut/ch,4937,2,2021-11-11T03:09:54Z,2468.5
ChainLadder,"Various statistical methods and models which are
    typically used for the estimation of outstanding claims reserves
    in general insurance, including those to estimate the claims
    development result as required under Solvency II.",2022-01-09,Markus Gesmann,"https://github.com/mages/ChainLadder,
https://mages.github.io/ChainLadder/",TRUE,https://github.com/mages/chainladder,85827,58,2022-07-02T11:41:09Z,1479.7758620689656
chandwich,"Performs adjustments of a user-supplied independence loglikelihood 
    function using a robust sandwich estimator of the parameter covariance 
    matrix, based on the methodology in Chandler and Bate (2007) 
    <doi:10.1093/biomet/asm015>.  This can be used for cluster correlated data 
    when interest lies in the parameters of the marginal distributions or for 
    performing inferences that are robust to certain types of model 
    misspecification.  Functions for profiling the adjusted loglikelihoods are 
    also provided, as are functions for calculating and plotting confidence 
    intervals, for single model parameters, and confidence regions, for pairs 
    of model parameters.  Nested models can be compared using an adjusted 
    likelihood ratio test.",2021-10-30,Paul J. Northrop,"https://paulnorthrop.github.io/chandwich/,
https://github.com/paulnorthrop/chandwich",TRUE,https://github.com/paulnorthrop/chandwich,18203,3,2022-04-02T01:21:27Z,6067.666666666667
changepoint,"Implements various mainstream and specialised changepoint methods for finding single and multiple changepoints within data.  Many popular non-parametric and frequentist methods are included.  The cpt.mean(), cpt.var(), cpt.meanvar() functions should be your first point of call.",2022-03-14,Rebecca Killick,https://github.com/rkillick/changepoint/,TRUE,https://github.com/rkillick/changepoint,336549,102,2021-09-13T12:08:00Z,3299.5
changepoint.influence,"Allows users to input their data, segmentation and function used for the segmentation (and additional arguments) and the package calculates the influence of the data on the changepoint locations, see Wilms et al. (2021) <arXiv:2107.10572>.  Currently this can only be used with the changepoint package functions to identify changes, but we plan to extend this.  There are options for different types of graphics to assess the influence.",2021-08-04,Rebecca Killick,https://github.com/rkillick/changepoint.influence/,TRUE,https://github.com/rkillick/changepoint.influence,4013,0,2021-08-03T14:52:13Z,NA
changepoints,"Performs a series of offline and/or online change-point detection algorithms for 1) univariate mean; 2) univariate polynomials; 3) univariate and multivariate nonparametric settings; 4) high-dimensional covariances; 5) high-dimensional networks with and without missing values; 6) high-dimensional linear regression models; 7) high-dimensional vector autoregressive models; 8) high-dimensional self exciting point processes; 9) dependent dynamic nonparametric random dot product graphs; 10) univariate mean against adversarial attacks. For more informations, see <arXiv:1810.09498>; <arXiv:2006.03283>; <arXiv:2007.09910>; <arXiv:1905.10019>; <arXiv:1910.13289>; <arXiv:1712.09912>; <arXiv:1809.09602>; <arXiv:1911.07494>; <arXiv:2101.05477>; <arXiv:2010.10410>; <arXiv:1909.06359>; <arXiv:2006.03572>; <arXiv:2110.06450>; <arXiv:2105.10417>.",2021-12-10,Haotian Xu,https://github.com/HaotianXu/changepoints,TRUE,https://github.com/haotianxu/changepoints,2118,8,2022-03-09T23:35:15Z,264.75
changer,Changing the name of an existing R package is annoying but common task especially in the early stages of package development. This package (mostly) automates this task.,2022-05-03,Jouni Helske,https://github.com/helske/changer,TRUE,https://github.com/helske/changer,14267,42,2022-05-03T10:15:03Z,339.6904761904762
chantrics,"Adjusts the loglikelihood of common econometric models for
    clustered data based on the estimation process suggested in 
    Chandler and Bate (2007) <doi:10.1093/biomet/asm015>, using the 'chandwich' 
    package <https://cran.r-project.org/package=chandwich>, and provides 
    convenience functions for inference on the adjusted models. ",2021-09-29,Theo Bruckbauer,"https://chantrics.theobruckbauer.eu,
https://github.com/tbruckbauer/chantrics",TRUE,https://github.com/tbruckbauer/chantrics,3041,0,2021-09-28T14:02:45Z,NA
cheatsheet,A simple package to grab cheat sheets and save them to your local computer.,2021-04-13,Brad Lindblad,https://bradlindblad.github.io/cheatsheet/,TRUE,https://github.com/bradlindblad/cheatsheet,14269,6,2022-02-06T03:12:42Z,2378.1666666666665
checkmate,"Tests and assertions to perform frequent argument checks. A
    substantial part of the package was written in C to minimize any worries
    about execution time overhead.",2022-04-21,Michel Lang,"https://mllg.github.io/checkmate/,
https://github.com/mllg/checkmate",TRUE,https://github.com/mllg/checkmate,9632532,218,2022-06-13T15:55:16Z,44185.92660550459
checkpoint,"The goal of checkpoint is to solve the problem of package
    reproducibility in R. Specifically, checkpoint allows you to install packages
    as they existed on CRAN on a specific snapshot date as if you had a CRAN time
    machine. To achieve reproducibility, the checkpoint() function installs the
    packages required or called by your project and scripts to a local library
    exactly as they existed at the specified point in time. Only those packages
    are available to your project, thereby avoiding any package updates that came
    later and may have altered your results. In this way, anyone using checkpoint's
    checkpoint() can ensure the reproducibility of your scripts or projects at any
    time. To create the snapshot archives, once a day (at midnight UTC) Microsoft
    refreshes the Austria CRAN mirror on the ""Microsoft R Archived Network""
    server (<https://mran.microsoft.com/>). Immediately after completion
    of the rsync mirror process, the process takes a snapshot, thus creating the
    archive. Snapshot archives exist starting from 2014-09-17.",2022-01-28,Folashade Daniel,https://github.com/RevolutionAnalytics/checkpoint,TRUE,https://github.com/revolutionanalytics/checkpoint,70998,151,2022-01-26T17:11:23Z,470.18543046357615
checkr,"Expressive, assertive, pipe-friendly functions 
  to check the properties of common R objects.
  In the case of failure the functions issue informative error messages.",2019-04-25,Joe Thorley,https://github.com/poissonconsulting/checkr,TRUE,https://github.com/poissonconsulting/checkr,27893,12,2021-11-13T00:08:38Z,2324.4166666666665
cheddar,"Provides a flexible, extendable representation of an ecological community and a range of functions for analysis and visualisation, focusing on food web, body mass and numerical abundance data. Allows inter-web comparisons such as examining changes in community structure over environmental, temporal or spatial gradients.",2020-02-13,Lawrence Hudson with contributions from Dan Reuman and Rob Emerson,https://github.com/quicklizard99/cheddar/,TRUE,https://github.com/quicklizard99/cheddar,28490,12,2021-09-02T15:22:31Z,2374.1666666666665
cheem,"Given a tree-based model, calculate the tree SHAP 
    <arXiv:1802.03888>; <https://github.com/ModelOriented/treeshap> 
    local explanation of every observation. View the data space, explanation 
    space, and residual plot as ensemble graphic interactive on a shiny 
    application. After an observation of interest is identified, the normalized 
    variable importance of the local explanation is used as a 1D projection
    basis. The support of the local explanation is then explored by changing
    the basis with the use of the radial tour <doi:10.32614/RJ-2020-027>; 
    <doi:10.1080/10618600.1997.10474754>.",2022-03-14,Nicholas Spyrison,https://github.com/nspyrison/cheem/,TRUE,https://github.com/nspyrison/cheem,1098,1,2022-04-17T08:55:22Z,1098
cheese,"Contains tools for working with data during statistical analysis, promoting flexible, intuitive, and reproducible workflows. There are functions designated for specific statistical tasks such building a custom univariate descriptive table, computing pairwise association statistics, etc. These are built on a collection of data manipulation tools designed for general use that are motivated by the functional programming concept.",2020-10-19,Alex Zajichek,"https://zajichek.github.io/cheese,
https://github.com/zajichek/cheese",TRUE,https://github.com/zajichek/cheese,16686,0,2022-02-10T00:48:11Z,NA
chemCal,"Simple functions for plotting linear
	calibration functions and estimating standard errors for measurements
	according to the Handbook of Chemometrics and Qualimetrics: Part A
	by Massart et al. (1997) There are also functions estimating the limit
	of detection (LOD) and limit of quantification (LOQ).
	The functions work on model objects from - optionally weighted - linear
	regression (lm) or robust linear regression ('rlm' from the 'MASS' package).",2022-04-01,Johannes Ranke,"https://pkgdown.jrwb.de/chemCal/,
https://cgit.jrwb.de/chemCal/about",TRUE,https://github.com/jranke/chemcal,27588,4,2022-04-01T12:31:18Z,6897
chemmodlab,"Contains a set of methods for fitting models and methods for
    validating the resulting models. The statistical methodologies comprise
    a comprehensive collection of approaches whose validity and utility have
    been accepted by experts in the Cheminformatics field. As promising new
    methodologies emerge from the statistical and data-mining communities, they
    will be incorporated into the laboratory. These methods are aimed at discovering
    quantitative structure-activity relationships (QSARs). However, the user can
    directly input their own choices of descriptors and responses, so the capability
    for comparing models is effectively unlimited.",2022-05-01,Jeremy Ash,https://github.com/jrash/ChemModLab,TRUE,https://github.com/jrash/chemmodlab,16996,11,2022-05-01T20:29:24Z,1545.090909090909
chemodiv,"Quantify and visualise various measures of chemical diversity and
    dissimilarity, for phytochemical compounds and other sets of chemical
    composition data. Importantly, these measures can incorporate biosynthetic
    and/or structural properties of the chemical compounds, resulting in a more
    comprehensive quantification of diversity and dissimilarity.",2022-06-02,Hampus Petrén,https://github.com/hpetren/chemodiv,TRUE,https://github.com/hpetren/chemodiv,298,0,2022-06-08T12:10:31Z,NA
ChemoSpec,"A collection of functions for top-down exploratory data analysis
    of spectral data including nuclear magnetic resonance (NMR), infrared (IR),
    Raman, X-ray fluorescence (XRF) and other similar types of spectroscopy.
    Includes functions for plotting and inspecting spectra, peak alignment,
    hierarchical cluster analysis (HCA), principal components analysis (PCA) and
    model-based clustering. Robust methods appropriate for this type of
    high-dimensional data are available. ChemoSpec is designed for structured
    experiments, such as metabolomics investigations, where the samples fall into
    treatment and control groups. Graphical output is formatted consistently for
    publication quality plots. ChemoSpec is intended to be very user friendly and
    to help you get usable results quickly. A vignette covering typical operations
    is available.",2022-03-11,Bryan A. Hanson,https://bryanhanson.github.io/ChemoSpec/,TRUE,https://github.com/bryanhanson/chemospec,39065,40,2022-03-11T05:12:27Z,976.625
ChemoSpec2D,"A collection of functions for exploratory chemometrics of 2D spectroscopic data sets such as COSY (correlated spectroscopy) and HSQC (heteronuclear single quantum coherence) 2D NMR (nuclear magnetic resonance) spectra. 'ChemoSpec2D' deploys methods aimed primarily at classification of samples and the identification of spectral features which are important in distinguishing samples from each other. Each 2D spectrum (a matrix) is treated as the unit of observation, and thus the physical sample in the spectrometer corresponds to the  sample from a statistical perspective.  In addition to chemometric tools, a few tools are provided for plotting 2D spectra, but these are not intended to replace the functionality typically available on the spectrometer. 'ChemoSpec2D' takes many of its cues from 'ChemoSpec' and tries to create consistent graphical output and to be very user friendly.",2021-10-11,Bryan A. Hanson,https://github.com/bryanhanson/ChemoSpec2D,TRUE,https://github.com/bryanhanson/chemospec2d,17484,2,2021-10-11T16:24:08Z,8742
ChemoSpecUtils,Functions supporting the common needs of packages 'ChemoSpec' and 'ChemoSpec2D'.,2021-10-10,Bryan A. Hanson,https://github.com/bryanhanson/ChemoSpecUtils,TRUE,https://github.com/bryanhanson/chemospecutils,27233,2,2021-10-18T16:46:25Z,13616.5
cherryblossom,"Race results of the Cherry Blossom Run, which is an annual road race that takes place in Washington, DC.",2020-06-25,Mine Çetinkaya-Rundel,https://github.com/OpenIntroStat/cherryblossom,TRUE,https://github.com/openintrostat/cherryblossom,124989,5,2021-12-15T04:31:29Z,24997.8
chessR,"A set of functions to enable users to extract chess game data from 
    popular chess sites, including 'Lichess'<https://lichess.org/> and 
    'Chess.com' <https://www.chess.com/> and then perform analysis on that game data.",2022-01-20,Jason Zivkovic,https://github.com/JaseZiv/chessR,TRUE,https://github.com/jaseziv/chessr,1794,22,2022-04-24T11:39:44Z,81.54545454545455
childesr,"Tools for connecting to 'CHILDES', an open repository for
    transcripts of parent-child interaction. For more information on the 
    underlying data, see <https://langcog.github.io/childes-db-website/>.",2022-01-27,Mika Braginsky,https://github.com/langcog/childesr,TRUE,https://github.com/langcog/childesr,15429,11,2022-01-26T23:48:51Z,1402.6363636363637
chilemapas,"Mapas terrestres con topologias simplificadas. Estos mapas no 
  tienen precision geodesica, por lo que aplica el DFL-83 de 1979 de la Republica
  de Chile y se consideran referenciales sin validez legal.
  No se incluyen los territorios antarticos y bajo ningun evento estos mapas
  significan que exista una cesion u ocupacion de territorios soberanos en
  contra del Derecho Internacional por parte de Chile. Esta paquete esta 
  documentado intencionalmente en castellano asciificado para que funcione sin 
  problema en diferentes plataformas.
  (Terrestrial maps with simplified toplogies. These maps lack geodesic
  precision, therefore DFL-83 1979 of the Republic of Chile applies and are
  considered to have no legal validity.
  Antartic territories are excluded and under no event these maps mean
  there is a cession or occupation of sovereign territories against International
  Laws from Chile. This package was intentionally documented in asciified
  spanish to make it work without problem on different platforms.)",2020-03-28,Mauricio Vargas,https://pachamaltese.github.io/chilemapas/,TRUE,https://github.com/pachamaltese/chilemapas,19005,25,2022-07-05T00:23:46Z,760.2
ChineseNames,"
  A database of Chinese surnames and Chinese given names (1930-2008).
  This database contains nationwide frequency statistics of
  1,806 Chinese surnames and 2,614 Chinese characters used in given names,
  covering about 1.2 billion Han Chinese population
  (96.8% of the Han Chinese household-registered population
  born from 1930 to 2008 and still alive in 2008).
  This package also contains a function for computing multiple features of
  Chinese surnames and Chinese given names for scientific research (e.g.,
  name uniqueness, name gender, name valence, and name warmth/competence).",2021-11-29,Han-Wu-Shuang Bao,https://github.com/psychbruce/ChineseNames,TRUE,https://github.com/psychbruce/chinesenames,5915,92,2021-11-29T14:19:53Z,64.29347826086956
chirps,"API Client for the Climate Hazards Center 'CHIRPS' and 'CHIRTS'. 
  The 'CHIRPS' data is a quasi-global (50°S – 50°N) high-resolution 
  (0.05 arc-degrees) rainfall data set, which incorporates satellite imagery 
  and in-situ station data to create gridded rainfall time series for trend 
  analysis and seasonal drought monitoring. 'CHIRTS' is a quasi-global 
  (60°S – 70°N), high-resolution data set of daily maximum and minimum
  temperatures. For more details on 'CHIRPS' and 'CHIRTS' data please visit 
  its official home page <https://www.chc.ucsb.edu/data>.",2022-01-13,Kauê de Sousa,https://docs.ropensci.org/chirps/,TRUE,https://github.com/ropensci/chirps,12673,22,2022-04-03T05:53:23Z,576.0454545454545
chk,"For developers to check user-supplied function arguments.  It
    is designed to be simple, fast and customizable.  Error messages
    follow the tidyverse style guide.",2022-02-05,Joe Thorley,https://github.com/poissonconsulting/chk,TRUE,https://github.com/poissonconsulting/chk,74103,34,2022-06-18T18:57:51Z,2179.5
CHMM,"An exact and a variational inference for
    coupled Hidden Markov Models applied to the joint detection of copy number variations.",2017-09-29,Julie Aubert,http://github.com/julieaubert/CHMM,TRUE,https://github.com/julieaubert/chmm,15469,4,2022-04-15T12:35:54Z,3867.25
CHOIRBM,"Collection of utility functions for visualizing
    body map data collected with the Collaborative Health Outcomes
    Information Registry.",2021-02-15,Eric Cramer,https://github.com/emcramer/CHOIRBM,TRUE,https://github.com/emcramer/choirbm,5645,2,2021-08-27T23:40:11Z,2822.5
cholera,"Amends errors, augments data and aids analysis of John Snow's map
  of the 1854 London cholera outbreak.",2021-10-11,Peter Li,https://github.com/lindbrook/cholera,TRUE,https://github.com/lindbrook/cholera,20065,121,2022-07-01T20:50:37Z,165.82644628099175
chromatographR,"Tools for high-throughput analysis of HPLC-DAD/UV
    chromatograms (or similar data). Includes functions for preprocessing, alignment,
    peak-finding and fitting, peak-table construction, data-visualization, etc.
    Preprocessing and peak-table construction follow the rough formula laid out
    in alsace (Wehrens, R., Bloemberg, T.G., and Eilers P.H.C., 2015.
    <doi:10.1093/bioinformatics/btv299>. Alignment of chromatograms is available
    using parametric time warping (ptw) (Wehrens, R., Bloemberg, T.G., and Eilers
    P.H.C. 2015. <doi:10.1093/bioinformatics/btv299>) or variable penalty dynamic
    time warping (VPdtw) (Clifford, D., & Stone, G. 2012. <doi:10.18637/jss.v047.i08>).
    Peak-finding uses the algorithm by Tom O'Haver
    <http://terpconnect.umd.edu/~toh/spectrum/PeakFindingandMeasurement.htm>.
    Peaks are then fitted to a gaussian or exponential-gaussian hybrid peak shape
    using non-linear least squares (Lan, K. & Jorgenson, J. W. 2001.
    <doi:10.1016/S0021-9673(01)00594-5>). See the vignette for more details and
    suggested workflow.",2022-05-19,Ethan Bass,https://ethanbass.github.io/chromatographR/,TRUE,https://github.com/ethanbass/chromatographr,448,2,2022-07-03T16:59:50Z,224
chromConverter,"Reads chromatograms from binary formats into R objects. Currently supports conversion of Agilent ChemStation '.uv' and MassHunter '.sp', files using file parsers from the 'Aston' package <https://github.com/bovee/aston>.",2022-04-19,Ethan Bass,https://github.com/ethanbass/chromConverter,TRUE,https://github.com/ethanbass/chromconverter,739,1,2022-07-08T23:31:30Z,739
chromote,"An implementation of the 'Chrome DevTools Protocol', for controlling a headless Chrome web browser.",2022-04-19,Winston Chang,https://github.com/rstudio/chromote,TRUE,https://github.com/rstudio/chromote,8703,124,2022-05-12T15:14:21Z,70.18548387096774
chronicler,"Decorate functions to make them return enhanced output. The enhanced output consists in an object of type
  'chronicle' containing the result of the function applied to its arguments, as well as a log detailing when the function
  was run, what were its inputs, what were the errors (if the function failed to run) and other useful information.
  Tools to handle decorated functions are included, such as a forward pipe operator that makes chaining decorated functions possible.",2022-05-17,Bruno Rodrigues,NA,TRUE,https://github.com/b-rodrigues/chronicler,461,34,2022-05-18T08:34:26Z,13.558823529411764
chunked,"Data stored in text file can be processed chunkwise using 'dplyr' commands. These
    are recorded and executed per data chunk, so large files can be processed with
    limited memory using the 'LaF' package.",2022-03-07,Edwin de Jonge,https://github.com/edwindj/chunked,TRUE,https://github.com/edwindj/chunked,21681,158,2022-03-02T10:53:19Z,137.22151898734177
chunkhooks,"
    Set chunk hooks for 'R Markdown' documents <https://rmarkdown.rstudio.com/>,
    and improve user experience.
    For example, change units of figure sizes, benchmark chunks, and number
    lines on code blocks.",2020-08-05,Atsushi Yasumoto,"https://chunkhooks.atusy.net, https://github.com/atusy/chunkhooks",TRUE,https://github.com/atusy/chunkhooks,8564,3,2021-11-26T14:02:50Z,2854.6666666666665
CICA,Clustering multi-subject resting state functional Magnetic Resonance Imaging data. This methods enables the clustering of subjects based on multi-subject resting state functional Magnetic Resonance Imaging data. Objects are clustered based on similarities and differences in cluster-specific estimated components obtained by Independent Component Analysis.,2021-07-01,Jeffrey Durieux,"https://hdl.handle.net/1887/35077,
https://github.com/jeffreydurieux/CICA",TRUE,https://github.com/jeffreydurieux/cica,4822,1,2022-06-01T09:16:32Z,4822
ciccr,"Estimation and inference methods for causal relative and attributable risk in case-control and case-population studies.
    Semiparametrically efficient estimation of the aggregated (log) odds ratio and causal inference procedures for relative and attributable risk. 
    For more details, see the paper by Jun and Lee (2020), ""Causal Inference in Case-Control Studies,"" <arXiv:2004.08318 [econ.EM]>.",2020-10-29,Sokbae Lee,https://github.com/sokbae/ciccr/,TRUE,https://github.com/sokbae/ciccr,7912,2,2021-08-07T14:10:30Z,3956
cicerone,Provide step by step guided tours of 'Shiny' applications.,2021-01-10,John Coene,https://cicerone.john-coene.com/,TRUE,https://github.com/johncoene/cicerone,17538,160,2022-02-12T09:38:48Z,109.6125
CIDER,"A workflow of (a) meta-clustering based on 
    inter-group similarity measures and (b) a ground-truth-free test metric to 
    assess the biological correctness of integration in real datasets. See Hu Z,
    Ahmed A, Yau C (2021) <doi:10.1101/2021.03.29.437525> for
    more details.",2021-11-19,Zhiyuan Hu,"https://github.com/zhiyhu/CIDER, https://zhiyhu.github.io/CIDER/",TRUE,https://github.com/zhiyhu/cider,1960,2,2022-04-22T13:36:14Z,980
ciftiTools,"CIFTI files contain brain imaging data in ""grayordinates,"" which 
    represent the gray matter as cortical surface vertices (left and right) and
    subcortical voxels (cerebellum, basal ganglia, and other deep gray matter). 
    'ciftiTools' provides a unified environment for reading, writing, 
    visualizing and manipulating CIFTI-format data. It supports the ""dscalar,"" 
    ""dlabel,"" and ""dtseries"" intents. Grayordinate data is read in as a ""xifti"" 
    object, which is structured for convenient access to the data and metadata,
    and includes support for surface geometry files to enable
    spatially-dependent functionality such as static or interactive 
    visualizations and smoothing.",2022-07-01,Amanda Mejia,https://github.com/mandymejia/ciftiTools,TRUE,https://github.com/mandymejia/ciftitools,9675,16,2022-07-02T09:27:25Z,604.6875
cinaR,"Differential analyses and Enrichment pipeline for bulk 'ATAC-seq' data
  analyses. This package combines different packages to have an ultimate package
  for both data analyses and visualization of 'ATAC-seq' data. Methods are described in 
  'Karakaslar et al.' (2021) <doi:10.1101/2021.03.05.434143>.",2022-05-18,Onur Karakaslar,https://github.com/eonurk/cinaR/,TRUE,https://github.com/eonurk/cinar,8982,9,2022-05-17T10:42:46Z,998
CIPerm,"Implements computationally-efficient construction of
    confidence intervals from permutation or randomization tests
    for simple differences in means,
    based on Nguyen (2009) <doi:10.15760/etd.7798>.",2022-06-21,Jerzy Wieczorek,https://github.com/ColbyStatSvyRsch/CIPerm/,TRUE,https://github.com/colbystatsvyrsch/ciperm,651,1,2022-06-21T20:08:51Z,651
circletyper,Enables curving text elements in 'Shiny' apps.,2021-07-17,Etienne Bacher,https://github.com/etiennebacher/circletyper,TRUE,https://github.com/etiennebacher/circletyper,6685,3,2021-07-20T20:12:46Z,2228.3333333333335
circlize,"Circular layout is an efficient way for the visualization of huge 
    amounts of information. Here this package provides an implementation 
    of circular layout generation in R as well as an enhancement of available 
    software. The flexibility of the package is based on the usage of low-level 
    graphics functions such that self-defined high-level graphics can be easily 
    implemented by users for specific purposes. Together with the seamless 
    connection between the powerful computational and visual environment in R, 
    it gives users more convenience and freedom to design figures for 
    better understanding complex patterns behind multiple dimensional data. 
    The package is described in Gu et al. 2014 <doi:10.1093/bioinformatics/btu393>.",2022-05-10,Zuguang Gu,"https://github.com/jokergoo/circlize,
https://jokergoo.github.io/circlize_book/book/",TRUE,https://github.com/jokergoo/circlize,680109,789,2022-06-10T08:54:20Z,861.9885931558936
circumplex,"Circumplex models, which organize constructs in a circle around two 
    underlying dimensions, are popular for studying interpersonal functioning, 
    mood/affect, and vocational preferences/environments. This package provides 
    tools for analyzing and visualizing circular data, including scoring 
    functions for relevant instruments and a generalization of the bootstrapped 
    structural summary method from Zimmermann & Wright (2017) 
    <doi:10.1177/1073191115621795> and functions for creating publication-ready 
    tables and figures from the results.",2021-05-28,Jeffrey Girard,https://github.com/jmgirard/circumplex,TRUE,https://github.com/jmgirard/circumplex,19514,8,2021-07-12T16:13:30Z,2439.25
cIRT,"Jointly model the accuracy of cognitive responses and item choices
    within a Bayesian hierarchical framework as described by Culpepper and
    Balamuta (2015) <doi:10.1007/s11336-015-9484-7>. In addition, the package
    contains the datasets used within the analysis of the paper.",2022-02-21,Steven Andrew Culpepper,"https://tmsalab.github.io/cIRT/, https://github.com/tmsalab/cIRT",TRUE,https://github.com/tmsalab/cirt,17869,4,2022-02-21T21:02:18Z,4467.25
CITAN,"Supports quantitative
    research in scientometrics and bibliometrics. Provides
    various tools for preprocessing bibliographic
    data retrieved, e.g., from Elsevier's SciVerse Scopus,
    computing bibliometric impact of individuals,
    or modelling phenomena encountered in the social sciences.
    This package is deprecated, see 'agop' instead.",2022-03-21,Marek Gagolewski,https://github.com/gagolews/CITAN,TRUE,https://github.com/gagolews/citan,19427,6,2022-03-21T23:12:10Z,3237.8333333333335
citation,"A collection of functions to extract citation information from 'R' packages and to deal with files in 'citation file format' (<https://citation-file-format.github.io/>), extending the functionality already provided by the citation() function in the 'utils' package.",2022-01-31,Jan Philipp Dietrich,"https://github.com/pik-piam/citation,
https://doi.org/10.5281/zenodo.3813429",TRUE,https://github.com/pik-piam/citation,10577,1,2022-01-31T13:41:55Z,10577
cjbart,"A tool for analyzing conjoint experiments using Bayesian Additive Regression Trees ('BART'), a machine learning method developed by Chipman, George and McCulloch (2010) <doi:10.1214/09-AOAS285>. This tool focuses specifically on estimating, identifying, and visualizing the heterogeneity within marginal component effects, at the observation- and individual-level. It uses a variable importance measure ('VIMP') with delete-d jackknife variance estimation, following Ishwaran and Lu (2019) <doi:10.1002/sim.7803>, to obtain bias-corrected estimates of which variables drive heterogeneity in the predicted individual-level effects.",2022-03-02,Thomas Robinson,https://github.com/tsrobinson/cjbart,TRUE,https://github.com/tsrobinson/cjbart,5011,6,2022-03-02T10:58:58Z,835.1666666666666
classInt,Selected commonly used methods for choosing univariate class intervals for mapping or other graphics purposes.,2022-06-10,Roger Bivand,"https://r-spatial.github.io/classInt/,
https://github.com/r-spatial/classInt/",TRUE,https://github.com/r-spatial/classint,3894588,26,2022-06-10T15:24:01Z,149791.84615384616
cld3,"Google's Compact Language Detector 3 is a neural network model for language 
    identification and the successor of 'cld2' (available from CRAN). The algorithm is still
    experimental and takes a novel approach to language detection with different properties
    and outcomes. It can be useful to combine this with the Bayesian classifier results 
    from 'cld2'. See <https://github.com/google/cld3#readme> for more information.",2021-07-28,Jeroen Ooms,"https://docs.ropensci.org/cld3/, https://github.com/ropensci/cld3
(devel) https://github.com/google/cld3 (upstream)",TRUE,https://github.com/ropensci/cld3,37961,36,2021-07-26T08:05:54Z,1054.4722222222222
clean,"A wrapper around the new 'cleaner' package, that allows
  data cleaning functions for classes 'logical', 'factor', 'numeric', 
  'character', 'currency' and 'Date' to make data cleaning fast and
  easy. Relying on very few dependencies, it provides smart guessing,
  but with user options to override anything if needed.",2020-06-01,Matthijs S. Berends,https://github.com/msberends/cleaner,TRUE,https://github.com/msberends/cleaner,17773,23,2022-06-24T10:50:14Z,772.7391304347826
cleaner,"Data cleaning functions for classes logical,
  factor, numeric, character, currency and Date to make
  data cleaning fast and easy. Relying on very few dependencies, it 
  provides smart guessing, but with user options to override 
  anything if needed.",2021-06-13,Matthijs S. Berends,https://github.com/msberends/cleaner,TRUE,https://github.com/msberends/cleaner,39313,23,2022-06-24T10:50:14Z,1709.2608695652175
cleanrmd,"A collection of clean 'R Markdown' HTML document templates
    using classy-looking classless CSS styles. These documents use a
    minimal set of dependencies but still look great, making them suitable
    for use a package vignettes or for sharing results via email.",2022-06-14,Garrick Aden-Buie,"https://pkg.garrickadenbuie.com/cleanrmd/,
https://github.com/gadenbuie/cleanrmd",TRUE,https://github.com/gadenbuie/cleanrmd,426,102,2022-06-14T16:19:02Z,4.176470588235294
cleanTS,"A reliable and efficient tool for cleaning univariate time 
    series data. It implements reliable and efficient procedures for 
    automating the process of cleaning univariate time series data. 
    The package provides integration with already developed and deployed 
    tools for missing value imputation and outlier detection. It also 
    provides a way of visualizing large time-series data in different 
    resolutions.",2022-06-15,Mayur Shende,https://github.com/Mayur1009/cleanTS,TRUE,https://github.com/mayur1009/cleants,3869,11,2022-06-15T11:27:47Z,351.72727272727275
cleaR,"Small package to clean the R console and the R environment
    with the call of just one function.",2022-06-27,Jonathan M. Mang,https://github.com/joundso/cleaR,TRUE,https://github.com/joundso/clear,8191,0,2022-04-26T08:50:39Z,NA
clere,"Implements an empirical Bayes approach for
    simultaneous variable clustering and regression. This version also
    (re)implements in C++ an R script proposed by Howard Bondell that fits
    the Pairwise Absolute Clustering and Sparsity (PACS) methodology (see
    Sharma et al (2013) <DOI:10.1080/15533174.2012.707849>).",2020-02-06,Loic Yengo,https://github.com/mcanouil/clere,TRUE,https://github.com/mcanouil/clere,17548,1,2021-09-16T19:44:26Z,17548
clhs,"Conditioned Latin hypercube sampling, as published by Minasny and McBratney (2006) <DOI:10.1016/j.cageo.2005.12.009>. This method proposes to stratify sampling in presence of ancillary data. An extension of this method, which propose to associate a cost to each individual and take it into account during the optimisation process, is also proposed (Roudier et al., 2012, <DOI:10.1201/b12728>).",2021-10-14,Pierre Roudier,https://github.com/pierreroudier/clhs/,TRUE,https://github.com/pierreroudier/clhs,27374,10,2022-04-21T04:40:58Z,2737.4
ClickHouseHTTP,"'ClickHouse' (<https://clickhouse.com/>)
   is an open-source, high performance columnar
   OLAP (online analytical processing of queries) database management system
   for real-time analytics using SQL. This 'DBI' backend
   relies on the 'ClickHouse' HTTP interface and support HTTPS protocol.",2022-03-29,Patrice Godard,https://github.com/patzaw/ClickHouseHTTP,TRUE,https://github.com/patzaw/clickhousehttp,996,6,2022-04-01T09:09:47Z,166
cliff,Execute command line programs and format results for interactive use. It is based on the package 'processx' so it does not use shell to start up the process like system() and system2(). It also provides a simpler and cleaner interface than processx::run().,2021-11-02,Randy Lai,https://github.com/RTagBot/cliff,TRUE,https://github.com/rtagbot/cliff,2664,0,2021-11-09T17:21:36Z,NA
clifford,"A suite of routines for Clifford algebras, using the
   'Map' class of the Standard Template Library.  Canonical
   reference: Hestenes (1987, ISBN 90-277-1673-0, ""Clifford algebra
   to geometric calculus"").  Special cases including Lorentz transforms,
   quaternion multiplication, and Grassman algebra, are discussed.
   Conformal geometric algebra theory is implemented.",2022-05-02,Robin K. S. Hankin,https://github.com/RobinHankin/clifford,TRUE,https://github.com/robinhankin/clifford,15509,2,2022-04-26T21:47:05Z,7754.5
clifro,"CliFlo is a web portal to the New Zealand National Climate
    Database and provides public access (via subscription) to around 6,500
    various climate stations (see <https://cliflo.niwa.co.nz/> for more
    information). Collating and manipulating data from CliFlo
    (hence clifro) and importing into R for further analysis, exploration and
    visualisation is now straightforward and coherent. The user is required to
    have an internet connection, and a current CliFlo subscription (free) if
    data from stations, other than the public Reefton electronic weather
    station, is sought.",2021-05-24,Blake Seers,"https://docs.ropensci.org/clifro/,
https://github.com/ropensci/clifro",TRUE,https://github.com/ropensci/clifro,25320,23,2022-01-24T03:28:24Z,1100.8695652173913
climaemet,"Tools to download the climatic data of the Spanish
    Meteorological Agency (AEMET) directly from R using their API and
    create scientific graphs (climate charts, trend analysis of climate
    time series, temperature and precipitation anomalies maps, warming
    stripes graphics, climatograms, etc.).",2022-02-24,Manuel Pizarro,"https://ropenspain.github.io/climaemet/,
https://github.com/rOpenSpain/climaemet",TRUE,https://github.com/ropenspain/climaemet,11161,21,2022-05-19T06:57:22Z,531.4761904761905
climate,"Automatize downloading of meteorological and hydrological data from publicly available repositories:
    OGIMET (<http://ogimet.com/index.phtml.en>), 
    University of Wyoming - atmospheric vertical profiling data (<http://weather.uwyo.edu/upperair/>),
    Polish Institute of Meterology and Water Management - National Research Institute (<https://danepubliczne.imgw.pl>),
    and National Oceanic & Atmospheric Administration (NOAA).
    This package also allows for adding geographical coordinates for each observation.",2022-02-22,Bartosz Czernecki,https://github.com/bczernecki/climate,TRUE,https://github.com/bczernecki/climate,32144,51,2022-02-22T18:45:41Z,630.2745098039215
climateStability,"Climate stability measures are not formalized in the literature and
  tools for generating stability metrics from existing data are nascent.
  This package provides tools for calculating climate stability from raster data
  encapsulating climate change as a series of time slices. The methods follow
  Owens and Guralnick <doi:10.17161/bi.v14i0.9786> Biodiversity Informatics.",2019-11-21,Hannah Owens,https://github.com/hannahlowens/climateStability,TRUE,https://github.com/hannahlowens/climatestability,13981,5,2022-03-06T10:21:50Z,2796.2
climatrends,"Supports analysis of trends in climate change, ecological and crop modelling.",2022-02-24,Kauê de Sousa,https://agrdatasci.github.io/climatrends/,TRUE,https://github.com/agrdatasci/climatrends,16422,1,2022-06-29T18:30:42Z,16422
ClimMobTools,"API client for 'ClimMob', an open source software for experimental 
    crowdsourcing citizen science under the 'tricot' approach <https://climmob.net/>. 
    Developed by van Etten et al. (2019) <doi:10.1017/S0014479716000739>, it turns the 
    research paradigm on its head; instead of a few researchers designing complicated 
    trials to compare several technologies in search of the best solutions for the 
    target environment, it enables many participants to carry out reasonably simple 
    experiments that taken together can offer even more information. 
    'ClimMobTools' enables project managers to deep explore and analyse their 
    'ClimMob' data in R.",2022-02-18,Kauê de Sousa,https://agrdatasci.github.io/ClimMobTools/,TRUE,https://github.com/agrdatasci/climmobtools,15869,3,2022-06-29T18:31:04Z,5289.666666666667
clinDataReview,"Creation of interactive tables, listings and figures ('TLFs') 
  and associated report for exploratory analysis of data in a clinical trial, 
  e.g. for clinical oversight activities.
  Interactive figures include sunburst, treemap, scatterplot, line plot and
  barplot of counts data. 
  Interactive tables include table of summary statistics
  (as counts of adverse events, enrollment table) and listings.
  Possibility to compare data (summary table or listing) across two data batches/sets.
  A clinical data review report is created via study-specific configuration 
  files and template 'R Markdown' reports contained in the package.",2022-02-23,Laure Cougnaud,https://github.com/openanalytics/clinDataReview,TRUE,https://github.com/openanalytics/clindatareview,5707,8,2022-02-24T00:01:17Z,713.375
clinmon,"
   Every research team have their own script for calculation of hemodynamic indexes. 
   This package makes it possible  to insert a long-format dataframe, and add both 
   periods of interest (trigger-periods), and delete artifacts with deleter-files.",2021-02-04,Markus Harboe Olsen,https://github.com/lilleoel/clinmon,TRUE,https://github.com/lilleoel/clinmon,8423,1,2022-06-22T08:23:51Z,8423
clinPK,"Calculates equations commonly used in clinical
        pharmacokinetics and clinical pharmacology, such as equations
        for dose individualization, compartmental pharmacokinetics,
        drug exposure, anthropomorphic calculations, clinical
        chemistry, and conversion of common clinical parameters. Where
        possible and relevant, it provides multiple published and
        peer-reviewed equations within the respective R function.",2022-05-09,Kara Woo,https://github.com/InsightRX/clinPK,TRUE,https://github.com/insightrx/clinpk,16007,15,2022-07-05T19:36:24Z,1067.1333333333334
clinspacy,"Performs biomedical named entity recognition,
    Unified Medical Language System (UMLS) concept mapping, and negation
    detection using the Python 'spaCy', 'scispaCy', and 'medspaCy' packages, and 
    transforms extracted data into a wide format for inclusion in machine
    learning models. The development of the 'scispaCy' package is described by
    Neumann (2019) <doi:10.18653/v1/W19-5034>. The 'medspacy' package uses
    'ConText', an algorithm for determining the context of clinical statements
    described by Harkema (2009) <doi:10.1016/j.jbi.2009.05.002>. Clinspacy
    also supports entity embeddings from 'scispaCy' and UMLS 'cui2vec' concept
    embeddings developed by Beam (2018) <arXiv:1804.01486>.",2021-03-20,Karandeep Singh,https://github.com/ML4LHS/clinspacy,TRUE,https://github.com/ml4lhs/clinspacy,5467,78,2021-08-21T19:15:52Z,70.08974358974359
clintools,"
   Every research team have their own script for data management, statistics and 
   most importantly hemodynamic indices. The purpose is to standardize scripts 
   utilized in clinical research. The hemodynamic indices can be used in a long-format dataframe, 
   and add both periods of interest (trigger-periods), and delete artifacts with deleter-files. 
   Transfer function analysis (Claassen et al. (2016) <doi:10.1177/0271678X15626425>) and
   Mx (Czosnyka et al. (1996) <doi:10.1161/01.str.27.10.1829>) can be calculated using this package.",2022-07-06,Markus Harboe Olsen,https://github.com/lilleoel/clintools,TRUE,https://github.com/lilleoel/clintools,6480,1,2022-06-22T08:23:51Z,6480
clinUtils,"
 Utility functions to facilitate the import, 
 the reporting and analysis of clinical data.
 Example datasets in 'SDTM' and 'ADaM' format, containing a subset of patients/domains
 from the 'CDISC Pilot 01 study' are also available as R datasets to demonstrate
 the package functionalities.",2022-02-22,Laure Cougnaud,https://github.com/openanalytics/clinUtils,TRUE,https://github.com/openanalytics/clinutils,6604,1,2022-02-22T11:53:58Z,6604
clipr,"Simple utility functions to read from and write to
    the Windows, OS X, and X11 clipboards.",2022-02-22,Matthew Lincoln,"https://github.com/mdlincoln/clipr,
http://matthewlincoln.net/clipr/",TRUE,https://github.com/mdlincoln/clipr,13820050,129,2022-02-24T11:47:14Z,107132.17054263566
clock,"Provides a comprehensive library for date-time manipulations
    using a new family of orthogonal date-time classes (durations, time
    points, zoned-times, and calendars) that partition responsibilities so
    that the complexities of time zones are only considered when they are
    really needed. Capabilities include: date-time parsing, formatting,
    arithmetic, extraction and updating of components, and rounding.",2021-12-02,Davis Vaughan,"https://clock.r-lib.org, https://github.com/r-lib/clock",TRUE,https://github.com/r-lib/clock,34143,73,2022-01-31T20:10:56Z,467.71232876712327
cloudos,"The 'CloudOS' client library for R makes it easy to interact with 
    CloudOS <https://cloudos.lifebit.ai/> in the R environment for analysis.",2022-02-09,Sangram Keshari Sahu,https://github.com/lifebit-ai/cloudos,TRUE,https://github.com/lifebit-ai/cloudos,4161,3,2022-02-07T16:20:16Z,1387
cloudstoR,"Access Cloudstor via their WebDAV API. This package can read, write, and navigate Cloudstor from R.",2022-01-16,Taren Sanders,"https://pdparker.github.io/cloudstoR/,
https://github.com/pdparker/cloudstoR",TRUE,https://github.com/pdparker/cloudstor,4248,1,2022-01-16T07:29:38Z,4248
clubSandwich,"Provides several cluster-robust variance estimators (i.e.,
    sandwich estimators) for ordinary and weighted least squares linear regression
    models, including the bias-reduced linearization estimator introduced by Bell
    and McCaffrey (2002) 
    <https://www150.statcan.gc.ca/n1/pub/12-001-x/2002002/article/9058-eng.pdf> and 
    developed further by Pustejovsky and Tipton (2017) 
    <DOI:10.1080/07350015.2016.1247004>. The package includes functions for estimating
    the variance- covariance matrix and for testing single- and multiple-
    contrast hypotheses based on Wald test statistics. Tests of single regression
    coefficients use Satterthwaite or saddle-point corrections. Tests of multiple-
    contrast hypotheses use an approximation to Hotelling's T-squared distribution.
    Methods are provided for a variety of fitted models, including lm() and mlm
    objects, glm(), ivreg() (from package 'AER'), plm() (from package 'plm'), gls()
    and lme() (from 'nlme'), lmer() (from `lme4`), robu() (from 'robumeta'), and 
    rma.uni() and rma.mv() (from 'metafor').",2022-06-15,James Pustejovsky,http://jepusto.github.io/clubSandwich/,TRUE,https://github.com/jepusto/clubsandwich,152292,41,2022-06-16T14:42:30Z,3714.439024390244
clusrank,"Non-parametric tests (Wilcoxon rank sum test and Wilcoxon signed rank test)
       for clustered data documented in
       Jiang et. al (2020) <doi:10.18637/jss.v096.i06>.",2022-01-23,Wenjie Wang,https://github.com/wenjie2wang/clusrank,TRUE,https://github.com/wenjie2wang/clusrank,28137,1,2022-01-23T19:23:43Z,28137
ClusROC,"Statistical methods for ROC surface analysis in three-class classification problems for clustered data and in presence of covariates. In particular, the package allows to obtain covariate-specific point and interval estimation for:
  (i) true class fractions (TCFs) at fixed pairs of thresholds;
  (ii) the ROC surface;
  (iii) the volume under ROC surface (VUS);
  (iv) the optimal pairs of thresholds.
  Methods considered in points (i), (ii) and (iv) are proposed and discussed in To et al. (2022) <doi:10.1177/09622802221089029>. Referring to point (iv), three  different selection criteria are implemented: Generalized Youden Index (GYI), Closest to Perfection (CtP) and Maximum Volume (MV). Methods considered in point (iii) are proposed and discussed in Xiong et al. (2018) <doi:10.1177/0962280217742539>. Visualization tools are also provided. We refer readers to the articles cited above for all details. ",2022-05-25,Duc-Khanh To,https://github.com/toduckhanh/ClusROC,TRUE,https://github.com/toduckhanh/clusroc,369,0,2022-05-23T08:56:06Z,NA
ClustAssess,"A set of tools for evaluating clustering robustness using 
    proportion of ambiguously clustered pairs (Senbabaoglu et al. (2014) 
    <doi:10.1038/srep06207>), as well as similarity across methods 
    and method stability using element-centric clustering comparison (Gates et 
    al. (2019) <doi:10.1038/s41598-019-44892-y>). Additionally, this package 
    enables stability-based parameter assessment for graph-based clustering 
    pipelines typical in single-cell data analysis.",2022-01-26,Arash Shahsavari,https://github.com/Core-Bioinformatics/ClustAssess,TRUE,https://github.com/core-bioinformatics/clustassess,5426,13,2022-06-20T11:09:51Z,417.38461538461536
clustcurv,"A method for determining groups in multiple 
    curves with an automatic selection of their number based on k-means or 
    k-medians algorithms. The selection of the optimal number is provided by 
    bootstrap methods. The methodology can be applied both in regression and survival framework.
     Implemented methods are:
    Grouping multiple survival curves described by Villanueva et al. (2018) <doi:10.1002/sim.8016>.",2021-01-10,Nora M. Villanueva,https://github.com/noramvillanueva/clustcurv,TRUE,https://github.com/noramvillanueva/clustcurv,14610,2,2022-03-23T11:49:17Z,7305
Cluster.OBeu,"Estimate and return the needed parameters for visualisations designed for 'OpenBudgets' <http://openbudgets.eu/> data. Calculate cluster analysis measures in Budget data of municipalities across Europe, according to the 'OpenBudgets' data model. It involves a set of techniques and algorithms used to find and divide the data into groups of similar observations. Also, can be used generally to extract visualisation parameters convert them to 'JSON' format and use them as input in a different graphical interface.",2019-12-17,Kleanthis Koupidis,https://github.com/okgreece/Cluster.OBeu,TRUE,https://github.com/okgreece/cluster.obeu,14486,2,2021-09-02T13:47:10Z,7243
clusterCons,"Functions for calculation of robustness measures for clusters and cluster membership based on generating consensus matrices from bootstrapped clustering experiments in which a random proportion of rows of the data set are used in each individual clustering. This allows the user to prioritise clusters and the members of clusters based on their consistency in this regime. The functions allow the user to select several algorithms to use in the re-sampling scheme and with any of the parameters that the algorithm would normally take. See Simpson, T. I., Armstrong, J. D. & Jarman, A. P. (2010) <doi:10.1186/1471-2105-11-590> and Monti, S., Tamayo, P., Mesirov, J. & Golub, T. (2003) <doi:10.1023/a:1023949509487>.",2022-02-22,Dr. T. Ian Simpson,https://github.com/biomedicalinformaticsgroup/clusterCons,TRUE,https://github.com/biomedicalinformaticsgroup/clustercons,2348,0,2022-02-22T21:17:55Z,NA
Clustering,"The design of this package allows us to run different clustering packages and compare the results between them, to determine which algorithm behaves best from the data provided.",2022-06-22,Luis Alfonso Perez Martos,https://github.com/laperez/clustering,TRUE,https://github.com/laperez/clustering,15548,3,2022-06-22T17:55:49Z,5182.666666666667
clustermq,"Evaluate arbitrary function calls using workers on HPC schedulers
    in single line of code. All processing is done on the network without
    accessing the file system. Remote schedulers are supported via SSH.",2022-01-26,Michael Schubert,https://mschubert.github.io/clustermq/,TRUE,https://github.com/mschubert/clustermq,49504,129,2022-03-04T21:11:33Z,383.7519379844961
ClusterR,"Gaussian mixture models, k-means, mini-batch-kmeans, k-medoids and affinity propagation clustering with the option to plot, validate, predict (new data) and estimate the optimal number of clusters. The package takes advantage of 'RcppArmadillo' to speed up the computationally intensive parts of the functions. For more information, see (i) ""Clustering in an Object-Oriented Environment"" by Anja Struyf, Mia Hubert, Peter Rousseeuw (1997), Journal of Statistical Software, <doi:10.18637/jss.v001.i04>; (ii) ""Web-scale k-means clustering"" by D. Sculley (2010), ACM Digital Library, <doi:10.1145/1772690.1772862>; (iii) ""Armadillo: a template-based C++ library for linear algebra"" by Sanderson et al (2016), The Journal of Open Source Software, <doi:10.21105/joss.00026>; (iv) ""Clustering by Passing Messages Between Data Points"" by Brendan J. Frey and Delbert Dueck, Science 16 Feb 2007: Vol. 315, Issue 5814, pp. 972-976, <doi:10.1126/science.1136800>.",2022-01-27,Lampros Mouselimis,https://github.com/mlampros/ClusterR,TRUE,https://github.com/mlampros/clusterr,233952,68,2022-01-28T08:29:52Z,3440.470588235294
ClusTorus,"Provides various tools of for clustering multivariate angular 
  data on the torus. The package provides angular 
  adaptations of usual clustering methods such as the k-means 
  clustering, pairwise angular distances, which can be used as an 
  input for distance-based clustering algorithms, and implements
  clustering based on the conformal prediction framework. Options 
  for the conformal scores include scores based on a kernel density 
  estimate, multivariate von Mises mixtures, and naive k-means clusters. 
  Moreover, the package provides some basic data handling tools for 
  angular data.",2022-01-04,Seungki Hong,https://github.com/sungkyujung/ClusTorus,TRUE,https://github.com/sungkyujung/clustorus,7371,3,2022-04-28T06:25:41Z,2457
clustree,"Deciding what resolution to use can be a difficult question when
    approaching a clustering analysis. One way to approach this problem is to
    look at how samples move as the number of clusters increases. This package
    allows you to produce clustering trees, a visualisation for interrogating
    clusterings as resolution increases.",2022-06-25,Luke Zappia,https://github.com/lazappi/clustree,TRUE,https://github.com/lazappi/clustree,105540,131,2022-06-27T07:08:19Z,805.6488549618321
CLVTools,"
    A set of state-of-the-art probabilistic modeling approaches to derive estimates of individual customer lifetime values (CLV).
    Commonly, probabilistic approaches focus on modelling 3 processes, i.e. individuals' attrition, transaction, and spending process. 
    Latent customer attrition models, which are also known as ""buy-'til-you-die models"", model the attrition as well as the transaction process. 
    They are used to make inferences and predictions about transactional patterns of individual customers such as their future purchase behavior. 
    Moreover, these models have also been used to predict individuals’ long-term engagement in activities such as playing an online game or 
    posting to a social media platform. The spending process is usually modelled by a separate probabilistic model. Combining these results yields in 
    lifetime values estimates for individual customers.
    This package includes fast and accurate implementations of various probabilistic models for non-contractual settings 
    (e.g., grocery purchases or hotel visits). All implementations support time-invariant covariates, which can be used to control for e.g., 
    socio-demographics. If such an extension has been proposed in literature, we further provide the possibility to control for time-varying 
    covariates to control for e.g., seasonal patterns. 
    Currently, the package includes the following latent attrition models to model individuals' attrition and transaction process: 
    [1] Pareto/NBD model (Pareto/Negative-Binomial-Distribution), 
    [2] the Extended Pareto/NBD model (Pareto/Negative-Binomial-Distribution with time-varying covariates), 
    [3] the BG/NBD model (Beta-Gamma/Negative-Binomial-Distribution) and the 
    [4] GGom/NBD (Gamma-Gompertz/Negative-Binomial-Distribution). 
    Further, we provide an implementation of the Gamma/Gamma model to model the spending process of individuals.",2022-01-09,Patrick Bachmann,https://github.com/bachmannpatrick/CLVTools,TRUE,https://github.com/bachmannpatrick/clvtools,18380,30,2022-01-10T14:39:59Z,612.6666666666666
cmfrec,"Collective matrix factorization (a.k.a. multi-view or multi-way factorization,
	Singh, Gordon, (2008) <doi:10.1145/1401890.1401969>) tries to approximate a (potentially very sparse
	or having many missing values) matrix 'X' as the product of two low-dimensional matrices,
	optionally aided with secondary information matrices about rows and/or columns of 'X',
	which are also factorized using the same latent components.
	The intended usage is for recommender systems, dimensionality reduction, and missing value imputation.
	Implements extensions of the original model (Cortes, (2018) <arXiv:1809.00366>) and can produce
	different factorizations such as the weighted 'implicit-feedback' model (Hu, Koren, Volinsky,
	(2008) <doi:10.1109/ICDM.2008.22>), the 'weighted-lambda-regularization' model,
	(Zhou, Wilkinson, Schreiber, Pan, (2008) <doi:10.1007/978-3-540-68880-8_32>),
	or the enhanced model with 'implicit features' (Rendle, Zhang,
	Koren, (2019) <arXiv:1905.01395>), with or without side information. Can use gradient-based
	procedures or alternating-least squares procedures (Koren, Bell, Volinsky, (2009)
	<doi:10.1109/MC.2009.263>), with either a Cholesky solver, a faster conjugate gradient solver
	(Takacs, Pilaszy, Tikk, (2011) <doi:10.1145/2043932.2043987>), or a non-negative
	coordinate descent solver (Franc, Hlavac, Navara, (2005) <doi:10.1007/11556121_50>),
	providing efficient methods for sparse and dense data, and mixtures thereof.
	Supports L1 and L2 regularization in the main models,
	offers alternative most-popular and content-based models, and implements functionality
	for cold-start recommendations and imputation of 2D data.",2022-07-09,David Cortes,https://github.com/david-cortes/cmfrec,TRUE,https://github.com/david-cortes/cmfrec,10727,91,2022-07-09T15:34:57Z,117.87912087912088
cmhc,Wrapper around the Canadian Mortgage and Housing Corporation (CMHC) web interface. It enables programmatic and reproducible access to a wide variety of housing data from CMHC.,2022-06-15,Jens von Bergmann,"https://github.com/mountainMath/cmhc,
https://mountainmath.github.io/cmhc/,
https://www03.cmhc-schl.gc.ca/hmip-pimh/en",TRUE,https://github.com/mountainmath/cmhc,241,10,2022-06-15T16:01:22Z,24.1
cmna,"Provides the source and examples for James P. Howard, II, 
             ""Computational Methods for Numerical Analysis with R,"" 
             <https://jameshoward.us/cmna/>, a book on numerical
             methods in R.",2021-07-14,James Howard,https://jameshoward.us/cmna/,TRUE,https://github.com/k3jph/cmna-pkg,21666,12,2021-07-14T13:18:39Z,1805.5
cmocean,"Perceptually uniform palettes for commonly used
	variables in oceanography as functions taking an integer
	and producing character vectors of colours.
	See Thyng, K.M., Greene, C.A., Hetland, R.D., Zimmerle, H.M.
	and S.F. DiMarco (2016) <doi:10.5670/oceanog.2016.66> for
	the guidelines adhered to when creating the palettes.",2020-11-18,Ivan Krylov,https://matplotlib.org/cmocean/,TRUE,https://github.com/aitap/cmocean,21132,2,2022-01-17T10:22:37Z,10566
CMplot,"Manhattan plot, a type of scatter plot, was widely used to display the association results. However, it is usually time-consuming and laborious for a non-specialist user to write scripts and adjust parameters of an elaborate plot. Moreover, the ever-growing traits measured have necessitated the integration of results from different Genome-wide association study researches. Circle Manhattan Plot is the first open R package that can lay out. Genome-wide association study P-value results in both traditional rectangular patterns, QQ-plot and novel circular ones. United in only one bull's eye style plot, association results from multiple traits can be compared interactively, thereby to reveal both similarities and differences between signals. Additional functions include: highlight signals, a group of SNPs, chromosome visualization and candidate genes around SNPs.",2022-05-24,LiLin-Yin,https://github.com/YinLiLin/CMplot,TRUE,https://github.com/yinlilin/cmplot,48861,312,2022-06-21T14:23:17Z,156.60576923076923
cmstatr,"An implementation of the statistical methods commonly
  used for advanced composite materials in aerospace applications.
  This package focuses on calculating basis values (lower tolerance
  bounds) for material strength properties, as well as performing the
  associated diagnostic tests. This package provides functions for
  calculating basis values assuming several different distributions,
  as well as providing functions for non-parametric methods of computing
  basis values. Functions are also provided for testing the hypothesis
  that there is no difference between strength and modulus data from an
  alternate sample and that from a ""qualification"" or ""baseline"" sample.
  For a discussion of these statistical methods and their use, see the
  Composite Materials Handbook, Volume 1 (2012, ISBN: 978-0-7680-7811-4).
  Additional details about this package are available in the paper by
  Kloppenborg (2020, <doi:10.21105/joss.02265>).",2021-09-30,Stefan Kloppenborg,"https://www.cmstatr.net/, https://github.com/cmstatr/cmstatr",TRUE,https://github.com/cmstatr/cmstatr,10696,1,2021-09-30T16:52:25Z,10696
cmvnorm,Various utilities for the complex multivariate Gaussian distribution and complex Gaussian processes.,2022-01-31,Robin K. S. Hankin,https://github.com/RobinHankin/cmvnorm,TRUE,https://github.com/robinhankin/cmvnorm,20244,2,2022-06-21T07:20:17Z,10122
CNAIM,"Implementation of the CNAIM standard in R. Contains a series of
    algorithms which determine the probability of failure, consequences of
    failure and monetary risk associated with electricity distribution
    companies' assets such as transformers and cables. Results are visualized
    in an easy-to-understand risk matrix.",2022-06-18,Mohsin Vindhani,https://www.cnaim.io/,TRUE,https://github.com/utiligize/cnaim,7742,5,2022-07-09T16:31:48Z,1548.4
cNORM,"Conventional methods for producing standard scores or percentiles 
    in psychometrics or biometrics are often plagued with 'jumps' or 'gaps' 
    (i.e., discontinuities) in norm tables and low confidence for assessing 
    extreme scores. The continuous norming method introduced by A. Lenhard et al.
    (2016, <doi:10.1177/1073191116656437>; 2019, <doi:10.1371/journal.pone.0222279>;
    2021 <doi: 10.1177/0013164420928457>) estimates percentile development 
    (e. g. over age) and generates continuous test norm scores on the basis of 
    the raw data from standardization samples, without requiring assumptions 
    about the distribution of the raw data: Norm scores are directly established 
    from raw data by modeling the latter ones as a function of both percentile 
    scores and an explanatory variable (e.g., age). The method minimizes bias 
    arising from sampling and measurement error, while handling marked deviations 
    from normality, addressing bottom or ceiling effects and capturing almost 
    all of the variance in the original norm data sample. It includes procedures 
    for post stratification of norm samples to overcome bias in data collection 
    and to mitigate violations of representativeness. An online demonstration is 
    available via <https://cnorm.shinyapps.io/cNORM/>.",2022-06-12,Alexandra Lenhard,"https://www.psychometrica.de/cNorm_en.html,
https://github.com/WLenhard/cNORM",TRUE,https://github.com/wlenhard/cnorm,104894,2,2022-06-12T08:00:54Z,52447
CNVScope,"Provides the ability to create interaction maps, discover CNV map domains (edges), gene annotate interactions, and create interactive visualizations of these CNV interaction maps.",2022-03-30,James Dalgeish,https://github.com/jamesdalg/CNVScope/,TRUE,https://github.com/jamesdalg/cnvscope,13364,6,2022-03-30T23:05:57Z,2227.3333333333335
coala,"Coalescent simulators can rapidly simulate biological sequences
    evolving according to a given model of evolution.
    You can use this package to specify such models, to conduct the simulations
    and to calculate additional statistics from the results (Staab, Metzler,
    2016 <doi:10.1093/bioinformatics/btw098>).
    It relies on existing simulators for doing the simulation, and currently
    supports the programs 'ms', 'msms' and 'scrm'. It also supports finite-sites
    mutation models by combining the simulators with the program 'seq-gen'.",2022-02-14,Paul Staab,https://github.com/statgenlmu/coala,TRUE,https://github.com/statgenlmu/coala,18180,18,2022-02-19T21:51:55Z,1010
coalitions,"An implementation of a Bayesian framework for the opinion poll
    based estimation of event probabilities in multi-party electoral systems
    (Bender and Bauer (2018) <doi:10.21105/joss.00606>).",2022-05-02,Andreas Bender,https://adibender.github.io/coalitions/,TRUE,https://github.com/adibender/coalitions,17885,19,2022-05-02T08:49:55Z,941.3157894736842
cobalt,"Generate balance tables and plots for covariates of groups preprocessed through matching, weighting or subclassification, for example, using propensity scores. Includes integration with 'MatchIt', 'twang', 'Matching', 'optmatch', 'CBPS', 'ebal', 'WeightIt', 'cem', 'sbw', and 'designmatch' for assessing balance on the output of their preprocessing functions. Users can also specify data for balance assessment not generated through the above packages. Also included are methods for assessing balance in clustered or multiply imputed data sets or data sets with longitudinal treatments.",2022-01-19,Noah Greifer,"https://ngreifer.github.io/cobalt/,
https://github.com/ngreifer/cobalt",TRUE,https://github.com/ngreifer/cobalt,164292,55,2022-05-23T15:06:17Z,2987.1272727272726
cocktailApp,"A 'shiny' app to discover cocktails. The
    app allows one to search for cocktails by ingredient,
    filter on rating, and number of ingredients. The
    package also contains data with the ingredients of
    nearly 26 thousand cocktails scraped from the web.",2021-04-01,Steven E. Pav,https://github.com/shabbychef/cocktailApp,TRUE,https://github.com/shabbychef/cocktailapp,14748,40,2022-07-07T03:18:52Z,368.7
coda.base,"A minimum set of functions to perform compositional data analysis
    using the log-ratio approach introduced by John Aitchison (1982) <http://www.jstor.org/stable/2345821>. Main functions
    have been implemented in c++ for better performance.",2022-03-16,Marc Comas-Cufí,"https://mcomas.net/coda.base/, https://github.com/mcomas/coda.base",TRUE,https://github.com/mcomas/coda.base,21324,3,2022-07-07T09:54:39Z,7108
coda4microbiome,"Functions for microbiome data analysis that take into account its compositional nature. Performs variable selection through penalized regression for both, cross-sectional and longitudinal studies, and for binary and continuous outcomes.    ",2022-03-31,Malu Calle,https://malucalle.github.io/coda4microbiome/,TRUE,https://github.com/malucalle/coda4microbiome,1287,5,2022-06-16T17:38:07Z,257.4
CodeDepends,"Tools for analyzing R expressions
  or blocks of code and determining the dependencies between them.
  It focuses on R scripts, but can be used on the bodies of functions.
  There are many facilities including the ability to summarize  or get a high-level
  view of code, determining dependencies between variables,  code improvement
  suggestions.",2018-07-17,Duncan Temple Lang,https://github.com/duncantl/CodeDepends,TRUE,https://github.com/duncantl/codedepends,21990,74,2022-04-25T22:11:20Z,297.1621621621622
codemeta,"The 'Codemeta' Project defines a 'JSON-LD' format
    for describing software metadata, as detailed at
    <https://codemeta.github.io>. This package provides core utilities
    to generate this metadata with a minimum of dependencies.",2021-12-22,Carl Boettiger,https://github.com/cboettig/codemeta,TRUE,https://github.com/cboettig/codemeta,6872,5,2021-12-22T00:42:19Z,1374.4
codemetar,"The 'Codemeta' Project defines a 'JSON-LD' format
    for describing software metadata, as detailed at
    <https://codemeta.github.io>. This package provides utilities to
    generate, parse, and modify 'codemeta.json' files automatically for R
    packages, as well as tools and examples for working with
    'codemeta.json' 'JSON-LD' more generally.",2022-03-16,Carl Boettiger,"https://github.com/ropensci/codemetar,
https://docs.ropensci.org/codemetar/",TRUE,https://github.com/ropensci/codemetar,20239,55,2022-03-15T20:08:08Z,367.9818181818182
codename,"This creates code names that a user can consider for their organizations, their projects, themselves, people
    in their organizations or projects, or whatever else. The user can also supply a numeric seed (and even a character seed)
    for maximum reproducibility. Use is simple and the code names produced come in various types too, contingent on what the
    user may be desiring as a code name or nickname.",2021-09-07,Steve Miller,https://github.com/svmiller/codename,TRUE,https://github.com/svmiller/codename,6548,4,2021-09-09T20:18:57Z,1637
coga,"Evaluation for density and distribution function of convolution of gamma
    distributions in R. Two related exact methods and one approximate method are
    implemented with efficient algorithm and C++ code. A quick guide for choosing
    correct method and usage of this package is given in package vignette. For the
    detail of methods used in this package, we refer the user to
    Mathai(1982)<doi:10.1007/BF02481056>,
    Moschopoulos(1984)<doi:10.1007/BF02481123>,
    Barnabani(2017)<doi:10.1080/03610918.2014.963612>,
    Hu et al.(2020)<doi:10.1007/s00180-019-00924-9>.",2021-10-07,Chaoran Hu,https://github.com/ChaoranHu/coga,TRUE,https://github.com/chaoranhu/coga,19340,4,2021-10-06T18:00:56Z,4835
cohortBuilder,"Common API for filtering data stored in different data models.
    Provides multiple filter types and reproducible R code.
    Works standalone or with 'shinyCohortBuilder' as the GUI for interactive Shiny apps.",2022-06-01,Krystian Igras,"https://github.com/r-world-devs/cohortBuilder/,
https://r-world-devs.github.io/cohortBuilder/",TRUE,https://github.com/r-world-devs/cohortbuilder,328,0,2022-06-01T13:00:04Z,NA
cohorts,Functions to simplify the process of preparing event and transaction for cohort analysis.,2022-05-15,Peer Christensen,https://github.com/PeerChristensen/cohorts,TRUE,https://github.com/peerchristensen/cohorts,4964,3,2022-05-15T21:55:00Z,1654.6666666666667
coinmarketcapr,Extract and monitor price and market cap of 'Cryptocurrencies' from 'Coin Market Cap' <https://coinmarketcap.com/api/>. ,2022-02-27,AbdulMajedRaja RS,https://github.com/amrrs/coinmarketcapr,TRUE,https://github.com/amrrs/coinmarketcapr,24385,75,2022-02-27T11:57:55Z,325.1333333333333
COINr,"A comprehensive high-level package, for composite indicator construction and analysis. It is a ""development environment""
    for composite indicators and scoreboards, which includes utilities for construction (indicator selection, denomination, imputation,
    data treatment, normalisation, weighting and aggregation) and analysis (multivariate analysis, correlation plotting, short cuts for
    principal component analysis, global sensitivity analysis, and more). A composite indicator is completely encapsulated inside a single
    hierarchical list called a ""coin"". This allows a fast and efficient work flow, as well as making quick copies, testing methodological variations and making comparisons.
    It also includes many plotting options, both statistical (scatter plots, distribution plots) as well as for presenting results.",2022-07-05,William Becker,https://bluefoxr.github.io/COINr/,TRUE,https://github.com/bluefoxr/coinr,4379,10,2022-07-08T15:59:32Z,437.9
collapse,"A C/C++ based package for advanced data transformation and 
    statistical computing in R that is extremely fast, class-agnostic,
    and programmer friendly through a flexible and parsimonious syntax.
    It is well integrated with base R, 'dplyr' / (grouped) 'tibble', 
    'data.table', 'sf', 'plm' (panel-series and data frames), and 
    non-destructively handles other matrix or data frame based classes (like 
    'ts', 'xts' / 'zoo', 'tsibble', ...)
    --- Key Features: ---
    (1) Advanced statistical programming: A full set of fast statistical functions 
        supporting grouped and weighted computations on vectors, matrices and 
        data frames. Fast and programmable grouping, ordering, unique values/rows, 
        factor generation and interactions. Fast and flexible functions for data 
        manipulation, data object conversions, and memory efficient R programming.
    (2) Advanced aggregation: Fast and easy multi-data-type, multi-function, weighted 
        and parallelized data aggregation.
    (3) Advanced transformations: Fast row/column arithmetic, (grouped) replacing 
        and sweeping out of statistics (by reference), (grouped, weighted) scaling/standardizing, 
        (higher-dimensional) between (averaging) and (quasi-)within (demeaning) transformations, 
        linear prediction, model fitting and testing exclusion restrictions.
    (4) Advanced time-computations: Fast and flexible indexed time series and panel data classes. 
        Fast (sequences of) lags/leads, and  (lagged/leaded, iterated, quasi-, log-) 
        differences and (compounded) growth rates on (irregular) time series and panels. 
        Multivariate auto-, partial- and cross-correlation functions for panel data. 
        Panel data to (ts-)array conversions.
    (5) List processing: Recursive list search, splitting, 
        extraction/subsetting, apply, and generalized row-binding / unlisting to data frame.
    (6) Advanced data exploration: Fast (grouped, weighted, panel-decomposed) 
        summary statistics and descriptive tools.",2022-06-14,Sebastian Krantz,"https://sebkrantz.github.io/collapse/,
https://github.com/SebKrantz/collapse,
https://twitter.com/collapse_R",TRUE,https://github.com/sebkrantz/collapse,412827,377,2022-07-10T05:27:20Z,1095.0318302387268
collateral,"Map functions while capturing results, errors, warnings, messages and other output tidily, then filter and summarise data frames or lists on the basis of those side effects.",2021-10-25,James Goldie,"https://collateral.jamesgoldie.dev,
https://github.com/jimjam-slam/collateral",TRUE,https://github.com/jimjam-slam/collateral,8168,39,2021-10-26T09:59:13Z,209.43589743589743
collections,"Provides high performance container data types such
    as queues, stacks, deques, dicts and ordered dicts. Benchmarks
    <https://randy3k.github.io/collections/articles/benchmark.html> have
    shown that these containers are asymptotically more efficient than
    those offered by other packages.",2020-08-10,Randy Lai,https://github.com/randy3k/collections,TRUE,https://github.com/randy3k/collections,130482,89,2021-11-09T17:21:17Z,1466.0898876404494
coloc,"Performs the colocalisation tests described in
    Giambartolomei et al (2013) <doi:10.1371/journal.pgen.1004383>,
    Wallace (2020) <doi:10.1371/journal.pgen.1008720>,
    Wallace (2021) <doi:10.1101/2021.02.23.432421>.",2022-07-05,Chris Wallace,https://github.com/chr1swallace/coloc,TRUE,https://github.com/chr1swallace/coloc,32536,72,2022-06-24T13:53:06Z,451.8888888888889
colorblindcheck,"Compare color palettes with simulations of color vision deficiencies - deuteranopia, protanopia, and tritanopia.
        It includes calculation of distances between colors, and creating summaries of differences between a color palette and simulations of color vision deficiencies.
        This work was inspired by the blog post at <http://www.vis4.net/blog/2018/02/automate-colorblind-checking/>.",2021-09-09,Jakub Nowosad,https://github.com/Nowosad/colorblindcheck,TRUE,https://github.com/nowosad/colorblindcheck,3959,17,2022-07-01T14:03:36Z,232.88235294117646
colormap,Allows to generate colors from palettes defined in the colormap module of 'Node.js'. (see <https://github.com/bpostlethwaite/colormap> for more information). In total it provides 44 distinct palettes made from sequential and/or diverging colors. In addition to the pre defined palettes you can also specify your own set of colors. There are also scale functions that can be used with 'ggplot2'.,2016-11-15,Bhaskar Karambelkar,https://github.com/bhaskarvk/colormap,TRUE,https://github.com/bhaskarvk/colormap,32597,55,2021-09-30T14:44:26Z,592.6727272727272
ColorNameR,"A tool for transforming coordinates in a color space to common
    color names using data from the Royal Horticultural Society and the
    International Union for the Protection of New Varieties of Plants.",2021-07-08,Marco Sánchez Beeckman,https://github.com/msanchez-beeckman/ColorNameR,TRUE,https://github.com/msanchez-beeckman/colornamer,4357,6,2021-07-11T12:17:34Z,726.1666666666666
colourlovers,"Provides access to the COLOURlovers <https://www.colourlovers.com/>
    API, which offers color inspiration and color palettes.",2020-12-09,Andrew Heiss,https://github.com/andrewheiss/colourlovers,TRUE,https://github.com/andrewheiss/colourlovers,19167,99,2021-08-31T16:40:49Z,193.6060606060606
colourpicker,"A colour picker that can be used as an input in 'Shiny' apps
    or Rmarkdown documents. The colour picker supports alpha opacity, custom
    colour palettes, and many more options. A Plot Colour Helper tool is
    available as an 'RStudio' Addin, which helps you pick colours to use in your
    plots. A more generic Colour Picker 'RStudio' Addin is also provided to let 
    you select colours to use in your R code.",2021-10-04,Dean Attali,https://github.com/daattali/colourpicker,TRUE,https://github.com/daattali/colourpicker,1003152,171,2021-12-30T14:31:02Z,5866.3859649122805
comat,"Builds co-occurrence matrices based on spatial raster data.
    It includes creation of weighted co-occurrence matrices (wecoma) and 
    integrated co-occurrence matrices 
    (incoma; Vadivel et al. (2007) <doi:10.1016/j.patrec.2007.01.004>).",2022-01-29,Jakub Nowosad,https://nowosad.github.io/comat/,TRUE,https://github.com/nowosad/comat,18296,4,2022-01-29T15:14:13Z,4574
combiroc,"Provides functions and a workflow to easily and powerfully calculating specificity, sensitivity and ROC curves of biomarkers combinations. Allows to rank and select multi-markers signatures as well as to find the best performing sub-signatures. The method used was first published as a Shiny app and described in Mazzara et al. (2017) <doi:10.1038/srep45477> and further described in Bombaci & Rossi (2019) <doi:10.1007/978-1-4939-9164-8_16>.",2021-08-17,Ivan Ferrari,https://github.com/ingmbioinfo/combiroc,TRUE,https://github.com/ingmbioinfo/combiroc,3608,3,2022-03-15T10:30:33Z,1202.6666666666667
cometr,"A convenient 'R' wrapper to the 'Comet' API, which is a cloud
    platform allowing you to track, compare, explain and optimize machine
    learning experiments and models. Experiments can be viewed on the 'Comet'
    online dashboard at <https://www.comet.ml>.",2020-08-13,Doug Blank,https://github.com/comet-ml/cometr,TRUE,https://github.com/comet-ml/cometr,12021,7,2022-03-02T16:30:27Z,1717.2857142857142
comorbidity,"Computing comorbidity indices and scores such as the weighted Charlson
  score (Charlson, 1987 <doi:10.1016/0021-9681(87)90171-8>) and the Elixhauser
  comorbidity score (Elixhauser, 1998 <doi:10.1097/00005650-199801000-00004>)
  using ICD-9-CM or ICD-10 codes (Quan, 2005 <doi:10.1097/01.mlr.0000182534.19832.83>).
  Australian and Swedish modifications of the Charlson Comorbidity Index are available
  as well (Sundararajan, 2004 <doi:10.1016/j.jclinepi.2004.03.012> and Ludvigsson, 2021 
  <doi:10.2147/CLEP.S282475>).",2022-04-06,Alessandro Gasparini,"https://ellessenne.github.io/comorbidity/,
https://github.com/ellessenne/comorbidity/",TRUE,https://github.com/ellessenne/comorbidity,30002,54,2022-04-06T15:14:49Z,555.5925925925926
comorosmaps,"Maps of Comoro Islands. Layers include the country coastline, each island coastline and administrative regions boundaries.",2022-06-06,Housni Hassani,https://github.com/hhousni/comorosmaps,TRUE,https://github.com/hhousni/comorosmaps,275,0,2022-06-07T15:57:27Z,NA
comparator,"Implements functions for comparing strings, sequences and 
    numeric vectors for clustering and record linkage applications. 
    Supported comparison functions include: generalized edit distances 
    for comparing sequences/strings, Monge-Elkan similarity for fuzzy 
    comparison of token sets, and L-p distances for comparing numeric 
    vectors. Where possible, comparison functions are implemented in 
    C/C++ to ensure good performance.",2022-03-16,Neil Marchant,https://github.com/ngmarchant/comparator,TRUE,https://github.com/ngmarchant/comparator,7415,11,2022-03-16T07:46:43Z,674.0909090909091
comparer,"Quickly run experiments to compare the run time and output of
    code blocks. The function mbc() can make fast comparisons of code,
    and will calculate statistics comparing the resulting outputs.
    It can be used to compare model fits to the same data or
    see which function runs faster.
    The R6 class ffexp$new() runs a function using all possible combinations
    of selected inputs. This is useful for comparing the effect of
    different parameter values. It can also run in parallel and
    automatically save intermediate results, which is very useful
    for long computations.",2021-03-29,Collin Erickson,https://github.com/CollinErickson/comparer,TRUE,https://github.com/collinerickson/comparer,14276,2,2022-05-07T14:09:18Z,7138
ComplexUpset,"UpSet plots are an improvement over Venn Diagram for set overlap visualizations.
    Striving to bring the best of the 'UpSetR' and 'ggplot2', this package offers a way to create
    complex overlap visualisations, using simple and familiar tools, i.e. geoms of 'ggplot2'.
    For introduction to UpSet concept, see Lex et al. (2014) <doi:10.1109/TVCG.2014.2346248>.",2021-12-11,Michał Krassowski,"https://github.com/krassowski/complex-upset,
https://krassowski.github.io/complex-upset/",TRUE,https://github.com/krassowski/complex-upset,17817,296,2022-07-01T21:04:15Z,60.192567567567565
comtradr,"Interface with and extract data from the United Nations Comtrade 
  API <https://comtrade.un.org/data/>. Comtrade provides country level shipping 
  data for a variety of commodities, these functions allow for easy API query 
  and data returned as a tidy data frame.",2022-04-20,Chris Muir,"https://docs.ropensci.org/comtradr/,
https://github.com/ropensci/comtradr",TRUE,https://github.com/ropensci/comtradr,22977,39,2022-06-15T00:06:39Z,589.1538461538462
concatipede,"Concatenation of multiple sequence alignments based on a
    correspondence table that can be edited in Excel <doi:10.5281/zenodo.5130603>.",2021-08-06,Matteo Vecchi,"https://github.com/tardipede/concatipede,
https://tardipede.github.io/concatipede/",TRUE,https://github.com/tardipede/concatipede,4060,0,2022-04-12T07:35:54Z,NA
concaveman,The concaveman function ports the 'concaveman' (<https://github.com/mapbox/concaveman>) library from 'mapbox'. It computes the concave polygon(s) for one or several set of points.,2020-05-11,Joël Gombin,"https://joelgombin.github.io/concaveman/,
http://www.github.com/joelgombin/concaveman/",TRUE,https://github.com/joelgombin/concaveman,125889,57,2022-06-20T21:10:36Z,2208.5789473684213
concom,"Provides a function for fast computation of the connected
    components of an undirected graph (though not faster than the
    components() function of the 'igraph' package) from the edges or the
    adjacency matrix of the graph. Based on this one, a function to
    compute the connected components of a triangle 'rgl' mesh is also
    provided.",2022-06-15,Stéphane Laurent,https://github.com/stla/concom,TRUE,https://github.com/stla/concom,225,1,2022-06-14T09:23:08Z,225
concordance,"A set of utilities for matching products in different
	     classification codes used in international trade
	     research. It supports concordance between the Harmonized
	     System (HS0, HS1, HS2, HS3, HS4, HS5, HS combined), the Standard 
	     International Trade Classification (SITC1, SITC2, SITC3, SITC4), 
	     the North American Industry Classification System (NAICS combined),
	     as well as the Broad Economic Categories (BEC), the International 
	     Standard of Industrial Classification (ISIC), and the Standard Industrial 
	     Classification (SIC). It also provides code nomenclature/descriptions 
	     look-up, Rauch classification look-up (via concordance to SITC2), and
	     trade elasticity look-up (via concordance to HS0 or SITC3
	     codes).",2020-04-24,Steven Liao,NA,TRUE,https://github.com/insongkim/concordance,18977,10,2022-02-23T02:30:57Z,1897.7
concstats,"Based on individual market shares of all participants in a
    market or space or their respective sales figures, the package offers
    a set of different structural and concentration measures frequently -
    and not so frequently - used in research and in practice. Measures can
    be calculated in groups or individually. The calculated measure or the
    resulting vector in table format should help practitioners make more
    informed decisions. Methods used in this package are from:
    1.  Chang, E. J., Guerra, S. M., de Souza Penaloza, R. A. & Tabak, B. M.
    (2005) ""Banking concentration: the Brazilian case"".
    2.  Cobham, A. and A. Summer (2013). ""Is It All About the Tails? The
    Palma Measure of Income Inequality"".
    3.  Garcia Alba Idunate, P. (1994). ""Un Indice de dominancia para el
    analisis de la estructura de los mercados"".
    4.  Ginevicius, R. and S. Cirba (2009). ""Additive measurement of market
    concentration"" <doi:10.3846/1611-1699.2009.10.191-198>.
    5.  Herfindahl, O. C. (1950), ""Concentration in the steel industry (PhD thesis)"".
    6.  Hirschmann, A. O. (1945), ""National power and structure of foreign trade"".
    7.  Melnik, A., O. Shy, and R. Stenbacka (2008), ""Assessing market dominance""
    <doi:10.1016/j.jebo.2008.03.010>.
    8.  Palma, J. G. (2006). ""Globalizing Inequality: 'Centrifugal' and
    'Centripetal' Forces at Work"".
    9.  Shannon, C. E. (1948). ""A Mathematical Theory of Communication"".",2022-05-14,Andreas Schneider,"https://github.com/schneiderpy/concstats,
https//schneiderpy.github.io/constats (website)",TRUE,https://github.com/schneiderpy/concstats,592,1,2022-06-17T23:01:28Z,592
concurve,"Computes compatibility (confidence) distributions along with their corresponding P-values,
    S-values, and likelihoods. The intervals can be plotted to form the distributions themselves.  
    Functions can be compared to one another to see how much they overlap. Results can be
    exported to Microsoft Word, Powerpoint, and TeX documents. The package currently supports 
    resampling methods, computing differences, generalized linear models, mixed-effects models, 
    survival analysis, and meta-analysis. These methods are discussed 
    by Schweder T, Hjort NL. (2016, ISBN:9781316445051) and 
    Rafi Z, Greenland S. (2020) <doi:10.1186/s12874-020-01105-9>.",2020-10-12,Zad Rafi,"https://data.lesslikely.com/concurve/,
https://github.com/zadrafi/concurve",TRUE,https://github.com/zadrafi/concurve,17163,16,2021-12-20T02:00:55Z,1072.6875
CondCopulas,"
  Provides functions for the estimation of conditional copulas models,
  various estimators of conditional Kendall's tau
  (proposed in Derumigny and Fermanian (2019a, 2019b, 2020) <doi:10.1515/demo-2019-0016>,
  <doi:10.1016/j.csda.2019.01.013>, <doi:10.1016/j.jmva.2020.104610>),
  and test procedures for the simplifying assumption
  (proposed in Derumigny and Fermanian (2017) <doi:10.1515/demo-2017-0011>
  and Derumigny, Fermanian and Min (2020) <arXiv:2008.09498>).",2022-04-25,Alexis Derumigny,https://github.com/AlexisDerumigny/CondCopulas,TRUE,https://github.com/alexisderumigny/condcopulas,1083,0,2022-05-26T17:40:48Z,NA
conductor,"Enable the use of 'Shepherd.js' to create tours in 'Shiny' 
    applications.",2022-04-28,Etienne Bacher,https://github.com/etiennebacher/conductor,TRUE,https://github.com/etiennebacher/conductor,546,12,2022-07-05T11:33:03Z,45.5
condvis2,"Constructs a shiny app function with interactive displays for conditional visualization of models, 
     data and density functions. An extended version of package 'condvis'. 
     Mark O'Connell, Catherine B. Hurley, Katarina Domijan (2017) <doi:10.18637/jss.v081.i05>.",2020-09-25,Catherine Hurley,https://github.com/cbhurley/condvis2,TRUE,https://github.com/cbhurley/condvis2,15119,5,2021-10-29T15:31:24Z,3023.8
config,"Manage configuration values across multiple environments (e.g.
  development, test, production). Read values using a function that determines
  the current environment and returns the appropriate value.",2020-12-17,Andrie de Vries,https://github.com/rstudio/config,TRUE,https://github.com/rstudio/config,2123030,209,2022-03-10T18:17:17Z,10158.038277511961
configural,"R functions for criterion profile analysis, Davison and Davenport (2002) <doi:10.1037/1082-989X.7.4.468> and meta-analytic criterion profile analysis, Wiernik, Wilmot, Davison, and Ones (2020) <doi:10.1037/met0000305>. Sensitivity analyses to aid in interpreting criterion profile analysis results are also included.",2021-01-18,Brenton M. Wiernik,NA,TRUE,https://github.com/bwiernik/configural,13771,4,2022-01-18T14:46:27Z,3442.75
confintr,"Calculates classic and/or bootstrap confidence intervals for
    many parameters such as the population mean, variance, interquartile
    range (IQR), median absolute deviation (MAD), skewness, kurtosis,
    Cramer's V, odds ratio, R-squared, quantiles (incl. median),
    proportions, different types of correlation measures, difference in
    means, quantiles and medians. Many of the classic confidence intervals
    are described in Smithson, M. (2003, ISBN: 978-0761924999). Bootstrap
    confidence intervals are calculated with the R package 'boot'. Both
    one- and two-sided intervals are supported.",2022-01-28,Michael Mayer,https://github.com/mayer79/confintr,TRUE,https://github.com/mayer79/confintr,10968,6,2022-04-06T19:58:52Z,1828
conflicted,"R's default conflict management system gives the most
    recently loaded package precedence. This can make it hard to detect
    conflicts, particularly when they arise because a package update
    creates ambiguity that did not previously exist. 'conflicted' takes a
    different approach, making every conflict an error and forcing you to
    choose which function to use.",2021-11-26,Hadley Wickham,"https://conflicted.r-lib.org, https://github.com/r-lib/conflicted",TRUE,https://github.com/r-lib/conflicted,740949,217,2021-11-27T15:43:34Z,3414.5115207373274
conformalbayes,"Provides functions to construct finite-sample calibrated predictive 
    intervals for Bayesian models, following the approach in Barber et al. 
    (2021) <doi:10.1214/20-AOS1965>. These intervals are calculated efficiently
    using importance sampling for the leave-one-out residuals. By default,
    the intervals will also reflect the relative uncertainty in the Bayesian 
    model, using the locally-weighted conformal methods of Lei et al. (2018)
    <doi:10.1080/01621459.2017.1307116>.",2022-03-10,Cory McCartan,"https://github.com/CoryMcCartan/conformalbayes,
https://corymccartan.github.io/conformalbayes/",TRUE,https://github.com/corymccartan/conformalbayes,1086,0,2022-03-10T20:59:48Z,NA
conformalInference.fd,"It computes full conformal, split conformal and multi split
    conformal prediction regions when the response has functional nature.
    Moreover, the package also contain a plot function to visualize the
    output of the split conformal.
    To guarantee consistency, the package structure mimics the univariate 
    'conformalInference' package of professor Ryan Tibshirani.
    The main references for the code are: 
    Diquigiovanni, Fontana, and Vantini (2021) <arXiv:2102.06746>, 
    Diquigiovanni, Fontana, and Vantini (2021) <arXiv:2106.01792>,
    Solari, and Djordjilovic (2021) <arXiv:2103.00627>.",2022-03-23,Paolo Vergottini,"https://github.com/ryantibs/conformal ,
https://github.com/paolo-vergo/conformalInference.fd",TRUE,https://github.com/ryantibs/conformal,1318,123,2022-04-02T11:54:09Z,10.715447154471544
conformalInference.multi,"It computes full conformal, split conformal and multi split
    conformal prediction regions when the response variable is
    multivariate (i.e. dimension is greater than one). Moreover, the
    package also contain plot functions to visualize the output of the
    full and split conformal functions. 
    To guarantee consistency, the package structure mimics the univariate 'conformalInference'
    package of professor Ryan Tibshirani.
    The main references for the code are: 
    Lei et al. (2016) <arXiv:1604.04173>,
    Diquigiovanni, Fontana, and Vantini (2021) <arXiv:2102.06746>, 
    Diquigiovanni, Fontana, and Vantini (2021) <arXiv:2106.01792>,
    Solari, and Djordjilovic (2021) <arXiv:2103.00627>.",2022-03-16,Paolo Vergottini,"https://github.com/ryantibs/conformal,
https://github.com/paolo-vergo/conformalInference.multi",TRUE,https://github.com/ryantibs/conformal,1320,123,2022-04-02T11:54:09Z,10.731707317073171
ConformalSmallest,"An implementation of efficiency first conformal prediction (EFCP) and validity first conformal prediction (VFCP) that demonstrates both validity (coverage guarantee) and efficiency (width guarantee). To learn how to use it, check the vignettes for a quick tutorial. The package is based on the work by Yang Y., Kuchibhotla A.,(2021) <arxiv:2104.13871>.",2021-08-09,Yachong Yang,https://github.com/Elsa-Yang98/ConformalSmallest,TRUE,https://github.com/elsa-yang98/conformalsmallest,3816,1,2021-08-10T11:51:00Z,3816
confoundr,"Implements three covariate-balance diagnostics for time-varying confounding and selection-bias in complex longitudinal data, as described in Jackson (2016) <doi:10.1097/EDE.0000000000000547> and Jackson (2019) <doi:10.1093/aje/kwz136>. Diagnostic 1 assesses measured confounding/selection-bias, diagnostic 2 assesses exposure-covariate feedback, and diagnostic 3 assesses residual confounding/selection-bias after inverse probability weighting or propensity score stratification. All diagnostics appropriately account for exposure history, can be adapted to assess a particular depth of covariate history, and can be implemented in right-censored data. Balance assessments can be obtained for all times, selected-times, or averaged across person-time. The balance measures are reported as tables or plots. These diagnostics can be applied to the study of multivariate exposures including time-varying exposures, direct effects, interaction, and censoring.",2019-09-20,John W. Jackson,NA,TRUE,https://github.com/jwjackson/confoundr,13155,10,2022-03-25T17:32:34Z,1315.5
conjurer,Builds synthetic data applicable across multiple domains. This package also provides flexibility to control data distribution to make it relevant to many industry examples.,2022-05-01,Sidharth Macherla,https://www.foyi.co.nz/posts/documentation/documentationconjurer/,TRUE,https://github.com/sidharthmacherla/conjurer,16342,6,2022-06-05T00:24:31Z,2723.6666666666665
connectwidgets,"A collection of helper functions and 'htmlwidgets' to help publishers
    curate content collections on 'RStudio Connect'. The components,
    Card, Grid, Table, Search, and Filter can be used to produce a
    showcase page or gallery contained within a static or interactive
    R Markdown page.",2021-07-23,Brian Smith,"https://rstudio.github.io/connectwidgets/,
https://github.com/rstudio/connectwidgets",TRUE,https://github.com/rstudio/connectwidgets,4320,12,2022-01-03T21:35:24Z,360
conos,"Wires together large collections of single-cell RNA-seq datasets, which allows for both the identification of recurrent cell clusters and the propagation of information between datasets in multi-sample or atlas-scale collections. 'Conos' focuses on the uniform mapping of homologous cell types across heterogeneous sample collections. For instance, users could investigate a collection of dozens of peripheral blood samples from cancer patients combined with dozens of controls, which perhaps includes samples of a related tissue such as lymph nodes. This package interacts with data available through the 'conosPanel' package, which is available in a 'drat' repository. To access this data package, see the instructions at <https://github.com/kharchenkolab/conos>. The size of the 'conosPanel' package is approximately 12 MB.",2022-04-11,Evan Biederstedt,https://github.com/kharchenkolab/conos,TRUE,https://github.com/kharchenkolab/conos,10843,146,2022-04-01T03:55:07Z,74.26712328767124
conquer,"Estimation and inference for conditional linear quantile regression models using a convolution smoothed approach. In the low-dimensional setting, efficient gradient-based methods are employed for fitting both a single model and a regression process over a quantile range. Normal-based and (multiplier) bootstrap confidence intervals for all slope coefficients are constructed. In high dimensions, the conquer method is complemented with flexible types of penalties (Lasso, elastic-net, group lasso, sparse group lasso, scad and mcp) to deal with complex low-dimensional structures.",2022-03-21,Xiaoou Pan,https://github.com/XiaoouPan/conquer,TRUE,https://github.com/xiaooupan/conquer,5619348,11,2022-05-22T21:00:32Z,510849.8181818182
ConR,"Multi-species estimation of geographical range parameters
	for preliminary assessment of conservation status following Criterion B of the 
	International Union for Conservation of Nature (IUCN, 
	see <http://www.iucnredlist.org>).",2020-05-18,Gilles Dauby,https://gdauby.github.io/ConR/,TRUE,https://github.com/gdauby/conr,20309,6,2021-08-25T10:48:00Z,3384.8333333333335
conserveR,"Helping biologists to choose the most suitable approach to link their research to conservation. After answering few questions on the data available, geographic and taxonomic scope, 'conserveR' ranks existing methods for conservation prioritization and systematic conservation planning by suitability. The methods data base of 'conserveR' contains 133 methods for conservation prioritization based on a systematic review of > 12,000 scientific publications from the fields of spatial conservation prioritization, systematic conservation planning, biogeography and ecology.",2021-08-02,Alexander Zizka,https://github.com/azizka/conserveR,TRUE,https://github.com/azizka/conserver,3937,3,2021-08-17T11:57:07Z,1312.3333333333333
consort,"To make it easy to create CONSORT diagrams for the transparent reporting of participant allocation in randomized, controlled clinical trials. This is done by creating a standardized disposition data, and using this data as the source for the creation a standard CONSORT diagram. Human effort by supplying text labels on the node can also be achieved.",2021-12-20,Alim Dayim,https://github.com/adayim/consort/,TRUE,https://github.com/adayim/consort,4793,5,2022-06-20T22:08:40Z,958.6
contact,"Process spatially- and temporally-discrete data into contact and 
   social networks, and facilitate network analysis by randomizing 
   individuals' movement paths and/or related categorical variables. To use 
   this package, users need only have a dataset containing spatial data 
   (i.e., latitude/longitude, or planar x & y coordinates), individual IDs 
   relating spatial data to specific individuals, and date/time information 
   relating spatial locations to temporal locations. The functionality of this 
   package ranges from data ""cleaning"" via multiple filtration functions, to 
   spatial and temporal data interpolation, and network creation and analysis. 
   Functions within this package are not limited to describing interpersonal 
   contacts. Package functions can also identify and quantify ""contacts"" 
   between individuals and fixed areas (e.g., home ranges, water bodies, 
   buildings, etc.). As such, this package is an incredibly useful resource 
   for facilitating epidemiological, ecological, ethological and sociological 
   research.",2021-05-17,Trevor Farthing,NA,TRUE,https://github.com/lanzaslab/contact,14605,2,2021-12-06T02:32:51Z,7302.5
contactdata,"Data package for the supplementary data in Prem et al. (2017)
    <doi:10.1371/journal.pcbi.1005697>.
    Provides easy access to contact data for 152 countries, for use in
    epidemiological, demographic or social sciences research.",2021-02-19,Hugo Gruson,"https://bisaloo.github.io/contactdata/,
https://github.com/bisaloo/contactdata",TRUE,https://github.com/bisaloo/contactdata,7927,5,2022-02-18T09:06:10Z,1585.4
container,"Extends the functionality of base R list and
    provides specialized data structures deque,
    set, dict, and dict.table, the latter to extend the data.table
    package.",2022-02-19,Roman Pahl,https://rpahl.github.io/container/,TRUE,https://github.com/rpahl/container,16064,8,2022-04-16T14:52:33Z,2008
contentid,"An interface for creating, registering, and resolving content-based
             identifiers for data management. Content-based identifiers rely on
             the 'cryptographic' hashes to refer to the files they identify, thus,
             anyone possessing the file can compute the identifier using a 
             well-known standard algorithm, such as 'SHA256'.  By registering
             a URL at which the content is accessible to a public archive (such as 
             Hash Archive) or depositing data in a scientific repository such 'Zenodo',
             'DataONE' or 'SoftwareHeritage', the content identifier can serve 
             many functions typically associated with A Digital Object Identifier
             ('DOI').  Unlike location-based identifiers like 'DOIs', content-based
             identifiers permit the same content to be registered in many locations.",2021-11-29,Carl Boettiger,https://github.com/cboettig/contentid,TRUE,https://github.com/cboettig/contentid,19917,39,2022-06-14T20:46:18Z,510.6923076923077
conText,"A fast, flexible and transparent framework to estimate context-specific word and short document embeddings using the 'a la carte' 
    embeddings approach developed by Khodak et al. (2018) <arXiv:1805.05388> and evaluate hypotheses about covariate effects on embeddings using 
    the regression framework developed by Rodriguez et al. (2021)<https://github.com/prodriguezsosa/EmbeddingRegression>.",2022-04-05,Pedro L. Rodriguez,https://github.com/prodriguezsosa/EmbeddingRegression,TRUE,https://github.com/prodriguezsosa/embeddingregression,3216,62,2022-06-02T00:27:24Z,51.87096774193548
contfrac,Various utilities for evaluating continued fractions.,2018-05-17,Robin K. S. Hankin,https://github.com/RobinHankin/contfrac.git,TRUE,https://github.com/robinhankin/contfrac,605132,0,2021-11-16T23:58:16Z,NA
contingencytables,"Provides functions to perform statistical inference of data organized in contingency tables. This package is a companion to the ""Statistical Analysis of Contingency Tables"" book by Fagerland et al. <ISBN 9781466588172>.",2022-06-07,Waldir Leoncio,https://contingencytables.com/,TRUE,https://github.com/ocbe-uio/contingencytables,2017,1,2022-06-07T14:00:32Z,2017
contrast,"One degree of freedom contrasts for 'lm', 'glm', 'gls', and 'geese' objects.",2021-12-14,Alan OCallaghan,https://github.com/Alanocallaghan/contrast,TRUE,https://github.com/alanocallaghan/contrast,42835,1,2021-12-14T23:06:29Z,42835
contribution,"Contribution table for credit assignment based on 'ggplot2'.
    This can improve the author contribution information in academic journals and personal CV.  ",2022-03-23,Shixiang Wang,https://github.com/openbiox/contribution,TRUE,https://github.com/openbiox/contribution,18498,6,2022-03-23T03:23:49Z,3083
convdistr,"Convolute probabilistic distributions using the random generator 
 function of each distribution. A new random number generator function is created that 
 perform the mathematical operation on the individual random samples from the 
 random generator function of each distribution. See the documentation for examples.",2021-04-20,Aponte John,https://github.com/johnaponte/convdistr,TRUE,https://github.com/johnaponte/convdistr,4954,1,2022-01-06T18:37:27Z,4954
ConvergenceClubs,"Functions for clustering regions that form convergence clubs, according to the definition of Phillips and Sul (2009) <doi:10.1002/jae.1080>. A package description is available in Sichera and Pizzuto (2019).",2022-06-13,Roberto Sichera,https://CRAN.R-project.org/package=ConvergenceClubs,TRUE,https://github.com/rhobis/convergenceclubs,17036,2,2022-06-13T16:56:20Z,8518
convey,"Variance estimation on indicators of income concentration and
    poverty using complex sample survey designs. Wrapper around the
    'survey' package.",2022-04-27,Anthony Damico,https://guilhermejacob.github.io/context/,TRUE,https://github.com/ajdamico/convey,28162,16,2022-07-08T17:18:05Z,1760.125
coop,"Fast implementations of the co-operations: covariance,
    correlation, and cosine similarity.  The implementations are
    fast and memory-efficient and their use is resolved
    automatically based on the input data, handled by R's S3
    methods.  Full descriptions of the algorithms and benchmarks
    are available in the package vignettes.",2021-09-19,Drew Schmidt,https://github.com/wrathematics/coop,TRUE,https://github.com/wrathematics/coop,37346,28,2021-11-23T12:20:19Z,1333.7857142857142
CoordinateCleaner,"Automated flagging of common spatial and temporal errors in biological and paleontological collection data, for the use in conservation, ecology and paleontology. Includes automated tests to easily flag (and exclude) records assigned to country or province centroid, the open ocean, the headquarters of the Global Biodiversity Information Facility, urban areas or the location of biodiversity institutions (museums, zoos, botanical gardens, universities). Furthermore identifies per species outlier coordinates, zero coordinates, identical latitude/longitude and invalid coordinates. Also implements an algorithm to identify data sets with a significant proportion of rounded coordinates. Especially suited for large data sets. The reference for the methodology is: Zizka et al. (2019) <doi:10.1111/2041-210X.13152>.",2021-10-21,Alexander Zizka,https://ropensci.github.io/CoordinateCleaner/,TRUE,https://github.com/ropensci/coordinatecleaner,36264,60,2021-10-20T18:22:14Z,604.4
copent,"The nonparametric methods for estimating copula entropy and transfer entropy are implemented. The method for estimating copula entropy composes of two simple steps: estimating empirical copula by rank statistic and estimating copula entropy with k-Nearest-Neighbour method. The method for estimating transfer entropy composes of two steps: estimating three copula entropy terms and then calculate transfer entropy from the estimated copula entropy terms. Copula Entropy is a mathematical concept for multivariate statistical independence measuring and testing, and proved to be equivalent to mutual information. Estimating copula entropy can be applied to many cases, including but not limited to variable selection and causal discovery (by estimating transfer entropy). Please refer to Ma and Sun (2011) <doi:10.1016/S1007-0214(11)70008-6> and Ma (2019) <arXiv:1910.04375> for more information.",2021-03-21,MA Jian,https://github.com/majianthu/copent,TRUE,https://github.com/majianthu/copent,12563,23,2022-07-08T22:21:20Z,546.2173913043479
CopernicusDEM,"Copernicus Digital Elevation Model datasets (DEM) of 90 and 30 meters resolution using the 'awscli' command line tool. The Copernicus (DEM) is included in the Registry of Open Data on 'AWS (Amazon Web Services)' and represents the surface of the Earth including buildings, infrastructure and vegetation.",2022-02-06,Lampros Mouselimis,https://github.com/mlampros/CopernicusDEM,TRUE,https://github.com/mlampros/copernicusdem,6519,14,2022-02-07T07:47:19Z,465.64285714285717
CopSens,"Implements the copula-based sensitivity analysis method, 
  as discussed in Copula-based Sensitivity Analysis for Multi-Treatment Causal Inference with Unobserved Confounding
  <arXiv:2102.09412>, with Gaussian copula adopted in particular.",2022-05-12,Jiajing Zheng,https://github.com/JiajingZ/CopSens,TRUE,https://github.com/jiajingz/copsens,475,1,2022-04-21T22:59:17Z,475
copyseparator,Assembles two or more gene copies from short-read Next-Generation Sequencing data. Works best when there are only two gene copies and read length >=250 base pairs. High and relatively even coverage are important.,2022-07-06,Lei Yang,https://github.com/LeiYang-Fish/copyseparator,TRUE,https://github.com/leiyang-fish/copyseparator,406,0,2022-07-06T17:41:16Z,NA
coRanking,"Calculates the co-ranking matrix to assess the
    quality of a dimensionality reduction.",2022-02-07,Guido Kraemer,https://www.guido-kraemer.com/software/coranking/,TRUE,https://github.com/gdkrmr/coranking,54442,9,2022-02-07T16:13:22Z,6049.111111111111
Corbi,"Provides a bundle of basic and fundamental bioinformatics tools,
    such as network querying and alignment, subnetwork extraction and search,
    network biomarker identification.",2022-05-30,Ling-Yun Wu,https://github.com/wulingyun/Corbi,TRUE,https://github.com/wulingyun/corbi,19586,5,2022-05-03T08:31:21Z,3917.2
corels,"The 'Certifiably Optimal RulE ListS (Corels)' learner by
 Angelino et al described in <arXiv:1704.01701> provides interpretable decision
 rules with an optimality guarantee, and is made available to R with this package.
 See the file 'AUTHORS' for a list of copyright holders and contributors.",2022-02-04,Dirk Eddelbuettel,https://github.com/corels/rcppcorels,TRUE,https://github.com/corels/rcppcorels,9266,41,2022-02-04T17:08:38Z,226
corncob,"Statistical modeling for correlated count data using the beta-binomial distribution, described in Martin et al. (2020) <doi:10.1214/19-AOAS1283>. It allows for both mean and overdispersion covariates.",2021-03-11,Bryan D Martin,https://github.com/bryandmartin/corncob,TRUE,https://github.com/bryandmartin/corncob,7288,82,2021-10-18T18:18:56Z,88.8780487804878
coro,"Provides 'coroutines' for R, a family of functions that
    can be suspended and resumed later on. This includes 'async'
    functions (which await) and generators (which yield). 'Async'
    functions are based on the concurrency framework of the 'promises'
    package. Generators are based on a dependency free iteration
    protocol defined in 'coro' and are compatible with iterators from
    the 'reticulate' package.",2021-12-03,Lionel Henry,https://github.com/r-lib/coro,TRUE,https://github.com/r-lib/coro,54003,118,2022-06-29T14:33:30Z,457.6525423728813
coronavirus,Provides a daily summary of the Coronavirus (COVID-19) cases by state/province. Data source: Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus <https://systems.jhu.edu/research/public-health/ncov/>.,2022-06-24,Rami Krispin,https://github.com/RamiKrispin/coronavirus,TRUE,https://github.com/ramikrispin/coronavirus,60887,469,2022-07-10T08:18:03Z,129.8230277185501
corporaexplorer,"Facilitates dynamic exploration of text collections through an
    intuitive graphical user interface and the power of regular expressions.
    The package contains 1) a helper function to convert a data frame to a
    'corporaexplorerobject', 2) a 'Shiny' app for fast and flexible exploration
    of a 'corporaexplorerobject', and 3) a 'Shiny' app for simple
    retrieval/extraction of documents from a 'corporaexplorerobject' in a
    reading-friendly format. The package also includes demo apps with which
    one can explore Jane Austen's novels and the State of the Union Addresses
    (data from the 'janeaustenr' and 'sotu' packages respectively).",2022-06-20,Kristian Lundby Gjerde,"https://kgjerde.github.io/corporaexplorer/,
https://github.com/kgjerde/corporaexplorer",TRUE,https://github.com/kgjerde/corporaexplorer,18522,58,2022-06-20T13:02:17Z,319.3448275862069
corpustools,"Provides text analysis in R, focusing on the use of a tokenized text format. In this format, the positions of tokens are maintained, and each token can be annotated (e.g., part-of-speech tags, dependency relations).
    Prominent features include advanced Lucene-like querying for specific tokens or contexts (e.g., documents, sentences),
    similarity statistics for words and documents, exporting to DTM for compatibility with many text analysis packages,
    and the possibility to reconstruct original text from tokens to facilitate interpretation.",2022-05-11,Kasper Welbers and Wouter van Atteveldt,https://github.com/kasperwelbers/corpustools,TRUE,https://github.com/kasperwelbers/corpustools,33016,26,2022-06-21T13:05:01Z,1269.8461538461538
corrcoverage,"Using a computationally efficient method, the package can
    be used to find the corrected coverage estimate of a credible set 
    of putative causal variants from Bayesian genetic fine-mapping. 
    The package can also be used to obtain a corrected credible set
    if required; that is, the smallest set of variants required such 
    that the corrected coverage estimate of the resultant credible set is  
    within some user defined accuracy of the desired coverage.
    Maller et al. (2012) <doi:10.1038/ng.2435>,
    Wakefield (2009) <doi:10.1002/gepi.20359>,
    Fortune and Wallace (2018) <doi:10.1093/bioinformatics/bty898>.",2019-12-06,Anna Hutchinson,https://annahutch.github.io/corrcoverage,TRUE,https://github.com/annahutch/corrcoverage,9331,6,2021-11-26T13:16:39Z,1555.1666666666667
correlation,"Lightweight package for computing different kinds
    of correlations, such as partial correlations, Bayesian correlations,
    multilevel correlations, polychoric correlations, biweight
    correlations, distance correlations and more. Part of the 'easystats'
    ecosystem.",2022-05-20,Dominique Makowski,https://easystats.github.io/correlation/,TRUE,https://github.com/easystats/correlation,250548,332,2022-06-17T06:29:14Z,754.6626506024096
corrplot,Provides a visual exploratory tool on correlation matrix that supports automatic variable reordering to help detect hidden patterns among variables.,2021-11-18,Taiyun Wei,https://github.com/taiyun/corrplot,TRUE,https://github.com/taiyun/corrplot,7624287,257,2022-02-07T06:55:46Z,29666.486381322957
corrr,"A tool for exploring correlations.
    It makes it possible to easily perform routine tasks when
    exploring correlation matrices such as ignoring the diagonal,
    focusing on the correlations of certain variables against others,
    or rearranging and visualizing the matrix in terms of the
    strength of the correlations.",2020-11-24,Max Kuhn,"https://github.com/tidymodels/corrr, https://corrr.tidymodels.org",TRUE,https://github.com/tidymodels/corrr,242997,563,2022-05-15T19:19:36Z,431.61101243339255
corrsieve,"Statistical summary of STRUCTURE output. STRUCTURE is a K-means clustering method for inferring population structure and assigning individuals to populations using genetic data. Pritchard JK, Stephens M, Donnelly PJ (2000) <DOI:10.1093/genetics/155.2.945>. <https://web.stanford.edu/group/pritchardlab/structure.html>.",2022-05-02,Michael G. Campana,https://github.com/campanam/rCorrSieve,TRUE,https://github.com/campanam/rcorrsieve,21028,0,2022-05-02T20:29:22Z,NA
cort,"Provides S4 classes and methods to fit several copula models: The classic empirical checkerboard copula and the empirical checkerboard copula with known margins, see Cuberos, Masiello and Maume-Deschamps (2019) <doi:10.1080/03610926.2019.1586936> are proposed. These two models allow to fit copulas in high dimension with a small number of observations, and they are always proper copulas. Some flexibility is added via a possibility to differentiate the checkerboard parameter by dimension. The last model consist of the implementation of the Copula Recursive Tree algorithm proposed by Laverny, Maume-Deschamps, Masiello and Rullière (2020) <arXiv:2005.02912>, including the localised dimension reduction, which fits a copula by recursive splitting of the copula domain. We also provide an efficient way of mixing copulas, allowing to bag the algorithm into a forest, and a generic way of measuring d-dimensional boxes with a copula.",2020-12-01,Oskar Laverny,https://github.com/lrnv/cort,TRUE,https://github.com/lrnv/cort,12517,4,2022-03-22T11:15:50Z,3129.25
cosinor,"A set of simple functions that transforms longitudinal
    data to estimate the cosinor linear model as described in Tong (1976).
    Methods are given to summarize the mean, amplitude and acrophase, to
    predict the mean annual outcome value, and to test the coefficients.",2022-05-24,Michael Sachs,https://github.com/sachsmc/cosinor,TRUE,https://github.com/sachsmc/cosinor,21088,5,2022-05-24T06:45:40Z,4217.6
cosmicsig,"A data package with 2 main package variables: 'signature' and 'etiology'. 
     The 'signature' variable contains the latest mutational signature profiles 
     released on COSMIC <https://cancer.sanger.ac.uk/signatures/> for 4 mutation
     types:
     * single base substitutions in the context of preceding and following bases,
     * Strand bias single base substitutions: single base substitutions
        from transcribed regions, that take into consideration the 
        the transcribed versus non-transcribed strand,
     * Doublet base substitutions, and
     * Small insertions and deletions.
    The 'etiology' variable provides the known or hypothesized causes of signatures. 
    'cosmicsig' stands for COSMIC signatures. Please run ?'cosmicsig' for more
    information.",2021-12-20,Steven Rozen,https://github.com/Rozen-Lab/cosmicsig,TRUE,https://github.com/rozen-lab/cosmicsig,1978,1,2021-12-23T06:07:12Z,1978
costsensitive,"Reduction-based techniques for cost-sensitive multi-class classification, in which each observation has a different cost for classifying it into one class, and the goal is to predict the class with the minimum expected cost for each new observation.
	Implements Weighted All-Pairs (Beygelzimer, A., Langford, J., & Zadrozny, B., 2008, <doi:10.1007/978-0-387-79361-0_1>), Weighted One-Vs-Rest (Beygelzimer, A., Dani, V., Hayes, T., Langford, J., & Zadrozny, B., 2005, <https://dl.acm.org/citation.cfm?id=1102358>) and Regression One-Vs-Rest.
	Works with arbitrary classifiers taking observation weights, or with regressors. Also implements cost-proportionate rejection sampling for working with classifiers
	that don't accept observation weights.",2019-07-28,David Cortes,https://github.com/david-cortes/costsensitive,TRUE,https://github.com/david-cortes/costsensitive,18298,39,2022-05-30T19:50:18Z,469.1794871794872
CoTiMA,"The 'CoTiMA' package performs meta-analyses of correlation matrices of repeatedly measured variables taken from 
   studies that used different time intervals. Different time intervals between measurement occasions impose problems for 
   meta-analyses because the effects (e.g. cross-lagged effects) cannot be simply aggregated, for example, by means of common 
   fixed or random effects analysis. However, continuous time math, which is applied in 'CoTiMA', can be used to extrapolate or 
   intrapolate the results from all studies to any desired time lag. By this, effects obtained in studies that used different 
   time intervals can be meta-analyzed. 'CoTiMA' fits models to empirical data using the structural equation model (SEM) package 
   'ctsem', the effects specified in a SEM are related to parameters that are not directly included in the model (i.e., 
   continuous time parameters; together, they represent the continuous time structural equation model, CTSEM). Statistical 
   model comparisons and significance tests are then performed on the continuous time parameter estimates. 'CoTiMA' also allows 
   analysis of publication bias (Egger's test, PET-PEESE estimates, zcurve analysis etc.) and analysis of statistical power 
   (post hoc power, required sample sizes). See Dormann, C., Guthier, C., & Cortina, J. M. (2019) <doi:10.1177/1094428119847277>.
   and Guthier, C., Dormann, C., & Voelkle, M. C. (2020) <doi:10.1037/bul0000304>.",2022-01-20,Christian Dormann,https://github.com/CoTiMA/CoTiMA,TRUE,https://github.com/cotima/cotima,6761,1,2022-07-09T14:45:14Z,6761
Counternull,"Calculates the difference in average change over time for
 variables in given dataset. Generates a randomization matrix to resample data
 for permutation testing. Creates and plots null distributions and calculates 
 P-Values. Identifies potential counternull values by generating and plotting 
 counternull distributions.
 Rosenthal and Rubin (1994) <doi:10.1111/j.1467-9280.1994.tb00281.x>.",2021-12-17,Mabene Yasmine,https://github.com/ymabene/Counternull,TRUE,https://github.com/ymabene/counternull,1821,0,2022-03-26T07:01:09Z,NA
countrycode,"Standardize country names, convert them into one of 40
    different coding schemes, convert between coding schemes, and assign
    region descriptors.",2022-05-04,Vincent Arel-Bundock,https://vincentarelbundock.github.io/countrycode/,TRUE,https://github.com/vincentarelbundock/countrycode,550702,291,2022-07-08T04:41:52Z,1892.446735395189
coveffectsplot,"Produce forest plots to visualize covariate effects using either
    the command line or an interactive 'Shiny' application.",2022-05-30,Samer Mouksassi,https://github.com/smouksassi/coveffectsplot,TRUE,https://github.com/smouksassi/coveffectsplot,17406,23,2022-06-18T20:01:02Z,756.7826086956521
COVID19,"Provides a daily summary of COVID-19 cases, deaths, recovered, tests,
  vaccinations, and hospitalizations for 230+ countries, 760+ regions, 
  and 12000+ administrative divisions of lower level. 
  Includes policy measures, mobility data, and geospatial identifiers.
  Data source: COVID-19 Data Hub <https://covid19datahub.io>.",2022-02-22,Emanuele Guidotti,https://covid19datahub.io,TRUE,https://github.com/covid19datahub/covid19,53826,245,2022-06-05T14:23:43Z,219.69795918367348
covid19.analytics,"Load and analyze updated time series worldwide data of reported cases for the Novel Coronavirus Disease (COVID-19) from different sources, including the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) data repository <https://github.com/CSSEGISandData/COVID-19>, ""Our World in Data"" <https://github.com/owid/> among several others. The datasets reporting the COVID-19 cases are available in two main modalities, as a time series sequences and aggregated data for the last day with greater spatial resolution. Several analysis, visualization and modelling functions are available in the package that will allow the user to compute and visualize total number of cases, total number of changes and growth rate globally or for an specific geographical location, while at the same time generating models using these trends; generate interactive visualizations and generate Susceptible-Infected-Recovered (SIR) model for the disease spread.",2022-04-06,Marcelo Ponce,https://mponce0.github.io/covid19.analytics/,TRUE,https://github.com/mponce0/covid19.analytics,34595,34,2022-05-26T14:49:06Z,1017.5
covid19br,"Set of functions to import COVID-19 pandemic data into R. The Brazilian COVID-19 data, obtained from the official Brazilian repository at <https://covid.saude.gov.br/>, is available at country, region, state, and city-levels. The package also downloads the world-level COVID-19 data from the John Hopkins University's repository.",2022-03-30,Fabio Demarqui,https://fndemarqui.github.io/covid19br/,TRUE,https://github.com/fndemarqui/covid19br,10933,4,2022-03-30T10:52:07Z,2733.25
covid19brazil,"Dataset with strategic information about COVID-19 in Brazil.
    Data for municipalities, states, region and Brazil. Data source:
    Sistema Unico de Saude - SUS.",2022-06-23,Alexandre Loures,https://github.com/alexandreloures/covid19Brazil,TRUE,https://github.com/alexandreloures/covid19brazil,188,0,2022-07-09T22:50:37Z,NA
covid19india,"Pull raw and pre-cleaned versions of national and state-level 
    COVID-19 time-series data from covid19india.org <https://www.covid19india.org>. 
    Easily obtain and merge case count data, testing data, and vaccine data. 
    Also assists in calculating the time-varying effective reproduction number 
    with sensible parameters for COVID-19.",2021-10-09,Max Salvatore,https://github.com/maxsal/covid19india,TRUE,https://github.com/maxsal/covid19india,4619,0,2022-01-25T15:40:41Z,NA
covid19italy,"Provides a daily summary of the Coronavirus (COVID-19) cases in Italy by country, region and province level. Data source: Presidenza del Consiglio dei Ministri - Dipartimento della Protezione Civile <https://www.protezionecivile.it/>.",2021-07-28,Rami Krispin,https://github.com/RamiKrispin/covid19italy,TRUE,https://github.com/ramikrispin/covid19italy,16304,42,2022-07-09T16:22:20Z,388.1904761904762
covid19sf,"Provides a verity of summary tables of the Covid19 cases in San Francisco. Data source: San Francisco, Department of Public Health - Population Health Division <https://datasf.org/opendata/>.",2021-12-19,Rami Krispin,https://github.com/RamiKrispin/covid19sf,TRUE,https://github.com/ramikrispin/covid19sf,7945,11,2022-07-10T13:00:40Z,722.2727272727273
covidcast,"Tools for Delphi's 'COVIDcast Epidata' API: data access, maps and
    time series plotting, and basic signal processing. The API includes a
    collection of numerous indicators relevant to the COVID-19 pandemic in the
    United States, including official reports, de-identified aggregated medical
    claims data, large-scale surveys of symptoms and public behavior, and
    mobility data, typically updated daily and at the county level. All data
    sources are documented at
    <https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html>.",2021-05-04,Alex Reinhart,"https://cmu-delphi.github.io/covidcast/covidcastR/,
https://github.com/cmu-delphi/covidcast",TRUE,https://github.com/cmu-delphi/covidcast,86501,29,2021-10-23T01:33:57Z,2982.793103448276
COVIDIBGE,"Provides tools for downloading, reading and analyzing the PNAD COVID19,
	a household survey from Brazilian Institute of Geography and Statistics - IBGE.
	The data must be downloaded from the official website <https://www.ibge.gov.br/>. 
	Further analysis must be made using package 'survey'.",2021-11-30,Gabriel Assuncao,NA,TRUE,https://github.com/gabriel-assuncao/covidibge,10576,2,2021-11-30T13:20:13Z,5288
covidsymptom,"The COVID Symptom Study is a non-commercial project that uses a free mobile app to facilitate real-time data collection of symptoms, exposures, and risk factors related to COVID19. The package allows easy access to summary statistics data from COVID Symptom Study Sweden.",2022-01-26,Hugo Fitipaldi,https://github.com/csss-resultat/covidsymptom,TRUE,https://github.com/csss-resultat/covidsymptom,6332,3,2022-07-02T18:14:18Z,2110.6666666666665
covr,"Track and report code coverage for your package and (optionally)
    upload the results to a coverage service like 'Codecov' <https://codecov.io> or
    'Coveralls' <https://coveralls.io>. Code coverage is a measure of the amount of
    code being exercised by a set of tests. It is an indirect measure of test
    quality and completeness. This package is compatible with any testing
    methodology or framework and tracks coverage of both R code and compiled
    C/C++/FORTRAN code.",2020-09-16,Jim Hester,"https://covr.r-lib.org, https://github.com/r-lib/covr",TRUE,https://github.com/r-lib/covr,7621993,302,2022-07-05T13:24:55Z,25238.387417218542
CovTools,"Covariance is of universal prevalence across various disciplines within statistics.
    We provide a rich collection of geometric and inferential tools for convenient analysis of
    covariance structures, topics including distance measures, mean covariance estimator,
    covariance hypothesis test for one-sample and two-sample cases, and covariance estimation.
    For an introduction to covariance in multivariate statistical analysis,
    see Schervish (1987) <doi:10.1214/ss/1177013111>.",2021-08-13,Kisung You,https://github.com/kisungyou/CovTools,TRUE,https://github.com/kisungyou/covtools,20025,11,2021-08-13T16:34:51Z,1820.4545454545455
cowsay,"Allows printing of character strings as messages/warnings/etc.
    with ASCII animals, including cats, cows, frogs, chickens, ghosts,
    and more.",2020-02-06,Scott Chamberlain,https://github.com/sckott/cowsay,TRUE,https://github.com/sckott/cowsay,52442,231,2021-11-14T05:27:00Z,227.021645021645
coxrobust,"An implementation of robust estimation in Cox model. Functionality includes fitting efficiently and robustly Cox proportional hazards regression model in its basic form, where explanatory variables are time independent with one event per subject.  Method is based on a smooth modification of the partial likelihood.",2022-04-06,Shana Scogin,https://github.com/ShanaScogin/coxrobust,TRUE,https://github.com/shanascogin/coxrobust,18753,3,2022-04-08T20:56:58Z,6251
CPC,"Implements cluster-polarization coefficient for measuring distributional
	polarization in single or multiple dimensions, as well as associated functions.
	Contains support for hierarchical clustering, k-means, partitioning around medoids,
	density-based spatial clustering with noise, and manually imposed cluster membership.",2022-06-01,Isaac Mehlhaff,https://github.com/imehlhaff/CPC,TRUE,https://github.com/imehlhaff/cpc,300,0,2022-05-30T17:02:55Z,NA
cpi,"A general test for conditional independence in supervised learning 
  algorithms as proposed by Watson & Wright (2021) <doi:10.1007/s10994-021-06030-6>. 
  Implements a conditional variable importance measure which can be applied to any supervised 
  learning algorithm and loss function. Provides statistical inference procedures without 
  parametric assumptions and applies equally well to continuous and categorical predictors 
  and outcomes.",2022-03-03,Marvin N. Wright,"https://github.com/bips-hb/cpi, https://bips-hb.github.io/cpi/",TRUE,https://github.com/bips-hb/cpi,1154,8,2022-03-15T05:09:36Z,144.25
cplm,"Likelihood-based and Bayesian methods for various compound Poisson linear models based on Zhang, Yanwei (2013) <https://link.springer.com/article/10.1007/s11222-012-9343-7>.",2022-04-26,Yanwei (Wayne) Zhang,https://github.com/actuaryzhang/cplm,TRUE,https://github.com/actuaryzhang/cplm,206168,13,2022-04-26T16:56:43Z,15859.076923076924
cpp11,"Provides a header only, C++11 interface to R's C
    interface.  Compared to other approaches 'cpp11' strives to be safe
    against long jumps from the C API as well as C++ exceptions, conform
    to normal R function semantics and supports interaction with 'ALTREP'
    vectors.",2021-11-30,Jim Hester,"https://cpp11.r-lib.org, https://github.com/r-lib/cpp11",TRUE,https://github.com/r-lib/cpp11,22679348,168,2022-06-23T06:54:16Z,134996.11904761905
cppcheckR,"Allow to run 'Cppcheck' (<https://cppcheck.sourceforge.io/>)
    on 'C' and 'C++' files with a 'R' command or a 'RStudio' addin. The report
    appears in the 'RStudio' viewer pane as a formatted 'HTML' file. It is
    also possible to get this report with a 'shiny' application. 'Cppcheck' 
    can spot many error types and it can also give some recommendations on the 
    code.",2022-06-10,Stéphane Laurent,https://github.com/stla/cppcheckR,TRUE,https://github.com/stla/cppcheckr,271,2,2022-06-09T15:38:40Z,135.5
cpr,"Implementation of the Control Polygon Reduction and Control Net
    Reduction methods for finding parsimonious B-spline regression models.",2017-03-07,Peter DeWitt,https://github.com/dewittpe/cpr/,TRUE,https://github.com/dewittpe/cpr,17569,2,2022-02-14T18:38:53Z,8784.5
cpsR,"Load Current Population Survey (CPS) microdata into R using the
    'Census Bureau Data' API
    (<https://www.census.gov/data/developers/data-sets.html>), including basic
    monthly CPS and CPS ASEC microdata.",2022-02-09,Matt Saenz,https://github.com/matt-saenz/cpsR,TRUE,https://github.com/matt-saenz/cpsr,3427,5,2022-02-11T10:42:34Z,685.4
cpsurvsim,"Simulates time-to-event data
    with type I right censoring using two methods: the inverse CDF
    method and our proposed memoryless method. The latter method
    takes advantage of the memoryless property of survival and
    simulates a separate distribution between change-points. We
    include two parametric distributions: exponential and Weibull.
    Inverse CDF method draws on the work of Rainer Walke (2010), 
    <https://www.demogr.mpg.de/papers/technicalreports/tr-2010-003.pdf>.",2022-01-14,Camille Hochheimer,https://github.com/camillejo/cpsurvsim,TRUE,https://github.com/camillejo/cpsurvsim,13475,0,2021-12-20T01:18:38Z,NA
cptcity,Incorporates colour gradients from the 'cpt-city' web archive available at <http://soliton.vm.bytemark.co.uk/pub/cpt-city/>. ,2020-10-02,Sergio Ibarra-Espinosa,https://github.com/ibarraespinosa/cptcity,TRUE,https://github.com/ibarraespinosa/cptcity,21445,12,2022-02-02T02:17:10Z,1787.0833333333333
cptec,"Allows to retrieve data from the
    'CPTEC/INPE' weather forecast API. 'CPTEC' stands for 'Centro de Previsão
    de Tempo e Estudos Climáticos' and 'INPE' for 'Instituto Nacional de
    Pesquisas Espaciais'. 'CPTEC' is the most advanced numerical weather and
    climate forecasting center in Latin America, with high-precision short
    and medium-term weather forecasting since the beginning of 1995. See
    <https://www.cptec.inpe.br/> for more information.",2022-06-07,Renato Prado Siqueira,https://github.com/rpradosiqueira/cptec,TRUE,https://github.com/rpradosiqueira/cptec,16963,8,2022-06-07T18:48:52Z,2120.375
CR2,"Estimate different types of cluster robust standard errors (CR0, CR1, CR2) with degrees of freedom adjustments. Standard errors are computed based on 'Liang and Zeger' (1986) <doi:10.1093/biomet/73.1.13> and Bell and 'McCaffrey' <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2002002/article/9058-eng.pdf?st=NxMjN1YZ>. Functions used in Huang and Li <doi:10.3758/s13428-021-01627-0>, Huang, 'Wiedermann', and 'Zhang' <doi:10.1080/00273171.2022.2077290>, and Huang, 'Zhang', and Li (forthcoming: Journal of Research on Educational Effectiveness).",2022-06-16,Francis Huang,https://github.com/flh3/CR2,TRUE,https://github.com/flh3/cr2,463,0,2022-07-01T21:09:55Z,NA
CRABS,"Features tools for exploring congruent phylogenetic birth-death models. It can construct the pulled speciation- and net-diversification rates from a reference model. Given alternative speciation- or extinction rates, it can construct new models that are congruent with the reference model. Functionality is included to sample new rate functions, and to visualize the distribution of one congruence class. See also Louca & Pennell (2020) <doi:10.1038/s41586-020-2176-1>.",2022-06-20,Bjørn Tore Kopperud,https://github.com/afmagee/CRABS,TRUE,https://github.com/afmagee/crabs,217,3,2022-06-17T13:28:23Z,72.33333333333333
crandep,"The dependencies of CRAN packages can be analysed in a network fashion. For each package we can obtain the packages that it depends, imports, suggests, etc. By iterating this procedure over a number of packages, we can build, visualise, and analyse the dependency network, enabling us to have a bird's-eye view of the CRAN ecosystem. One aspect of interest is the number of reverse dependencies of the packages, or equivalently the in-degree distribution of the dependency network. This can be fitted by the power law and/or an extreme value mixture distribution <arXiv:2008.03073>, of which functions are provided.",2022-06-03,Clement Lee,https://github.com/clement-lee/crandep,TRUE,https://github.com/clement-lee/crandep,13347,6,2022-06-02T23:44:47Z,2224.5
cranlike,"A set of functions to manage 'CRAN'-like repositories
    efficiently.",2018-11-26,Gábor Csárdi,https://github.com/r-hub/cranlike,TRUE,https://github.com/r-hub/cranlike,18582,24,2021-11-19T12:42:15Z,774.25
crestr,"Applies the CREST climate reconstruction
             method. It can be used using the calibration data that can be obtained
             through the package or by importing private data. An ensemble of
             graphical outputs were designed to facilitate the use of the
             package and the interpretation of the results. More information can
             be obtained from Chevalier (2022) <doi:10.5194/cp-18-821-2022>.",2022-07-01,Manuel Chevalier,"https://github.com/mchevalier2/crestr,
https://mchevalier2.github.io/crestr/index.html",TRUE,https://github.com/mchevalier2/crestr,2365,8,2022-07-08T13:25:37Z,295.625
crfsuite,"Wraps the 'CRFsuite' library <https://github.com/chokkan/crfsuite> allowing users 
    to fit a Conditional Random Field model and to apply it on existing data.
    The focus of the implementation is in the area of Natural Language Processing where this R package allows you to easily build and apply models 
    for named entity recognition, text chunking, part of speech tagging, intent recognition or classification of any category you have in mind. Next to training, a small web application
    is included in the package to allow you to easily construct training data.",2021-11-12,Jan Wijffels,https://github.com/bnosac/crfsuite,TRUE,https://github.com/bnosac/crfsuite,20010,56,2021-11-12T21:00:36Z,357.32142857142856
cricketdata,"Data on international and other major cricket matches from 
  ESPNCricinfo <https://www.espncricinfo.com> and Cricsheet <https://cricsheet.org>.
  This package provides some functions to download the data into tibbles ready
  for analysis.",2022-02-14,Rob Hyndman,"http://pkg.robjhyndman.com/cricketdata/,
https://github.com/robjhyndman/cricketdata",TRUE,https://github.com/robjhyndman/cricketdata,1862,55,2022-06-01T22:14:30Z,33.85454545454545
crimedata,"Gives convenient access to publicly available police-recorded open
    crime data from large cities in the United States that are included in the
    Crime Open Database <https://osf.io/zyaqn/>.",2022-06-21,Matthew Ashby,"http://pkgs.lesscrime.info/crimedata/,
https://github.com/mpjashby/crimedata",TRUE,https://github.com/mpjashby/crimedata,16130,17,2022-06-18T22:17:42Z,948.8235294117648
crimeutils,"A collection of functions that make it easier to understand crime (or other)
    data, and assist others in understanding it. The package helps you read data 
    from various sources, clean it, fix column names, and graph the data. ",2021-02-03,Jacob Kaplan,https://github.com/jacobkap/crimeutils/,TRUE,https://github.com/jacobkap/crimeutils,8446,0,2022-03-06T19:37:18Z,NA
crispRdesignR,"Designs guide sequences for CRISPR/Cas9 genome editing and 
    provides information on sequence features pertinent to guide 
    efficiency. Sequence features include annotated off-target 
    predictions in a user-selected genome and a predicted efficiency 
    score based on the model described in Doench et al. (2016) 
    <doi:10.1038/nbt.3437>. Users are able to import additional genomes 
    and genome annotation files to use when searching and annotating 
    off-target hits. All guide sequences and off-target data can be 
    generated through the 'R' console with sgRNA_Design() or through 
    'crispRdesignR's' user interface with crispRdesignRUI(). CRISPR 
    (Clustered Regularly Interspaced Short Palindromic Repeats) and the 
    associated protein Cas9 refer to a technique used in genome editing.",2021-01-11,Dylan Beeber,<https://github.com/dylanbeeber/crispRdesignR>,TRUE,https://github.com/dylanbeeber/crisprdesignr,11441,9,2021-12-21T21:54:33Z,1271.2222222222222
criticalpath,"
    An R implementation of the Critical Path Method (CPM).
    CPM is a method used to estimate the minimum project duration and determine 
    the amount of scheduling flexibility on the logical network paths within the 
    schedule model. The flexibility is in terms of early start, early finish, 
    late start, late finish, total float and free float. Beside, it permits 
    to quantify the complexity of network diagram through the analysis of 
    topological indicators. Finally, it permits to change the activities duration 
    to perform what-if scenario analysis. The package was built based on following 
    references: To make topological sorting and other graph operation, we use 
    Csardi, G. & Nepusz, T. (2005) 
    <https://www.researchgate.net/publication/221995787_The_Igraph_Software_Package_for_Complex_Network_Research>;
    For schedule concept, the reference was Project Management Institute (2017) 
    <https://www.pmi.org/pmbok-guide-standards/foundational/pmbok>;
    For standards terms, we use Project Management Institute (2017) 
    <https://www.pmi.org/pmbok-guide-standards/lexicon>;
    For algorithms on Critical Path Method development, we use 
    Vanhoucke, M. (2013) <doi:10.1007/978-3-642-40438-2> and 
    Vanhoucke, M. (2014) <doi:10.1007/978-3-319-04331-9>; 
    And, finally, for topological definitions, we use
    Vanhoucke, M. (2009) <doi:10.1007/978-1-4419-1014-1>.",2022-03-13,Rubens Jose Rosa,"https://rubensjoserosa.com/criticalpath,
https://github.com/rubens2005/criticalpath",TRUE,https://github.com/rubens2005/criticalpath,6622,1,2022-02-05T19:24:50Z,6622
crmPack,"Implements a wide range of model-based dose
    escalation designs, ranging from classical and modern continual
    reassessment methods (CRMs) based on dose-limiting toxicity endpoints to
    dual-endpoint designs taking into account a biomarker/efficacy outcome. The
    focus is on Bayesian inference, making it very easy to setup a new design
    with its own JAGS code. However, it is also possible to implement 3+3
    designs for comparison or models with non-Bayesian estimation. The whole
    package is written in a modular form in the S4 class system, making it very
    flexible for adaptation to new models, escalation or stopping rules.",2022-04-25,Daniel Sabanes Bove,https://github.com/roche/crmPack,TRUE,https://github.com/roche/crmpack,18074,12,2022-07-08T19:03:16Z,1506.1666666666667
cronR,"Create, edit, and remove 'cron' jobs on your unix-alike system. The package provides a set of easy-to-use wrappers
    to 'crontab'. It also provides an RStudio add-in to easily launch and schedule your scripts.",2022-02-17,Jan Wijffels,https://github.com/bnosac/cronR,TRUE,https://github.com/bnosac/cronr,43001,259,2022-05-18T21:12:01Z,166.02702702702703
crossmap,"Provides an extension to the 'purrr' family of mapping
    functions to apply a function to each combination of elements in a
    list of inputs.  Also includes functions for automatically detecting
    output type in mapping functions, finding every combination of
    elements of lists or rows of data frames, and applying multiple models
    to multiple subsets of a dataset.",2021-04-02,Alexander Rossell Hayes,"https://crossmap.rossellhayes.com,
https://github.com/rossellhayes/crossmap",TRUE,https://github.com/rossellhayes/crossmap,8541,13,2022-03-04T00:13:11Z,657
crossnma,"Network meta-analysis and meta-regression (allows including up to 3 covariates) for individual participant data, aggregate data, and mixtures of both formats using the three-level hierarchical model. Each format can come from randomized controlled trials or non-randomized studies or mixtures of both. Estimates are generated in a Bayesian framework using JAGS. The implemented models are described by Hamza et al. 2022 <DOI:10.48550/arXiv.2203.06350>.",2022-04-15,Tasnim Hamza,https://github.com/htx-r/crossnma,TRUE,https://github.com/htx-r/crossnma,614,0,2022-03-30T15:02:41Z,NA
crossrun,"Joint distribution of number of crossings and the 
  longest run in a series of independent Bernoulli trials. The
  computations uses an iterative procedure where computations 
  are based on results from shorter series. The procedure 
  conditions on the start value and partitions by further 
  conditioning on the position of the first crossing (or none).",2022-04-13,Tore Wentzel-Larsen,https://github.com/ToreWentzel-Larsen/crossrun,TRUE,https://github.com/torewentzel-larsen/crossrun,12568,0,2022-04-12T14:59:07Z,NA
crosstable,"Create descriptive tables for continuous and categorical variables. 
    Apply summary statistics and counting function, with or without a grouping variable, and create beautiful reports using 'rmarkdown' or 'officer'.
    You can also compute effect sizes and statistical tests if needed.",2022-02-25,Dan Chaltiel,"https://danchaltiel.github.io/crosstable/,
https://github.com/DanChaltiel/crosstable/",TRUE,https://github.com/danchaltiel/crosstable,23199,78,2022-07-07T20:05:13Z,297.4230769230769
crosstalk,"Provides building blocks for allowing HTML widgets to communicate
    with each other, with Shiny or without (i.e. static .html files). Currently
    supports linked brushing and filtering.",2021-11-04,Carson Sievert,https://rstudio.github.io/crosstalk/,TRUE,https://github.com/rstudio/crosstalk,9334856,263,2021-11-19T15:40:36Z,35493.74904942966
crplyr,"In order to facilitate analysis of datasets hosted on the Crunch
    data platform <https://crunch.io/>, the 'crplyr' package implements 'dplyr'
    methods on top of the Crunch backend. The usual methods 'select', 'filter',
    'group_by', 'summarize', and 'collect' are implemented in such a way as to
    perform as much computation on the server and pull as little data locally
    as possible.",2022-05-01,Greg Freedman Ellis,"https://crunch.io/r/crplyr/, https://github.com/Crunch-io/crplyr",TRUE,https://github.com/crunch-io/crplyr,20237,5,2022-04-30T00:45:52Z,4047.4
crs,"Regression splines that handle a mix of continuous and categorical (discrete) data often encountered in applied settings. I would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <https://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <https://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://www.sharcnet.ca>).",2022-03-31,Jeffrey S. Racine,https://github.com/JeffreyRacine/R-Package-crs,TRUE,https://github.com/jeffreyracine/r-package-crs,86130,15,2022-03-30T21:54:33Z,5742
crseEventStudy,"Based on Dutta et al. (2018) <doi:10.1016/j.jempfin.2018.02.004>, this package provides their standardized test for abnormal returns in long-horizon event studies. The methods used improve the major weaknesses of size, power, and robustness of long-run statistical tests described in Kothari/Warner (2007) <doi:10.1016/B978-0-444-53265-7.50015-9>. Abnormal returns are weighted by their statistical precision (i.e., standard deviation), resulting in abnormal standardized returns. This procedure efficiently captures the heteroskedasticity problem. Clustering techniques following Cameron et al. (2011) <doi:10.1198/jbes.2010.07136> are adopted for computing cross-sectional correlation robust standard errors. The statistical tests in this package therefore accounts for potential biases arising from returns' cross-sectional correlation, autocorrelation, and volatility clustering without power loss.",2022-02-23,Siegfried Köstlmeier,https://github.com/skoestlmeier/crseEventStudy,TRUE,https://github.com/skoestlmeier/crseeventstudy,17493,1,2022-02-22T13:22:28Z,17493
CRTConjoint,"Computes p-value according to the CRT using the HierNet test statistic. For more details, see Ham, Imai, Janson (2022) ""Using Machine Learning to Test Causal Hypotheses in Conjoint Analysis"" <arXiv:2201.08343>.",2022-06-09,Dae Woong Ham,https://github.com/daewoongham97/CRTConjoint,TRUE,https://github.com/daewoongham97/crtconjoint,249,1,2022-06-07T16:00:58Z,249
crunch,"The Crunch.io service <https://crunch.io/> provides a cloud-based
    data store and analytic engine, as well as an intuitive web interface.
    Using this package, analysts can interact with and manipulate Crunch
    datasets from within R. Importantly, this allows technical researchers to
    collaborate naturally with team members, managers, and clients who prefer a
    point-and-click interface.",2022-05-02,Greg Freedman Ellis,"https://crunch.io/r/crunch/, https://github.com/Crunch-io/rcrunch",TRUE,https://github.com/crunch-io/rcrunch,40834,7,2022-05-02T23:03:14Z,5833.428571428572
CruzPlot,"A utility program oriented to create maps, plot data, and do basic data summaries
    of 'DAS' data <https://swfsc-publications.fisheries.noaa.gov/publications/TM/SWFSC/NOAA-TM-NMFS-SWFSC-305.PDF> 
    produced by 'WinCruz' from the Southwest Fisheries Science Center.
    <https://www.fisheries.noaa.gov/west-coast/science-data/california-current-marine-mammal-assessment-program>.",2022-06-02,Sam Woodman,"https://smwoodman.github.io/CruzPlot/,
https://github.com/smwoodman/CruzPlot/",TRUE,https://github.com/smwoodman/cruzplot,9784,1,2022-06-02T16:42:49Z,9784
crypto2,"Retrieves crypto currency information and historical prices as well as information on the exchanges they are listed on. Historical data contains daily open, high, low and close values for all crypto currencies. All data is scraped from <https://coinmarketcap.com> via their 'web-api'.",2022-01-25,Sebastian Stoeckl  (<https://orcid.org/0000-0002-4196-6093>,https://github.com/sstoeckl/crypto2,TRUE,https://github.com/sstoeckl/crypto2,7436,29,2022-01-25T16:45:08Z,256.41379310344826
cryptowatchR,"An API wrapper for 'Cryptowatch' to get prices and other information (e.g., volume, trades, order books, bid and ask prices, live quotes, and more) about cryptocurrencies and crypto exchanges. See <https://docs.cryptowat.ch/rest-api> for a detailed documentation.",2021-06-09,Lorenz Brachtendorf,https://github.com/lorenzbr/cryptowatchR,TRUE,https://github.com/lorenzbr/cryptowatchr,5439,7,2022-03-23T14:32:34Z,777
CSCDRNA,"Provides accurate cell type proportion estimation by incorporating covariance structure in both single-cell and bulk RNA-seq datasets into the analysis. For more detail, see Karimnezhad, A. (2022) <doi:10.1101/2022.05.13.491858>.",2022-06-24,Ali Karimnezhad,NA,TRUE,https://github.com/empiricalbayes/cscdrna,559,0,2022-06-24T17:09:01Z,NA
cSEM,"Estimate, assess, test, and study linear, nonlinear, hierarchical 
  and multigroup structural equation models using composite-based approaches 
  and procedures, including estimation techniques such as partial least squares 
  path modeling (PLS-PM) and its derivatives (PLSc, ordPLSc, robustPLSc), 
  generalized structured component analysis (GSCA), generalized structured 
  component analysis with uniqueness terms (GSCAm), generalized canonical 
  correlation analysis (GCCA), principal component analysis (PCA), 
  factor score regression (FSR) using sum score, regression or 
  bartlett scores (including bias correction using Croon’s approach), 
  as well as several tests and typical postestimation procedures 
  (e.g., verify admissibility of the estimates, assess the model fit, 
  test the model fit etc.).",2021-04-19,Manuel E. Rademaker,"https://github.com/M-E-Rademaker/cSEM,
https://m-e-rademaker.github.io/cSEM/",TRUE,https://github.com/m-e-rademaker/csem,17805,17,2022-06-09T10:50:07Z,1047.3529411764705
cstab,"Selection of the number of clusters in cluster analysis using
    stability methods.",2018-06-19,Jonas M. B. Haslbeck,NA,TRUE,https://github.com/jmbh/cstab,18643,3,2021-12-15T18:27:15Z,6214.333333333333
csvwr,"Provide functions for reading and writing CSVW - i.e. CSV tables and JSON metadata.
    The metadata helps interpret CSV by setting the types and variable names.",2021-11-09,Robin Gower,"https://robsteranium.github.io/csvwr/,
https://github.com/Robsteranium/csvwr",TRUE,https://github.com/robsteranium/csvwr,5229,7,2022-07-07T08:05:18Z,747
ctbi,"Clean, decompose and aggregate univariate time series following the procedure ""Cyclic/trend decomposition using bin interpolation"" and the Logbox method for flagging outliers, both detailed in Ritter, F.: Technical note: A procedure to clean, decompose and aggregate time series, Hydrol. Earth Syst. Sci. Discuss. [preprint], <doi:10.5194/hess-2021-609>, in review.",2022-03-09,Francois Ritter,https://github.com/fritte2/ctbi,TRUE,https://github.com/fritte2/ctbi,797,0,2022-06-10T11:30:59Z,NA
ctf,"
    Column Text Format (CTF) is a new tabular data format designed for simplicity and performance.
    CTF is the simplest column store you can imagine: plain text files for each column in a table, and a metadata file.
    The underlying plain text means the data is human readable and familiar to programmers, unlike specialized binary formats.
    CTF is faster than row oriented formats like CSV when loading a subset of the columns in a table.
    This package provides functions to read and write CTF data from R.",2021-07-07,Clark Fitzgerald,https://github.com/julianofhernandez/ctf,TRUE,https://github.com/julianofhernandez/ctf,3749,1,2021-07-23T17:46:07Z,3749
cthist,"Retrieves historical versions of clinical trial registry
    entries.",2022-06-07,Benjamin Gregory Carlisle,https://github.com/bgcarlisle/cthist,TRUE,https://github.com/bgcarlisle/cthist,2917,1,2022-07-03T21:29:18Z,2917
ctmm,"Functions for identifying, fitting, and applying continuous-space, continuous-time stochastic movement models to animal tracking data.
  The package is described in Calabrese et al (2016) <doi:10.1111/2041-210X.12559>, with models and methods based on those introduced in
  Fleming & Calabrese et al (2014) <doi:10.1086/675504>,
  Fleming et al (2014) <doi:10.1111/2041-210X.12176>,
  Fleming et al (2015) <doi:10.1103/PhysRevE.91.032107>,
  Fleming et al (2015) <doi:10.1890/14-2010.1>,
  Fleming et al (2016) <doi:10.1890/15-1607>,
  Péron & Fleming et al (2016) <doi:10.1186/s40462-016-0084-7>,
  Fleming & Calabrese (2017) <doi:10.1111/2041-210X.12673>,
  Péron et al (2017) <doi:10.1002/ecm.1260>,
  Fleming et al (2017) <doi:10.1016/j.ecoinf.2017.04.008>,
  Fleming et al (2018) <doi:10.1002/eap.1704>,
  Winner & Noonan et al (2018) <doi:10.1111/2041-210X.13027>,
  Fleming et al (2019) <doi:10.1111/2041-210X.13270>,
  Noonan & Fleming et al (2019) <doi:10.1186/s40462-019-0177-1>,
  Fleming et al (2020) <doi:10.1101/2020.06.12.130195>,
  and
  Noonan et al (2021) <doi:10.1111/2041-210X.13597>.",2021-07-28,Christen H. Fleming,"https://github.com/ctmm-initiative/ctmm,
https://groups.google.com/g/ctmm-user",TRUE,https://github.com/ctmm-initiative/ctmm,48169,22,2022-07-10T10:16:53Z,2189.5
ctpm,"Functions for identifying, fitting, and applying continuous-time stochastic models to phylogenetic data.
  The package is based on methods introduced in
  Noonan et al. (2021) <doi:10.1101/2021.05.21.445056>.",2021-11-08,Michael J. Noonan,"https://github.com/NoonanM/ctpm,",TRUE,https://github.com/noonanm/ctpm,6001,0,2021-11-04T23:32:59Z,NA
ctrdata,"A system for querying, retrieving and analyzing
        protocol- and results-related information on clinical trials from
        three public registers, the 'European Union Clinical Trials Register'
        ('EUCTR', <https://www.clinicaltrialsregister.eu/>), 
        'ClinicalTrials.gov' ('CTGOV', <https://clinicaltrials.gov/>) and
        the 'ISRCTN' (<http://www.isrctn.com/>). 
        Trial information is downloaded, converted and stored in a database 
        ('PostgreSQL', 'SQLite' or 'MongoDB'; via package 'nodbi'). 
        Functions are included to identify de-duplicated records, 
        to easily find and extract variables (fields) of interest even 
        from complex nesting as used by the registers, and
        to update previous queries. 
        The package can be used for meta-analysis and trend-analysis of
        the design and conduct as well as for results of clinical trials.",2022-07-06,Ralf Herold,https://cran.r-project.org/package=ctrdata,TRUE,https://github.com/rfhb/ctrdata,22384,22,2022-07-10T06:30:21Z,1017.4545454545455
ctsem,"Hierarchical continuous (and discrete) time state space modelling, for linear
    and nonlinear systems measured by  continuous variables, with limited support for 
    binary data. The subject specific dynamic system is modelled as a stochastic 
    differential equation (SDE) or difference equation, measurement models are typically multivariate normal factor models. 
    Linear mixed effects SDE's estimated via maximum likelihood and optimization are the default.
    Nonlinearities,  (state dependent parameters) and random effects on all parameters
    are possible, using either max likelihood / max a posteriori optimization 
    (with optional importance sampling) or Stan's Hamiltonian Monte Carlo sampling. 
    See  <https://github.com/cdriveraus/ctsem/raw/master/vignettes/hierarchicalmanual.pdf>
    for details. Priors may be used. For the conceptual overview of the hierarchical Bayesian 
    linear SDE approach, 
    see <https://www.researchgate.net/publication/324093594_Hierarchical_Bayesian_Continuous_Time_Dynamic_Modeling>.
    Exogenous inputs may also be included, for an overview of such possibilities see <https://www.researchgate.net/publication/328221807_Understanding_the_Time_Course_of_Interventions_with_Continuous_Time_Dynamic_Models> .
    Stan based functions are not available on 32 bit Windows systems at present. 
    <https://cdriver.netlify.app/> contains some tutorial blog posts.",2022-03-10,Charles Driver,https://github.com/cdriveraus/ctsem,TRUE,https://github.com/cdriveraus/ctsem,36014,30,2022-07-07T09:20:42Z,1200.4666666666667
ctv,"Infrastructure for task views to CRAN-style repositories: Querying task views and installing the associated
             packages (client-side tools), generating HTML pages and storing task view information in the repository
	     (server-side tools).",2022-03-27,Achim Zeileis,"https://github.com/cran-task-views/ctv/,
https://ctv.R-Forge.R-project.org/",TRUE,https://github.com/cran-task-views/ctv,65428,35,2022-06-24T13:26:35Z,1869.3714285714286
cubature,"R wrappers around the cubature C library of Steven
    G. Johnson for adaptive multivariate integration over hypercubes
    and the Cuba C library of Thomas Hahn for deterministic and
    Monte Carlo integration. Scalar and vector interfaces for 
    cubature and Cuba routines are provided; the vector interfaces
    are highly recommended as demonstrated in the package
    vignette.",2022-03-22,Balasubramanian Narasimhan,https://bnaras.github.io/cubature/,TRUE,https://github.com/bnaras/cubature,702589,6,2022-03-22T20:40:30Z,117098.16666666667
cubble,A spatiotemperal data object in a relational data structure to separate the recording of time variant/ invariant variables.,2022-06-02,H. Sherry Zhang,https://github.com/huizezhang-sherry/cubble,TRUE,https://github.com/huizezhang-sherry/cubble,795,5,2022-06-21T05:09:31Z,159
cubfits,"Estimating mutation and selection coefficients on synonymous
       codon bias usage based on models of ribosome overhead cost (ROC).
       Multinomial logistic regression and Markov Chain Monte Carlo are used to
       estimate and predict protein production rates with/without the presence
       of expressions and measurement errors. Work flows with examples for
       simulation, estimation and prediction processes are also provided
       with parallelization speedup. The whole framework is tested with
       yeast genome and gene expression data of Yassour, et al. (2009)
       <doi:10.1073/pnas.0812841106>.",2021-11-07,Wei-Chen Chen,https://github.com/snoweye/cubfits,TRUE,https://github.com/snoweye/cubfits,21054,4,2021-11-07T01:54:08Z,5263.5
Cubist,Regression modeling using rules with added instance-based corrections.,2022-02-05,Max Kuhn,"https://topepo.github.io/Cubist//,
https://topepo.github.io/Cubist/",TRUE,https://github.com/topepo/cubist,815527,33,2022-02-07T00:52:09Z,24712.939393939392
cuda.ml,"R interface for RAPIDS cuML (<https://github.com/rapidsai/cuml>),
    a suite of GPU-accelerated machine learning libraries powered by CUDA
    (<https://en.wikipedia.org/wiki/CUDA>).",2022-01-08,Daniel Falbel,https://mlverse.github.io/cuda.ml/,TRUE,https://github.com/mlverse/cuda.ml,1807,20,2022-01-11T18:29:59Z,90.35
CUFF,"Utility functions that provides wrapper to descriptive base functions
  like cor, mean and table.  It makes use of the formula interface to pass
  variables to functions.  It also provides operators to concatenate (%+%), to
  repeat (%n%) and manage character vectors for nice display.",2022-02-22,Charles-Édouard Giguère,https://github.com/giguerch/CUFF,TRUE,https://github.com/giguerch/cuff,18701,0,2022-05-02T11:32:14Z,NA
cuperdec,"Calculates and visualises cumulative percent 'decay' curves,
    which are typically calculated from metagenomic taxonomic profiles.
    These can be used to estimate the level of expected 'endogenous' taxa
    at different abundance levels retrieved from metagenomic samples, when
    comparing to samples of known sampling site or source. Method
    described in Fellows Yates, J. A. et. al. (2021) Proceedings of the
    National Academy of Sciences USA <doi:10.1073/pnas.2021655118>.",2021-09-12,James A. Fellows Yates,https://github.com/jfy133/cuperdec,TRUE,https://github.com/jfy133/cuperdec,5556,3,2021-09-14T11:43:00Z,1852
cuRe,"Contains functions for estimating generalized parametric mixture and non-mixture cure models, loss of lifetime, mean residual lifetime, and crude event probabilities.",2022-05-16,Lasse Hjort Jakobsen,https://github.com/LasseHjort/cuRe,TRUE,https://github.com/lassehjort/cure,13043,5,2022-06-30T09:51:21Z,2608.6
curl,"The curl() and curl_download() functions provide highly
    configurable drop-in replacements for base url() and download.file() with
    better performance, support for encryption (https, ftps), gzip compression,
    authentication, and other 'libcurl' goodies. The core of the package implements a
    framework for performing fully customized requests where data can be processed
    either in memory, on disk, or streaming via the callback or connection
    interfaces. Some knowledge of 'libcurl' is recommended; for a more-user-friendly
    web client see the 'httr' package which builds on this package with http
    specific tools and logic.",2021-06-23,Jeroen Ooms,"https://github.com/jeroen/curl (devel) https://curl.se/libcurl/
(upstream)",TRUE,https://github.com/jeroen/curl,21321757,183,2022-06-22T14:58:33Z,116512.33333333333
cusumcharter,"Create CUSUM (cumulative sum) statistics from a vector or dataframe.
    Also create single or faceted CUSUM control charts, with or without control limits.
    Accepts vector, dataframe, tibble or data.table inputs.",2021-11-15,John MacKintosh,"https://github.com/johnmackintosh/cusumcharter,
https://johnmackintosh.github.io/cusumcharter/",TRUE,https://github.com/johnmackintosh/cusumcharter,2430,17,2022-02-08T21:45:04Z,142.94117647058823
cutpointr,"Estimate cutpoints that optimize a specified metric in binary classification tasks
    and validate performance using bootstrapping. Some methods for more robust cutpoint
    estimation are supported, e.g. a parametric method assuming normal distributions,
    bootstrapped cutpoints, and smoothing of the metric values per cutpoint using
    Generalized Additive Models. Various plotting functions are included. For an overview
    of the package see Thiele and Hirschfeld (2021) <doi:10.18637/jss.v098.i11>.",2022-04-13,Christian Thiele,https://github.com/thie1e/cutpointr,TRUE,https://github.com/thie1e/cutpointr,44135,74,2022-04-13T17:32:19Z,596.418918918919
cvap,Works with the Citizen Voting Age Population special tabulation from the US Census Bureau <https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.html>. Provides tools to download and process raw data. Also provides a downloading interface to processed data. Implements a very basic approach to estimate block level citizen voting age population from block group data.,2022-04-16,Christopher T. Kenny,"https://github.com/christopherkenny/cvap,
https://www.christophertkenny.com/cvap/",TRUE,https://github.com/christopherkenny/cvap,2755,0,2022-04-19T02:34:21Z,NA
cvar,"Compute expected shortfall (ES) and Value at Risk (VaR) from a
    quantile function, distribution function, random number generator or
    probability density function.  ES is also known as Conditional Value at
    Risk (CVaR). Virtually any continuous distribution can be specified.
    The functions are vectorized over the arguments. The computations are
    done directly from the definitions, see e.g. Acerbi and Tasche (2002)
    <doi:10.1111/1468-0300.00091>. Some support for GARCH models is provided,
    as well.",2019-03-15,Georgi N. Boshnakov,https://github.com/GeoBosh/cvar https://geobosh.github.io/cvar/,TRUE,https://github.com/geobosh/cvar,24800,2,2022-03-05T13:18:00Z,12400
cvAUC,"Tools for working with and evaluating cross-validated area under the ROC curve (AUC) estimators.  The primary functions of the package are ci.cvAUC and ci.pooled.cvAUC, which report cross-validated AUC and compute confidence intervals for cross-validated AUC estimates based on influence curves for i.i.d. and pooled repeated measures data, respectively.  One benefit to using influence curve based confidence intervals is that they require much less computation time than bootstrapping methods.  The utility functions, AUC and cvAUC, are simple wrappers for functions from the ROCR package.",2022-01-17,Erin LeDell,https://github.com/ledell/cvAUC,TRUE,https://github.com/ledell/cvauc,98241,22,2022-01-17T23:07:23Z,4465.5
cvCovEst,"An efficient cross-validated approach for covariance matrix
    estimation, particularly useful in high-dimensional settings. This
    method relies upon the theory of loss-based estimator selection to
    identify the optimal estimator of the covariance matrix from among a
    prespecified set of candidates.",2022-05-04,Philippe Boileau,https://github.com/PhilBoileau/cvCovEst,TRUE,https://github.com/philboileau/cvcovest,6601,7,2022-05-03T15:08:33Z,943
cvms,"Cross-validate one or multiple regression and classification models
    and get relevant evaluation metrics in a tidy format. Validate the
    best model on a test set and compare it to a baseline evaluation.
    Alternatively, evaluate predictions from an external model. Currently
    supports regression and classification (binary and multiclass).
    Described in chp. 5 of Jeyaraman, B. P., Olsen, L. R., 
    & Wambugu M. (2019, ISBN: 9781838550134).",2021-11-14,Ludvig Renbo Olsen,https://github.com/ludvigolsen/cvms,TRUE,https://github.com/ludvigolsen/cvms,40410,32,2021-11-14T17:17:27Z,1262.8125
CVrisk,"Calculate various cardiovascular disease risk scores from the
    Framingham Heart Study (FHS), the American College of Cardiology (ACC),
    and the American Heart Association (AHA) as described in D’agostino, et al
    (2008) <doi:10.1161/circulationaha.107.699579>, Goff, et al (2013)
    <doi:10.1161/01.cir.0000437741.48606.98>, and Mclelland, et al (2015)
    <doi:10.1016/j.jacc.2015.08.035>.",2021-12-06,Victor Castro,https://github.com/vcastro/CVrisk,TRUE,https://github.com/vcastro/cvrisk,7558,5,2021-12-06T20:12:27Z,1511.6
CVXR,"An object-oriented modeling language for disciplined
    convex programming (DCP) as described in Fu, Narasimhan, and Boyd
    (2020, <doi:10.18637/jss.v094.i14>). It allows the user to
    formulate convex optimization problems in a natural way following
    mathematical convention and DCP rules. The system analyzes the
    problem, verifies its convexity, converts it into a canonical
    form, and hands it off to an appropriate solver to obtain the
    solution. Interfaces to solvers on CRAN and elsewhere are
    provided, both commercial and open source.",2021-11-10,Anqi Fu,"https://cvxr.rbind.io, https://www.cvxgrp.org/CVXR/",TRUE,https://github.com/cvxgrp/cvxr,105764,168,2021-11-11T19:44:47Z,629.547619047619
cwbtools,"The 'Corpus Workbench' ('CWB', <https://cwb.sourceforge.io/>) offers a classic and mature
 approach for working with large, linguistically and structurally annotated corpora. The 'CWB'
 is memory efficient and its design makes running queries fast (Evert and Hardie 2011,
 <http://www.stefan-evert.de/PUB/EvertHardie2011.pdf>). The 'cwbtools' package offers
 pure R tools to create indexed corpus files as well as high-level wrappers for the original C
 implementation of CWB as exposed by the 'RcppCWB' package
 <https://CRAN.R-project.org/package=RcppCWB>. Additional functionality to add and
 modify annotations of corpora from within R makes working with CWB indexed corpora
 much more flexible and convenient. The 'cwbtools' package in combination with the R packages
 'RcppCWB' (<https://CRAN.R-project.org/package=RcppCWB>) and 'polmineR'
 (<https://CRAN.R-project.org/package=polmineR>) offers a lightweight infrastructure
 to support the combination of quantitative and qualitative approaches for working
 with textual data.",2022-06-02,Andreas Blaette,https://github.com/PolMine/cwbtools,TRUE,https://github.com/polmine/cwbtools,19366,2,2022-05-15T12:25:36Z,9683
cxhull,"Computes the convex hull in arbitrary dimension, based on the
    Qhull library (<http://www.qhull.org>). The package provides a
    complete description of the convex hull: edges, ridges, facets,
    adjacencies. Triangulation is optional.",2022-06-11,C. B. Barber [cph,https://github.com/stla/cxhull,TRUE,https://github.com/stla/cxhull,18207,10,2022-06-11T10:09:53Z,1820.7
cxr,"Recent developments in modern coexistence theory have advanced 
    our understanding on how species are able to persist and co-occur 
    with other species at varying abundances. However, applying this 
    mathematical framework to empirical data is still challenging, 
    precluding a larger adoption of the theoretical tools developed 
    by empiricists. This package provides a complete toolbox for modelling 
    interaction effects between species, and calculate fitness and 
    niche differences. 
    The functions are flexible, may accept covariates, 
    and different fitting algorithms can be used. 
    A full description of the underlying methods is available in 
    García-Callejas, D., Godoy, O., and Bartomeus, I. (2020) <doi:10.1111/2041-210X.13443>.",2021-04-16,David Garcia-Callejas,https://github.com/RadicalCommEcol/cxr,TRUE,https://github.com/radicalcommecol/cxr,4829,7,2022-03-15T15:14:03Z,689.8571428571429
cyclestreets,"An interface to the cycle routing/data services provided by
    'CycleStreets', a not-for-profit social enterprise and advocacy
    organisation.  The application programming interfaces (APIs) provided
    by 'CycleStreets' are documented at
    (<https://www.cyclestreets.net/api/>).  The focus of this package is
    the journey planning API, which aims to emulate the routes taken by a
    knowledgeable cyclist.  An innovative feature of the routing service
    of its provision of fastest, quietest and balanced profiles.  These
    represent routes taken to minimise time, avoid traffic and compromise
    between the two, respectively.",2022-01-04,Robin Lovelace,"https://rpackage.cyclestreets.net/,
https://github.com/cyclestreets/cyclestreets-r",TRUE,https://github.com/cyclestreets/cyclestreets-r,18854,13,2022-07-07T09:32:27Z,1450.3076923076924
Cyclops,"This model fitting tool incorporates cyclic coordinate descent and
    majorization-minimization approaches to fit a variety of regression models
    found in large-scale observational healthcare data.  Implementations focus
    on computational optimization and fine-scale parallelization to yield
    efficient inference in massive datasets.  Please see:
    Suchard, Simpson, Zorych, Ryan and Madigan (2013) <doi:10.1145/2414416.2414791>.",2022-06-30,Marc A. Suchard,https://github.com/ohdsi/cyclops,TRUE,https://github.com/ohdsi/cyclops,32351,31,2022-06-30T23:21:20Z,1043.5806451612902
cyphr,"Encryption wrappers, using low-level support from
    'sodium' and 'openssl'.  'cyphr' tries to smooth over some pain
    points when using encryption within applications and data analysis
    by wrapping around differences in function names and arguments in
    different encryption providing packages.  It also provides
    high-level wrappers for input/output functions for seamlessly
    adding encryption to existing analyses.",2022-06-20,Rich FitzJohn,"https://github.com/ropensci/cyphr,
https://docs.ropensci.org/cyphr/",TRUE,https://github.com/ropensci/cyphr,24460,92,2022-06-20T13:18:15Z,265.8695652173913
cytometree,"Given the hypothesis of a bi-modal distribution of cells for
    each marker, the algorithm constructs a binary tree, the nodes of which are
    subpopulations of cells. At each node, observed cells and markers are modeled
    by both a family of normal distributions and a family of bi-modal normal mixture
    distributions. Splitting is done according to a normalized difference of AIC
    between the two families. Method is detailed in: Commenges, Alkhassim, Gottardo, 
    Hejblum & Thiebaut (2018) <doi: 10.1002/cyto.a.23601>. ",2019-12-04,Chariff Alkhassim,NA,TRUE,https://github.com/sistm/cytometree,16889,5,2022-03-09T12:09:27Z,3377.8
cytominer,"Typical morphological profiling datasets have millions of cells
    and hundreds of features per cell. When working with this data, you must
    clean the data, normalize the features to make them comparable across
    experiments, transform the features, select features based on their
    quality, and aggregate the single-cell data, if needed. 'cytominer' makes
    these steps fast and easy. Methods used in practice in the field are
    discussed in Caicedo (2017) <doi:10.1038/nmeth.4397>. An overview of the
    field is presented in Caicedo (2016) <doi:10.1016/j.copbio.2016.04.003>.",2020-05-09,Shantanu Singh,https://github.com/cytomining/cytominer,TRUE,https://github.com/cytomining/cytominer,11444,37,2021-12-20T20:13:23Z,309.2972972972973
CytOpT,"Supervised learning from a source distribution (with known segmentation into cell sub-populations) 
             to fit a target distribution with unknown segmentation. It relies regularized optimal transport to directly 
             estimate the different cell population proportions from a biological sample characterized with flow cytometry 
             measurements. It is based on the regularized Wasserstein metric to compare cytometry measurements from 
             different samples, thus accounting for possible mis-alignment of a given cell population across sample 
             (due to technical variability from the technology of measurements). Supervised learning technique based 
             on the Wasserstein metric that is used to estimate an optimal re-weighting of class proportions in a 
             mixture model Details are presented in Freulon P, Bigot J and Hejblum BP (2021) <arXiv:2006.09003>.",2022-02-09,Boris Hejblum,"https://sistm.github.io/CytOpT-R/,
https://github.com/sistm/CytOpT-R/",TRUE,https://github.com/sistm/cytopt-r,1583,1,2022-02-15T11:09:23Z,1583
czso,"Get programmatic access to the open data provided by the
    Czech Statistical Office (CZSO, <https://czso.cz>).",2022-03-09,Petr Bouchal,"https://github.com/petrbouchal/czso, https://petrbouchal.xyz/czso/",TRUE,https://github.com/petrbouchal/czso,13692,10,2022-03-17T20:56:23Z,1369.2
d3r,"Provides a suite of functions to help ease the use of 'd3.js' in R.
              These helpers include 'htmltools::htmlDependency' functions, hierarchy
              builders, and conversion tools for 'partykit', 'igraph,' 'table',
              and 'data.frame' R objects into the 'JSON' that 'd3.js' expects.",2021-08-15,Mike Bostock,https://github.com/timelyportfolio/d3r,TRUE,https://github.com/timelyportfolio/d3r,138107,144,2021-08-15T17:31:56Z,959.0763888888889
d4storagehub4R,"Provides an interface to 'D4Science' 'StorageHub' API (<https://dev.d4science.org/>). Allows to get user profile, and perform 
 actions over the 'StorageHub' (workspace) including creation of folders, files management (upload/update/deletion/sharing), and listing of 
 stored resources.",2022-06-29,Emmanuel Blondel,"https://github.com/eblondel/d4storagehub4R,
https://www.d4science.org/, https://dev.d4science.org/",TRUE,https://github.com/eblondel/d4storagehub4r,2409,1,2022-06-29T12:18:33Z,2409
DA,"Discriminant Analysis (DA) for evolutionary inference (Qin, X. et al, 2020, <doi:10.22541/au.159256808.83862168>), especially for population genetic structure and community structure inference. This package incorporates the commonly used linear and non-linear, local and global supervised learning approaches (discriminant analysis), including Linear Discriminant Analysis of Kernel Principal Components (LDAKPC), Local (Fisher) Linear Discriminant Analysis (LFDA), Local (Fisher) Discriminant Analysis of Kernel Principal Components (LFDAKPC) and Kernel Local (Fisher) Discriminant Analysis (KLFDA). These discriminant analyses can be used to do ecological and evolutionary inference, including demography inference, species identification, and population/community structure inference.",2021-07-12,Xinghu Qin,https://xinghuq.github.io/DA/index.html,TRUE,https://github.com/xinghuq/da,4301,1,2021-07-11T04:34:22Z,4301
dabestr,"Data Analysis using Bootstrap-Coupled ESTimation.
    Estimation statistics is a simple framework that avoids the pitfalls of
    significance testing. It uses familiar statistical concepts: means,
    mean differences, and error bars. More importantly, it focuses on the
    effect size of one's experiment/intervention, as opposed to a false
    dichotomy engendered by P values.
    An estimation plot has two key features:
    1. It presents all datapoints as a swarmplot, which orders each point to
    display the underlying distribution.
    2. It presents the effect size as a bootstrap 95% confidence interval on a
    separate but aligned axes.
    Estimation plots are introduced in Ho et al., Nature Methods 2019, 1548-7105.
    <doi:10.1038/s41592-019-0470-3>.
    The free-to-view PDF is located at <https://rdcu.be/bHhJ4>.",2020-07-13,Joses W. Ho,https://github.com/ACCLAB/dabestr,TRUE,https://github.com/acclab/dabestr,29759,192,2021-07-26T11:26:36Z,154.99479166666666
dados,"Este pacote traduz os seguintes 
    conjuntos de dados: 'airlines', 'airports', 'ames_raw', 'AwardsManagers',
    'babynames', 'Batting', 'diamonds', 'faithful', 'fueleconomy',
    'Fielding', 'flights', 'gapminder', 'gss_cat', 'iris', 'Managers',
    'mpg', 'mtcars', 'atmos', 'penguins', 'People, 'Pitching', 'pixarfilms','planes',
    'presidential', 'table1', 'table2', 'table3', 'table4a', 'table4b',
    'table5', 'vehicles', 'weather', 'who'.  English: It provides a
    Portuguese translated version of the datasets listed above.",2022-02-24,Riva Quiroga,https://github.com/cienciadedatos/dados,TRUE,https://github.com/cienciadedatos/dados,1869,34,2022-02-24T20:10:52Z,54.970588235294116
dagitty,"A port of the web-based software 'DAGitty', available at 
    <http://dagitty.net>, for analyzing structural causal models 
    (also known as directed acyclic graphs or DAGs).
    This package computes covariate adjustment sets for estimating causal
    effects, enumerates instrumental variables, derives testable
    implications (d-separation and vanishing tetrads), generates equivalent
    models, and includes a simple facility for data simulation. ",2021-01-21,Johannes Textor,"http://www.dagitty.net, https://github.com/jtextor/dagitty",TRUE,https://github.com/jtextor/dagitty,119530,181,2022-04-06T23:01:43Z,660.3867403314918
daiR,"R interface for the Google Cloud Services 'Document AI API' 
    <https://cloud.google.com/document-ai/> with additional tools for output file 
    parsing and text reconstruction. 'Document AI' is a powerful server-based 
    OCR processor that extracts text and tables from images and pdf files with 
    high accuracy. 'daiR' gives R users programmatic access to this processor and 
    additional tools to handle and visualize the output. See the package website 
    <https://dair.info/> for more information and examples.",2021-06-11,Thomas Hegghammer,"https://github.com/Hegghammer/daiR, https://dair.info",TRUE,https://github.com/hegghammer/dair,5022,29,2022-01-25T09:04:40Z,173.17241379310346
DAISIE,"Simulates and computes the (maximum) likelihood of a dynamical 
    model of island biota assembly through speciation, immigration and
    extinction. See e.g. Valente et al. 2015. Ecology Letters 18: 844-852,
    <DOI:10.1111/ele.12461>.",2022-06-02,Rampal S. Etienne,https://github.com/rsetienne/DAISIE,TRUE,https://github.com/rsetienne/daisie,20667,6,2022-06-08T12:16:06Z,3444.5
DALEX,"Any unverified black box model is the path to failure. Opaqueness leads to distrust. 
  Distrust leads to ignoration. Ignoration leads to rejection. 
  DALEX package xrays any model and helps to explore and explain its behaviour.
  Machine Learning (ML) models are widely used and have various applications in classification 
  or regression. Models created with boosting, bagging, stacking or similar techniques are often
  used due to their high performance. But such black-box models usually lack direct interpretability.
  DALEX package contains various methods that help to understand the link between input variables 
  and model output. Implemented methods help to explore the model on the level of a single instance 
  as well as a level of the whole dataset.
  All model explainers are model agnostic and can be compared across different models.
  DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration.
  Find more details in (Biecek 2018) <arXiv:1806.08915>.",2022-06-15,Przemyslaw Biecek,"https://modeloriented.github.io/DALEX/, https://dalex.drwhy.ai",TRUE,https://github.com/modeloriented/dalex,123759,1070,2022-06-01T09:54:02Z,115.66261682242991
DALEXtra,"Provides wrapper of various machine learning models. 
  In applied machine learning, there 
  is a strong belief that we need to strike a balance 
  between interpretability and accuracy. 
  However, in field of the interpretable machine learning, 
  there are more and more new ideas for explaining black-box models, 
  that are implemented in 'R'. 
  'DALEXtra' creates 'DALEX' Biecek (2018) <arXiv:1806.08915> explainer for many type of models
  including those created using 'python' 'scikit-learn' and 'keras' libraries, and 'java' 'h2o' library. 
  Important part of the package is Champion-Challenger analysis and innovative approach
  to model performance across subsets of test data presented in Funnel Plot. ",2022-06-14,Szymon Maksymiuk,"https://ModelOriented.github.io/DALEXtra/,
https://github.com/ModelOriented/DALEXtra",TRUE,https://github.com/modeloriented/dalextra,27655,53,2022-06-13T17:24:42Z,521.7924528301887
dampack,"A suite of functions for analyzing and visualizing the health economic outputs of mathematical models.
    This package was developed with funding from the National Institutes of Allergy and Infectious Diseases of the 
    National Institutes of Health under award no. R01AI138783. The content of this package is solely the 
    responsibility of the authors and does not necessarily represent the official views of the National Institutes 
    of Health. The theoretical underpinnings of 'dampack''s functionality are detailed in Hunink et al. (2014) 
    <doi:10.1017/CBO9781139506779>.",2021-05-30,Greg Knowlton,https://github.com/DARTH-git/dampack,TRUE,https://github.com/darth-git/dampack,6882,23,2021-07-28T17:16:31Z,299.2173913043478
dams,"The single largest source of dams in the United States is the
    National Inventory of Dams (NID) <http://nid.usace.army.mil> from the US
    Army Corps of Engineers. Entire data from the NID cannot be obtained all at
    once and NID's website limits extraction of more than a couple of thousand
    records at a time. Moreover, selected data from the NID's user interface
    cannot not be saved to a file. In order to make the analysis of this data
    easier, all the data from NID was extracted manually. Subsequently, the raw
    data was checked for potential errors and cleaned. This package provides
    sample cleaned data from the NID and provides functionality to access the
    entire cleaned NID data.",2020-05-20,Joseph Stachelek,https://github.com/jsta/dams,TRUE,https://github.com/jsta/dams,16758,6,2021-11-13T13:27:14Z,2793
dang,A collection of utility functions.,2021-10-29,Dirk Eddelbuettel with contributions by Brodie Gaslam,"https://github.com/eddelbuettel/dang,
https://dirk.eddelbuettel.com/code/dang.html",TRUE,https://github.com/eddelbuettel/dang,15840,7,2022-04-19T14:15:07Z,2262.8571428571427
dashboardthemes,"Allows manual creation of themes and logos to be used in
    applications created using the 'shinydashboard' package. Removes the need to
    change the underlying css code by wrapping it into a set of convenient R
    functions.",2021-08-21,Nik Lilovski,https://github.com/nik01010/dashboardthemes,TRUE,https://github.com/nik01010/dashboardthemes,68112,315,2021-09-26T11:27:55Z,216.22857142857143
dashCoreComponents,"'Dash' ships with supercharged components for interactive user interfaces. A core set of components, written and maintained by the 'Dash' team, is available in the 'dashCoreComponents' package. The source for this package is on GitHub: plotly/dash-core-components.",2020-05-06,Ryan Patrick Kyle,https://github.com/plotly/dash-core-components,TRUE,https://github.com/plotly/dash-core-components,26932,265,2022-03-02T16:51:48Z,101.63018867924528
dashHtmlComponents,"'Dash' is a web application framework that provides pure Python and R abstraction around HTML, CSS, and JavaScript. Instead of writing HTML or using an HTML templating engine, you compose your layout using R functions within the 'dashHtmlComponents' package. The source for this package is on GitHub: plotly/dash-html-components.",2020-05-06,Ryan Patrick Kyle,https://github.com/plotly/dash-html-components,TRUE,https://github.com/plotly/dash-html-components,26760,154,2022-03-02T16:57:05Z,173.76623376623377
dashTable,"An interactive table component designed for editing and exploring large datasets, 'dashDataTable' is rendered with standard, semantic HTML <table/> markup, which makes it accessible, responsive, and easy to style. This component was written from scratch in 'React.js' specifically for the 'dash' community. Its API was designed to be ergonomic and its behaviour is completely customizable through its  properties.",2020-05-14,Ryan Patrick Kyle,https://github.com/plotly/dash-table,TRUE,https://github.com/plotly/dash-table,22521,425,2021-10-05T13:49:21Z,52.99058823529412
data.table,"Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.",2021-09-27,Matt Dowle,"https://r-datatable.com, https://Rdatatable.gitlab.io/data.table,
https://github.com/Rdatatable/data.table",TRUE,https://github.com/rdatatable/data.table,21841910,3054,2022-03-16T16:00:23Z,7151.902423051735
data.validator,"Validate dataset by columns and rows using convenient predicates inspired by 'assertr' package. 
             Generate good looking HTML report or print console output to display in logs of your data processing pipeline.",2022-01-19,Marcin Dubel,NA,TRUE,https://github.com/appsilon/data.validator,6055,74,2022-06-23T10:51:14Z,81.82432432432432
data360r,"Makes it easy to engage with the Application Program Interface (API)
    of the 'TCdata360' and 'Govdata360' platforms at <https://tcdata360.worldbank.org/>
    and <https://govdata360.worldbank.org/>, respectively.
    These application program interfaces provide access to over 5000 trade, competitiveness, and governance
    indicator data, metadata, and related information from sources
    both inside and outside the World Bank Group.
    Package functions include easier download of data sets, metadata, and
    related information, as well as searching based on user-inputted query.",2022-06-10,Ramin Aliyev,https://github.com/mrpsonglao/data360r,TRUE,https://github.com/mrpsonglao/data360r,9611,25,2022-06-10T18:02:26Z,384.44
DatabaseConnector,"An R 'DataBase Interface' ('DBI') compatible interface to various database platforms ('PostgreSQL', 'Oracle', 'Microsoft SQL Server', 
    'Amazon Redshift', 'Microsoft Parallel Database Warehouse', 'IBM Netezza', 'Apache Impala', 'Google BigQuery', 'Spark', and 'SQLite'). Also includes support for
    fetching data as 'Andromeda' objects. Uses 'Java Database Connectivity' ('JDBC') to connect to databases (except SQLite).",2022-06-28,Martijn Schuemie,"https://ohdsi.github.io/DatabaseConnector/,
https://github.com/OHDSI/DatabaseConnector",TRUE,https://github.com/ohdsi/databaseconnector,64200,39,2022-06-28T13:17:56Z,1646.1538461538462
DatabaseConnectorJars,Provides external JAR dependencies for the 'DatabaseConnector' package.,2019-04-07,Martijn Schuemie,https://github.com/OHDSI/DatabaseConnectorJars,TRUE,https://github.com/ohdsi/databaseconnectorjars,26765,0,2022-01-21T09:53:43Z,NA
DatabionicSwarm,"Algorithms implementing populations of agents that interact with one another and sense their environment may exhibit emergent behavior such as self-organization and swarm intelligence. Here, a swarm system called Databionic swarm (DBS) is introduced which was published in Thrun, M.C., Ultsch A.: ""Swarm Intelligence for Self-Organized Clustering"" (2020), Artificial Intelligence, <DOI:10.1016/j.artint.2020.103237>. DBS is able to adapt itself to structures of high-dimensional data such as natural clusters characterized by distance and/or density based structures in the data space. The first module is the parameter-free projection method called Pswarm (Pswarm()), which exploits the concepts of self-organization and emergence, game theory, swarm intelligence and symmetry considerations. The second module is the parameter-free high-dimensional data visualization technique, which generates projected points on the topographic map with hypsometric tints defined by the generalized U-matrix (GeneratePswarmVisualization()). The third module is the clustering method itself with non-critical parameters (DBSclustering()). Clustering can be verified by the visualization and vice versa. The term DBS refers to the method as a whole. It enables even a non-professional in the field of data mining to apply its algorithms for visualization and/or clustering to data sets with completely different structures drawn from diverse research fields. The comparison to common projection methods can be found in the book of Thrun, M.C.: ""Projection Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <DOI:10.1007/978-3-658-20540-9>. A comparison to 26 common clustering algorithms on 15 datasets is presented on the website.",2021-01-12,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/databionicswarm,21683,9,2022-06-17T07:24:24Z,2409.222222222222
datacleanr,"Flexible and efficient cleaning of data with interactivity.
  'datacleanr' facilitates best practices in data analyses and reproducibility with built-in features and by translating interactive/manual operations to code. 
  The package is designed for interoperability, and so seamlessly fits into reproducible analyses pipelines in 'R'.",2021-11-18,Alexander Hurley,https://github.com/the-Hull/datacleanr,TRUE,https://github.com/the-hull/datacleanr,8591,17,2022-06-23T09:23:42Z,505.3529411764706
dataCompareR,"Easy comparison of two tabular data
    objects in R. Specifically designed to show differences between two sets of
    data in a useful way that should make it easier to understand the differences,
    and if necessary, help you work out how to remedy them. Aims
    to offer a more useful output than all.equal() when your two data sets do not
    match, but isn't intended to replace all.equal() as a way to test for equality.",2021-11-23,Sarah Johnston,https://github.com/capitalone/dataCompareR,TRUE,https://github.com/capitalone/datacomparer,32187,66,2022-05-13T12:49:34Z,487.6818181818182
DataEditR,"An interactive editor built on 'rhandsontable' to allow the 
  interactive viewing, entering, filtering and editing of data in R 
  <https://dillonhammill.github.io/DataEditR/>.",2022-03-08,Dillon Hammill,https://github.com/DillonHammill/DataEditR,TRUE,https://github.com/dillonhammill/dataeditr,30919,332,2022-04-28T05:02:23Z,93.12951807228916
DataExplorer,"Automated data exploration process for analytic tasks and predictive modeling, so
    that users could focus on understanding data and extracting insights. The package scans and
    analyzes each variable, and visualizes them with typical graphical techniques. Common
    data processing methods are also available to treat and format data.",2020-12-15,Boxuan Cui,http://boxuancui.github.io/DataExplorer/,TRUE,https://github.com/boxuancui/dataexplorer,388906,434,2021-08-12T01:15:10Z,896.0967741935484
datagovindia,"This wrapper allows the user to communicate with more than
    80,000 API posted on data.gov.in - open data
    platform of the government of India <https:data.gov.in/ogpl_apis>. 
    It also allows the user to search for the API required through the universe
    of the API with a better interface than the one the official website provides.
    Once a user has the ID by using the API discovery functionalities, 
    it allows one to converse with the API using a consistent format across all
    available API.",2021-09-27,Abhishek Arora,https://github.com/econabhishek/datagovindia,TRUE,https://github.com/econabhishek/datagovindia,5812,8,2022-07-08T13:19:34Z,726.5
dataMaid,"Data screening is an important first step of any statistical
    analysis. dataMaid auto generates a customizable data report with a thorough
    summary of the checks and the results that a human can use to identify possible
    errors. It provides an extendable suite of test for common potential
    errors in a dataset. ",2021-10-08,Claus Thorn Ekstrøm,"https://github.com/ekstroem/dataMaid,
https://doi.org/10.18637/jss.v090.i06",TRUE,https://github.com/ekstroem/datamaid,40920,133,2022-01-25T10:21:01Z,307.6691729323308
dataMeta,Designed to create a basic data dictionary and append to the original dataset's attributes list. The package makes use of a tidy dataset and creates a data frame that will serve as a linker that will aid in building the dictionary. The dictionary is then appended to the list of the original dataset's attributes. The user will have the option of entering variable and item descriptions by writing code or use alternate functions that will prompt the user to add these.,2017-08-12,Dania M. Rodriguez,https://github.com/dmrodz/dataMeta,TRUE,https://github.com/dmrodz/datameta,17430,17,2022-04-19T23:27:45Z,1025.2941176470588
datamods,"'Shiny' modules to import data into an application or 'addin'
    from various sources, and to manipulate them after that.",2022-05-06,Victor Perrier,https://github.com/dreamRs/datamods,TRUE,https://github.com/dreamrs/datamods,119573,89,2022-05-06T07:24:15Z,1343.5168539325844
dataonderivatives,"Post Global Financial Crisis derivatives reforms have lifted
    the veil off over-the-counter (OTC) derivative markets. Swap Execution
    Facilities (SEFs) and Swap Data Repositories (SDRs) now publish data
    on swaps that are traded on or reported to those facilities
    (respectively). This package provides you the ability to get this data
    from supported sources.",2022-01-04,Imanuel Costigan,"https://github.com/imanuelcostigan/dataonderivatives,
http://imanuelcostigan.github.io/dataonderivatives/",TRUE,https://github.com/imanuelcostigan/dataonderivatives,16414,33,2022-01-04T01:29:59Z,497.3939393939394
dataone,"Provides read and write access to data and metadata from
    the DataONE network <https://www.dataone.org> of data repositories.  
    Each DataONE repository implements a consistent repository application 
    programming interface. Users call methods in R to access these remote 
    repository functions, such as methods to query the metadata catalog, get 
    access to metadata for particular data packages, and read the data objects 
    from the data repository. Users can also insert and update data objects on 
    repositories that support these methods.",2022-06-10,Matthew B. Jones,https://github.com/DataONEorg/rdataone,TRUE,https://github.com/dataoneorg/rdataone,25292,31,2022-06-09T21:07:26Z,815.8709677419355
datapack,"Provides a flexible container to transport and manipulate complex
    sets of data. These data may consist of multiple data files and associated
    meta data and ancillary files. Individual data objects have associated system
    level meta data, and data files are linked together using the OAI-ORE standard
    resource map which describes the relationships between the files. The OAI-
    ORE standard is described at <https://www.openarchives.org/ore/>. Data packages
    can be serialized and transported as structured files that have been created
    following the BagIt specification. The BagIt specification is described at
    <https://tools.ietf.org/html/draft-kunze-bagit-08>.",2022-06-10,Matthew B. Jones,"https://docs.ropensci.org/datapack/,
https://github.com/ropensci/datapack",TRUE,https://github.com/ropensci/datapack,24292,40,2022-06-09T21:03:40Z,607.3
datapasta,RStudio addins and R functions that make copy-pasting vectors and tables to text painless.,2020-01-17,Miles McBain,https://github.com/milesmcbain/datapasta,TRUE,https://github.com/milesmcbain/datapasta,65763,814,2022-04-29T11:08:00Z,80.78992628992629
dataPreparation,Do most of the painful data preparation for a data science project with a minimum amount of code; Take advantages of 'data.table' efficiency and use some algorithmic trick in order to perform data preparation in a time and RAM efficient way.,2021-12-21,Emmanuel-Lin Toulemonde,NA,TRUE,https://github.com/eltoulemonde/datapreparation,106310,28,2022-02-11T13:44:14Z,3796.785714285714
dataReporter,"Data screening is an important first step of any statistical
    analysis. 'dataReporter' auto generates a customizable data report with a thorough
    summary of the checks and the results that a human can use to identify possible
    errors. It provides an extendable suite of test for common potential
    errors in a dataset. See Petersen AH, Ekstrøm CT (2019). ""dataMaid: Your Assistant for Documenting Supervised Data Quality Screening in R."" _Journal of Statistical Software_, *90*(6), 1-38 <doi:10.18637/jss.v090.i06> for more information.",2021-11-11,Claus Thorn Ekstrøm,https://github.com/ekstroem/dataReporter,TRUE,https://github.com/ekstroem/datareporter,8955,57,2021-10-07T09:15:04Z,157.10526315789474
dataRetrieval,"Collection of functions to help retrieve U.S. Geological Survey
    (USGS) and U.S. Environmental Protection Agency (EPA) water quality and
    hydrology data from web services. USGS web services are discovered from 
    National Water Information System (NWIS) <https://waterservices.usgs.gov/> and <https://waterdata.usgs.gov/nwis>. 
    Both EPA and USGS water quality data are obtained from the Water Quality Portal <https://www.waterqualitydata.us/>.",2022-02-18,Laura DeCicco,https://pubs.usgs.gov/tm/04/a10/,TRUE,https://github.com/usgs-r/dataretrieval,75265,205,2022-07-08T21:24:10Z,367.1463414634146
datasailr,A row by row data processing tool. You can write data processing code in 'DataSailr' script which is specially intended for data manipulation. The package uses 'libsailr' (C/C++ library) for its 'DataSailr' code parsing and its execution.,2021-11-08,Toshihiro Umehara,https://datasailr.io,TRUE,https://github.com/niceume/datasailr,13106,2,2021-08-14T05:37:50Z,6553
datasauRus,"The Datasaurus Dozen is a set of datasets with the same
    summary statistics. They retain the same summary statistics despite
    having radically different distributions.  The datasets represent a
    larger and quirkier object lesson that is typically taught via
    Anscombe's Quartet (available in the 'datasets' package). Anscombe's
    Quartet contains four very different distributions with the same
    summary statistics and as such highlights the value of visualisation
    in understanding data, over and above summary statistics. As well as
    being an engaging variant on the Quartet, the data is generated in a
    novel way. The simulated annealing process used to derive datasets
    from the original Datasaurus is detailed in ""Same Stats, Different
    Graphs: Generating Datasets with Varied Appearance and Identical
    Statistics through Simulated Annealing"" <doi:10.1145/3025453.3025912>.",2022-05-04,Rhian Davies,"https://github.com/jumpingrivers/datasauRus,
https://jumpingrivers.github.io/datasauRus/",TRUE,https://github.com/jumpingrivers/datasaurus,51807,268,2022-02-21T11:55:14Z,193.3097014925373
DataSpaceR,"Provides a convenient API interface to access immunological data
    within 'the CAVD DataSpace'(<https://dataspace.cavd.org>), a data sharing 
    and discovery tool that facilitates exploration of HIV immunological data 
    from pre-clinical and clinical HIV vaccine studies.",2022-06-24,Jason Taylor,"https://docs.ropensci.org/DataSpaceR/,
https://github.com/ropensci/DataSpaceR",TRUE,https://github.com/ropensci/dataspacer,16625,4,2022-06-24T00:46:23Z,4156.25
dataverse,"Provides access to Dataverse APIs <https://dataverse.org/> (versions 4-5),
    enabling data search, retrieval, and deposit. For Dataverse versions <= 3.0,
    use the archived 'dvn' package <https://cran.r-project.org/package=dvn>.",2022-06-11,Shiro Kuriwaki,"https://iqss.github.io/dataverse-client-r/,
https://dataverse.org/,
https://github.com/iqss/dataverse-client-r",TRUE,https://github.com/iqss/dataverse-client-r,28187,51,2022-06-11T15:21:43Z,552.6862745098039
DataVisualizations,"Gives access to data visualisation methods that are relevant from the data scientist's point of view. The flagship idea of 'DataVisualizations' is the mirrored density plot (MD-plot) for either classified or non-classified multivariate data published in Thrun, M.C. et al.: ""Analyzing the Fine Structure of Distributions"" (2020), PLoS ONE, <DOI:10.1371/journal.pone.0238835>. The MD-plot outperforms the box-and-whisker diagram (box plot), violin plot and bean plot and geom_violin plot of ggplot2. Furthermore, a collection of various visualization methods for univariate data is provided. In the case of exploratory data analysis, 'DataVisualizations' makes it possible to inspect the distribution of each feature of a dataset visually through a combination of four methods. One of these methods is the Pareto density estimation (PDE) of the probability density function (pdf). Additionally, visualizations of the distribution of distances using PDE, the scatter-density plot using PDE for two variables as well as the Shepard density plot and the Bland-Altman plot are presented here. Pertaining to classified high-dimensional data, a number of visualizations are described, such as f.ex. the heat map and silhouette plot. A political map of the world or Germany can be visualized with the additional information defined by a classification of countries or regions. By extending the political map further, an uncomplicated function for a Choropleth map can be used which is useful for measurements across a geographic area. For categorical features, the Pie charts, slope charts and fan plots, improved by the ABC analysis, become usable. More detailed explanations are found in the book by Thrun, M.C.: ""Projection-Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <DOI:10.1007/978-3-658-20540-9>.",2022-05-21,Michael Thrun,https://www.deepbionics.org/,TRUE,https://github.com/mthrun/datavisualizations,30865,6,2022-06-05T16:05:35Z,5144.166666666667
datawizard,"A lightweight package to easily manipulate, clean, transform,
    and prepare your data for analysis. It also forms the data wrangling
    backend for the packages in the 'easystats' ecosystem.",2022-05-16,Dominique Makowski (<https://orcid.org/0000-0001-5375-9967>,https://easystats.github.io/datawizard/,TRUE,https://github.com/easystats/datawizard,881743,104,2022-07-09T08:20:43Z,8478.298076923076
datelife,"Methods and workflows to get chronograms (i.e., phylogenetic trees with branch lengths
    proportional to time), using open, peer-reviewed, state-of-the-art scientific data on time of lineage divergence.
    This package constitutes the main underlying code of the DateLife web service
    at <www.datelife.org>. To obtain a single summary chronogram from a group of
    relevant chronograms, we implement the Super Distance Matrix (SDM) method
    described in Criscuolo et al. (2006) <doi:10.1080/10635150600969872>.
    To find the grove of chronograms with a sufficiently overlapping set of taxa
    for summarizing, we implement theorem 1.1. from Ané et al. (2009)
    <doi:10.1007/s00026-009-0017-x>.
    A given phylogenetic tree can be dated using time of lineage divergence data
    as secondary calibrations (with caution, see Schenk (2016) <doi:10.1371/journal.pone.0148228>).
    To obtain and apply secondary calibrations, the package implements the congruification method described
    in Eastman et al. (2013) <doi:10.1111/2041-210X.12051>. Tree dating can be performed with different methods
    including BLADJ (Webb et al. (2008) <doi:10.1093/bioinformatics/btn358>), PATHd8
    (Britton et al. (2007) <doi:10.1080/10635150701613783>), mrBayes (Huelsenbeck
    and Ronquist (2001) <doi:10.1093/bioinformatics/17.8.754>), and treePL (Smith
    and O'Meara (2012) <doi:10.1093/bioinformatics/bts492>).",2022-06-21,Luna L. Sanchez Reyes,"https://github.com/phylotastic/datelife,
http://phylotastic.org/datelife/",TRUE,https://github.com/phylotastic/datelife,1505,9,2022-06-20T23:15:14Z,167.22222222222223
daterangepicker,"A Shiny Input for date-ranges, which pops up two calendars for selecting dates, times, or predefined ranges like ""Last 30 Days"". It wraps the JavaScript library 'daterangepicker' which is available at <https://www.daterangepicker.com>.",2020-03-20,Sebastian Gatscha,"https://github.com/trafficonese/daterangepicker/,
https://www.daterangepicker.com",TRUE,https://github.com/trafficonese/daterangepicker,20539,12,2022-03-31T16:57:56Z,1711.5833333333333
datetimeutils,"Utilities for handling dates and times, such
   as selecting particular days of the week or month,
   formatting timestamps as required by RSS feeds, or
   converting timestamp representations of other software
   (such as 'MATLAB' and 'Excel') to R. The package is
   lightweight (no dependencies, pure R implementations) and
   relies only on R's standard classes to represent dates
   and times ('Date' and 'POSIXt'); it aims to provide
   efficient implementations, through vectorisation and the
   use of R's native numeric representations of timestamps
   where possible.",2021-04-01,Enrico Schumann,"http://enricoschumann.net/R/packages/datetimeutils/,
https://github.com/enricoschumann/datetimeutils",TRUE,https://github.com/enricoschumann/datetimeutils,29921,5,2022-07-01T13:21:59Z,5984.2
dateutils,"Utilities for mixed frequency data. In particular, use to aggregate and normalize tabular mixed frequency data, index dates to end of period, and seasonally adjust tabular data.",2021-11-10,Seth Leonard,https://github.com/macroeconomicdata/dateutils,TRUE,https://github.com/macroeconomicdata/dateutils,2025,2,2021-12-07T20:10:14Z,1012.5
datos,"Provee una versión traducida de los siguientes
    conjuntos de datos: 'airlines', 'airports', 'AwardsManagers',
    'babynames', 'Batting', 'diamonds', 'faithful', 'fueleconomy',
    'Fielding', 'flights', 'gapminder', 'gss_cat', 'iris', 'Managers',
    'mpg', 'mtcars', 'atmos', 'palmerpenguins', 'People, 'Pitching', 'planes',
    'presidential', 'table1', 'table2', 'table3', 'table4a', 'table4b',
    'table5', 'vehicles', 'weather', 'who'.  English: It provides a
    Spanish translated version of the datasets listed above.",2022-02-20,Riva Quiroga,https://github.com/cienciadedatos/datos,TRUE,https://github.com/cienciadedatos/datos,41303,34,2022-02-19T23:39:55Z,1214.7941176470588
daymetr,"Programmatic interface to the 'Daymet' web services
    (<http://daymet.ornl.gov>). Allows for easy downloads of
    'Daymet' climate data directly to your R workspace or your computer.
    Routines for both single pixel data downloads and
    gridded (netCDF) data are provided.",2021-12-20,Koen Hufkens,https://github.com/bluegreen-labs/daymetr,TRUE,https://github.com/bluegreen-labs/daymetr,21605,21,2021-12-20T08:09:42Z,1028.8095238095239
dbarts,"Fits Bayesian additive regression trees (BART; Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>) while allowing the updating of predictors or response so that BART can be incorporated as a conditional model in a Gibbs/Metropolis-Hastings sampler. Also serves as a drop-in replacement for package 'BayesTree'.",2022-03-29,Vincent Dorie,https://github.com/vdorie/dbarts,TRUE,https://github.com/vdorie/dbarts,62271,41,2022-06-07T21:49:44Z,1518.8048780487804
dbflobr,"Reads and writes files to SQLite databases
    <https://www.sqlite.org/index.html> as flobs (a flob is a blob that
    preserves the file extension).",2021-10-30,Sebastian Dalgarno,https://github.com/poissonconsulting/dbflobr,TRUE,https://github.com/poissonconsulting/dbflobr,15213,5,2021-11-10T01:42:43Z,3042.6
dbhydroR,"Client for programmatic access to the South Florida Water
  Management District's 'DBHYDRO' database at 
  <https://www.sfwmd.gov/science-data/dbhydro>, with functions
  for accessing hydrologic and water quality data. ",2021-02-21,Joseph Stachelek,"https://github.com/ropensci/dbhydroR,
https://docs.ropensci.org/dbhydroR/",TRUE,https://github.com/ropensci/dbhydror,11097,11,2021-08-04T14:33:45Z,1008.8181818181819
DBI,"A database interface definition for communication between R
    and relational database management systems.  All classes in this
    package are virtual and need to be extended by the various R/DBMS
    implementations.",2022-06-18,Kirill Müller,"https://dbi.r-dbi.org, https://github.com/r-dbi/DBI",TRUE,https://github.com/r-dbi/dbi,12718831,247,2022-06-18T10:32:55Z,51493.24291497975
DBItest,"A helper that tests DBI back ends for conformity
    to the interface.",2021-12-17,Kirill Müller,"https://dbitest.r-dbi.org, https://github.com/r-dbi/DBItest",TRUE,https://github.com/r-dbi/dbitest,254156,19,2022-06-19T02:56:22Z,13376.631578947368
dbmss,"Simple computation of spatial statistic functions of distance to characterize the spatial structures of mapped objects, following Marcon, Traissac, Puech, and Lang (2015) <doi:10.18637/jss.v067.c03>.
  Includes classical functions (Ripley's K and others) and more recent ones used by spatial economists (Duranton and Overman's Kd, Marcon and Puech's M). 
  Relies on 'spatstat' for some core calculation.",2022-07-10,Eric Marcon,https://github.com/EricMarcon/dbmss,TRUE,https://github.com/ericmarcon/dbmss,29449,5,2022-07-10T12:47:32Z,5889.8
dbnR,"Learning and inference over dynamic Bayesian networks of arbitrary 
    Markovian order. Extends some of the functionality offered by the 'bnlearn' 
    package to learn the networks from data and perform exact inference. 
    It offers three structure learning algorithms for dynamic Bayesian networks:
    Trabelsi G. (2013) <doi:10.1007/978-3-642-41398-8_34>, Santos F.P. and Maciel C.D. (2014)
    <doi:10.1109/BRC.2014.6880957>, Quesada D., Bielza C. and Larrañaga P. (2021)
    <doi:10.1007/978-3-030-86271-8_14>. It also offers the possibility to perform 
    forecasts of arbitrary length. A tool for visualizing the structure of the 
    net is also provided via the 'visNetwork' package.",2022-03-14,David Quesada,https://github.com/dkesada/dbnR,TRUE,https://github.com/dkesada/dbnr,13851,18,2022-03-14T09:22:00Z,769.5
dbplyr,"A 'dplyr' back end for databases that allows you to work with
    remote database tables as if they are in-memory data frames.  Basic
    features works with any database that has a 'DBI' back end; more
    advanced features require 'SQL' translation to be provided by the
    package author.",2022-06-27,Hadley Wickham,"https://dbplyr.tidyverse.org/, https://github.com/tidyverse/dbplyr",TRUE,https://github.com/tidyverse/dbplyr,13662065,367,2022-06-27T16:45:35Z,37226.33514986376
dbscan,"A fast reimplementation of several density-based algorithms of
    the DBSCAN family. Includes the clustering algorithms DBSCAN (density-based 
    spatial clustering of applications with noise) and HDBSCAN (hierarchical 
    DBSCAN), the ordering algorithm OPTICS (ordering points to identify the 
    clustering structure), shared nearest neighbor clustering, and the outlier 
    detection algorithms LOF (local outlier factor) and GLOSH (global-local 
    outlier score from hierarchies). The implementations use the kd-tree data 
    structure (from library ANN) for faster k-nearest neighbor search. An R 
    interface to fast kNN and fixed-radius NN search is also provided. 
    Hahsler, Piekenbrock and Doran (2019) <doi:10.18637/jss.v091.i01>.",2022-01-15,Michael Hahsler,https://github.com/mhahsler/dbscan,TRUE,https://github.com/mhahsler/dbscan,1722518,195,2022-06-27T00:32:38Z,8833.42564102564
dbx,"Provides select, insert, update, upsert, and delete database operations. Supports 'PostgreSQL', 'MySQL', 'SQLite', and more, and plays nicely with the 'DBI' package.",2021-01-17,Andrew Kane,https://github.com/ankane/dbx,TRUE,https://github.com/ankane/dbx,26819,168,2022-03-23T23:31:25Z,159.63690476190476
dccpp,"Fast computation of the distance covariance 'dcov' and distance correlation 'dcor'.  The computation cost is only O(n log(n)) for the distance correlation (see Chaudhuri, Hu (2019) <arXiv:1810.11332> <doi:10.1016/j.csda.2019.01.016>). The functions are written entirely in C++ to speed up the computation.",2022-03-02,Jonathan Berrisch,"https://dccpp.berrisch.biz/, https://github.com/BerriJ/dccpp",TRUE,https://github.com/berrij/dccpp,1150,3,2022-03-02T09:07:05Z,383.3333333333333
dccvalidator,"Performs checks for common metadata quality issues. Used by the
    data coordinating centers for the 'AMP-AD' consortium
    (<https://adknowledgeportal.synapse.org>), 'PsychENCODE' consortium
    (<http://www.psychencode.org>), and others to validate metadata prior to
    data releases.",2020-06-19,Nicole Kauer,"https://sage-bionetworks.github.io/dccvalidator,
https://github.com/Sage-Bionetworks/dccvalidator",TRUE,https://github.com/sage-bionetworks/dccvalidator,13851,9,2022-05-05T20:59:53Z,1539
DCEM,"Implements the Improved Expectation Maximisation EM* and the traditional EM algorithm for clustering 
    big data (gaussian mixture models for both multivariate and univariate datasets). This version 
    implements the faster alternative-EM* that expedites convergence via structure based data segregation. 
    The implementation supports both random and K-means++ based initialization. Reference: Parichit Sharma, 
    Hasan Kurban, Mehmet Dalkilic (2022) <doi:10.1016/j.softx.2021.100944>. Hasan Kurban, 
    Mark Jenne, Mehmet Dalkilic (2016) <doi:10.1007/s41060-017-0062-1>.",2022-01-16,Sharma Parichit,https://github.com/parichit/DCEM,TRUE,https://github.com/parichit/dcem,17026,3,2022-01-15T22:54:22Z,5675.333333333333
DCLEAR,R codes for distance based cell lineage reconstruction. Our methods won both sub-challenges 2 and 3 of the Allen Institute Cell Lineage Reconstruction DREAM Challenge in 2020. The challenge paper is Gong et al. (2021) <doi:10.1016/j.cels.2021.05.008>.,2021-09-03,Il-Youp Kwak,https://github.com/ikwak2/DCLEAR,TRUE,https://github.com/ikwak2/dclear,4547,3,2021-11-23T00:29:14Z,1515.6666666666667
dcmodify,"Data cleaning scripts typically contain a lot of 'if this change that'
    type of statements. Such statements are typically condensed expert knowledge.
    With this package, such 'data modifying rules' are taken out of the code and
    become in stead parameters to the work flow. This allows one to maintain, document,
    and reason about data modification rules as separate entities.",2021-09-24,Mark van der Loo,https://github.com/data-cleaning/dcmodify,TRUE,https://github.com/data-cleaning/dcmodify,17804,8,2021-09-24T09:29:45Z,2225.5
dcmodifydb,"Apply modification rules from R package 'dcmodify' to the database, 
  prescribing and documenting deterministic data cleaning steps on records in a database.
  The rules are translated into SQL statements using R package 'dbplyr'.",2022-06-17,Edwin de Jonge,https://github.com/data-cleaning/dcmodifydb,TRUE,https://github.com/data-cleaning/dcmodifydb,3299,3,2022-06-17T14:29:49Z,1099.6666666666667
dcurves,"Diagnostic and prognostic models are typically evaluated with
    measures of accuracy that do not address clinical consequences.
    Decision-analytic techniques allow assessment of clinical outcomes,
    but often require collection of additional information may be
    cumbersome to apply to models that yield a continuous result. Decision
    curve analysis is a method for evaluating and comparing prediction
    models that incorporates clinical consequences, requires only the data
    set on which the models are tested, and can be applied to models that
    have either continuous or dichotomous results. See the following references 
    for details on the methods: Vickers (2006) <doi:10.1177/0272989X06295361>,
    Vickers (2008) <doi:10.1186/1472-6947-8-53>, 
    and Pfeiffer (2020) <doi:10.1002/bimj.201800240>.",2022-05-25,Daniel D. Sjoberg,"https://github.com/ddsjoberg/dcurves,
https://www.danieldsjoberg.com/dcurves/",TRUE,https://github.com/ddsjoberg/dcurves,7546,19,2022-06-28T01:48:20Z,397.1578947368421
DDIwR,"Useful functions for various DDI (Data Documentation Initiative) related inputs and outputs.
    Converts data files to and from SPSS, Stata, SAS, R and Excel, including user declared missing values.",2022-06-21,Adrian Dusa,https://github.com/dusadrian/DDIwR,TRUE,https://github.com/dusadrian/ddiwr,21705,11,2022-07-06T10:01:07Z,1973.1818181818182
DDPNA,"Functions designed to connect disease-related differential proteins and 
  co-expression network. It provides the basic statics analysis included t test, ANOVA analysis. 
  The network construction is not offered by the package, you can used 'WGCNA' package which you 
  can learn in Peter et al. (2008) <doi:10.1186/1471-2105-9-559>. It also provides module analysis 
  included PCA analysis, two enrichment analysis, Planner maximally filtered graph extraction and 
  hub analysis.",2022-05-17,Kefu Liu,https://github.com/liukf10/DDPNA,TRUE,https://github.com/liukf10/ddpna,14315,2,2021-09-25T00:58:46Z,7157.5
DEBBI,"Bayesian inference algorithms based on the population-based ""differential evolution"" (DE) algorithm. Users can obtain posterior mode (MAP) estimates via DEMAP, posterior samples via DEMCMC, and variational approximations via DEVI. ",2022-05-17,Brendan Matthew Galdo,https://github.com/bmgaldo/DEBBI,TRUE,https://github.com/bmgaldo/debbi,396,0,2022-05-12T21:55:39Z,NA
deBInfer,"A Bayesian framework for parameter inference in differential equations.
    This approach offers a rigorous methodology for parameter inference as well as
    modeling the link between unobservable model states and parameters, and
    observable quantities. Provides templates for the DE model, the
    observation model and data likelihood, and the model parameters and their prior
    distributions. A Markov chain Monte Carlo (MCMC) procedure processes these inputs
    to estimate the posterior distributions of the parameters and any derived
    quantities, including the model trajectories. Further functionality is provided
    to facilitate MCMC diagnostics and the visualisation of the posterior distributions
    of model parameters and trajectories.",2022-04-21,Philipp H Boersch-Supan,https://github.com/pboesu/debinfer,TRUE,https://github.com/pboesu/debinfer,17435,12,2022-04-21T10:06:16Z,1452.9166666666667
DeCAFS,"Detect abrupt changes in time series with local fluctuations as a random walk process and autocorrelated noise as an AR(1) process. See Romano, G., Rigaill, G., Runge, V., Fearnhead, P. (2021) <doi:10.1080/01621459.2021.1909598>.",2022-01-05,Gaetano Romano,NA,TRUE,https://github.com/gtromano/decafs,9747,0,2022-01-05T10:37:02Z,NA
deckgl,"Makes 'deck.gl' <https://deck.gl/>, a WebGL-powered open-source JavaScript framework
  for visual exploratory data analysis of large datasets, available within R via the 'htmlwidgets' package.
  Furthermore, it supports basemaps from 'mapbox' <https://www.mapbox.com/> via
  'mapbox-gl-js' <https://github.com/mapbox/mapbox-gl-js>.",2020-05-06,Stefan Kuethe,"https://github.com/crazycapivara/deckgl/,
https://crazycapivara.github.io/deckgl/",TRUE,https://github.com/crazycapivara/deckgl,14503,72,2022-07-09T10:12:04Z,201.43055555555554
declared,"A set of functions to declare labels and missing values, coupled
    with associated functions to create (weighted) tables of frequencies and
    various other summary measures. 
    Some of the base functions have been rewritten to make use of the specific 
    information about the missing values, most importantly to distinguish
    between empty and declared missing values.
    Many functions have a similar functionality with the corresponding ones from
    packages ""haven"" and ""labelled"". The aim is to ensure as much compatibility
    as possible with these packages, while offering an alternative in the
    objects of class ""declared"".",2022-06-20,Adrian Dusa,https://github.com/dusadrian/declared,TRUE,https://github.com/dusadrian/declared,7740,1,2022-07-03T22:55:20Z,7740
DeclareDesign,"Researchers can characterize and learn about the properties of
    research designs before implementation using `DeclareDesign`. Ex ante
    declaration and diagnosis of designs can help researchers clarify the 
    strengths and limitations of their designs and to improve their 
    properties, and can help readers evaluate a research strategy prior
    to implementation and without access to results. It can also make it
    easier for designs to be shared, replicated, and critiqued.",2022-06-20,Graeme Blair,"https://declaredesign.org/r/declaredesign/,
https://github.com/DeclareDesign/DeclareDesign",TRUE,https://github.com/declaredesign/declaredesign,26684,90,2022-06-28T19:48:47Z,296.4888888888889
decompr,"Three global value chain (GVC) decompositions are implemented. 
    The Leontief decomposition derives the value added origin of exports by 
    country and industry as in Hummels, Ishii and Yi (2001). The Koopman, 
    Wang and Wei (2014) decomposition splits country-level exports into 9 
    value added components, and the Wang, Wei and Zhu (2013) decomposition 
    splits bilateral exports into 16 value added components. Various GVC 
    indicators based on these decompositions are computed in the 
    complimentary 'gvc' package. 
    --- References: ---
    Hummels, D., Ishii, J., & Yi, K. M. (2001). The nature and growth of 
       vertical specialization in world trade. Journal of international 
       Economics, 54(1), 75-96.
    Koopman, R., Wang, Z., & Wei, S. J. (2014). Tracing value-added and double 
       counting in gross exports. American Economic Review, 104(2), 459-94.
    Wang, Z., Wei, S. J., & Zhu, K. (2013). Quantifying international production 
       sharing at the bilateral and sector levels (No. w19677). 
       National Bureau of Economic Research.",2022-06-19,Bastiaan Quast,"https://qua.st/decompr/, https://github.com/bquast/decompr",TRUE,https://github.com/bquast/decompr,26770,12,2022-06-19T09:26:48Z,2230.8333333333335
decor,"Retrieves code comment decorations for C++
    languages of the form '\\ [[xyz]]', which are used for automated
    wrapping of C++ functions.",2021-11-30,Romain François,https://github.com/r-lib/decor,TRUE,https://github.com/r-lib/decor,191581,2,2021-11-30T14:25:52Z,95790.5
dedupewider,"Duplicated data can exist in different rows and columns and user may need to
    treat observations (rows) connected by duplicated data as one observation,
    e.g. companies can belong to one family (and thus: be one company) by sharing
    some telephone numbers. This package allows to find connected rows
    based on data on chosen columns and collapse it into one row.",2021-10-28,Grzegorz Smoliński,https://github.com/gsmolinski/dedupewider,TRUE,https://github.com/gsmolinski/dedupewider,4305,3,2021-10-28T11:16:08Z,1435
deepdep,"Provides tools for exploration of R package dependencies. 
    The main deepdep() function allows to acquire deep dependencies of any package and plot them in an elegant way.
    It also adds some popularity measures for the packages e.g. in the form of download count through the 'cranlogs' package. 
    Uses the CRAN metadata database <http://crandb.r-pkg.org> and Bioconductor metadata <http://bioconductor.org>.
    Other data acquire functions are: get_dependencies(), get_downloads() and get_description(). 
    The deepdep_shiny() function runs shiny application that helps to produce a nice 'deepdep' plot. ",2021-12-20,Dominik Rafacz,"https://dominikrafacz.github.io/deepdep/,
https://github.com/DominikRafacz/deepdep",TRUE,https://github.com/dominikrafacz/deepdep,15818,61,2022-05-11T14:03:50Z,259.3114754098361
deepredeff,"A tool that contains trained deep learning models
    for predicting effector proteins. 'deepredeff' has been trained to
    identify effector proteins using a set of known experimentally
    validated effectors from either bacteria, fungi, or oomycetes.
    Documentation is available via several vignettes, and the paper by
    Kristianingsih and MacLean (2020) <doi:10.1101/2020.07.08.193250>.",2021-07-16,Ruth Kristianingsih,https://github.com/ruthkr/deepredeff/,TRUE,https://github.com/ruthkr/deepredeff,7973,2,2021-07-16T09:09:49Z,3986.5
deeptime,"Extends the functionality of other plotting packages like
    'ggplot2' and 'lattice' to help facilitate the plotting of data over long time
    intervals, including, but not limited to, geological, evolutionary, and ecological
    data. The primary goal of 'deeptime' is to enable users to add highly customizable
    timescales to their visualizations. Other functions are also included to assist
    with other areas of deep time visualization.",2022-05-18,William Gearty,https://github.com/willgearty/deeptime,TRUE,https://github.com/willgearty/deeptime,5001,49,2022-07-05T15:29:21Z,102.06122448979592
deformula,"Numerical quadrature of functions of one variable over a finite
  or infinite interval with double exponential formulas.",2022-05-30,Hiroyuki Okamura,https://github.com/okamumu/deformula/,TRUE,https://github.com/okamumu/deformula,18824,0,2022-05-31T03:27:01Z,NA
Delaporte,"Provides probability mass, distribution, quantile, random-variate
    generation, and method-of-moments parameter-estimation functions for the
    Delaporte distribution with parameterization based on Vose (2008)
    <isbn:9780470512845>. The Delaporte is a discrete probability distribution
    which can be considered the convolution of a negative binomial distribution
    with a Poisson distribution. Alternatively, it can be considered a counting
    distribution with both Poisson and negative binomial components. It has been
    studied in actuarial science as a frequency distribution which has more
    variability than the Poisson, but less than the negative binomial.",2022-01-20,Avraham Adler,https://github.com/aadler/Delaporte,TRUE,https://github.com/aadler/delaporte,30819,2,2022-04-26T01:22:20Z,15409.5
delaunay,"Construction and visualization of 2d Delaunay triangulations,
    possibly constrained, 2.5d (i.e. elevated) Delaunay triangulations,
    and 3d Delaunay triangulations.",2022-07-06,Stéphane Laurent,https://github.com/stla/delaunay,TRUE,https://github.com/stla/delaunay,17,4,2022-07-06T11:48:08Z,4.25
delayed,"Mechanisms to parallelize dependent tasks in a manner that
    optimizes the compute resources available. It provides access to ""delayed""
    computations, which may be parallelized using futures. It is, to an extent,
    a facsimile of the 'Dask' library (<https://dask.org/>), for the 'Python'
    language.",2020-02-28,Jeremy Coyle,https://tlverse.org/delayed,TRUE,https://github.com/tlverse/delayed,16348,14,2021-08-29T16:44:59Z,1167.7142857142858
deltaccd,"Infer progression of circadian rhythms in transcriptome data in
  which samples are not labeled with time of day and coverage of the circadian
  cycle may be incomplete. See Shilts et al. (2018) <doi:10.7717/peerj.4327>.",2022-02-11,Jake Hughey,"https://deltaccd.hugheylab.org,
https://github.com/hugheylab/deltaccd",TRUE,https://github.com/hugheylab/deltaccd,1246,0,2022-05-18T16:36:44Z,NA
demography,"Functions for demographic analysis including lifetable
        calculations; Lee-Carter modelling; functional data analysis of
        mortality rates, fertility rates, net migration numbers; and
        stochastic population forecasting.",2019-04-22,Rob J Hyndman with contributions from Heather Booth,https://github.com/robjhyndman/demography,TRUE,https://github.com/robjhyndman/demography,58117,49,2022-06-17T01:29:31Z,1186.061224489796
dendextend,"Offers a set of functions for extending
    'dendrogram' objects in R, letting you visualize and compare trees of
    'hierarchical clusterings'. You can (1) Adjust a tree's graphical parameters
    - the color, size, type, etc of its branches, nodes and labels. (2)
    Visually and statistically compare different 'dendrograms' to one another.",2022-07-04,Tal Galili,"http://talgalili.github.io/dendextend/,
https://github.com/talgalili/dendextend/,
https://cran.r-project.org/package=dendextend,
https://www.r-statistics.com/tag/dendextend/,
https://academic.oup.com/bioinformatics/article/31/22/3718/240978/dendextend-an-R-package-for-visualizing-adjusting",TRUE,https://github.com/talgalili/dendextend,2956442,136,2022-07-04T04:25:20Z,21738.54411764706
dendroTools,"Provides novel dendroclimatological methods, primarily used by the
    Tree-ring research community. There are four core functions. The first one is 
    daily_response(), which finds the optimal sequence of days that are related 
    to one or more tree-ring proxy records. Similar function is daily_response_seascorr(), 
    which implements partial correlations in the analysis of daily response functions.
    For the enthusiast of monthly data, there is monthly_response() function.
    The last core function is compare_methods(), which effectively compares several 
    linear and nonlinear regression algorithms on the task of climate reconstruction.   ",2022-05-04,Jernej Jevsenak,https://github.com/jernejjevsenak/dendroTools,TRUE,https://github.com/jernejjevsenak/dendrotools,24459,3,2022-06-04T08:55:49Z,8153
densitr,"Provides various tools for analysing density profiles
    obtained by resistance drilling. It can load individual or
    multiple files and trim the starting and ending part of each
    density profile. Tools are also provided to trim profiles
    manually, to remove the trend from measurements using several
    methods, to plot the profiles and to detect tree rings
    automatically. Written with a focus on forestry use of resistance
    drilling in standing trees.",2022-03-22,Luka Krajnc,https://github.com/krajnc/densitr,TRUE,https://github.com/krajnc/densitr,9685,2,2022-03-22T09:51:25Z,4842.5
densityClust,"An improved implementation (based on k-nearest neighbors) of the 
    density peak clustering algorithm, originally described by Alex Rodriguez 
    and Alessandro Laio (Science, 2014 vol. 344) <DOI: 10.1126/science.1242072>. 
    It can handle large datasets (> 100, 000 samples) very efficiently. It was 
    initially implemented by Thomas Lin Pedersen, with inputs from Sean Hughes 
    and later improved by Xiaojie Qiu to handle large datasets with kNNs.",2022-03-06,Thomas Lin Pedersen,https://github.com/thomasp85/densityClust,TRUE,https://github.com/thomasp85/densityclust,80342,132,2022-02-21T10:06:27Z,608.6515151515151
DepCens,"Dependent censoring regression models for survival multivariate data. These models are based on extensions of the frailty models, capable to accommodating the dependence between failure and censoring times, with Weibull and piecewise exponential marginal distributions. Theoretical details regarding the models implemented in the package can be found in Schneider et al. (2019) <doi:10.1002/bimj.201800391>.",2022-05-19,Silvana Schneider,https://github.com/GabrielGrandemagne/DepCens,TRUE,https://github.com/gabrielgrandemagne/depcens,365,0,2022-07-01T18:47:25Z,NA
DepthProc,"Data depth concept offers a variety of powerful and user friendly
    tools for robust exploration and inference for multivariate data. The offered
    techniques may be successfully used in cases of lack of our knowledge on
    parametric models generating data due to their nature. The
    package consist of among others implementations of several data depth techniques
    involving multivariate quantile-quantile plots, multivariate scatter estimators,
    multivariate Wilcoxon tests and robust regressions.",2022-02-03,Zygmunt Zawadzki,"https://www.depthproc.zstat.pl/,
https://github.com/zzawadz/DepthProc",TRUE,https://github.com/zzawadz/depthproc,24812,6,2022-02-03T19:52:08Z,4135.333333333333
dequer,"Queues, stacks, and 'deques' are list-like, abstract data types. 
    These are meant to be very cheap to ""grow"", or insert new objects into.
    A typical use case involves storing data in a list in a streaming fashion,
    when you do not necessarily know how may elements need to be stored.
    Unlike R's lists, the new data structures provided here are not
    necessarily stored contiguously, making insertions and deletions at the
    front/end of the structure much faster.  The underlying implementation
    is new and uses a head/tail doubly linked list; thus, we do not rely on R's
    environments or hashing.  To avoid unnecessary data copying, most operations
    on these data structures are performed via side-effects.",2022-03-13,Drew Schmidt,https://github.com/wrathematics/dequer,TRUE,https://github.com/wrathematics/dequer,23034,28,2022-03-13T23:06:48Z,822.6428571428571
Deriv,"R-based solution for symbolic differentiation. It admits
    user-defined function as well as function substitution
    in arguments of functions to be differentiated. Some symbolic
    simplification is part of the work.",2021-02-24,Serguei Sokol,NA,TRUE,https://github.com/sgsokol/deriv,944410,27,2021-12-15T13:45:22Z,34978.148148148146
DescriptiveStats.OBeu,"Estimate and return the needed parameters for visualizations designed for 'OpenBudgets.eu' <http://openbudgets.eu/> datasets. Calculate descriptive statistical measures in budget data of municipalities across Europe, according to the 'OpenBudgets.eu' data model. There are functions for measuring central tendency and dispersion of amount variables along with their distributions and correlations and the frequencies of categorical variables for a given dataset. Also, can be used generally to other datasets, to extract visualization parameters, convert them to 'JSON' format and use them as input in a different graphical interface. ",2020-05-04,Kleanthis Koupidis,https://github.com/okgreece/DescriptiveStats.OBeu,TRUE,https://github.com/okgreece/descriptivestats.obeu,18025,1,2021-09-02T12:08:35Z,18025
DescrTab2,"Provides functions to create descriptive statistics tables for continuous and categorical variables.
    By default, summary statistics such as mean, standard deviation, quantiles, minimum and maximum for continuous
    variables and relative and absolute frequencies for categorical variables are calculated. 'DescrTab2' features a sophisticated algorithm to
    choose appropriate test statistics for your data and provides p-values. On top of this, confidence intervals for group
    differences of appropriated summary measures are automatically produces for two-group comparison.
    Tables generated by 'DescrTab2' can be integrated in a variety of document formats, including .html, .tex and .docx documents.
    'DescrTab2' also allows printing tables to console and saving table objects for later use.",2022-01-20,Jan Meis,https://imbi-heidelberg.github.io/DescrTab2/,TRUE,https://github.com/imbi-heidelberg/descrtab2,6848,6,2022-05-24T12:56:45Z,1141.3333333333333
desctable,"Easily create descriptive and comparative tables.
    It makes use and integrates directly with the tidyverse family of packages, and pipes.
    Tables are produced as (nested) dataframes for easy manipulation.",2022-03-24,Maxime Wack,https://desctable.github.io,TRUE,https://github.com/desctable/desctable,21363,49,2022-03-24T16:36:09Z,435.9795918367347
DescTools,"A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.",2022-05-09,Andri Signorell,"https://andrisignorell.github.io/DescTools/,
https://github.com/AndriSignorell/DescTools/",TRUE,https://github.com/andrisignorell/desctools,1666301,43,2022-06-02T19:08:24Z,38751.186046511626
DescToolsAddIns,"'RStudio' as of recently offers the option to define addins and assign shortcuts to them. This package contains addins for a few most frequently used functions in a data scientist's (at least mine) daily work (like str(), example(), plot(), head(), view(), Desc()). Most of these functions will use the current selection in the editor window and send the specific command to the console while instantly executing it. Assigning shortcuts to these addins will save you quite a few keystrokes.",2022-05-09,Andri Signorell,https://github.com/AndriSignorell/DescToolsAddIns/,TRUE,https://github.com/andrisignorell/desctoolsaddins,31615,1,2022-05-10T05:53:50Z,31615
designer,"A 'shiny' application that enables the user to create a prototype UI, 
    being able to drag and drop UI components before being able to save or download the equivalent R code.",2022-05-17,Ashley Baldry,"https://github.com/ashbaldry/designer,
https://ashbaldry.github.io/designer/",TRUE,https://github.com/ashbaldry/designer,640,70,2022-06-22T19:51:12Z,9.142857142857142
DesignLibrary,"
    A simple interface to build designs using the package 'DeclareDesign'. 
    In one line of code, users can specify the parameters of individual 
    designs and diagnose their properties. The designers can also be used 
    to compare performance of a given design across a range of combinations 
    of parameters, such as effect size, sample size, and assignment probabilities.",2021-10-18,Jasper Cooper,"https://declaredesign.org/r/designlibrary/,
https://github.com/DeclareDesign/DesignLibrary",TRUE,https://github.com/declaredesign/designlibrary,22537,30,2022-03-02T06:51:43Z,751.2333333333333
designr,Generate balanced factorial designs with crossed and nested random and fixed effects <https://github.com/mmrabe/designr>.,2021-04-22,Maximilian M. Rabe,https://maxrabe.com/designr,TRUE,https://github.com/mmrabe/designr,15219,6,2022-02-02T15:40:49Z,2536.5
desplot,"A function for plotting maps of agricultural field experiments that
    are laid out in grids.",2021-10-29,Kevin Wright,https://kwstat.github.io/desplot/,TRUE,https://github.com/kwstat/desplot,35023,19,2021-10-30T02:55:28Z,1843.3157894736842
details,"Create a details HTML tag around R objects to place
    in a Markdown, 'Rmarkdown' and 'roxygen2' documentation.",2022-03-27,Jonathan Sidi,https://github.com/yonicd/details,TRUE,https://github.com/yonicd/details,32618,84,2022-03-27T20:57:52Z,388.3095238095238
detect,"Models for analyzing site occupancy and count data models
  with detection error, including single-visit based models,
  conditional distance sampling and time-removal models.
  Package development was supported by the
  Alberta Biodiversity Monitoring Institute (<https://www.abmi.ca>)
  and the Boreal Avian Modelling Project (<https://borealbirds.ualberta.ca>).",2020-08-12,Peter Solymos,https://github.com/psolymos/detect,TRUE,https://github.com/psolymos/detect,20150,5,2021-11-12T19:59:59Z,4030
detectseparation,"Provides pre-fit and post-fit methods for detecting separation and infinite maximum likelihood estimates in generalized linear models with categorical responses. The pre-fit methods apply on binomial-response generalized liner models such as logit, probit and cloglog regression, and can be directly supplied as fitting methods to the glm() function. They solve the linear programming problems for the detection of separation developed in Konis (2007, <https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a>) using 'ROI' <https://cran.r-project.org/package=ROI> or 'lpSolveAPI' <https://cran.r-project.org/package=lpSolveAPI>. The post-fit methods apply to models with categorical responses, including binomial-response generalized linear models and multinomial-response models, such as baseline category logits and adjacent category logits models; for example, the models implemented in the 'brglm2' <https://cran.r-project.org/package=brglm2> package. The post-fit methods successively refit the model with increasing number of iteratively reweighted least squares iterations, and monitor the ratio of the estimated standard error for each parameter to what it has been in the first iteration. According to the results in Lesaffre & Albert (1989, <https://www.jstor.org/stable/2345845>), divergence of those ratios indicates data separation.",2021-04-22,Ioannis Kosmidis,https://github.com/ikosmidis/detectseparation,TRUE,https://github.com/ikosmidis/detectseparation,31404,4,2021-07-17T15:05:26Z,7851
detourr,"Provides 2D and 3D tour animations as HTML widgets. The user can interact with the widgets using orbit controls, tooltips, brushing, and timeline controls. Linked brushing is supported using 'crosstalk', and widgets can be embedded in Shiny apps or HTML documents. ",2022-06-20,Casper Hart,https://casperhart.github.io/detourr/,TRUE,https://github.com/casperhart/detourr,199,8,2022-06-20T08:51:23Z,24.875
detzrcr,"Compare detrital zircon suites by uploading univariate,
      U-Pb age, or bivariate, U-Pb age and Lu-Hf data, in a 'shiny'-based
      user-interface. Outputs publication quality figures using 'ggplot2', and
      tables of statistics currently in use in the detrital zircon geochronology
      community.",2020-07-23,Magnus Kristoffersen,https://github.com/magnuskristoffersen/detzrcr,TRUE,https://github.com/magnuskristoffersen/detzrcr,20344,6,2022-01-27T07:43:45Z,3390.6666666666665
devoid,"Provides a non-drawing graphic device for benchmarking purpose.
    In order to properly benchmark graphic drawing code it is necessary
    to factor out the device implementation itself so that results are not 
    related to the specific graphics device used during benchmarking. The 
    'devoid' package implements a graphic device that accepts all the required
    calls from R's graphic engine but performs no action. Apart from 
    benchmarking it is unlikely that this device has any practical use.",2020-08-03,Thomas Lin Pedersen,https://github.com/r-lib/devoid,TRUE,https://github.com/r-lib/devoid,18051,20,2021-10-28T06:00:53Z,902.55
devRate,"A set of functions to quantify the relationship between development
    rate and temperature and to build phenological models. The package comprises 
    a set of models and estimated parameters borrowed from a literature review 
    in ectotherms. The methods and literature review are described in Rebaudo 
    et al. (2018) <doi:10.1111/2041-210X.12935>, Rebaudo and Rabhi (2018) 
    <doi:10.1111/eea.12693>, and Regnier et al. (2021) <doi:10.1093/ee/nvab115>. 
    An example can be found in Rebaudo et al. (2017) 
    <doi:10.1007/s13355-017-0480-5>. ",2022-06-29,Francois Rebaudo,https://github.com/frareb/devRate/,TRUE,https://github.com/frareb/devrate,19016,2,2022-06-29T07:07:56Z,9508
devtoolbox,"Reporting tools for the R developer to evaluate their packages in terms of complexity, usage, and performance. Developers can generate an HTML report that displays CRAN downloads, number of open GitHub issues and pull requests, package dependencies, and so on, with each component of the report available as independent functions. ",2022-07-08,Martin Chan,https://github.com/martinctc/devtoolbox/,TRUE,https://github.com/martinctc/devtoolbox,5133,3,2022-07-08T15:38:52Z,1711
devtools,Collection of package development tools.,2021-11-30,Jennifer Bryan,"https://devtools.r-lib.org/, https://github.com/r-lib/devtools",TRUE,https://github.com/r-lib/devtools,40029009,2193,2022-06-16T13:43:38Z,18253.082079343367
dexter,"A system for the management, assessment, and psychometric analysis of data from educational and psychological tests. ",2022-05-24,Jesse Koops,https://dexter-psychometrics.github.io/dexter/,TRUE,https://github.com/dexter-psychometrics/dexter,32177,6,2022-07-08T08:18:00Z,5362.833333333333
dextergui,"Classical Test and Item analysis, 
  Item Response analysis and data management for educational and psychological tests.",2022-06-21,Jesse Koops,https://dexter-psychometrics.github.io/dexter/,TRUE,https://github.com/dexter-psychometrics/dexter,18153,6,2022-07-08T08:18:00Z,3025.5
dexterMST,"Conditional Maximum Likelihood Calibration and data management of multistage tests. 
  Supports polytomous items and incomplete designs with linear as well as multistage tests.
  Extended Nominal Response and Interaction models, DIF and profile analysis.
  See Robert J. Zwitser and Gunter Maris (2015)<doi:10.1007/s11336-013-9369-6>.",2022-02-14,Timo Bechger,https://dexter-psychometrics.github.io/dexter/,TRUE,https://github.com/dexter-psychometrics/dexter,19345,6,2022-07-08T08:18:00Z,3224.1666666666665
dfadjust,"Computes small-sample degrees of freedom adjustment for
    heteroskedasticity robust standard errors, and for clustered standard errors
    in linear regression. See Imbens and Kolesár (2016)
    <doi:10.1162/REST_a_00552> for a discussion of these adjustments.",2022-04-24,Michal Kolesár,https://github.com/kolesarm/Robust-Small-Sample-Standard-Errors,TRUE,https://github.com/kolesarm/robust-small-sample-standard-errors,14294,25,2022-04-24T17:19:34Z,571.76
dfvad,"Decomposing value added growth into explanatory factors.
    A cost constrained value added function is defined to specify the 
    production frontier. Industry estimates can also be aggregated using 
    a weighted average approach.
    Details about the methodology and data can be found in Diewert and Fox (2018)
    <doi:10.1093/oxfordhb/9780190226718.013.19>
    and Zeng, Parsons, Diewert and Fox (2018)
    <https://www.business.unsw.edu.au/research-site/centreforappliedeconomicresearch-site/Documents/emg2018-6_SZeng_EMG-Slides.pdf>.",2021-10-15,Shipei Zeng,https://github.com/shipei-zeng/dfvad,TRUE,https://github.com/shipei-zeng/dfvad,12114,0,2021-10-15T02:42:57Z,NA
DGLMExtPois,"Model estimation, dispersion testing and diagnosis of hyper-Poisson
    Saez-Castillo, A.J. and Conde-Sanchez, A. (2013) 
    <doi:10.1016/j.csda.2012.12.009> and Conway-Maxwell-Poisson Huang, A. (2017)
    regression models.",2022-02-07,Francisco Martinez,https://github.com/franciscomartinezdelrio/DGLMExtPois,TRUE,https://github.com/franciscomartinezdelrio/dglmextpois,14243,0,2022-02-07T12:37:34Z,NA
DGM,"
    Dynamic graphical models for multivariate time series data to estimate directed
    dynamic networks in functional magnetic resonance imaging (fMRI), see Schwab et
    al. (2017) <doi:10.1016/j.neuroimage.2018.03.074>.",2021-12-05,Simon Schwab,https://github.com/schw4b/DGM,TRUE,https://github.com/schw4b/dgm,11810,21,2021-12-05T14:49:01Z,562.3809523809524
DHARMa,"The 'DHARMa' package uses a simulation-based approach to create
    readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed
    models. Currently supported are linear and generalized linear (mixed) models from 'lme4'
    (classes 'lmerMod', 'glmerMod'), 'glmmTMB' 'GLMMadaptive' and 'spaMM', generalized additive models
    ('gam' from 'mgcv'), 'glm' (including 'negbin' from 'MASS', but excluding quasi-distributions) and
    'lm' model classes. Moreover, externally created simulations, e.g. posterior predictive simulations
    from Bayesian software such as 'JAGS', 'STAN', or 'BUGS' can be processed as well.
    The resulting residuals are standardized to values between 0 and 1 and can be interpreted
    as intuitively as residuals from a linear regression. The package also provides a number of
    plot and test functions for typical model misspecification problems, such as
    over/underdispersion, zero-inflation, and residual spatial and temporal autocorrelation.",2022-01-16,Florian Hartig,http://florianhartig.github.io/DHARMa/,TRUE,https://github.com/florianhartig/dharma,180219,153,2022-07-05T13:25:57Z,1177.9019607843138
diagis,"Fast functions for effective sample size, weighted multivariate 
    mean, variance, and quantile computation, and weight diagnostic plot for 
    generic importance sampling type or other probability weighted samples.",2021-11-29,Jouni Helske,https://github.com/helske/diagis/,TRUE,https://github.com/helske/diagis,33994,1,2022-01-27T10:33:02Z,33994
diagmeta,Provides methods by Steinhauser et al. (2016) <DOI:10.1186/s12874-016-0196-1> for meta-analysis of diagnostic accuracy studies with several cutpoints.,2022-04-22,Guido Schwarzer,https://github.com/guido-s/diagmeta,TRUE,https://github.com/guido-s/diagmeta,16685,3,2022-04-22T14:57:39Z,5561.666666666667
diagonals,"Several tools for handling block-matrix diagonals and similar
    constructs are implemented. Block-diagonal matrices can be extracted or removed
    using two small functions implemented here. In addition, non-square matrices
    are supported. Block diagonal matrices occur when two dimensions of a data set
    are combined along one edge of a matrix. For example, trade-flow data in the
    'decompr' and 'gvc' packages have each country-industry combination occur along
    both edges of the matrix.",2022-06-19,Bastiaan Quast,"https://qua.st/diagonals, https://github.com/bquast/diagonals",TRUE,https://github.com/bquast/diagonals,33320,2,2022-06-19T18:17:27Z,16660
DiagrammeR,"
    Build graph/network structures using functions for stepwise addition and
    deletion of nodes and edges. Work with data available in tables for bulk
    addition of nodes, edges, and associated metadata. Use graph selections
    and traversals to apply changes to specific nodes or edges. A wide
    selection of graph algorithms allow for the analysis of graphs. Visualize
    the graphs and take advantage of any aesthetic properties assigned to
    nodes and edges.",2022-03-05,Richard Iannone,https://github.com/rich-iannone/DiagrammeR,TRUE,https://github.com/rich-iannone/diagrammer,937757,1548,2022-03-18T15:45:09Z,605.7861757105943
dialr,"Parse, format, and validate international phone
    numbers using Google's 'libphonenumber' java library,
    <https://github.com/google/libphonenumber>.",2021-05-24,Danny Smith,"https://socialresearchcentre.github.io/dialr/,
https://github.com/socialresearchcentre/dialr,
https://github.com/socialresearchcentre/dialrjars,
https://github.com/google/libphonenumber",TRUE,https://github.com/socialresearchcentre/dialr,23729,7,2021-09-24T01:31:09Z,3389.8571428571427
dialrjars,"Collects 'libphonenumber' jars required for the
    'dialr' package.",2022-05-31,Danny Smith,"https://github.com/socialresearchcentre/dialrjars,
https://github.com/google/libphonenumber",TRUE,https://github.com/socialresearchcentre/dialrjars,27576,2,2022-07-07T01:40:42Z,13788
dials,"Many models contain tuning parameters (i.e. parameters that
    cannot be directly estimated from the data). These tools can be used
    to define objects for creating, simulating, or validating values for
    such parameters.",2022-06-14,Hannah Frick,"https://dials.tidymodels.org, https://github.com/tidymodels/dials",TRUE,https://github.com/tidymodels/dials,798682,106,2022-06-14T12:12:04Z,7534.735849056604
dibble,"Provides a 'dibble' that implements data cubes (derived from 
    'dimensional tibble'), and allows broadcasting by dimensional names.",2022-05-29,Mizuki Uchida,"https://github.com/UchidaMizuki/dibble,
https://uchidamizuki.github.io/dibble/",TRUE,https://github.com/uchidamizuki/dibble,1319,7,2022-06-23T15:52:42Z,188.42857142857142
diceR,"Performs cluster analysis using an ensemble
    clustering framework, Chiu & Talhouk (2018)
    <doi:10.1186/s12859-017-1996-y>.  Results from a diverse set of
    algorithms are pooled together using methods such as majority voting,
    K-Modes, LinkCluE, and CSPA. There are options to compare cluster
    assignments across algorithms using internal and external indices,
    visualizations such as heatmaps, and significance testing for the
    existence of clusters.",2022-05-13,Derek Chiu,"https://github.com/AlineTalhouk/diceR/,
https://alinetalhouk.github.io/diceR/",TRUE,https://github.com/alinetalhouk/dicer,22410,30,2022-05-13T21:01:23Z,747
dictionar6,"Efficient object-oriented R6 dictionary capable of holding objects of any class, including R6. Typed and untyped dictionaries are provided as well as the 'usual' dictionary methods that are available in other OOP languages, for example listing keys, items, values, and methods to get/set these.",2021-09-13,Raphael Sonabend,"https://xoopR.github.io/dictionar6/,
https://github.com/xoopR/dictionar6/",TRUE,https://github.com/xoopr/dictionar6,27659,0,2022-03-25T21:40:09Z,NA
dictionaRy,"An R interface to the 'Free Dictionary API' 
    <https://dictionaryapi.dev/>, 
    <https://github.com/meetDeveloper/freeDictionaryAPI>. Retrieve
    dictionary definitions for English words, as well 
    as additional information including phonetics, part of speech, origins, 
    audio pronunciation, example usage, synonyms and antonyms, returned in 
    'tidy' format for ease of use.",2022-01-10,Steve Condylios,https://github.com/stevecondylios/dictionaRy,TRUE,https://github.com/stevecondylios/dictionary,1881,3,2022-02-09T18:58:52Z,627
dietr,Estimates fractional trophic level from quantitative and qualitative diet data and calculates electivity indices in R. Borstein (2020) <doi:10.1007/s10750-020-04417-5>.,2021-12-14,Samuel R. Borstein,https://github.com/sborstein/dietr,TRUE,https://github.com/sborstein/dietr,13601,4,2021-12-14T06:05:48Z,3400.25
diffEnrich,"Compare functional enrichment between two experimentally-derived groups of genes or proteins (Peterson, DR., et al.(2018)) <doi: 10.1371/journal.pone.0198139>. Given a list of gene symbols, 'diffEnrich'  will
  perform differential enrichment analysis using the Kyoto Encyclopedia of Genes
  and Genomes (KEGG) REST API. This package provides a number of functions that are 
  intended to be used in a pipeline. Briefly, the user provides a KEGG formatted species id for either human, mouse or rat, and the package will
  download and clean species specific ENTREZ gene IDs and map them to their respective
  KEGG pathways by accessing KEGG's REST API. KEGG's API is used to guarantee the most up-to-date pathway data from KEGG. Next, the user will identify significantly
  enriched pathways from two gene sets, and finally, the user will identify 
  pathways that are differentially enriched between the two gene sets. In addition to 
  the analysis pipeline, this package also provides a plotting function. ",2022-06-27,Harry Smith,https://github.com/SabaLab/diffEnrich,TRUE,https://github.com/sabalab/diffenrich,12892,2,2022-06-27T17:27:35Z,6446
diffeqr,"An interface to 'DifferentialEquations.jl' <https://diffeq.sciml.ai/dev/> from the R programming language.
  It has unique high performance methods for solving ordinary differential equations (ODE), stochastic differential equations (SDE),
  delay differential equations (DDE), differential-algebraic equations (DAE), and more. Much of the functionality,
  including features like adaptive time stepping in SDEs, are unique and allow for multiple orders of magnitude speedup over more common methods.
  'diffeqr' attaches an R interface onto the package, allowing seamless use of this tooling by R users. For more information,
  see Rackauckas and Nie (2017) <doi:10.5334/jors.151>.",2021-08-05,Christopher Rackauckas,https://github.com/SciML/diffeqr,TRUE,https://github.com/sciml/diffeqr,18246,119,2021-08-04T12:24:21Z,153.32773109243698
diffobj,"Generate a colorized diff of two R objects for an intuitive
    visualization of their differences.",2021-10-05,Brodie Gaslam,https://github.com/brodieG/diffobj,TRUE,https://github.com/brodieg/diffobj,9937368,212,2021-10-05T10:18:29Z,46874.377358490565
diffpriv,"An implementation of major general-purpose mechanisms for privatizing
    statistics, models, and machine learners, within the framework of differential
    privacy of Dwork et al. (2006) <doi:10.1007/11681878_14>. Example mechanisms
    include the Laplace mechanism for releasing numeric aggregates, and the 
    exponential mechanism for releasing set elements. A sensitivity sampler 
    (Rubinstein & Alda, 2017) <arXiv:1706.02562> permits sampling target 
    non-private function sensitivity; combined with the generic mechanisms, it 
    permits turn-key privatization of arbitrary programs.",2017-07-18,Benjamin Rubinstein,"https://github.com/brubinstein/diffpriv,
http://brubinstein.github.io/diffpriv",TRUE,https://github.com/brubinstein/diffpriv,13285,58,2022-07-01T05:30:18Z,229.05172413793105
diffudist,"Enables the evaluation of diffusion distances for complex single-layer networks.
    Given a network one can define different types of Laplacian (or transition)
    matrices corresponding to different continuous-time random walks dynamics on the network. 
    This package enables the evaluation of Laplacians, stochastic matrices, and the 
    corresponding diffusion distance matrices. The metric structure induced by the network-driven
    process is richer and more robust than the one given by shortest-paths and allows to study 
    the geometry induced by different types of diffusion-like communication mechanisms taking 
    place on complex networks. 
    For more details see: De Domenico, M. (2017) <doi:10.1103/physrevlett.118.168301> and 
    Bertagnolli, G. and De Domenico, M. (2021) <doi:10.1103/PhysRevE.103.042301>.",2021-11-30,Giulia Bertagnolli,https://gbertagnolli.github.io/diffudist/,TRUE,https://github.com/gbertagnolli/diffudist,2034,2,2021-11-30T09:00:16Z,1017
diffviewer,"A HTML widget that shows differences between files
    (text, images, and data frames).",2021-09-30,Hadley Wickham,"https://diffviewer.r-lib.org, https://github.com/r-lib/diffviewer",TRUE,https://github.com/r-lib/diffviewer,67751,52,2021-09-30T20:17:29Z,1302.9038461538462
difNLR,"Detection of differential item functioning (DIF) among dichotomously scored items and differential distractor functioning (DDF) among unscored items with non-linear regression  procedures based on generalized logistic regression models (Hladka & Martinkova, 2020, <doi:10.32614/RJ-2020-014>).",2022-04-18,Adela Hladka,NA,TRUE,https://github.com/adelahladka/difnlr,30705,5,2022-04-18T07:28:16Z,6141
digest,"Implementation of a function 'digest()' for the creation of hash
 digests of arbitrary R objects (using the 'md5', 'sha-1', 'sha-256', 'crc32',
 'xxhash', 'murmurhash', 'spookyhash' and 'blake3' algorithms) permitting easy
 comparison of R language objects, as well as functions such as'hmac()' to
 create hash-based message authentication code. Please note that this package
 is not meant to be deployed for cryptographic purposes for which more
 comprehensive (and widely tested) libraries such as 'OpenSSL' should be
 used.",2021-12-01,"Dirk Eddelbuettel <edd@debian.org> with contributions 
 by Antoine Lucas","https://github.com/eddelbuettel/digest,
http://dirk.eddelbuettel.com/code/digest.html",TRUE,https://github.com/eddelbuettel/digest,25354627,96,2021-12-01T12:02:44Z,264110.6979166667
digitalDLSorteR,Deconvolution of bulk RNA-Seq data using context-specific deconvolution models based on Deep Neural Networks using scRNA-Seq data as input. These models are able to make accurate estimates of the cell composition of bulk RNA-Seq samples from the same context using the advances provided by Deep Learning and the meaningful information provided by scRNA-Seq data. See Torroja and Sanchez-Cabo (2019) <doi:10.3389/fgene.2019.00978> for more details.,2022-05-24,Diego Mañanes,"https://diegommcc.github.io/digitalDLSorteR/,
https://github.com/diegommcc/digitalDLSorteR",TRUE,https://github.com/diegommcc/digitaldlsorter,2607,3,2022-05-24T10:16:41Z,869
digitTests,"Provides statistical tests and support functions for detecting irregular digit patterns in numerical data. The package includes tools for extracting digits at various locations in a number, tests for repeated values, and (Bayesian) tests of digit distributions.",2022-06-16,Koen Derks,"https://koenderks.github.io/digitTests/,
https://github.com/koenderks/digitTests",TRUE,https://github.com/koenderks/digittests,5836,3,2022-06-16T14:35:17Z,1945.3333333333333
DIGSS,"Simulation tool to estimate the rate of success that surveys possessing user-specific characteristics have in identifying archaeological sites (or any groups of clouds of objects), given specific parameters of survey area, survey methods, and site properties. The survey approach used is largely based on the work of Kintigh (1988) <doi:10.2307/281113>.",2021-08-04,Mark Hubbe,https://github.com/markhubbe/DIGSS,TRUE,https://github.com/markhubbe/digss,3750,1,2021-08-03T13:28:12Z,3750
dimensio,"Simple Principal Components Analysis (PCA) and
    Correspondence Analysis (CA) based on the Singular Value Decomposition
    (SVD). This package provides S4 classes and methods to compute,
    extract, summarize and visualize results of multivariate data
    analysis. It also includes methods for partial bootstrap validation
    described in Greenacre (1984) <isbn: 978-0-12-299050-2> and Lebart et al. 
    (2006) <isbn: 978-2-10-049616-7>.",2021-09-18,Nicolas Frerebeau,"https://packages.tesselle.org/dimensio/,
https://github.com/tesselle/dimensio",TRUE,https://github.com/tesselle/dimensio,9506,8,2021-12-08T13:42:05Z,1188.25
dimensionsR,A set of tools to extract bibliographic content from 'Digital Science Dimensions' using 'DSL' API <https://www.dimensions.ai/dimensions-apis/>.,2022-02-07,Massimo Aria,https://github.com/massimoaria/dimensionsR,TRUE,https://github.com/massimoaria/dimensionsr,94329,20,2022-02-07T09:27:36Z,4716.45
dimRed,"A collection of dimensionality reduction
    techniques from R packages and a common
    interface for calling the methods.",2022-03-10,Guido Kraemer,https://www.guido-kraemer.com/software/dimred/,TRUE,https://github.com/gdkrmr/dimred,111113,74,2022-07-10T13:45:18Z,1501.527027027027
dineR,An efficient and convenient set of functions to perform differential network estimation through the use of alternating direction method of multipliers optimization with a variety of loss functions. ,2021-11-15,Ricardo Daniel Marques Salgado,https://github.com/RicSalgado/dineR,TRUE,https://github.com/ricsalgado/diner,2670,1,2021-11-22T17:40:33Z,2670
dipsaus,"Works as an ""add-on"" to packages like 'shiny', 'future', as well as 
    'rlang', and provides utility functions. Just like dipping sauce adding 
    flavors to potato chips or pita bread, 'dipsaus' for data analysis and 
    visualizations adds handy functions and enhancements to popular packages. 
    The goal is to provide simple solutions that are frequently asked for 
    online, such as how to synchronize 'shiny' inputs without freezing the app,
    or how to get memory size on 'Linux' or 'MacOS' system. The enhancements 
    roughly fall into these four categories: 1. 'shiny' input widgets; 2. 
    high-performance computing using 'RcppParallel' and 'future' package; 3. 
    modify R calls and convert among numbers, strings, and other objects. 4. 
    utility functions to get system information such like CPU chip-set, memory 
    limit, etc.",2022-06-18,Zhengjia Wang,https://github.com/dipterix/dipsaus,TRUE,https://github.com/dipterix/dipsaus,23559,11,2022-06-18T04:47:22Z,2141.7272727272725
diptest,"Compute Hartigan's dip test statistic for unimodality /
 multimodality and provide a test with simulation based p-values,  where
 the original public code has been corrected.",2021-05-04,Martin Maechler (originally from Fortran and S-plus by Dario Ringach,https://github.com/mmaechler/diptest,TRUE,https://github.com/mmaechler/diptest,2332635,4,2021-10-04T12:36:01Z,583158.75
Dire,"Fit latent variable linear models, estimating score distributions for groups of people, following Cohen and Jiang (1999) <doi:10.2307/2669917>. In this model, a latent distribution is conditional on students item response, item characteristics, and conditioning variables the user includes. This latent trait is then integrated out. This software is intended to fit the same models as the existing software 'AM' <https://am.air.org/>. As of version 2, also allows the user to draw plausible values.",2022-06-29,Paul Bailey,https://american-institutes-for-research.github.io/Dire/,TRUE,https://github.com/american-institutes-for-research/dire,14557,1,2022-06-29T22:07:36Z,14557
DirectEffects,"A set of functions to estimate the controlled direct effect of treatment fixing a potential mediator to a specific value. Implements the sequential g-estimation estimator described in Vansteelandt (2009) <doi:10.1097/EDE.0b013e3181b6f4c9> and Acharya, Blackwell, and Sen (2016) <doi:10.1017/S0003055416000216>.",2021-05-12,Matthew Blackwell,https://www.mattblackwell.org/software/direct-effects/,TRUE,https://github.com/mattblackwell/directeffects,14082,15,2022-03-21T18:21:39Z,938.8
directlabels,"An extensible framework
 for automatically placing direct labels onto multicolor 'lattice' or
 'ggplot2' plots.
 Label positions are described using Positioning Methods
 which can be re-used across several different plots.
 There are heuristics for examining ""trellis"" and ""ggplot"" objects
 and inferring an appropriate Positioning Method.",2021-01-16,Toby Dylan Hocking,https://github.com/tdhock/directlabels,TRUE,https://github.com/tdhock/directlabels,217119,56,2022-06-17T05:03:49Z,3877.125
dirichletprocess,"Perform nonparametric Bayesian analysis using Dirichlet 
    processes without the need to program the inference algorithms. 
    Utilise included pre-built models or specify custom 
    models and allow the 'dirichletprocess' package to handle the 
    Markov chain Monte Carlo sampling. 
    Our Dirichlet process objects can act as building blocks for a variety 
    of statistical models including and not limited to: density estimation, 
    clustering and prior distributions in hierarchical models.
    See Teh, Y. W. (2011) 
    <https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf>, 
    among many other sources.",2020-06-13,Dean Markwick,https://github.com/dm13450/dirichletprocess,TRUE,https://github.com/dm13450/dirichletprocess,17858,42,2022-05-06T15:09:23Z,425.1904761904762
DirStats,"Nonparametric kernel density estimation, bandwidth selection,
    and other utilities for analyzing directional data. Implements the estimator
    in Bai, Rao and Zhao (1987) <doi:10.1016/0047-259X(88)90113-3>, the
    cross-validation bandwidth selectors in Hall, Watson and Cabrera (1987)
    <doi:10.1093/biomet/74.4.751> and the plug-in bandwidth selectors in
    García-Portugués (2013) <doi:10.1214/13-ejs821>.",2022-06-27,Eduardo García-Portugués,https://github.com/egarpor/DirStats,TRUE,https://github.com/egarpor/dirstats,10766,8,2022-06-04T14:29:47Z,1345.75
disaggR,"The twoStepsBenchmark() and threeRuleSmooth() functions allow you to 
    disaggregate a low-frequency time series with higher frequency time series, 
    using the French National Accounts methodology. The aggregated sum of the 
    resulting time series is strictly equal to the low-frequency time series within the 
    benchmarking window. Typically, the low-frequency time series is an annual one, 
    unknown for the last year, and the high frequency one is either quarterly or 
    monthly. See ""Methodology of quarterly national accounts"", Insee Méthodes 
    N°126, by Insee (2012, ISBN:978-2-11-068613-8, <https://www.insee.fr/en/information/2579410>).",2022-03-04,Arnaud Feldmann (<https://orcid.org/0000-0003-0109-7505>,NA,TRUE,https://github.com/inseefr/disaggr,14498,8,2022-05-26T10:56:54Z,1812.25
DIscBIO,"An open, multi-algorithmic pipeline for easy, fast and efficient
	analysis of cellular sub-populations and the molecular signatures that
	characterize them. The pipeline consists of four successive steps: data
	pre-processing, cellular clustering with pseudo-temporal ordering, defining
	differential expressed genes and biomarker identification. More details on
	Ghannoum et. al. (2021) <doi:10.3390/ijms22031399>. This package implements
	extensions of the work published by Ghannoum et. al. (2019)
	<doi:10.1101/700989>.",2021-04-28,Waldir Leoncio,https://github.com/ocbe-uio/DIscBIO,TRUE,https://github.com/ocbe-uio/discbio,5098,8,2022-05-06T04:58:14Z,637.25
disclapmix,"Make inference in a mixture of discrete Laplace distributions using the EM algorithm. This can e.g. be used for modelling the distribution of Y chromosomal haplotypes as described in [1, 2] (refer to the URL section).",2022-06-29,Mikkel Meyer Andersen,"http://dx.doi.org/10.1016/j.jtbi.2013.03.009
https://arxiv.org/abs/1304.2129",TRUE,https://github.com/mikldk/disclapmix,19020,0,2022-07-09T19:44:47Z,NA
discord,"Functions for discordant kinship modeling (and other sibling-based quasi-experimental designs). Currently, the package contains data restructuring functions and functions for generating biometrically informed data for kin pairs.",2021-07-15,S. Mason Garrison,https://github.com/R-Computing-Lab/discord,TRUE,https://github.com/r-computing-lab/discord,15795,0,2022-04-21T19:08:30Z,NA
DiscreteFDR,"Multiple testing procedures described in the paper Döhler, Durand and Roquain (2018) ""New FDR bounds for discrete and heterogeneous tests"" <doi:10.1214/18-EJS1441>. The main procedures of the paper (HSU and HSD), their adaptive counterparts (AHSU and AHSD), and the HBR variant are available and are coded to take as input a set of observed p-values and their discrete support under the null. A function to compute such p-values and supports for Fisher's exact tests is also provided, along with a wrapper allowing to apply discrete procedures directly from contingency tables.",2021-09-03,Florian Junge,https://github.com/DISOhda/DiscreteFDR,TRUE,https://github.com/disohda/discretefdr,16519,1,2021-09-04T10:01:47Z,16519
discretefit,"Implements fast Monte Carlo simulations for 
    goodness-of-fit (GOF) tests for discrete distributions. This 
    includes tests based on the Chi-squared statistic, the 
    log-likelihood-ratio (G^2) statistic, the Freeman-Tukey 
    (Hellinger-distance) statistic, the Kolmogorov-Smirnov 
    statistic, the Cramer-von Mises statistic as described in 
    Choulakian, Lockhart and Stephens (1994) <doi:10.2307/3315828>, 
    and the root-mean-square statistic, see Perkins, 
    Tygert, and Ward (2011) <doi:10.1016/j.amc.2011.03.124>.",2022-01-25,Josh McCormick,https://github.com/josh-mc/discretefit,TRUE,https://github.com/josh-mc/discretefit,3640,0,2022-01-24T23:53:02Z,NA
discrim,"Bindings for additional classification models for use with
    the 'parsnip' package. Models include flavors of discriminant
    analysis, such as linear (Fisher (1936)
    <doi:10.1111/j.1469-1809.1936.tb02137.x>), regularized (Friedman
    (1989) <doi:10.1080/01621459.1989.10478752>), and flexible (Hastie,
    Tibshirani, and Buja (1994) <doi:10.1080/01621459.1994.10476866>), as
    well as naive Bayes classifiers (Hand and Yu (2007)
    <doi:10.1111/j.1751-5823.2001.tb00465.x>).",2022-06-23,Emil Hvitfeldt,"https://discrim.tidymodels.org/,
https://github.com/tidymodels/discrim/",TRUE,https://github.com/tidymodels/discrim,42505,26,2022-06-23T22:34:17Z,1634.8076923076924
diseq,"Superseded by package markets. Provides estimation methods for
    markets in equilibrium and disequilibrium. Supports the estimation of an
    equilibrium and four disequilibrium models with both correlated and
    independent shocks. Also provides post-estimation analysis tools, such
    as aggregation, marginal effect, and shortage calculations. The estimation
    methods are based on full information maximum likelihood techniques given
    in Maddala and Nelson (1974) <doi:10.2307/1914215>. They are implemented
    using the analytic derivative expressions calculated in
    Karapanagiotis (2020) <doi:10.2139/ssrn.3525622>. Standard
    errors can be estimated by adjusting for heteroscedasticity or clustering.
    The equilibrium estimation constitutes a case of a system of linear,
    simultaneous equations. Instead, the disequilibrium models replace the
    market-clearing condition with a non-linear,
    short-side rule and allow for different specifications of price dynamics. ",2022-06-01,Pantelis Karapanagiotis,"https://github.com/pi-kappa-devel/diseq/,
https://diseq.pikappa.eu/",TRUE,https://github.com/pi-kappa-devel/diseq,13058,2,2022-06-01T16:46:16Z,6529
DisImpact,"Implements methods for calculating disproportionate impact: the percentage point gap, proportionality index, and the 80% index.
 California Community Colleges Chancellor's Office (2017).  Percentage Point Gap Method. <https://www.cccco.edu/-/media/CCCCO-Website/About-Us/Divisions/Digital-Innovation-and-Infrastructure/Research/Files/PercentagePointGapMethod2017.ashx>.
 California Community Colleges Chancellor's Office (2014).  Guidelines for Measuring Disproportionate Impact in Equity Plans. <https://www.cccco.edu/-/media/CCCCO-Website/Files/DII/guidelines-for-measuring-disproportionate-impact-in-equity-plans-tfa-ada.pdf>.",2022-06-07,Vinh Nguyen,https://github.com/vinhdizzo/DisImpact,TRUE,https://github.com/vinhdizzo/disimpact,19622,1,2022-06-07T17:49:27Z,19622
disk.frame,"A disk-based data manipulation tool for working with 
  large-than-RAM datasets. Aims to lower the barrier-to-entry for 
  manipulating large datasets by adhering closely to popular and 
  familiar data manipulation paradigms like 'dplyr' verbs and 
  'data.table' syntax.",2022-03-07,Dai ZJ,https://diskframe.com,TRUE,https://github.com/diskframe/disk.frame,34441,578,2022-03-07T11:13:28Z,59.58650519031142
dismo,"Methods for species distribution modeling, that is, predicting the environmental similarity of any site to that of the locations of known occurrences of a species.",2021-10-11,Robert J. Hijmans,https://rspatial.org/raster/sdm/,TRUE,https://github.com/rspatial/dismo,317728,11,2022-07-08T23:40:29Z,28884.363636363636
disordR,"Functionality for manipulating values of associative
  maps.  Ordinary R vectors are unsuitable for working with values of
  associative maps because elements of an R vector may be accessed by
  reference to their location in the vector, but associative maps are
  stored in arbitrary order.  However, when associating keys with
  values one needs both parts to be in 1-1 correspondence, so one
  cannot dispense with the order entirely.  The 'disordR' package
  includes a single S4 class, disord.  This class allows one to
  perform only those operations appropriate for manipulating values of
  associative maps and prevents any other operation (such as accessing
  an element at a particular location).  A useful heuristic is that
  one is only allowed to access or modify a disord object using a
  python list comprehension.  The idea is to prevent ill-defined
  operations on values (or keys) of associative maps, whose order is
  undefined or at best implementation-specific, while allowing and
  facilitating sensible operations.",2022-05-24,Robin K. S. Hankin,https://github.com/RobinHankin/disordR,TRUE,https://github.com/robinhankin/disordr,7243,1,2022-06-30T21:30:10Z,7243
dispositionEffect,"Evaluate the presence of disposition effect and others irrational
    investor's behaviors based solely on investor's transactions and financial
    market data. Experimental data can also be used to perform the analysis.  
    Four different methodologies are implemented to account for the different
    nature of human behaviors on financial markets.  
    Novel analyses such as portfolio driven and time series disposition effect
    are also allowed.",2022-05-30,Marco Zanotti,"https://marcozanotti.github.io/dispositionEffect/,
https://github.com/marcozanotti/dispositionEffect",TRUE,https://github.com/marcozanotti/dispositioneffect,2222,1,2022-05-30T07:15:16Z,2222
dispRity,"A modular package for measuring disparity (multidimensional space occupancy). Disparity can be calculated from any matrix defining a multidimensional space. The package provides a set of implemented metrics to measure properties of the space and allows users to provide and test their own metrics (Guillerme (2018) <doi:10.1111/2041-210X.13022>). The package also provides functions for looking at disparity in a serial way (e.g. disparity through time - Guillerme and Cooper (2018) <doi:10.1111/pala.12364>) or per groups as well as visualising the results. Finally, this package provides several statistical tests for disparity analysis.",2022-04-26,Thomas Guillerme,https://github.com/TGuillerme/dispRity,TRUE,https://github.com/tguillerme/disprity,23918,17,2022-05-24T11:53:44Z,1406.9411764705883
disprofas,"Similarity of dissolution profiles is assessed using the
    similarity factor f2 according to the EMA guideline (European
    Medicines Agency 2010) ""On the investigation of bioequivalence"".
    Dissolution profiles are regarded as similar if the f2 value is
    between 50 and 100. For the applicability of the similarity factor f2,
    the variability between profiles needs to be within certain limits.
    Often, this constraint is violated. One possibility in this situation
    is to resample the measured profiles in order to obtain a bootstrap
    estimate of f2 (Shah et al. (1998) <doi:10.1023/A:1011976615750>).
    Other alternatives are the model-independent non-parametric
    multivariate confidence region (MCR) procedure (Tsong et al. (1996)
    <doi:10.1177/009286159603000427>) or the T2-test for equivalence
    procedure (Hoffelder (2016)
    <https://www.ecv.de/suse_item.php?suseId=Z|pi|8430>). Functions for
    estimation of f1, f2, bootstrap f2, MCR / T2-test for equivalence
    procedure are implemented.",2021-12-08,Pius Dahinden,https://github.com/piusdahinden/disprofas,TRUE,https://github.com/piusdahinden/disprofas,5269,0,2021-12-10T09:16:45Z,NA
dissCqN,"Calculate multiple or pairwise dissimilarity for orders q = 0-N 
    (CqN; Chao et al. 2008 <doi:10/fcvn63>) for a set of species assemblages or 
    interaction networks.",2021-10-14,Mark Murphy,"https://murphymv.github.io/dissCqN/,
https://github.com/murphymv/dissCqN",TRUE,https://github.com/murphymv/disscqn,2599,0,2021-10-18T14:08:44Z,NA
Distance,"A simple way of fitting detection functions to distance sampling
    data for both line and point transects. Adjustment term selection, left and
    right truncation as well as monotonicity constraints and binning are
    supported. Abundance and density estimates can also be calculated (via a
    Horvitz-Thompson-like estimator) if survey area information is provided. See
    Miller et al. (2019) <doi:10.18637/jss.v089.i01> for more information on
    methods and <https://examples.distancesampling.org/> for example analyses.",2022-03-17,David Lawrence Miller,https://github.com/DistanceDevelopment/Distance/,TRUE,https://github.com/distancedevelopment/distance,48781,4,2022-06-23T20:11:07Z,12195.25
distanceto,"Calculates distances from point locations to features.
    The usual approach for eg. resource selection function analyses is to
    generate a complete distance to features surface then sample it with your 
    observed and random points. Since these raster based approaches can be
    pretty costly with large areas, and often lead to memory issues in R, 
    the distanceto package opts to compute these distances using
    efficient, vector based approaches. As a helper, there's a decidedly 
    low-res raster based approach for visually inspecting your region's 
    distance surface. But the workhorse is distance_to.",2021-11-11,Alec L. Robitaille,"https://github.com/robitalec/distance-to,
https://robitalec.github.io/distance-to/",TRUE,https://github.com/robitalec/distance-to,2307,1,2021-11-26T16:56:07Z,2307
distill,"Scientific and technical article format for the web.
    'Distill' articles feature attractive, reader-friendly typography,
    flexible layout options for visualizations, and full support for
    footnotes and citations.",2022-05-12,Christophe Dervieux,"https://github.com/rstudio/distill,
https://pkgs.rstudio.com/distill",TRUE,https://github.com/rstudio/distill,83682,385,2022-07-04T09:50:28Z,217.35584415584415
distillML,"Provides several methods for model distillation and interpretability 
    for general black box machine learning models and treatment effect estimation
    methods. For details on the algorithms implemented, see <https://forestry-labs.github.io/distillML/index.html>
    Brian Cho, Theo F. Saarinen, Jasjeet S. Sekhon, Simon Walter.",2022-07-07,Theo Saarinen,https://github.com/forestry-labs/distillML,TRUE,https://github.com/forestry-labs/distillml,20,1,2022-07-05T23:52:20Z,20
DistPlotter,"Package including an interactive Shiny application for plotting 
    common univariate distributions.",2022-03-10,Christopher Casement,"https://github.com/ccasement/DistPlotter,
https://CRAN.R-project.org/package=DistPlotter",TRUE,https://github.com/ccasement/distplotter,1186,0,2022-03-10T21:38:35Z,NA
distr6,"An R6 object oriented distributions package. Unified
    interface for 42 probability distributions and 11 kernels including
    functionality for multiple scientific types. Additionally
    functionality for composite distributions and numerical imputation.
    Design patterns including wrappers and decorators are described in
    Gamma et al. (1994, ISBN:0-201-63361-2). For quick reference of
    probability distributions including d/p/q/r functions and results we
    refer to McLaughlin, M. P. (2001). Additionally Devroye (1986,
    ISBN:0-387-96305-7) for sampling the Dirichlet distribution, Gentle
    (2009) <doi:10.1007/978-0-387-98144-4> for sampling the Multivariate
    Normal distribution and Michael et al. (1976) <doi:10.2307/2683801>
    for sampling the Wald distribution.",2022-03-27,Raphael Sonabend,"https://alan-turing-institute.github.io/distr6/,
https://github.com/alan-turing-institute/distr6/",TRUE,https://github.com/alan-turing-institute/distr6,151612,94,2022-06-18T20:45:21Z,1612.8936170212767
distreg.vis,"Functions for visualizing distributional regression models fitted using the 'gamlss', 'bamlss' or 'betareg' R package. The core of the package consists of a 'shiny' application, where the model results can be interactively explored and visualized.",2022-02-07,Stanislaus Stadlmann,https://github.com/Stan125/distreg.vis,TRUE,https://github.com/stan125/distreg.vis,15079,2,2022-02-07T10:48:40Z,7539.5
distributional,"Vectorised distribution objects with tools for manipulating, 
    visualising, and using probability distributions. Designed to allow model
    prediction outputs to return distributions rather than their parameters, 
    allowing users to directly interact with predictive distributions in a
    data-oriented workflow. In addition to providing generic replacements for
    p/d/q/r functions, other useful statistics can be computed including means,
    variances, intervals, and highest density regions.",2022-01-05,Mitchell OHara-Wild,"https://pkg.mitchelloharawild.com/distributional/,
https://github.com/mitchelloharawild/distributional",TRUE,https://github.com/mitchelloharawild/distributional,571698,68,2022-06-10T04:17:28Z,8407.323529411764
distributions3,"Tools to create and manipulate probability distributions
    using S3.  Generics random(), pdf(), cdf() and quantile() provide
    replacements for base R's r/d/p/q style functions.  Functions and
    arguments have been named carefully to minimize confusion for students
    in intro stats courses. The documentation for each distribution
    contains detailed mathematical notes.",2022-06-21,Alex Hayes,"https://github.com/alexpghayes/distributions3,
https://alexpghayes.github.io/distributions3/",TRUE,https://github.com/alexpghayes/distributions3,23982,90,2022-06-21T19:59:40Z,266.46666666666664
distrom,"Fast distributed/parallel estimation for multinomial logistic regression via Poisson factorization and the 'gamlr' package.  For details see: Taddy (2015, AoAS), Distributed Multinomial Regression, <arXiv:1311.6139>.",2022-03-29,Nelson Rayl,https://github.com/TaddyLab/distrom,TRUE,https://github.com/taddylab/distrom,26010,16,2022-03-28T20:51:19Z,1625.625
distrr,"Tools to estimate and manage empirical distributions,
    which should work with survey data. One of the main features is the 
    possibility to create data cubes of estimated statistics, that include
    all the combinations of the variables of interest (see for example functions
    dcc5() and dcc6()).",2020-07-14,Sandro Petrillo Burri,"https://gibonet.github.io/distrr,
https://github.com/gibonet/distrr",TRUE,https://github.com/gibonet/distrr,16626,6,2021-09-13T06:17:33Z,2771
dittodb,"Testing and documenting code that communicates with remote
  databases can be painful. Although the interaction with R is usually relatively 
  simple (e.g. data(frames) passed to and from a database), because they rely on 
  a separate service and the data there, testing them can be difficult to set up,
  unsustainable in a continuous integration environment, or impossible without 
  replicating an entire production cluster. This package addresses that by 
  allowing you to make recordings from your database interactions and then play 
  them back while testing (or in other contexts) all without needing to spin up 
  or have access to the database your code would typically connect to.",2022-06-17,Jonathan Keane,"https://dittodb.jonkeane.com/, https://github.com/ropensci/dittodb",TRUE,https://github.com/ropensci/dittodb,13349,65,2022-06-25T21:19:54Z,205.36923076923077
diveR,"A suite of 'loon' related packages providing data analytic tools for 
    Direct Interactive Visual Exploration in R ('diveR').
    These tools work with and complement those of the 'tidyverse' suite, 
    extending the grammar of 'ggplot2' to become a grammar of interactive
    graphics.
    The suite provides many visual tools designed for moderately (100s of variables)
    high dimensional data analysis, through 'zenplots' and novel tools in 'loon', and
    extends the 'ggplot2' grammar to provide parallel coordinates, Andrews plots, and arbitrary 
    glyphs through 'ggmulti'.
    The  'diveR' package gathers together and installs all these related packages
    in a single step. ",2021-09-28,R. Wayne Oldford,https://github.com/great-northern-diver/diver/,TRUE,https://github.com/great-northern-diver/diver,5243,1,2021-09-28T19:10:49Z,5243
divest,"Provides tools to sort DICOM-format medical image files, and
    convert them to NIfTI-1 format.",2022-01-11,Jon Clayden,https://github.com/jonclayden/divest,TRUE,https://github.com/jonclayden/divest,22665,11,2022-01-12T09:28:37Z,2060.4545454545455
divseg,Implements common measures of diversity and spatial segregation. This package has tools to compute the majority of measures are reviewed in Douglas and Massey (1988) <doi:10.2307/2579183>. Multiple common measures of within-geography diversity are implemented as well. All functions operate on data frames with a 'tidyselect' based workflow.,2021-08-09,Christopher T. Kenny,"https://github.com/christopherkenny/divseg/,
https://christopherkenny.github.io/divseg/",TRUE,https://github.com/christopherkenny/divseg,3661,1,2021-08-11T21:27:48Z,3661
diyar,"An R package for record linkage and implementing epidemiological case definitions in R.
    Record linkage is implemented either through a multistage deterministic approach or a probabilistic approach. 
    Matching records are assigned to unique groups. There are mechanisms to address missing data and conflicting matches across linkage stages.
    Track and assign events (e.g. sample collection) and periods (e.g. hospital admission) to unique groups based on a case definition. 
    The tracking process permits several options such as episode lengths and recurrence.
    Duplicate events or records can then be identified for removal or further analyses.  ",2021-12-05,Olisaeloka Nsonwu,https://olisansonwu.github.io/diyar/index.html,TRUE,https://github.com/olisansonwu/diyar,17024,4,2022-06-16T13:27:02Z,4256
DIZtools,"Lightweight utility functions used for the R package
    development infrastructure inside the data integration centers ('DIZ')
    to standardize and facilitate repetitive tasks such as setting up a
    database connection or issuing notification messages and to avoid
    redundancy.",2022-05-18,Jonathan M. Mang,https://github.com/miracum/misc-diztools,TRUE,https://github.com/miracum/misc-diztools,7106,1,2022-05-18T07:01:49Z,7106
DIZutils,"Utility functions used for the R package development
    infrastructure inside the data integration centers ('DIZ') to
    standardize and facilitate repetitive tasks such as setting up a
    database connection or issuing notification messages and to avoid
    redundancy.",2022-06-27,Jonathan M. Mang,https://github.com/miracum/misc-dizutils,TRUE,https://github.com/miracum/misc-dizutils,16379,2,2022-06-27T06:40:03Z,8189.5
DLL,"Implementation of the Decorrelated Local Linear estimator proposed 
    in <arxiv:1907.12732>. It constructs the confidence interval for the derivative 
    of the function of interest under the high-dimensional sparse additive model.",2022-02-18,Wei Yuan,https://github.com/zijguo/HighDim-Additive-Inference,TRUE,https://github.com/zijguo/highdim-additive-inference,1511,1,2022-03-02T20:24:01Z,1511
dlnm,Collection of functions for distributed lag linear and non-linear models.,2021-10-07,Antonio Gasparrini,"https://github.com/gasparrini/dlnm,
http://www.ag-myresearch.com/package-dlnm",TRUE,https://github.com/gasparrini/dlnm,58746,43,2021-10-07T10:13:13Z,1366.1860465116279
dlookr,"A collection of tools that support data diagnosis, exploration, and transformation. 
    Data diagnostics provides information and visualization of missing values and outliers and 
    unique and negative values to help you understand the distribution and quality of your data. 
    Data exploration provides information and visualization of the descriptive statistics of 
    univariate variables, normality tests and outliers, correlation of two variables, and 
    relationship between target variable and predictor. Data transformation supports binning 
    for categorizing continuous variables, imputates missing values and outliers, resolving skewness. 
    And it creates automated reports that support these three tasks.",2022-06-07,Choonghyun Ryu,"https://github.com/choonghyunryu/dlookr/,
https://choonghyunryu.github.io/dlookr/",TRUE,https://github.com/choonghyunryu/dlookr,108179,153,2022-07-10T15:09:22Z,707.0522875816994
dlr,"The goal of dlr is to provide a friendly wrapper around the common 
    pattern of downloading a file if that file does not already exist locally. ",2021-09-18,Jonathan Bratt,https://github.com/macmillancontentscience/dlr,TRUE,https://github.com/macmillancontentscience/dlr,4173,0,2021-09-17T19:31:19Z,NA
dlstats,"Monthly download stats of 'CRAN' and 'Bioconductor' packages.
	     Download stats of 'CRAN' packages is from the 'RStudio' 'CRAN mirror', see <https://cranlogs.r-pkg.org:443>.
	     'Bioconductor' package download stats is at <https://bioconductor.org/packages/stats/>.",2022-04-13,Guangchuang Yu,https://github.com/GuangchuangYu/dlstats,TRUE,https://github.com/guangchuangyu/dlstats,38706,9,2022-04-13T08:32:10Z,4300.666666666667
dm,"Provides tools for working with multiple related
    tables, stored as data frames or in a relational database.  Multiple
    tables (data and metadata) are stored in a compound object, which can
    then be manipulated with a pipe-friendly syntax.",2022-07-06,Kirill Müller,"https://cynkra.github.io/dm/, https://github.com/cynkra/dm",TRUE,https://github.com/cynkra/dm,31631,400,2022-07-10T06:11:18Z,79.0775
dmbc,"Functions for fitting a Bayesian model for grouping binary
    dissimilarity matrices in homogeneous clusters. Currently, it includes
    methods only for binary data (<doi:10.18637/jss.v100.i16>).",2022-04-26,Sergio Venturini,NA,TRUE,https://github.com/sergioventurini/dmbc,9786,1,2022-04-26T08:35:04Z,9786
DMCfun,"
  DMC model simulation detailed in Ulrich, R., Schroeter, H., Leuthold, H., & Birngruber, T. (2015).
  Automatic and controlled stimulus processing in conflict tasks: Superimposed diffusion processes and delta functions.
  Cognitive Psychology, 78, 148-174. Ulrich et al. (2015) <doi:10.1016/j.cogpsych.2015.02.005>.
  Decision processes within choice reaction-time (CRT) tasks are often modelled using evidence accumulation models (EAMs),
  a variation of which is the Diffusion Decision Model (DDM, for a review, see Ratcliff & McKoon, 2008).
  Ulrich et al. (2015) introduced a Diffusion Model for Conflict tasks (DMC). The DMC model combines common
  features from within standard diffusion models with the addition of superimposed controlled and automatic activation.
  The DMC model is used to explain distributional reaction time (and error rate) patterns in common behavioural
  conflict-like tasks (e.g., Flanker task, Simon task). This R-package implements the DMC model and provides functionality
  to fit the model to observed data. Further details are provided in the following paper: 
  Mackenzie, I. G., & Dudschig, C. (2021). DMCfun: An R package for fitting Diffusion Model of Conflict (DMC) to reaction 
  time and error rate data. Methods in Psychology, 100074. <doi:10.1016/j.metip.2021.100074>.",2021-10-25,Ian G. Mackenzie,"https://github.com/igmmgi/DMCfun,
https://CRAN.R-project.org/package=DMCfun,
https://www.sciencedirect.com/science/article/pii/S259026012100031X",TRUE,https://github.com/igmmgi/dmcfun,10903,13,2022-07-08T07:36:40Z,838.6923076923077
dmdScheme,"Forms the core for developing own domain specific metadata schemes. 
                  It contains the basic functionality needed for all metadata schemes based on the
                  'dmdScheme'. See R.M. Krug and O.L. Petchey (2019) <DOI:10.5281/zenodo.3581970>.",2022-04-12,Rainer M. Krug,"https://UZH-PEG.github.io/dmdScheme/,
https://github.com/UZH-PEG/dmdScheme/",TRUE,https://github.com/uzh-peg/dmdscheme,12306,2,2022-04-12T13:10:33Z,6153
DNAtools,"Computationally efficient tools for comparing all pairs of profiles
    in a DNA database. The expectation and covariance of the summary statistic
    is implemented for fast computing. Routines for estimating proportions of
    close related individuals are available. The use of wildcards (also called F-
    designation) is implemented. Dedicated functions ease plotting the results. 
    See Tvedebrink et al. (2012) <doi:10.1016/j.fsigen.2011.08.001>. 
    Compute the distribution of the numbers of alleles in DNA mixtures. 
    See Tvedebrink (2013) <doi:10.1016/j.fsigss.2013.10.142>.",2022-03-17,Mikkel Meyer Andersen,NA,TRUE,https://github.com/mikldk/dnatools,20411,0,2022-03-17T13:02:44Z,NA
DNH4,"Provides some utils to get Korean text sample from news articles
            in Daum which is popular news portal service in Korea.",2022-03-09,Chanyub Park,"https://forkonlp.github.io/DNH4/,
https://github.com/forkonlp/DNH4/",TRUE,https://github.com/forkonlp/dnh4,2006,30,2022-03-06T12:36:00Z,66.86666666666666
DNMF,"Discriminant Non-Negative Matrix Factorization aims to extend the Non-negative Matrix Factorization algorithm in order to extract features that enforce not only the spatial locality, but also the separability between classes in a discriminant manner. It refers to three article, Zafeiriou, Stefanos, et al. ""Exploiting discriminant information in nonnegative matrix factorization with application to frontal face verification."" Neural Networks, IEEE Transactions on 17.3 (2006): 683-695. Kim, Bo-Kyeong, and Soo-Young Lee. ""Spectral Feature Extraction Using dNMF for Emotion Recognition in Vowel Sounds."" Neural Information Processing. Springer Berlin Heidelberg, 2013. and Lee, Soo-Young, Hyun-Ah Song, and Shun-ichi Amari. ""A new discriminant NMF algorithm and its application to the extraction of subtle emotional differences in speech."" Cognitive neurodynamics 6.6 (2012): 525-535.",2022-05-10,Zhilong Jia,https://github.com/zhilongjia/DNMF,TRUE,https://github.com/zhilongjia/dnmf,15633,8,2022-05-10T09:02:43Z,1954.125
do,"Flexibly convert data between long and wide format using just two
    functions: reshape_toLong() and reshape_toWide().",2021-08-03,Jing Zhang,https://github.com/yikeshu0611/do,TRUE,https://github.com/yikeshu0611/do,44056,3,2021-07-31T11:53:41Z,14685.333333333334
doc2vec,"Learn vector representations of sentences, paragraphs or documents by using the 'Paragraph Vector' algorithms,
    namely the distributed bag of words ('PV-DBOW') and the distributed memory ('PV-DM') model. 
    The techniques in the package are detailed in the paper ""Distributed Representations of Sentences and Documents"" by Mikolov et al. (2014), available at <arXiv:1405.4053>.
    The package also provides an implementation to cluster documents based on these embedding using a technique called top2vec. 
    Top2vec finds clusters in text documents by combining techniques to embed documents and words and density-based clustering.
    It does this by embedding documents in the semantic space as defined by the 'doc2vec' algorithm. Next it maps
    these document embeddings to a lower-dimensional space using the 'Uniform Manifold Approximation and Projection' (UMAP) clustering algorithm 
    and finds dense areas in that space using a 'Hierarchical Density-Based Clustering' technique (HDBSCAN). These dense
    areas are the topic clusters which can be represented by the corresponding topic vector which is an aggregate of the 
    document embeddings of the documents which are part of that topic cluster. In the same semantic space similar words can 
    be found which are representative of the topic.
    More details can be found in the paper 'Top2Vec: Distributed Representations of Topics' by D. Angelov available at <arXiv:2008.09470>. ",2021-03-28,Jan Wijffels,https://github.com/bnosac/doc2vec,TRUE,https://github.com/bnosac/doc2vec,16614,30,2021-11-11T11:47:38Z,553.8
dockerfiler,"Build a Dockerfile straight from your R session.
    'dockerfiler' allows you to create step by step a Dockerfile, and
    provide convenient tools to wrap R code inside this Dockerfile.",2022-07-06,Colin Fay,https://github.com/ThinkR-open/dockerfiler,TRUE,https://github.com/thinkr-open/dockerfiler,130891,110,2022-07-04T07:16:02Z,1189.918181818182
DockerParallel,"This is the core package that provides both the user API and developer API to deploy 
    the parallel cluster on the cloud using the container service. The user can call 
    clusterPreset() to define the cloud service provider and container and makeDockerCluster()
    to create the cluster. The developer should see ""developer's cookbook"" on how to define
    the cloud provider and container.",2021-06-23,Jiefei Wang,https://github.com/Jiefei-Wang/DockerParallel,TRUE,https://github.com/jiefei-wang/dockerparallel,6002,14,2022-01-26T03:38:04Z,428.7142857142857
doconv,"Functions to convert 'Microsoft Word' or 'Microsoft PowerPoint' 
 documents to 'PDF' format and also for converting them into a thumbnail. 
 In order to work, 'LibreOffice' must be installed on the machine and 
 possibly 'python' and 'Microsoft Word'. If the latter is available, 
 it can be used to produce PDF documents identical to the originals, 
 otherwise, 'LibreOffice' is used.",2021-05-19,David Gohel,NA,TRUE,https://github.com/ardata-fr/doconv,6393,8,2021-09-01T20:56:03Z,799.125
docreview,High quality documentation can make for a great experience for your users. You can use 'docreview' to check that your R package documentation passes a number of configurable checks relating to documentation content.,2021-08-17,Nic Crane,https://thisisnic.github.io/docreview/,TRUE,https://github.com/thisisnic/docreview,8594,13,2021-08-25T20:15:58Z,661.0769230769231
docstring,"Provides the ability to display something analogous to
    Python's docstrings within R.  By allowing the user to document
    their functions as comments at the beginning of their function
    without requiring putting the function into a package we allow
    more users to easily provide documentation for their functions.
    The documentation can be viewed just like any other help files
    for functions provided by packages as well.",2017-03-24,Dason Kurkiewicz,https://github.com/dasonk/docstring,TRUE,https://github.com/dasonk/docstring,898591,46,2021-12-21T22:32:46Z,19534.58695652174
dodgr,"Distances on dual-weighted directed graphs using
    priority-queue shortest paths (Padgham (2019) <doi:10.32866/6945>).
    Weighted directed graphs have weights from A to B which may differ
    from those from B to A.  Dual-weighted directed graphs have two sets
    of such weights. A canonical example is a street network to be used
    for routing in which routes are calculated by weighting distances
    according to the type of way and mode of transport, yet lengths of
    routes must be calculated from direct distances.",2022-06-08,Mark Padgham,https://github.com/ATFutures/dodgr,TRUE,https://github.com/atfutures/dodgr,31505,108,2022-06-28T10:24:03Z,291.712962962963
doFuture,"Provides a '%dopar%' adapter such that any type of futures can
    be used as backends for the 'foreach' framework.",2022-04-26,Henrik Bengtsson,"https://doFuture.futureverse.org,
https://github.com/HenrikBengtsson/doFuture",TRUE,https://github.com/henrikbengtsson/dofuture,138788,68,2022-06-02T05:50:28Z,2041
domir,"Provides tools that support relative importance analysis focusing 
    on dominance analysis.  Dominance analysis is a methodology for 
    determining the relative importance of predictors/features/independent
    variables (Azen, R., & Budescu, D. V. (2003) <doi:10.1037/1082-989X.8.2.129>; 
    Groemping, U. (2007) <doi:10.1198/000313007X188252>) 
    as well as parameter estimates (Luchman, J. N, Lei, X., & Kaplan, S. 
    (2020) <doi:10.47263/JASEM.4(2)02>). 
    These tools are intended to extend relative importance analysis to, 
    effectively, any statistical or machine learning function as defined or 
    desired by the user-especially those where the user wants to use custom 
    importance/fit statistic or modeling function.",2022-05-09,Joseph Luchman,https://github.com/jluchman/domir,TRUE,https://github.com/jluchman/domir,7054,2,2022-07-10T13:40:50Z,3527
donut,"Finds the k nearest neighbours in a dataset of specified points, 
  adding the option to wrap certain variables on a torus.  The user chooses
  the algorithm to use to find the nearest neighbours. Two such algorithms,
  provided by the packages 'RANN' <https://cran.r-project.org/package=RANN>, 
  and 'nabor' <https://cran.r-project.org/package=nabor>, are suggested.",2021-11-10,Paul J. Northrop,"https://github.com/paulnorthrop/donut,
https://paulnorthrop.github.io/donut/",TRUE,https://github.com/paulnorthrop/donut,14541,0,2022-04-11T21:55:18Z,NA
doParallel,"Provides a parallel backend for the %dopar% function using
        the parallel package.",2022-02-07,Folashade Daniel,https://github.com/RevolutionAnalytics/doparallel,TRUE,https://github.com/revolutionanalytics/doparallel,5981233,2,2022-02-15T18:30:09Z,2990616.5
doRedis,Create and manage fault-tolerant task queues for the 'foreach' package using the 'Redis' key/value database.,2022-03-11,B. W. Lewis,NA,TRUE,https://github.com/bwlewis/doredis,54022,70,2021-08-24T22:29:26Z,771.7428571428571
doremi,"Provides models to fit the dynamics of a regulated system experiencing exogenous inputs. 
    The underlying models use differential equations and linear mixed-effects regressions to estimate the 
    coefficients of the equation. With them, the functions can provide an estimated signal.
    The package provides simulation and analysis functions and also print, summary, plot and predict methods,
    adapted to the function outputs, for easy implementation and presentation of results.",2021-01-29,Mongin Denis,https://github.com/dcourvoisier/doremi,TRUE,https://github.com/dcourvoisier/doremi,13660,0,2022-01-13T09:42:00Z,NA
doseminer,"Utilities for converting unstructured electronic prescribing instructions into structured medication data. Extracts drug dose, units, daily dosing frequency and intervals from English-language prescriptions. Based on Karystianis et al. (2015) <doi:10.1186/s12911-016-0255-x>.",2021-07-19,David Selby,NA,TRUE,https://github.com/selbosh/doseminer,5204,0,2021-07-19T10:28:44Z,NA
DOSPortfolio,"
  Constructs dynamic optimal shrinkage estimators for the weights of the global 
  minimum variance portfolio which are reconstructed at given reallocation 
  points as derived in Bodnar, Parolya, and Thorsén (2021) (<arXiv:2106.02131>).
  Two dynamic shrinkage estimators are available in this package. One using 
  overlapping samples while the other use nonoverlapping samples.",2021-09-13,Taras Bodnar,https://github.com/Statistics-In-Portfolio-Theory/DOSportfolio,TRUE,https://github.com/statistics-in-portfolio-theory/dosportfolio,3649,2,2021-09-09T08:09:21Z,1824.5
dostats,"A small package containing helper utilities for creating functions
    for computing statistics.",2022-05-10,Andrew Redd,https://github.com/halpo/dostats,TRUE,https://github.com/halpo/dostats,17254,3,2022-05-10T19:07:50Z,5751.333333333333
dotenv,"Load configuration from a '.env' file, that is
    in the current working directory, into environment variables.",2021-04-22,Gábor Csárdi,https://github.com/gaborcsardi/dotenv,TRUE,https://github.com/gaborcsardi/dotenv,53691,55,2022-05-10T07:57:09Z,976.2
dotprofile,"A toolbox to create and manage metadata files and
    configuration profiles: files used to configure the parameters and
    initial settings for some computer programs.",2021-11-23,Jean-Mathieu Potvin,https://github.com/jeanmathieupotvin/dotprofile,TRUE,https://github.com/jeanmathieupotvin/dotprofile,1280,0,2021-11-25T02:38:23Z,NA
dotwhisker,Quick and easy dot-and-whisker plots of regression results.,2021-09-02,Yue Hu,NA,TRUE,https://github.com/fsolt/dotwhisker,130047,53,2021-08-31T02:11:40Z,2453.7169811320755
DoubleML,"Implementation of the double/debiased machine learning framework of
    Chernozhukov et al. (2018) <doi:10.1111/ectj.12097> for partially linear
    regression models, partially linear instrumental variable regression models,
    interactive regression models and interactive instrumental variable
    regression models. 'DoubleML' allows estimation of the nuisance parts in
    these models by machine learning methods and computation of the Neyman
    orthogonal score functions. 'DoubleML' is built on top of 'mlr3' and the
    'mlr3' ecosystem. The object-oriented implementation of 'DoubleML' based on
    the 'R6' package is very flexible. ",2022-06-14,Malte S. Kurz,"https://docs.doubleml.org/stable/index.html,
https://github.com/DoubleML/doubleml-for-r/",TRUE,https://github.com/doubleml/doubleml-for-r,12221,63,2022-06-15T07:54:49Z,193.984126984127
downlit,"Syntax highlighting of R code, specifically designed for the
    needs of 'RMarkdown' packages like 'pkgdown', 'hugodown', and
    'bookdown'. It includes linking of function calls to their
    documentation on the web, and automatic translation of ANSI escapes in
    output to the equivalent HTML.",2022-07-05,Hadley Wickham,"https://downlit.r-lib.org/, https://github.com/r-lib/downlit",TRUE,https://github.com/r-lib/downlit,711835,71,2022-07-05T04:19:59Z,10025.845070422536
downloadthis,Implement download buttons in HTML output from 'rmarkdown' without the need for 'runtime:shiny'.,2022-02-23,Felipe Mattioni Maturana,https://github.com/fmmattioni/downloadthis,TRUE,https://github.com/fmmattioni/downloadthis,26028,123,2022-02-23T08:47:51Z,211.609756097561
dparser,"A Scannerless GLR parser/parser generator.  Note that GLR standing for ""generalized LR"", where L stands for ""left-to-right"" and
   R stands for ""rightmost (derivation)"".  For more information see <https://en.wikipedia.org/wiki/GLR_parser>. This parser is based on the Tomita
   (1987) algorithm. (Paper can be found at <https://aclanthology.org/P84-1073.pdf>).
   The original 'dparser' package documentation can be found at <http://dparser.sourceforge.net/>.  This allows you to add mini-languages to R (like
   RxODE's ODE mini-language Wang, Hallow, and James 2015 <DOI:10.1002/psp4.12052>) or to parse other languages like 'NONMEM' to automatically translate
   them to R code.   To use this in your code, add a LinkingTo dparser in your DESCRIPTION file and instead of using #include <dparse.h> use
   #include <dparser.h>.  This also provides a R-based port of the make_dparser <http://dparser.sourceforge.net/d/make_dparser.cat> command called
   mkdparser().  Additionally you can parse an arbitrary grammar within R using the dparse() function, which works on most OSes and is mainly for grammar
   testing.  The fastest parsing, of course, occurs at the C level, and is suggested.",2022-03-21,Matthew Fidler,"https://nlmixr2.github.io/dparser-R/,
https://github.com/nlmixr2/dparser-R/",TRUE,https://github.com/nlmixr2/dparser-r,41082,1,2022-03-19T00:32:11Z,41082
dplbnDE,"Implements Differential Evolution (DE) to train parameters of Bayesian Networks for optimizing the Conditional Log-Likelihood (Discriminative Learning) instead of the log-likelihood (Generative Learning). Any given Bayesian Network structure encodes assumptions about conditional independencies among the attributes and will result in an error if they do not hold in the data. Such an error includes the classification dimension. The main goal of Discriminative learning is to minimize this type of error. This package provides main variants of differential evolution described in Price & Storn (1996) <doi:10.1109/ICEC.1996.542711> and recent ones, described in Tanabe & Fukunaga (2014) <doi:10.1109/CEC.2014.6900380> and Zhang & Sanderson (2009) <doi:10.1109/TEVC.2009.2014613> with adaptation mechanism for factor mutarion and crossover rate.",2022-01-10,Alejandro Platas-Lopez,NA,TRUE,https://github.com/alexplatasl/dplbnde,1601,0,2022-01-05T17:31:01Z,NA
dplR,"Perform tree-ring analyses such as detrending, chronology
        building, and cross dating.  Read and write standard file formats
        used in dendrochronology.",2022-06-23,Andy Bunn,https://github.com/AndyBunn/dplR,TRUE,https://github.com/andybunn/dplr,101527,24,2022-07-01T16:06:06Z,4230.291666666667
dplyr,"A fast, consistent tool for working with data frame
    like objects, both in memory and out of memory.",2022-04-28,Hadley Wickham,"https://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr",TRUE,https://github.com/tidyverse/dplyr,45642329,4144,2022-07-05T12:39:58Z,11014.07553088803
DQAgui,A graphical user interface (GUI) to the functions implemented in the R package 'DQAstats'.,2022-07-04,Lorenz A. Kapsner,https://github.com/miracum/dqa-dqagui,TRUE,https://github.com/miracum/dqa-dqagui,2269,1,2022-07-04T11:20:17Z,2269
DQAstats,"Perform data quality assessment ('DQA') of electronic health
    records ('EHR'). Publication: Kapsner et al. (2021)
    <doi:10.1055/s-0041-1733847>.",2022-06-27,Lorenz A. Kapsner,https://github.com/miracum/dqa-dqastats,TRUE,https://github.com/miracum/dqa-dqastats,5013,6,2022-06-27T19:50:49Z,835.5
dragon,"Create, visualize, manipulate, and analyze bipartite mineral-chemistry
    networks for set of focal element(s) across deep-time on Earth. The method is 
    described in Spielman and Moore (2020) <doi:10.3389/feart.2020.585087>.",2022-04-08,Stephanie J. Spielman,https://github.com/sjspielman/dragon,TRUE,https://github.com/sjspielman/dragon,17386,2,2022-04-07T17:40:52Z,8693
drake,"A general-purpose computational engine for data
  analysis, drake rebuilds intermediate data objects when their
  dependencies change, and it skips work when the results are already up
  to date.  Not every execution starts from scratch, there is native
  support for parallel and distributed computing, and completed projects
  have tangible evidence that they are reproducible.  Extensive
  documentation, from beginner-friendly tutorials to practical examples
  and more, is available at the reference website
  <https://docs.ropensci.org/drake/> and the online manual
  <https://books.ropensci.org/drake/>.",2021-09-21,William Michael Landau,"https://github.com/ropensci/drake,
https://docs.ropensci.org/drake/,
https://books.ropensci.org/drake/",TRUE,https://github.com/ropensci/drake,79317,1321,2021-09-24T12:46:09Z,60.043149129447386
drat,"Creation and use of R Repositories via helper functions 
 to insert packages into a repository, and to add repository information 
 to the current R session. Two primary types of repositories are support:
 gh-pages at GitHub, as well as local repositories on either the same machine
 or a local network. Drat is a recursive acronym: Drat R Archive Template. ",2022-04-13,Dirk Eddelbuettel with contributions by Carl Boettiger,"https://github.com/eddelbuettel/drat,
https://dirk.eddelbuettel.com/code/drat.html",TRUE,https://github.com/eddelbuettel/drat,268978,138,2022-04-14T12:05:57Z,1949.1159420289855
drawer,"An interactive image editing tool that can be added as part of the HTML in Shiny,
    R markdown or any type of HTML document. Often times, plots, photos are embedded
    in the web application/file. 'drawer' can take screenshots of these image-like elements, or 
    any part of the HTML document and send to an image editing space called 'canvas' to allow users 
    immediately edit the screenshot(s) within the same document. Users can quickly 
    combine, compare different screenshots, upload their own images 
    and maybe make a scientific figure. ",2022-04-11,Le Zhang,https://github.com/lz100/drawer,TRUE,https://github.com/lz100/drawer,5171,11,2022-05-25T00:25:40Z,470.09090909090907
drawsample,"A tool to sample data with the desired properties.Samples can be 
    drawn by purposive sampling with determining distributional 
    conditions, such as deviation from normality (skewness and kurtosis), 
    and sample size in quantitative research studies.
    For purposive sampling, a researcher has something in mind and participants that 
    fit the purpose of the study are included (Etikan,Musa, & Alkassim, 2015) 
    <doi:10.11648/j.ajtas.20160501.11>.Purposive sampling can be useful for answering
    many research questions (Klar & Leeper, 2019) 
    <doi:10.1002/9781119083771.ch21>.",2021-03-01,Kubra Atalay Kabasakal,https://github.com/atalay-k/drawsample,TRUE,https://github.com/atalay-k/drawsample,6958,2,2022-04-27T11:26:19Z,3479
drda,"Fit logistic functions to observed dose-response continuous
    data and evaluate goodness-of-fit measures. See Malyutina A., Tang J.,
    and Pessia A. (2021) <doi:10.1101/2021.06.07.447323>.",2022-07-08,Alberto Pessia,https://github.com/albertopessia/drda,TRUE,https://github.com/albertopessia/drda,4830,5,2022-07-06T11:32:41Z,966
dreamer,"Fits (longitudinal) dose-response models utilizing a Bayesian model
  averaging approach as outlined in Gould (2019) <doi:10.1002/bimj.201700211>
  for both continuous and binary responses.  Functions
  for plotting and calculating various posterior quantities
  (e.g. posterior mean, quantiles, probability of minimum efficacious dose,
  etc.) are also implemented.  Copyright Eli Lilly and Company (2019).",2021-08-20,Richard Payne,https://github.com/rich-payne/dreamer,TRUE,https://github.com/rich-payne/dreamer,3353,1,2022-04-19T19:46:13Z,3353
drf,An implementation of distributional random forests as introduced in Cevid & Michel & Meinshausen & Buhlmann (2020) <arXiv:2005.14458>.,2021-03-29,Loris Michel,https://github.com/lorismichel/drf,TRUE,https://github.com/lorismichel/drf,8341,18,2022-04-25T12:57:54Z,463.3888888888889
drhur,"A fast, interactive tool built upon the 'learnr' function which will open a shiny app for learners to interact with the instructions and tasks. The best way to learn these skills together with the “Learning R with Dr. Hu” online/offline workshops.",2020-10-30,Yue Hu,NA,TRUE,https://github.com/sammo3182/drhur,7203,11,2021-12-12T23:34:11Z,654.8181818181819
DriveML,"Implementing some of the pillars of an automated machine learning pipeline such as (i) Automated data preparation, (ii) Feature engineering, (iii) Model building in classification context that includes techniques such as (a) Regularised regression [1], (b) Logistic regression [2], (c) Random Forest [3], (d) Decision tree [4] and (e) Extreme Gradient Boosting (xgboost) [5], and finally, (iv) Model explanation (using lift chart and partial dependency plots). Accomplishes the above tasks  by running the function instead of writing lengthy R codes. Also provides some additional features such as generating missing at random (MAR) variables and automated exploratory data analysis. Moreover, function exports the model results with the required plots in an HTML vignette report format that follows the best practices of the industry and the academia. [1] Gonzales G B and De Saeger (2018) <doi:10.1038/s41598-018-21851-7>, [2] Sperandei S (2014) <doi:10.11613/BM.2014.003>, [3] Breiman L (2001) <doi:10.1023/A:1010933404324>, [4] Kingsford C and Salzberg S (2008) <doi:10.1038/nbt0908-1011>, [5] Chen Tianqi and Guestrin Carlos (2016) <doi:10.1145/2939672.2939785>.",2021-10-18,Dayanand Ubrangala,NA,TRUE,https://github.com/daya6489/driveml,9877,13,2021-07-19T15:17:01Z,759.7692307692307
driveR,"Cancer genomes contain large numbers of somatic alterations but few
    genes drive tumor development. Identifying cancer driver genes is critical 
    for precision oncology. Most of current approaches either identify driver 
    genes based on mutational recurrence or using estimated scores predicting 
    the functional consequences of mutations. 'driveR' is a tool for 
    personalized or batch analysis of genomic data for driver gene prioritization 
    by combining genomic information and prior biological knowledge. As features, 
    'driveR' uses coding impact metaprediction scores, non-coding impact scores, 
    somatic copy number alteration scores, hotspot gene/double-hit gene 
    condition, 'phenolyzer' gene scores and memberships to cancer-related KEGG 
    pathways. It uses these features to estimate cancer-type-specific 
    probability for each gene of being a cancer driver using the related task of 
    a multi-task learning classification model. The method is described in detail 
    in Ulgen E, Sezerman OU. 2021. driveR: driveR: a novel method for 
    prioritizing cancer driver genes using somatic genomics data. BMC 
    Bioinformatics <doi:10.1186/s12859-021-04203-7>.",2022-01-18,Ege Ulgen,"https://egeulgen.github.io/driveR/,
https://github.com/egeulgen/driveR/",TRUE,https://github.com/egeulgen/driver,5584,11,2022-07-05T11:44:35Z,507.6363636363636
DRomics,"Several functions are provided for dose-response (or concentration-response) characterization from omics data. 'DRomics' is especially dedicated to omics data obtained using a typical dose-response design, favoring a great number of tested doses (or concentrations) rather than a great number of replicates (no need of replicates). 'DRomics' provides functions 1) to check, normalize and or transform data, 2) to select monotonic or biphasic significantly responding items (e.g. probes, metabolites), 3) to choose the best-fit model among a predefined family of monotonic and biphasic models to describe each selected item, 4) to derive a benchmark dose or concentration and a typology of response from each fitted curve. In the available version data are supposed to be single-channel microarray data in log2, RNAseq data in raw counts, or already pretreated continuous omics data (such as metabolomic data) in log scale. In order to link responses across biological levels based on a common method, 'DRomics' also handles apical data as long as they are continuous and follow a normal distribution for each dose or concentration, with a common standard error. For further details see Larras et al (2018) <DOI:10.1021/acs.est.8b04752> at <https://hal.archives-ouvertes.fr/hal-02309919>.",2022-01-06,Aurelie Siberchicot,"https://lbbe.univ-lyon1.fr/fr/dromics,
https://github.com/aursiber/DRomics",TRUE,https://github.com/aursiber/dromics,13957,2,2022-07-06T15:04:36Z,6978.5
DRR,"An Implementation of Dimensionality Reduction
    via Regression using Kernel Ridge Regression.",2020-02-12,Guido Kraemer,https://github.com/gdkrmr/DRR,TRUE,https://github.com/gdkrmr/drr,122461,8,2022-03-04T15:56:49Z,15307.625
drtmle,"Targeted minimum loss-based estimators of counterfactual means and
    causal effects that are doubly-robust with respect both to consistency and
    asymptotic normality (Benkeser et al (2017), <doi:10.1093/biomet/asx053>; MJ
    van der Laan (2014), <doi:10.1515/ijb-2012-0038>).",2022-04-23,David Benkeser,https://github.com/benkeser/drtmle,TRUE,https://github.com/benkeser/drtmle,16536,14,2022-04-20T18:40:16Z,1181.142857142857
drugprepr,"Prepare prescription data (such as from the Clinical Practice Research Datalink) into an analysis-ready format, with start and stop dates for each patient's prescriptions. Based on Pye et al (2018) <doi:10.1002/pds.4440>.",2021-11-09,Belay Birlie Yimer,NA,TRUE,https://github.com/belayb/drugprepr,2348,0,2021-11-10T12:40:26Z,NA
ds4psy,"All datasets and functions required for the examples and exercises of the book ""Data Science for Psychologists"" (by Hansjoerg Neth, Konstanz University, 2022), available at <https://bookdown.org/hneth/ds4psy/>. The book and course introduce principles and methods of data science to students of psychology and other biological or social sciences. The 'ds4psy' package primarily provides datasets, but also functions for data generation and manipulation (e.g., of text and time data) and graphics that are used in the book and its exercises. All functions included in 'ds4psy' are designed to be explicit and instructive, rather than efficient or elegant. ",2022-04-07,Hansjoerg Neth,"https://bookdown.org/hneth/ds4psy/,
https://github.com/hneth/ds4psy/",TRUE,https://github.com/hneth/ds4psy,20052,13,2022-07-07T11:24:19Z,1542.4615384615386
DSAIDE,"Exploration of simulation models (apps) of various infectious disease transmission dynamics scenarios.
    The purpose of the package is to help individuals learn 
    about infectious disease epidemiology (ecology/evolution) from a dynamical systems perspective.
    All apps include explanations of the underlying models and instructions on what to do with the models. ",2021-07-23,Andreas Handel,"https://ahgroup.github.io/DSAIDE/,
https://github.com/ahgroup/DSAIDE/",TRUE,https://github.com/ahgroup/dsaide,20619,20,2022-07-05T18:43:01Z,1030.95
DSAIRM,"Simulation models (apps) of various within-host immune response scenarios.
    The purpose of the package is to help individuals learn 
    about within-host infection and immune response modeling from a dynamical systems perspective.
    All apps include explanations of the underlying models and instructions on what to do with the models. ",2022-07-01,Andreas Handel,"https://ahgroup.github.io/DSAIRM/,
https://github.com/ahgroup/DSAIRM/",TRUE,https://github.com/ahgroup/dsairm,17094,25,2022-07-05T18:54:43Z,683.76
dsb,"This lightweight R package provides a method for normalizing and denoising protein expression data from droplet based single cell experiments. Raw protein Unique Molecular Index (UMI) counts from sequencing DNA-conjugated antibody derived tags (ADT) in droplets (e.g. 'CITE-seq') have substantial measurement noise. Our experiments and computational modeling revealed two major components of this noise: 1) protein-specific noise originating from ambient, unbound antibody encapsulated in droplets that can be accurately inferred via the expected protein counts detected in empty droplets, and 2) droplet/cell-specific noise revealed via the shared variance component associated with isotype antibody controls and background protein counts in each cell. This package normalizes and removes both of these sources of noise from raw protein data derived from methods such as 'CITE-seq', 'REAP-seq', 'ASAP-seq', 'TEA-seq', 'proteogenomic' data from the Mission Bio platform, etc. See the vignette for tutorials on how to integrate dsb with 'Seurat' and 'Bioconductor' and how to use dsb in 'Python'. Please see our paper Mulè M.P., Martins A.J., and Tsang J.S. Nature Communications 2022 <https://www.nature.com/articles/s41467-022-29356-8> for more details on the method.",2022-05-27,Matthew Mulè,https://github.com/niaid/dsb,TRUE,https://github.com/niaid/dsb,7924,35,2022-05-26T19:02:31Z,226.4
dscore,"The D-score is a quantitative measure of child development. 
    The D-score follows the Rasch model. See Jacobusse, van Buuren and 
    Verkerk (2006) <doi:10.1002/sim.2351>. The user can convert 
    milestone scores from 19 assessment instruments into the D-score 
    and the DAZ (D-score adjusted for age). Several tools assist in 
    mapping milestone names into the 9-position Global Scale of Early 
    Development (GSED) convention. Supports calculation of the D-score 
    using 'dutch' <doi:10.1177/0962280212473300>, 
    'gcdg' <doi:10.1136/bmjgh-2019-001724> and 'gsed' conversion keys.
    The user can calculate DAZ using 'dutch' and 'gcdg' age-conditional 
    references.",2020-11-29,Stef van Buuren,"https://github.com/d-score/dscore, https://d-score.org/dscore/,
https://d-score.org/dbook1/",TRUE,https://github.com/d-score/dscore,15685,1,2022-06-02T14:58:10Z,15685
DSI,"'DataSHIELD' is an infrastructure and series of R packages that 
    enables the remote and 'non-disclosive' analysis of sensitive research data. 
    This package defines the API that is to be implemented by 'DataSHIELD' compliant 
    data repositories.",2022-04-06,Yannick Marcon,"https://github.com/datashield/DSI/,
https://datashield.github.io/DSI/, https://datashield.org/",TRUE,https://github.com/datashield/dsi,27559,0,2022-04-06T14:20:55Z,NA
dsims,"Performs distance sampling simulations. 'dsims' repeatedly generates
    instances of a user defined population within a given survey region. It then 
    generates realisations of a survey design and simulates the detection process. 
    The data are then analysed so that the results can be compared for accuracy 
    and precision across all replications. This process allows users to optimise 
    survey designs for their specific set of survey conditions. The effects of 
    uncertainty in population distribution or parameters can be investigated
    under a number of simulations so that users can be confident that they have
    achieved a robust survey design before deploying vessels into the field. The
    distance sampling designs used in this package from 'dssd' are detailed in
    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, ISBN-13: 
    978-0199225873). General distance sampling methods are detailed in Introduction 
    to Distance Sampling: Estimating Abundance of Biological Populations, Buckland 
    et. al. (2004, ISBN-13: 978-0198509271). Find out more about estimating 
    animal/plant abundance with distance sampling at <http://distancesampling.org/>.",2022-06-15,Laura Marshall,https://github.com/DistanceDevelopment/dsims,TRUE,https://github.com/distancedevelopment/dsims,5234,1,2022-07-06T08:33:54Z,5234
dsm,"Density surface modelling of line transect data. A Generalized
    Additive Model-based approach is used to calculate spatially-explicit estimates
    of animal abundance from distance sampling (also presence/absence and strip
    transect) data. Several utility functions are provided for model checking,
    plotting and variance estimation.",2022-03-17,David L. Miller,https://github.com/DistanceDevelopment/dsm,TRUE,https://github.com/distancedevelopment/dsm,18529,7,2022-06-29T12:59:02Z,2647
DSMolgenisArmadillo,"'DataSHIELD' is an infrastructure and series of R packages that 
    enables the remote and 'non-disclosive' analysis of sensitive research data.
    This package is the 'DataSHIELD' interface implementation to analyze data
    shared on a 'MOLGENIS Armadillo' server. 'MOLGENIS Armadillo' is a
    light-weight 'DataSHIELD' server using a file store and an 'RServe' server.",2022-03-25,Mariska Slofstra,"https://github.com/molgenis/molgenis-r-datashield/,
https://molgenis.github.io/molgenis-r-datashield/",TRUE,https://github.com/molgenis/molgenis-r-datashield,8373,0,2022-03-25T13:40:14Z,NA
DSOpal,"'DataSHIELD' is an infrastructure and series of R packages that 
    enables the remote and 'non-disclosive' analysis of sensitive research data.
    This package is the 'DataSHIELD' interface implementation for 'Opal', which is
    the data integration application for biobanks by 'OBiBa'. Participant data, once
    collected from any data source, must be integrated and stored in a central
    data repository under a uniform model. 'Opal' is such a central repository.
    It can import, process, validate, query, analyze, report, and export data.
    'Opal' is the reference implementation of the 'DataSHIELD' infrastructure.",2021-08-23,Yannick Marcon,"https://github.com/datashield/DSOpal/,
https://datashield.github.io/DSOpal/, https://www.obiba.org,
https://www.obiba.org/pages/products/opal/,
https://www.datashield.org,
https://academic.oup.com/ije/article/43/6/1929/707730,
https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008880",TRUE,https://github.com/datashield/dsopal,16738,0,2021-08-23T08:37:28Z,NA
dsos,"Test for no adverse shift in two-sample comparison when we
    have a training set, the reference distribution, and a test set. The
    approach is flexible and relies on a robust and powerful test
    statistic, the weighted AUC. Technical details are in Kamulete, V. M.
    (2021) <arXiv:1908.04000>. Modern notions of outlyingness such as
    trust scores and prediction uncertainty can be used as the underlying
    scores for example.",2022-01-18,Vathy M. Kamulete,https://github.com/vathymut/dsos,TRUE,https://github.com/vathymut/dsos,1620,1,2022-01-17T20:43:47Z,1620
dsrTest,"Perform a test of a simple null hypothesis about a 
    directly standardized rate and obtain the matching confidence 
    interval using a choice of methods.",2022-06-20,Michael Nelson,https://github.com/mnelsonr/dsrTest,TRUE,https://github.com/mnelsonr/dsrtest,17449,0,2022-06-19T06:45:59Z,NA
DSSAT,"The purpose of this package is to provide a comprehensive
    R interface to the Decision Support System for Agrotechnology
    Transfer Cropping Systems Model (DSSAT-CSM; see <https://dssat.net> for more information).
    The package provides cross-platform functions to read and
    write input files, run DSSAT-CSM, and read output files.",2022-01-19,Phillip D. Alderman,NA,TRUE,https://github.com/palderman/dssat,14716,10,2022-01-18T21:01:19Z,1471.6
dssd,"Creates survey designs for distance sampling surveys. These
    designs can be assessed for various effort and coverage statistics.
    Once the user is satisfied with the design characteristics they can 
    generate a set of transects to use in their distance sampling survey.
    Many of the designs implemented in this R package were first made 
    available in our 'Distance' for Windows software and are detailed in 
    Chapter 7 of Advanced Distance Sampling, Buckland et. al. (2008, 
    ISBN-13: 978-0199225873). Find out more about estimating animal/plant 
    abundance with distance sampling at <http://distancesampling.org/>. ",2022-06-14,Laura Marshall,NA,TRUE,https://github.com/distancedevelopment/dssd,16945,1,2022-06-01T17:19:28Z,16945
dst,"Using the Theory of Belief Functions for evidence calculus. Basic probability assignments, or mass functions, can be defined on the subsets of a set of possible values and combined. A mass function can be extended to a larger frame. Marginalization, i.e. reduction to a smaller frame can also be done. These features can be combined to analyze small belief networks and take into account situations where information cannot be satisfactorily described by probability distributions.",2022-01-03,Claude Boivin,NA,TRUE,https://github.com/rapler/dst-1,17239,2,2022-03-05T01:51:03Z,8619.5
DstarM,"A collection of functions to estimate parameters of a diffusion model via a D*M analysis. Build in models are: the Ratcliff diffusion model, the RWiener diffusion model, and Linear Ballistic Accumulator models. Custom models functions can be specified as long as they have a density function.",2020-08-28,Don van den Bergh,https://github.com/vandenman/DstarM,TRUE,https://github.com/vandenman/dstarm,17600,2,2021-10-29T10:16:07Z,8800
DSWE,"Data science methods used in wind energy applications. 
              Current functionalities include creating a multi-dimensional power curve model, 
              performing power curve function comparison, covariate matching, and energy decomposition. 
              Relevant works for the developed functions are: 
              funGP() - Prakash et al. (2022) <doi:10.1080/00401706.2021.1905073>, 
              AMK() - Lee et al. (2015) <doi:10.1080/01621459.2014.977385>, 
              tempGP() - Prakash et al. (2022) <doi:10.1080/00401706.2022.2069158>, 
              ComparePCurve() - Ding et al. (2021) <doi:10.1016/j.renene.2021.02.136>,
              deltaEnergy() - Latiffianti et al. (2022) <doi:10.1002/we.2722>,
              syncSize() - Latiffianti et al. (2022) <doi:10.1002/we.2722>,
              imptPower() - Latiffianti et al. (2022) <doi:10.1002/we.2722>,
              All other functions - Ding (2019, ISBN:9780429956508).",2022-07-07,Yu Ding,"https://github.com/TAMU-AML/DSWE-Package,
https://aml.engr.tamu.edu/book-dswe/",TRUE,https://github.com/tamu-aml/dswe-package,5849,9,2022-07-07T22:43:26Z,649.8888888888889
DT,"Data objects in R can be rendered as HTML tables using the
    JavaScript library 'DataTables' (typically via R Markdown or Shiny). The
    'DataTables' library has been included in this R package. The package name
    'DT' is an abbreviation of 'DataTables'.",2022-05-10,Yihui Xie,https://github.com/rstudio/DT,TRUE,https://github.com/rstudio/dt,8624413,522,2022-06-30T21:27:03Z,16521.863984674328
dtplyr,"Provides a data.table backend for 'dplyr'. The goal of
    'dtplyr' is to allow you to write 'dplyr' code that is automatically
    translated to the equivalent, but usually much faster, data.table
    code.",2022-01-19,Hadley Wickham,"https://dtplyr.tidyverse.org, https://github.com/tidyverse/dtplyr",TRUE,https://github.com/tidyverse/dtplyr,7513369,579,2022-06-25T15:36:59Z,12976.45768566494
DTSg,"Basic time series functionalities such as listing of missing
    values, application of arbitrary aggregation as well as rolling (asymmetric)
    window functions and automatic detection of periodicity. As it is mainly
    based on 'data.table', it is fast and - in combination with the 'R6'
    package - offers reference semantics. In addition to its native R6
    interface, it provides an S3 interface for those who prefer the latter.
    Finally yet importantly, its functional approach allows for incorporating
    functionalities from many other packages.",2022-06-08,Gerold Hepp,https://gisler.github.io/DTSg/,TRUE,https://github.com/gisler/dtsg,21080,3,2022-06-19T10:15:53Z,7026.666666666667
dttr2,"Manipulates date ('Date'), date time ('POSIXct') and time
    ('hms') vectors.  Date/times are considered discrete and are floored
    whenever encountered.  Times are wrapped and time zones are maintained
    unless explicitly altered by the user.",2021-09-19,Joe Thorley,https://github.com/poissonconsulting/dttr2,TRUE,https://github.com/poissonconsulting/dttr2,22692,9,2022-06-17T21:55:22Z,2521.3333333333335
dtts,High-frequency time-series support via 'nanotime' and 'data.table'.,2022-03-09,Dirk Eddelbuettel and Leonardo Silvestri,NA,TRUE,https://github.com/eddelbuettel/dtts,1244,10,2022-03-12T19:40:22Z,124.4
dtwclust,"Time series clustering along with optimized techniques related
    to the Dynamic Time Warping distance and its corresponding lower bounds.
    Implementations of partitional, hierarchical, fuzzy, k-Shape and TADPole
    clustering are available. Functionality can be easily extended with
    custom distance measures and centroid definitions. Implementations of
    DTW barycenter averaging, a distance based on global alignment kernels,
    and the soft-DTW distance and centroid routines are also provided. 
    All included distance functions have custom loops optimized for the 
    calculation of cross-distance matrices, including parallelization support.
    Several cluster validity indices are included.",2022-04-15,Alexis Sarda-Espinosa,https://github.com/asardaes/dtwclust,TRUE,https://github.com/asardaes/dtwclust,128607,216,2022-05-24T16:32:53Z,595.4027777777778
dtwSat,"Provides an implementation of the Time-Weighted Dynamic Time
    Warping (TWDTW) method for land cover mapping using satellite image time series.
    TWDTW compares unclassified satellite image time series with a set of known
    temporal patterns (e.g. phenological cycles associated with the vegetation).
    Using 'dtwSat' the user can build temporal patterns for land cover types, apply
    the TWDTW analysis for satellite datasets, visualize the results of the time
    series analysis, produce land cover maps, create temporal plots for land cover
    change, and compute accuracy assessment metrics.",2021-09-19,Victor Maus,https://github.com/vwmaus/dtwSat/,TRUE,https://github.com/vwmaus/dtwsat,20407,109,2022-04-07T11:50:22Z,187.22018348623854
duckdb,"The DuckDB project is an embedded analytical data
    management system with support for the Structured Query Language (SQL). This package includes all of
    DuckDB and a R Database Interface (DBI) connector.",2022-06-21,Hannes Mühleisen,"https://duckdb.org/, https://github.com/duckdb/duckdb",TRUE,https://github.com/duckdb/duckdb,126635,5460,2022-07-10T11:38:50Z,23.19322344322344
DVHmetrics,"Functionality for analyzing dose-volume histograms (DVH)
        in radiation oncology: Read DVH text files, calculate DVH
        metrics as well as generalized equivalent uniform dose (gEUD),
        biologically effective dose (BED), equivalent dose in 2 Gy
        fractions (EQD2), normal tissue complication probability
        (NTCP), and tumor control probability (TCP). Show DVH
        diagrams, check and visualize quality assurance constraints
        for the DVH. Includes web-based graphical user interface.",2022-03-23,Daniel Wollschlaeger,https://github.com/dwoll/DVHmetrics/,TRUE,https://github.com/dwoll/dvhmetrics,19596,7,2022-03-28T08:12:12Z,2799.4285714285716
dvir,"Joint DNA-based disaster victim identification (DVI), as described in 
    Vigeland and Egeland (2021) <doi:10.21203/rs.3.rs-296414/v1>. Identification is 
    performed by optimising the joint likelihood of all victim samples and 
    reference individuals. Individual identification probabilities, conditional on
    all available information, are derived from the joint solution in the form of 
    posterior pairing probabilities. 'dvir' is part of the 'ped suite' collection
    of packages for pedigree analysis. In particular it uses 'forrel' for 
    calculation of likelihood ratios.",2021-05-18,Thore Egeland,https://github.com/thoree/dvir,TRUE,https://github.com/thoree/dvir,5128,1,2022-06-08T13:38:26Z,5128
DWLS,"The rapid development of single-cell transcriptomic technologies 
    has helped uncover the cellular heterogeneity within cell populations. 
    However, bulk RNA-seq continues to be the main workhorse for quantifying 
    gene expression levels due to technical simplicity and low cost. To most 
    effectively extract information from bulk data given the new knowledge 
    gained from single-cell methods, we have developed a novel algorithm to 
    estimate the cell-type composition of bulk data from a single-cell 
    RNA-seq-derived cell-type signature. Comparison with existing methods using 
    various real RNA-seq data sets indicates that our new approach is more 
    accurate and comprehensive than previous methods, especially for the 
    estimation of rare cell types. More importantly,our method can detect 
    cell-type composition changes in response to external perturbations, 
    thereby providing a valuable, cost-effective method for dissecting the 
    cell-type-specific effects of drug treatments or condition changes. 
    As such, our method is applicable to a wide range of biological and 
    clinical investigations. Dampened weighted least squares ('DWLS') is an 
    estimation method for gene expression deconvolution, in which the cell-type 
    composition of a bulk RNA-seq data set is computationally inferred. 
    This method corrects common biases towards cell types that are 
    characterized by highly expressed genes and/or are highly prevalent, to 
    provide accurate detection across diverse cell types. See: 
    <https://www.nature.com/articles/s41467-019-10802-z.pdf> for more 
    information about the development of 'DWLS' and the methods behind our 
    functions. ",2022-05-24,Adriana Sistig,https://github.com/sistia01/DWLS,TRUE,https://github.com/sistia01/dwls,386,1,2022-05-19T13:36:10Z,386
dycdtools,"Tools for DYRESM-CAEDYM model development, including assisting with calibrating selected model parameters and visualising model output through time series plot, profile plot, contour plot, and scatter plot.",2022-05-25,Songyan Yu,https://github.com/SongyanYu/dycdtools,TRUE,https://github.com/songyanyu/dycdtools,9239,0,2022-05-25T07:12:33Z,NA
dyn.log,"A comprehensive and dynamic configuration driven logging package for R. While there 
    are several excellent logging solutions already in the R ecosystem, I always feel constrained 
    in some way by each of them. Every project is designed differently to solve it's domain specific problem, 
    and ultimately the utility of a logging solution is its ability to adapt to this design. This is the 
    raison d'être for 'dyn.log': to provide a modular design, template mechanics and a configuration-based 
    integration model, so that the logger can integrate deeply into your design, even though it knows 
    nothing about it.",2022-03-14,Brandon Moretz,https://bmoretz.github.io/dyn.log/,TRUE,https://github.com/bmoretz/dyn.log,1022,0,2022-03-26T18:02:22Z,NA
dynamAedes,Generalised model for population dynamics of invasive Aedes mosquitoes. Rationale and model structure are described here: <doi:10.1016/j.ecoinf.2020.101180> and <doi:10.1101/2021.12.21.473628> .,2022-01-17,Matteo Marcantonio,NA,TRUE,https://github.com/mattmar/dynamaedes,1589,0,2022-06-27T14:51:34Z,NA
dynamic,"Returns dynamic fit index (DFI) cutoffs for latent variable models 
    that are tailored to the user's model statement, model type, and sample size.  
    This is the counterpart of the Shiny Application, <https://dynamicfit.app>.",2022-02-28,Melissa G. Wolf,https://github.com/melissagwolf/dynamic,TRUE,https://github.com/melissagwolf/dynamic,1332,8,2022-02-25T00:36:33Z,166.5
dynamichazard,"Contains functions that lets you fit dynamic hazard models using 
  state space models. The first implemented model is described in Fahrmeir 
  (1992) <doi:10.1080/01621459.1992.10475232> and Fahrmeir (1994) 
  <doi:10.1093/biomet/81.2.317>. Extensions hereof are available where the  
  Extended Kalman filter is replaced by an unscented Kalman filter. 
  See Christoffersen (2021) <doi:10.18637/jss.v099.i07> for more details. 
  Particle filters and smoothers are also supported more general state space 
  models.",2021-10-11,Benjamin Christoffersen,https://github.com/boennecd/dynamichazard,TRUE,https://github.com/boennecd/dynamichazard,22984,7,2021-10-11T16:03:43Z,3283.4285714285716
DynareR,"It allows running 'Dynare' program from base R and R Markdown. 'Dynare' is a software platform for handling a wide class of economic models, in particular dynamic stochastic general equilibrium ('DSGE') and overlapping generations ('OLG') models.  This package does not only integrate R and Dynare but also serves as a 'Dynare' Knit-Engine for 'knitr' package. The package requires 'Dynare' (<https://www.dynare.org/>) and 'Octave' (<https://www.gnu.org/software/octave/download.html>).  Write all your 'Dynare' commands in R or R Markdown chunk.",2022-04-30,Sagiru Mati,https://CRAN.R-project.org/package=DynareR,TRUE,https://github.com/sagirumati/dynarer,9905,3,2022-07-09T04:59:07Z,3301.6666666666665
dynaSpec,A set of tools to generate dynamic spectrogram visualizations in video format.,2021-03-10,Marcelo Araya-Salas,https://github.com/maRce10/dynaSpec,TRUE,https://github.com/marce10/dynaspec,8770,8,2022-07-01T18:23:56Z,1096.25
dynatop,An R implementation and enhancement of the Dynamic TOPMODEL semi-distributed hydrological model originally proposed by Beven and Freer (2001) <doi:10.1002/hyp.252>. The 'dynatop' package implements code for simulating models which can be created using the 'dynatopGIS' package.,2022-04-13,Paul Smith,"https://waternumbers.github.io/dynatop/,
https://github.com/waternumbers/dynatop",TRUE,https://github.com/waternumbers/dynatop,1742,1,2022-06-14T15:30:20Z,1742
dynatopGIS,"A set of algorithms based on Quinn et al. (1991) <doi:10.1002/hyp.3360050106> for processing river network and digital elevation data to build implementations of Dynamic TOPMODEL, a semi-distributed hydrological model proposed in Beven and Freer (2001) <doi:10.1002/hyp.252>. The 'dynatop' package implements simulation code for Dynamic TOPMODEL based on the output of 'dynatopGIS'.",2022-04-13,Paul Smith,"https://waternumbers.github.io/dynatopGIS/,
https://github.com/waternumbers/dynatopGIS",TRUE,https://github.com/waternumbers/dynatopgis,1752,1,2022-04-14T10:04:35Z,1752
dynConfiR,"
       Provides density functions for the joint distribution of choice, 
       response time and confidence for discrete confidence judgments
       as well as functions for parameter fitting, prediction and simulation 
       for various dynamical models of decision confidence. 
       All models are explained in detail by Hellmann et al. 
       (preprint; <https://osf.io/9jfqr/>).
       Implemented models are the dynWEV model, the 2DSD model (Pleskac & Busemeyer, 2010, 
       <doi:10.1037/a0019737>), and various race models. 
       C++ code for dynWEV and 2DSD is based on the 'rtdists' package by 
       Henrik Singmann. ",2022-05-27,Sebastian Hellmann,https://github.com/SeHellmann/dynConfiR,TRUE,https://github.com/sehellmann/dynconfir,317,0,2022-06-27T14:52:55Z,NA
dyngen,"A novel, multi-modal simulation engine for
    studying dynamic cellular processes at single-cell resolution. 'dyngen'
    is more flexible than current single-cell simulation engines. It
    allows better method development and benchmarking, thereby stimulating
    development and testing of novel computational methods. Cannoodt et
    al. (2021) <doi:10.1038/s41467-021-24152-2>.",2021-09-20,Robrecht Cannoodt,"https://dyngen.dynverse.org, https://github.com/dynverse/dyngen",TRUE,https://github.com/dynverse/dyngen,9050,48,2021-11-30T20:52:48Z,188.54166666666666
dynplot,"Visualise a single-cell trajectory as a graph or dendrogram, 
  as a dimensionality reduction or heatmap of the expression data, 
  or a comparison between two trajectories as a pairwise scatterplot
  or dimensionality reduction projection. Saelens and Cannoodt et
  al. (2019) <doi:10.1038/s41587-019-0071-9>.",2021-12-07,Robrecht Cannoodt,https://github.com/dynverse/dynplot,TRUE,https://github.com/dynverse/dynplot,6419,15,2021-12-07T19:08:33Z,427.93333333333334
dynr,"Intensive longitudinal data have become increasingly prevalent in
    various scientific disciplines. Many such data sets are noisy, multivariate,
    and multi-subject in nature. The change functions may also be continuous, or
    continuous but interspersed with periods of discontinuities (i.e., showing
    regime switches). The package 'dynr' (Dynamic Modeling in R) is an R package
    that implements a set of computationally efficient algorithms for handling a
    broad class of linear and nonlinear discrete- and continuous-time models with
    regime-switching properties under the constraint of linear Gaussian measurement
    functions. The discrete-time models can generally take on the form of a state-
    space or difference equation model. The continuous-time models are generally
    expressed as a set of ordinary or stochastic differential equations. All
    estimation and computations are performed in C, but users are provided with the
    option to specify the model of interest via a set of simple and easy-to-learn
    model specification functions in R. Model fitting can be performed using single-
    subject time series data or multiple-subject longitudinal data. Ou, Hunter, &
    Chow (2019) <doi:10.32614/RJ-2019-012> provided a detailed introduction to the
    interface and more information on the algorithms.",2021-11-18,Michael D. Hunter,"https://dynrr.github.io/, https://github.com/mhunter1/dynr",TRUE,https://github.com/mhunter1/dynr,28981,2,2022-05-10T18:28:09Z,14490.5
dynsurv,"Time-varying coefficient models for interval censored and
    right censored survival data including
    1) Bayesian Cox model with time-independent, time-varying or
    dynamic coefficients for right censored and interval censored data studied by
    Sinha et al. (1999) <doi:10.1111/j.0006-341X.1999.00585.x> and
    Wang et al. (2013) <doi:10.1007/s10985-013-9246-8>,
    2) Spline based time-varying coefficient Cox model for right censored data
    proposed by Perperoglou et al. (2006) <doi:10.1016/j.cmpb.2005.11.006>, and
    3) Transformation model with time-varying coefficients for right censored data
    using estimating equations proposed by
    Peng and Huang (2007) <doi:10.1093/biomet/asm058>.",2022-03-03,Wenjie Wang,https://github.com/wenjie2wang/dynsurv,TRUE,https://github.com/wenjie2wang/dynsurv,57476,6,2022-04-06T03:57:45Z,9579.333333333334
eaf,"Computation and visualization of the empirical attainment function (EAF) for the analysis of random sets in multi-criterion optimization. M. López-Ibáñez, L. Paquete, and T. Stützle (2010) <doi:10.1007/978-3-642-02538-9_9>.",2021-12-21,Manuel López-Ibáñez,"https://mlopez-ibanez.github.io/eaf/,
https://github.com/MLopez-Ibanez/eaf",TRUE,https://github.com/mlopez-ibanez/eaf,66681,11,2022-06-30T15:47:29Z,6061.909090909091
earthtide,"This is a port of 'Fortran ETERNA 3.4' 
             <http://igets.u-strasbg.fr/soft_and_tool.php> by H.G. Wenzel
             for calculating synthetic Earth tides using the 
             Hartmann and Wenzel (1994) <doi:10.1029/95GL03324> or 
             Kudryavtsev (2004) <doi:10.1007/s00190-003-0361-2> tidal catalogs. ",2022-06-30,Jonathan Kennel,https://github.com/jkennel/earthtide,TRUE,https://github.com/jkennel/earthtide,15867,15,2022-06-30T01:47:31Z,1057.8
easyalluvial,"Alluvial plots are similar to sankey diagrams and visualise categorical data 
    over multiple dimensions as flows. (Rosvall M, Bergstrom CT (2010) Mapping Change in 
    Large Networks. PLoS ONE 5(1): e8694. <doi:10.1371/journal.pone.0008694> 
    Their graphical grammar however is a bit more complex then that of a regular x/y 
    plots. The 'ggalluvial' package made a great job of translating that grammar into 
    'ggplot2' syntax and gives you many options to tweak the appearance of an alluvial 
    plot, however there still remains a multi-layered complexity that makes it difficult
    to use 'ggalluvial' for explorative data analysis. 'easyalluvial' provides a simple 
    interface to this package that allows you to produce a decent alluvial plot from any 
    dataframe in either long or wide format from a single line of code while also handling 
    continuous data. It is meant to allow a quick visualisation of entire dataframes 
    with a focus on different colouring options that can make alluvial plots a great 
    tool for data exploration. ",2022-07-05,Bjoern Koneswarakantha,https://github.com/erblast/easyalluvial/,TRUE,https://github.com/erblast/easyalluvial,27243,97,2022-07-09T07:06:21Z,280.8556701030928
easycensus,"Extracting desired data using the proper Census variable names can 
    be time-consuming. This package takes the pain out of that process by 
    providing functions to quickly locate variables and download labeled tables 
    from the Census APIs (<https://www.census.gov/data/developers/data-sets.html>).",2022-02-28,Cory McCartan,https://corymccartan.github.io/easycensus/,TRUE,https://github.com/corymccartan/easycensus,1194,6,2022-03-01T04:26:04Z,199
easyCODA,"Univariate and multivariate methods for compositional data 
    analysis, based on logratios. The package implements the approach in the
    book Compositional Data Analysis in Practice by Michael Greenacre (2018),
    where accent is given to simple pairwise logratios. Selection can be made
    of logratios that account for a maximum percentage of logratio variance.
    Various multivariate analyses of logratios are included in the package. ",2020-09-19,Michael Greenacre,https://github.com/michaelgreenacre/CODAinPractice/,TRUE,https://github.com/michaelgreenacre/codainpractice,16681,18,2022-01-18T09:19:17Z,926.7222222222222
easyDifferentialGeneCoexpression,"A function that reads in the GEO code of a list of probesets or gene symbols, a gene expression dataset GEO accession code, the name of the dataset feature discriminating the two conditions for the differential coexpression, and the values of the two different conditions for the differential coexpression, and returns the significant pairs of genes/probesets with highest differential coexpression (p-value < 0.005). If the input gene list is made of gene symbols, this package associates the probesets to these gene symbols, if found.  Platforms available: GPL80, GPL8300, GPL80, GPL96, GPL570, GPL571, GPL20115, GPL1293,  GPL6102, GPL6104, GPL6883, GPL6884, GPL13497, GPL14550, GPL17077, GPL6480. GEO: Gene Expression Omnibus. ID: identifier code. The GEO datasets are downloaded from the URL <https://ftp.ncbi.nlm.nih.gov/geo/series/>. ",2022-02-16,Davide Chicco,https://github.com/davidechicco/easyDifferentialGeneCoexpression,TRUE,https://github.com/davidechicco/easydifferentialgenecoexpression,1393,0,2022-02-17T14:43:20Z,NA
easyr,"Makes difficult operations easy. Includes these types of functions: 
    shorthand, type conversion, data wrangling, and work flow. 
    Also includes some helpful data objects: NA strings, U.S. state list, color blind charting colors. 
    Built and shared by Oliver Wyman Actuarial Consulting. Accepting proposed contributions through GitHub.",2022-06-25,Bryce Chamberlain,https://github.com/oliver-wyman-actuarial/easyr,TRUE,https://github.com/oliver-wyman-actuarial/easyr,18575,16,2022-06-25T14:22:02Z,1160.9375
easySdcTable,"The main function, ProtectTable(), performs table suppression according to a 
 frequency rule with a data set as the only required input. Within this function, 
 protectTable(), protect_linked_tables() or runArgusBatchFile() in package 'sdcTable' is called. 
 Lists of level-hierarchy (parameter 'dimList') and other required input to these functions 
 are created automatically. 
 The suppression method Gauss (default) is an additional method that is not available in 'sdcTable'.
 The function, PTgui(), starts a graphical user interface based on the 'shiny' package.",2022-03-22,Øyvind Langsrud,https://github.com/statisticsnorway/easySdcTable,TRUE,https://github.com/statisticsnorway/easysdctable,21380,0,2022-03-22T13:03:50Z,NA
eat,"Functions are provided to determine production frontiers and technical 
    efficiency measures through non-parametric techniques based upon regression trees. 
    The package includes code for estimating radial input, output, directional and 
    additive measures, plotting graphical representations of the scores and the production 
    frontiers by means of trees, and determining rankings of importance of input variables 
    in the analysis. Additionally, an adaptation of Random Forest by a set of individual 
    Efficiency Analysis Trees for estimating technical efficiency is also included. More 
    details in: <doi:10.1016/j.eswa.2020.113783>.",2022-01-16,Miriam Esteve,https://efficiencytools.wordpress.com/,TRUE,https://github.com/miriamesteve/eat,10116,2,2022-01-16T12:04:03Z,5058
eatATA,"Provides simple functions to create constraints for small test assembly problems 
    (e.g. van der Linden (2005, ISBN: 978-0-387-29054-6)) using sparse matrices. Currently, 
    'GLPK', 'lpSolve', 'Symphony', and 'Gurobi' are supported as solvers. The 'gurobi' package is not available from 
    any mainstream repository; see <https://www.gurobi.com/downloads/>.",2021-07-06,Benjamin Becker,https://github.com/beckerbenj/eatATA,TRUE,https://github.com/beckerbenj/eatata,9961,1,2022-06-28T15:31:54Z,9961
eatGADS,"Import 'SPSS' data, handle and change 'SPSS' meta data, store and access large hierarchical data in 'SQLite' data bases.",2022-06-24,Benjamin Becker,https://github.com/beckerbenj/eatGADS,TRUE,https://github.com/beckerbenj/eatgads,8920,0,2022-06-28T17:16:23Z,NA
eatRep,"Replication methods to compute some basic statistic operations (means, standard deviations,
  frequency tables, percentiles and generalized linear models) in complex survey designs comprising multiple
  imputed variables and/or a clustered sampling structure which both deserve special procedures at least in
  estimating standard errors. See the package documentation for a more detailed description along with references.",2022-07-08,Sebastian Weirich,https://github.com/weirichs/eatRep,TRUE,https://github.com/weirichs/eatrep,8143,1,2022-07-05T20:20:37Z,8143
eatTools,"
   Miscellaneous functions for data cleaning and data analysis of educational assessments. Includes functions for descriptive 
   analyses, character vector manipulations and weighted statistics. Mainly a lightweight dependency for the packages 'eatRep', 
   'eatGADS', 'eatPrep' and 'eatModel' (which will be subsequently submitted to 'CRAN').
   The function for defining (weighted) contrasts in weighted effect coding refers to
   te Grotenhuis et al. (2017) <doi:10.1007/s00038-016-0901-1>.
   Functions for weighted statistics refer to
   Wolter (2007) <doi:10.1007/978-0-387-35099-8>.",2022-06-28,Sebastian Weirich,https://github.com/weirichs/eatTools,TRUE,https://github.com/weirichs/eattools,11592,1,2022-06-29T19:15:32Z,11592
EBCHS,We provide the main R functions to compute the posterior interval for the noncentrality parameter of the chi-squared distribution. The skewness estimate of the posterior distribution is also available to improve the coverage rate of posterior intervals. Details can be found in Du and Hu (2020) <doi:10.1080/01621459.2020.1777137>.  ,2021-06-01,Lilun Du,https://github.com/dulilun/EBCHS,TRUE,https://github.com/dulilun/ebchs,4441,0,2022-04-16T09:24:38Z,NA
ebci,"Computes empirical Bayes confidence estimators and confidence
    intervals in a normal means model. The intervals are robust in the sense
    that they achieve correct coverage regardless of the distribution of the
    means. If the means are treated as fixed, the intervals have an average
    coverage guarantee. The implementation is based on Armstrong, Kolesár and
    Plagborg-Møller (2020) <arXiv:2004.03448>.",2021-09-06,Michal Kolesár,https://github.com/kolesarm/ebci,TRUE,https://github.com/kolesarm/ebci,2283,6,2021-09-06T14:02:42Z,380.5
ebdbNet,"Infer the adjacency matrix of a
	network from time course data using an empirical Bayes
	estimation procedure based on Dynamic Bayesian Networks.",2021-10-15,Andrea Rau,https://github.com/andreamrau/ebdbNet,TRUE,https://github.com/andreamrau/ebdbnet,18821,3,2021-10-15T13:10:30Z,6273.666666666667
ebirdst,"Tools to download, load, plot, and analyze eBird Status and
    Trends Data Products
    (<https://science.ebird.org/en/status-and-trends>). eBird
    (<https://ebird.org/home>) is a global database of bird observations
    collected by member of the public. eBird Status and Trends uses these
    data to model global bird abundances, range boundaries, and habitat
    associations at a high spatial and temporal resolution.",2022-07-08,Matthew Strimas-Mackey,https://github.com/CornellLabofOrnithology/ebirdst,TRUE,https://github.com/cornelllabofornithology/ebirdst,19246,49,2022-07-08T12:23:22Z,392.7755102040816
ebnm,"Provides simple, fast, and stable functions to fit the normal
    means model using empirical Bayes. For available models and details, see 
    function ebnm(). A comprehensive introduction to the package is provided
    by Willwerscheid and Stephens (2021) <arXiv:2110.00152>.",2022-03-08,Carbonetto Peter,https://github.com/stephenslab/ebnm,TRUE,https://github.com/stephenslab/ebnm,1129,8,2022-03-25T04:18:35Z,141.125
ec50estimator,"An implementation for estimating Effective control to 50% of growth
    inhibition (EC50) for multi isolates and stratified datasets. It implements 
    functions from the drc package in a way that is displayed a tidy data.frame 
    as output. Info about the drc package is available in Ritz C, Baty F, Streibig JC,
    Gerhard D (2015) <doi:10.1371/journal.pone.0146021>.",2020-09-15,Kaique dos S. Alves,https://github.com/AlvesKS/ec50estimator,TRUE,https://github.com/alvesks/ec50estimator,7914,0,2022-03-03T18:43:04Z,NA
eCAR,"Fits Leroux model in spectral domain to estimate causal spatial effect as detailed in 
             Guan, Y; Page, G.L.; Reich, B.J.; Ventrucci, M.; Yang, S; (2020) <arXiv:2012.11767>.  
             Both the parametric and semi-parametric models are available.  The semi-parametric model 
             relies on 'INLA'.  The 'INLA' package can be obtained from <https://www.r-inla.org/>.",2021-05-15,Garritt L. Page,https://github.com/gpage2990/eCAR,TRUE,https://github.com/gpage2990/ecar,5648,1,2022-04-17T00:28:38Z,5648
echarts4r,"Easily create interactive charts by leveraging the 'Echarts Javascript' library which includes
    36 chart types, themes, 'Shiny' proxies and animations.",2022-05-28,John Coene,"https://echarts4r.john-coene.com/,
https://github.com/JohnCoene/echarts4r",TRUE,https://github.com/johncoene/echarts4r,109017,488,2022-06-26T15:05:08Z,223.3954918032787
echarty,Deliver the full functionality of 'ECharts' with minimal overhead. 'echarty' users build R lists for 'ECharts' API. Lean set of powerful commands.,2022-04-01,Larry Helgason,https://github.com/helgasoft/echarty,TRUE,https://github.com/helgasoft/echarty,8991,37,2022-07-06T19:48:05Z,243
echogram,"Easily import multi-frequency acoustic data stored in 'HAC' files (see <http://biblio.uqar.ca/archives/30005500.pdf> for more information on the format), and produce echogram visualisations with predefined or customized color palettes. It is also possible to merge consecutive echograms; mask or delete unwanted echogram areas; model and subtract background noise; and more important, develop, test and interpret different combinations of frequencies in order to perform acoustic filtering of the echogram's data. ",2019-12-16,Héctor Villalobos,https://github.com/hvillalo/echogram,TRUE,https://github.com/hvillalo/echogram,14865,2,2022-05-26T18:21:56Z,7432.5
echor,"An R interface to United States Environmental 
    Protection Agency (EPA) Environmental Compliance 
    History Online ('ECHO') Application Program Interface
    (API). 'ECHO' provides information about EPA permitted 
    facilities, discharges, and other reporting info 
    associated with permitted entities. Data are obtained 
    from <https://echo.epa.gov/>. ",2021-08-21,Michael Schramm,NA,TRUE,https://github.com/mps9506/echor,17272,3,2022-05-13T20:57:12Z,5757.333333333333
ecmwfr,"Programmatic interface to the European Centre for Medium-Range
    Weather Forecasts dataset web services (ECMWF; <https://www.ecmwf.int/>)
    and Copernicus's Climate Data Store (CDS; 
    <https://cds.climate.copernicus.eu>). Allows for easy downloads of weather 
    forecasts and climate reanalysis data in R.",2020-07-13,Koen Hufkens,https://github.com/bluegreen-labs/ecmwfr,TRUE,https://github.com/bluegreen-labs/ecmwfr,22965,71,2022-05-25T19:15:54Z,323.4507042253521
ecocomDP,"Work with the Ecological Community Data Design Pattern. 'ecocomDP' 
    is a flexible data model for harmonizing ecological community surveys, in a 
    research question agnostic format, from source data published across 
    repositories, and with methods that keep the derived data up-to-date as the 
    underlying sources change. Described in O'Brien et al. (2021), 
    <doi:10.1016/j.ecoinf.2021.101374>.",2022-03-07,Colin Smith,https://github.com/EDIorg/ecocomDP,TRUE,https://github.com/ediorg/ecocomdp,5461,26,2022-03-07T05:33:52Z,210.03846153846155
EcoDiet,"Biotracers and stomach content analyses are combined in a Bayesian hierarchical model
    to estimate a probabilistic topology matrix (all trophic link probabilities) and a diet matrix 
    (all diet proportions).
    The package relies on the JAGS software and the 'rjags' package to run a Markov chain Monte Carlo 
    approximation of the different variables.",2020-03-05,Pierre-Yves Hernvann,https://github.com/pyhernvann/EcoDiet,TRUE,https://github.com/pyhernvann/ecodiet,9422,3,2022-04-26T07:30:47Z,3140.6666666666665
ecodist,"Dissimilarity-based analysis functions including ordination and Mantel test functions, intended for use with spatial and community data. The original package description is in Goslee and Urban (2007) <doi:10.18637/jss.v022.i07>, with further statistical detail in Goslee (2010) <doi:10.1007/s11258-009-9641-0>.",2022-05-05,Sarah Goslee,NA,TRUE,https://github.com/phiala/ecodist,134425,4,2022-05-04T19:46:50Z,33606.25
ecospat,"Collection of R functions and data sets for the support of spatial ecology analyses with a focus on pre, core and post modelling analyses of species distribution, niche quantification and community assembly. Written by current and former members and collaborators of the ecospat group of Antoine Guisan, Department of Ecology and Evolution (DEE) and Institute of Earth Surface Dynamics (IDYST), University of Lausanne, Switzerland. Read Di Cola et al. (2016) <doi:10.1111/ecog.02671> for details.",2022-06-03,Olivier Broennimann,http://www.unil.ch/ecospat/home/menuguid/ecospat-resources/tools.html,TRUE,https://github.com/ecospat/ecospat,40352,23,2022-06-07T13:04:31Z,1754.4347826086957
ECOTOXr,"The US EPA ECOTOX database is a freely available database
    with a treasure of aquatic and terrestrial ecotoxicological data.
    As the online search interface doesn't come with an API, this
    package provides the means to easily access and search the database
    in R. To this end, all raw tables are downloaded from the EPA website
    and stored in a local SQLite database.",2021-10-05,Pepijn de Vries,<https://github.com/pepijn-devries/ECOTOXr>,TRUE,https://github.com/pepijn-devries/ecotoxr,7339,2,2021-10-04T11:43:04Z,3669.5
edeaR,"Exploratory and descriptive analysis of event based data. Provides methods for describing and selecting process data, and for preparing event log data for process mining. Builds on the S3-class for event logs implemented in the package 'bupaR'.",2020-10-01,Gert Janssenswillen,"https://www.bupar.net, https://github.com/bupaverse/edeaR",TRUE,https://github.com/bupaverse/edear,107993,10,2022-06-28T10:37:06Z,10799.3
EDFtest,"This repository contains software for the calculation of goodness-of-fit test statistics and their P-values. The three statistics computed are the Empirical Distribution function statistics called Cramer-von Mises, Anderson-Darling, and Watson statistics. The statistics and their P-values can be used to assess an assumed distribution.The following distributions are available: Uniform, Normal, Gamma, Logistic, Laplace, Weibull, Extreme Value, and Exponential.",2021-10-25,Li Yao,NA,TRUE,https://github.com/liyao-sfu/edftest,2830,0,2021-12-11T17:12:57Z,NA
edgebundle,"Implements several algorithms for bundling edges in networks and flow and metro map layouts. This includes force directed edge bundling <doi:10.1111/j.1467-8659.2009.01450.x>, a flow algorithm based on Steiner trees<doi:10.1080/15230406.2018.1437359> and a multicriteria optimization method for metro map layouts <doi:10.1109/TVCG.2010.24>.",2022-07-05,David Schoch,"http://edgebundle.schochastics.net/,
https://github.com/schochastics/edgebundle",TRUE,https://github.com/schochastics/edgebundle,14109,96,2022-07-04T05:50:49Z,146.96875
edibble,"A system to facilitate designing comparative experiments using the 
  grammar of experimental designs <https://emitanaka.org/edibble-book/>. 
  An experimental design is treated as an intermediate, mutable object that is 
  built progressively by fundamental experimental components like units, treatments, and their relation.",2022-06-22,Emi Tanaka,"https://edibble.emitanaka.org/,
https://github.com/emitanaka/edibble",TRUE,https://github.com/emitanaka/edibble,910,163,2022-07-06T00:19:07Z,5.58282208588957
editData,"An 'RStudio' addin for editing a 'data.frame' or a 'tibble'. You can delete, add or update a 'data.frame'
    without coding. You can get resultant data as a 'data.frame'. In the package, modularized 'shiny' app codes are provided. 
    These modules are intended for reuse across applications.",2021-04-02,Keon-Woong Moon,https://github.com/cardiomoon/editData,TRUE,https://github.com/cardiomoon/editdata,62680,26,2021-07-13T12:11:52Z,2410.769230769231
EDIutils,"A client for the Environmental Data Initiative repository REST API. The 'EDI' data repository <https://portal.edirepository.org/nis/home.jsp> is for publication and reuse of ecological data with emphasis on metadata accuracy and completeness. It is built upon the 'PASTA+' software stack <https://pastaplus-core.readthedocs.io/en/latest/index.html#> and was developed in collaboration with the US 'LTER' Network <https://lternet.edu/>. 'EDIutils' includes functions to search and access existing data, evaluate and upload new data, and assist other data management tasks common to repository users.",2022-06-29,Colin Smith,"https://github.com/ropensci/EDIutils,
https://docs.ropensci.org/EDIutils/",TRUE,https://github.com/ropensci/ediutils,468,8,2022-06-28T21:51:44Z,58.5
edlibR,"Bindings to edlib, a lightweight performant C/C++ library for exact pairwise sequence alignment using edit distance (Levenshtein distance). The algorithm computes the optimal alignment path, but also can be used to find only the start and/or end of the alignment path for convenience. Edlib was designed to be ultrafast and require little memory, with the capability to handle very large sequences. Three alignment methods are supported: global (Needleman-Wunsch), infix (Hybrid Wunsch), and prefix (Semi-Hybrid Wunsch). The original C/C++ library is described in ""Edlib: a C/C++ library for fast, exact sequence alignment using edit distance"", M. Šošić, M. Šikić, <doi:10.1093/bioinformatics/btw753>.",2022-01-12,Evan Biederstedt,https://github.com/evanbiederstedt/edlibR,TRUE,https://github.com/evanbiederstedt/edlibr,1657,5,2022-01-25T22:09:24Z,331.4
edmcr,"Implements various general algorithms to estimate missing elements
   of a Euclidean (squared) distance matrix.  
   Includes optimization methods based on semi-definite programming found in
   Alfakih, Khadani, and Wolkowicz (1999)<doi:10.1023/A:1008655427845>, 
   a non-convex position formulation by Fang and O'Leary (2012)<doi:10.1080/10556788.2011.643888>, and 
   a dissimilarity parameterization formulation by Trosset (2000)<doi:10.1023/A:1008722907820>.
   When the only non-missing
   distances are those on the minimal spanning tree, the guided random search
   algorithm will complete the matrix while preserving the minimal spanning tree following
   Rahman and Oldford (2018)<doi:10.1137/16M1092350>.
   Point configurations in specified dimensions can be determined from the completions. 
   Special problems such as the sensor localization problem, 
   as for example in Krislock and Wolkowicz (2010)<doi:10.1137/090759392>,
   as well as reconstructing
   the geometry of a molecular structure, as for example in 
   Hendrickson (1995)<doi:10.1137/0805040>, can also be solved.
   These and other methods are described in the thesis of Adam Rahman(2018)<https://hdl.handle.net/10012/13365>.",2021-09-10,R. Wayne Oldford,https://github.com/great-northern-diver/edmcr,TRUE,https://github.com/great-northern-diver/edmcr,3732,2,2021-09-08T18:18:08Z,1866
edmdata,"Collection of data sets from various assessments that can be used to 
    evaluate psychometric models. These data sets have been analyzed in the
    following papers that introduced new methodology as part of the application section:
    Yinghan Chen et al. (2021) <doi:10.1007/s11336-021-09750-9>,
    Yinyin Chen et al. (2020) <doi:10.1007/s11336-019-09693-2>,
    Culpepper, S. A. (2019a) <doi:10.1007/s11336-019-09683-4>,
    Culpepper, S. A. (2019b) <doi:10.1007/s11336-018-9643-8>,
    Culpepper, S. A., & Chen, Y. (2019) <doi:10.3102/1076998618791306>,
    Culpepper, S. A., & Balamuta, J. J. (2017) <doi:10.1007/s11336-015-9484-7>,
    and Culpepper, S. A. (2015) <doi:10.3102/1076998615595403>.",2021-07-25,James Joseph Balamuta,"https://tmsalab.github.io/edmdata/,
https://github.com/tmsalab/edmdata/",TRUE,https://github.com/tmsalab/edmdata,14117,4,2021-11-08T22:52:18Z,3529.25
EdSurvey,"Read in and analyze functions for education survey and assessment data from the National Center for Education Statistics (NCES) <https://nces.ed.gov/>, including National Assessment of Educational Progress (NAEP) data <https://nces.ed.gov/nationsreportcard/> and data from the International Assessment Database: Organisation for Economic Co-operation and Development (OECD) <https://www.oecd.org/>, including Programme for International Student Assessment (PISA), Teaching and Learning International Survey (TALIS), Programme for the International Assessment of Adult Competencies (PIAAC), and International Association for the Evaluation of Educational Achievement (IEA) <https://www.iea.nl/>, including Trends in International Mathematics and Science Study (TIMSS), TIMSS Advanced, Progress in International Reading Literacy Study (PIRLS), International Civic and Citizenship Study (ICCS), International Computer and Information Literacy Study (ICILS), and Civic Education Study (CivEd).",2021-10-05,Paul Bailey,https://www.air.org/project/nces-data-r-project-edsurvey,TRUE,https://github.com/american-institutes-for-research/edsurvey,25612,2,2022-07-06T21:01:23Z,12806
educationdata,"Allows R users to retrieve and parse data from the Urban 
    Institute's Education Data API <https://ed-data-portal.urban.org/> into a 
    'data.frame' for analysis.",2021-05-31,Kyle Ueyama,https://urbaninstitute.github.io/education-data-package-r/,TRUE,https://github.com/urbaninstitute/education-data-package-r,5288,63,2022-06-29T00:11:40Z,83.93650793650794
edwards97,"Implements the Edwards (1997) <doi:10.1002/j.1551-8833.1997.tb08229.x>
    Langmuir-based semi-empirical coagulation model, which predicts the concentration
    of organic carbon remaining in water after treatment with an Al- or Fe-based
    coagulant. Data and methods are provided to optimise empirical coefficients.",2020-03-23,Dewey Dunnington,"https://paleolimbot.github.io/edwards97/,
https://github.com/paleolimbot/edwards97",TRUE,https://github.com/paleolimbot/edwards97,9133,0,2022-03-30T11:51:32Z,NA
eefAnalytics,"Analysing data from evaluations of educational interventions using a randomised controlled trial design. Various analytical tools to perform sensitivity analysis using different methods are supported (e.g. frequentist models with bootstrapping and permutations options, Bayesian models). The included commands can be used for simple randomised trials, cluster randomised trials and multisite trials. The methods can also be used more widely beyond education trials. This package can be used to evaluate other intervention designs using Frequentist and Bayesian multilevel models.",2022-07-02,Germaine Uwimpuhwe,https://github.com/dimitris-90/eefanalytics,TRUE,https://github.com/dimitris-90/eefanalytics,10618,0,2022-07-01T10:02:12Z,NA
eemR,"Provides various tools for preprocessing Emission-Excitation-Matrix (EEM) for Parallel Factor Analysis (PARAFAC). Different
  methods are also provided to calculate common metrics such as humification index and fluorescence index.",2019-06-26,Philippe Massicotte,https://github.com/PMassicotte/eemR,TRUE,https://github.com/pmassicotte/eemr,19376,15,2021-10-19T10:53:57Z,1291.7333333333333
EFAtools,"Provides functions to perform exploratory factor analysis (EFA) procedures and compare their solutions. The goal is to provide state-of-the-art factor retention methods and a high degree of flexibility in the EFA procedures. This way, for example, implementations from R 'psych' and 'SPSS' can be compared. Moreover, functions for Schmid-Leiman transformation and the computation of omegas are provided. To speed up the analyses, some of the iterative procedures, like principal axis factoring (PAF), are implemented in C++.",2022-04-24,Markus Steiner,https://github.com/mdsteiner/EFAtools,TRUE,https://github.com/mdsteiner/efatools,17877,4,2022-04-24T11:24:56Z,4469.25
efdm,"An implementation of European Forestry Dynamics Model (EFDM) and
    an estimation algorithm for the transition probabilities.
    The EFDM is a large-scale forest model that simulates the development of
    the forest and estimates volume of wood harvested for any given forested
    area. This estimate can be broken down by, for example, species, site
    quality, management regime and ownership category.
    See Packalen et al. (2015) <doi:10.2788/153990>.",2022-01-10,Mikko Kuronen,https://github.com/mikkoku/efdm,TRUE,https://github.com/mikkoku/efdm,3422,0,2021-12-22T19:09:02Z,NA
eff2,"Estimate a total causal effect from observational data under 
    linearity and causal sufficiency. The observational data is supposed to 
    be generated from a linear structural equation model (SEM) with independent 
    and additive noise. The underlying causal DAG associated the SEM is required
    to be known up to a maximally oriented partially directed graph (MPDAG), 
    which is a general class of graphs consisting of both directed and 
    undirected edges, including CPDAGs (i.e., essential graphs) and DAGs. Such
    graphs are usually obtained with structure learning algorithms with added 
    background knowledge. The program is able to estimate every identified 
    effect, including single and multiple treatment variables. Moreover, the 
    resulting estimate has the minimal asymptotic covariance (and hence 
    shortest confidence intervals) among all estimators that are based on the 
    sample covariance. ",2021-09-30,Richard Guo,https://github.com/richardkwo/eff2,TRUE,https://github.com/richardkwo/eff2,4873,0,2021-09-30T20:29:26Z,NA
EffectLiteR,"Use structural equation modeling to estimate average and
    conditional effects of a treatment variable on an outcome variable, taking into
    account multiple continuous and categorical covariates.",2022-03-26,Axel Mayer,https://github.com/amayer2010/EffectLiteR,TRUE,https://github.com/amayer2010/effectliter,20286,5,2021-11-22T23:16:12Z,4057.2
effectsize,"Provide utilities to work with indices of effect size and
    standardized parameters for a wide variety of models (see list of
    supported models using the function 'insight::supported_models()'),
    allowing computation of and conversion between indices such as Cohen's
    d, r, odds, etc.",2022-05-26,"Mattan S. Ben-Shachar 
    (<https://orcid.org/0000-0002-4287-4801>",https://easystats.github.io/effectsize/,TRUE,https://github.com/easystats/effectsize,958915,270,2022-07-07T12:02:39Z,3551.537037037037
effsize,"A collection of functions to compute the standardized 
  effect sizes for experiments (Cohen d, Hedges g, Cliff delta, Vargha-Delaney A). 
  The computation algorithms have been optimized to allow efficient computation even 
  with very large data sets.",2020-10-05,Marco Torchiano,https://github.com/mtorchiano/effsize/,TRUE,https://github.com/mtorchiano/effsize,183972,100,2021-10-13T16:44:13Z,1839.72
eflm,"Efficient Fitting of Linear and Generalized Linear Models by using
  just base R. As an alternative to lm() and glm(), this package provides elm()
  and eglm(), with a significant speedup when the number of 
  observations is larger than the number of parameters to estimate. The speed
 gains are obtained by reducing the NxP model matrix to a PxP matrix, and the 
 best computational performance is obtained when R is linked against 'OpenBLAS',
 'Intel MKL' or other optimized 'BLAS' library. This implementation aims at being
 compatible with 'broom' and 'sandwich' packages for summary statistics and
 clustering by providing S3 methods.",2021-05-31,Mauricio Vargas,https://github.com/pachadotdev/eflm/,TRUE,https://github.com/pachadotdev/eflm,5327,14,2021-12-31T08:08:00Z,380.5
egor,"Tools for importing, analyzing and visualizing ego-centered
    network data. Supports several data formats, including the export formats of
    'EgoNet', 'EgoWeb 2.0' and 'openeddi'. An interactive (shiny) app for the
    intuitive visualization of ego-centered networks is provided. Also included
    are procedures for creating and visualizing Clustered Graphs 
    (Lerner 2008 <DOI:10.1109/PACIFICVIS.2008.4475458>).",2022-05-14,Till Krenz,"https://github.com/tilltnet/egor, https://egor.tillt.net/",TRUE,https://github.com/tilltnet/egor,22151,17,2022-05-13T19:08:32Z,1303
EGRETci,"Collection of functions to evaluate uncertainty of results from
    water quality analysis using the Weighted Regressions on Time Discharge and
    Season (WRTDS) method. This package is an add-on to the EGRET package that
    performs the WRTDS analysis. The WRTDS modeling
    method was initially introduced and discussed in Hirsch et al. (2010) <doi:10.1111/j.1752-1688.2010.00482.x>,
    and expanded in Hirsch and De Cicco (2015) <doi:10.3133/tm4A10>. The 
    paper describing the uncertainty and confidence interval calculations 
    is Hirsch et al. (2015) <doi:10.1016/j.envsoft.2015.07.017>.",2021-04-13,Laura DeCicco,https://github.com/USGS-R/EGRETci,TRUE,https://github.com/usgs-r/egretci,16735,6,2022-01-25T17:32:33Z,2789.1666666666665
eha,"Parametric proportional hazards fitting with left truncation and
        right censoring for common families of distributions, piecewise constant 
        hazards, and discrete models. Parametric accelerated failure time models
        for left truncated and right censored data. Proportional hazards
        models for tabular and register data. Sampling of risk sets in Cox 
        regression, selections in the Lexis diagram, bootstrapping. 
        Broström (2012) <doi:10.1201/9781315373942>.",2022-04-17,Göran Broström,http://ehar.se/r/eha/,TRUE,https://github.com/goranbrostrom/eha,140291,3,2022-04-23T17:01:27Z,46763.666666666664
EIAdata,"An R wrapper to allow the user to query categories and Series IDs, and import data, from the EIA's API <https://www.eia.gov/opendata/>.",2022-02-13,Matthew Brigida and others,https://github.com/Matt-Brigida/EIAdata,TRUE,https://github.com/matt-brigida/eiadata,20787,16,2022-02-22T16:02:11Z,1299.1875
EigenR,"Matrix algebra using the 'Eigen' C++ library: determinant, rank, inverse, pseudo-inverse, kernel and image, QR decomposition, Cholesky decomposition, linear least-squares problems. Also provides matrix functions such as exponential, logarithm, power, sine and cosine. Complex matrices are supported.",2022-05-18,Stéphane Laurent,https://github.com/stla/EigenR,TRUE,https://github.com/stla/eigenr,8294,2,2022-05-17T08:29:36Z,4147
einet,"Methods and utilities for causal emergence.
    Used to explore and compute various information theory metrics for networks, such as effective information, effectiveness and causal emergence.",2020-04-23,Travis Byrum,https://github.com/travisbyrum/einet,TRUE,https://github.com/travisbyrum/einet,8081,3,2022-01-04T19:01:07Z,2693.6666666666665
eirm,"Analysis of dichotomous and polytomous response data using the explanatory item response modeling framework, as described in Bulut, Gorgun, & Yildirim-Erbasli (2021) <doi:10.3390/psych3030023>, Stanke & Bulut (2019) <doi:10.21449/ijate.515085>, and De Boeck & Wilson (2004) <doi:10.1007/978-1-4757-3990-9>. Generalized linear mixed modeling is used for estimating the effects of item-related and person-related variables on dichotomous and polytomous item responses. ",2021-10-25,Okan Bulut,https://github.com/okanbulut/eirm,TRUE,https://github.com/okanbulut/eirm,8402,4,2022-01-22T16:49:00Z,2100.5
elbird,"This is the R wrapper package Kiwi(Korean Intelligent Word Identifier), 
             a blazing fast speed morphological analyzer for Korean. 
             It supports configuration of user dictionary and detection of 
             unregistered nouns based on frequency.",2022-04-19,Chanyub Park,https://github.com/mrchypark/elbird/,TRUE,https://github.com/mrchypark/elbird,1358,27,2022-06-18T06:38:01Z,50.2962962962963
ELCIC,"We developed a consistent and robust information criterion to conduct model selection for semiparametric models. It is free of distribution specification and powerful to locate the true model given large sample size. This package provides several usage of ELCIC with applications in generalized linear model (GLM), generalized estimating equation (GEE) for longitudinal data, and weighted GEE (WGEE) for missing longitudinal data under the mechanism of missing at random and drop-out. Chixaing Chen, Ming Wang, Rongling Wu, Runze Li (2020) <doi:10.5705/ss.202020.0254>.  ",2022-02-14,Chixiang Chen,https://github.com/chencxxy28/ELCIC,TRUE,https://github.com/chencxxy28/elcic,1211,0,2022-02-13T19:48:59Z,NA
electionsBR,"Offers a set of functions to easily download and clean 
    Brazilian electoral data from the Superior Electoral Court website. 
    Among others, the package retrieves data on local and
    federal elections for all positions (city councilor, mayor, state deputy,
    federal deputy, governor, and president) aggregated by
    state, city, and electoral zones. ",2021-01-30,Denisson Silva,http://electionsbr.com/,TRUE,https://github.com/silvadenisson/electionsbr,19376,59,2022-05-26T18:43:02Z,328.40677966101697
elementR,"Aims to facilitate the reduction of elemental microchemistry data from solid-phase LAICPMS analysis (laser ablation inductive coupled plasma mass spectrometry). The 'elementR' package provides a reactive and user friendly interface (based on a 'shiny' application) and a set of 'R6' classes for conducting all steps needed for an optimal data reduction while leaving maximum control for user. For more details about the methods used in 'elementR', see Sirot et al (2017) <DOI:10.1111/2041-210X.12822>.",2020-09-02,Charlotte Sirot,https://github.com/charlottesirot/elementR,TRUE,https://github.com/charlottesirot/elementr,17600,7,2022-02-07T10:27:03Z,2514.285714285714
elevatr,"Several web services are available that provide access to elevation
             data. This package provides access to several of those services and 
             returns elevation data either as a SpatialPointsDataFrame from 
             point elevation services or as a raster object from raster 
             elevation services.  Currently, the package supports access to the
             Amazon Web Services Terrain Tiles <https://registry.opendata.aws/terrain-tiles/>, 
             the Open Topography Global Datasets API <https://opentopography.org/developers/>, 
             and the USGS Elevation Point Query Service <https://nationalmap.gov/epqs/>.",2022-01-07,Jeffrey Hollister,https://github.com/jhollist/elevatr/,TRUE,https://github.com/jhollist/elevatr,44268,135,2022-04-25T13:15:47Z,327.9111111111111
ElliptCopulas,"Provides functions for the simulation and
  the nonparametric estimation of elliptical distributions,
  meta-elliptical copulas and trans-elliptical distributions,
  following the article Derumigny and Fermanian (2022) <doi:10.1016/j.jmva.2022.104962>.",2022-04-25,Alexis Derumigny,https://github.com/AlexisDerumigny/ElliptCopulas,TRUE,https://github.com/alexisderumigny/elliptcopulas,1829,0,2022-04-25T14:12:25Z,NA
elliptic,"
 A suite of elliptic and related functions including Weierstrass and
 Jacobi forms.  Also includes various tools for manipulating and
 visualizing complex functions.",2019-03-14,Robin K. S. Hankin,https://github.com/RobinHankin/elliptic.git,TRUE,https://github.com/robinhankin/elliptic,606390,2,2022-06-17T01:22:47Z,303195
elmNNRcpp,"Training and predict functions for Single Hidden-layer Feedforward Neural Networks (SLFN) using the Extreme Learning Machine (ELM) algorithm. The ELM algorithm differs from the traditional gradient-based algorithms for very short training times (it doesn't need any iterative tuning, this makes learning time very fast) and there is no need to set any other parameters like learning rate, momentum, epochs, etc. This is a reimplementation of the 'elmNN' package using 'RcppArmadillo' after the 'elmNN' package was archived. For more information, see ""Extreme learning machine: Theory and applications"" by Guang-Bin Huang, Qin-Yu Zhu, Chee-Kheong Siew (2006), Elsevier B.V, <doi:10.1016/j.neucom.2005.12.126>.",2022-01-28,Lampros Mouselimis,https://github.com/mlampros/elmNNRcpp,TRUE,https://github.com/mlampros/elmnnrcpp,28326,12,2022-01-28T08:14:37Z,2360.5
elo,"A flexible framework for calculating Elo ratings and resulting
    rankings of any two-team-per-matchup system (chess, sports leagues, 'Go',
    etc.). This implementation is capable of evaluating a variety of matchups,
    Elo rating updates, and win probabilities, all based on the basic Elo
    rating system. It also includes methods to benchmark performance,
    including logistic regression and Markov chain models.",2022-02-04,Ethan Heinzen,"https://github.com/eheinzen/elo,
https://cran.r-project.org/package=elo,
https://eheinzen.github.io/elo/",TRUE,https://github.com/eheinzen/elo,21883,28,2022-02-03T15:51:00Z,781.5357142857143
EloOptimized,"Provides an implementation of the maximum likelihood methods for deriving
    Elo scores as published in Foerster, Franz et al. (2016) <DOI:10.1038/srep35404>.",2021-06-10,Joseph Feldblum,https://github.com/jtfeld/EloOptimized,TRUE,https://github.com/jtfeld/elooptimized,13809,0,2021-12-20T15:14:07Z,NA
emayili,"A light, simple tool for sending emails with minimal dependencies.",2022-04-28,Andrew B. Collier,https://datawookie.github.io/emayili/,TRUE,https://github.com/datawookie/emayili,79590,146,2022-06-12T06:10:03Z,545.1369863013699
embed,"Predictors can be converted to one or more numeric
    representations using a variety of methods. Effect encodings using
    simple generalized linear models <arXiv:1611.09477> or nonlinear
    models <arXiv:1604.06737> can be used.  There are also functions for
    dimension reduction and other approaches.",2022-07-02,Emil Hvitfeldt,"https://embed.tidymodels.org, https://github.com/tidymodels/embed",TRUE,https://github.com/tidymodels/embed,37656,129,2022-07-02T17:44:46Z,291.90697674418607
EmbedSOM,"Provides a smooth mapping of multidimensional points into
    low-dimensional space defined by a self-organizing map. Designed to work
    with 'FlowSOM' and flow-cytometry use-cases. See Kratochvil et al. (2019)
    <doi:10.12688/f1000research.21642.1>.",2022-07-05,Mirek Kratochvil,https://github.com/exaexa/EmbedSOM,TRUE,https://github.com/exaexa/embedsom,16633,21,2022-07-05T10:02:51Z,792.047619047619
EMCluster,"EM algorithms and several efficient
        initialization methods for model-based clustering of finite
        mixture Gaussian distribution with unstructured dispersion
        in both of unsupervised and semi-supervised learning.",2021-03-16,Wei-Chen Chen,https://github.com/snoweye/EMCluster,TRUE,https://github.com/snoweye/emcluster,29638,16,2022-02-10T01:57:03Z,1852.375
emdi,"Functions that support estimating, assessing and mapping regional
    disaggregated indicators. So far, estimation methods comprise direct estimation,
    the model-based unit-level approach Empirical Best Prediction (see ""Small area
    estimation of poverty indicators"" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), 
    the area-level model (see ""Estimates of income for small places: An 
    application of James-Stein procedures to Census Data"" by Fay and Herriot (1979) 
    <doi:10.1080/01621459.1979.10482505>) and various extensions of it (adjusted variance 
    estimation methods, log and arcsin transformation, spatial, robust and measurement 
    error models), as well as their precision estimates. The assessment of the used model
    is supported by a summary and diagnostic plots. For a suitable presentation of
    estimates, map plots can be easily created. Furthermore, results can easily be
    exported to excel. For a detailed description of the package and the methods used
    see ""The R Package emdi for Estimating and Mapping Regionally Disaggregated Indicators"" 
    by Kreutzmann et al. (2019) <doi:10.18637/jss.v091.i07> and the second package vignette 
    ""A Framework for Producing Small Area Estimates Based on Area-Level Models in R"".",2022-01-04,Soeren Pannier,https://github.com/SoerenPannier/emdi,TRUE,https://github.com/soerenpannier/emdi,23893,9,2022-01-04T13:15:29Z,2654.777777777778
EmissV,"Processing tools to create emissions for use in numerical air 
  quality models. Emissions can be calculated both using emission factors 
  and activity data (Schuch et al 2018) <doi:10.21105/joss.00662> or using 
  pollutant inventories (Schuch et al., 2018) <doi:10.30564/jasr.v1i1.347>. 
  Functions to process individual point emissions, line emissions and 
  area emissions of pollutants are available as well as methods to 
  incorporate alternative data for Spatial distribution of emissions 
  such as satellite images (Martins et al, 2012) <doi:10.3389/fenvs.2015.00009> 
  or openstreetmap data (Andrade et al, 2015) <doi:10.3389/fenvs.2015.00009>.",2022-06-01,Daniel Schuch,https://atmoschem.github.io/EmissV/,TRUE,https://github.com/atmoschem/emissv,22064,24,2022-05-31T21:10:54Z,919.3333333333334
EML,"Work with Ecological Metadata Language ('EML') files. 
    'EML' is a widely used metadata standard in the ecological and
    environmental sciences, described in Jones et al. (2006),
    <doi:10.1146/annurev.ecolsys.37.091305.110031>.",2022-04-28,Carl Boettiger,"https://docs.ropensci.org/EML/, https://github.com/ropensci/EML/",TRUE,https://github.com/ropensci/eml,195611,85,2022-06-06T22:10:05Z,2301.3058823529414
emmeans,"Obtain estimated marginal means (EMMs) for many linear, generalized 
  linear, and mixed models. Compute contrasts or linear functions of EMMs,
  trends, and comparisons of slopes. Plots and other displays.
  Least-squares means are discussed, and the term ""estimated marginal means""
  is suggested, in Searle, Speed, and Milliken (1980) Population marginal means 
  in the linear model: An alternative to least squares means, The American 
  Statistician 34(4), 216-221 <doi:10.1080/00031305.1980.10483031>.",2022-06-22,Russell V. Lenth,https://github.com/rvlenth/emmeans,TRUE,https://github.com/rvlenth/emmeans,1881630,248,2022-06-24T01:39:38Z,7587.217741935484
emoji,"Contains data about emojis with relevant metadata, and functions
    to work with emojis when they are in strings.",2021-09-18,Emil Hvitfeldt,"https://emilhvitfeldt.github.io/emoji/,
https://github.com/EmilHvitfeldt/emoji",TRUE,https://github.com/emilhvitfeldt/emoji,7440,20,2022-02-12T18:16:09Z,372
EmpiricalCalibration,"Routines for performing empirical calibration of observational
  study estimates. By using a set of negative control hypotheses we can
  estimate the empirical null distribution of a particular observational
  study setup. This empirical null distribution can be used to compute a
  calibrated p-value, which reflects the probability of observing an
  estimated effect size when the null hypothesis is true taking both random
  and systematic error into account. A similar approach can be used to
  calibrate confidence intervals, using both negative and positive controls. 
  For more details, see Schuemie et al. (2013) <doi:10.1002/sim.5925> and
  Schuemie et al. (2018) <doi:10.1073/pnas.1708282114>.",2022-07-01,Martijn Schuemie,"https://ohdsi.github.io/EmpiricalCalibration/,
https://github.com/OHDSI/EmpiricalCalibration",TRUE,https://github.com/ohdsi/empiricalcalibration,24700,9,2022-07-01T09:42:38Z,2744.4444444444443
EMSC,"Background correction of spectral like data. Handles variations in
  scaling, polynomial baselines, interferents, constituents and replicate variation.
  Parameters for corrections are stored for further analysis, and spectra are corrected
  accordingly.",2021-09-20,Kristian Hovde Liland,https://github.com/khliland/EMSC/,TRUE,https://github.com/khliland/emsc,18320,0,2021-09-20T20:57:12Z,NA
EMSS,"Some EM-type algorithms to estimate parameters for the well-known Heckman selection model are provided in the package. Such algorithms are as follow: ECM(Expectation/Conditional Maximization), ECM(NR)(the Newton-Raphson method is adapted to the ECM) and ECME(Expectation/Conditional Maximization Either). Since the algorithms are based on the EM algorithm, they also have EM’s main advantages, namely, stability and ease of implementation. Further details and explanations of the algorithms can be found in Zhao et al. (2020) <doi: 10.1016/j.csda.2020.106930>.",2022-01-10,Kexuan Yang,https://github.com/SangkyuStat/EMSS,TRUE,https://github.com/sangkyustat/emss,10641,0,2021-12-21T09:07:48Z,NA
emstreeR,"Fast and easily computes an Euclidean Minimum Spanning Tree (EMST) from data,
    relying on the R API for 'mlpack' - the C++ Machine Learning Library (Curtin et. al., 2013).
    'emstreeR' uses the Dual-Tree Boruvka (March, Ram, Gray, 2010, <doi:10.1145/1835804.1835882>), 
    which is theoretically and empirically the fastest algorithm for computing an EMST. This package also provides 
    functions and an S3 method for readily plotting Minimum Spanning Trees (MST) using either the 
    style of the 'base', 'scatterplot3d', or 'ggplot2' libraries.",2022-03-21,Allan Quadros,NA,TRUE,https://github.com/allanvc/emstreer,16592,5,2022-03-18T05:53:23Z,3318.4
emulator,"
 Allows one to estimate the output of a computer program,
 as a function of the input parameters, without actually running it.
 The computer program is assumed to be a Gaussian process, whose
 parameters are estimated using Bayesian techniques that give a PDF of
 expected program output.  This PDF is conditional on a training set
 of runs, each consisting of a point in parameter space and the model
 output at that point.  The emphasis is on complex codes that take
 weeks or months to run, and that have a large number of undetermined
 input parameters; many climate prediction models fall into this
 class.  The emulator essentially determines Bayesian posterior
 estimates of the PDF of the output of a model, conditioned on results
 from previous runs and a user-specified prior linear model.  The
 package includes functionality to evaluate quadratic forms 
 efficiently. ",2021-04-25,Robin K. S. Hankin,https://github.com/RobinHankin/emulator,TRUE,https://github.com/robinhankin/emulator,48961,1,2021-09-22T08:21:37Z,48961
emuR,"An R package that provides the EMU Speech 
    Database Management System (EMU-SDMS) with database management, data 
    extraction, data preparation and data visualization facilities. See
    <https://ips-lmu.github.io/The-EMU-SDMS-Manual/> for more details.",2021-06-11,Raphael Winkelmann,"https://github.com/IPS-LMU/emuR,
https://ips-lmu.github.io/The-EMU-SDMS-Manual/",TRUE,https://github.com/ips-lmu/emur,26353,22,2022-06-17T14:17:22Z,1197.8636363636363
enc,"
    Implements an S3 class for storing 'UTF-8' strings, based on regular character vectors.
    Also contains routines to portably read and write 'UTF-8' encoded text files,
    to convert all strings in an object to 'UTF-8',
    and to create character vectors with various encodings.",2019-12-19,Kirill Müller,https://github.com/krlmlr/enc,TRUE,https://github.com/krlmlr/enc,31419,12,2022-05-14T00:30:56Z,2618.25
encryptedRmd,"Create encrypted html files that are fully self contained and do
  not require any additional software. Using the package you can encrypt
  arbitrary html files and also directly create encrypted 'rmarkdown' html reports.",2020-12-09,Dirk Schumacher,https://github.com/dirkschumacher/encryptedRmd,TRUE,https://github.com/dirkschumacher/encryptedrmd,9422,157,2022-01-27T15:56:45Z,60.01273885350319
endorse,"Fit the hierarchical and non-hierarchical Bayesian measurement models proposed by Bullock, Imai, and Shapiro (2011) <DOI:10.1093/pan/mpr031> to analyze endorsement experiments.  Endorsement experiments are a survey methodology for eliciting truthful responses to sensitive questions.  This methodology is helpful when measuring support for socially sensitive political actors such as militant groups.  The model is fitted with a Markov chain Monte Carlo algorithm and produces the output containing draws from the posterior distribution. ",2022-05-02,Yuki Shiraito,https://github.com/SensitiveQuestions/endorse/,TRUE,https://github.com/sensitivequestions/endorse,18077,2,2022-05-02T06:51:10Z,9038.5
energy,"E-statistics (energy) tests and statistics for multivariate and univariate inference,
             including distance correlation, one-sample, two-sample, and multi-sample tests for
             comparing multivariate distributions, are implemented. Measuring and testing
             multivariate independence based on distance correlation, partial distance correlation,
             multivariate goodness-of-fit tests, k-groups and hierarchical clustering based on energy 
             distance, testing for multivariate normality, distance components (disco) for non-parametric 
             analysis of structured data, and other energy statistics/methods are implemented.",2022-04-19,Maria Rizzo,https://github.com/mariarizzo/energy,TRUE,https://github.com/mariarizzo/energy,285302,31,2022-04-18T15:11:27Z,9203.290322580646
enpls,"An algorithmic framework for measuring feature importance,
    outlier detection, model applicability domain evaluation,
    and ensemble predictive modeling with (sparse)
    partial least squares regressions.",2019-05-18,Nan Xiao,"https://nanx.me/enpls/, https://github.com/nanxstats/enpls",TRUE,https://github.com/nanxstats/enpls,18894,16,2021-12-21T03:56:28Z,1180.875
entropart,"Measurement and partitioning of diversity, based on Tsallis entropy, following Marcon and Herault (2015) <doi:10.18637/jss.v067.i08>.
  'entropart' provides functions to calculate alpha, beta and gamma diversity of communities, including phylogenetic and functional diversity.
  Estimation-bias corrections are available.",2022-04-02,Eric Marcon,https://github.com/EricMarcon/entropart,TRUE,https://github.com/ericmarcon/entropart,32583,4,2022-07-10T13:41:00Z,8145.75
envi,"Estimates an ecological niche using occurrence data, covariates, and kernel
        density-based estimation methods. For a single species with presence and absence data,
        the 'envi' package uses the spatial relative risk function that is estimated using the
        'sparr' package. Details about the 'sparr' package methods can be found in the tutorial:
        Davies et al. (2018) <doi:10.1002/sim.7577>. Details about kernel density estimation can
        be found in J. F. Bithell (1990) <doi:10.1002/sim.4780090616>.  More information about
        relative risk functions using kernel density estimation can be found in J. F. Bithell
        (1991) <doi:10.1002/sim.4780101112>.",2022-03-24,Ian D. Buller,https://github.com/Waller-SUSAN/envi,TRUE,https://github.com/waller-susan/envi,8396,0,2022-03-24T03:59:24Z,NA
enviGCMS,"Gas/Liquid Chromatography-Mass Spectrometer(GC/LC-MS) Data Analysis for Environmental Science. This package covered topics such molecular isotope ratio, matrix effects and Short-Chain Chlorinated Paraffins analysis etc. in environmental analysis.",2020-06-04,Miao YU,https://github.com/yufree/enviGCMS,TRUE,https://github.com/yufree/envigcms,16898,13,2022-02-27T23:24:28Z,1299.8461538461538
enviPat,"Fast and very memory-efficient calculation of isotope patterns,
    subsequent convolution to theoretical envelopes (profiles) plus valley
    detection and centroidization or intensoid calculation. Batch processing,
    resolution interpolation, wrapper, adduct calculations and molecular
    formula parsing. 
	Loos, M., Gerber, C., Corona, F., Hollender, J., Singer, H. (2015) 
	<doi:10.1021/acs.analchem.5b00941>.",2019-04-07,Martin Loos,"http://www.envipat.eawag.ch/,
http://pubs.acs.org/doi/abs/10.1021/acs.analchem.5b00941",TRUE,https://github.com/blosloos/envipat,30855,4,2021-09-29T06:59:42Z,7713.75
envir,"Provides a small set of functions for managing R environments, with defaults designed to encourage usage patterns that scale well to larger code bases. It provides: import_from(), a flexible way to assign bindings that defaults to the current environment; include(), a vectorized alternative to base::source() that also default to the current environment; and attach_eval() and attach_source(), a way to evaluate expressions in attached environments. Together, these (and other) functions pair to provide a robust alternative to base::library() and base::source().",2021-09-20,Tomasz Kalinowski,https://t-kalinowski.github.io/envir/,TRUE,https://github.com/t-kalinowski/envir,11567,5,2021-09-20T18:06:36Z,2313.4
envstat,"Runs a series of configurable tests against a user's compute 
  environment. This can be used for checking that things like a specific 
  directory or an environment variable is available before you start an analysis.
  Alternatively, you can use the package's situation report when filing error
  reports with your compute infrastructure.",2022-06-14,Mark Sellors,https://envstat.sellorm.com,TRUE,https://github.com/sellorm/envstat,1922,5,2022-06-14T22:22:37Z,384.4
EnvStats,"Graphical and statistical analyses of environmental data, with 
  focus on analyzing chemical concentrations and physical parameters, usually in 
  the context of mandated environmental monitoring.  Major environmental 
  statistical methods found in the literature and regulatory guidance documents, 
  with extensive help that explains what these methods do, how to use them, 
  and where to find them in the literature.  Numerous built-in data sets from 
  regulatory guidance documents and environmental statistics literature.  Includes 
  scripts reproducing analyses presented in the book ""EnvStats:  An R Package for 
  Environmental Statistics"" (Millard, 2013, Springer, ISBN 978-1-4614-8455-4, 
  <https://link.springer.com/book/9781461484554>).",2022-03-07,Steven P. Millard,https://github.com/alexkowa/EnvStats,TRUE,https://github.com/alexkowa/envstats,401013,15,2022-03-07T13:01:12Z,26734.2
epcc,"Provides several functions that allow model and simulate 
             the effects of thermal sensitivity and the exposition to 
             different trends in environmental temperature on the 
             abundance dynamics of ectotherms populations. It allows 
             an easy implementation of the possible consequences of 
             warming at global and local scales, constituting a useful 
             tool for understanding the extinction risk of populations.
             (Víctor Saldaña-Núñez, Fernando Córdova-Lepe, & Felipe N. 
             Moreno-Gómez, 2021) <doi:10.5281/zenodo.5034087>.",2021-06-29,Víctor Saldaña-Núñez,https://github.com/Victor-Saldana/epcc,TRUE,https://github.com/victor-saldana/epcc,4247,0,2021-10-29T20:17:06Z,NA
eph,"Tools to download and manipulate the Permanent Household Survey from Argentina
    (EPH is the Spanish acronym for Permanent Household Survey).
    e.g: get_microdata() for downloading the datasets, get_poverty_lines() for downloading the official poverty baskets,
    calculate_poverty() for the calculation of stating if a household is in poverty or not, following the official methodology.
    organize_panels() is used to concatenate observations from different periods, and organize_labels()
    adds the official labels to the data. The implemented methods are based on INDEC (2016) <http://www.estadistica.ec.gba.gov.ar/dpe/images/SOCIEDAD/EPH_metodologia_22_pobreza.pdf>.
    As this package works with the argentinian Permanent Household Survey and its main audience is from this country,
    the documentation was written in Spanish.",2020-06-25,Diego Kozlowski,https://github.com/holatam/eph,TRUE,https://github.com/holatam/eph,19745,42,2022-05-16T01:56:32Z,470.1190476190476
epi2me2r,"The functions in this package take WIMP and ARMA data files generated by Oxford Nanopore EPI2ME workflows, 
  read them, clean them, and prepare them for downstream analysis. 
  This package was written by United States federal government employees in their official capacity. Therefore, it is not protected by copyright and is in the public domain.  ",2022-06-03,Quentin D. Read,https://mweinroth.github.io/epi2me2r/,TRUE,https://github.com/mweinroth/epi2me2r,253,1,2022-06-02T00:14:24Z,253
epicontacts,"A collection of tools for representing epidemiological contact data, composed of case line lists and contacts between cases. Also contains procedures for data handling, interactive graphics, and statistics.",2021-10-21,Finlay Campbell,https://www.repidemicsconsortium.org/epicontacts/,TRUE,https://github.com/reconhub/epicontacts,22482,11,2021-11-02T11:01:20Z,2043.8181818181818
EpiContactTrace,"Routines for epidemiological contact tracing
    and visualisation of network of contacts.",2021-09-03,Maria Noremark,https://github.com/stewid/EpiContactTrace,TRUE,https://github.com/stewid/epicontacttrace,26876,7,2021-08-30T14:19:06Z,3839.4285714285716
EpiCurve,"Creates simple or stacked epidemic curves for hourly, daily, weekly or monthly outcome data.",2021-07-14,Jean Pierre Decorps,https://github.com/IamKDO/EpiCurve,TRUE,https://github.com/iamkdo/epicurve,23592,1,2021-07-29T13:54:09Z,23592
epidm,"Contains utilities and functions for the cleaning, processing and 
    management of patient level public health data for surveillance 
    and analysis held by the UK Health Security Agency, UKHSA. ",2022-07-06,Alex Bhattacharya,"https://github.com/alexbhatt/epidm,
https://alexbhatt.github.io/epidm/",TRUE,https://github.com/alexbhatt/epidm,1294,9,2022-07-08T14:07:37Z,143.77777777777777
EpiEstim,"Tools to quantify transmissibility throughout
    an epidemic from the analysis of time series of incidence as described in
    Cori et al. (2013) <doi:10.1093/aje/kwt133> and Wallinga and Teunis (2004) 
    <doi:10.1093/aje/kwh255>.",2021-01-07,Anne Cori,https://github.com/mrc-ide/EpiEstim,TRUE,https://github.com/mrc-ide/epiestim,114501,70,2022-04-01T16:50:24Z,1635.7285714285715
epigraphdb,"The interface package to access data from the
    'EpiGraphDB' <https://epigraphdb.org> platform.
    It provides easy access to the 'EpiGraphDB' platform with functions that
    query the corresponding REST endpoints on the API <https://api.epigraphdb.org>
    and return the response data in the 'tibble' data frame format.",2022-01-14,Yi Liu,https://mrcieu.github.io/epigraphdb-r/,TRUE,https://github.com/mrcieu/epigraphdb-r,8757,12,2022-01-14T19:42:52Z,729.75
EpiInvert,"Estimation,  by inverting a renewal equation,  
  of time-varying reproduction numbers and restored incidence curves with 
  festive days and weekly biases corrected as described in 
  Alvarez et al. (2021) <doi:10.1073/pnas.2105112118> and 
  Alvarez et al. (2022) <doi:10.3390/biology11040540>.",2022-05-20,Luis Alvarez,https://github.com/lalvarezmat/EpiInvert,TRUE,https://github.com/lalvarezmat/epiinvert,466,1,2022-07-10T11:58:38Z,466
epikit,"Contains tools for formatting inline code, renaming redundant
  columns, aggregating age categories, and calculating proportions with
  confidence intervals. This is part of the 'R4Epis' project
  <https://r4epis.netlify.com>.",2020-09-07,Zhian N. Kamvar,"https://github.com/R4EPI/epikit, https://r4epis.netlify.com,
https://r4epi.github.io/epikit",TRUE,https://github.com/r4epi/epikit,17634,1,2021-11-28T11:20:43Z,17634
EpiLPS,"Estimation of the instantaneous reproduction number with 
 Laplacian-P-splines following the methodology of Gressani et al.(2021)
 <doi:10.1101/2021.12.02.21267189>. The negative Binomial 
 distribution is used to model the time series of case counts. Two methods are 
 available for inference : (1) a sampling-free approach based on a maximum a 
 posteriori calibration of the hyperparameter vector and (2) a fully stochastic 
 approach with a Metropolis-within-Gibbs algorithm and Langevin diffusions for
 efficient sampling of the posterior distribution.",2022-05-06,Oswaldo Gressani,<https://github.com/oswaldogressani/EpiLPS>,TRUE,https://github.com/oswaldogressani/epilps,3262,7,2022-05-06T06:52:40Z,466
epimdr,"Functions, data sets and shiny apps for ""Epidemics: Models and Data in R"" by Ottar N. Bjornstad (ISBN 978-3-319-97487-3) <https://www.springer.com/gp/book/9783319974866>. The package contains functions to study the S(E)IR model, spatial and age-structured SIR models; time-series SIR and chain-binomial stochastic models; catalytic disease models; coupled map lattice models of spatial transmission and network models for social spread of infection. The package is also an advanced quantitative companion to the coursera Epidemics Massive Online Open Course <https://www.coursera.org/learn/epidemics>.",2020-01-25,Ottar N. Bjornstad,"https://github.com/objornstad/epimdr,
https://www.springer.com/gp/book/9783319974866,
http://ento.psu.edu/directory/onb1",TRUE,https://github.com/objornstad/epimdr,16944,48,2022-06-12T18:55:14Z,353
EpiModel,"Tools for simulating mathematical models of infectious disease dynamics.
    Epidemic model classes include deterministic compartmental models, stochastic
    individual-contact models, and stochastic network models. Network models use the
    robust statistical methods of exponential-family random graph models (ERGMs)
    from the Statnet suite of software packages in R. Standard templates for epidemic
    modeling include SI, SIR, and SIS disease types. EpiModel features an API for
    extending these templates to address novel scientific research aims. Full
    methods for EpiModel are detailed in Jenness et al. (2018, <doi:10.18637/jss.v084.i08>).",2022-02-02,Samuel Jenness,http://www.epimodel.org/,TRUE,https://github.com/epimodel/epimodel,58843,206,2022-07-08T17:42:53Z,285.6456310679612
epinetr,"Allows for forward-in-time simulation of epistatic networks with associated
    phenotypic output.",2022-03-10,Dion Detterer,https://github.com/diondetterer/epinetr,TRUE,https://github.com/diondetterer/epinetr,7728,0,2022-03-10T05:44:21Z,NA
EpiNow2,"Estimates the time-varying reproduction number, rate of spread,
             and doubling time using a range of open-source tools (Abbott et al. (2020) <doi:10.12688/wellcomeopenres.16006.1>),
             and current best practices (Gostic et al. (2020) <doi:10.1101/2020.06.18.20134858>).
             It aims to help users avoid some of the limitations of naive implementations in a framework
             that is informed by community feedback and is under active development.",2020-12-14,Sam Abbott,"https:/epiforecasts.io/EpiNow2/,
https:/epiforecasts.io/EpiNow2/dev/,
https://github.com/epiforecasts/EpiNow2",TRUE,https://github.com/epiforecasts/epinow2,17866,67,2022-05-05T10:11:58Z,266.65671641791045
episensr,"Basic sensitivity analysis of the observed relative risks adjusting
    for unmeasured confounding and misclassification of the
    exposure/outcome, or both. It follows the bias analysis methods and
    examples from the book by Lash T.L, Fox M.P, and Fink A.K.
    ""Applying Quantitative Bias Analysis to Epidemiologic Data"",
    ('Springer', 2009).",2021-08-20,Denis Haine,https://github.com/dhaine/episensr,TRUE,https://github.com/dhaine/episensr,22020,9,2021-08-20T17:27:18Z,2446.6666666666665
epitweetr,"It allows you to automatically monitor trends of tweets by time, place and topic aiming at detecting public health threats early through the detection of signals (e.g. an unusual increase in the number of tweets). It was designed to focus on infectious diseases, and it can be extended to all hazards or other fields of study by modifying the topics and keywords.",2022-01-05,Laura Espinosa,https://github.com/EU-ECDC/epitweetr,TRUE,https://github.com/eu-ecdc/epitweetr,13868,40,2022-01-05T11:05:34Z,346.7
eplusr,"A rich toolkit of using the whole building
    simulation program 'EnergyPlus'(<https://energyplus.net>), which
    enables programmatic navigation, modification of 'EnergyPlus' models
    and makes it less painful to do parametric simulations and analysis.",2022-01-21,Hongyuan Jia,"https://hongyuanjia.github.io/eplusr/,
https://github.com/hongyuanjia/eplusr",TRUE,https://github.com/hongyuanjia/eplusr,22732,52,2022-05-11T15:54:28Z,437.15384615384613
epm,"Facilitates the aggregation of species' geographic ranges from vector or raster spatial data, and that enables the calculation of various morphological and phylogenetic community metrics across geography. Citation: Title, PO, DL Swiderski and ML Zelditch (2022) <doi:10.1111/2041-210X.13914>. ",2022-06-22,Pascal Title,https://github.com/ptitle/epm,TRUE,https://github.com/ptitle/epm,529,8,2022-06-22T14:37:56Z,66.125
epocakir,"Clinical coding and diagnosis of patients with kidney using
    clinical practice guidelines. The guidelines used are the evidence-based
    KDIGO guidelines, see <https://kdigo.org/guidelines/> for more information.
    This package covers acute kidney injury (AKI), anemia, and
    chronic kidney disease (CKD).",2022-05-04,Alwin Wang,https://github.com/alwinw/epocakir,TRUE,https://github.com/alwinw/epocakir,4724,3,2022-05-04T12:59:44Z,1574.6666666666667
epsiwal,"Implements the conditional estimation procedure of
  Lee, Sun, Sun and Taylor (2016) <doi:10.1214/15-AOS1371>.
  This procedure allows hypothesis testing on the mean of
  a normal random vector subject to linear constraints.",2019-07-02,Steven E. Pav,https://github.com/shabbychef/epsiwal,TRUE,https://github.com/shabbychef/epsiwal,11763,0,2022-05-10T05:28:12Z,NA
epwshiftr,"
    Query, download climate change projection data from the 'CMIP6' (Coupled
    Model Intercomparison Project Phase 6) project
    <https://pcmdi.llnl.gov/CMIP6/> in the 'ESGF' (Earth System Grid Federation)
    platform <https://esgf.llnl.gov>, and create future 'EnergyPlus'
    <https://energyplus.net> Weather ('EPW') files adjusted from climate changes
    using data from Global Climate Models ('GCM').",2021-05-26,Hongyuan Jia,https://github.com/ideas-lab-nus/epwshiftr,TRUE,https://github.com/ideas-lab-nus/epwshiftr,10723,14,2022-06-27T02:40:35Z,765.9285714285714
eq5d,"EQ-5D is a popular health related quality of life instrument used 
    in the clinical and economic evaluation of health care. Developed by the 
    EuroQol group <https://euroqol.org/>, the instrument consists of two 
    components: health state description and evaluation. For the description 
    component a subject self-rates their health in terms of five dimensions; 
    mobility, self-care, usual activities, pain/discomfort, and 
    anxiety/depression using either a three-level (EQ-5D-3L,
    <https://euroqol.org/eq-5d-instruments/eq-5d-3l-about/>) or a five-level
    (EQ-5D-5L, <https://euroqol.org/eq-5d-instruments/eq-5d-5l-about/>) 
    scale. Frequently the scores on these five dimensions are converted to a 
    single utility index using country specific value sets, which can be used
    in the clinical and economic evaluation of health care as well as in 
    population health surveys. The eq5d package provides methods to calculate 
    index scores from a subject's dimension scores. 29 TTO and 11 VAS EQ-5D-3L
    value sets including those for countries in Szende et al (2007) 
    <doi:10.1007/1-4020-5511-0> and Szende et al (2014) 
    <doi:10.1007/978-94-007-7596-1>, 33 EQ-5D-5L EQ-VT value sets from the 
    EuroQol website, the EQ-5D-5L crosswalk value sets developed by 
    van Hout et al. (2012) <doi:10.1016/j.jval.2012.02.008>, the
    crosswalk value set for Russia and reverse crosswalk value sets. Three 
    EQ-5D-Y value sets are also included as are the NICE 'DSU' age-sex
    based EQ-5D-3L to EQ-5D-5L and EQ-5D-5L to EQ-5D-3L mappings. Methods are 
    also included for the analysis of EQ-5D profiles along with a shiny web 
    tool to enable the calculation, visualisation and automated statistical 
    analysis of EQ-5D data via a web browser using EQ-5D dimension scores 
    stored in CSV or Excel files. ",2022-04-05,Fraser Morton,https://github.com/fragla/eq5d,TRUE,https://github.com/fragla/eq5d,29725,14,2022-07-07T15:49:41Z,2123.214285714286
equatags,"Provides function to transform latex math expressions 
 into format 'HTML' or 'Office Open XML Math'. The 'XML' 
 result can then be included in 'HTML', 'Microsoft Word' 
 documents or 'Microsoft PowerPoint' presentations by using 
 a 'Markdown' document or the R package 'officer'. ",2022-06-13,David Gohel,NA,TRUE,https://github.com/ardata-fr/equatags,29331,4,2022-06-13T21:56:03Z,7332.75
equate,"Contains methods for observed-score linking
  and equating under the single-group, equivalent-groups,
  and nonequivalent-groups with anchor test(s) designs.
  Equating types include identity, mean, linear, general
  linear, equipercentile, circle-arc, and composites of
  these. Equating methods include synthetic, nominal
  weights, Tucker, Levine observed score, Levine true
  score, Braun/Holland, frequency estimation, and chained
  equating. Plotting and summary methods, and methods for
  multivariate presmoothing and bootstrap error estimation
  are also provided.",2022-06-07,Anthony Albano,https://github.com/talbano/equate,TRUE,https://github.com/talbano/equate,54717,2,2022-06-07T16:00:07Z,27358.5
equatiomatic,"The goal of 'equatiomatic' is to reduce the pain
    associated with writing 'LaTeX' formulas from fitted models. The
    primary function of the package, extract_eq(), takes a fitted model
    object as its input and returns the corresponding 'LaTeX' code for the
    model.",2022-01-30,Daniel Anderson,"https://github.com/datalorax/equatiomatic,
https://datalorax.github.io/equatiomatic/",TRUE,https://github.com/datalorax/equatiomatic,35548,544,2022-03-14T16:45:03Z,65.34558823529412
era,"Provides a consistent representation of year-based time scales as a
    numeric vector with an associated 'era'. There are built-in era definitions
    for many year numbering systems used in contemporary and historic calendars 
    (e.g. Common Era, Islamic 'Hijri' years); year-based time scales used in 
    archaeology, astronomy, geology, and other palaeosciences (e.g. 
    Before Present, SI-prefixed 'annus'); and support for arbitrary user-defined
    eras. Years can converted from any one era to another using a generalised 
    transformation function. Methods are also provided for robust casting and 
    coercion between years and other numeric types, type-stable arithmetic with 
    years, and pretty-printing in tables.",2022-03-09,Joe Roe,"https://era.joeroe.io, https://github.com/joeroe/era",TRUE,https://github.com/joeroe/era,6166,5,2022-03-09T14:55:20Z,1233.2
ergm,"An integrated set of tools to analyze and simulate networks based on exponential-family random graph models (ERGMs). 'ergm' is a part of the Statnet suite of packages for network analysis. See Hunter, Handcock, Butts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and Krivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",2022-06-01,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm,225941,77,2022-07-01T07:02:43Z,2934.2987012987014
ergm.count,"A set of extensions for the 'ergm' package to fit weighted networks whose edge weights are counts. See Krivitsky (2012) <doi:10.1214/12-EJS696> and Krivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",2022-05-25,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm.count,98540,7,2022-05-24T12:03:30Z,14077.142857142857
ergm.ego,Utilities for managing egocentrically sampled network data and a wrapper around the 'ergm' package to facilitate ERGM inference and simulation from such data. See Krivitsky and Morris (2017) <doi:10.1214/16-AOAS1010>.,2022-05-26,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm.ego,29600,9,2022-05-26T13:29:08Z,3288.8888888888887
ergm.multi,"A set of extensions for the 'ergm' package to fit multilayer/multiplex/multirelational networks and samples of multiple networks. 'ergm.multi' is a part of the Statnet suite of packages for network analysis. See Krivitsky, Koehly, and Marcum (2020) <doi:10.1007/s11336-020-09720-7> and Krivitsky, Coletti, and Hens (2022) <doi:10.48550/arXiv.2202.03685>.",2022-07-03,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm.multi,103,8,2022-07-03T06:29:14Z,12.875
ergm.rank,"A set of extensions for the 'ergm' package to fit weighted networks whose edge weights are ranks. See Krivitsky and Butts (2017) <doi:10.1177/0081175017692623> and Krivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",2022-06-01,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/ergm.rank,22822,1,2022-06-01T13:05:00Z,22822
err,"Messages should provide users with readable information 
    about R objects without flooding their console. 
    'cc()' concatenates vector and data frame values 
    into a grammatically correct string using commas, an ellipsis and conjunction. 
    'cn()' allows the user to define a string which varies based on a count.
    'co()' combines the two to produce a customizable object aware string.
    The package further facilitates this process by providing five 'sprintf'-like 
    types such as '%n' for the length of an object and '%o' for its name as
    well as wrappers for pasting objects and issuing errors, warnings and messages.",2019-04-25,Joe Thorley,https://github.com/poissonconsulting/err,TRUE,https://github.com/poissonconsulting/err,28770,6,2021-11-12T22:46:24Z,4795
erratum,Elegantly handle error and warning messages.,2022-01-03,John Coene,NA,TRUE,https://github.com/devopifex/erratum,7169,19,2022-02-08T18:40:02Z,377.3157894736842
errorlocate,"Errors in data can be located and removed using validation rules from package 
   'validate'. See also Van der Loo and De Jonge (2018) <doi:10.1002/9781118897126>,
   chapter 7.",2022-06-29,Edwin de Jonge,https://github.com/data-cleaning/errorlocate,TRUE,https://github.com/data-cleaning/errorlocate,21682,18,2022-06-29T07:32:52Z,1204.5555555555557
errors,"Support for measurement errors in R vectors, matrices and arrays:
    automatic uncertainty propagation and reporting.
    Documentation about 'errors' is provided in the paper by Ucar, Pebesma &
    Azcorra (2018, <doi:10.32614/RJ-2018-075>), included in this package as a
    vignette; see 'citation(""errors"")' for details.",2020-11-10,Iñaki Ucar,https://github.com/r-quantities/errors,TRUE,https://github.com/r-quantities/errors,22465,39,2022-01-05T15:38:34Z,576.025641025641
eRTG3D,"Creates realistic random trajectories in a 3-D space between two given fix points, so-called conditional empirical random walks (CERWs). The trajectory generation is based on empirical distribution functions extracted from observed trajectories (training data) and thus reflects the geometrical movement characteristics of the mover. A digital elevation model (DEM), representing the Earth's surface, and a background layer of probabilities (e.g. food sources, uplift potential, waterbodies, etc.) can be used to influence the trajectories.
    Unterfinger M (2018). ""3-D Trajectory Simulation in Movement Ecology: Conditional Empirical Random Walk"". Master's thesis, University of Zurich. <https://www.geo.uzh.ch/dam/jcr:6194e41e-055c-4635-9807-53c5a54a3be7/MasterThesis_Unterfinger_2018.pdf>.
    Technitis G, Weibel R, Kranstauber B, Safi K (2016). ""An algorithm for empirically informed random trajectory generation between two endpoints"". GIScience 2016: Ninth International Conference on Geographic Information Science, 9, online. <doi:10.5167/uzh-130652>.",2022-02-25,Merlin Unterfinger,"https://munterfi.github.io/eRTG3D/,
https://github.com/munterfi/eRTG3D/",TRUE,https://github.com/munterfi/ertg3d,14485,3,2022-02-23T14:41:15Z,4828.333333333333
esaps,"It allows structuring electoral data of different size and structure 
        to calculate various indicators frequently used in the studies of electoral systems and party systems.
        Indicators of electoral volatility, electoral disproportionality, party nationalization and the 
        effective number of parties are included.",2021-09-13,Nicolas Schmidt,https://github.com/Nicolas-Schmidt/esaps,TRUE,https://github.com/nicolas-schmidt/esaps,13411,3,2021-11-09T15:10:17Z,4470.333333333333
eSDM,"A tool which allows users to create and evaluate ensembles 
    of species distribution model (SDM) predictions. 
    Functionality is offered through R functions or a GUI (R Shiny app). 
    This tool can assist users in identifying spatial uncertainties and 
    making informed conservation and management decisions. The package is 
    further described in Woodman et al (2019) <doi:10.1111/2041-210X.13283>.",2021-05-04,Sam Woodman,"https://smwoodman.github.io/eSDM/,
https://github.com/smwoodman/eSDM/",TRUE,https://github.com/smwoodman/esdm,18317,6,2022-06-02T02:44:36Z,3052.8333333333335
esquisse,"A 'shiny' gadget to create 'ggplot2' figures interactively with drag-and-drop to map your variables to different aesthetics.
    You can quickly visualize your data accordingly to their type, export in various formats,
    and retrieve the code to reproduce the plot.",2022-05-03,Victor Perrier,"https://dreamrs.github.io/esquisse/,
https://github.com/dreamRs/esquisse",TRUE,https://github.com/dreamrs/esquisse,233460,1502,2022-06-28T08:19:51Z,155.43275632490014
ess,"An implementation of the ESS algorithm following Amol Deshpande, Minos Garofalakis,
	     Michael I Jordan (2013) <arXiv:1301.2267>. The ESS algorithm
	     is used for model selection in decomposable graphical models.",2021-05-31,Mads Lindskou,https://github.com/mlindsk/ess,TRUE,https://github.com/mlindsk/ess,10043,1,2021-10-13T07:38:25Z,10043
essurvey,Download data from the European Social Survey directly from their website <http://www.europeansocialsurvey.org/>. There are two families of functions that allow you to download and interactively check all countries and rounds available.,2022-01-09,Jorge Cimentada,"https://docs.ropensci.org/essurvey/,
https://github.com/ropensci/essurvey",TRUE,https://github.com/ropensci/essurvey,22281,47,2022-01-10T11:13:58Z,474.06382978723406
EstimationTools,"Routines for parameter estimation for any probability density or
    mass function implemented in R via maximum likelihood (ML) given a data set.
    The main routines 'maxlogL' and 'maxlogLreg' are  wrapper functions specifically
    developed for ML estimation. There are included optimization procedures such as
    'nlminb' and 'optim' from base package, and 'DEoptim' Mullen (2011)
    <doi: 10.18637/jss.v040.i06>. Standard errors are estimated with 'numDeriv'
    Gilbert (2011) <https://CRAN.R-project.org/package=numDeriv>
    or the option 'Hessian = TRUE' of 'optim' function.",2021-03-10,Jaime Mosquera,"https://jaimemosg.github.io/EstimationTools/,
https://github.com/Jaimemosg/EstimationTools",TRUE,https://github.com/jaimemosg/estimationtools,19189,2,2021-10-11T00:51:40Z,9594.5
estimatr,"Fast procedures for small set of commonly-used, design-appropriate estimators with robust standard errors and confidence intervals. Includes estimators for linear regression, instrumental variables regression, difference-in-means, Horvitz-Thompson estimation, and regression improving precision of experimental estimates by interacting treatment with centered pre-treatment covariates introduced by Lin (2013) <doi:10.1214/12-AOAS583>.",2022-07-04,Graeme Blair,"https://declaredesign.org/r/estimatr/,
https://github.com/DeclareDesign/estimatr",TRUE,https://github.com/declaredesign/estimatr,191774,121,2022-06-26T03:50:32Z,1584.909090909091
estmeansd,"Implements the methods of McGrath et al. (2020) 
    <doi:10.1177/0962280219889080> and Cai et al. (2021) 
    <doi:10.1177/09622802211047348> for estimating the sample mean and standard 
    deviation from commonly reported quantiles in meta-analysis. These methods 
    can be applied to studies that report the sample median, sample size, and 
    one or both of (i) the sample minimum and maximum values and (ii) the first 
    and third quartiles. ",2022-06-19,Sean McGrath,https://github.com/stmcg/estmeansd,TRUE,https://github.com/stmcg/estmeansd,16380,0,2022-06-17T18:34:58Z,NA
estudy2,"An implementation of a most commonly used event study methodology,
    including both parametric and nonparametric tests. It contains variety
    aspects of the rate of return estimation (the core calculation is done in
    C++), as well as three classical for event study market models: mean
    adjusted returns, market adjusted returns and single-index market models.
    There are 6 parametric and 6 nonparametric tests provided, which examine
    cross-sectional daily abnormal return (see the documentation of the
    functions for more information). Parametric tests include tests proposed by 
    Brown and Warner (1980) <DOI:10.1016/0304-405X(80)90002-1>, Brown and Warner
    (1985) <DOI:10.1016/0304-405X(85)90042-X>, Boehmer et al. (1991)
    <DOI:10.1016/0304-405X(91)90032-F>, Patell (1976) <DOI:10.2307/2490543>, and
    Lamb (1995) <DOI:10.2307/253695>. Nonparametric tests covered in estudy2 are
    tests described in Corrado and Zivney (1992) <DOI:10.2307/2331331>,
    McConnell and Muscarella (1985) <DOI:10.1016/0304-405X(85)90006-6>,
    Boehmer et al. (1991) <DOI:10.1016/0304-405X(91)90032-F>, Cowan (1992)
    <DOI:10.1007/BF00939016>, Corrado (1989) <DOI:10.1016/0304-405X(89)90064-0>,
    Campbell and Wasley (1993) <DOI:10.1016/0304-405X(93)90025-7>, Savickas (2003)
    <DOI:10.1111/1475-6803.00052>, Kolari and Pynnonen (2010)
    <DOI:10.1093/rfs/hhq072>. Furthermore, tests for the cumulative
    abnormal returns proposed by Brown and Warner (1985)
    <DOI:10.1016/0304-405X(85)90042-X> and Lamb (1995) <DOI:10.2307/253695>
    are included.",2021-11-15,Iegor Rudnytskyi,"https://github.com/irudnyts/estudy2,
https://irudnyts.github.io/estudy2/",TRUE,https://github.com/irudnyts/estudy2,20739,10,2022-04-12T12:36:33Z,2073.9
ETAS,"Fits the space-time Epidemic Type Aftershock Sequence
    ('ETAS') model to earthquake catalogs using a stochastic 'declustering' 
    approach. The 'ETAS' model is a 'spatio-temporal' marked point process
    model and a special case of the 'Hawkes' process. The package is based 
    on a Fortran program by 'Jiancang Zhuang'
    (available at <http://bemlar.ism.ac.jp/zhuang/software.html>),
    which is modified and translated into C++ and C such that it 
    can be called from R. Parallel computing with 'OpenMP' is possible 
    on supported platforms.",2022-02-21,Abdollah Jalilian,https://github.com/jalilian/ETAS,TRUE,https://github.com/jalilian/etas,19256,15,2022-02-21T18:53:53Z,1283.7333333333333
ethnobotanyR,"An implementation of the quantitative ethnobotany indices in R. The goal is to provide an easy-to-use platform for ethnobotanists to assess the cultural significance of plant species based on informant consensus. The package closely follows the paper by Tardio and Pardo-de-Santayana (2008). Tardio, J., and M. Pardo-de-Santayana, 2008. Cultural Importance Indices: A Comparative Analysis Based on the Useful Wild Plants of Southern Cantabria (Northern Spain) 1. Economic Botany, 62(1), 24-39. <doi:10.1007/s12231-007-9004-5>.",2021-01-06,Cory Whitney,https://CRAN.R-project.org/package=ethnobotanyR,TRUE,https://github.com/cwwhitney/ethnobotanyr,16419,4,2022-02-07T16:22:52Z,4104.75
etrader,"Use R to interface with the 'ETRADE' API <https://developer.etrade.com/home>.
    Functions include authentication, trading, quote requests, account information, and option 
    chains. A user will need an ETRADE brokerage account and 'ETRADE' API approval. See README 
    for authentication process and examples.",2021-02-22,Anthony Balentine,https://exploringfinance.github.io/etrader/,TRUE,https://github.com/exploringfinance/etrader,6636,4,2021-10-20T01:55:49Z,1659
eudract,"The remit of the European Clinical Trials Data Base (EudraCT <https://eudract.ema.europa.eu/> ), or ClinicalTrials.gov <https://clinicaltrials.gov/>, is to provide open access to summaries of all registered clinical trial results; thus aiming to prevent non-reporting of negative results and provide open-access to results to inform future research. The amount of information required and the format of the results, however, imposes a large extra workload at the end of studies on clinical trial units. In particular, the adverse-event-reporting component requires entering: each unique combination of treatment group and safety event; for every such event above, a further 4 pieces of information (body system, number of occurrences, number of subjects, number exposed) for non-serious events, plus an extra three pieces of data for serious adverse events (numbers of causally related events, deaths, causally related deaths). This package prepares the required statistics needed by EudraCT and formats them into the precise requirements to directly upload an XML file into the web portal, with no further data entry by hand.",2022-01-14,Simon Bond,https://eudract-tool.medschl.cam.ac.uk/,TRUE,https://github.com/shug0131/eudract,14643,3,2022-01-17T10:29:27Z,4881
eulerr,"Generate area-proportional Euler diagrams
    using numerical optimization. An Euler diagram is a generalization of a Venn
    diagram, relaxing the criterion that all interactions need to be
    represented. Diagrams may be fit with ellipses and circles via
    a wide range of inputs and can be visualized in numerous ways.",2021-09-06,Johan Larsson,"https://github.com/jolars/eulerr, https://jolars.github.io/eulerr/",TRUE,https://github.com/jolars/eulerr,65762,108,2022-07-06T20:29:10Z,608.9074074074074
eurocordexr,"
    Daily 'netCDF' data from e.g. regional climate models (RCMs) are not trivial
    to work with. This package, which relies on 'data.table', makes it easier
    to deal with large data from RCMs, such as from EURO-CORDEX 
    (<https://www.euro-cordex.net/>, <https://cordex.org/data-access/>). It has 
    functions to extract single grid cells from rotated pole grids as well as 
    the whole array in long format. Can handle non-standard calendars (360, 
    noleap) and interpolate them to a standard one. Potentially works with many 
    CF-conform 'netCDF' files. ",2021-08-19,Michael Matiu,https://github.com/mitmat/eurocordexr,TRUE,https://github.com/mitmat/eurocordexr,3616,0,2021-08-24T09:44:18Z,NA
eurodata,"Interface to Eurostat’s Bulk Download Facility with fast data.table-based import of
    data, labels, and metadata. On top of the core functionality, data search and data
    description/comparison functions are also provided.",2022-05-24,Aleksander Rutkowski,https://github.com/alekrutkowski/eurodata/,TRUE,https://github.com/alekrutkowski/eurodata,363,4,2022-05-30T07:50:59Z,90.75
europeanaR,"Interact with the Europeana Data Model via a variety of API
 endpoints that contains digital collections from thousands of institutions
 around Europe. This translates to millions of Cultural Heritage Objects in the
 form of image, text, video, sound and 3D, accompanied by rich metadata. The
 Data Model design principles are based on the core principles and best
 practices of the Semantic Web and Linked Data efforts to which Europeana
 contributes (see, e.g., Doerr, Martin, et al. The europeana data model (edm).
 World Library and Information Congress: 76th IFLA general conference
 and assembly. Vol. 10. 2010.). The package also provides methods for bulk
 downloads of specific subsets of items, including both their metadata
 and their associated media files.",2022-05-17,Alexandros Kouretsis,https://github.com/AleKoure/europeanaR,TRUE,https://github.com/alekoure/europeanar,400,1,2022-05-22T21:19:12Z,400
europepmc,"An R Client for the Europe PubMed Central RESTful Web Service
    (see <https://europepmc.org/RestfulWebService> for more information). It
    gives access to both metadata on life science literature and open access
    full texts. Europe PMC indexes all PubMed content and other literature
    sources including Agricola, a bibliographic database of citations to the
    agricultural literature, or Biological Patents. In addition to bibliographic
    metadata, the client allows users to fetch citations and reference lists.
    Links between life-science literature and other EBI databases, including
    ENA, PDB or ChEMBL are also accessible. No registration or API key is
    required. See the vignettes for usage examples.",2021-09-02,Najko Jahn,"https://docs.ropensci.org/europepmc/,
https://github.com/ropensci/europepmc/",TRUE,https://github.com/ropensci/europepmc,156437,23,2022-01-16T14:20:52Z,6801.608695652174
eurostat,"Tools to download data from the Eurostat database
    <https://ec.europa.eu/eurostat> together with search and manipulation
    utilities.",2022-02-09,Leo Lahti,"https://ropengov.github.io/eurostat/,
https://github.com/rOpenGov/eurostat",TRUE,https://github.com/ropengov/eurostat,76383,190,2022-06-25T08:46:49Z,402.0157894736842
evalITR,"Provides various statistical methods for evaluating Individualized Treatment Rules under randomized data. The provided metrics include Population Average Value (PAV), Population Average Prescription Effect (PAPE), Area Under Prescription Effect Curve (AUPEC). It also provides the tools to analyze Individualized Treatment Rules under budget constraints. Detailed reference in Imai and Li (2019) <arXiv:1905.05389>.",2022-03-29,Michael Lingzhi Li,https://github.com/MichaelLLi/evalITR,TRUE,https://github.com/michaellli/evalitr,13873,7,2022-03-28T05:36:29Z,1981.857142857143
evaluate,"Parsing and evaluation tools that make it easy to recreate the
    command line behaviour of R.",2022-02-18,Yihui Xie,https://github.com/r-lib/evaluate,TRUE,https://github.com/r-lib/evaluate,19542999,94,2022-05-25T12:10:55Z,207904.24468085106
eventdataR,Event dataset repository including both real-life and artificial event logs. They can be used in combination with functionalities provided by the 'bupaR' packages. Janssenswillen et al. (2020) <http://ceur-ws.org/Vol-2703/paperTD7.pdf>.,2022-06-28,Gert Janssenswillen,"https://bupar.net/, https://github.com/bupaverse/eventdataR/",TRUE,https://github.com/bupaverse/eventdatar,133266,0,2022-02-28T17:42:14Z,NA
eventglm,"A user friendly, easy to understand way of doing event
    history regression for marginal estimands of interest,
    including the cumulative incidence and the restricted mean
    survival, using the pseudo observation framework for 
    estimation. For a review of the methodology, see Andersen and
    Pohar Perme (2010) <doi:10.1177/0962280209105020> or Sachs 
    and Gabriel (2022) <doi:10.18637/jss.v102.i09>. The
    interface uses the well known formulation of a generalized
    linear model and allows for features including plotting of 
    residuals, the use of sampling weights, and corrected
    variance estimation. ",2022-04-26,Michael C Sachs,https://sachsmc.github.io/eventglm/,TRUE,https://github.com/sachsmc/eventglm,7896,4,2022-06-06T07:40:42Z,1974
EventStudy,"Perform Event Studies from through our <https://EventStudyTools.com> Application Programming Interface, parse the results, visualize it, and / or use the results in further analysis.",2021-12-20,Dr. Simon Mueller,https:://data-zoo.de,TRUE,https://github.com/eventstudytools/api-wrapper.r,18783,9,2021-12-28T18:26:40Z,2087
EvidenceSynthesis,"Routines for combining causal effect estimates and study diagnostics across multiple data sites in a distributed study, without sharing patient-level data. 
  Allows for normal and non-normal approximations of the data-site likelihood of the effect parameter. ",2021-01-29,Martijn Schuemie,"https://ohdsi.github.io/EvidenceSynthesis/,
https://github.com/OHDSI/EvidenceSynthesis",TRUE,https://github.com/ohdsi/evidencesynthesis,7899,6,2022-01-21T05:27:31Z,1316.5
EviewsR,"It allows running 'EViews'(<https://eviews.com>) program from R, R Markdown and Quarto documents. 'EViews' (Econometric Views) is a statistical software for Econometric analysis.  This package integrates 'EViews' and R and also serves as an 'EViews' Knit-Engine for 'knitr' package. Write all your 'EViews' commands in R, R Markdown or Quarto documents.",2022-05-01,Sagiru Mati,https://CRAN.R-project.org/package=EviewsR,TRUE,https://github.com/sagirumati/eviewsr,8386,3,2022-07-08T16:40:05Z,2795.3333333333335
evolqg,"Provides functions for covariance matrix comparisons, estimation
    of repeatabilities in measurements and matrices, and general evolutionary
    quantitative genetics tools.",2021-05-28,Ana Paula Assis,NA,TRUE,https://github.com/lem-usp/evolqg,20986,7,2021-11-19T20:23:34Z,2998
EvoPhylo,"Performs automated morphological character partitioning for 
             phylogenetic analyses and analyze macroevolutionary parameter 
             outputs from clock (time-calibrated) Bayesian inference analyses, following 
             concepts introduced by Simões and Pierce (2021) <doi:10.1038/s41559-021-01532-x>.",2022-05-17,Tiago Simoes,"https://github.com/tiago-simoes/EvoPhylo,
https://tiago-simoes.github.io/EvoPhylo/",TRUE,https://github.com/tiago-simoes/evophylo,322,0,2022-07-08T20:26:46Z,NA
ewoc,"An implementation of a variety of escalation with overdose control designs introduced by Babb, Rogatko and Zacks (1998) <doi:10.1002/(SICI)1097-0258(19980530)17:10%3C1103::AID-SIM793%3E3.0.CO;2-9>. It calculates the next dose as a clinical trial proceeds and performs simulations to obtain operating characteristics.",2020-06-07,Marcio A. Diniz,https://github.com/dnzmarcio/ewoc/,TRUE,https://github.com/dnzmarcio/ewoc,15945,2,2021-09-26T23:04:07Z,7972.5
exactextractr,"Provides a replacement for the 'extract' function from the 'raster' package
    that is suitable for extracting raster values using 'sf' polygons.",2022-04-15,Daniel Baston,"https://isciences.gitlab.io/exactextractr/,
https://github.com/isciences/exactextractr",TRUE,https://github.com/isciences/exactextractr,164882,198,2022-06-27T02:36:49Z,832.7373737373738
ExamPAData,"Contains all data sets for Exam PA: Predictive Analytics at 
    <https://exampa.net/>.",2021-10-23,Guanglai Li,https://github.com/sdcastillo/ExamPAData,TRUE,https://github.com/sdcastillo/exampadata,10321,5,2021-10-20T23:07:41Z,2064.2
excel.link,"Allows access to data in running instance of Microsoft Excel
    (e. g. 'xl[a1] = xl[b2]*3' and so on). Graphics can be transferred with
    'xl[a1] = current.graphics()'. Additionally there are function for reading/writing 
    'Excel' files - 'xl.read.file'/'xl.save.file'. They are not fast but able to read/write 
    '*.xlsb'-files and password-protected files. There is an Excel workbook with 
    examples of calling R from Excel in the 'doc' folder. It tries to keep things as
    simple as possible - there are no needs in any additional
    installations besides R, only 'VBA' code in the Excel workbook.
    Microsoft Excel is required for this package.",2021-11-02,"Gregory Demin <excel.link.feedback@gmail.com>. To comply CRAN policy
    includes source code from RDCOMClient (http://www.omegahat.net/RDCOMClient/) by
    Duncan Temple Lang <duncan@wald.ucdavis.edu>.",https://github.com/gdemin/excel.link,TRUE,https://github.com/gdemin/excel.link,42341,45,2021-11-02T16:53:26Z,940.9111111111112
excelR,An R interface to 'jExcel' library to create web-based interactive tables and spreadsheets compatible with 'Excel' or any other spreadsheet software.,2020-03-09,Swechhya Bista,https://github.com/Swechhya/excelR,TRUE,https://github.com/swechhya/excelr,31714,133,2022-01-24T12:05:37Z,238.45112781954887
excluder,"Data that are collected through online sources such as Mechanical 
            Turk may require excluding rows because of IP address duplication, 
            geolocation, or completion duration. This package facilitates
            exclusion of these data for Qualtrics datasets.",2022-06-22,Jeffrey R. Stevens,"https://docs.ropensci.org/excluder/,
https://github.com/ropensci/excluder/",TRUE,https://github.com/ropensci/excluder,2245,8,2022-06-26T16:02:55Z,280.625
excursions,"Functions that compute probabilistic excursion sets, contour credibility regions, contour avoiding regions, and simultaneous confidence bands for latent Gaussian random processes and fields. The package also contains functions that calculate these quantities for models estimated with the INLA package. The main references for excursions are Bolin and Lindgren (2015) <doi:10.1111/rssb.12055>, Bolin and Lindgren (2017) <doi:10.1080/10618600.2016.1228537>, and Bolin and Lindgren (2018) <doi:10.18637/jss.v086.i05>. These can be generated by the citation function in R.",2021-09-17,David Bolin,https://github.com/davidbolin/excursions,TRUE,https://github.com/davidbolin/excursions,21828,0,2022-06-12T10:52:44Z,NA
exdex,"Performs frequentist inference for the extremal index of a 
    stationary time series.  Two types of methodology are used.  One type is
    based on a model that relates the distribution of block maxima to the 
    marginal distribution of series and leads to the semiparametric maxima 
    estimators described in Northrop (2015) <doi:10.1007/s10687-015-0221-5> and 
    Berghaus and Bucher (2018) <doi:10.1214/17-AOS1621>.  Sliding block maxima
    are used to increase precision of estimation. A graphical block size 
    diagnostic is provided.  The other type of methodology uses a model for the 
    distribution of threshold inter-exceedance times (Ferro and Segers (2003) 
    <doi:10.1111/1467-9868.00401>). Three versions of this type of approach are 
    provided: the iterated weight least squares approach of Suveges (2007) 
    <doi:10.1007/s10687-007-0034-2>, the K-gaps model of 
    Suveges and Davison (2010) <doi:10.1214/09-AOAS292> and a similar approach
    of Holesovsky, J. and Fusek, M. (2020) <doi:10.1007/s10687-020-00374-3> 
    that we refer to as D-gaps. For the K-gaps and D-gaps models this package 
    allows missing values in the data, can accommodate independent subsets of 
    data, such as monthly or seasonal time series from different years, and can 
    incorporate information from right-censored inter-exceedance times.  
    Graphical diagnostics for the threshold level and the respective tuning
    parameters K and D are provided.",2022-04-16,Paul J. Northrop,"https://github.com/paulnorthrop/exdex,
https://paulnorthrop.github.io/exdex/",TRUE,https://github.com/paulnorthrop/exdex,14211,0,2022-05-07T10:26:46Z,NA
exoplanets,"The goal of exoplanets is to provide access to
    NASA's Exoplanet Archive TAP Service. For more information regarding
    the API please read the documentation
    <https://exoplanetarchive.ipac.caltech.edu/index.html>.",2021-07-24,Tyler Littlefield,"https://docs.ropensci.org/exoplanets/,
https://github.com/ropensci/exoplanets",TRUE,https://github.com/ropensci/exoplanets,5790,11,2021-07-24T19:30:00Z,526.3636363636364
expDB,"A SQLite database is designed to store all information 
  of experiment-based data including metadata, experiment design, 
  managements, phenotypic values and climate records. The dataset can be
  imported from an excel file.",2021-10-08,Bangyou Zheng,"https://expdb.bangyou.me/, https://github.com/byzheng/expdb",TRUE,https://github.com/byzheng/expdb,3112,0,2022-06-14T05:00:40Z,NA
experDesign,"Distributes samples in batches while making batches homogeneous 
    according to their description. Allows for an arbitrary number of variables, 
    both numeric and categorical. For quality control it provides functions to 
    subset a representative sample.",2021-04-22,Lluís Revilla Sancho,"https://experdesign.llrs.dev, https://github.com/llrs/experDesign/",TRUE,https://github.com/llrs/experdesign,8163,7,2022-05-18T22:24:16Z,1166.142857142857
experiment,"Provides various statistical methods for
  designing and analyzing randomized experiments. One functionality
  of the package is the implementation of randomized-block and
  matched-pair designs based on possibly multivariate pre-treatment
  covariates. The package also provides the tools to analyze various
  randomized experiments including cluster randomized experiments,
  two-stage randomized experiments, randomized experiments with 
  noncompliance, and randomized experiments with missing data.",2022-04-12,Kosuke Imai,https://github.com/kosukeimai/experiment,TRUE,https://github.com/kosukeimai/experiment,21216,7,2022-04-08T12:22:48Z,3030.8571428571427
expirest,"The Australian Regulatory Guidelines for Prescription
    Medicines (ARGPM), guidance on ""Stability testing for prescription
    medicines""
    <https://www.tga.gov.au/stability-testing-prescription-medicines>,
    recommends to predict the shelf life of chemically derived medicines
    from stability data by taking the worst case situation at batch
    release into account. Consequently, if a change over time is observed,
    a release limit needs to be specified. Finding a release limit and the
    associated shelf life is supported, as well as the standard approach
    that is recommended by guidance Q1E ""Evaluation of stability data""
    from the International Council for Harmonisation (ICH)
    <https://database.ich.org/sites/default/files/Q1E%20Guideline.pdf>.",2022-06-01,Pius Dahinden,https://github.com/piusdahinden/expirest,TRUE,https://github.com/piusdahinden/expirest,2030,0,2022-06-01T07:18:37Z,NA
explor,Shiny interfaces and graphical functions for multivariate analysis results exploration.,2021-06-01,Julien Barnier,https://juba.github.io/explor/,TRUE,https://github.com/juba/explor,40546,173,2022-02-11T16:59:15Z,234.36994219653178
explore,"Interactive data exploration with one line of code or use an easy 
    to remember set of tidy functions for exploratory data analysis. 
    Introduces three main verbs. explore() to graphically explore a variable or 
    table, describe() to describe a variable or table and report() to create an 
    automated report.",2022-01-30,Roland Krasser,https://github.com/rolkra/explore/,TRUE,https://github.com/rolkra/explore,44139,83,2022-01-29T13:00:21Z,531.7951807228916
expss,"Package computes and displays tables with support for 'SPSS'-style 
        labels, multiple and nested banners, weights, multiple-response variables 
        and significance testing. There are facilities for nice output of tables 
        in 'knitr', 'Shiny', '*.xlsx' files, R and 'Jupyter' notebooks. Methods 
        for labelled variables add value labels support to base R functions and to 
        some functions from other packages. Additionally, the package brings 
        popular data transformation functions from 'SPSS' Statistics and 'Excel': 
        'RECODE', 'COUNT', 'COUNTIF', 'VLOOKUP' and etc. 
        These functions are very useful for data processing in marketing research 
        surveys. Package intended to help people to move data 
        processing from 'Excel' and 'SPSS' to R.",2022-01-07,Gregory Demin,https://gdemin.github.io/expss/,TRUE,https://github.com/gdemin/expss,265774,71,2022-01-06T19:32:11Z,3743.2957746478874
expstudy,"Provides a data class of 'tbl_es' to help aid in the formation and
    analyses of recurrent or novel experience studies. A 'tbl_es' has attributes
    which identify the key variables used for calculating metrics under an 
    actuarial perspective. Common metrics (such as actual-to-expected analysis) 
    can be quickly generated in aggregate or according to different qualitative 
    factors. If multiple factors are of interest, grouped metrics can be 
    automatically computed for each factor individually as well as for all 
    possible combinations. All resulting output can then be formatted for 
    presentations or left unformatted for subsequent analyses. Ultimately, this
    package aims to reduce time spent completing repetitive code therefore 
    increasing time for analysis and insight.",2022-04-25,Cody Buehler,"https://github.com/cb12991/expstudy,
https://cb12991.github.io/expstudy/",TRUE,https://github.com/cb12991/expstudy,1546,1,2022-04-28T18:40:50Z,1546
extraoperators,"Speed up common tasks, particularly logical or
  relational comparisons and routine follow up tasks such as finding the
  indices and subsetting. Inspired by mathematics, where something like:
  3 < x < 6 is a standard, elegant and clear way to assert that
  x is both greater than 3 and less than 6
  (see for example <https://en.wikipedia.org/wiki/Relational_operator>),
  a chaining operator is implemented. The chaining operator, %c%,
  allows multiple relational operations to be used in quotes on the right
  hand side for the same object, on the left hand side.
  The %e% operator allows something like set-builder notation 
  (see for example <https://en.wikipedia.org/wiki/Set-builder_notation>) 
  to be used on the right hand side.
  All operators have built in prefixes defined for all, subset, and which
  to reduce the amount of code needed for common tasks, such as return those
  values that are true.",2019-11-04,Joshua F. Wiley,"http://joshuawiley.com/extraoperators,
https://github.com/JWiley/extraoperators",TRUE,https://github.com/jwiley/extraoperators,21947,3,2022-05-10T10:57:10Z,7315.666666666667
extras,"Functions to 'numericise' 'R' objects (coerce to numeric
    objects), summarise 'MCMC' (Monte Carlo Markov Chain) samples and
    calculate deviance residuals as well as 'R' translations of some
    'BUGS' (Bayesian Using Gibbs Sampling), 'JAGS' (Just Another Gibbs
    Sampler), 'STAN' and 'TMB' (Template Model Builder) functions.",2022-06-08,Joe Thorley,"https://poissonconsulting.github.io/extras/,
https://github.com/poissonconsulting/extras",TRUE,https://github.com/poissonconsulting/extras,24010,5,2022-06-17T22:05:49Z,4802
exuber,"Testing for and dating periods of explosive
    dynamics (exuberance) in time series using the univariate and panel
    recursive unit root tests proposed by Phillips et al. (2015)
    <doi:10.1111/iere.12132> and Pavlidis et al. (2016)
    <doi:10.1007/s11146-015-9531-2>.  The recursive least-squares
    algorithm utilizes the matrix inversion lemma to avoid matrix
    inversion which results in significant speed improvements. Simulation
    of a variety of periodically-collapsing bubble processes.",2020-12-18,Kostas Vasilopoulos,https://github.com/kvasilopoulos/exuber,TRUE,https://github.com/kvasilopoulos/exuber,17336,18,2021-07-16T14:52:59Z,963.1111111111111
eye,"There is no ophthalmic researcher who has not had headaches from 
    the handling of visual acuity entries. Different notations, untidy entries. 
    This shall now be a matter of the past. Eye makes it as easy as pie to work
    with VA data - easy cleaning, easy conversion between 
    Snellen, logMAR, ETDRS letters, and qualitative visual acuity 
    shall never pester you again. The eye 
    package automates the pesky task to count number of patients and eyes, 
    and can help to clean data with easy re-coding for right and left eyes. 
    It also contains functions to help reshaping eye side specific variables 
    between wide and long format. Visual acuity conversion is based on 
    Schulze-Bonsel et al. (2006) <doi:10.1167/iovs.05-0981>, 
    Gregori et al. (2010) <doi:10.1097/iae.0b013e3181d87e04>, 
    Beck et al. (2003) <doi:10.1016/s0002-9394(02)01825-1> and 
    Bach (2007) <http:michaelbach.de/sci/acuity.html>.",2021-09-04,Tjebo Heeren,https://github.com/tjebo/eye,TRUE,https://github.com/tjebo/eye,7417,4,2022-01-18T18:43:14Z,1854.25
eyetrackingR,"Addresses tasks along the pipeline from raw
    data to analysis and visualization for eye-tracking data. Offers several
    popular types of analyses, including linear and growth curve time analyses,
    onset-contingent reaction time analyses, as well as several non-parametric
    bootstrapping approaches. For references to the approach see Mirman, 
    Dixon & Magnuson (2008) <doi:10.1016/j.jml.2007.11.006>, and
    Barr (2008) <doi:10.1016/j.jml.2007.09.002>.",2021-09-27,Samuel Forbes,http://www.eyetracking-r.com/,TRUE,https://github.com/samhforbes/eyetrackingr,14766,12,2022-04-05T15:31:38Z,1230.5
ezcox,"A tool to operate a batch of univariate or multivariate Cox
    models and return tidy result.",2021-10-28,Shixiang Wang,https://github.com/ShixiangWang/ezcox,TRUE,https://github.com/shixiangwang/ezcox,19143,15,2022-05-27T07:48:12Z,1276.2
fabisearch,"Implementation of the Factorized Binary Search (FaBiSearch) methodology for the estimation of the number and the location of multiple change points in the network (or clustering) structure of multivariate high-dimensional time series. The method is motivated by the detection of change points in functional connectivity networks for functional magnetic resonance imaging (fMRI) data. FaBiSearch uses non-negative matrix factorization (NMF), an unsupervised dimension reduction technique, and a new binary search algorithm to identify multiple change points.  It requires minimal assumptions. Lastly, we provide interactive, 3-dimensional, brain-specific network visualization capability in a flexible, stand-alone function. This function can be conveniently used with any node coordinate atlas, and nodes can be color coded according to community membership, if applicable. The output is an elegantly displayed network laid over a cortical surface, which can be rotated in the 3-dimensional space. The main routines of the package are detect.cps(), for multiple change point detection, est.net(), for estimating a network between stationary multivariate time series, net.3dplot(), for plotting the estimated functional connectivity networks, and opt.rank(), for finding the optimal rank in NMF for a given data set. The functions have been extensively tested on simulated multivariate high-dimensional time series data and fMRI data. For details on the FaBiSearch methodology, please see Ondrus et al. (2021) <arXiv:2103.06347>. For a more detailed explanation and applied examples of the fabisearch package, please see Ondrus and Cribben (2022), preprint.",2022-03-15,Martin Ondrus,https://github.com/mondrus96/FaBiSearch,TRUE,https://github.com/mondrus96/fabisearch,5059,0,2022-03-15T21:40:21Z,NA
fable,"Provides a collection of commonly used univariate and multivariate
    time series forecasting models including automatically selected exponential 
    smoothing (ETS) and autoregressive integrated moving average (ARIMA) models.
    These models work within the 'fable' framework provided by the 'fabletools'
    package, which provides the tools to evaluate, visualise, and combine models 
    in a workflow consistent with the tidyverse.",2021-05-16,Mitchell OHara-Wild,"https://fable.tidyverts.org, https://github.com/tidyverts/fable",TRUE,https://github.com/tidyverts/fable,273785,481,2022-06-15T06:13:59Z,569.1995841995843
fable.ata,"Allows ATA (Automatic Time series analysis using the Ata method) models from the 'ATAforecasting' package to be used in a tidy workflow with the modeling interface of
    'fabletools'. This extends 'ATAforecasting' to provide enhanced model specification and management, performance evaluation methods, and
    model combination tools. The Ata method (Yapar et al. (2019) <doi:10.15672/hujms.461032>), an alternative to exponential smoothing (described in Yapar (2016) 
    <doi:10.15672/HJMS.201614320580>, Yapar et al. (2017) <doi:10.15672/HJMS.2017.493>), is a new univariate time series forecasting method which provides 
    innovative solutions to issues faced during the initialization and optimization stages of existing forecasting methods. 
    Forecasting performance of the Ata method is superior to existing methods both in terms of easy implementation and accurate forecasting. 
    It can be applied to non-seasonal or seasonal time series which can be decomposed into four components (remainder, level, trend and seasonal).",2021-12-09,Ali Sabri Taylan,https://alsabtay.github.io/fable.ata/,TRUE,https://github.com/alsabtay/fable.ata,1890,3,2021-12-08T11:22:18Z,630
fable.prophet,"Allows prophet models from the 'prophet' package to be used in a tidy workflow with the modelling interface of 'fabletools'. This extends 'prophet' to provide enhanced model specification and management, performance evaluation methods, and model combination tools.",2020-08-20,Mitchell OHara-Wild,https://pkg.mitchelloharawild.com/fable.prophet/,TRUE,https://github.com/mitchelloharawild/fable.prophet,23385,51,2022-04-25T07:33:27Z,458.52941176470586
fabletools,"Provides tools, helpers and data structures for
    developing models and time series functions for 'fable' and extension
    packages. These tools support a consistent and tidy interface for time
    series modelling and analysis.",2021-11-29,Mitchell OHara-Wild,"https://fabletools.tidyverts.org/,
https://github.com/tidyverts/fabletools",TRUE,https://github.com/tidyverts/fabletools,320656,84,2022-06-13T09:20:21Z,3817.3333333333335
fabricatr,"Helps you imagine your data before you collect it. Hierarchical data structures
   and correlated data can be easily simulated, either from random number generators or
   by resampling from existing data sources. This package is faster with 'data.table' and
   'mvnfast' installed.",2022-06-29,Graeme Blair,"https://declaredesign.org/r/fabricatr/,
https://github.com/DeclareDesign/fabricatr",TRUE,https://github.com/declaredesign/fabricatr,56350,88,2022-06-29T01:15:28Z,640.3409090909091
factiv,Implements instrumental variable estimators for 2^K factorial experiments with noncompliance.,2021-05-21,Matthew Blackwell,https://github.com/mattblackwell/factiv,TRUE,https://github.com/mattblackwell/factiv,4531,1,2021-12-01T19:42:56Z,4531
FactorAssumptions,"Tests for Kaiser-Meyer-Olkin (KMO) and
    communalities in a dataset. It provides a final sample by removing
    variables in a iterable manner while keeping account of the variables
    that were removed in each step. It follows the best practices and assumptions according to
    Hair, Black, Babin & Anderson (2018, ISBN:9781473756540).",2022-03-08,Jose Storopoli,https://github.com/storopoli/FactorAssumptions,TRUE,https://github.com/storopoli/factorassumptions,9793,3,2022-03-08T08:57:43Z,3264.3333333333335
factorEx,"Provides design-based and model-based estimators for the population average marginal component effects in general factorial experiments, including conjoint analysis. The package also implements a series of recommendations offered in de la Cuesta, Egami, and Imai (2019+), and Egami and Imai (2019) <doi:10.1080/01621459.2018.1476246>.",2020-05-11,Naoki Egami,https://github.com/naoki-egami/factorEx,TRUE,https://github.com/naoki-egami/factorex,14173,6,2022-05-01T18:45:26Z,2362.1666666666665
factset.analyticsapi.engines,"Allow clients to fetch 'analytics' through API for Portfolio 
    'Analytics'('PA'), Style Performance Risk('SPAR') and 'Vault' products of 
    'FactSet'. Visit 
    <https://github.com/factset/analyticsapi-engines-r-sdk/tree/master/Engines>
    for more information on the usage of package. Visit 
    <https://developer.factset.com/> for more information on products.",2020-02-02,Akshay Sheth,https://github.com/factset/analyticsapi-engines-r-sdk,TRUE,https://github.com/factset/analyticsapi-engines-r-sdk,11779,3,2022-02-22T12:58:23Z,3926.3333333333335
factset.protobuf.stach.v2,"Generates 'RProtobuf' classes for 'FactSet' 'STACH V2' tabular 
    format which represents complex multi-dimensional array of data. These 
    classes help in the 'serialization' and 'deserialization' of 'STACH V2' 
    formatted data. See 'GitHub' repository documentation for more 
    information.",2022-02-02,analytics-reporting,https://github.com/factset/stachschema-sdks,TRUE,https://github.com/factset/stachschema-sdks,1654,0,2022-07-07T11:27:39Z,NA
factset.protobuf.stachextensions,"Allow clients to convert 'FactSet' 'STACH' formatted data to simpler 
    tabular formats in the form of data frames. This package also provides helper
    methods to extract the meta data from 'FactSet' 'STACH' formatted
    data. See documentation on the 'GitHub' repository for more information.",2022-02-14,analytics-api,https://github.com/factset/stach-extensions,TRUE,https://github.com/factset/stach-extensions,1173,1,2022-06-21T04:30:39Z,1173
fad,"Compute maximum likelihood estimators of parameters in a Gaussian factor model using
  the the matrix-free methodology described in Dai et al. (2020) <doi:10.1080/10618600.2019.1704296>.
  In contrast to the factanal() function from 'stats' package, fad() can handle high-dimensional datasets where
  number of variables exceed the sample size and is also substantially faster than the EM algorithms.",2022-05-01,Somak Dutta,https://github.com/somakd/fad,TRUE,https://github.com/somakd/fad,14253,3,2022-05-01T19:13:20Z,4751
FAdist,Probability distributions that are sometimes useful in hydrology.,2022-03-03,Francois Aucoin,https://github.com/tpetzoldt/FAdist,TRUE,https://github.com/tpetzoldt/fadist,34149,4,2022-03-03T15:48:00Z,8537.25
fairadapt,"An implementation of the fair data adaptation with quantile
    preservation described in Plecko & Meinshausen (2019) <arXiv:1911.06685>.
    The adaptation procedure uses the specified causal graph to pre-process the
    given training and testing data in such a way to remove the bias caused by
    the protected attribute. The procedure uses tree ensembles for quantile
    regression.",2022-07-01,Drago Plecko,https://github.com/dplecko/fairadapt,TRUE,https://github.com/dplecko/fairadapt,13486,0,2022-07-01T15:05:03Z,NA
fairmodels,"Measure fairness metrics in one place for many models. Check how big is model's bias towards different races, sex, nationalities etc. Use measures such as Statistical Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various pre-processing and post-processing bias mitigation algorithms implemented. Package also supports calculating fairness metrics for regression models. Find more details in (Wiśniewski, Biecek (2021)) <arXiv:2104.00507>.  ",2021-10-08,Jakub Wiśniewski,https://fairmodels.drwhy.ai/,TRUE,https://github.com/modeloriented/fairmodels,12028,68,2021-10-08T10:53:45Z,176.88235294117646
fairness,"Offers calculation, visualization and comparison of algorithmic fairness metrics. Fair machine learning is an emerging topic with the overarching aim to critically assess whether ML algorithms reinforce existing social biases. Unfair algorithms can propagate such biases and produce predictions with a disparate impact on various sensitive groups of individuals (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities). Fair algorithms possess the underlying foundation that these groups should be treated similarly or have similar prediction outcomes. The fairness R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. These methods are described by Calders and Verwer (2010) <doi:10.1007/s10618-010-0190-x>, Chouldechova (2017) <doi:10.1089/big.2016.0047>, Feldman et al. (2015) <doi:10.1145/2783258.2783311> , Friedler et al. (2018) <doi:10.1145/3287560.3287589> and Zafar et al. (2017) <doi:10.1145/3038912.3052660>. The package also offers convenient visualizations to help understand fairness metrics.",2021-04-14,Nikita Kozodoi,https://kozodoi.me/r/fairness/packages/2020/05/01/fairness-tutorial.html,TRUE,https://github.com/kozodoi/fairness,17324,24,2022-01-27T11:36:59Z,721.8333333333334
fakmct,"A set of function for clustering data observation with hybrid method Fuzzy ART and K-Means 
            by Sengupta, Ghosh & Dan (2011) <doi:10.1080/0951192X.2011.602362>.",2022-06-22,"Alfi Nurrahmah 
        Budi Yuniarto",<https://github.com/alfinurrahmah/fakmct>,TRUE,https://github.com/alfinurrahmah/fakmct,233,1,2022-06-29T13:55:51Z,233
familial,"Provides functionality for testing familial hypotheses. Supports testing centers 
    belonging to the Huber family. Testing is carried out using the Bayesian bootstrap. One- and 
    two-sample tests are supported, as are directional tests. Methods for visualizing output are 
    provided.",2022-05-04,Ryan Thompson,https://github.com/ryan-thompson/familial,TRUE,https://github.com/ryan-thompson/familial,1651,2,2022-05-04T05:56:52Z,825.5
familiar,"Single unified interface for end-to-end modelling of regression, 
    categorical and time-to-event (survival) outcomes. Models created using
    familiar are self-containing, and their use does not require additional
    information such as baseline survival, feature clustering, or feature
    transformation and normalisation parameters. Model performance,
    calibration, risk group stratification, (permutation) variable importance,
    individual conditional expectation, partial dependence, and more, are
    assessed automatically as part of the evaluation process and exported in
    tabular format and plotted, and may also be computed manually using export
    and plot functions. Where possible, metrics and values obtained during the
    evaluation process come with confidence intervals.",2022-04-07,Alex Zwanenburg,https://github.com/alexzwanenburg/familiar,TRUE,https://github.com/alexzwanenburg/familiar,1745,11,2022-07-04T12:09:38Z,158.63636363636363
Families,"Tools to study kinship networks, grandparenthood, and double burden (presence of children and oldest old parents) in virtual population produced by 'VirtualPop'.",2022-07-08,Frans Willekens,NA,TRUE,https://github.com/willekens/virtualpop,6,2,2022-07-08T07:45:07Z,3
FAmle,"Estimate parameters of univariate probability distributions 
  with maximum likelihood and Bayesian methods.",2022-03-04,Francois Aucoin,https://github.com/tpetzoldt/FAmle,TRUE,https://github.com/tpetzoldt/famle,17640,0,2022-03-04T00:09:05Z,NA
fanplot,"Visualise sequential distributions using a range of plotting
    styles. Sequential distribution data can be input as either simulations or
    values corresponding to percentiles over time. Plots are added to
    existing graphic devices using the fan function. Users can choose from four
    different styles, including fan chart type plots, where a set of coloured
    polygon, with shadings corresponding to the percentile values are layered
    to represent different uncertainty levels. Full details in R Journal article; Abel (2015) <doi:10.32614/RJ-2015-002>.",2021-08-02,Guy J. Abel,http://guyabel.github.io/fanplot/,TRUE,https://github.com/guyabel/fanplot,44758,2,2022-05-02T05:08:48Z,22379
fansi,"Counterparts to R string manipulation functions that account for
   the effects of ANSI text formatting control sequences.",2022-03-24,Brodie Gaslam,https://github.com/brodieG/fansi,TRUE,https://github.com/brodieg/fansi,25029246,50,2022-03-24T11:17:33Z,500584.92
farver,"The encoding of colour can be handled in many different ways,
    using different colour spaces. As different colour spaces have
    different uses, efficient conversion between these representations are
    important. The 'farver' package provides a set of functions that gives
    access to very fast colour space conversion and comparisons
    implemented in C++, and offers speed improvements over the
    'convertColor' function in the 'grDevices' package.",2022-07-06,Thomas Lin Pedersen,"https://farver.data-imaginist.com,
https://github.com/thomasp85/farver",TRUE,https://github.com/thomasp85/farver,17987194,83,2022-07-06T17:48:32Z,216713.18072289156
fasano.franceschini.test,"An implementation of the two-sample multidimensional
    Kolmogorov-Smirnov test described by Fasano and Franceschini (1987)
    <doi:10.1093/mnras/225.1.155>. This test evaluates the null hypothesis
    that two i.i.d. random samples were drawn from the same underlying
    probability distribution. The data can be of any dimension, and can be
    of any type (continuous, discrete, or mixed).",2022-05-29,Connor Puritz,https://github.com/nesscoder/fasano.franceschini.test,TRUE,https://github.com/nesscoder/fasano.franceschini.test,5118,3,2022-05-30T04:25:12Z,1706
fasstr,"The Flow Analysis Summary Statistics Tool for R, 'fasstr', provides various 
    functions to tidy and screen daily stream discharge data, calculate and visualize various summary statistics
    and metrics, and compute annual trending and volume frequency analyses. It features useful function arguments 
    for filtering of and handling dates, customizing data and metrics, and the ability to pull daily data directly 
    from the Water Survey of Canada hydrometric database (<https://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/>).",2021-12-10,Jon Goetz,"https://bcgov.github.io/fasstr/, https://github.com/bcgov/fasstr,
https://www2.gov.bc.ca/gov/content/environment/air-land-water/water",TRUE,https://github.com/bcgov/fasstr,18316,45,2022-07-04T21:02:23Z,407.02222222222224
fastadi,"Implements the AdaptiveImpute matrix completion
    algorithm of 'Intelligent Initialization and Adaptive Thresholding for
    Iterative Matrix Completion',
    <https://amstat.tandfonline.com/doi/abs/10.1080/10618600.2018.1518238>.
    AdaptiveImpute is useful for embedding sparsely observed matrices,
    often out performs competing matrix completion algorithms, and
    self-tunes its hyperparameter, making usage easy.",2022-02-11,Alex Hayes,https://github.com/RoheLab/fastadi,TRUE,https://github.com/rohelab/fastadi,1207,9,2022-02-16T19:36:37Z,134.11111111111111
fastai,"The 'fastai' <https://docs.fast.ai/index.html> library 
             simplifies training fast and accurate neural networks 
             using modern best practices. It is based on research 
             in to deep learning best practices undertaken 
             at 'fast.ai', including 'out of the box' support
             for vision, text, tabular, audio, time series, and 
             collaborative filtering models. ",2022-03-21,Turgut Abdullayev [ctb,https://github.com/EagerAI/fastai,TRUE,https://github.com/eagerai/fastai,18186,112,2022-03-25T07:08:51Z,162.375
fastDummies,"Creates dummy columns from columns that have categorical variables (character or factor types). You can also specify which columns to make dummies out of, or which columns to ignore. Also creates dummy rows from character, factor, and Date columns. This package provides a significant speed increase from creating dummy variables through model.matrix().",2020-11-29,Jacob Kaplan,"https://github.com/jacobkap/fastDummies,
https://jacobkap.github.io/fastDummies/",TRUE,https://github.com/jacobkap/fastdummies,769097,33,2021-10-12T16:30:51Z,23305.969696969696
fastGHQuad,"Fast, numerically-stable Gauss-Hermite quadrature rules and
    utility functions for adaptive GH quadrature. See Liu, Q. and Pierce, D. A.
    (1994) <doi:10.2307/2337136> for a reference on these methods.",2022-05-05,Alexander W Blocker,https://github.com/awblocker/fastGHQuad,TRUE,https://github.com/awblocker/fastghquad,177006,8,2022-05-05T17:17:40Z,22125.75
fastglm,"Fits generalized linear models efficiently using 'RcppEigen'. The iteratively reweighted least squares 
    implementation utilizes the step-halving approach of Marschner (2011) <doi:10.32614/RJ-2011-012> to help safeguard
    against convergence issues.",2022-05-23,Jared Huling,NA,TRUE,https://github.com/jaredhuling/fastglm,38990,47,2022-05-23T16:31:04Z,829.5744680851063
fasthplus,"Estimation procedures for assessing fitness of observation labels (i.e., clusters or partitions) given observation dissimilarities, or vice versa. The estimated parameter of interest is modified from G+ (Williams 1971), so we call it H+.",2022-02-07,Nathan Dyjack,https://github.com/ntdyjack/fasthplus/,TRUE,https://github.com/ntdyjack/fasthplus,1428,1,2022-02-03T18:24:40Z,1428
fastLink,"Implements a Fellegi-Sunter probabilistic record linkage model that allows for missing data
    and the inclusion of auxiliary information. This includes functionalities to conduct a merge of two 
    datasets under the Fellegi-Sunter model using the Expectation-Maximization algorithm. In addition, 
    tools for preparing, adjusting, and summarizing data merges are included. The package implements methods 
    described in Enamorado, Fifield, and Imai (2019) ''Using a Probabilistic Model to Assist Merging of 
    Large-scale Administrative Records'', American Political Science Review and is available 
    at <http://imai.fas.harvard.edu/research/linkage.html>.",2020-04-29,Ted Enamorado,NA,TRUE,https://github.com/kosukeimai/fastlink,22627,205,2021-11-26T18:58:43Z,110.37560975609756
fastmap,"Fast implementation of data structures, including a key-value
    store, stack, and queue. Environments are commonly used as key-value stores
    in R, but every time a new key is used, it is added to R's global symbol
    table, causing a small amount of memory leakage. This can be problematic in
    cases where many different keys are used. Fastmap avoids this memory leak
    issue by implementing the map using data structures in C++.",2021-01-25,Winston Chang,"https://r-lib.github.io/fastmap/, https://github.com/r-lib/fastmap",TRUE,https://github.com/r-lib/fastmap,12798028,108,2021-11-16T14:36:06Z,118500.25925925926
fastqq,"New and faster implementations for quantile quantile plots. 
    The package also includes a function to prune data for quantile quantile 
    plots. This can drastically reduce the running time for large samples, 
    for 100 million samples, you can expect a factor 80X speedup.",2021-08-19,Gudmundur Einarsson,https://github.com/gumeo/fastqq,TRUE,https://github.com/gumeo/fastqq,3064,0,2021-08-21T07:54:34Z,NA
fastR2,"Data sets and utilities to accompany the second edition of
    ""Foundations and Applications of Statistics: an Introduction
    using R"" (R Pruim, published by AMS, 2017), a text covering
    topics from probability and mathematical statistics at an advanced
    undergraduate level.  R is integrated throughout, and access to all
    the R code in the book is provided via the snippet() function.",2022-03-15,Randall Pruim,"https://github.com/rpruim/fastR2, http://rpruim.github.io/fastR2/",TRUE,https://github.com/rpruim/fastr2,21207,10,2022-03-15T23:06:08Z,2120.7
fastRG,"Samples generalized random product graph, a generalization of
    a broad class of network models. Given matrices X, S, and Y with with
    non-negative entries, samples a matrix with expectation X S Y^T and
    independent Poisson or Bernoulli entries using the fastRG algorithm of
    Rohe et al. (2017) <https://www.jmlr.org/papers/v19/17-128.html>. The
    algorithm first samples the number of edges and then puts them down
    one-by-one.  As a result it is O(m) where m is the number of edges, a
    dramatic improvement over element-wise algorithms that which require
    O(n^2) operations to sample a random graph, where n is the number of
    nodes.",2022-06-30,Alex Hayes,"https://rohelab.github.io/fastRG/,
https://github.com/RoheLab/fastRG",TRUE,https://github.com/rohelab/fastrg,5254,2,2022-06-30T13:41:13Z,2627
fastRhockey,"A utility to scrape and load play-by-play data
    and statistics from the Premier Hockey Federation (PHF)<https://www.premierhockeyfederation.com/>, formerly
    known as the National Women's Hockey League (NWHL). Additionally, allows access to the National Hockey League's
    stats API <https://www.nhl.com/>.",2022-03-25,Saiem Gilani,"https://benhowell71.github.io/fastRhockey/,
https://github.com/benhowell71/fastRhockey",TRUE,https://github.com/benhowell71/fastrhockey,2026,13,2022-07-02T09:05:53Z,155.84615384615384
fastrmodels,"A data package that hosts all models for the
    'nflfastR' package.",2021-02-20,Sebastian Carl,https://github.com/mrcaseb/fastrmodels,TRUE,https://github.com/mrcaseb/fastrmodels,16733,1,2022-05-25T11:26:13Z,16733
fastText,"An interface to the 'fastText' <https://github.com/facebookresearch/fastText> library for efficient learning of word representations and sentence classification. The 'fastText' algorithm is explained in detail in (i) ""Enriching Word Vectors with subword Information"", Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov, 2017, <doi:10.1162/tacl_a_00051>; (ii) ""Bag of Tricks for Efficient Text Classification"", Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov, 2017, <doi:10.18653/v1/e17-2068>; (iii) ""FastText.zip: Compressing text classification models"", Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Herve Jegou, Tomas Mikolov, 2016, <arXiv:1612.03651>.",2022-04-07,Lampros Mouselimis,https://github.com/mlampros/fastText,TRUE,https://github.com/mlampros/fasttext,5754,30,2022-06-07T07:01:15Z,191.8
fastTopics,"Implements fast, scalable optimization algorithms for
    fitting topic models (""grade of membership"" models) and
    non-negative matrix factorizations to count data. The methods
    exploit the special relationship between the multinomial topic
    model (also, ""probabilistic latent semantic indexing"") and Poisson
    non-negative matrix factorization. The package provides tools to
    compare, annotate and visualize model fits, including functions to
    efficiently create ""structure plots"" and identify key features in
    topics. The 'fastTopics' package is a successor to the 'CountClust'
    package.",2022-05-27,Peter Carbonetto,https://github.com/stephenslab/fastTopics,TRUE,https://github.com/stephenslab/fasttopics,382,36,2022-05-27T11:33:32Z,10.61111111111111
fastverse,"Easy installation, loading and management, of a complementary set of 
             high-performance packages for statistical computing and data manipulation. 
             The core 'fastverse' consists of 6 packages: 'data.table', 'collapse', 
             'matrixStats', 'kit', 'magrittr' and 'fst', that jointly only depend on 
             'Rcpp'. These packages are attached and harmonized through the 'fastverse'. 
             In addition, the 'fastverse' can be freely and permanently extended with 
             additional packages, both globally or for individual projects. Entirely 
             separate package verses can also be created. Selected fast and low-dependency 
             packages are suggested for various topics such as time series, dates and times, 
             strings, spatial data, statistics and data serialization (see GitHub / website).  ",2022-05-31,Sebastian Krantz,"https://fastverse.github.io/fastverse/,
https://github.com/fastverse/fastverse",TRUE,https://github.com/fastverse/fastverse,7202,111,2022-05-31T20:41:42Z,64.88288288288288
faux,Create datasets with factorial structure through simulation by specifying variable parameters. Extended documentation at <https://debruine.github.io/faux/>. Described in DeBruine (2020) <doi:10.5281/zenodo.2669586>.,2021-09-13,Lisa DeBruine,https://github.com/debruine/faux,TRUE,https://github.com/debruine/faux,24585,71,2022-05-14T11:17:07Z,346.2676056338028
fauxnaif,"Provides a replacement for dplyr::na_if().  Allows you to
    specify multiple values to be replaced with NA using a single
    function.",2022-04-27,Alexander Rossell Hayes,"https://fauxnaif.rossellhayes.com/,
https://github.com/rossellhayes/fauxnaif",TRUE,https://github.com/rossellhayes/fauxnaif,14005,1,2022-04-27T21:35:48Z,14005
faviconPlease,"Finds the URL to the 'favicon' for a website. This is useful if you
  want to display the 'favicon' in an HTML document or web application,
  especially if the website is behind a firewall.",2022-05-07,John Blischak,https://github.com/jdblischak/faviconPlease,TRUE,https://github.com/jdblischak/faviconplease,6234,4,2022-07-05T15:04:30Z,1558.5
fbRads,"Wrapper functions around the Facebook Marketing 'API' to create, read, update and delete custom audiences, images, campaigns, ad sets, ads and related content.",2016-04-06,Ajaykumar Gopal,https://github.com/cardcorp/fbRads,TRUE,https://github.com/cardcorp/fbrads,20359,140,2022-01-04T15:18:20Z,145.42142857142858
fca,"Perform various floating catchment area methods to calculate a
    spatial accessibility index (SPAI) for demand point data. The distance
    matrix used for weighting is normalized in a preprocessing step using
    common functions (gaussian, gravity, exponential or logistic).",2021-12-06,Etienne Grueebler,"https://egrueebler.github.io/fca/,
https://github.com/egrueebler/fca/",TRUE,https://github.com/egrueebler/fca,1932,4,2021-12-06T13:56:34Z,483
fcci,"
	Provides support for building Feldman-Cousins confidence intervals 
	[G. J. Feldman and R. D. Cousins (1998) <doi:10.1103/PhysRevD.57.3873>].",2022-01-07,Valerio Gherardi,"https://github.com/vgherard/fcci, https://vgherard.github.io/fcci/",TRUE,https://github.com/vgherard/fcci,4946,2,2022-01-02T19:38:19Z,2473
fcirt,Bayesian estimation of forced choice models in Item Response Theory using 'rstan' (See Stan Development Team (2020) <https://mc-stan.org/>).,2022-02-01,Naidan Tu,https://github.com/Naidantu/fcirt,TRUE,https://github.com/naidantu/fcirt,1464,1,2022-04-22T01:36:45Z,1464
FCPS,"Over sixty clustering algorithms are provided in this package with consistent input and output, which enables the user to try out algorithms swiftly. Additionally, 26 statistical approaches for the estimation of the number of clusters as well as the mirrored density plot (MD-plot) of clusterability are implemented. The packages is published in Thrun, M.C., Stier Q.: ""Fundamental Clustering Algorithms Suite"" (2021), SoftwareX, <DOI:10.1016/j.softx.2020.100642>. Moreover, the fundamental clustering problems suite (FCPS) offers a variety of clustering challenges any algorithm should handle when facing real world data, see Thrun, M.C., Ultsch A.: ""Clustering Benchmark Datasets Exploiting the Fundamental Clustering Problems"" (2020), Data in Brief, <DOI:10.1016/j.dib.2020.105501>.",2022-05-20,Michael Thrun,https://www.deepbionics.org/,TRUE,https://github.com/mthrun/fcps,25467,7,2022-06-17T09:28:03Z,3638.1428571428573
fctbases,"Easy-to-use, very fast implementation of various functional bases. Easily used together with other packages.
    A functional basis is a collection of basis functions [\phi_1, ..., \phi_n] that can represent a smooth function, i.e. $f(t) = \sum c_k \phi_k(t)$.
    First- and second-order derivatives are also included. These are the mathematically correct ones, no approximations applied.
    As of version 1.1, this package includes B-splines, Fourier bases and polynomials.",2022-05-17,Niels Olsen,https://github.com/naolsen/fctbases,TRUE,https://github.com/naolsen/fctbases,5928,1,2021-12-13T22:25:08Z,5928
FCVAR,"Estimation and inference using the Fractionally Cointegrated 
    Vector Autoregressive (VAR) model. It includes functions for model specification, 
    including lag selection and cointegration rank selection, as well as a comprehensive
    set of options for hypothesis testing, including tests of hypotheses on the 
    cointegrating relations, the adjustment coefficients and the fractional 
    differencing parameters. 
    An article describing the FCVAR model with examples is available on the Webpage 
    <https://sites.google.com/view/mortennielsen/software>.",2022-05-05,Lealand Morin,https://github.com/LeeMorinUCF/FCVAR,TRUE,https://github.com/leemorinucf/fcvar,4329,3,2022-05-04T18:54:02Z,1443
fda.usc,"Routines for exploratory and descriptive analysis of functional data such as depth measurements, atypical curves detection, regression models, supervised classification, unsupervised classification and functional analysis of variance.",2020-02-17,Manuel Oviedo de la Fuente,"https://github.com/moviedo5/fda.usc,
http://www.jstatsoft.org/v51/i04/",TRUE,https://github.com/moviedo5/fda.usc,92194,2,2022-07-06T12:02:22Z,46097
fdacluster,"Revisited clustering approaches to accommodate functional 
    data by allowing to jointly align the data during the clustering 
    process. Currently, shift, dilation and affine transformations 
    only are available to perform alignment. The k-mean algorithm has 
    been extended to integrate alignment and is fully parallelized. 
    Hierarchical clustering will soon be available as well. References: 
    Sangalli L.M., Secchi P., Vantini S., Vitelli V. (2010) ""k-mean 
    alignment for curve clustering"" <doi:10.1016/j.csda.2009.12.008>.",2022-05-09,Aymeric Stamm,"https://astamm.github.io/fdacluster/index.html,
https://github.com/astamm/fdacluster",TRUE,https://github.com/astamm/fdacluster,796,0,2022-05-10T10:49:19Z,NA
fdapace,"A versatile package that provides implementation of various
    methods of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this
    package is Functional Principal Component Analysis (FPCA), a key technique for
    functional data analysis, for sparsely or densely sampled random trajectories
    and time courses, via the Principal Analysis by Conditional Estimation
    (PACE) algorithm. This core algorithm yields covariance and mean functions,
    eigenfunctions and principal component (scores), for both functional data and
    derivatives, for both dense (functional) and sparse (longitudinal) sampling designs.
    For sparse designs, it provides fitted continuous trajectories with confidence bands,
    even for subjects with very few longitudinal observations. PACE is a viable and
    flexible alternative to random effects modeling of longitudinal data. There is also a
    Matlab version (PACE) that contains some methods not available on fdapace and vice
    versa. Updates to fdapace were supported by grants from NIH Echo and NSF DMS-1712864 and DMS-2014626. Please cite our package if you use it (You may run the command citation(""fdapace"") to get the citation format and bibtex entry).
    References: Wang, J.L., Chiou, J., Müller, H.G. (2016) <doi:10.1146/annurev-statistics-041715-033624>;
    Chen, K., Zhang, X., Petersen, A., Müller, H.G. (2017) <doi:10.1007/s12561-015-9137-5>.",2021-11-22,Alvaro Gajardo,https://github.com/functionaldata/tPACE,TRUE,https://github.com/functionaldata/tpace,42699,23,2021-11-22T19:42:12Z,1856.4782608695652
fdapaceShiny,Shiny app for the 'fdapace' package.,2021-11-11,Camden Possinger,https://github.com/cpossinger/fdapaceShiny,TRUE,https://github.com/cpossinger/fdapaceshiny,4211,2,2022-04-21T03:46:30Z,2105.5
fdaPOIFD,"Applications to visualization, outlier detection and classification. Software companion for Elías, Antonio, Jiménez, Raúl, Paganoni, Anna M. and Sangalli, Laura M., (2022), ""Integrated Depth for Partially Observed Functional Data"". Journal of Computational and Graphical Statistics. <doi:10.1080/10618600.2022.2070171>.",2022-05-16,Antonio Elías,https://github.com/aefdz/fdaPOIFD,TRUE,https://github.com/aefdz/fdapoifd,6578,0,2022-05-13T15:56:43Z,NA
fddm,"Provides the probability density function (PDF), cumulative
  distribution function (CDF), and the partial derivatives of the PDF of the
  diffusion decision model (DDM; e.g.,
  Ratcliff & McKoon, 2008, <doi:10.1162/neco.2008.12-06-420>) with across-trial
  variability in the drift rate. Because the PDF, its partial derivatives, and
  the CDF of the DDM both contain an infinite sum, they need to be approximated.
  'fddm' implements all published approximations
  (Navarro & Fuss, 2009, <doi:10.1016/j.jmp.2009.02.003>;
  Gondan, Blurton, & Kesselmeier, 2014, <doi:10.1016/j.jmp.2014.05.002>;
  Blurton, Kesselmeier, & Gondan, 2017, <doi:10.1016/j.jmp.2016.11.003>;
  Hartmann & Klauer, 2021, <doi:10.1016/j.jmp.2021.102550>) plus
  new approximations. All approximations are implemented purely in 'C++'
  providing faster speed than existing packages.",2022-03-15,Kendal B. Foster,https://github.com/rtdists/fddm,TRUE,https://github.com/rtdists/fddm,19874,11,2022-07-05T13:17:05Z,1806.7272727272727
FDX,"Multiple testing procedures for heterogeneous and discrete tests as described in Döhler and Roquain (2019) <arXiv:1912.04607v1>. The main algorithms of the paper are available as continuous, discrete and weighted versions.",2022-01-19,Florian Junge,https://github.com/DISOhda/FDX,TRUE,https://github.com/disohda/fdx,13816,1,2022-01-19T10:32:13Z,13816
feamiR,"Comprises a pipeline for predicting microRNA/mRNA interactions, as detailed in Williams, Calinescu, Mohorianu (2020) <doi:10.1101/2020.12.23.424130>. Its input consists of [a] a messenger RNA (mRNA) dataset (either in fasta format, focused on 3' UTRs or in gtf format; for the latter, the sequences of the 3’ UTRs are generated using the genomic coordinates), [b] a microRNA dataset (in fasta format, retrieved from miRBase,  <http://www.mirbase.org/>) and [c] an interaction dataset (in csv format, from miRTarBase <http://mirtarbase.cuhk.edu.cn/php/index.php>). To characterise and predict microRNA/mRNA interactions, we use [a] statistical analyses based on Chi-squared and Fisher exact tests and [b] Machine Learning classifiers (decision trees, random forests and support vector machines). To enhance the accuracy of the classifiers we also employ feature selection approaches used in on conjunction with the classifiers. The feature selection approaches include a voting scheme for decision trees, a measure based on Gini index for random forests, forward feature selection and Genetic Algorithms on SVMs. The pipeline also includes a novel approach based on embryonic Genetic Algorithms which combines and optimises the forward feature selection and Genetic Algorithms. All analyses, including the classification and feature selection, are applicable on the microRNA seed features (default), on the full microRNA features and/or flanking features on the mRNA. The sets of features can be combined. ",2021-01-19,Eleanor Williams,https://github.com/Core-Bioinformatics/feamiR,TRUE,https://github.com/core-bioinformatics/feamir,5587,1,2021-10-14T14:35:45Z,5587
feasts,"Provides a collection of features, decomposition methods, 
    statistical summaries and graphics functions for the analysing tidy time
    series data. The package name 'feasts' is an acronym comprising of its key
    features: Feature Extraction And Statistics for Time Series.",2021-06-03,Mitchell OHara-Wild,"http://feasts.tidyverts.org/, https://github.com/tidyverts/feasts/",TRUE,https://github.com/tidyverts/feasts,264544,264,2022-01-26T00:49:10Z,1002.060606060606
febr,"
  Utilities to access and process data from the
  Data Repository of the Brazilian Soil
  <https://www.pedometria.org/febr/>.",2022-02-28,Alessandro Samuel-Rosa,https://github.com/laboratorio-de-pedometria/febr-package/,TRUE,https://github.com/laboratorio-de-pedometria/febr-package,9927,9,2022-04-16T19:01:55Z,1103
fec16,"Easily analyze relational data from the United States 2016 federal 
    election cycle as reported by the Federal Election Commission.
    This package contains data about candidates, committees, and a
    variety of different financial expenditures. Data is from <https://www.fec.gov/data/browse-data/?tab=bulk-data>. ",2020-11-15,Marium Tapal,https://github.com/baumer-lab/fec16,TRUE,https://github.com/baumer-lab/fec16,11504,2,2022-04-26T13:32:36Z,5752
FedData,"Functions to automate downloading geospatial data available from
    several federated data sources (mainly sources maintained by the US Federal
    government). Currently, the package enables extraction from seven datasets:
    The National Elevation Dataset digital elevation models (1 and 1/3 arc-second;
    USGS); The National Hydrography Dataset (USGS); The Soil Survey Geographic
    (SSURGO) database from the National Cooperative Soil Survey (NCSS), which is
    led by the Natural Resources Conservation Service (NRCS) under the USDA; the
    Global Historical Climatology Network (GHCN), coordinated by National Climatic
    Data Center at NOAA; the Daymet gridded estimates of daily weather parameters 
    for North America, version 3, available from the Oak Ridge National Laboratory's
    Distributed Active Archive Center (DAAC); the International Tree Ring Data Bank; 
    and the National Land Cover Database (NLCD).",2019-04-22,R. Kyle Bocinsky,https://github.com/ropensci/FedData,TRUE,https://github.com/ropensci/feddata,30558,75,2022-03-08T17:50:57Z,407.44
fedstatAPIr,"An API for automatic data queries to the fedstat <https://www.fedstat.ru>, using a small set of functions with a common interface.",2022-01-14,Denis Krylov,https://github.com/DenchPokepon/fedstatAPIr,TRUE,https://github.com/denchpokepon/fedstatapir,4248,6,2022-01-14T14:21:52Z,708
feisr,"Provides the function feis() to estimate fixed effects individual 
    slope (FEIS) models. The FEIS model constitutes a more general version of 
    the often-used fixed effects (FE) panel model, as implemented in the 
    package 'plm' by Croissant and Millo (2008) <doi:10.18637/jss.v027.i02>. 
    In FEIS models, data are not only person demeaned like in conventional 
    FE models, but detrended by the predicted individual slope of each 
    person or group. Estimation is performed by applying least squares lm() 
    to the transformed data. For more details on FEIS models see Bruederl and 
    Ludwig (2015, ISBN:1446252442); Frees (2001) <doi:10.2307/3316008>; 
    Polachek and Kim (1994) <doi:10.1016/0304-4076(94)90075-2>; 
	Ruettenauer and Ludwig (2020) <doi:10.1177/0049124120926211>;
    Wooldridge (2010, ISBN:0262294354). To test consistency of conventional FE 
    and random effects estimators against heterogeneous slopes, the package 
    also provides the functions feistest() for an artificial regression test 
    and bsfeistest() for a bootstrapped version of the Hausman test.",2022-04-01,Tobias Ruettenauer,https://github.com/ruettenauer/feisr,TRUE,https://github.com/ruettenauer/feisr,56415,7,2022-04-01T13:31:32Z,8059.285714285715
fergm,"Frailty Exponential Random Graph Models estimated through pseudo likelihood with frailty terms estimated using 'Stan' as per Box-Steffensmeier et. al (2017) <doi:10.7910/DVN/K3D1M2>.
    Goodness of fit for Frailty Exponential Random Graph Models is also available, with easy visualizations for comparison to fit Exponential Random Graph Models.  ",2018-10-17,Benjamin W. Campbell,http://github.com/benjamin-w-campbell/fergm,TRUE,https://github.com/benjamin-w-campbell/fergm,16413,3,2022-04-13T23:32:53Z,5471
ferrn,"Diagnostic plots for optimisation, with a focus on projection pursuit. These show paths the optimiser 
    takes in the high-dimensional space in multiple ways: by reducing the dimension using principal component analysis, and
    also using the tour to show the path on the high-dimensional space. Several botanical colour palettes are included, reflecting the 
    name of the package. ",2021-03-17,H. Sherry Zhang,https://github.com/huizezhang-sherry/ferrn/,TRUE,https://github.com/huizezhang-sherry/ferrn,4904,4,2022-04-26T06:13:10Z,1226
ff,"The ff package provides data structures that are stored on
	disk but behave (almost) as if they were in RAM by transparently 
	mapping only a section (pagesize) in main memory - the effective 
	virtual memory consumption per ff object. ff supports R's standard 
	atomic data types 'double', 'logical', 'raw' and 'integer' and 
	non-standard atomic types boolean (1 bit), quad (2 bit unsigned), 
	nibble (4 bit unsigned), byte (1 byte signed with NAs), ubyte (1 byte 
	unsigned), short (2 byte signed with NAs), ushort (2 byte unsigned), 
	single (4 byte float with NAs). For example 'quad' allows efficient 
	storage of genomic data as an 'A','T','G','C' factor. The unsigned 
	types support 'circular' arithmetic. There is also support for 
	close-to-atomic types 'factor', 'ordered', 'POSIXct', 'Date' and 
	custom close-to-atomic types. 
	ff not only has native C-support for vectors, matrices and arrays 
	with flexible dimorder (major column-order, major row-order and 
	generalizations for arrays). There is also a ffdf class not unlike 
	data.frames and import/export filters for csv files.
	ff objects store raw data in binary flat files in native encoding,
	and complement this with metadata stored in R as physical and virtual
	attributes. ff objects have well-defined hybrid copying semantics, 
	which gives rise to certain performance improvements through 
	virtualization. ff objects can be stored and reopened across R 
	sessions. ff files can be shared by multiple ff R objects 
	(using different data en/de-coding schemes) in the same process 
	or from multiple R processes to exploit parallelism. A wide choice of 
	finalizer options allows to work with 'permanent' files as well as 
	creating/removing 'temporary' ff files completely transparent to the 
	user. On certain OS/Filesystem combinations, creating the ff files
	works without notable delay thanks to using sparse file allocation.
	Several access optimization techniques such as Hybrid Index 
	Preprocessing and Virtualization are implemented to achieve good 
	performance even with large datasets, for example virtual matrix 
	transpose without touching a single byte on disk. Further, to reduce 
	disk I/O, 'logicals' and non-standard data types get stored native and 
	compact on binary flat files i.e. logicals take up exactly 2 bits to 
	represent TRUE, FALSE and NA. 
	Beyond basic access functions, the ff package also provides 
	compatibility functions that facilitate writing code for ff and ram 
	objects and support for batch processing on ff objects (e.g. as.ram, 
	as.ff, ffapply). ff interfaces closely with functionality from package 
	'bit': chunked looping, fast bit operations and coercions between 
	different objects that can store subscript information ('bit', 
	'bitwhich', ff 'boolean', ri range index, hi hybrid index). This allows
	to work interactively with selections of large datasets and quickly 
	modify selection criteria. 
	Further high-performance enhancements can be made available upon request. ",2022-05-06,Jens Oehlschlägel,https://github.com/truecluster/ff,TRUE,https://github.com/truecluster/ff,904386,17,2022-05-06T15:47:08Z,53199.17647058824
ffmanova,"General linear modeling with multiple responses (MANCOVA). An overall p-value for each model term is calculated by the 50-50 MANOVA method by Langsrud (2002) <doi:10.1111/1467-9884.00320>, which handles collinear responses. Rotation testing, described by Langsrud (2005) <doi:10.1007/s11222-005-4789-5>, is used to compute adjusted single response p-values according to familywise error rates and false discovery rates (FDR). The approach to FDR is described in the appendix of Moen et al. (2005) <doi:10.1128/AEM.71.4.2086-2094.2005>. Unbalanced designs are handled by Type II sums of squares as argued in Langsrud (2003) <doi:10.1023/A:1023260610025>. Furthermore, the Type II philosophy is extended to continuous design variables as described in Langsrud et al. (2007) <doi:10.1080/02664760701594246>. This means that the method is invariant to scale changes and that common pitfalls are avoided.",2022-03-28,Øyvind Langsrud,https://github.com/olangsrud/ffmanova,TRUE,https://github.com/olangsrud/ffmanova,17752,2,2022-03-28T09:00:56Z,8876
ffp,"Implements numerical entropy-pooling for scenario analysis as
    described in Meucci, Attilio (2010) <doi:10.2139/ssrn.1696802>.",2022-03-24,Bernardo Reckziegel,https://github.com/Reckziegel/FFP,TRUE,https://github.com/reckziegel/ffp,15100,4,2022-03-25T14:27:58Z,3775
ffscrapr,"Helps access various Fantasy Football APIs by handling
    authentication and rate-limiting, forming appropriate calls, and
    returning tidy dataframes which can be easily connected to other data
    sources.",2021-11-10,Tan Ho,"https://ffscrapr.ffverse.com, https://github.com/ffverse/ffscrapr,
https://api.myfantasyleague.com/2020/api_info,
https://docs.sleeper.app,
https://www.fleaflicker.com/api-docs/index.html,
https://www.espn.com/fantasy/,
https://www.nflfastr.com/reference/load_player_stats.html",TRUE,https://github.com/ffverse/ffscrapr,13472,46,2022-06-22T13:57:09Z,292.8695652173913
ffsimulator,"Uses bootstrap resampling to run fantasy football season
    simulations supported by historical rankings and 'nflfastR' data,
    calculating optimal lineups, and returning aggregated results.",2021-12-21,Tan Ho,"https://ffsimulator.ffverse.com,
https://github.com/ffverse/ffsimulator",TRUE,https://github.com/ffverse/ffsimulator,4936,9,2022-05-13T16:36:58Z,548.4444444444445
fgdr,"Read and Parse for Fundamental Geo-Spatial Data (FGD) which downloads XML file 
    from providing site (<https://fgd.gsi.go.jp/download/menu.php>). The JPGIS format file 
    provided by FGD so that it can be handled as an R spatial object such as 'sf' and 
    'raster', 'terra' or 'stars'.
    Supports the FGD version 4.1, and accepts fundamental items and digital elevation models.",2022-02-22,Shinya Uryu,https://github.com/uribo/fgdr,TRUE,https://github.com/uribo/fgdr,15076,7,2022-02-24T00:06:02Z,2153.714285714286
fgitR,'FastGit' <https://doc.fastgit.org/> works like a mirror of 'GitHub' to make significant acceleration. 'fgitR' is a package to do git operation with 'FastGit' automatically.,2022-02-28,Han Chen,NA,TRUE,https://github.com/fastgitorg/fgitr,1062,4,2022-03-01T04:59:34Z,265.5
fhircrackr,"Useful tools for conveniently downloading FHIR resources in xml format 
    and converting them to R data frames. The package uses FHIR-search to download bundles 
    from a FHIR server, provides functions to save and read xml-files containing such bundles 
    and allows flattening the bundles to data.frames using XPath expressions.",2021-06-17,Thomas Peschel,NA,TRUE,https://github.com/polar-fhir/fhircrackr,10736,12,2022-07-05T06:15:15Z,894.6666666666666
fHMM,"Fitting (hierarchical) hidden Markov models to financial data
    via maximum likelihood estimation. See Oelschläger, L. and Adam, T.
    ""Detecting bearish and bullish markets in financial time series using 
    hierarchical hidden Markov models"" (2021, Statistical Modelling) 
    <doi:10.1177/1471082X211034048> for a reference.",2022-07-07,Lennart Oelschläger,https://loelschlaeger.de/fHMM/,TRUE,https://github.com/loelschlaeger/fhmm,6727,5,2022-07-07T09:23:37Z,1345.4
fidelius,"Create secure, encrypted, and password-protected static HTML 
  documents that include the machinery for secure in-browser authentication 
  and decryption.",2021-11-16,Matthew T. Warkentin,"https://mattwarkentin.github.io/fidelius/,
https://github.com/mattwarkentin/fidelius",TRUE,https://github.com/mattwarkentin/fidelius,2402,24,2021-11-16T14:39:39Z,100.08333333333333
fido,"Provides methods for fitting and inspection of Bayesian Multinomial Logistic Normal Models using MAP estimation 
 and Laplace Approximation as developed in Silverman et. Al. (2022) <https://www.jmlr.org/papers/v23/19-882.html>. Key functionality is implemented in C++ for 
 scalability. 'fido' replaces the previous package 'stray'.",2022-07-06,Justin Silverman,https://jsilve24.github.io/fido/,TRUE,https://github.com/jsilve24/fido,1179,10,2022-07-05T14:17:39Z,117.9
FielDHub,"A shiny design of experiments (DOE) app that aids in the creation of traditional, 
 un-replicated, augmented and partially-replicated designs applied to agriculture, 
 plant breeding, forestry, animal and biological sciences.",2021-05-19,Didier Murillo,https://github.com/DidierMurilloF/FielDHub,TRUE,https://github.com/didiermurillof/fieldhub,4805,20,2022-06-28T18:48:52Z,240.25
fields,"For curve, surface and function fitting with an emphasis
 on splines, spatial data, geostatistics,  and spatial statistics. The major methods
 include cubic, and thin plate splines, Kriging, and compactly supported
 covariance functions for large data sets. The splines and Kriging methods are
 supported by functions that can determine the smoothing parameter
 (nugget and sill variance) and other covariance function parameters by cross
 validation and also by restricted maximum likelihood. For Kriging
 there is an easy to use function that also estimates the correlation
 scale (range parameter).  A major feature is that any covariance function
 implemented in R and following a simple format can be used for
 spatial prediction. There are also many useful functions for plotting
 and working with spatial data as images. This package also contains
 an implementation of sparse matrix methods for large spatial data
 sets and currently requires the sparse matrix (spam) package. Use
 help(fields) to get started and for an overview.  The fields source
 code is deliberately commented and provides useful explanations of
 numerical details as a companion to the manual pages. The commented
 source code can be viewed by expanding the source code version
 and looking in the R subdirectory. The reference for fields can be generated
 by the citation function in R and has DOI <doi:10.5065/D6W957CT>. Development
 of this package was supported in part by the National Science Foundation  Grant
 1417857,  the National Center for Atmospheric Research, and Colorado School of Mines.
 See the Fields URL
 for a vignette on using this package and some background on spatial statistics.",2022-07-05,Douglas Nychka,https://github.com/dnychka/fieldsRPackage,TRUE,https://github.com/dnychka/fieldsrpackage,1208965,6,2022-07-05T18:26:05Z,201494.16666666666
FIESTAutils,"A set of tools for data wrangling, spatial data analysis,
    statistical modeling (including direct, model-assisted, photo-based, and
    small area tools), and USDA Forest Service data base tools. These tools are
    aimed to help Foresters, Analysts, and Scientists extract and perform
    analyses on USDA Forest Service data.",2022-06-14,Grayson White,https://github.com/USDAForestService/FIESTAutils,TRUE,https://github.com/usdaforestservice/fiestautils,1561,2,2022-06-29T17:44:45Z,780.5
fig,"Work with configs with a source precedence. Either create own R6
  instance or work with convenient functions at a package level.",2022-03-31,Tymoteusz Makowski,https://github.com/TymekDev/fig,TRUE,https://github.com/tymekdev/fig,885,1,2022-04-22T16:14:46Z,885
figpatch,"For including external figures into an assembled 
    {patchwork}. This enables the creation of more complex figures that include 
    images alongside plots. ",2022-05-03,Brady Johnston,https://github.com/BradyAJohnston/figpatch,TRUE,https://github.com/bradyajohnston/figpatch,4785,46,2022-05-03T03:39:55Z,104.02173913043478
file2meco,Transform output files of some tools to the 'microtable' object of 'microtable' class in 'microeco' package. The 'microtable' class is the basic class in 'microeco' package and is necessary for the downstream microbial community data analysis.,2022-06-07,Chi Liu,https://github.com/ChiLiubio/file2meco,TRUE,https://github.com/chiliubio/file2meco,5933,8,2022-06-07T09:20:57Z,741.625
filearray,"Stores large arrays in files to avoid occupying large
    memories. Implemented with super fast gigabyte-level multi-threaded 
    reading/writing via 'OpenMP'. Supports multiple non-character data 
    types (double, float, complex, integer, logical, and raw).",2022-01-28,Zhengjia Wang,"http://dipterix.org/filearray/,
https://github.com/dipterix/filearray",TRUE,https://github.com/dipterix/filearray,5123,8,2022-01-27T23:01:34Z,640.375
filehash,"Implements a simple key-value style database where character string keys
  are associated with data values that are stored on the disk. A simple interface is provided for inserting,
  retrieving, and deleting data from the database. Utilities are provided that allow 'filehash' databases to be
  treated much like environments and lists are already used in R. These utilities are provided to encourage
  interactive and exploratory analysis on large datasets. Three different file formats for representing the
  database are currently available and new formats can easily be incorporated by third parties for use in the
  'filehash' framework.",2022-03-01,Roger D. Peng,https://github.com/rdpeng/filehash,TRUE,https://github.com/rdpeng/filehash,312375,21,2022-03-01T21:08:57Z,14875
filehashSQLite,Simple key-value database using SQLite as the back end.,2022-05-11,Roger D. Peng,https://github.com/rdpeng/filehashsqlite,TRUE,https://github.com/rdpeng/filehashsqlite,18607,9,2022-05-11T16:44:46Z,2067.4444444444443
finalfit,"Generate regression results tables and plots in final 
    format for publication. Explore models and export directly to PDF 
    and 'Word' using 'RMarkdown'. ",2021-12-05,Ewen Harrison,https://github.com/ewenharrison/finalfit,TRUE,https://github.com/ewenharrison/finalfit,90348,247,2022-07-09T12:44:38Z,365.7813765182186
finbif,"A programmatic interface to the 'Finnish Biodiversity Information
    Facility' ('FinBIF') API (<https://api.laji.fi>). 'FinBIF' aggregates
    Finnish biodiversity data from multiple sources in a single open access
    portal for researchers, citizen scientists, industry and government.
    'FinBIF' allows users of biodiversity information to find, access, combine
    and visualise data on Finnish plants, animals and microorganisms. The
    'finbif' package makes the publicly available data in 'FinBIF' easily
    accessible to programmers. Biodiversity information is available on taxonomy
    and taxon occurrence. Occurrence data can be filtered by taxon, time,
    location and other variables. The data accessed are conveniently
    preformatted for subsequent analyses.",2022-05-20,William K. Morris,"https://github.com/luomus/finbif, https://luomus.github.io/finbif/",TRUE,https://github.com/luomus/finbif,16890,2,2022-05-22T23:47:29Z,8445
findInFiles,"Creates a HTML widget which displays the results of searching for a pattern in files in a given folder. The results can be viewed in the 'RStudio' viewer pane, included in a 'R Markdown' document or in a 'Shiny' app. Also provides a 'Shiny' application allowing to run the widget and to navigate in the results.",2022-04-11,Stéphane Laurent,https://github.com/stla/findInFiles,TRUE,https://github.com/stla/findinfiles,8465,9,2022-04-11T12:03:20Z,940.5555555555555
findInGit,"Creates a HTML widget which displays the results of searching for a pattern in files in a given 'git' repository, including all its branches. The results can also be returned in a dataframe.",2021-07-28,Stéphane Laurent,https://github.com/stla/findInGit,TRUE,https://github.com/stla/findingit,3869,3,2021-07-28T09:56:40Z,1289.6666666666667
finetune,"The ability to tune models is important. 'finetune' enhances
    the 'tune' package by providing more specialized methods for finding
    reasonable values of model tuning parameters.  Two racing methods
    described by Kuhn (2014) <arXiv:1405.6974> are included. An iterative
    search method using generalized simulated annealing (Bohachevsky,
    Johnson and Stein, 1986) <doi:10.1080/00401706.1986.10488128> is also
    included.",2022-03-24,Max Kuhn,"https://github.com/tidymodels/finetune,
https://finetune.tidymodels.org",TRUE,https://github.com/tidymodels/finetune,27933,47,2022-03-25T00:41:25Z,594.3191489361702
fingerprint,"Functions to manipulate binary fingerprints
 of arbitrary length. A fingerprint is represented by an object of S4 class 'fingerprint'
 which is internally represented a vector of integers, such
 that each element represents the position in the fingerprint that is set to 1.
 The bitwise logical functions in R are overridden so that they can be used directly
 with 'fingerprint' objects. A number of distance metrics are also
 available (many contributed by Michael Fadock). Fingerprints 
 can be converted to Euclidean vectors (i.e., points on the unit hypersphere) and
 can also be folded using OR.  Arbitrary fingerprint formats can be handled via line
 handlers. Currently handlers are provided for CDK, MOE and BCI fingerprint data.",2018-01-07,Rajarshi Guha,NA,TRUE,https://github.com/rajarshi/cdkr,43956,37,2021-11-25T15:23:26Z,1188
finnishgrid,"R API client package for 'Fingrid Open Data' on the 
    electricity market and the power system. get_data() function
    holds the main application logic to retrieve time-series data.
    API calls require free user account registration.",2022-02-07,Markus Virtanen,https://github.com/virmar/finnishgrid,TRUE,https://github.com/virmar/finnishgrid,1449,1,2022-02-04T11:31:28Z,1449
finnts,"Automated time series forecasting developed by Microsoft Finance. The Microsoft Finance Time 
    Series Forecasting Framework, aka Finn, can be used to forecast any component of the income 
    statement, balance sheet, or any other area of interest by finance. Any numerical quantity over time, 
    Finn can be used to forecast it. While it can be applied outside of the finance domain, Finn want built 
    to meet the needs of financial analysts to better forecast their businesses within a company, and has 
    a lot of built in features that are specific to the needs of financial forecasters. Happy forecasting!",2022-03-28,Mike Tokic,"https://microsoft.github.io/finnts/,
https://github.com/microsoft/finnts",TRUE,https://github.com/microsoft/finnts,1850,41,2022-07-05T22:41:50Z,45.1219512195122
finreportr,"Download and display company financial data from the U.S. Securities
    and Exchange Commission's EDGAR database. It contains a suite of functions with
    web scraping and XBRL parsing capabilities that allows users to extract data from EDGAR 
    in an automated and scalable manner. See <https://www.sec.gov/edgar/searchedgar/companysearch.html>
    for more information.",2022-01-17,Seward Lee,https://github.com/sewardlee337/finreportr,TRUE,https://github.com/sewardlee337/finreportr,31506,105,2022-01-17T07:24:26Z,300.0571428571429
fipio,"Provides a lightweight suite
             of functions for retrieving information
             about 5-digit or 2-digit US FIPS codes.",2022-03-15,Justin Singh-Mohudpur,"https://fipio.justinsingh.me, https://github.com/UFOKN/fipio",TRUE,https://github.com/ufokn/fipio,3718,12,2022-03-15T18:57:49Z,309.8333333333333
firebase,"Authenticate users in 'Shiny' applications using 'Google Firebase' 
    with any of the many methods provided; email and password, email link, or
    using a third-party provider such as 'Github', 'Twitter', or 'Google'.
    use 'Firebase Storage' to store files securely, and leverage 'Firebase Analytics'
    to easily log events and better understand your audience.",2022-02-08,John Coene,"https://firebase.john-coene.com/,
https://github.com/JohnCoene/firebase",TRUE,https://github.com/johncoene/firebase,12152,123,2022-06-01T13:55:11Z,98.79674796747967
fishbc,"Provides raw and curated data on the codes,
    classification and conservation status of freshwater fishes in British
    Columbia. Marine fishes will be added in a future release.",2021-05-12,Evan Amies-Galonski,https://github.com/poissonconsulting/fishbc,TRUE,https://github.com/poissonconsulting/fishbc,9107,4,2022-03-09T19:53:17Z,2276.75
fishtree,"An interface to the Fish Tree of Life API to download taxonomies,
    phylogenies, fossil calibrations, and diversification rate information for
    ray-finned fishes.",2021-01-31,Jonathan Chang,"https://fishtreeoflife.org/, https://github.com/jonchang/fishtree",TRUE,https://github.com/jonchang/fishtree,16330,7,2022-03-01T20:17:22Z,2332.8571428571427
fishualize,Implementation of color palettes based on fish species. ,2022-03-08,Nina M. D. Schiettekatte,https://github.com/nschiett/fishualize,TRUE,https://github.com/nschiett/fishualize,24597,134,2022-02-17T03:22:15Z,183.5597014925373
fitbitr,"Many 'Fitbit' users, and R-friendly 'Fitbit' users
    especially, have found themselves curious about their 'Fitbit' data.
    'Fitbit' aggregates a large amount of personal data, much of which is
    interesting for personal research and to satisfy curiosity, and is
    even potentially useful in medical settings. The goal of 'fitbitr' is
    to make interfacing with the 'Fitbit' API as streamlined as possible,
    to make it simple for R users of all backgrounds and comfort levels to
    analyze their 'Fitbit' data and do whatever they want with it!
    Currently, 'fitbitr' includes methods for pulling data on activity,
    sleep, and heart rate, but this list is likely to grow in the future
    as the package gains more traction and more requests for new methods
    to be implemented come in.  You can find details on the 'Fitbit' API
    at <https://dev.fitbit.com/build/reference/web-api/>.",2021-08-22,Matt Kaye,"https://github.com/mrkaye97/fitbitr,
https://mrkaye97.github.io/fitbitr/",TRUE,https://github.com/mrkaye97/fitbitr,5072,8,2021-08-21T20:10:22Z,634
fitbitViz,"Connection to the 'Fitbit' Web API <https://dev.fitbit.com/build/reference/web-api/> by including 'ggplot2' Visualizations, 'Leaflet' and 3-dimensional 'Rayshader' Maps. The 3-dimensional 'Rayshader' Map requires the installation of the 'CopernicusDEM' R package which includes the 30- and 90-meter elevation data.",2022-03-07,Lampros Mouselimis,https://github.com/mlampros/fitbitViz,TRUE,https://github.com/mlampros/fitbitviz,7996,6,2022-02-27T18:56:02Z,1332.6666666666667
fitdistrplus,"Extends the fitdistr() function (of the MASS package) with several functions 
  to help the fit of a parametric distribution to non-censored or censored data. 
  Censored data may contain left censored, right censored and interval censored values, 
  with several lower and upper bounds. In addition to maximum likelihood estimation (MLE), 
  the package provides moment matching (MME), quantile matching (QME), maximum goodness-of-fit 
  estimation (MGE) and maximum spacing estimation (MSE) methods (available only for 
  non-censored data). Weighted versions of MLE, MME, QME and MSE are available. See e.g. 
  Casella & Berger (2002), Statistical inference, Pacific Grove, for a general introduction 
  to parametric estimation.",2022-03-10,Aurelie Siberchicot,"https://lbbe.univ-lyon1.fr/fr/fitdistrplus,
https://github.com/aursiber/fitdistrplus",TRUE,https://github.com/aursiber/fitdistrplus,1215167,31,2022-03-14T08:41:44Z,39198.93548387097
fitHeavyTail,"Robust estimation methods for the mean vector, scatter matrix,
    and covariance matrix (if it exists) from data (possibly containing NAs) 
    under multivariate heavy-tailed distributions such as angular Gaussian 
    (via Tyler's method), Cauchy, and Student's t distributions. Additionally, 
    a factor model structure can be specified for the covariance matrix. The
    latest revision also includes the multivariate skewed t distribution.
    The package is based on the papers: Sun, Babu, and Palomar (2014),
    Sun, Babu, and Palomar (2015), Liu and Rubin (1995), and 
    Zhou, Liu, Kumar, and Palomar (2019).",2022-05-11,Daniel P. Palomar,"https://CRAN.R-project.org/package=fitHeavyTail,
https://github.com/dppalomar/fitHeavyTail,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2014.2348944,
https://doi.org/10.1109/TSP.2015.2417513",TRUE,https://github.com/dppalomar/fitheavytail,15813,13,2022-04-20T01:07:11Z,1216.3846153846155
fitscape,"Convenient classes to model fitness landscapes and fitness
    seascapes. A low-level package with which most users will not interact but
    upon which other packages modeling fitness landscapes and fitness seascapes
    will depend.",2022-03-01,Raoul Wadhwa,https://github.com/rrrlw/fitscape,TRUE,https://github.com/rrrlw/fitscape,1040,0,2022-02-26T21:59:16Z,NA
fitur,"Wrapper for computing parameters for univariate distributions using MLE. It creates an object that stores d, p, q, r functions as well as parameters and statistics for diagnostics. Currently supports automated fitting from base and actuar packages. A manually fitting distribution fitting function is included to support directly specifying parameters for any distribution from ancillary packages.",2021-10-06,Thomas Roh,https://github.com/tomroh/fitur,TRUE,https://github.com/tomroh/fitur,22191,5,2022-06-16T22:17:11Z,4438.2
fitzRoy,"An easy package for scraping and processing Australia Rules Football (AFL)
    data. 'fitzRoy' provides a range of functions for accessing publicly available data 
    from 'AFL Tables' <https://afltables.com/afl/afl_index.html>, 'Footy Wire' <https://www.footywire.com> and
    'The Squiggle' <https://squiggle.com.au>. Further functions allow for easy processing, 
    cleaning and transformation of this data into formats that can be used for analysis. ",2022-01-10,James Day,"https://jimmyday12.github.io/fitzRoy/,
https://github.com/jimmyday12/fitzRoy",TRUE,https://github.com/jimmyday12/fitzroy,19406,97,2022-06-29T23:54:55Z,200.06185567010309
fivethirtyeight,"Datasets and code published by the data journalism website 
    'FiveThirtyEight' available at <https://github.com/fivethirtyeight/data>. 
    Note that while we received guidance from editors at 'FiveThirtyEight', this 
    package is not officially published by 'FiveThirtyEight'.",2021-10-07,Albert Y. Kim,https://github.com/rudeboybert/fivethirtyeight,TRUE,https://github.com/rudeboybert/fivethirtyeight,94342,430,2021-11-29T16:45:07Z,219.4
fixedincome,"Fixed income mathematics made easy. A rich set of functions 
    that helps with calculations of interest rates and fixed income.
    It has objects that abstract interest rates, compounding factors, day count rules,
    forward rates and term structure of interest rates.
    Many interpolation methods and parametric curve models commonly used by practitioners
    are implemented.",2022-03-17,Wilson Freitas,https://github.com/wilsonfreitas/R-fixedincome,TRUE,https://github.com/wilsonfreitas/r-fixedincome,985,32,2022-07-06T19:19:00Z,30.78125
fixedTimeEvents,"Distribution functions and test for over-representation of short
    distances in the Liland distribution. Simulation functions are included for
    comparison.",2022-01-04,Kristian Hovde Liland,https://github.com/khliland/fixedTimeEvents/,TRUE,https://github.com/khliland/fixedtimeevents,14599,0,2021-12-28T09:31:53Z,NA
fixest,"Fast and user-friendly estimation of econometric models with multiple fixed-effects. Includes ordinary least squares (OLS), generalized linear models (GLM) and the negative binomial.
    The core of the package is based on optimized parallel C++ code, scaling especially well for large data sets. The method to obtain the fixed-effects coefficients is based on Berge (2018) <https://wwwen.uni.lu/content/download/110162/1299525/file/2018_13>.
    Further provides tools to export and view the results of several estimations with intuitive design to cluster the standard-errors.",2022-03-31,Laurent Berge,"https://lrberge.github.io/fixest/,
https://github.com/lrberge/fixest",TRUE,https://github.com/lrberge/fixest,204171,267,2022-05-14T14:02:34Z,764.685393258427
fixtuRes,Generate mock data in R using YAML configuration.,2022-02-16,Jakub Nowicki,https://github.com/jakubnowicki/fixtuRes,TRUE,https://github.com/jakubnowicki/fixtures,1697,6,2022-02-16T09:24:27Z,282.8333333333333
FKF,"This is a fast and flexible implementation of the Kalman
        filter and smoother, which can deal with NAs. It is entirely written in C and relies fully on linear algebra subroutines contained in
        BLAS and LAPACK. Due to the speed of the filter, the fitting of
        high-dimensional linear state space models to large datasets
        becomes possible. This package also contains a plot function
        for the visualization of the state vector and graphical
        diagnostics of the residuals.",2021-12-17,Paul Smith,"https://waternumbers.github.io/FKF/,
https://github.com/waternumbers/FKF",TRUE,https://github.com/waternumbers/fkf,40531,10,2022-06-14T08:34:23Z,4053.1
FKF.SP,"Fast and flexible Kalman filtering implementation utilizing sequential processing, designed for efficient parameter estimation through maximum likelihood estimation. Sequential processing is a univariate treatment of a multivariate series of observations and can benefit from computational efficiency over traditional Kalman filtering when independence is assumed in the variance of the disturbances of the measurement equation. Sequential processing is described in the textbook of Durbin and Koopman (2001, ISBN:978-0-19-964117-8). 'FKF.SP' was built upon the existing 'FKF' package and is, in general, a faster Kalman filter.",2022-03-21,Thomas Aspinall,https://github.com/TomAspinall/FKF.SP,TRUE,https://github.com/tomaspinall/fkf.sp,10928,0,2022-03-21T09:56:33Z,NA
flacco,"Tools and features for ""Exploratory Landscape Analysis (ELA)"" of
	single-objective continuous optimization problems.
    Those features are able to quantify rather complex properties, such as the
    global structure, separability, etc., of the optimization problems.",2020-03-31,Pascal Kerschke,https://github.com/kerschke/flacco,TRUE,https://github.com/kerschke/flacco,18922,48,2021-09-11T22:10:23Z,394.2083333333333
FLAME,"Efficient implementations of the algorithms in the 
    Almost-Matching-Exactly framework for interpretable matching in causal
    inference. These algorithms match units via a learned, weighted Hamming
    distance that determines which covariates are more important to match on.
    For more information and examples, see the Almost-Matching-Exactly website. ",2021-12-07,Vittorio Orlandi,"https://almost-matching-exactly.github.io,https://vittorioorlandi.github.io/",TRUE,https://github.com/vittorioorlandi/flame,18051,5,2021-12-13T14:29:24Z,3610.2
flametree,"A generative art system for producing tree-like
    images using an L-system to create the structures. The package 
    includes tools for generating the data structures and visualise
    them in a variety of styles.",2021-11-29,Danielle Navarro,https://github.com/djnavarro/flametree,TRUE,https://github.com/djnavarro/flametree,6609,155,2021-11-29T06:08:14Z,42.63870967741936
flashlight,"Shed light on black box machine learning models by the help
    of model performance, variable importance, global surrogate models,
    ICE profiles, partial dependence (Friedman J. H. (2001)
    <doi:10.1214/aos/1013203451>), accumulated local effects (Apley D. W.
    (2016) <arXiv:1612.08468>), further effects plots, scatter plots,
    interaction strength, and variable contribution breakdown (approximate
    SHAP) for single observations (Gosiewska and Biecek (2019)
    <arxiv:1903.11420>). All tools are implemented to work with case
    weights and allow for stratified analysis. Furthermore, multiple
    flashlights can be combined and analyzed together.",2021-04-21,Michael Mayer,https://github.com/mayer79/flashlight,TRUE,https://github.com/mayer79/flashlight,21925,18,2022-02-10T06:24:50Z,1218.0555555555557
fledge,"Streamlines the process of updating changelogs (NEWS.md)
    and versioning R packages developed in git repositories.",2021-12-07,Kirill Müller,"https://cynkra.github.io/fledge/, https://github.com/cynkra/fledge",TRUE,https://github.com/cynkra/fledge,2215,156,2022-06-27T09:40:14Z,14.198717948717949
flexdashboard,"Format for converting an R Markdown document to a grid oriented
  dashboard. The dashboard flexibly adapts the size of it's components to the
  containing web page.",2020-06-24,Richard Iannone,http://rmarkdown.rstudio.com/flexdashboard,TRUE,https://github.com/rstudio/flexdashboard,659724,618,2022-04-06T20:09:30Z,1067.514563106796
FlexDotPlot,Flexible Dotplot and Pacman plot for multimodal data.,2022-04-04,Simon Leonard,https://github.com/Simon-Leonard/FlexDotPlot,TRUE,https://github.com/simon-leonard/flexdotplot,1894,15,2022-06-17T09:10:28Z,126.26666666666667
flexiblas,"Provides functions to switch the 'BLAS'/'LAPACK' optimized backend
    and change the number of threads without leaving the R session, which needs
    to be linked against the 'FlexiBLAS' wrapper library
    <https://www.mpi-magdeburg.mpg.de/projects/flexiblas>.",2022-02-25,Iñaki Ucar,https://github.com/Enchufa2/r-flexiblas,TRUE,https://github.com/enchufa2/r-flexiblas,5069,8,2022-02-25T15:35:44Z,633.625
flexpolyline,"Binding to the C++ implementation of the flexible polyline
    encoding by HERE <https://github.com/heremaps/flexible-polyline>. The
    flexible polyline encoding is a lossy compressed representation of a list of
    coordinate pairs or coordinate triples. The encoding is achieved by:
    (1) Reducing the decimal digits of each value;
    (2) encoding only the offset from the previous point;
    (3) using variable length for each coordinate delta; and
    (4) using 64 URL-safe characters to display the result.",2021-11-19,Merlin Unterfinger,"https://munterfi.github.io/flexpolyline/,
https://github.com/munterfi/flexpolyline/",TRUE,https://github.com/munterfi/flexpolyline,20476,7,2021-11-19T20:14:48Z,2925.1428571428573
flexsurv,"Flexible parametric models for time-to-event data,
    including the Royston-Parmar spline model, generalized gamma and
    generalized F distributions.  Any user-defined parametric
    distribution can be fitted, given at least an R function defining
    the probability density or hazard. There are also tools for
    fitting and predicting from fully parametric multi-state models,
    based on either cause-specific hazards or mixture models.",2022-06-17,Christopher Jackson,https://github.com/chjackson/flexsurv-dev,TRUE,https://github.com/chjackson/flexsurv-dev,169171,33,2022-07-04T16:42:43Z,5126.393939393939
flexsurvcure,Flexible parametric mixture and non-mixture cure models for time-to-event data.,2022-06-17,Jordan Amdahl,https://github.com/jrdnmdhl/flexsurvcure,TRUE,https://github.com/jrdnmdhl/flexsurvcure,22656,11,2022-06-17T05:29:58Z,2059.6363636363635
flextable,"Create pretty tables for 'HTML', 'PDF', 'Microsoft Word' and 'Microsoft PowerPoint' 
  documents from 'R Markdown'. Functions are provided to let users create tables, modify and format 
  their content. It also extends package 'officer' that does not contain any feature for customized 
  tabular reporting.",2022-06-12,David Gohel,"https://ardata-fr.github.io/flextable-book/,
https://davidgohel.github.io/flextable/",TRUE,https://github.com/davidgohel/flextable,762356,414,2022-07-07T12:34:11Z,1841.4396135265702
FLightR,"Spatio-temporal locations of an animal are computed 
    from annotated data with a hidden Markov  model via particle
    filter algorithm. The package is relatively robust to varying
    degrees of shading.
    The hidden Markov model is described in Movement Ecology (Rakhimberdiev et al., 2015) <doi:10.1186/s40462-015-0062-5>,
    general package description is in the Methods in Ecology and Evolution (Rakhimberdiev et al., 2017) <doi:10.1111/2041-210X.12765>
    and package accuracy assessed in the Journal of Avian Biology (Rakhimberdiev et al. 2016) <doi:10.1111/jav.00891>.",2022-02-15,Eldar Rakhimberdiev,https://CRAN.R-project.org/package=FLightR,TRUE,https://github.com/eldarrak/flightr,16066,18,2022-03-23T11:06:40Z,892.5555555555555
flightsbr,"Download flight and airport data from Brazil’s Civil Aviation Agency
             (ANAC) <https://www.gov.br/anac>. The data includes detailed 
             information on all aircrafts, aerodromes, airports, and airport 
             movements registered in ANAC, on airfares and on every international
             flight to and from Brazil, as well as domestic flights within the country.",2022-05-05,Rafael H. M. Pereira,https://github.com/ipeaGIT/flightsbr,TRUE,https://github.com/ipeagit/flightsbr,2502,32,2022-07-07T21:37:17Z,78.1875
flintyR,"Given a multivariate dataset and some knowledge about the dependencies between its features, it is important to ensure the observations or individuals are exchangeable before fitting a model to the data in order to make inferences from it, or assigning randomized treatments in order to estimate treatment effects. This package provides a flexible non-parametric test of exchangeability, allowing the user to specify the feature dependencies by hand. It can be used directly to evaluate whether a sample is exchangeable, and can also be piped into larger procedures that require exchangeable samples as outputs (e.g., clustering or community detection). See Aw, Spence and Song (2021+) for the accompanying paper.",2021-09-28,Alan Aw,https://alanaw1.github.io/flintyR/,TRUE,https://github.com/alanaw1/flintyr,3399,0,2022-06-13T21:54:59Z,NA
flipr,"A flexible permutation framework for making 
    inference such as point estimation, confidence 
    intervals or hypothesis testing, on any kind of data, 
    be it univariate, multivariate, or more complex such 
    as network-valued data, topological data, functional 
    data or density-valued data.",2021-09-16,Aymeric Stamm,"https://astamm.github.io/flipr/, https://github.com/astamm/flipr/",TRUE,https://github.com/astamm/flipr,6939,2,2022-06-21T20:15:10Z,3469.5
float,"R comes with a suite of utilities for linear algebra with ""numeric""
    (double precision) vectors/matrices. However, sometimes single precision (or
    less!) is more than enough for a particular task.  This package extends R's
    linear algebra facilities to include 32-bit float (single precision) data.
    Float vectors/matrices have half the precision of their ""numeric""-type
    counterparts but are generally faster to numerically operate on, for a
    performance vs accuracy trade-off.  The internal representation is an S4
    class, which allows us to keep the syntax identical to that of base R's.
    Interaction between floats and base types for binary operators is generally
    possible; in these cases, type promotion always defaults to the higher
    precision.  The package ships with copies of the single precision 'BLAS' and
    'LAPACK', which are automatically built in the event they are not available
    on the system.",2022-04-07,Drew Schmidt,https://github.com/wrathematics/float,TRUE,https://github.com/wrathematics/float,381123,42,2022-04-07T22:12:39Z,9074.357142857143
flobr,"Converts files to and from flobs.  A flob is a file that was
    read into binary in integer-mode as little endian, saved as the single
    element of a named list (where the name is the name of the original
    file) and then serialized before being coerced into a blob.  Flobs are
    useful for writing and reading files to and from databases.",2021-10-27,Joe Thorley,https://github.com/poissonconsulting/flobr,TRUE,https://github.com/poissonconsulting/flobr,16038,7,2022-01-24T18:25:57Z,2291.1428571428573
flora,"Tools to quickly compile taxonomic and distribution data from
    the Brazilian Flora 2020.",2020-04-28,Gustavo Carvalho,http://www.github.com/gustavobio/flora,TRUE,https://github.com/gustavobio/flora,19909,20,2022-03-18T12:26:18Z,995.45
flow,"Visualize as flow diagrams the logic of functions, expressions or 
  scripts in a static way or when running a call, and ease debugging. Advanced
  features include analogs to 'debug' and 'debugonce' to target specific functions to draw,
  an utility to draw the calls used in the tests of the package in a markdown report, 
  and an utility to draw all the functions of one package in a markdown report.",2022-03-08,Antoine Fabri,"https://github.com/moodymudskipper/flow,
https://moodymudskipper.github.io/flow/",TRUE,https://github.com/moodymudskipper/flow,5058,335,2022-05-14T02:36:59Z,15.098507462686568
flowTraceR,"Useful functions to standardize software outputs from ProteomeDiscoverer, Spectronaut, DIA-NN and MaxQuant on precursor, modified peptide and proteingroup level and to trace software differences for identifications such as varying proteingroup denotations for common precursor.",2022-06-03,Oliver Kardell,https://github.com/OKdll/flowTraceR,TRUE,https://github.com/okdll/flowtracer,299,0,2022-06-23T13:40:40Z,NA
FlyingR,"Functions for range estimation in birds based on Pennycuick (2008)
    and Pennycuick (1975), 'Flight' program which compliments Pennycuick (2008)
    requires manual entry of birds which can be tedious when there are hundreds
    of birds to estimate. Implemented are two ODE methods discussed in Pennycuick (1975)
    and time-marching computation methods as in Pennycuick (1998) and Pennycuick (2008).
    See Pennycuick (1975, ISBN:978-0-12-249405-5), Pennycuick (1998) <doi:10.1006/jtbi.1997.0572>,
    and Pennycuick (2008, ISBN:9780080557816).",2022-06-27,Brian Masinde,https://github.com/BMasinde/FlyingR,TRUE,https://github.com/bmasinde/flyingr,6672,1,2022-06-27T19:58:43Z,6672
fm.index,"Wrapper for the Succinct Data Structure C++ library (SDSL v3)
  <https://github.com/xxsds/sdsl-lite> enabling fast string searching using FM
  indices. Partial string matching can be ~50-fold faster than simple string
  scans for many real-world string collections (corpora). A given corpus is
  converted into a compact in-memory FM index representation that can be
  efficiently queried for partial string matches.",2022-04-08,Clemens Hug,https://github.com/clemenshug/fm.index,TRUE,https://github.com/clemenshug/fm.index,516,0,2022-04-12T15:18:10Z,NA
fmcmc,"Provides a friendly (flexible) Markov Chain Monte Carlo (MCMC)
         framework for implementing Metropolis-Hastings algorithm in a modular way
         allowing users to specify automatic convergence checker, personalized
         transition kernels, and out-of-the-box multiple MCMC chains using
         parallel computing. Most of the methods implemented in this package can
         be found in Brooks et al. (2011, ISBN 9781420079425). Among the methods
         included, we have: Haario (2001) <doi:10.1007/s11222-011-9269-5>
         Adaptive Metropolis, Vihola (2012) <doi:10.1007/s11222-011-9269-5>
         Robust Adaptive Metropolis, and Thawornwattana et
         al. (2018) <doi:10.1214/17-BA1084> Mirror transition kernels.",2022-01-14,George Vega Yon,https://github.com/USCbiostats/fmcmc,TRUE,https://github.com/uscbiostats/fmcmc,15320,13,2022-01-14T00:17:48Z,1178.4615384615386
FMM,"Provides a collection of functions to fit and explore single, multi-component and restricted Frequency Modulated Moebius (FMM) models. 'FMM' is a nonlinear parametric regression model capable of fitting non-sinusoidal shapes in rhythmic patterns. Details about the mathematical formulation of 'FMM' models can be found in Rueda et al. (2019) <doi:10.1038/s41598-019-54569-1>.",2021-12-17,Itziar Fernandez,https://github.com/alexARC26/FMM,TRUE,https://github.com/alexarc26/fmm,6794,0,2021-12-21T11:37:32Z,NA
fMRIscrub,"Data-driven fMRI denoising with projection scrubbing (Pham et al 
    (2022) <arXiv:2108.00319>). Also includes routines for DVARS (Derivatives 
    VARianceS) (Afyouni and Nichols (2018) 
    <doi:10.1016/j.neuroimage.2017.12.098>), motion scrubbing (Power et al 
    (2012) <doi:10.1016/j.neuroimage.2011.10.018>), aCompCor (anatomical 
    Components Correction) (Muschelli et al (2014)
    <doi:10.1016/j.neuroimage.2014.03.028>), detrending, and nuisance
    regression. Projection scrubbing and DVARS are also applicable to other
    outlier detection tasks involving high-dimensional data.",2022-07-08,Amanda Mejia,https://github.com/mandymejia/fMRIscrub,TRUE,https://github.com/mandymejia/fmriscrub,3309,1,2022-07-06T06:00:50Z,3309
fmtr,"Contains a set of functions that can be used to apply
  formats to data frames or vectors.  The package aims to provide to 
  functionality similar to that of SAS® formats. Formats are assigned to
  the format attribute on data frame columns.  Then when the fdata() 
  function is called, a new data frame is created with the column data
  formatted as specified.  The package also contains a value() function
  to create a user-defined format, similar to a SAS® user-defined format.",2022-06-25,David Bosak,https://fmtr.r-sassy.org,TRUE,https://github.com/dbosak01/fmtr,14965,8,2022-07-01T21:27:22Z,1870.625
foghorn,"The CRAN check results and where your package stands in the
    CRAN submission queue in your R terminal.",2021-07-11,Francois Michonneau,https://github.com/fmichonneau/foghorn,TRUE,https://github.com/fmichonneau/foghorn,625021,55,2021-07-11T10:17:12Z,11364.018181818183
foieGras,"Fits continuous-time random walk and correlated random walk state-space models for quality control animal tracking data ('Argos', processed light-level 'geolocation', 'GPS'). Template Model Builder ('TMB') is used for fast estimation. The 'Argos' data can be: (older) least squares-based locations; (newer) Kalman filter-based locations with error ellipse information; or a mixture of both. The models estimate two sets of location states corresponding to: 1) each observation, which are (usually) irregularly timed; and 2) user-specified time intervals (regular or irregular). Latent variable models are provided to estimate move persistence along tracks as an index of behaviour. Track simulation functions are provided. 'Jonsen I', 'McMahon CR', 'Patterson TA', 'Auger-Méthé M', 'Harcourt R', 'Hindell MA', 'Bestley S' (2019) Movement responses to environment: fast inference of variation among southern elephant seals with a mixed effects model. Ecology 100:e02566 <doi:10.1002/ecy.2566>.",2021-04-26,Ian Jonsen,https://github.com/ianjonsen/foieGras/,TRUE,https://github.com/ianjonsen/foiegras,25234,15,2022-06-15T15:07:22Z,1682.2666666666667
folio,"Datasets for teaching quantitative approaches and
    modeling in archaeology and paleontology. This package provides
    several types of data related to broad topics (cultural evolution,
    radiocarbon dating, paleoenvironments, etc.), which can be used to
    illustrate statistical methods in the classroom (multivariate data
    analysis, compositional data analysis, diversity measurement, etc.).",2022-05-05,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>,"https://packages.tesselle.org/folio/,
https://github.com/tesselle/folio",TRUE,https://github.com/tesselle/folio,7609,7,2022-06-09T13:15:42Z,1087
fomantic.plus,"Extend 'shiny.semantic' with extra 'Fomantic UI' components.
    Create pages in a format similar to 'shiny', form validation and more.",2022-01-24,Ashley Baldry,https://github.com/ashbaldry/fomantic.plus,TRUE,https://github.com/ashbaldry/fomantic.plus,1509,2,2022-01-21T22:31:46Z,754.5
fontawesome,"Easily and flexibly insert 'Font Awesome' icons into 'R Markdown'
    documents and 'Shiny' apps. These icons can be inserted into HTML content
    through inline 'SVG' tags or 'i' tags. There is also a utility function for
    exporting 'Font Awesome' icons as 'PNG' images for those situations where
    raster graphics are needed.",2021-07-02,Richard Iannone,https://github.com/rstudio/fontawesome,TRUE,https://github.com/rstudio/fontawesome,2413937,239,2022-07-08T03:46:09Z,10100.154811715482
foolbox,"Provides functionality for manipulating functions and translating them
    in metaprogramming.",2018-12-15,Thomas Mailund,https://github.com/mailund/foolbox,TRUE,https://github.com/mailund/foolbox,12611,7,2022-01-17T08:02:26Z,1801.5714285714287
footBayes,"This is the first package allowing for the estimation,
             visualization and prediction of the most well-known 
             football models: double Poisson, bivariate Poisson,
             Skellam, student_t. The package allows Hamiltonian
             Monte Carlo (HMC) estimation through the underlying Stan
             environment and Maximum Likelihood estimation (MLE, for 
             'static' models only). The model construction relies on
             the most well-known football references, such as 
             Dixon and Coles (1997) <doi:10.1111/1467-9876.00065>,
             Karlis and Ntzoufras (2003) <doi:10.1111/1467-9884.00366> and
             Egidi, Pauli and Torelli (2018) <doi:10.1177/1471082X18798414>.",2022-02-21,Leonardo Egidi,https://github.com/leoegidi/footbayes,TRUE,https://github.com/leoegidi/footbayes,1273,25,2022-05-23T17:13:48Z,50.92
foqat,"Tools for quickly processing and analyzing 
	field observation data and air quality data. This 
	tools contain functions that facilitate analysis 
	in atmospheric chemistry (especially in ozone 
	pollution). Some functions of time series are also 
	applicable to other fields. For detail please view 
	homepage<https://github.com/tianshu129/foqat>.
	Scientific Reference:
	1. The Hydroxyl Radical (OH) Reactivity: Roger Atkinson and Janet Arey (2003) <doi:10.1021/cr0206420>.
	2. Ozone Formation Potential (OFP): <https://ww2.arb.ca.gov/sites/default/files/classic/regact/2009/mir2009/mir10.pdf>, Zhang et al.(2021) <doi:10.5194/acp-21-11053-2021>.
	3. Aerosol Formation Potential (AFP): Wenjing Wu et al. (2016) <doi:10.1016/j.jes.2016.03.025>.
	4. TUV model: <https://www2.acom.ucar.edu/modeling/tropospheric-ultraviolet-and-visible-tuv-radiation-model>.",2022-04-08,Tianshu Chen,"https://github.com/tianshu129/foqat,
https://tianshu129.github.io/foqat/",TRUE,https://github.com/tianshu129/foqat,7586,27,2022-04-06T11:15:56Z,280.962962962963
forcats,"Helpers for reordering factor levels (including
    moving specified levels to front, ordering by first appearance,
    reversing, and randomly shuffling), and tools for modifying factor
    levels (including collapsing rare levels into other, 'anonymising',
    and manually 'recoding').",2021-01-27,Hadley Wickham,"https://forcats.tidyverse.org,
https://github.com/tidyverse/forcats",TRUE,https://github.com/tidyverse/forcats,14331859,490,2022-05-20T16:51:09Z,29248.691836734695
forceR,"For cleaning and analyses of animal closing force measurements. 
    'forceR' was initially written and optimized to deal with insect bite force 
    measurements, but can be used for any time series. Includes a full workflow 
    to load, plot and crop data, correct amplifier and baseline drifts, 
    identify individual peak shapes (bites), rescale (normalize) peak curves, 
    and find best polynomial fits to describe and analyze force curve shapes.",2022-06-07,Peter T. Rühr,https://github.com/Peter-T-Ruehr/forceR,TRUE,https://github.com/peter-t-ruehr/forcer,672,0,2022-06-23T13:33:43Z,NA
foreach,"Support for the foreach looping construct.  Foreach is an
        idiom that allows for iterating over elements in a collection,
        without the use of an explicit loop counter.  This package in
        particular is intended to be used for its return value, rather
        than for its side effects.  In that sense, it is similar to the
        standard lapply function, but doesn't require the evaluation
        of a function.  Using foreach without side effects also
        facilitates executing the loop in parallel.",2022-02-02,Folashade Daniel,https://github.com/RevolutionAnalytics/foreach,TRUE,https://github.com/revolutionanalytics/foreach,6500490,42,2022-02-15T17:52:13Z,154773.57142857142
forecast,"Methods and tools for displaying and analysing
             univariate time series forecasts including exponential smoothing
             via state space models and automatic ARIMA modelling.",2022-01-10,Rob Hyndman,"https://pkg.robjhyndman.com/forecast/,
https://github.com/robjhyndman/forecast",TRUE,https://github.com/robjhyndman/forecast,8222627,990,2022-05-09T08:13:12Z,8305.683838383839
FoReco,"Classical (bottom-up and top-down), optimal and heuristic combination forecast 
    reconciliation procedures for cross-sectional, temporal, and cross-temporal linearly 
    constrained time series (Di Fonzo and Girolimetto, 2021) <doi:10.1016/j.ijforecast.2021.08.004>.",2022-07-04,Daniele Girolimetto,"https://github.com/daniGiro/FoReco,
https://danigiro.github.io/FoReco/",TRUE,https://github.com/danigiro/foreco,11964,14,2022-07-04T12:04:10Z,854.5714285714286
forestControl,"Approximate false positive rate control in selection frequency for
    random forest using the methods described by Ender Konukoglu and Melanie Ganz (2014) <arXiv:1410.2838>.
    Methods for calculating the selection frequency threshold at false positive rates
    and selection frequency false positive rate feature selection.",2022-02-09,Tom Wilson,https://github.com/aberHRML/forestControl,TRUE,https://github.com/aberhrml/forestcontrol,16446,2,2022-02-09T10:33:59Z,8223
forestecology,"Code for fitting and assessing models for the growth of trees. In 
    particular for the Bayesian neighborhood competition linear regression model 
    of Allen (2020): methods for model fitting and generating fitted/predicted 
    values, evaluating the effect of competitor species identity using 
    permutation tests, and evaluating model performance using spatial 
    cross-validation. ",2021-10-02,Albert Y. Kim,https://github.com/rudeboybert/forestecology,TRUE,https://github.com/rudeboybert/forestecology,5906,4,2021-10-21T12:27:39Z,1476.5
forestplot,"A forest plot that allows for
    multiple confidence intervals per row,
    custom fonts for each text element,
    custom confidence intervals,
    text mixed with expressions, and more.
    The aim is to extend the use of forest plots beyond meta-analyses.
    This is a more general version of the original 'rmeta' package's forestplot()
    function and relies heavily on the 'grid' package.",2021-09-03,Max Gordon,https://gforge.se/packages/,TRUE,https://github.com/gforge/forestplot,219692,30,2021-11-02T19:52:08Z,7323.066666666667
forestploter,"Create forest plot based on the layout of the data. Confidence interval in multiple columns by groups can be done easily. Editing plot, inserting/adding text, applying theme to the plot and much more.",2022-06-23,Alimu Dayimu,https://github.com/adayim/forestploter,TRUE,https://github.com/adayim/forestploter,3870,20,2022-06-23T12:00:56Z,193.5
forestr,"Provides a toolkit for calculating forest and canopy structural complexity metrics from
    terrestrial LiDAR (light detection and ranging). References:  Atkins et al. 2018 <doi:10.1111/2041-210X.13061>; Hardiman et al. 2013 <doi:10.3390/f4030537>;
    Parker et al. 2004 <doi:10.1111/j.0021-8901.2004.00925.x>.",2020-04-14,Jeff Atkins,https://github.com/atkinsjeff/forestr,TRUE,https://github.com/atkinsjeff/forestr,15026,16,2021-07-30T17:58:29Z,939.125
ForestTools,"Provides tools for analyzing remotely sensed forest data, including functions for detecting treetops from canopy models, outlining tree crowns, calculating textural metrics and generating spatial statistics.",2021-09-11,Andrew Plowright,https://github.com/andrew-plowright/ForestTools,TRUE,https://github.com/andrew-plowright/foresttools,21035,26,2021-09-21T22:15:44Z,809.0384615384615
formatR,"Provides a function tidy_source() to format R source code. Spaces
    and indent will be added to the code automatically, and comments will be
    preserved under certain conditions, so that R code will be more
    human-readable and tidy. There is also a Shiny app as a user interface in
    this package (see tidy_app()).",2022-03-31,Yihui Xie,https://github.com/yihui/formatR,TRUE,https://github.com/yihui/formatr,3514358,218,2022-03-31T20:17:58Z,16120.908256880733
formattable,"Provides functions to create formattable vectors and data frames.
    'Formattable' vectors are printed with text formatting, and formattable
    data frames are printed with multiple types of formatting in HTML
    to improve the readability of data presented in tabular form rendered in
    web pages.",2021-01-07,Kun Ren,"https://renkun-ken.github.io/formattable/,
https://github.com/renkun-ken/formattable",TRUE,https://github.com/renkun-ken/formattable,908650,670,2022-05-18T00:24:13Z,1356.1940298507463
formatters,"We provide a framework for rendering complex tables to ASCII, and a set of formatters for transforming values or sets of values into ASCII-ready display strings.",2022-06-09,Gabriel Becker,https://github.com/insightsengineering/formatters,TRUE,https://github.com/insightsengineering/formatters,3391,3,2022-06-14T16:55:43Z,1130.3333333333333
formulaic,"Many statistical models and analyses in R are implemented through formula objects. The formulaic package creates a unified approach for programmatically and dynamically generating formula objects. Users may specify the outcome and inputs of a model directly, search for variables to include based upon naming patterns, incorporate interactions, and identify variables to exclude. A wide range of quality checks are implemented to identify issues such as misspecified variables, duplication, a lack of contrast in the inputs, and a large number of levels in categorical data.  Variables that do not meet these quality checks can be automatically excluded from the model.  These issues are documented and reported in a manner that provides greater accountability and useful information to guide an investigation of the data.",2021-02-15,David Shilane,https://dachosen1.github.io/formulaic/index.html,TRUE,https://github.com/dachosen1/formulaic,15716,7,2022-02-21T18:40:15Z,2245.1428571428573
forrel,"Forensic applications of pedigree analysis, including
    likelihood ratios for relationship testing, general relatedness
    inference, marker simulation, and power analysis. General computation
    of exclusion powers is based on Egeland et al. (2014)
    <doi:10.1016/j.fsigen.2013.05.001>. Several functions deal
    specifically with family reunion cases, implementing and developing
    ideas from Kling et al. (2017) <doi:10.1016/j.fsigen.2017.08.006>. A
    novelty of 'forrel' is the ability to model background inbreeding in
    forensic pedigree computations.  This can have significant impact in
    applications, as exemplified in Vigeland and Egeland (2019)
    <doi:10.1016/j.fsigss.2019.10.175>. 'forrel' is part of the ped suite,
    a collection of packages for pedigree analysis. In particular,
    'forrel' imports 'pedtools' for creating and manipulating pedigrees
    and markers, 'pedprobr' for likelihood computations, and 'pedmut' for
    mutation modelling.  Pedigree data may be created from scratch, or
    loaded from text files. Data import from the 'Familias' software
    (Egeland et al. (2000) <doi:10.1016/S0379-0738(00)00147-X>) is
    supported.",2022-02-25,Magnus Dehli Vigeland,https://github.com/magnusdv/forrel,TRUE,https://github.com/magnusdv/forrel,14882,8,2022-05-20T10:51:07Z,1860.25
FORTLS,"Process automation of point cloud data derived from terrestrial-based technologies such as Terrestrial Laser Scanner (TLS) or Simultaneous Localization and Mapping (SLAM). 'FORTLS' enables (i) detection of trees and estimation of tree-level attributes (e.g. diameters and heights), (ii) estimation of stand-level variables (e.g. density, basal area, mean and dominant height), (iii) computation of metrics related to important forest attributes estimated in Forest Inventories at stand-level, and (iv) optimization of plot design for combining TLS data and field measured data. Documentation about 'FORTLS' is described in Molina-Valero et al. (2022, <doi:10.1016/j.envsoft.2022.105337>). ",2022-06-10,Juan Alberto Molina-Valero,https://github.com/Molina-Valero/FORTLS,TRUE,https://github.com/molina-valero/fortls,6820,7,2022-05-27T16:12:20Z,974.2857142857143
fossilbrush,Functions to automate the detection and resolution of taxonomic and stratigraphic errors in fossil occurrence datasets. Functions were developed using data from the Paleobiology Database.,2022-05-21,Joe Flannery-Sutherland,https://github.com/jf15558/fossilbrush,TRUE,https://github.com/jf15558/fossilbrush,616,2,2022-04-08T16:18:36Z,308
fpcb,"Functions to represent functional objects under a Reproducing Kernel Hilbert Space (RKHS) framework as described 
  in Muñoz & González (2010). Autoregressive Hilbertian Model for functional time series using RKHS and predictive confidence bands construction 
  as proposed in Hernández et al (2021).",2021-06-07,Nicolás Hernández,NA,TRUE,https://github.com/nicolashernandezb/fpcb,5167,1,2021-11-30T18:44:06Z,5167
fpp3,"
    All data sets required for the examples and exercises in the book
    ""Forecasting: principles and practice"" by Rob J Hyndman and George Athanasopoulos
    <https://OTexts.com/fpp3/>.  All packages required to run the examples are also
    loaded.",2021-02-06,Rob Hyndman,"https://github.com/robjhyndman/fpp3-package,
https://OTexts.com/fpp3/",TRUE,https://github.com/robjhyndman/fpp3-package,134794,84,2022-01-12T04:52:07Z,1604.6904761904761
fracdist,"Calculate numerical asymptotic distribution functions of likelihood ratio 
    statistics for fractional unit root tests and tests of cointegration rank. 
    For these distributions, the included functions calculate critical values 
    and P-values used in unit root tests, cointegration tests, and rank tests 
    in the Fractionally Cointegrated Vector Autoregression (FCVAR) model.
    The functions implement procedures for tests described in the following articles:
    Johansen, S. and M. Ø. Nielsen (2012) <doi:10.3982/ECTA9299>,
    MacKinnon, J. G. and M. Ø. Nielsen (2014) <doi:10.1002/jae.2295>.",2021-05-25,Lealand Morin,https://github.com/LeeMorinUCF/fracdist,TRUE,https://github.com/leemorinucf/fracdist,4601,0,2021-08-05T20:36:45Z,NA
FracKrigingR,"Aim is to provide fractional Brownian vector field generation algorithm, Hurst parameter estimation method and fractional kriging model for multivariate data modeling.",2021-11-08,Neringa Urbonaite,https://github.com/NidaGreen/FracKriging,TRUE,https://github.com/nidagreen/frackriging,2215,0,2021-11-04T16:00:51Z,NA
fracture,"Provides functions for converting decimals to a
    matrix of numerators and denominators or a character vector of
    fractions.  Supports mixed or improper fractions, finding common
    denominators for vectors of fractions, limiting denominators to powers
    of ten, and limiting denominators to a maximum value.  Also includes
    helper functions for finding the least common multiple and greatest
    common divisor for a vector of integers.  Implemented using C++ for
    maximum speed.",2022-05-21,Alexander Rossell Hayes,"https://fracture.rossellhayes.com/,
https://github.com/rossellhayes/fracture",TRUE,https://github.com/rossellhayes/fracture,9876,19,2022-05-20T23:03:13Z,519.7894736842105
frailtySurv,"Simulates and fits semiparametric shared frailty models under a
    wide range of frailty distributions using a consistent and
    asymptotically-normal estimator. Currently supports: gamma, power variance
    function, log-normal, and inverse Gaussian frailty models.",2021-09-13,Vinnie Monaco,https://github.com/vmonaco/frailtySurv/,TRUE,https://github.com/vmonaco/frailtysurv,17890,8,2021-09-13T17:05:45Z,2236.25
framecleaner,"Provides a friendly interface for modifying data frames with a sequence of piped commands built upon the 'tidyverse' Wickham et al., (2019) <doi:10.21105/joss.01686> . The majority of commands wrap 'dplyr' mutate statements in a convenient way to concisely solve common issues that arise when tidying small to medium data sets. Includes smart defaults and allows flexible selection of columns via 'tidyselect'. ",2021-11-17,Harrison Tietze,"https://harrison4192.github.io/framecleaner/,
https://github.com/Harrison4192/framecleaner",TRUE,https://github.com/harrison4192/framecleaner,4410,3,2022-04-25T14:39:02Z,1470
frechet,"Provides implementation of statistical methods for random objects 
    lying in various metric spaces, which are not necessarily linear spaces. 
    The core of this package is Fréchet regression for random objects with 
    Euclidean predictors, which allows one to perform regression analysis 
    for non-Euclidean responses under some mild conditions. 
    Examples include distributions in L^2-Wasserstein space, 
    covariance matrices endowed with power metric (with Frobenius metric 
    as a special case), Cholesky and log-Cholesky metrics.  
    References: Petersen, A., & Müller, H.-G. (2019) <doi:10.1214/17-AOS1624>.",2020-12-16,Yaqing Chen,https://github.com/functionaldata/tFrechet,TRUE,https://github.com/functionaldata/tfrechet,8750,3,2022-06-06T19:03:42Z,2916.6666666666665
fredr,"An R client for the 'Federal Reserve Economic Data'
    ('FRED') API <https://research.stlouisfed.org/docs/api/>.  Functions
    to retrieve economic time series and other data from 'FRED'.",2021-01-29,Sam Boysel,https://github.com/sboysel/fredr,TRUE,https://github.com/sboysel/fredr,62949,79,2021-08-13T08:47:33Z,796.8227848101266
freealg,The free algebra in R; multivariate polynomials with non-commuting indeterminates.,2022-05-20,Robin K. S. Hankin,https://github.com/RobinHankin/freealg,TRUE,https://github.com/robinhankin/freealg,14846,1,2022-05-13T06:54:53Z,14846
freedom,"Implements the formulae required to calculate freedom
    from disease according to Cameron and Baldock (1998)
    <doi:10.1016/S0167-5877(97)00081-0>. These are the
    methods used at the Swedish national veterinary institute (SVA) to
    evaluate the performance of our nation animal disease
    surveillance programmes.",2020-09-08,Thomas Rosendal,https://github.com/SVA-SE/freedom,TRUE,https://github.com/sva-se/freedom,7506,0,2022-03-24T09:12:41Z,NA
freegroup,"The free group in R; juxtaposition is represented by a plus.  Includes inversion, multiplication by a scalar, group-theoretic power operation, and Tietze forms.  ",2021-11-20,Robin K. S.  Hankin,https://github.com/RobinHankin/freegroup,TRUE,https://github.com/robinhankin/freegroup,14942,0,2022-06-27T20:12:26Z,NA
freesurferformats,"Provides functions to read and write neuroimaging data in various file formats, with a focus on 'FreeSurfer' <http://freesurfer.net/> formats. This includes, but is not limited to, the following file formats: 1) MGH/MGZ format files, which can contain multi-dimensional images or other data. Typically they contain time-series of three-dimensional brain scans acquired by magnetic resonance imaging (MRI). They can also contain vertex-wise measures of surface morphometry data. The MGH format is named after the Massachusetts General Hospital, and the MGZ format is a compressed version of the same format. 2) 'FreeSurfer' morphometry data files in binary 'curv' format. These contain vertex-wise surface measures, i.e., one scalar value for each vertex of a brain surface mesh. These are typically values like the cortical thickness or brain surface area at each vertex. 3) Annotation file format. This contains a brain surface parcellation derived from a cortical atlas. 4) Surface file format. Contains a brain surface mesh, given by a list of vertices and a list of faces.",2022-02-11,Tim Schäfer,https://github.com/dfsp-spirit/freesurferformats,TRUE,https://github.com/dfsp-spirit/freesurferformats,28774,15,2022-04-13T18:55:07Z,1918.2666666666667
frenchdata,"Download data sets from Kenneth's French finance data library site <http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html>, reads all the data subsets from the file. Allows R users to collect the data as
    'tidyverse'-ready data frames.",2021-09-10,Nelson Areal,"https://nareal.github.io/frenchdata/,
https://github.com/nareal/frenchdata",TRUE,https://github.com/nareal/frenchdata,6158,5,2021-09-10T17:54:13Z,1231.6
freqpcr,"Interval estimation of the population allele frequency from qPCR analysis based on the restriction enzyme digestion (RED)-DeltaDeltaCq method (Osakabe et al. 2017, <doi:10.1016/j.pestbp.2017.04.003>), as well as general DeltaDeltaCq analysis. Compatible with the Cq measurement of DNA extracted from multiple individuals at once, so called ""group-testing"", this model assumes that the quantity of DNA extracted from an individual organism follows a gamma distribution. Therefore, the point estimate is robust regarding the uncertainty of the DNA yield.",2022-01-27,Masaaki Sudo,https://github.com/sudoms/freqpcr,TRUE,https://github.com/sudoms/freqpcr,1466,1,2022-01-26T10:54:10Z,1466
freqtables,"Quickly make tables of descriptive statistics (i.e., counts, 
    percentages, confidence intervals) for categorical variables. This 
    package is designed to work in a Tidyverse pipeline, and consideration
    has been given to get results from R to Microsoft Word ® with minimal pain.",2022-04-03,Brad Cannell,https://github.com/brad-cannell/freqtables,TRUE,https://github.com/brad-cannell/freqtables,11545,6,2022-04-03T15:52:02Z,1924.1666666666667
frequencyConnectedness,"Accompanies a paper (Barunik, Krehlik (2018) <doi:10.1093/jjfinec/nby001>) dedicated to spectral decomposition of connectedness measures and their interpretation. We implement all the developed estimators as well as the historical counterparts. For more information, see the help or GitHub page (<https://github.com/tomaskrehlik/frequencyConnectedness>) for relevant information.",2020-11-10,Tomas Krehlik,https://github.com/tomaskrehlik/frequencyConnectedness,TRUE,https://github.com/tomaskrehlik/frequencyconnectedness,22936,53,2022-06-07T19:56:03Z,432.75471698113205
frictionless,"Read and write Frictionless Data Packages. A 'Data Package'
    (<https://specs.frictionlessdata.io/data-package/>) is a simple container
    format and standard to describe and package a collection of (tabular) data. 
    It is typically used to publish FAIR 
    (<https://www.go-fair.org/fair-principles/>) and open datasets.",2022-02-16,Peter Desmet,"https://github.com/frictionlessdata/frictionless-r,
https://docs.ropensci.org/frictionless/",TRUE,https://github.com/frictionlessdata/frictionless-r,1442,16,2022-07-07T16:46:37Z,90.125
friends,"The complete scripts from the American sitcom Friends in tibble 
    format. Use this package to practice data wrangling, text analysis and 
    network analysis.",2020-09-03,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/friends,TRUE,https://github.com/emilhvitfeldt/friends,9042,47,2021-12-21T22:30:59Z,192.38297872340425
FRK,"Fixed Rank Kriging is a tool for spatial/spatio-temporal modelling and prediction with large datasets. The approach models the field, and hence the covariance function, using a set of r basis functions, where r is typically much smaller than the number of data points (or polygons) m. This low-rank basis-function representation facilitates the modelling of 'big' spatial/spatio-temporal data. The method naturally allows for non-stationary, anisotropic covariance functions. Discretisation of the spatial domain into so-called basic areal units (BAUs) facilitates the use of observations with varying support (i.e., both point-referenced and areal supports, potentially simultaneously), and prediction over arbitrary user-specified regions. `FRK` also supports inference over various manifolds, including the 2D plane and 3D sphere, and it provides helper functions to model, fit, predict, and plot with relative ease. Version 2.0.0 and above of the package `FRK` also supports modelling of non-Gaussian data, by employing a spatial generalised linear mixed model (GLMM) framework  to cater for Poisson, binomial, negative-binomial, gamma, and inverse-Gaussian distributions.  Zammit-Mangion and Cressie <doi:10.18637/jss.v098.i04> describe `FRK` in a Gaussian setting, and detail its use of basis functions and BAUs.",2022-03-25,Andrew Zammit-Mangion,NA,TRUE,https://github.com/andrewzm/frk,31939,51,2022-04-10T22:13:52Z,626.2549019607843
fs,"A cross-platform interface to file system operations, built on
  top of the 'libuv' C library.",2021-12-08,Gábor Csárdi,"https://fs.r-lib.org, https://github.com/r-lib/fs",TRUE,https://github.com/r-lib/fs,25763456,318,2022-03-27T21:04:17Z,81017.1572327044
FSA,"A variety of simple fish stock assessment methods.
    Detailed vignettes are available on the fishR website <http://derekogle.com/fishR/>.",2022-02-18,Derek Ogle,https://github.com/fishR-Core-Team/FSA,TRUE,https://github.com/fishr-core-team/fsa,259300,52,2022-04-08T22:30:47Z,4986.538461538462
FSAdata,The datasets to support the Fish Stock Assessment ('FSA') package.,2022-02-13,Derek Ogle,"http://derekogle.com/fishR/, https://github.com/droglenc/FSAdata",TRUE,https://github.com/droglenc/fsadata,51293,10,2022-02-20T19:00:30Z,5129.3
fsbrain,"Provides high-level access to neuroimaging data from standard software packages like 'FreeSurfer' <http://freesurfer.net/> on the level of subjects and groups. Load morphometry data, surfaces and brain parcellations based on atlases. Mask data using labels, load data for specific atlas regions only, and visualize data and statistical results directly in 'R'.",2022-02-12,Tim Schäfer,https://github.com/dfsp-spirit/fsbrain,TRUE,https://github.com/dfsp-spirit/fsbrain,18445,35,2022-02-23T20:26:31Z,527
fspe,Estimating the number of factors in Exploratory Factor Analysis (EFA) with out-of-sample prediction errors using a cross-validation scheme. Haslbeck & van Bork (Preprint) <https://psyarxiv.com/qktsd>.,2022-06-15,Jonas Haslbeck,NA,TRUE,https://github.com/jmbh/fspe,5079,0,2022-06-15T10:51:54Z,NA
fsr,"Support for fuzzy spatial objects, their operations, and fuzzy spatial inference models based on Spatial Plateau Algebra. 
    It employs fuzzy set theory and fuzzy logic as foundation to deal with spatial fuzziness. 
    It implements underlying concepts defined in the following research papers: 
    (i) ""Spatial Plateau Algebra: An Executable Type System for Fuzzy Spatial Data Types"" <doi:10.1109/FUZZ-IEEE.2018.8491565>; 
    (ii) ""A Systematic Approach to Creating Fuzzy Region Objects from Real Spatial Data Sets"" <doi:10.1109/FUZZ-IEEE.2019.8858878>; 
    (iii) ""Fuzzy Inference on Fuzzy Spatial Objects (FIFUS) for Spatial Decision Support Systems"" <doi:10.1109/FUZZ-IEEE.2017.8015707>.",2022-07-05,Anderson Carniel [rth,"https://accarniel.github.io/fsr/, https://github.com/accarniel/fsr",TRUE,https://github.com/accarniel/fsr,3201,8,2022-07-05T12:35:12Z,400.125
fssemR,"An optimizer of Fused-Sparse Structural Equation Models, which is 
 the state of the art jointly fused sparse maximum likelihood function 
 for structural equation models proposed by Xin Zhou and Xiaodong Cai (2018 
 <doi:10.1101/466623>).",2022-02-11,Xin Zhou,https://github.com/Ivis4ml/fssemR,TRUE,https://github.com/ivis4ml/fssemr,13266,3,2022-04-01T21:00:20Z,4422
fst,"Multithreaded serialization of compressed data frames using the 'fst' format. The
    'fst' format allows for full random access of stored data and a wide range of compression
    settings using the LZ4 and ZSTD compressors.",2022-02-08,Mark Klik,http://www.fstpackage.org,TRUE,https://github.com/fstpackage/fst,382259,569,2022-02-08T09:31:09Z,671.8084358523726
fstcore,"The 'fstlib' library provides multithreaded serialization of compressed data frames using the
    'fst' format. The 'fst' format allows for random access of stored data and compression with the 'LZ4' and 'ZSTD'
    compressors.",2022-03-23,Mark Klik,https://www.fstpackage.org/fstcore/,TRUE,https://github.com/fstpackage/fst,84114,569,2022-02-08T09:31:09Z,147.82776801405976
ftExtra,"Build display tables easily by extending the functionality of the
    'flextable' package. Features include spanning header, grouping rows,
    parsing markdown and so on.",2022-04-20,Atsushi Yasumoto,"https://ftextra.atusy.net, https://github.com/atusy/ftExtra",TRUE,https://github.com/atusy/ftextra,53511,60,2022-05-10T12:58:25Z,891.85
fullROC,"Enable researchers to adjust identification rates using the 1/(lineup size) method, generate the full receiver operating characteristic (ROC) curves, and statistically compare the area under the curves (AUC). 
  References: Yueran Yang & Andrew Smith. (2020). ""fullROC: An R package for generating and analyzing eyewitness-lineup ROC curves"". <doi:10.13140/RG.2.2.20415.94885/1>  ,
              Andrew Smith, Yueran Yang, & Gary Wells. (2020). ""Distinguishing between investigator discriminability and eyewitness discriminability: A method for creating full receiver operating characteristic curves of lineup identification performance"". Perspectives on Psychological Science, 15(3), 589-607. <doi:10.1177/1745691620902426>.",2021-01-13,Yueran Yang,NA,TRUE,https://github.com/yuerany/fullroc,7484,0,2022-07-01T17:52:26Z,NA
funcharts,"Provides functional control charts 
    for statistical process monitoring of functional data, 
    using the methods of Capezza et al. (2020) <doi:10.1002/asmb.2507> and 
    Centofanti et al. (2020) <doi:10.1080/00401706.2020.1753581>.",2022-06-15,Christian Capezza,https://github.com/unina-sfere/funcharts,TRUE,https://github.com/unina-sfere/funcharts,4945,0,2022-06-14T21:20:28Z,NA
funchir,YACFP (Yet Another Convenience Function Package). get_age() is a fast & accurate tool for measuring fractional years between two dates. abbr_to_colClass() is a much more concise way of feeding many types to a colClass argument in a data reader. stale_package_check() tries to identify any library() calls to unused packages.,2022-04-17,Michael Chirico,https://github.com/MichaelChirico/funchir,TRUE,https://github.com/michaelchirico/funchir,17016,5,2022-04-17T22:47:40Z,3403.2
funData,"S4 classes for univariate and multivariate functional data with
    utility functions. See <doi:10.18637/jss.v093.i05> for a detailed description 
    of the package functionalities and its interplay with the MFPCA package for 
    multivariate functional principal component analysis 
    <https://CRAN.R-project.org/package=MFPCA>. ",2021-10-17,Clara Happ-Kurz,https://github.com/ClaraHapp/funData,TRUE,https://github.com/clarahapp/fundata,20776,10,2021-11-07T18:09:03Z,2077.6
fundiversity,"Computes 5 alpha-functional diversity indices: Functional
  Divergence (FDiv), Function Evenness (FEve), Functional Richness (FRic),
  Functional Dispersion (FDis) and Rao's entropy (Q) (reviewed in Villéger
  et al. 2008 <doi:10.1890/07-1206.1>). Provides efficient and modular functions
  to compute functional diversity indices.",2021-09-21,Matthias Grenié,"https://bisaloo.github.io/fundiversity/,
https://github.com/bisaloo/fundiversity",TRUE,https://github.com/bisaloo/fundiversity,6443,3,2022-07-07T19:16:23Z,2147.6666666666665
FunnelPlotR,"An implementation of methods presented by Spiegelhalter (2005) <doi:10.1002/sim.1970> Funnel plots for comparing institutional performance, for standardised ratios, ratios of counts and proportions with additive overdispersion adjustment.",2021-09-30,Chris Mainey,"https://chrismainey.github.io/FunnelPlotR/,
https://github.com/chrismainey/FunnelPlotR",TRUE,https://github.com/chrismainey/funnelplotr,17109,39,2022-01-18T16:30:04Z,438.6923076923077
funrar,"Computes functional rarity indices as proposed by Violle et al.
    (2017) <doi:10.1016/j.tree.2017.02.002>. Various indices can be computed
    using both regional and local information. Functional Rarity combines both
    the functional aspect of rarity as well as the extent aspect of rarity.
    'funrar' is presented in Grenié et al. (2017) <doi:10.1111/ddi.12629>.",2020-04-20,Matthias Grenié,https://rekyt.github.io/funrar/,TRUE,https://github.com/rekyt/funrar,23256,12,2022-03-18T13:27:10Z,1938
furrr,"Implementations of the family of map() functions from 'purrr'
    that can be resolved using any 'future'-supported backend, e.g.
    parallel on the local machine or distributed on a compute cluster.",2022-05-04,Davis Vaughan,"https://github.com/DavisVaughan/furrr,
https://furrr.futureverse.org/",TRUE,https://github.com/davisvaughan/furrr,2456894,642,2022-05-04T21:55:25Z,3826.93769470405
fusen,"Use Rmarkdown First method to build your package.  Start your
    package with documentation, functions, examples and tests in the same
    unique file. Everything can be set from the Rmarkdown template file
    provided in your project, then inflated as a package.  Inflating the
    template copies the relevant chunks and sections in the appropriate
    files required for package development.",2022-04-30,Sebastien Rochette,"https://thinkr-open.github.io/fusen/,
https://github.com/Thinkr-open/fusen",TRUE,https://github.com/thinkr-open/fusen,5962,102,2022-06-17T06:13:22Z,58.450980392156865
futility,"Randomized clinical trials commonly follow participants for a time-to-event efficacy endpoint for a fixed period of time. Consequently, at the time when the last enrolled participant completes their follow-up, the number of observed endpoints is a random variable. Assuming data collected through an interim timepoint, simulation-based estimation and inferential procedures in the standard right-censored failure time analysis framework are conducted for the distribution of the number of endpoints--in total as well as by treatment arm--at the end of the follow-up period. The future (i.e., yet unobserved) enrollment, endpoint, and dropout times are generated according to mechanisms specified in the simTrial() function in the 'seqDesign' package. A Bayesian model for the endpoint rate, offering the option to specify a robust mixture prior distribution, is used for generating future data (see the vignette for details). Inference can be restricted to participants who received treatment according to the protocol and are observed to be at risk for the endpoint at a specified timepoint. Plotting functions are provided for graphical display of results.",2019-04-11,Michal Juraska,https://github.com/mjuraska/futility,TRUE,https://github.com/mjuraska/futility,15134,1,2021-10-01T23:30:35Z,15134
future,"The purpose of this package is to provide a lightweight and
    unified Future API for sequential and parallel processing of R
    expression via futures.  The simplest way to evaluate an expression
    in parallel is to use `x %<-% { expression }` with `plan(multisession)`.
    This package implements sequential, multicore, multisession, and
    cluster futures.  With these, R expressions can be evaluated on the
    local machine, in parallel a set of local machines, or distributed
    on a mix of local and remote machines.
    Extensions to this package implement additional backends for
    processing futures via compute cluster schedulers, etc.
    Because of its unified API, there is no need to modify any code in order
    switch from sequential on the local machine to, say, distributed
    processing on a remote compute cluster.
    Another strength of this package is that global variables and functions
    are automatically identified and exported as needed, making it
    straightforward to tweak existing code to make use of futures.",2022-05-27,Henrik Bengtsson,"https://future.futureverse.org,
https://github.com/HenrikBengtsson/future",TRUE,https://github.com/henrikbengtsson/future,5502106,858,2022-06-30T17:14:28Z,6412.710955710956
future.apply,"Implementations of apply(), by(), eapply(), lapply(), Map(), .mapply(), mapply(), replicate(), sapply(), tapply(), and vapply() that can be resolved using any future-supported backend, e.g. parallel on the local machine or distributed on a compute cluster.  These future_*apply() functions come with the same pros and cons as the corresponding base-R *apply() functions but with the additional feature of being able to be processed via the future framework.",2022-04-25,Henrik Bengtsson,"https://future.apply.futureverse.org,
https://github.com/HenrikBengtsson/future.apply",TRUE,https://github.com/henrikbengtsson/future.apply,2684076,185,2022-06-28T04:26:29Z,14508.518918918919
future.batchtools,"Implementation of the Future API on top of the 'batchtools' package.
    This allows you to process futures, as defined by the 'future' package,
    in parallel out of the box, not only on your local machine or ad-hoc
    cluster of machines, but also via high-performance compute ('HPC') job
    schedulers such as 'LSF', 'OpenLava', 'Slurm', 'SGE', and 'TORQUE' / 'PBS',
    e.g. 'y <- future.apply::future_lapply(files, FUN = process)'.",2021-01-04,Henrik Bengtsson,https://github.com/HenrikBengtsson/future.batchtools,TRUE,https://github.com/henrikbengtsson/future.batchtools,66285,80,2022-03-30T15:54:13Z,828.5625
future.callr,"Implementation of the Future API on top of the 'callr' package.  This allows you to process futures, as defined by the 'future' package, in parallel out of the box, on your local (Linux, macOS, Windows, ...) machine.  Contrary to backends relying on the 'parallel' package (e.g. 'future::multisession') and socket connections, the 'callr' backend provided here can run more than 125 parallel R processes.",2022-04-01,Henrik Bengtsson,"https://future.callr.futureverse.org,
https://github.com/HenrikBengtsson/future.callr",TRUE,https://github.com/henrikbengtsson/future.callr,90399,52,2022-06-14T17:30:15Z,1738.4423076923076
future.tests,"Backends implementing the 'Future' API, as defined by the 'future' package, should use the tests provided by this package to validate that they meet the minimal requirements of the 'Future' API.  The tests can be performed easily from within R or from outside of R from the command line making it easy to include them package tests and in Continuous Integration (CI) pipelines.",2021-10-10,Henrik Bengtsson,"https://future.tests.futureverse.org,
https://github.com/HenrikBengtsson/future.tests",TRUE,https://github.com/henrikbengtsson/future.tests,11840,9,2022-05-20T16:36:07Z,1315.5555555555557
FuzzyClass,"Provides classifiers that can be used for discrete variables and for continuous variables based on the idea of Naive Bayes and Fuzzy Naive Bayes considering some statistical distributions of articles published in the literature developed in the LabTEVE and LEAPIG research laboratories. Among the proposed classification methods is a with the Gamma distribution, proposed by Moraes, Soares and Machado (2018) <doi:10.1142/9789813273238_0088>.",2022-05-27,Jodavid Ferreira,https://github.com/Jodavid/FuzzyClass,TRUE,https://github.com/jodavid/fuzzyclass,493,0,2022-05-31T18:05:00Z,NA
FuzzyNumbers,"S4 classes and methods
    to deal with fuzzy numbers. They allow for computing any arithmetic
    operations (e.g., by using the Zadeh extension principle),
    performing approximation of arbitrary fuzzy numbers by trapezoidal
    and piecewise linear ones, preparing plots for publications, computing
    possibility and necessity values for comparisons, etc.",2021-11-15,Marek Gagolewski,https://github.com/gagolews/FuzzyNumbers/,TRUE,https://github.com/gagolews/fuzzynumbers,24220,9,2021-11-15T02:15:25Z,2691.1111111111113
FuzzyResampling,"The classical (i.e. Efron's, see Efron and Tibshirani (1994, ISBN:978-0412042317)  ""An Introduction to the Bootstrap"") bootstrap is widely used for both the real (i.e. ""crisp"") and fuzzy data.
 The main aim of the algorithms implemented in this package  is to overcome a problem with repetition of a few distinct values and to create fuzzy numbers, which are ""similar"" (but not the same) to values from the initial sample.
 To do this, different characteristics of triangular/trapezoidal numbers are kept (like the value, the ambiguity, etc., see Grzegorzewski et al. <doi:10.2991/eusflat-19.2019.68>, Grzegorzewski et al. (2020) <doi:10.2991/ijcis.d.201012.003>, Grzegorzewski et al. (2020) <doi:10.34768/amcs-2020-0022>, Grzegorzewski and Romaniuk (2022) <doi:10.1007/978-3-030-95929-6_3>,  Romaniuk and Hryniewicz (2019) <doi:10.1007/s00500-018-3251-5>).
 Some additional procedures related to these resampling methods are also provided,
 like calculation of the Bertoluzza et al.'s distance (aka the mid/spread distance, see Bertoluzza et al. (1995) ""On a new class of distances between fuzzy numbers"")
 and estimation of the p-value of the one-sample bootstrapped test for the mean (see Lubiano et al. (2016, <doi:10.1016/j.ejor.2015.11.016>)).
 Additionally, there are procedures which randomly generate trapezoidal fuzzy numbers using some well-known statistical distributions.",2022-03-21,Maciej Romaniuk,https://github.com/mroman-ibs/FuzzyResampling,TRUE,https://github.com/mroman-ibs/fuzzyresampling,5001,0,2022-03-21T08:43:46Z,NA
fuzzywuzzyR,Fuzzy string matching implementation of the 'fuzzywuzzy' <https://github.com/seatgeek/fuzzywuzzy> 'python' package. It uses the Levenshtein Distance <https://en.wikipedia.org/wiki/Levenshtein_distance> to calculate the differences between sequences. ,2021-09-11,Lampros Mouselimis,https://github.com/mlampros/fuzzywuzzyR,TRUE,https://github.com/mlampros/fuzzywuzzyr,32742,32,2021-09-17T19:21:34Z,1023.1875
fwildclusterboot,"Implementation of the fast algorithm for wild cluster bootstrap 
             inference developed in Roodman et al (2019, STATA Journal) for 
             linear regression models <doi:10.1177/1536867X19830877>, 
             which makes it feasible to quickly calculate bootstrap test 
             statistics based on a large number of bootstrap draws even for 
             large samples. Multiway clustering, regression weights, 
             bootstrap weights, fixed effects and subcluster bootstrapping
             are supported. Further, both restricted (WCR) and unrestricted
             (WCU) bootstrap are supported. Methods are provided for a variety 
             of fitted models, including 'lm()', 'feols()' 
             (from package 'fixest') and 'felm()' (from package 'lfe'). 
             Additionally implements a heteroskedasticity-robust (HC1) wild 
             bootstrap.
             Further, the package provides an R binding to 'WildBootTests.jl',
             which provides additional speed gains and functionality, 
             including the 'WRE' bootstrap for instrumental variable models 
             (based on models of type 'ivreg()' from package 'ivreg')
             and hypotheses with q > 1.",2022-06-10,Alexander Fischer,https://s3alfisc.github.io/fwildclusterboot/,TRUE,https://github.com/s3alfisc/fwildclusterboot,10156,12,2022-07-08T06:03:40Z,846.3333333333334
fxTWAPLS,"The goal of this package is to provide an improved version of 
    WA-PLS (Weighted Averaging Partial Least Squares) by including the 
    tolerances of taxa and the frequency of the sampled climate variable. 
    This package also provides a way of leave-out cross-validation that 
    removes both the test site and sites that are both geographically 
    close and climatically close for each cycle, to avoid the risk of 
    pseudo-replication.",2022-06-06,Mengmeng Liu,"https://github.com/special-uor/fxTWAPLS/,
https://special-uor.github.io/fxTWAPLS/,
https://research.reading.ac.uk/palaeoclimate/",TRUE,https://github.com/special-uor/fxtwapls,8841,1,2022-06-01T11:18:35Z,8841
GA,"Flexible general-purpose toolbox implementing genetic algorithms (GAs) for stochastic optimisation. Binary, real-valued, and permutation representations are available to optimize a fitness function, i.e. a function provided by users depending on their objective function. Several genetic operators are available and can be combined to explore the best settings for the current task. Furthermore, users can define new genetic operators and easily evaluate their performances. Local search using general-purpose optimisation algorithms can be applied stochastically to exploit interesting regions. GAs can be run sequentially or in parallel, using an explicit master-slave parallelisation or a coarse-grain islands approach.",2021-10-15,Luca Scrucca,https://luca-scr.github.io/GA/,TRUE,https://github.com/luca-scr/ga,213642,77,2021-10-14T20:13:46Z,2774.5714285714284
GADMTools,"Manipulate, assemble, export <https://gadm.org/> maps. Create 'choropleth', 'isopleth', dots plot, proportional dots,
   dot-density and more.",2021-08-05,Jean Pierre Decorps,https://github.com/IamKDO/GADMTools,TRUE,https://github.com/iamkdo/gadmtools,32375,2,2021-08-18T19:06:23Z,16187.5
galah,"The Atlas of Living Australia ('ALA') provides tools to enable users
    of biodiversity information to find, access, combine and visualise data on
    Australian plants and animals. 'galah' enables the R community to directly 
    access data and resources hosted by the ALA and other living atlases.",2022-01-24,Martin Westgate,"https://github.com/AtlasOfLivingAustralia/galah,
https://atlasoflivingaustralia.github.io/galah/",TRUE,https://github.com/atlasoflivingaustralia/galah,7300,16,2022-03-25T01:25:59Z,456.25
gamboostLSS,"Boosting models for fitting generalized additive models for
  location, shape and scale ('GAMLSS') to potentially high dimensional
  data.",2022-05-11,Benjamin Hofner,"For source code, development versions and issue tracker see
https://github.com/boost-R/gamboostLSS",TRUE,https://github.com/boost-r/gamboostlss,77162,22,2022-05-05T14:57:47Z,3507.3636363636365
gameR,Palettes based on video games.,2022-05-31,Nathan Constantine-Cooke,https://www.constantine-cooke.com/gameR/,TRUE,https://github.com/nathansam/gamer,1180,4,2022-05-31T10:12:31Z,295
gap,"As first reported [Zhao, J. H. 2007. ""gap: Genetic Analysis Package"". J Stat Soft 23(8):1-18.
        <doi:10.18637/jss.v023.i08>], it is designed as an integrated package for genetic data
        analysis of both population and family data. Currently, it contains functions for
        sample size calculations of both population-based and family-based designs, probability
        of familial disease aggregation, kinship calculation, statistics in linkage analysis,
        and association analysis involving genetic markers including haplotype analysis with or
        without environmental covariates. Over years, the package has been developed in-between
        many projects hence also in line with the name (gap).",2022-05-13,Jing Hua Zhao  (<https://orcid.org/0000-0002-1463-5870>,https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,166419,6,2022-07-08T17:10:26Z,27736.5
gapclosing,"Provides functions to estimate the disparities across categories (e.g. Black and white) that persists if a treatment variable (e.g. college) is equalized. Makes estimates by treatment modeling, outcome modeling, and doubly-robust augmented inverse probability weighting estimation, with standard errors calculated by a nonparametric bootstrap. Cross-fitting is supported. Survey weights are supported for point estimation but not for standard error estimation; those applying this package with complex survey samples should consult the data distributor to select an appropriate approach for standard error construction, which may involve calling the functions repeatedly for many sets of replicate weights provided by the data distributor. The methods in this package are described in Lundberg (2021) <doi:10.31235/osf.io/gx4y3>.",2021-10-11,Ian Lundberg,https://ilundberg.github.io/gapclosing/,TRUE,https://github.com/ilundberg/gapclosing,3243,3,2021-09-21T03:50:04Z,1081
garchx,"Flexible and robust estimation and inference of generalised autoregressive conditional heteroscedasticity (GARCH) models with covariates ('X') based on the results by Francq and Thieu (2018) <doi:10.1017/S0266466617000512>. Coefficients can straightforwardly be set to zero by omission, and quasi maximum likelihood methods ensure estimates are generally consistent and inference valid, even when the standardised innovations are non-normal and/or dependent over time.",2021-07-15,Genaro Sucarrat,http://www.sucarrat.net/,TRUE,https://github.com/gsucarrat/garchx,16622,1,2021-07-20T15:51:30Z,16622
gargle,"Provides utilities for working with Google APIs
    <https://developers.google.com/apis-explorer>.  This includes
    functions and classes for handling common credential types and for
    preparing, executing, and processing HTTP requests.",2021-07-02,Jennifer Bryan,"https://gargle.r-lib.org, https://github.com/r-lib/gargle",TRUE,https://github.com/r-lib/gargle,13385502,97,2022-02-02T01:03:08Z,137994.86597938143
garma,"Methods for estimating univariate long memory-seasonal/cyclical
             Gegenbauer time series processes. See for example (2018) <doi:10.1214/18-STS649>.
             Refer to the vignette for details of fitting these processes.",2022-02-15,Richard Hunt,https://github.com/rlph50/garma,TRUE,https://github.com/rlph50/garma,12464,1,2021-10-21T09:41:24Z,12464
gaselect,"Provides a genetic algorithm for finding variable
    subsets in high dimensional data with high prediction performance. The
    genetic algorithm can use ordinary least squares (OLS) regression models or
    partial least squares (PLS) regression models to evaluate the prediction
    power of variable subsets. By supporting different cross-validation
    schemes, the user can fine-tune the tradeoff between speed and quality of
    the solution.",2022-04-06,David Kepplinger,https://github.com/dakep/gaselect,TRUE,https://github.com/dakep/gaselect,17473,4,2022-04-06T13:35:57Z,4368.25
gastempt,"Fits gastric emptying time series from MRI or 'scintigraphic' measurements
   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with 
   Stan; computes derived parameters such as t50 and AUC.",2022-05-02,Dieter Menne,https://github.com/dmenne/gastempt,TRUE,https://github.com/dmenne/gastempt,14372,3,2022-05-09T07:28:57Z,4790.666666666667
gateR,"Estimates statistically significant marker combination values within
        which one immunologically distinctive group (i.e., disease case) is more associated than
        another group (i.e., healthy control), successively, using various combinations (i.e.,
        ""gates"") of markers to examine features of cells that may be different between
        groups. For a two-group comparison, the 'gateR' package uses the spatial relative risk
        function that is estimated using the 'sparr' package. Details about the 'sparr' package
        methods can be found in the tutorial: Davies et al. (2018) <doi:10.1002/sim.7577>. Details
        about kernel density estimation can be found in J. F. Bithell (1990) <doi:10.1002/sim.4780090616>.
        More information about relative risk functions using kernel density estimation can be
        found in J. F. Bithell (1991) <doi:10.1002/sim.4780101112>.",2022-02-05,Ian D. Buller,https://github.com/Waller-SUSAN/gateR,TRUE,https://github.com/waller-susan/gater,9016,1,2022-02-04T17:17:43Z,9016
GauPro,"Fits a Gaussian process model to data. Gaussian processes
 are commonly used in computer experiments to fit an interpolating model.
 The model is stored as an 'R6' object and can be easily updated with new 
 data. There are options to run in parallel (not for Windows), and 'Rcpp'
 has been used to speed up calculations. Other R packages that perform
 similar calculations include 'laGP', 'DiceKriging', 'GPfit', and 'mlegp'.",2021-04-11,Collin Erickson,https://github.com/CollinErickson/GauPro,TRUE,https://github.com/collinerickson/gaupro,20546,8,2022-05-07T14:08:29Z,2568.25
gaussfacts,"Display a random fact about Carl Friedrich Gauss
 based the on collection curated by Mike Cavers via the
 <http://gaussfacts.com> site.",2016-08-03,Dirk Eddelbuettel,NA,TRUE,https://github.com/eddelbuettel/gaussfacts,18197,3,2021-11-06T00:13:16Z,6065.666666666667
gaussplotR,"
    Functions to fit two-dimensional Gaussian functions, predict values from
    fits, and produce plots of predicted data via either 'ggplot2' or base R 
    plotting.",2021-05-02,Vikram B. Baliga,https://github.com/vbaliga/gaussplotR,TRUE,https://github.com/vbaliga/gaussplotr,8406,3,2021-07-29T20:06:02Z,2802
GaussSuppression,"A statistical disclosure control tool to protect tables by suppression using the Gaussian elimination secondary suppression algorithm. Primary suppression functions for the minimum frequency rule, the dominance rule and a directly-disclosive rule are included. General primary suppression functions can be supplied as input. Suppressed frequencies can be replaced by synthetic decimal numbers as described in Langsrud (2019) <doi:10.1007/s11222-018-9848-9>.",2022-06-28,Øyvind Langsrud,https://github.com/statisticsnorway/GaussSuppression,TRUE,https://github.com/statisticsnorway/gausssuppression,3614,0,2022-06-28T14:33:54Z,NA
gbifdb,"A high performance interface to the Global Biodiversity
  Information Facility, 'GBIF'.  In contrast to 'rgbif', which can
  access small subsets of 'GBIF' data through web-based queries to
  a central server, 'gbifdb' provides enhanced performance for R users
  performing large-scale analyses on servers and cloud computing
  providers, providing full support for arbitrary 'SQL' or 'dplyr'
  operations on the complete 'GBIF' data tables (now over 1 billion
  records, and over a terabyte in size). 'gbifdb' accesses a copy
  of the 'GBIF' data in 'parquet' format, which is already readily
  available in commercial computing clouds such as the Amazon Open
  Data portal and the Microsoft Planetary Computer, or can be 
  accessed directly without downloading, or downloaded
  to any server with suitable bandwidth and storage space.
  The high-performance techniques for local and remote access 
  are described in <https://duckdb.org/why_duckdb>
  and <https://arrow.apache.org/docs/r/articles/fs.html> respectively.",2022-05-21,Carl Boettiger,"https://docs.ropensci.org/gbifdb/,
https://github.com/ropensci/gbifdb",TRUE,https://github.com/ropensci/gbifdb,391,20,2022-07-05T17:18:19Z,19.55
gbutils,"Plot density and distribution functions with automatic selection of
       suitable regions. Numerically invert (compute quantiles) distribution
       functions. Simulate real and complex numbers from distributions of their
       magnitude and arguments. Optionally, the magnitudes and/or arguments may
       be fixed in almost arbitrary ways. Create polynomials from roots given in
       Cartesian or polar form. Small programming utilities: check if an object
       is identical to NA, count positional arguments in a call, set
       intersection of more than two sets, check if an argument is unnamed,
       compute the graph of S4 classes in packages.",2022-05-27,Georgi N. Boshnakov,"https://github.com/GeoBosh/gbutils (devel),
https://geobosh.github.io/gbutils/ (website)",TRUE,https://github.com/geobosh/gbutils,29165,0,2022-06-20T15:11:24Z,NA
GCalignR,"Aligns peak based on peak retention times and matches homologous peaks
    across samples. The underlying alignment procedure comprises three sequential steps.
    (1) Full alignment of samples by linear transformation of retention times to 
    maximise similarity among homologous peaks (2) Partial alignment of peaks within 
    a user-defined retention time window to cluster homologous peaks (3) Merging rows
    that are likely representing homologous substances (i.e. no sample shows peaks in 
    both rows and the rows have similar retention time means). The algorithm is described in detail
    in Ottensmann et al., 2018 <doi:10.1371/journal.pone.0198311>. ",2020-08-26,Meinolf Ottensmann,https://github.com/mottensmann/GCalignR,TRUE,https://github.com/mottensmann/gcalignr,18053,3,2022-06-19T22:16:19Z,6017.666666666667
gcTensor,"Multiple matrices/tensors can be specified and decomposed simultaneously by Probabilistic Latent Tensor Factorisation (PLTF). See the reference section of GitHub README.md <https://github.com/rikenbit/gcTensor>, for details of the method.",2021-09-13,Koki Tsuyuzaki,https://github.com/rikenbit/gcTensor,TRUE,https://github.com/rikenbit/gctensor,2139,1,2021-09-11T04:02:00Z,2139
gdalcubes,"Processing collections of Earth observation images as on-demand multispectral, multitemporal raster data cubes. Users
    define cubes by spatiotemporal extent, resolution, and spatial reference system and let 'gdalcubes' automatically apply cropping, reprojection, and 
    resampling using the 'Geospatial Data Abstraction Library' ('GDAL'). Implemented functions on data cubes include reduction over space and time, 
    applying arithmetic expressions on pixel band values, moving window aggregates over time, filtering by space, time, bands, and predicates on pixel values, 
    exporting data cubes as 'netCDF' or 'GeoTIFF' files, plotting, and extraction from spatial and or spatiotemporal features.  
    All computational parts are implemented in C++, linking to the 'GDAL', 'netCDF', 'CURL', and 'SQLite' libraries. 
    See Appel and Pebesma (2019) <doi:10.3390/data4030092> for further details.",2022-03-23,Marius Appel,https://github.com/appelmar/gdalcubes_R,TRUE,https://github.com/appelmar/gdalcubes_r,24085,89,2022-05-13T07:16:06Z,270.6179775280899
gdalUtilities,"R's 'sf' package ships with self-contained 'GDAL'
    executables, including a bare bones interface to several
    'GDAL'-related utility programs collectively known as the 'GDAL
    utilities'. For each of those utilities, this package provides an
    R wrapper whose formal arguments closely mirror those of the
    'GDAL' command line interface. The utilities operate on data
    stored in files and typically write their output to other
    files. Therefore, to process data stored in any of R's more common
    spatial formats (i.e. those supported by the 'sp', 'sf', and
    'raster' packages), first write them to disk, then process them
    with the package's wrapper functions before reading the outputted
    results back into R. GDAL function arguments introduced in GDAL
    version 3.2.1 or earlier are supported.",2022-04-19,Joshua OBrien,https://github.com/JoshOBrien/gdalUtilities/,TRUE,https://github.com/joshobrien/gdalutilities,43838,27,2022-04-18T17:29:48Z,1623.6296296296296
GDAtools,"Contains functions for 'specific' Multiple Correspondence Analysis, 
	Class Specific Analysis, Multiple Factor Analysis, 'standardized' MCA, computing and plotting structuring factors and concentration ellipses, 
	inductive tests and others tools for Geometric Data Analysis (Le Roux & Rouanet (2005) <doi:10.1007/1-4020-2236-0>). It also provides functions
	for the translation of logit models coefficients into percentages (Deauvieau (2010) <doi:10.1177/0759106309352586>), weighted contingency tables, an association 
  measure for contingency tables (""Percentages of Maximum Deviation from Independence"", aka PEM, see Cibois (1993) <doi:10.1177/075910639304000103>) and some tools to measure 
  and plot bivariate associations between variables
  (phi, Cramér V, correlation coefficient, eta-squared...).",2022-02-22,Nicolas Robette,"https://github.com/nicolas-robette/GDAtools,
https://nicolas-robette.github.io/GDAtools/",TRUE,https://github.com/nicolas-robette/gdatools,25837,6,2022-06-03T21:49:14Z,4306.166666666667
gde,Functions to explore datasets from the Global Biodiversity Information Facility (GBIF - <https://www.gbif.org/>) using a Shiny interface.,2021-11-23,Luis J Villanueva,https://github.com/Smithsonian/GBIF-Dataset-Explorer,TRUE,https://github.com/smithsonian/gbif-dataset-explorer,7681,1,2021-11-23T16:06:18Z,7681
GDINA,"A set of psychometric tools for cognitive diagnosis modeling based on the generalized deterministic inputs, noisy and gate (G-DINA) model by de la Torre (2011) <DOI:10.1007/s11336-011-9207-7> and its extensions, including the sequential G-DINA model by Ma and de la Torre (2016) <DOI:10.1111/bmsp.12070> for polytomous responses, and the polytomous G-DINA model by Chen and de la Torre <DOI:10.1177/0146621613479818> for polytomous attributes. Joint attribute distribution can be independent, saturated, higher-order, loglinear smoothed or structured. Q-matrix validation, item and model fit statistics, model comparison at test and item level and differential item functioning can also be conducted. A graphical user interface is also provided. For tutorials, please check Ma and de la Torre (2020) <DOI:10.18637/jss.v093.i14>, Ma and de la Torre (2019) <DOI:10.1111/emip.12262>, Ma (2019) <DOI:10.1007/978-3-030-05584-4_29> and de la Torre and Akbay (2019). ",2022-01-20,Wenchao Ma,"https://github.com/Wenchao-Ma/GDINA,
https://wenchao-ma.github.io/GDINA/",TRUE,https://github.com/wenchao-ma/gdina,43108,25,2022-07-07T19:06:52Z,1724.32
gdistance,"Provides classes and functions to calculate various distance measures and routes in heterogeneous geographic spaces represented as grids. The package implements measures to model dispersal histories first presented by van Etten and Hijmans (2010) <doi:10.1371/journal.pone.0012060>. Least-cost distances as well as more complex distances based on (constrained) random walks can be calculated. The distances implemented in the package are used in geographical genetics, accessibility indicators, and may also have applications in other fields of geospatial analysis.",2020-06-29,Jacob van Etten,https://agrobioinfoservices.github.io/gdistance/,TRUE,https://github.com/agrobioinfoservices/gdistance,105798,4,2022-03-08T12:59:22Z,26449.5
gdm,"A toolkit with functions to fit, plot, summarize, and apply Generalized Dissimilarity Models. Mokany K, Ware C, Woolley SNC, Ferrier S, Fitzpatrick MC (2022) <doi:10.1111/geb.13459> Ferrier S, Manion G, Elith J, Richardson K (2007) <doi:10.1111/j.1472-4642.2007.00341.x>.",2022-04-05,Matt Fitzpatrick,"https://mfitzpatrick.al.umces.edu/gdm/,
https://github.com/fitzLab-AL/gdm/",TRUE,https://github.com/fitzlab-al/gdm,27142,19,2022-05-09T12:53:34Z,1428.5263157894738
GDSARM,"The method aims to identify important factors in screening experiments by aggregation over random models as studied in Singh and Stufken (2022) <doi:10.48550/arXiv.2205.13497>. This package provides functions to run Gauss-Dantzig selector on screening experiments when interactions may be affecting the response. Currently, all functions require each factor to be at two-levels coded as +1 and -1. ",2022-06-23,Rakhi Singh,https://github.com/agrakhi/GDSARM,TRUE,https://github.com/agrakhi/gdsarm,158,0,2022-05-27T03:01:30Z,NA
gdtools,Useful tools for writing vector graphics devices.,2022-02-14,David Gohel,NA,TRUE,https://github.com/davidgohel/gdtools,1788067,23,2022-01-31T11:34:09Z,77742.04347826086
geckor,"Collect the current and historical cryptocurrency market data using 
    the public 'CoinGecko' API (<https://www.coingecko.com/en/api>).",2021-11-01,Sergey Mastitsky,https://github.com/next-game-solutions/geckor,TRUE,https://github.com/next-game-solutions/geckor,8450,19,2021-11-01T15:53:46Z,444.7368421052632
gellipsoid,"Represent generalized geometric ellipsoids with the ""(U,D)"" representation. It allows degenerate
	and/or unbounded ellipsoids, together with methods for linear and duality transformations, and for plotting. 
	The ideas are described in Friendly, Monette & Fox (2013).",2022-04-22,Michael Friendly,https://github.com/friendly/gellipsoid,TRUE,https://github.com/friendly/gellipsoid,524,0,2022-04-19T16:48:42Z,NA
gen3sis,"Contains an engine for spatially-explicit eco-evolutionary mechanistic models with a modular implementation and several support functions. It allows exploring the consequences of ecological and macroevolutionary processes across realistic or theoretical spatio-temporal landscapes on biodiversity patterns as a general term. Reference: Oskar Hagen, Benjamin Flueck, Fabian Fopp, Juliano S. Cabral, Florian Hartig, Mikael Pontarp, Thiago F. Rangel, Loic Pellissier (2021) ""gen3sis: A general engine for eco-evolutionary simulations of the processes that shape Earth's biodiversity"" <doi:10.1371/journal.pbio.3001340>.",2021-10-27,Oskar Hagen  (Landscape Ecology,https://github.com/project-Gen3sis/R-package,TRUE,https://github.com/project-gen3sis/r-package,15582,16,2022-05-03T12:14:15Z,973.875
gender,"Infers state-recorded gender categories from first names and dates of birth using historical
    datasets. By using these datasets instead of lists of male and female names,
    this package is able to more accurately infer the gender of a name, and it
    is able to report the probability that a name was male or female. GUIDELINES:
    This method must be used cautiously and responsibly. Please be sure to see the
    guidelines and warnings about usage in the 'README' or the package documentation.
    See Blevins and Mullen (2015) <http://www.digitalhumanities.org/dhq/vol/9/3/000223/000223.html>.",2021-10-13,Lincoln Mullen,https://github.com/lmullen/gender,TRUE,https://github.com/lmullen/gender,135768,169,2021-10-08T20:07:33Z,803.3609467455622
geneExpressionFromGEO,"A function that reads in the GEO code of a gene expression dataset, retrieves its data from GEO, (optionally) retrieves the gene symbols of the dataset, and returns a simple dataframe table containing all the data. Platforms available: GPL11532, GPL23126, GPL6244, GPL8300, GPL80, GPL96, GPL570, GPL571, GPL20115, GPL1293,  GPL6102, GPL6104, GPL6883, GPL6884, GPL13497, GPL14550, GPL17077, GPL6480. GEO: Gene Expression Omnibus. ID: identifier code. The GEO datasets are downloaded from the URL <https://ftp.ncbi.nlm.nih.gov/geo/series/>. More information can be found in the following manuscript: Davide Chicco, ""geneExpressionFromGEO: an R package to facilitate data reading from Gene Expression Omnibus (GEO)"". Microarray Data Analysis, Methods in Molecular Biology, volume 2401, chapter 12, pages 187-194, Springer Protocols, 2021, <doi:10.1007/978-1-0716-1839-4_12>.",2021-12-16,Davide Chicco,https://github.com/davidechicco/geneExpressionFromGEO,TRUE,https://github.com/davidechicco/geneexpressionfromgeo,8585,2,2021-12-14T14:56:59Z,4292.5
genekitr,"An analysis toolkit focused on genes. It mainly includes five
    features (search, convert, analysis, plot, and export).
    The user just needs to input feature id ('entrez', 'symbol', 'ensembl' or
    'uniprot') to retrieve feature information and PubMed records, to convert id
    types, to easily do enrichment analysis and draw publication-level plots of GO,
    KEGG and GSEA, to plot group interaction and export results as sheets in one excel
    file to easily share and communicate with others.",2022-05-27,Yunze Liu,https://github.com/GangLiLab/genekitr,TRUE,https://github.com/ganglilab/genekitr,3398,3,2022-07-10T02:26:01Z,1132.6666666666667
GeneralizedUmatrix,"Projections are common dimensionality reduction methods, which represent high-dimensional data in a two-dimensional space. However, when restricting the output space to two dimensions, which results in a two dimensional scatter plot (projection) of the data, low dimensional similarities do not represent high dimensional distances coercively [Thrun, 2018] <DOI: 10.1007/978-3-658-20540-9>. This could lead to a misleading interpretation of the underlying structures [Thrun, 2018]. By means of the 3D topographic map the generalized Umatrix is able to depict errors of these two-dimensional scatter plots. The package is derived from the book of Thrun, M.C.: ""Projection Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <DOI:10.1007/978-3-658-20540-9> and the main algorithm called simplified self-organizing map for dimensionality reduction methods is published in <DOI: 10.1016/j.mex.2020.101093>.",2022-05-25,Michael Thrun,https://www.deepbionics.org,TRUE,https://github.com/mthrun/generalizedumatrix,23896,1,2022-05-25T15:41:56Z,23896
GenericML,"Generic Machine Learning Inference on heterogeneous treatment effects in randomized experiments as proposed in Chernozhukov, Demirer, Duflo and Fernández-Val (2020) <arXiv:1712.04802>. This package's workhorse is the 'mlr3' framework of Lang et al. (2019) <doi:10.21105/joss.01903>, which enables the specification of a wide variety of machine learners. The main functionality, GenericML(), runs Algorithm 1 in Chernozhukov, Demirer, Duflo and Fernández-Val (2020) <arXiv:1712.04802> for a suite of user-specified machine learners. All steps in the algorithm are customizable via setup functions. Methods for printing and plotting are available for objects returned by GenericML(). Parallel computing is supported.",2022-06-18,Max Welz,https://github.com/mwelz/GenericML/,TRUE,https://github.com/mwelz/genericml,2815,20,2022-06-21T07:59:24Z,140.75
generics,"In order to reduce potential package dependencies and
    conflicts, generics provides a number of commonly used S3 generics.",2022-07-05,Hadley Wickham,"https://generics.r-lib.org, https://github.com/r-lib/generics",TRUE,https://github.com/r-lib/generics,18099977,58,2022-07-05T21:25:22Z,312068.5689655172
GeNetIt,"Implementation of spatial graph-theoretic genetic gravity models.
    The model framework is applicable for other types of spatial flow questions.
    Includes functions for constructing spatial graphs, sampling and summarizing
    associated raster variables and building unconstrained and singly constrained
    gravity models.",2020-04-01,Jeffrey S. Evans,https://github.com/jeffreyevans/GeNetIt,TRUE,https://github.com/jeffreyevans/genetit,16656,3,2022-05-23T21:48:04Z,5552
genieclust,"A retake on the Genie algorithm - a robust
    hierarchical clustering method
    (Gagolewski, Bartoszuk, Cena, 2016 <DOI:10.1016/j.ins.2016.05.003>).
    Now faster and more memory efficient; determining the whole hierarchy
    for datasets of 10M points in low dimensional Euclidean spaces or
    100K points in high-dimensional ones takes only 1-2 minutes.
    Allows clustering with respect to mutual reachability distances
    so that it can act as a noise point detector or a robustified version of
    'HDBSCAN*' (that is able to detect a predefined number of
    clusters and hence it does not dependent on the somewhat
    fragile 'eps' parameter).
    The package also features an implementation of economic inequity indices
    (the Gini, Bonferroni index) and external cluster validity measures
    (partition similarity scores; e.g., the adjusted Rand, Fowlkes-Mallows,
    adjusted mutual information, pair sets index).
    See also the 'Python' version of 'genieclust' available on 'PyPI', which
    supports sparse data, more metrics, and even larger datasets.",2021-04-22,Marek Gagolewski,https://genieclust.gagolewski.com/,TRUE,https://github.com/gagolews/genieclust,13906,35,2022-02-09T00:58:34Z,397.3142857142857
genio,"Implements readers and writers for file formats associated with genetics data.  Reading and writing Plink BED/BIM/FAM and GCTA binary GRM formats is fully supported, including a lightning-fast BED reader and writer implementations.  Other functions are 'readr' wrappers that are more constrained, user-friendly, and efficient for these particular applications; handles Plink and Eigenstrat tables (FAM, BIM, IND, and SNP files).  There are also make functions for FAM and BIM tables with default values to go with simulated genotype data.",2022-04-27,Alejandro Ochoa,https://github.com/OchoaLab/genio,TRUE,https://github.com/ochoalab/genio,20588,11,2022-04-27T18:20:22Z,1871.6363636363637
genius,Easily access song lyrics in a tidy way.,2021-07-24,Josiah Parry,https://github.com/josiahparry/genius,TRUE,https://github.com/josiahparry/genius,27527,117,2021-10-31T15:28:55Z,235.27350427350427
genlasso,"Computes the solution path for generalized lasso problems. Important use cases are the fused lasso over an arbitrary graph, and trend fitting of any given polynomial order. Specialized implementations for the latter two subproblems are given to improve stability and speed.",2020-07-02,Taylor B. Arnold and Ryan J. Tibshirani,https://github.com/glmgen/genlasso,TRUE,https://github.com/glmgen/genlasso,25333,26,2022-02-07T15:10:44Z,974.3461538461538
GenomeAdapt,"Portable, scalable and highly computationally efficient tool for detecting signatures of local adaptation based on multidimensional ancestry map ( _n_ X _n_ ancestry genetic trajectories, _n_ is the number of individuals). If n samples are included in the analysis, there will be n dimensional spaces that represent the common ancestry maps based on the identity-by-descent (IBD). The package calculates the correlations of loci with the common ancestry genetic maps adopting the Genomic Data Structure (GDS, Zheng et al., 2012) <doi:10.1093/bioinformatics/bts606> and suitable for millions of SNP data. Loci sharing a greater level of most recent common ancestor (MRCA) (large Z-scores) indicates a large number of individuals descend from recent common ancestors, 
  which signals the rapid increase in frequency of a beneficial allele due to recent positive selection. The rationale underlying this package is somewhat analogous to KLFDAPT (Qin, 2021) <doi:10.1101/2021.05.15.444294> (<https://xinghuq.github.io/KLFDAPC/articles/Genome_scan_KLFDAPC.html>). It combines the concept of IBD-based genome scan (Albrechtsen et al., 2010) <doi:10.1534/genetics.110.113977>, iHS (Voight, 2006) <doi:10.1371/journal.pbio.0040072>, 
  and eigenanalysis of SNP data with an identity by descent interpretation (Zheng & Weir, 2016) <doi: 10.1016/j.tpb.2015.09.004>. It can also be interpreted as spatial varying selection as ancestry genetic maps reflect geographic origins. Besides the detection of local adaptation, this package also estimates the population admixtures and plots its geographic genetic structure.  ",2021-11-11,Xinghu Qin,https://github.com/xinghuq/GenomeAdapt,TRUE,https://github.com/xinghuq/genomeadapt,2174,0,2021-11-09T15:33:09Z,NA
GenomeAdmixR,"Individual-based simulations forward in time,
    simulating how patterns in ancestry along the genome change after
    admixture. Full description can be found in Janzen (2021)
    <doi:10.1111/2041-210X.13612>.",2022-03-01,Thijs Janzen,https://github.com/thijsjanzen/GenomeAdmixR,TRUE,https://github.com/thijsjanzen/genomeadmixr,6887,4,2022-02-28T09:18:11Z,1721.75
genridge,"
	The genridge package introduces generalizations of the standard univariate
	ridge trace plot used in ridge regression and related methods.  These graphical methods
	show both bias (actually, shrinkage) and precision, by plotting the covariance ellipsoids of the estimated
	coefficients, rather than just the estimates themselves.  2D and 3D plotting methods are provided,
	both in the space of the predictor variables and in the transformed space of the PCA/SVD of the
	predictors.  ",2020-01-29,Michael Friendly,NA,TRUE,https://github.com/friendly/genridge,19003,0,2022-06-03T01:01:10Z,NA
genSurv,"Generation of survival data with one (binary)
  time-dependent covariate.  Generation of survival data arising
  from a progressive illness-death model.",2021-10-19,Artur Araujo,https://github.com/arturstat/genSurv,TRUE,https://github.com/arturstat/gensurv,17333,0,2021-11-11T18:44:32Z,NA
geocmeans,"Provides functions to apply spatial fuzzy unsupervised classification, visualize and interpret results. This method is well suited when the user wants to analyze data with a fuzzy clustering algorithm and to account for the spatial dimension of the dataset. In addition, indexes for estimating the spatial consistency and classification quality are proposed.
    The methods were originally proposed in the field of brain imagery (seed Cai and al. 2007 <doi:10.1016/j.patcog.2006.07.011> and Zaho and al. 2013 <doi:10.1016/j.dsp.2012.09.016>) and recently applied in geography (see Gelb and Apparicio <doi:10.4000/cybergeo.36414>).",2022-06-16,Jeremy Gelb,https://github.com/JeremyGelb/geocmeans,TRUE,https://github.com/jeremygelb/geocmeans,5687,18,2022-06-04T04:42:02Z,315.94444444444446
geodata,"Functions for downloading of geographic data for use in spatial analysis and mapping. The package facilitates access to climate, elevation, land use, soil, species occurrence, accessibility, administrative boundaries and other data.",2022-04-09,Robert J. Hijmans,NA,TRUE,https://github.com/rspatial/geodata,10573,69,2022-07-08T23:39:47Z,153.231884057971
geodist,"Dependency-free, ultra fast calculation of geodesic
    distances.  Includes the reference nanometre-accuracy geodesic
    distances of Karney (2013) <doi:10.1007/s00190-012-0578-z>, as used by
    the 'sf' package, as well as Haversine and Vincenty distances. Default
    distance measure is the ""Mapbox cheap ruler"" which is generally more
    accurate than Haversine or Vincenty for distances out to a few hundred
    kilometres, and is considerably faster. The main function accepts one
    or two inputs in almost any generic rectangular form, and returns
    either matrices of pairwise distances, or vectors of sequential
    distances.",2021-01-27,Mark Padgham,https://github.com/hypertidy/geodist,TRUE,https://github.com/hypertidy/geodist,57986,81,2022-07-07T12:53:34Z,715.8765432098766
geodiv,"Methods for calculating gradient surface metrics for
    continuous analysis of landscape features. ",2022-04-08,Annie C. Smith,https://github.com/bioXgeo/geodiv,TRUE,https://github.com/bioxgeo/geodiv,15863,9,2022-04-07T17:22:36Z,1762.5555555555557
geodrawr,"Draw geospatial objects by clicks on the map.
    This packages can help data analyst who want to check
    their own geospatial hypothesis but has no ready-made geospatial objects.",2020-11-08,Heoncheol Ha,https://github.com/Curycu/geodrawr,TRUE,https://github.com/curycu/geodrawr,8574,3,2021-08-21T09:40:11Z,2858
GeodRegr,"Provides a gradient descent algorithm to find a geodesic relationship between real-valued independent variables and a manifold-valued dependent variable (i.e. geodesic regression). Available manifolds are Euclidean space, the sphere, hyperbolic space, and Kendall's 2-dimensional shape space. Besides the standard least-squares loss, the least absolute deviations, Huber, and Tukey biweight loss functions can also be used to perform robust geodesic regression. Functions to help choose appropriate cutoff parameters to maintain high efficiency for the Huber and Tukey biweight estimators are included, as are functions for generating random tangent vectors from the Riemannian normal distributions on the sphere and hyperbolic space. The n-sphere is a n-dimensional manifold: we represent it as a sphere of radius 1 and center 0 embedded in (n+1)-dimensional space. Using the hyperboloid model of hyperbolic space, n-dimensional hyperbolic space is embedded in (n+1)-dimensional Minkowski space as the upper sheet of a hyperboloid of two sheets. Kendall's 2D shape space with K landmarks is of real dimension 2K-4; preshapes are represented as complex K-vectors with mean 0 and magnitude 1. Details are described in Shin, H.-Y. and Oh, H.-S. (2020) <arXiv:2007.04518>. Also see Fletcher, P. T. (2013) <doi:10.1007/s11263-012-0591-y>.",2021-09-03,Ha-Young Shin,https://github.com/hayoungshin1/GeodRegr,TRUE,https://github.com/hayoungshin1/geodregr,6689,0,2021-08-28T04:19:56Z,NA
geofi,Tools for reading Finnish open geospatial data in R.,2022-01-30,Markus Kainu,"https://ropengov.github.io/geofi/,
https://github.com/rOpenGov/geofi",TRUE,https://github.com/ropengov/geofi,8046,10,2022-05-13T12:09:06Z,804.6
geojsonio,"Convert data to 'GeoJSON' or 'TopoJSON' from various R classes,
    including vectors, lists, data frames, shape files, and spatial classes.
    'geojsonio' does not aim to replace packages like 'sp', 'rgdal', 'rgeos',
    but rather aims to be a high level client to simplify conversions of data
    from and to 'GeoJSON' and 'TopoJSON'.",2021-01-13,Scott Chamberlain,"https://github.com/ropensci/geojsonio (devel),
https://docs.ropensci.org/geojsonio/ (docs)",TRUE,https://github.com/ropensci/geojsonio,339851,141,2021-12-18T16:06:14Z,2410.290780141844
geojsonsf,Converts Between GeoJSON and simple feature objects. ,2022-05-30,David Cooley,https://github.com/SymbolixAU/geojsonsf,TRUE,https://github.com/symbolixau/geojsonsf,621149,70,2022-05-30T22:42:43Z,8873.557142857142
geoknife,"Processes gridded datasets found on the U.S. Geological Survey
    Geo Data Portal web application or elsewhere, using a web-enabled workflow
    that eliminates the need to download and store large datasets that are reliably
    hosted on the Internet. The package provides access to several data subset and
    summarization algorithms that are available on remote web processing servers (Read et al. (2015) <doi:10.1111/ecog.01880>).",2021-12-10,David Blodgett,https://github.com/USGS-R/geoknife,TRUE,https://github.com/usgs-r/geoknife,66565,64,2022-02-06T03:46:37Z,1040.078125
geomander,"A compilation of tools to complete common tasks for studying gerrymandering. This focuses on the geographic tool side of common problems, such as linking different levels of spatial units or estimating how to break up units. Functions exist for creating redistricting-focused data for the US.",2022-06-23,Christopher T. Kenny,"https://www.christophertkenny.com/geomander/,
https://github.com/christopherkenny/geomander",TRUE,https://github.com/christopherkenny/geomander,5777,10,2022-06-30T04:00:31Z,577.7
geomaroc,"Tools to easily visualize geographic data of Morocco.
    This package interacts with data available through the
    'geomarocdata' package, which is available in a 'drat' 
    repository.   The size of the 'geomarocdata' package is
    approximately 12 MB. ",2022-05-13,Amine Andam,https://github.com/AmineAndam04/R-geomaroc,TRUE,https://github.com/amineandam04/r-geomaroc,410,3,2022-05-19T11:18:45Z,136.66666666666666
geometr,"Provides tools that generate and process fully accessible and tidy
    geometric shapes. The package improves interoperability of spatial and 
    other geometric classes by providing getters and setters that produce 
    identical output from various classes.",2021-09-20,Steffen Ehrmann,https://ehrmanns.github.io/geometr/,TRUE,https://github.com/ehrmanns/geometr,12814,13,2021-11-12T11:17:10Z,985.6923076923077
geometries,"Geometry shapes in 'R' are typically represented by matrices (points, lines), with more complex 
  shapes being lists of matrices (polygons). 'Geometries' will convert various 'R' objects into these shapes. 
  Conversion functions are available at both the 'R' level, and through 'Rcpp'.",2020-11-26,David Cooley,https://dcooley.github.io/geometries/,TRUE,https://github.com/dcooley/geometries,451910,25,2021-09-04T00:34:17Z,18076.4
geometry,"Makes the 'Qhull' library <http://www.qhull.org>
    available in R, in a similar manner as in Octave and MATLAB. Qhull
    computes convex hulls, Delaunay triangulations, halfspace
    intersections about a point, Voronoi diagrams, furthest-site
    Delaunay triangulations, and furthest-site Voronoi diagrams. It
    runs in 2D, 3D, 4D, and higher dimensions. It implements the
    Quickhull algorithm for computing the convex hull. Qhull does not
    support constrained Delaunay triangulations, or mesh generation of
    non-convex objects, but the package does include some R functions
    that allow for this.",2022-07-04,Jean-Romain Roussel [cph,https://davidcsterratt.github.io/geometry/,TRUE,https://github.com/davidcsterratt/geometry,505717,15,2022-04-18T09:15:30Z,33714.46666666667
GeoModels,"Functions for Gaussian and Non Gaussian (bivariate) spatial and spatio-temporal data analysis are provided for a) simulation and inference  for random fields using standard likelihood and a likelihood approximation  method called  weighted composite likelihood based on pairs and b) prediction using (local) best linear unbiased prediction. Weighted composite likelihood can be very efficient for estimating massive datasets. Both regression and spatial (temporal) dependence analysis can be jointly performed. Covariance functions for spatial and spatial-temporal data on Euclidean domains and spheres are provided. There are also many useful functions for plotting and performing diagnostic analysis. Different non Gaussian random fields can be considered in the analysis. Among them, random fields with marginal distributions such as Skew-Gaussian, Student-t, Tukey-h, Sin-Arcsin, Two-piece, Weibull, Gamma, Log-Gaussian, Binomial, Negative Binomial  and Poisson. See the URL for the papers associated with this package, as for instance, Bevilacqua and Gaetan (2015) <doi:10.1007/s11222-014-9460-6>, Bevilacqua et al. (2016) <doi:10.1007/s13253-016-0256-3>, Vallejos et al. (2020) <doi:10.1007/978-3-030-56681-4>, Bevilacqua et al. (2022) <doi:10.1016/j.jmva.2022.104949>, Bevilacqua et al. (2022) <doi:10.1007/s11749-021-00797-5>, Blasi et al. (2022) <doi:10.1016/j.spasta.2022.100596>, Morales-Navarrete et al. (2022) <arXiv:2105.03734>, and a large class of examples and tutorials.",2022-06-05,Moreno Bevilacqua,https://vmoprojs.github.io/GeoModels-page/,TRUE,https://github.com/vmoprojs/geomodels,466,2,2022-05-25T12:26:38Z,233
GeoMongo,"Utilizes methods of the 'PyMongo' 'Python' library to initialize, insert and query 'GeoJson' data (see <https://github.com/mongodb/mongo-python-driver> for more information on 'PyMongo'). Furthermore, it allows the user to validate 'GeoJson' objects and to use the console for 'MongoDB' (bulk) commands. The 'reticulate' package provides the 'R' interface to 'Python' modules, classes and functions.",2021-09-11,Lampros Mouselimis,https://github.com/mlampros/GeoMongo,TRUE,https://github.com/mlampros/geomongo,16393,1,2021-09-17T19:28:12Z,16393
geomorph,"Read, manipulate, and digitize landmark data, generate shape
    variables via Procrustes analysis for points, curves and surfaces, perform
    shape analyses, and provide graphical depictions of shapes and patterns of
    shape variation.",2022-06-23,Dean Adams,https://github.com/geomorphR/geomorph,TRUE,https://github.com/geomorphr/geomorph,82065,65,2022-06-22T18:03:22Z,1262.5384615384614
geomtextpath,"A 'ggplot2' extension that allows text to follow curved paths.
    Curved text makes it easier to directly label paths or neatly annotate in 
    polar co-ordinates.",2022-01-24,Allan Cameron,https://allancameron.github.io/geomtextpath/,TRUE,https://github.com/allancameron/geomtextpath,5935,494,2022-02-19T11:37:31Z,12.01417004048583
geos,"Provides an R API to the Open Source Geometry Engine
  ('GEOS') library (<https://trac.osgeo.org/geos/>) and a vector format 
  with which to efficiently store 'GEOS' geometries. High-performance functions 
  to extract information from, calculate relationships between, and
  transform geometries are provided. Finally, facilities to import 
  and export geometry vectors to other spatial formats are provided.",2021-11-07,Dewey Dunnington,"https://paleolimbot.github.io/geos/,
https://github.com/paleolimbot/geos/",TRUE,https://github.com/paleolimbot/geos,15925,44,2021-11-07T15:12:15Z,361.9318181818182
geosapi,"Provides an R interface to the GeoServer REST API, allowing to upload 
 and publish data in a GeoServer web-application and expose data to OGC Web-Services. 
 The package currently supports all CRUD (Create,Read,Update,Delete) operations
 on GeoServer workspaces, namespaces, datastores (stores of vector data), featuretypes,
 layers, styles, as well as vector data upload operations. For more information about 
 the GeoServer REST API, see <https://docs.geoserver.org/stable/en/user/rest/>.",2022-06-17,Emmanuel Blondel,"https://github.com/eblondel/geosapi,
https://eblondel.github.io/geosapi/, https://geoserver.org/",TRUE,https://github.com/eblondel/geosapi,22655,24,2022-07-04T14:39:48Z,943.9583333333334
geospark,"R binds 'GeoSpark' <http://geospark.datasyslab.org/> extending 'sparklyr' 
    <https://spark.rstudio.com/> R package to make distributed 'geocomputing' easier. Sf is a
    package that provides [simple features] <https://en.wikipedia.org/wiki/Simple_Features> access
    for R and which is a leading 'geospatial' data processing tool. 'Geospark' R package bring 
    the same simple features access like sf but running on Spark distributed system.",2020-03-02,Harry Zhu,NA,TRUE,https://github.com/harryprince/geospark,219630,51,2021-12-13T11:41:21Z,4306.470588235294
geosphere,"Spherical trigonometry for geographic applications. That is, compute distances and related measures for angular (longitude/latitude) locations. ",2021-10-13,Robert J. Hijmans,NA,TRUE,https://github.com/rspatial/geosphere,1298893,21,2022-06-17T07:00:52Z,61852.04761904762
geostan,"For Bayesian inference with spatial data, provides exploratory analysis tools, multiple spatial model specifications, spatial model diagnostics, and special methods for inference with small area survey data (e.g., the America Community Survey (ACS)). Models are pre-specified using the Stan programming language, a platform for Bayesian inference using Markov chain Monte Carlo (MCMC). References: Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>; Donegan, Chun and Hughes (2020) <doi:10.1016/j.spasta.2020.100450>; Donegan, Chun and Griffith (2021) <doi:10.3390/ijerph18136856>; Morris et al. (2019) <doi:10.1016/j.sste.2019.100301>.",2022-02-09,Connor Donegan,"https://connordonegan.github.io/geostan/,
https://github.com/ConnorDonegan/geostan/",TRUE,https://github.com/connordonegan/geostan,1391,35,2022-06-30T17:44:02Z,39.74285714285714
geostats,"A collection of datasets and simplified functions for an introductory (geo)statistics module at University College London. Provides functionality for compositional, directional and spatial data, including ternary diagrams, Wulff and Schmidt stereonets, and ordinary kriging interpolation. Implements logistic and (additive and centred) logratio transformations. Computes vector averages and concentration parameters for the von-Mises distribution. Includes a collection of natural and synthetic fractals, and a simulator for deterministic chaos using a magnetic pendulum example. The main purpose of these functions is pedagogical. Researchers can find more complete alternatives for these tools in other packages such as 'compositions', 'robCompositions', 'sp', 'gstat' and 'RFOC'. All the functions are written in plain R, with no compiled code and a minimal number of dependencies. Theoretical background and worked examples are available at <https://tinyurl.com/UCLgeostats/>.",2022-03-07,Pieter Vermeesch,https://github.com/pvermees/geostats/,TRUE,https://github.com/pvermees/geostats,13896,11,2022-05-19T13:26:42Z,1263.2727272727273
geotopbricks,"It analyzes raster maps and other information as input/output
    files from the Hydrological Distributed Model GEOtop. It contains functions
    and methods to import maps and other keywords from geotop.inpts file. Some
    examples with simulation cases of GEOtop 2.x/3.x are presented in the package.
    Any information about the GEOtop Distributed Hydrological Model source code
    is available on www.geotop.org. Technical details about the model are
    available in Endrizzi et al, 2014
    (<http://www.geosci-model-dev.net/7/2831/2014/gmd-7-2831-2014.html>).",2020-02-11,Emanuele Cordano,"http://www.geotop.org, https://github.com/ecor/geotopbricks",TRUE,https://github.com/ecor/geotopbricks,18923,3,2022-02-23T16:51:12Z,6307.666666666667
geouy,"The toolbox have functions to load and process geographic information for Uruguay. 
        And extra-function to get address coordinates and orthophotos through the uruguayan 'IDE' API <https://www.gub.uy/infraestructura-datos-espaciales/tramites-y-servicios/servicios/servicio-direcciones-geograficas>.",2021-08-17,Richard Detomasi,NA,TRUE,https://github.com/richdeto/geouy,18834,12,2022-07-07T21:54:51Z,1569.5
GeoWeightedModel,"Contains the development of a tool that provides a web-based
    graphical user interface (GUI) to perform Techniques from a subset of
    spatial statistics known as geographically weighted (GW) models.
    Contains methods described by Brunsdon et al., 1996
    <doi:10.1111/j.1538-4632.1996.tb00936.x>, Brunsdon et al., 2002
    <doi:10.1016/s0198-9715(01)00009-6>, Harris et al., 2011
    <doi:10.1080/13658816.2011.554838>, Brunsdon et al., 2007
    <doi:10.1111/j.1538-4632.2007.00709.x>.",2022-05-24,Javier De La Hoz Maestre,NA,TRUE,https://github.com/javierdelahoz/geoweightedmodel,2029,0,2022-01-08T22:25:56Z,NA
GerminaR,A collection of different indices and visualization techniques for evaluate the seed germination process in ecophysiological studies (Lozano-Isla et al. 2019) <doi:10.1111/1440-1703.1275>.,2022-05-18,Flavio Lozano-Isla,"https://germinar.inkaverse.com/,
https://github.com/flavjack/germinar",TRUE,https://github.com/flavjack/germinar,20965,2,2022-05-29T16:19:10Z,10482.5
germinationmetrics,"Provides functions to compute various germination indices such as
    germinability, median germination time, mean germination time, mean
    germination rate, speed of germination, Timson's index, germination value,
    coefficient of uniformity of germination, uncertainty of germination
    process, synchrony of germination etc. from germination count data. Includes
    functions for fitting cumulative seed germination curves using
    four-parameter hill function and computation of associated parameters. See
    the vignette for more, including full list of citations for the methods
    implemented.",2022-06-15,J. Aravind,"https://github.com/aravind-j/germinationmetrics,
https://aravind-j.github.io/germinationmetrics/
https://CRAN.R-project.org/package=germinationmetrics
https://doi.org/10.5281/zenodo.1219630",TRUE,https://github.com/aravind-j/germinationmetrics,17570,2,2022-07-03T21:22:41Z,8785
gert,"Simple git client for R based on 'libgit2' <https://libgit2.org> with
    support for SSH and HTTPS remotes. All functions in 'gert' use basic R data 
    types (such as vectors and data-frames) for their arguments and return values.
    User credentials are shared with command line 'git' through the git-credential
    store and ssh keys stored on disk or ssh-agent.",2022-03-29,Jeroen Ooms,"https://docs.ropensci.org/gert/, https://github.com/r-lib/gert",TRUE,https://github.com/r-lib/gert,5205456,127,2022-05-25T11:54:46Z,40987.84251968504
gesisdata,"Reproducible, programmatic retrieval of datasets from the
    GESIS Data Archive.  The GESIS Data Archive <https://search.gesis.org>  
    makes available thousands of invaluable datasets, but researchers using
    these datasets are caught in a bind.  The archive's terms and conditions
    bar dissemination of downloaded datasets to third parties, but to ensure 
    that one's work can be reproduced, assessed, and built upon by others, one
    must provide access to the raw data one has employed.  The 'gesisdata'
    package cuts this knot by providing registered users with programmatic,
    reproducible access to GESIS datasets from within 'R'.",2020-06-26,Frederick Solt,https://github.com/fsolt/gesisdata,TRUE,https://github.com/fsolt/gesisdata,7136,6,2021-10-21T19:41:58Z,1189.3333333333333
gestalt,"Provides a suite of function-building tools centered around a
  (forward) composition operator, %>>>%, which extends the semantics of the
  'magrittr' %>% operator and supports 'Tidyverse' quasiquotation. It enables
  you to construct composite functions that can be inspected and transformed as
  list-like objects. In conjunction with %>>>%, a compact function constructor,
  fn(), and a partial-application constructor, partial(), are also provided;
  both support quasiquotation.",2022-02-02,Eugene Ha,https://github.com/egnha/gestalt,TRUE,https://github.com/egnha/gestalt,14541,36,2022-07-06T05:59:00Z,403.9166666666667
gesttools,"Provides a series of general purpose tools to perform g-estimation using the methods described in Sjolander and Vansteelandt (2016) <doi:10.1515/em-2015-0005> and Dukes and Vansteelandt <doi:10.1093/aje/kwx347>. The package allows for g-estimation in a wide variety of circumstances, including an end of study or time-varying outcome, and an exposure that is a binary, continuous, or a categorical variable with three or more categories. The package also supports g-estimation with time-varying causal effects and effect modification by a confounding variable.",2022-01-04,Daniel Tompsett,https://github.com/danieltompsett/gesttools,TRUE,https://github.com/danieltompsett/gesttools,7086,2,2022-01-04T05:00:49Z,3543
GetBCBData,"Downloads and organizes datasets using BCB's API <https://www.bcb.gov.br/>. Offers options for caching with the 'memoise' package and
    , multicore/multisession with 'furrr' and format of output data (long/wide). ",2022-06-07,Marcelo Perlin,https://github.com/msperlin/GetBCBData/,TRUE,https://github.com/msperlin/getbcbdata,18991,11,2022-06-07T19:05:24Z,1726.4545454545455
GetDFPData2,"Reads annual and quarterly financial reports from companies traded at B3, the Brazilian exchange 
            <https://www.b3.com.br/>. 
            All data is downloaded and imported from CVM's public ftp site <http://dados.cvm.gov.br/dados/CIA_ABERTA/>.",2022-06-09,Marcelo Perlin,https://github.com/msperlin/GetDFPData2/,TRUE,https://github.com/msperlin/getdfpdata2,6716,20,2022-06-09T21:16:59Z,335.8
GetFREData,"Reads corporate data such as board composition and compensation for companies traded at B3, 
             the Brazilian exchange <https://www.b3.com.br/>. All data is downloaded and imported from the ftp site <http://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/FRE/>.",2022-06-13,Marcelo Perlin,https://github.com/msperlin/GetFREData/,TRUE,https://github.com/msperlin/getfredata,5794,4,2022-06-13T11:23:20Z,1448.5
getlandsat,"Get Landsat 8 Data from Amazon Web Services ('AWS')
    public data sets (<https://registry.opendata.aws/landsat-8/>).
    Includes functions for listing images and fetching them, and handles
    caching to prevent unnecessary additional requests.",2018-04-30,Scott Chamberlain,https://github.com/ropensci/getlandsat,TRUE,https://github.com/ropensci/getlandsat,15912,57,2021-10-04T10:35:08Z,279.1578947368421
getLattes,"Tool for import and process data from 'Lattes' curriculum platform (<http://lattes.cnpq.br/>). The Brazilian government keeps an extensive base of curricula for academics from all over the country, with over 5 million registrations. The academic life of the Brazilian researcher, or related to Brazilian universities, is documented in 'Lattes'. Some information that can be obtained: professional formation, research area, publications, academics advisories, projects, etc. 'getLattes' package allows work with 'Lattes' data exported to XML format.",2021-06-11,Roney Fraga Souza,https://github.com/roneyfraga/getLattes,TRUE,https://github.com/roneyfraga/getlattes,6498,3,2022-02-14T13:38:06Z,2166
GetLattesData,A simple API for downloading and reading xml data directly from Lattes <http://lattes.cnpq.br/>.,2022-06-08,Marcelo Perlin,https://github.com/msperlin/GetLattesData/,TRUE,https://github.com/msperlin/getlattesdata,17839,13,2022-06-08T12:53:53Z,1372.2307692307693
getopt,"Package designed to be used with Rscript to write
    ``#!'' shebang scripts that accept short and long flags/options.
    Many users will prefer using instead the packages optparse or argparse
    which add extra features like automatically generated help option and usage,
    support for default values, positional argument support, etc.",2019-03-22,Trevor L Davis,https://github.com/trevorld/r-getopt,TRUE,https://github.com/trevorld/r-getopt,860086,12,2021-10-08T15:07:38Z,71673.83333333333
GetoptLong,"This is a command-line argument parser which wraps the 
    powerful Perl module Getopt::Long and with some adaptations for easier use
	in R. It also provides a simple way for variable interpolation in R.",2020-12-15,Zuguang Gu,https://github.com/jokergoo/GetoptLong,TRUE,https://github.com/jokergoo/getoptlong,404376,14,2022-03-31T20:34:28Z,28884
getProxy,"Allows get address and port 
	of the free proxy server, from one of two services
	<http://gimmeproxy.com/> or <https://getproxylist.com/>. 
	And it's easy to redirect your Internet connection through
	a proxy server.",2022-01-05,Alexey Seleznev,https://selesnow.github.io/getProxy/,TRUE,https://github.com/selesnow/getproxy,13181,7,2022-01-06T06:42:15Z,1883
gets,"Automated General-to-Specific (GETS) modelling of the mean and variance of a regression, and indicator saturation methods for detecting and testing for structural breaks in the mean, see Pretis, Reade and Sucarrat (2018) <doi:10.18637/jss.v086.i03>.",2022-07-03,Genaro Sucarrat,"https://CRAN.R-project.org/package=gets,
http://www.sucarrat.net/R/gets/",TRUE,https://github.com/gsucarrat/gets,40543,5,2022-07-04T07:40:01Z,8108.6
GetTDData,Downloads and aggregates data for Brazilian government issued bonds directly from the website of Tesouro Direto <https://www.tesourodireto.com.br/>.,2022-05-11,Marcelo Perlin,"https://github.com/msperlin/GetTDData/,
https://msperlin.github.io/GetTDData/",TRUE,https://github.com/msperlin/gettddata,26711,16,2022-05-11T11:21:34Z,1669.4375
gettz,"A function to retrieve the system timezone on Unix systems
 which has been found to find an answer when 'Sys.timezone()' has failed.
 It is based on an answer by Duane McCully posted on 'StackOverflow', and
 adapted to be callable from R. The package also builds on Windows, but
 just returns NULL.",2020-04-14,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/gettz.html,TRUE,https://github.com/eddelbuettel/gettz,30377,1,2021-11-09T03:16:07Z,30377
geysertimes,"Download geyser eruption and observation data from the GeyserTimes
  site (<https://geysertimes.org>) and optionally store it locally. The vignette
  shows a simple analysis of downloading, accessing, and summarizing the data.",2021-09-09,Stephen Kaluzny,https://github.com/geysertimes/geysertimes-r-package,TRUE,https://github.com/geysertimes/geysertimes-r-package,7170,2,2022-06-12T02:16:07Z,3585
GFDsurv,"Implemented are three Wald-type statistic and respective
  permuted versions for null hypotheses formulated in terms of cumulative hazard rate functions, medians and the concordance measure, respectively, in the general framework of survival factorial designs with possibly heterogeneous survival and/or censoring distributions, for crossed designs with an arbitrary number of factors and nested designs with up to three factors.
	Ditzhaus, Dobler and Pauly (2020) <doi:10.1177/0962280220980784> 
	Ditzhaus, Janssen, Pauly (2020) <arXiv: 2004.10818v2>
	Dobler and Pauly (2019) <doi:10.1177/0962280219831316>.",2021-07-14,Philipp Steinhauer,https://github.com/PhilippSteinhauer/GFDsurv,TRUE,https://github.com/philippsteinhauer/gfdsurv,5091,0,2021-07-14T08:33:24Z,NA
gfer,"Focuses on data collecting, analyzing and visualization in green finance and environmental 
  risk research and analysis. Main function includes environmental data collecting from 
  official websites such as MEP (Ministry of Environmental Protection of China, <https://www.mee.gov.cn>), water 
  related projects identification and environmental data visualization.",2022-02-06,Yuanchao Xu,https://yuanchao-xu.github.io/gfer/,TRUE,https://github.com/yuanchao-xu/gfer,17186,7,2022-02-06T15:24:11Z,2455.1428571428573
GFM,"Generalized factor model for ultra-high dimensional variables with mixed types.
    We develop a two-step iterative procedure so that each update can be 
    carried out in parallel across all variables and samples. The fast 
    computation version is provided for ultra-high dimensional data,
    see examples for more details. More details can be referred to 
    Wei Liu, Huazhen Lin, Shurong Zheng and Jin Liu. (2021) <doi:10.1080/01621459.2021.1999818>. ",2022-01-05,Wei Liu,https://github.com/feiyoung/GFM,TRUE,https://github.com/feiyoung/gfm,1595,2,2021-12-29T06:09:32Z,797.5
gfonts,"Download 'Google' fonts and generate 'CSS' to use in 'rmarkdown' documents and 
  'shiny' applications. Some popular fonts are included and ready to use.",2021-09-22,Victor Perrier,https://github.com/dreamRs/gfonts,TRUE,https://github.com/dreamrs/gfonts,12768,96,2021-12-11T17:59:52Z,133
gfoRmula,"Implements the parametric g-formula algorithm of Robins (1986) 
    <doi:10.1016/0270-0255(86)90088-6>. The g-formula can be used to estimate 
    the causal effects of hypothetical time-varying treatment interventions on 
    the mean or risk of an outcome from longitudinal data with time-varying 
    confounding. This package allows: 1) binary or continuous/multi-level 
    time-varying treatments; 2) different types of outcomes (survival or 
    continuous/binary end of follow-up); 3) data with competing events or 
    truncation by death and loss to follow-up and other types of censoring 
    events; 4) different options for handling competing events in the case of 
    survival outcomes; 5) a random measurement/visit process; 6) joint 
    interventions on multiple treatments; and 7) general incorporation of a 
    priori knowledge of the data structure.",2022-04-09,Victoria Lin,"https://github.com/CausalInference/gfoRmula,
https://www.cell.com/patterns/fulltext/S2666-3899(20)30008-8",TRUE,https://github.com/causalinference/gformula,16458,91,2022-06-30T22:07:40Z,180.85714285714286
ggalluvial,"Alluvial plots use variable-width ribbons and stacked bar plots to
    represent multi-dimensional or repeated-measures data with categorical or
    ordinal variables; see Riehmann, Hanfler, and Froehlich (2005)
    <doi:10.1109/INFVIS.2005.1532152> and Rosvall and Bergstrom (2010)
    <doi:10.1371/journal.pone.0008694>.
    Alluvial plots are statistical graphics in the sense of Wilkinson (2006)
    <doi:10.1007/0-387-28695-0>; they share elements with Sankey diagrams and
    parallel sets plots but are uniquely determined from the data and a small
    set of parameters. This package extends Wickham's (2010)
    <doi:10.1198/jcgs.2009.07098> layered grammar of graphics to generate
    alluvial plots from tidy data.",2020-12-05,Jason Cory Brunson,http://corybrunson.github.io/ggalluvial/,TRUE,https://github.com/corybrunson/ggalluvial,185618,402,2022-01-09T13:37:52Z,461.7363184079602
GGally,"
    The R package 'ggplot2' is a plotting system based on the grammar of graphics.
    'GGally' extends 'ggplot2' by adding several functions
    to reduce the complexity of combining geometric objects with transformed data.
    Some of these functions include a pairwise plot matrix, a two group pairwise plot
    matrix, a parallel coordinates plot, a survival plot, and several functions to
    plot networks.",2021-06-21,Barret Schloerke,"https://ggobi.github.io/ggally/, https://github.com/ggobi/ggally",TRUE,https://github.com/ggobi/ggally,2269348,503,2022-01-14T16:26:29Z,4511.626242544731
ggbeeswarm,"Provides two methods of plotting categorical scatter plots such
    that the arrangement of points within a category reflects the density of
    data at that region, and avoids over-plotting.",2017-08-07,Erik Clarke,https://github.com/eclarke/ggbeeswarm,TRUE,https://github.com/eclarke/ggbeeswarm,431941,429,2021-11-08T16:20:36Z,1006.8554778554778
ggblanket,"Wrapper functions around the amazing 'ggplot2' package to simplify 
      pretty visualisation. ",2022-07-01,David Hodge,"https://github.com/davidhodge931/ggblanket/,
https://davidhodge931.github.io/ggblanket/",TRUE,https://github.com/davidhodge931/ggblanket,1271,54,2022-07-10T08:46:06Z,23.537037037037038
ggborderline,"A set of geometries to make line plots a little bit nicer. Use 
    along with 'ggplot2' to:
    - Improve the clarity of line plots with many overlapping lines
    - Draw more realistic worms.",2021-08-09,Jacob Scott,"https://github.com/wurli/ggborderline,
https://wurli.github.io/ggborderline/",TRUE,https://github.com/wurli/ggborderline,3713,12,2021-08-12T19:13:35Z,309.4166666666667
ggbraid,"A new stat, stat_braid(), that extends the functionality of
    geom_ribbon() to correctly fill the area between two alternating lines
    (or steps) with two different colors, and a geom, geom_braid(), that
    wraps geom_ribbon() and uses stat_braid() by default.",2022-05-17,Neal Grantham,"https://nsgrantham.github.io/ggbraid/,
https://github.com/nsgrantham/ggbraid/",TRUE,https://github.com/nsgrantham/ggbraid,432,61,2022-05-14T06:12:00Z,7.081967213114754
ggbreak,An implementation of scale functions for setting axis breaks of a 'gg' plot.,2022-06-01,Guangchuang Yu,"https://github.com/YuLab-SMU/ggbreak (devel),
https://www.frontiersin.org/articles/10.3389/fgene.2021.774846/full
(article)",TRUE,https://github.com/yulab-smu/ggbreak,25594,80,2022-06-01T04:07:34Z,319.925
ggcharts,"Streamline the creation of common charts by taking care of a lot of
    data preprocessing and plot customization for the user. Provides a
    high-level interface to create plots using 'ggplot2'.",2020-05-20,Thomas Neitmann,https://github.com/thomas-neitmann/ggcharts,TRUE,https://github.com/thomas-neitmann/ggcharts,19788,254,2021-10-04T14:44:17Z,77.90551181102362
ggcleveland,"William S. Cleveland's book 'Visualizing Data' is a classic piece 
	of literature on Exploratory Data Analysis. Although it was written 
	several decades ago, its content is still relevant as it proposes several 
	tools which are useful to discover patterns and relationships among the data 
	under study, and also to assess the goodness of fit o a model.  This package 
	provides functions to produce the 'ggplot2' versions of the visualization tools 
	described in this book and is thought to be used in the context of courses on 
	Exploratory Data Analysis.",2021-08-16,Marcos Prunello,https://github.com/mpru/ggcleveland,TRUE,https://github.com/mpru/ggcleveland,3809,4,2021-09-29T16:14:39Z,952.25
ggdag,"Tidy, analyze, and plot directed acyclic graphs (DAGs).
    'ggdag' is built on top of 'dagitty', an R package that uses the
    'DAGitty' web tool (<http://dagitty.net>) for creating and analyzing
    DAGs. 'ggdag' makes it easy to tidy and plot 'dagitty' objects using
    'ggplot2' and 'ggraph', as well as common analytic and graphical
    functions, such as determining adjustment sets and node relationships.",2021-10-10,Malcolm Barrett,https://github.com/malcolmbarrett/ggdag,TRUE,https://github.com/malcolmbarrett/ggdag,59125,349,2022-04-14T17:20:54Z,169.41260744985672
ggdemetra,"Provides 'ggplot2' functions to return the results of seasonal and trading day adjustment 
    made by 'RJDemetra'. 'RJDemetra' is an 'R' interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>),
    the seasonal adjustment software officially recommended to the members of the European Statistical System and
    the European System of Central Banks.",2020-12-02,Alain Quartier-la-Tente,https://github.com/AQLT/ggdemetra,TRUE,https://github.com/aqlt/ggdemetra,16643,10,2021-10-20T20:18:59Z,1664.3
ggdendro,"This is a set of tools for dendrograms and
    tree plots using 'ggplot2'.  The 'ggplot2' philosophy is to
    clearly separate data from the presentation.
    Unfortunately the plot method for dendrograms plots
    directly to a plot device without exposing the data.
    The 'ggdendro' package resolves this by making available
    functions that extract the dendrogram plot data. The package
    provides implementations for 'tree', 'rpart', as well as diana and agnes
    (from 'cluster') diagrams.",2022-02-16,Andrie de Vries,https://github.com/andrie/ggdendro,TRUE,https://github.com/andrie/ggdendro,686210,74,2022-02-15T15:56:37Z,9273.108108108108
ggdist,"Provides primitives for visualizing distributions using 'ggplot2' that are particularly tuned for
    visualizing uncertainty in either a frequentist or Bayesian mode. Both analytical distributions (such as 
    frequentist confidence distributions or Bayesian priors) and distributions represented as samples (such as 
    bootstrap distributions or Bayesian posterior samples) are easily visualized. Visualization primitives include
    but are not limited to: points with multiple uncertainty intervals, 
    eye plots (Spiegelhalter D., 1999) <https://ideas.repec.org/a/bla/jorssa/v162y1999i1p45-58.html>,
    density plots, gradient plots, dot plots (Wilkinson L., 1999) <doi:10.1080/00031305.1999.10474474>,
    quantile dot plots (Kay M., Kola T., Hullman J., Munson S., 2016) <doi:10.1145/2858036.2858558>,
    complementary cumulative distribution function 
    barplots (Fernandes M., Walls L., Munson S., Hullman J., Kay M., 2018) <doi:10.1145/3173574.3173718>,
    and fit curves with multiple uncertainty ribbons.",2022-02-27,Matthew Kay,"https://mjskay.github.io/ggdist/,
https://github.com/mjskay/ggdist/",TRUE,https://github.com/mjskay/ggdist,188156,526,2022-04-29T02:32:07Z,357.71102661596956
ggdmc,"Hierarchical Bayesian models. The package provides tools to fit two response time models, using the population-based Markov Chain Monte Carlo. ",2019-04-29,Yi-Shin Lin,https://github.com/yxlin/ggdmc,TRUE,https://github.com/yxlin/ggdmc,14309,13,2022-06-13T10:21:42Z,1100.6923076923076
ggDoubleHeat,"A data visualization design that provides comparison between 
    two (Double) data sources (usually on a par with each other) on one 
    reformed heatmap, while inheriting 'ggplot2' features.  ",2022-03-31,Youzhi Yu,https://pursuitofdatascience.github.io/ggDoubleHeat/,TRUE,https://github.com/pursuitofdatascience/ggdoubleheat,1307,7,2022-03-31T21:44:35Z,186.71428571428572
gge,"Create biplots for GGE (genotype plus genotype-by-environment) and
    GGB (genotype plus genotype-by-block-of-environments) models. 
    See Laffont et al. (2013) <doi:10.2135/cropsci2013.03.0178>.",2021-10-31,Kevin Wright,https://kwstat.github.io/gge/,TRUE,https://github.com/kwstat/gge,31237,6,2021-10-31T23:55:43Z,5206.166666666667
ggeffects,"Compute marginal effects and adjusted predictions from statistical
    models and returns the result as tidy data frames. These data frames are 
    ready to use with the 'ggplot2'-package. Effects and predictions can be 
    calculated for many different models. Interaction terms, splines and 
    polynomial terms are also supported. The main functions are ggpredict(), 
    ggemmeans() and ggeffect(). There is a generic plot()-method to plot the 
    results using 'ggplot2'.",2022-04-10,Daniel Lüdecke,https://strengejacke.github.io/ggeffects/,TRUE,https://github.com/strengejacke/ggeffects,574835,406,2022-05-23T13:24:48Z,1415.8497536945813
ggESDA,Implements an extension of 'ggplot2' and visualizes the symbolic data with multiple plot which can be adjusted by more general and flexible input arguments. It also provides a function to transform the classical data to symbolic data by both clustering algorithm and customized method.,2022-01-10,Bo-Syue Jiang,https://github.com/kiangkiangkiang/ggESDA,TRUE,https://github.com/kiangkiangkiang/ggesda,1763,8,2022-06-16T08:21:44Z,220.375
ggExtra,"Collection of functions and layers to enhance 'ggplot2'. The 
    flagship function is 'ggMarginal()', which can be used to add marginal
    histograms/boxplots/density plots to 'ggplot2' scatterplots.",2022-03-23,Dean Attali,https://github.com/daattali/ggExtra,TRUE,https://github.com/daattali/ggextra,332623,345,2022-03-23T16:01:57Z,964.1246376811595
ggfacto,"Readable, complete and pretty graphs for correspondence analysis made 
    with 'FactoMineR'. They can be rendered as interactive 'HTML' plots, showing useful
    informations at mouse hover. The interest is not mainly visual but statistical:
    it helps the reader to keep in mind the data contained in the cross-table or Burt
    table while reading the correspondence analysis, thus preventing over-interpretation.
    Graphs are made with 'ggplot2', which means that you can use the + syntax to 
    manually add as many graphical pieces you want, or change theme elements.",2021-10-22,Brice Nocenti,https://github.com/BriceNocenti/ggfacto,TRUE,https://github.com/bricenocenti/ggfacto,2676,0,2022-04-08T19:57:37Z,NA
ggfittext,"Provides 'ggplot2' geoms to fit text into a box by growing, shrinking
    or wrapping the text.",2021-01-30,David Wilkins,https://wilkox.org/ggfittext/,TRUE,https://github.com/wilkox/ggfittext,789925,267,2021-08-29T18:49:34Z,2958.5205992509364
ggformula,Provides a formula interface to 'ggplot2' graphics.,2021-01-13,Randall Pruim,https://github.com/ProjectMOSAIC/ggformula,TRUE,https://github.com/projectmosaic/ggformula,443103,34,2022-03-03T15:27:53Z,13032.441176470587
ggfortify,"Unified plotting tools for statistics commonly used, such as GLM,
    time series, PCA families, clustering and survival analysis. The package offers
    a single plotting interface for these analysis results and plots in a unified
    style using 'ggplot2'.",2022-01-03,Yuan Tang,https://github.com/sinhrks/ggfortify,TRUE,https://github.com/sinhrks/ggfortify,1182823,496,2022-04-11T15:15:34Z,2384.7237903225805
gggenes,"Provides a 'ggplot2' geom and helper functions for drawing gene
  arrow maps.",2020-12-10,David Wilkins,https://wilkox.org/gggenes/,TRUE,https://github.com/wilkox/gggenes,29125,304,2022-03-24T09:47:47Z,95.80592105263158
gggrid,"An extension of 'ggplot2' that makes it easy to add
             raw 'grid' output, such as customised annotations, to a 
             'ggplot2' plot.  ",2022-01-11,Paul Murrell,"https://github.com/pmur002/gggrid,https://stattech.wordpress.fos.auckland.ac.nz/2021/05/31/2021-01-accessing-grid-from-ggplot2/",TRUE,https://github.com/pmur002/gggrid,2842,31,2022-03-18T00:14:27Z,91.6774193548387
ggh4x,"A 'ggplot2' extension that does a variety of little
    helpful things.  The package extends 'ggplot2' facets through
    customisation, by setting individual scales per panel, resizing panels
    and providing nested facets.  Also allows multiple colour and fill
    scales per plot. Also hosts a smaller collection of stats, geoms and axis 
    guides.",2021-11-24,Teun van den Brand,https://github.com/teunbrand/ggh4x,TRUE,https://github.com/teunbrand/ggh4x,28512,328,2022-05-15T17:02:11Z,86.92682926829268
gghalves,"A 'ggplot2' extension for easy plotting of half-half geom combinations. Think half boxplot and half jitterplot, or half violinplot and half dotplot.",2022-05-30,Frederik Tiedemann,https://github.com/erocoar/gghalves,TRUE,https://github.com/erocoar/gghalves,42610,209,2022-05-27T17:26:53Z,203.8755980861244
gghdr,"Provides 'ggplot2' framework for visualising Highest Density Regions (HDR) 
    <doi:10.1080/00031305.1996.10474359>. This work is based on
    the package 'hdrcde'<https://pkg.robjhyndman.com/hdrcde/> and 
    displays highest density regions in 'ggplot2' for one and two dimensions and
    univariate densities conditional on one covariate.",2022-02-03,Sayani Gupta,https://github.com/Sayani07/gghdr,TRUE,https://github.com/sayani07/gghdr,1598,41,2022-02-17T01:40:26Z,38.97560975609756
gghighlight,Make it easier to explore data with highlights.,2022-06-06,Hiroaki Yutani,https://github.com/yutannihilation/gghighlight/,TRUE,https://github.com/yutannihilation/gghighlight,131136,468,2022-06-08T12:36:31Z,280.20512820512823
ggHoriPlot,"A user-friendly, highly customizable R package for building
    horizon plots in the 'ggplot2' environment.",2021-09-13,Iker Rivas-González,"https://rivasiker.github.io/ggHoriPlot/,
https://github.com/rivasiker/ggHoriPlot",TRUE,https://github.com/rivasiker/gghoriplot,4060,109,2022-05-04T09:45:35Z,37.24770642201835
ggimage,"Supports image files and graphic objects to be visualized in
    'ggplot2' graphic system.",2022-04-25,Guangchuang Yu,"https://github.com/GuangchuangYu/ggimage (devel),
https://yulab-smu.top/pkgdocs/ggimage.html (vignette)",TRUE,https://github.com/guangchuangyu/ggimage,154792,145,2022-04-25T01:59:59Z,1067.5310344827585
gginference,"Visualise the results of F test to compare two variances, Student's t-test, test of equal or given proportions, Pearson's chi-squared test for count data and test for association/correlation between paired samples.",2020-10-31,Kleanthis Koupidis,https://github.com/okgreece/gginference,TRUE,https://github.com/okgreece/gginference,19926,11,2021-09-02T13:39:03Z,1811.4545454545455
gginnards,"Extensions to 'ggplot2' providing low-level debug tools: statistics
    and geometries echoing their data argument. Layer manipulation: deletion,
    insertion, extraction and reordering of layers. Deletion of unused variables
    from the data object embedded in ""ggplot"" objects.",2021-07-30,Pedro J. Aphalo,"https://www.r4photobiology.info,
https://github.com/aphalo/gginnards",TRUE,https://github.com/aphalo/gginnards,44193,9,2022-04-10T22:18:58Z,4910.333333333333
GGIR,"A tool to process and analyse data collected with wearable raw acceleration sensors as described in Migueles and colleagues (JMPB 2019), and van Hees and colleagues (JApplPhysiol 2014; PLoSONE 2015). The package has been developed and tested for binary data from 'GENEActiv' <https://www.activinsights.com/> and GENEA devices (not for sale), .csv-export data from  'Actigraph' <https://actigraphcorp.com> devices, and .cwa and .wav-format data from 'Axivity' <https://axivity.com>. These devices are currently widely used in research on human daily physical activity. Further, the package can handle accelerometer data file from any other sensor brand providing that the data is stored in csv format and has either no header or a two column header. Also the package allows for external function embedding.",2022-05-30,Vincent T van Hees,"https://github.com/wadpac/GGIR/,
https://groups.google.com/forum/#!forum/RpackageGGIR",TRUE,https://github.com/wadpac/ggir,47236,55,2022-07-01T12:23:57Z,858.8363636363637
ggiraph,Create interactive 'ggplot2' graphics using 'htmlwidgets'.,2022-02-22,David Gohel,https://davidgohel.github.io/ggiraph/,TRUE,https://github.com/davidgohel/ggiraph,317806,606,2022-02-22T12:20:26Z,524.4323432343234
ggisotonic,Provides stat_isotonic() to add weighted univariate isotonic regression curves.,2022-05-24,Komala Sheshachala Srikanth,https://github.com/talegari/ggisotonic,TRUE,https://github.com/talegari/ggisotonic,363,1,2022-05-23T16:26:38Z,363
ggmatplot,"A quick and easy way of plotting the columns of two matrices or 
    data frames against each other using 'ggplot2'. Although 'ggmatplot' doesn't 
    provide the same flexibility as 'ggplot2', it can be used as a workaround for 
    having to wrangle wide format data into long format for plotting with
    'ggplot2'.",2022-05-17,Xuan Liang,"https://github.com/xuan-liang/ggmatplot,
https://xuan-liang.github.io/ggmatplot/",TRUE,https://github.com/xuan-liang/ggmatplot,2615,4,2022-06-20T23:58:18Z,653.75
ggmcmc,"Tools for assessing and diagnosing convergence of
    Markov Chain Monte Carlo simulations, as well as for graphically display
    results from full MCMC analysis. The package also facilitates the graphical
    interpretation of models by providing flexible functions to plot the
    results against observed variables, and functions to work with
    hierarchical/multilevel batches of parameters
    (Fernández-i-Marín, 2016 <doi:10.18637/jss.v070.i09>).",2021-02-10,Xavier Fernández i Marín,"http://xavier-fim.net/packages/ggmcmc/,
https://github.com/xfim/ggmcmc/",TRUE,https://github.com/xfim/ggmcmc,69131,101,2022-04-13T09:45:05Z,684.4653465346535
ggmice,"Enhance a 'mice' imputation workflow with visualizations for
    incomplete and/or imputed data. The plotting functions produce
    'ggplot' objects which may be easily manipulated or extended. Use
    'ggmice' to inspect missing data, develop imputation models, evaluate
    algorithmic convergence, or compare observed versus imputed data.",2022-03-17,Hanne Oberman,"https://github.com/amices/ggmice, https://amices.org/,
https://amices.org/ggmice/",TRUE,https://github.com/amices/ggmice,1397,19,2022-06-22T13:03:47Z,73.52631578947368
GGMncv,"Estimate Gaussian graphical models with nonconvex penalties <doi:10.31234/osf.io/ad57p>, 
  including the atan Wang and Zhu (2016) <doi:10.1155/2016/6495417>, 
  seamless L0 Dicker, Huang, and Lin (2013) <doi:10.5705/ss.2011.074>,
  exponential Wang, Fan, and Zhu <doi:10.1007/s10463-016-0588-3>, 
  smooth integration of counting and absolute deviation Lv and Fan (2009) <doi:10.1214/09-AOS683>,
  logarithm Mazumder, Friedman, and Hastie (2011) <doi:10.1198/jasa.2011.tm09738>,
  Lq, smoothly clipped absolute deviation Fan and Li (2001) <doi:10.1198/016214501753382273>,
  and minimax concave penalty Zhang (2010) <doi:10.1214/09-AOS729>. There are also extensions
  for computing variable inclusion probabilities, multiple regression coefficients, and 
  statistical inference <doi:10.1214/15-EJS1031>.",2021-12-15,Donald Williams,NA,TRUE,https://github.com/donaldrwilliams/ggmncv,8089,4,2021-12-14T14:07:45Z,2022.25
ggOceanMaps,"Allows plotting data on bathymetric maps using 'ggplot2'. Plotting
  oceanographic spatial data is made as simple as feasible, but also flexible
  for custom modifications. Data that contain geographic information from 
  anywhere around the globe can be plotted on maps generated by the basemap()
  or qmap() functions using 'ggplot2' layers separated by the '+' operator. The 
  package uses spatial shapefiles stored in the 'ggOceanMapsData' package, 
  geospatial packages for R to manipulate, and the 'ggspatial' package to help 
  to plot these shapefiles. High-resolution shapefiles for detailed maps are 
  stored on GitHub and downloaded automatically when needed. ",2022-01-08,Mikko Vihtakari  (Institute of Marine Research,https://mikkovihtakari.github.io/ggOceanMaps/,TRUE,https://github.com/mikkovihtakari/ggoceanmaps,7524,24,2022-07-01T13:45:22Z,313.5
ggokabeito,"Discrete scales for the colorblind-friendly 'Okabe-Ito'
    palette, including 'color', 'fill', and 'edge_colour'. 'ggokabeito'
    provides 'ggplot2' and 'ggraph' scales to easily use the 'Okabe-Ito'
    palette in your data visualizations.",2021-10-18,Malcolm Barrett,"https://github.com/malcolmbarrett/ggokabeito,
https://malcolmbarrett.github.io/ggokabeito/",TRUE,https://github.com/malcolmbarrett/ggokabeito,3455,27,2022-02-08T17:50:20Z,127.96296296296296
ggpacman,"A funny coding challenge to reproduce the game Pac-Man using 'ggplot2' and 'gganimate'.
    It provides a pre-defined moves set for Pac-Man and the ghosts for the first level of the
    game Pac-Man as well as polygon datasets to draw ghosts in 'ggplot2'.",2020-05-16,Mickaël Canouil,https://github.com/mcanouil/pacman,TRUE,https://github.com/mcanouil/pacman,7911,56,2021-09-16T09:22:19Z,141.26785714285714
ggparliament,Simple parliament plots using 'ggplot2'. Visualize election results as points in the architectural layout of the legislative chamber.,2018-09-30,Robert Hickman,https://github.com/robwhickman/ggparliament,TRUE,https://github.com/robwhickman/ggparliament,15161,138,2022-02-25T06:05:58Z,109.8623188405797
ggpattern,Provides 'ggplot2' geoms filled with various patterns.  Includes a patterned version of every 'ggplot2' geom that has a region that can be filled with a pattern.  Provides a suite of 'ggplot2' aesthetics and scales for controlling pattern appearances.  Supports over a dozen builtin patterns (every pattern implemented by 'gridpattern') as well as allowing custom user-defined patterns.,2022-02-23,Trevor L Davis,"https://github.com/coolbutuseless/ggpattern,
https://coolbutuseless.github.io/package/ggpattern/index.html",TRUE,https://github.com/coolbutuseless/ggpattern,21314,295,2022-03-18T21:09:27Z,72.25084745762712
ggpie,"Create pie, donut and rose pie plot with 'ggplot2'. ",2022-06-27,Yabing Song,https://github.com/showteeth/ggpie,TRUE,https://github.com/showteeth/ggpie,572,12,2022-06-26T11:10:12Z,47.666666666666664
ggplot2,"A system for 'declaratively' creating graphics,
    based on ""The Grammar of Graphics"". You provide the data, tell 'ggplot2'
    how to map variables to aesthetics, what graphical primitives to use,
    and it takes care of the details.",2022-05-03,Thomas Lin Pedersen,"https://ggplot2.tidyverse.org,
https://github.com/tidyverse/ggplot2",TRUE,https://github.com/tidyverse/ggplot2,59246287,5489,2022-07-09T02:35:13Z,10793.639460739661
ggplotify,"Convert plot function call (using expression or formula) to 'grob' or 'ggplot' object that compatible to the 'grid' and 'ggplot2' ecosystem. With this package, we are able to e.g. using 'cowplot' to align plots produced by 'base' graphics, 'ComplexHeatmap', 'eulerr', 'grid', 'lattice', 'magick', 'pheatmap', 'vcd' etc. by converting them to 'ggplot' objects.",2021-09-02,Guangchuang Yu,https://github.com/GuangchuangYu/ggplotify,TRUE,https://github.com/guangchuangyu/ggplotify,457122,85,2021-09-02T15:47:05Z,5377.905882352941
ggpmisc,"Extensions to 'ggplot2' respecting the grammar of graphics
    paradigm. Statistics: locate and tag peaks and valleys; label plot with the
    equation of a fitted polynomial or other types of models; labels
    with P-value, R^2 or adjusted R^2 or information criteria for fitted models;
    label with ANOVA table for fitted models; label with summary for fitted
    models. Model fit classes for which suitable methods are provided by package
    'broom' and 'broom.mixed' are supported. Scales and stats to build volcano
    and quadrant plots based on outcomes, fold changes, p-values and false 
    discovery rates.",2022-06-15,Pedro J. Aphalo,"https://docs.r4photobiology.info/ggpmisc/,
https://github.com/aphalo/ggpmisc",TRUE,https://github.com/aphalo/ggpmisc,277568,36,2022-06-14T22:43:34Z,7710.222222222223
ggPMX,"At Novartis, we aimed at standardizing the set of diagnostic plots used for modeling 
  activities in order to reduce the overall effort required for generating such plots. 
  For this, we developed a guidance that proposes an adequate set of diagnostics and a toolbox, 
  called 'ggPMX' to execute them. 'ggPMX' is a toolbox that can generate all diagnostic plots at a quality sufficient 
  for publication and submissions using few lines of code. This package focuses on plots recommended by ISoP
  <doi:10.1002/psp4.12161>. While not required, you can get/install the 'R' 'lixoftConnectors'
    package in the 'Monolix' installation, as described at the following url
    <https://monolix.lixoft.com/monolix-api/lixoftconnectors_installation/>.
    When 'lixoftConnectors' is available, 'R' can use 'Monolix' directly to create the required
    Chart Data instead of exporting it from the 'Monolix' gui.",2022-06-17,Matthew Fidler,https://github.com/ggPMXdevelopment/ggPMX,TRUE,https://github.com/ggpmxdevelopment/ggpmx,20966,31,2022-06-17T17:09:37Z,676.3225806451613
ggpointless,"A collection of new geometries and stats for
    'ggplot2'. geom_pointless() adds minimal emphasis to your 
    plots making it easy to highlight some observations. This
    layer provides additional context. Or just some visual sugar. 
    geom_lexis() draws a 45° lifeline of an event that mimics 
    lexis diagrams. ",2022-06-08,Markus Döring,"https://flrd.github.io/ggpointless/,
https://github.com/flrd/ggpointless",TRUE,https://github.com/flrd/ggpointless,1198,1,2022-06-08T11:36:21Z,1198
ggpol,A 'ggplot2' extension for implementing parliament charts and several other useful visualizations. ,2020-11-08,Frederik Tiedemann,https://github.com/erocoar/ggpol,TRUE,https://github.com/erocoar/ggpol,71155,82,2022-05-26T18:34:48Z,867.7439024390244
ggpolar,"Provides basic graphing functions to fully demonstrate
    point-to-point connections in a polar coordinate space.",2022-06-15,Shixiang Wang,https://github.com/ShixiangWang/polar,TRUE,https://github.com/shixiangwang/polar,2384,7,2022-06-15T09:05:20Z,340.57142857142856
ggpp,"Extensions to 'ggplot2' respecting the grammar of graphics 
    paradigm. Geometries: geom_table(), geom_plot() and geom_grob() add insets to 
    plots using native data coordinates, while geom_table_npc(), geom_plot_npc()
    and geom_grob_npc() do the same using ""npc"" coordinates through new 
    aesthetics ""npcx"" and ""npcy"". Statistics: select observations based on 2D 
    density. Positions: radial nudging away from a center point and nudging away
    from a line or curve; combined stacking and nudging; combined dodging and
    nudging.",2022-04-10,Pedro J. Aphalo,"https://docs.r4photobiology.info/ggpp/,
https://github.com/aphalo/ggpp",TRUE,https://github.com/aphalo/ggpp,108983,45,2022-05-09T14:14:58Z,2421.8444444444444
ggprism,"Provides various themes, palettes, and other functions
    that are used to customise ggplots to look like they were made in 'GraphPad 
    Prism'. The 'Prism'-look is achieved with theme_prism() and 
    scale_fill|colour_prism(), axes can be changed with custom guides like 
    guide_prism_minor(), and significance indicators added with add_pvalue().",2021-06-08,Charlotte Dawson,"https://csdaw.github.io/ggprism/, https://github.com/csdaw/ggprism",TRUE,https://github.com/csdaw/ggprism,20654,101,2022-06-27T09:13:53Z,204.4950495049505
ggquickeda,"Quickly and easily perform exploratory data analysis by uploading your
     data as a 'csv' file. Start generating insights using 'ggplot2' plots and
     'table1' tables with descriptive stats, all using an easy-to-use point and click 
     'Shiny' interface.",2022-05-16,Samer Mouksassi,https://github.com/smouksassi/ggquickeda,TRUE,https://github.com/smouksassi/ggquickeda,22377,50,2022-06-18T19:58:48Z,447.54
ggquiver,"An extension of 'ggplot2' to provide quiver plots to visualise vector fields. 
    This functionality is implemented using a geom to produce a new graphical layer, which
    allows aesthetic options. This layer can be overlaid on a map to improve visualisation
    of mapped data.",2021-12-06,Mitchell OHara-Wild,"https://github.com/mitchelloharawild/ggquiver,
https://pkg.mitchelloharawild.com/ggquiver/",TRUE,https://github.com/mitchelloharawild/ggquiver,18796,39,2021-12-06T07:59:37Z,481.94871794871796
ggRandomForests,"Graphic elements for exploring Random Forests using the 'randomForest' or
    'randomForestSRC' package for survival, regression and classification forests and
    'ggplot2' package plotting.",2022-05-09,John Ehrlinger,https://github.com/ehrlinger/ggRandomForests,TRUE,https://github.com/ehrlinger/ggrandomforests,33276,132,2022-05-09T15:44:29Z,252.0909090909091
ggrastr,Rasterize only specific layers of a 'ggplot2' plot while simultaneously keeping all labels and text in vector format. This allows users to keep plots within the reasonable size limit without loosing vector properties of the scale-sensitive information. ,2021-12-08,Evan Biederstedt,https://github.com/VPetukhov/ggrastr,TRUE,https://github.com/vpetukhov/ggrastr,111612,181,2021-12-08T07:03:31Z,616.6408839779006
ggrepel,"Provides text and label geoms for 'ggplot2' that help to avoid
    overlapping text labels. Labels repel away from each other and away from the
    data points.",2021-01-15,Kamil Slowikowski,https://github.com/slowkow/ggrepel,TRUE,https://github.com/slowkow/ggrepel,10151509,1013,2022-06-20T17:59:45Z,10021.232971372161
ggridges,Ridgeline plots provide a convenient way of visualizing changes in distributions over time or space. This package enables the creation of such plots in 'ggplot2'.,2021-01-08,Claus O. Wilke,https://wilkelab.org/ggridges/,TRUE,https://github.com/wilkelab/ggridges,1734582,368,2022-02-09T21:42:05Z,4713.538043478261
ggroups,"Calculates additive and dominance genetic relationship matrices and their inverses, in matrix and tabular-sparse formats. It includes functions for checking and processing pedigree, calculating inbreeding coefficients (Meuwissen & Luo, 1992 <doi:10.1186/1297-9686-24-4-305>), as well as functions to calculate the matrix of genetic group contributions (Q), and adding those contributions to the genetic merit of animals (Quaas (1988) <doi:10.3168/jds.S0022-0302(88)79691-5>). Calculation of Q is computationally extensive. There are computationally optimized functions to calculate Q.",2022-03-27,Mohammad Ali Nilforooshan,https://github.com/nilforooshan/ggroups,TRUE,https://github.com/nilforooshan/ggroups,17098,0,2022-03-31T23:20:45Z,NA
ggsci,"A collection of 'ggplot2' color palettes inspired by
    plots in scientific journals, data visualization libraries,
    science fiction movies, and TV shows.",2018-05-14,Nan Xiao,"https://nanx.me/ggsci/, https://github.com/road2stat/ggsci",TRUE,https://github.com/road2stat/ggsci,4914197,492,2021-12-22T23:38:42Z,9988.205284552845
ggseg,"Contains 'ggplot2' geom for plotting brain atlases using 
    simple features. The largest component of the package is the data 
    for the two built-in atlases. Mowinckel & Vidal-Piñeiro (2020)
    <doi:10.1177/2515245920928009>.",2022-06-13,Athanasia Mo Mowinckel,https://github.com/ggseg/ggseg,TRUE,https://github.com/ggseg/ggseg,7171,133,2022-06-14T09:13:21Z,53.91729323308271
ggseqplot,"A set of wrapper functions that mainly re-produces some of the 
  sequence plots rendered with TraMineR::seqplot() and 'TraMineRextras'. 
  Whereas 'TraMineR' uses base R to produce the plots this library draws on 
  'ggplot2'. The plots are produced on the basis of a sequence object defined  
  with TraMineR::seqdef(). The package automates the reshaping and plotting 
  of sequence data. Resulting plots are of class 'ggplot', i.e. components 
  can be added and tweaked using '+' and regular 'ggplot2' functions. ",2022-07-04,Marcel Raab,https://github.com/maraab23/ggseqplot,TRUE,https://github.com/maraab23/ggseqplot,67,2,2022-07-07T11:42:42Z,33.5
ggsignif,"Enrich your 'ggplots' with group-wise comparisons.
    This package provides an easy way to indicate if two groups are
    significantly different. Commonly this is shown by a bracket on top
    connecting the groups of interest which itself is annotated with the
    level of significance (NS, *, **, ***).  The package provides a single
    layer (geom_signif()) that takes the groups for comparison and the
    test (t.test(), wilcox.text() etc.) as arguments and adds the
    annotation to the plot.",2021-09-09,Constantin Ahlmann-Eltze,"https://const-ae.github.io/ggsignif/,
https://github.com/const-ae/ggsignif",TRUE,https://github.com/const-ae/ggsignif,5203382,443,2022-05-19T19:38:18Z,11745.78329571106
ggsoccer,"The 'ggplot2' package provides a powerful set of tools 
  for visualising and investigating data. The 'ggsoccer' package provides a 
  set of functions for elegantly displaying and exploring soccer event data
  with 'ggplot2'. Providing extensible layers and themes, it is designed to
  work smoothly with a variety of popular sports data providers.",2020-06-21,Ben Torvaney,"https://torvaney.github.io/ggsoccer/,
https://github.com/Torvaney/ggsoccer",TRUE,https://github.com/torvaney/ggsoccer,24320,137,2021-12-13T13:16:19Z,177.5182481751825
ggspatial,"Spatial data plus the power of the ggplot2 framework means easier mapping when input 
  data are already in the form of spatial objects.",2022-07-08,Dewey Dunnington,"https://paleolimbot.github.io/ggspatial/,
https://github.com/paleolimbot/ggspatial",TRUE,https://github.com/paleolimbot/ggspatial,208830,312,2022-07-08T17:25:50Z,669.3269230769231
ggspectra,"Additional annotations, stats, geoms and scales for plotting 
    ""light"" spectra with 'ggplot2', together with specializations of ggplot()
    and autoplot() methods for spectral data and waveband definitions
    stored in objects of classes defined in package 'photobiology'. Part of the 
    'r4photobiology' suite, Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.",2022-04-16,Pedro J. Aphalo,"https://docs.r4photobiology.info/ggspectra/,
https://github.com/aphalo/ggspectra/",TRUE,https://github.com/aphalo/ggspectra,27704,1,2022-04-15T22:46:18Z,27704
ggstar,"To create the multiple polygonal point layer for easily discernible shapes, 
             we developed the package, it is like the 'geom_point' of 'ggplot2'.
             It can be used to draw the scatter plot.",2021-12-03,Shuangbin Xu,https://github.com/xiangpin/ggstar/,TRUE,https://github.com/xiangpin/ggstar,22647,66,2022-06-06T07:09:28Z,343.1363636363636
ggstatsplot,"Extension of 'ggplot2', 'ggstatsplot' creates graphics with
    details from statistical tests included in the plots themselves. It
    provides an easier syntax to generate information-rich plots for
    statistical analysis of continuous (violin plots, scatterplots,
    histograms, dot plots, dot-and-whisker plots) or categorical (pie and
    bar charts) data. Currently, it supports the most common types of
    statistical approaches and tests: parametric, nonparametric, robust,
    and Bayesian versions of t-test/ANOVA, correlation analyses,
    contingency table analysis, meta-analysis, and regression analyses.",2022-05-27,Indrajeet Patil,"https://indrajeetpatil.github.io/ggstatsplot/,
https://github.com/IndrajeetPatil/ggstatsplot",TRUE,https://github.com/indrajeetpatil/ggstatsplot,197431,1538,2022-05-27T10:09:37Z,128.36866059817945
ggswissmaps,"Offers various swiss maps as data frames and 'ggplot2' objects and gives the
    possibility to add layers of data on the maps. Data are publicly available
    from the swiss federal statistical office.",2016-10-29,Sandro Petrillo Burri,https://github.com/gibonet/ggswissmaps,TRUE,https://github.com/gibonet/ggswissmaps,17103,5,2021-09-13T06:21:04Z,3420.6
ggtikz,"Annotation of 'ggplot2' plots with arbitrary 'TikZ' code, using absolute data or relative plot coordinates.",2021-11-04,Oliver Thomas,https://github.com/osthomas/ggtikz,TRUE,https://github.com/osthomas/ggtikz,3819,1,2021-11-05T10:06:29Z,3819
ggtrace,"Provides 'ggplot2' geoms that allow groups of data points to be
    outlined or highlighted for emphasis. This is particularly useful when
    working with dense datasets that are prone to overplotting.",2022-06-24,Ryan Sheridan,https://github.com/rnabioco/ggtrace,TRUE,https://github.com/rnabioco/ggtrace,196,8,2022-06-25T03:32:06Z,24.5
ggtrendline,"Add trendline and confidence interval of linear or nonlinear regression model and
    show equation to 'ggplot' as simple as possible. For a general overview of the methods used in
	  this package, see Ritz and Streibig (2008) <doi:10.1007/978-0-387-09616-2> and 
	  Greenwell and Schubert Kabban (2014) <doi:10.32614/RJ-2014-009>.",2022-04-27,Weiping Mei,https://github.com/PhDMeiwp/ggtrendline,TRUE,https://github.com/phdmeiwp/ggtrendline,806,10,2022-05-04T11:55:29Z,80.6
GGUM,"An implementation of the generalized graded unfolding model (GGUM) in R, see Roberts, Donoghue, and Laughlin (2000) <doi:10.1177/01466216000241001>). It allows to simulate data sets based on the GGUM. It fits the GGUM and the GUM, and it retrieves item and person parameter estimates. Several plotting functions are available (item and test information functions; item and test characteristic curves; item category response curves). Additionally, there are some functions that facilitate the communication between R and 'GGUM2004'. Finally, a model-fit checking utility, MODFIT(), is also available.",2021-10-07,Jorge N. Tendeiro,https://github.com/jorgetendeiro/GGUM/,TRUE,https://github.com/jorgetendeiro/ggum,16755,4,2021-10-14T07:18:50Z,4188.75
ggupset,"Replace the standard x-axis in 'ggplots' with a combination matrix
  to visualize complex set overlaps. 'UpSet' has introduced a new way to visualize
  the overlap of sets as an alternative to Venn diagrams. 
  This package provides a simple way to produce such plots using 'ggplot2'. 
  In addition it can convert any categorical axis into a combination
  matrix axis.",2020-05-05,Constantin Ahlmann-Eltze,https://github.com/const-ae/ggupset,TRUE,https://github.com/const-ae/ggupset,43272,280,2022-01-14T09:31:50Z,154.54285714285714
ggVennDiagram,"Easy-to-use functions to generate 2-7 sets Venn plot in publication quality. 
  'ggVennDiagram' plot Venn using well-defined geometry dataset and 'ggplot2'. The shapes of 2-4 sets 
  Venn use circles and ellipses, while the shapes of 4-7 sets Venn use irregular polygons (4 has both forms), which 
  are developed and imported from another package 'venn', authored by Adrian Dusa. We provided internal functions to 
  integrate shape data with user provided sets data, and calculated the geometry of every regions/intersections 
  of them, then separately plot Venn in three components: set edges, set labels, and regions.
  From version 1.0, it is possible to customize these components as you demand in ordinary 'ggplot2' grammar.",2021-10-22,Chun-Hui Gao,https://github.com/gaospecial/ggVennDiagram,TRUE,https://github.com/gaospecial/ggvenndiagram,61672,180,2021-11-01T06:14:30Z,342.6222222222222
ggwordcloud,"Provides a word cloud text geom for 'ggplot2'. Texts
    are placed so that they do not overlap as in 'ggrepel'.  The algorithm
    used is a variation around the one of 'wordcloud2.js'.",2019-06-02,Erwan Le Pennec,"https://github.com/lepennec/ggwordcloud,
https://lepennec.github.io/ggwordcloud/",TRUE,https://github.com/lepennec/ggwordcloud,72490,158,2022-05-25T09:55:00Z,458.7974683544304
Ghat,"Functions are provided for quantifying evolution and selection on complex traits. 
              The package implements effective handling and analysis algorithms scaled for 
              genome-wide data and calculates a composite statistic, denoted Ghat, which is used 
              to test for selection on a trait. The package provides a number of simple examples 
              for handling and analysing the genome data and visualising the output and results. 
              Beissinger et al., (2018) <doi:10.1534/genetics.118.300857>.",2019-08-02,Medhat Mahmoud,https://www.genetics.org/content/209/1/321,TRUE,https://github.com/medhat86/ghat,11590,0,2022-06-03T21:59:17Z,NA
ghclass,"Interface for the GitHub API that enables efficient 
    management of courses on GitHub. It has a functionality for 
    managing organizations, teams, repositories, and users on GitHub 
    and helps automate most of the tedious and repetitive tasks 
    around creating and distributing assignments.",2022-01-06,Colin Rundel,https://github.com/rundel/ghclass,TRUE,https://github.com/rundel/ghclass,1845,132,2022-01-07T03:31:36Z,13.977272727272727
ghcm,"A statistical hypothesis test for conditional independence.
    Given residuals from a sufficiently powerful regression, it tests whether 
    the covariance of the residuals is vanishing. It can be applied to both
    discretely-observed functional data and multivariate data. 
    Details of the method can be found in Anton Rask Lundborg, Rajen D. Shah and Jonas
    Peters (2021) <arXiv:2101.07108>.",2022-02-20,Anton Rask Lundborg,https://github.com/arlundborg/ghcm,TRUE,https://github.com/arlundborg/ghcm,5353,0,2022-02-16T13:17:01Z,NA
ghee,"Provides a user friendly wrapper for the 'gh' package facilitating easy
  access to the REST API for 'GitHub'. Includes support for common tasks such as 
  creating and commenting on issues, inviting collaborators, and more.",2021-03-11,Jonathan Trattner,https://github.com/jdtrat/ghee,TRUE,https://github.com/jdtrat/ghee,4806,6,2021-08-11T18:13:02Z,801
ghibli,"Colour palettes inspired by Studio Ghibli <https://en.wikipedia.org/wiki/Studio_Ghibli> 
    films, ported to R for your enjoyment.",2020-04-16,Ewen Henderson,"https://ewenme.github.io/ghibli/, https://github.com/ewenme/ghibli",TRUE,https://github.com/ewenme/ghibli,24237,319,2021-09-03T10:35:39Z,75.97805642633229
ghql,"A 'GraphQL' client, with an R6 interface for initializing
    a connection to a 'GraphQL' instance, and methods for constructing
    queries, including fragments and parameterized queries. Queries
    are checked with the 'libgraphqlparser' C++ parser via the
    'gaphql' package.",2020-03-04,Scott Chamberlain,"https://github.com/ropensci/ghql (devel)
https://docs.ropensci.org/ghql (docs)",TRUE,https://github.com/ropensci/ghql,28270,129,2022-03-31T15:06:21Z,219.14728682170542
gifski,"Multi-threaded GIF encoder written in Rust: <https://gif.ski/>. 
    Converts images to GIF animations using pngquant's efficient cross-frame 
    palettes and temporal dithering with thousands of colors per frame.",2022-04-05,Jeroen Ooms,"https://gif.ski/ (upstream), https://github.com/r-rust/gifski
(devel)",TRUE,https://github.com/r-rust/gifski,667883,60,2022-04-05T12:01:28Z,11131.383333333333
gifti,"Functions to read in the geometry format under the 
    'Neuroimaging' 'Informatics' Technology Initiative ('NIfTI'), called 
    'GIFTI' <https://www.nitrc.org/projects/gifti/>. 
    These files contain surfaces of brain imaging data.",2020-11-11,John Muschelli,NA,TRUE,https://github.com/muschellij2/gifti,23359,3,2022-04-20T13:34:47Z,7786.333333333333
gigg,"A Gibbs sampler corresponding to a Group 
    Inverse-Gamma Gamma (GIGG) regression model with adjustment covariates. 
    Hyperparameters in the GIGG prior specification can either be fixed by the 
    user or can be estimated via Marginal Maximum Likelihood Estimation.
    Jonathan Boss, Jyotishka Datta, Xin Wang, Sung Kyun Park, Jian Kang, Bhramar 
    Mukherjee (2021) <arXiv:2102.10670>.",2021-03-09,Michael Kleinsasser,https://github.com/umich-cphds/gigg,TRUE,https://github.com/umich-cphds/gigg,4802,0,2022-02-09T16:20:35Z,NA
GillespieSSA,"Provides a simple to use, intuitive, and
  extensible interface to several stochastic simulation
  algorithms for generating simulated trajectories of finite
  population continuous-time model. Currently it implements
  Gillespie's exact stochastic simulation algorithm (Direct
  method) and several approximate methods (Explicit tau-leap,
  Binomial tau-leap, and Optimized tau-leap). The package also
  contains a library of template models that can be run as demo
  models and can easily be customized and extended. Currently the
  following models are included, 'Decaying-Dimerization' reaction
  set, linear chain system, logistic growth model, 'Lotka'
  predator-prey model, Rosenzweig-MacArthur predator-prey model,
  'Kermack-McKendrick' SIR model, and a 'metapopulation' SIRS model.
  Pineda-Krch et al. (2008) <doi:10.18637/jss.v025.i12>.",2022-03-10,Robrecht Cannoodt,https://github.com/rcannood/GillespieSSA,TRUE,https://github.com/rcannood/gillespiessa,20588,1,2022-03-10T08:37:50Z,20588
gim,"Implements the generalized integration model, which integrates individual-level data and summary statistics under a generalized linear model framework. It supports continuous and binary outcomes to be modeled by the linear and logistic regression models. For binary outcome, data can be sampled in prospective cohort studies or case-control studies. Described in Zhang et al. (2020)<doi:10.1093/biomet/asaa014>. ",2020-06-12,Han Zhang,https://github.com/zhangh12/gim,TRUE,https://github.com/zhangh12/gim,15338,0,2021-08-26T05:39:20Z,NA
gimme,Data-driven approach for arriving at person-specific time series models. The method first identifies which relations replicate across the majority of individuals to detect signal from noise. These group-level relations are then used as a foundation for starting the search for person-specific (or individual-level) relations. See Gates & Molenaar (2012) <doi:10.1016/j.neuroimage.2012.06.026>. ,2021-10-18,Kathleen Gates,https://github.com/GatesLab/gimme/,TRUE,https://github.com/gateslab/gimme,29241,18,2022-04-06T19:12:11Z,1624.5
gimms,"This is a set of functions to retrieve information about GIMMS
    NDVI3g files currently available online; download (and re-arrange, in the 
    case of NDVI3g.v0) the half-monthly data sets; import downloaded files from 
    ENVI binary (NDVI3g.v0) or NetCDF format (NDVI3g.v1) directly into R based 
    on the widespread 'raster' package; conduct quality control; and generate 
    monthly composites (e.g., maximum values) from the half-monthly input data. 
    As a special gimmick, a method is included to conveniently apply the 
    Mann-Kendall trend test upon 'Raster*' images, optionally featuring 
    trend-free pre-whitening to account for lag-1 autocorrelation.",2021-07-30,Florian Detsch,https://github.com/environmentalinformatics-marburg/gimms,TRUE,https://github.com/environmentalinformatics-marburg/gimms,21459,15,2021-07-30T09:35:27Z,1430.6
giscoR,"Tools to download data from the GISCO (Geographic Information
    System of the Commission) Eurostat database
    <https://ec.europa.eu/eurostat/web/gisco>. Global and European map
    data available.  This package is in no way officially related to or
    endorsed by Eurostat.",2021-10-06,Diego Hernangómez,"https://ropengov.github.io/giscoR/,
https://github.com/rOpenGov/giscoR",TRUE,https://github.com/ropengov/giscor,19074,38,2022-05-18T18:49:12Z,501.94736842105266
git2r,"Interface to the 'libgit2' library, which is a pure C
    implementation of the 'Git' core methods. Provides access to 'Git'
    repositories to extract data and running some basic 'Git'
    commands.",2022-03-16,See AUTHORS file.,"https://docs.ropensci.org/git2r/ (website),
https://github.com/ropensci/git2r",TRUE,https://github.com/ropensci/git2r,3763225,184,2022-03-18T20:02:40Z,20452.309782608696
git2rdata,"The git2rdata package is an R package for writing and reading
    dataframes as plain text files.  A metadata file stores important
    information.  1) Storing metadata allows to maintain the classes of
    variables.  By default, git2rdata optimizes the data for file storage.
    The optimization is most effective on data containing factors.  The
    optimization makes the data less human readable.  The user can turn
    this off when they prefer a human readable format over smaller files.
    Details on the implementation are available in vignette(""plain_text"",
    package = ""git2rdata"").  2) Storing metadata also allows smaller row
    based diffs between two consecutive commits.  This is a useful feature
    when storing data as plain text files under version control.  Details
    on this part of the implementation are available in
    vignette(""version_control"", package = ""git2rdata"").  Although we
    envisioned git2rdata with a git workflow in mind, you can use it in
    combination with other version control systems like subversion or
    mercurial.  3) git2rdata is a useful tool in a reproducible and
    traceable workflow.  vignette(""workflow"", package = ""git2rdata"") gives
    a toy example.  4) vignette(""efficiency"", package = ""git2rdata"")
    provides some insight into the efficiency of file storage, git
    repository size and speed for writing and reading.",2022-03-17,Thierry Onkelinx,"https://ropensci.github.io/git2rdata/,
https://github.com/ropensci/git2rdata/",TRUE,https://github.com/ropensci/git2rdata,16342,94,2022-03-17T13:30:33Z,173.85106382978722
git4r,"An interactive git user interface from the R command line. Intuitive
         tools to make commits, branches, remotes, and diffs an integrated part
         of R coding. Built on git2r, a system installation of git is not required
         and has default on-premises remote option.",2022-03-11,John Hobbs,https://github.com/johnxhobbs/git4r,TRUE,https://github.com/johnxhobbs/git4r,1308,0,2022-03-01T13:24:00Z,NA
gitcreds,"Query, set, delete credentials from the 'git' credential
    store. Manage 'GitHub' tokens and other 'git' credentials. This package
    is to be used by other packages that need to authenticate to 'GitHub'
    and/or other 'git' repositories.",2020-12-04,Gábor Csárdi,https://github.com/r-lib/gitcreds,TRUE,https://github.com/r-lib/gitcreds,3520993,13,2022-03-11T11:41:50Z,270845.6153846154
gitdown,"Read all commit messages of your local git repository and
    sort them according to tags or specific text pattern into chapters of
    a HTML book using 'bookdown'. The git history book presentation helps
    organisms required to testify for every changes in their source code,
    in relation to features requests.",2022-03-05,Sébastien Rochette,"https://thinkr-open.github.io/gitdown/,
https://github.com/Thinkr-open/gitdown",TRUE,https://github.com/thinkr-open/gitdown,6216,31,2022-03-05T22:20:47Z,200.51612903225808
gitgadget,"An 'Rstudio' addin for version control that allows users to clone
    repositories, create and delete branches, and sync forks on GitHub, GitLab, etc.
    Furthermore, the addin uses the GitLab API to allow instructors to create
    forks and merge requests for all students/teams with one click of a button.",2022-06-13,Vincent Nijs,URL: https://github.com/vnijs/gitgadget,TRUE,https://github.com/vnijs/gitgadget,22563,17,2022-07-04T00:09:33Z,1327.235294117647
gitignore,"Simple interface to query gitignore.io to fetch
    gitignore templates that can be included in the .gitignore file. More
    than 450 templates are currently available.",2021-10-31,Philippe Massicotte,"https://docs.ropensci.org/gitignore/,
https://github.com/ropensci/gitignore",TRUE,https://github.com/ropensci/gitignore,17056,32,2021-10-31T21:16:05Z,533
gitlabr,"Provides R functions to access the API of the project and
    repository management web application 'GitLab'. For many common tasks
    (repository file access, issue assignment and status, commenting)
    convenience wrappers are provided, and in addition the full API can be
    used by specifying request locations. 'GitLab' is open-source software
    and can be self-hosted or used on <https://about.gitlab.com>.",2021-08-05,Sébastien Rochette,https://statnmap.github.io/gitlabr/,TRUE,https://github.com/statnmap/gitlabr,26904,27,2022-06-09T08:19:25Z,996.4444444444445
gittargets,"In computationally demanding data analysis pipelines,
  the 'targets' R package (2021, <doi:10.21105/joss.02959>) maintains
  an up-to-date set of results while skipping tasks that do not need to rerun.
  This process increases speed and increases trust in the final end product.
  However, it also overwrites old output with new output, and past
  results disappear by default. To preserve historical output, the 'gittargets'
  package captures version-controlled snapshots of the data store,
  and each snapshot links to the underlying commit of the source code.
  That way, when the user rolls back the code to a previous branch or commit,
  'gittargets' can recover the data contemporaneous with that commit so that
  all targets remain up to date.",2022-02-13,William Michael Landau,"https://docs.ropensci.org/gittargets/,
https://github.com/ropensci/gittargets",TRUE,https://github.com/ropensci/gittargets,1990,52,2022-02-13T00:32:02Z,38.26923076923077
glca,"Fits multiple-group latent class analysis (LCA) for exploring 
    differences between populations in the data with a multilevel structure. 
    There are two approaches to reflect group differences in glca: 
    fixed-effect LCA (Bandeen-Roche et al (1997) <doi:10.1080/01621459.1997.10473658>;
    Clogg and Goodman (1985) <doi:10.2307/270847>) and nonparametric random-effect LCA 
    (Vermunt (2003) <doi:10.1111/j.0081-1750.2003.t01-1-00131.x>).",2021-11-02,Youngsun Kim,https://kim0sun.github.io/glca/,TRUE,https://github.com/kim0sun/glca,11691,6,2022-07-06T06:15:23Z,1948.5
gld,"The generalised lambda distribution, or Tukey lambda distribution, 
  provides a wide variety of shapes with one functional form.   
  This package provides random numbers, quantiles, probabilities, 
  densities and density quantiles for four different types of the distribution,
  the FKML (Freimer et al 1988), RS (Ramberg and Schmeiser 1974), GPD (van Staden
  and Loots 2009) and FM5 - see documentation for details.
  It provides the density function, distribution function, and Quantile-Quantile 
  plots.  
  It implements a variety of estimation methods for the distribution, 
  including diagnostic plots. 
  Estimation methods include the starship (all 4 types), 
  method of L-Moments for the GPD and FKML types, and a 
  number of methods for only the FKML type.  
  These include maximum likelihood, maximum product of spacings, 
  Titterington's method, Moments, Trimmed L-Moments and 
  Distributional Least Absolutes. ",2022-06-29,Robert King,https://github.com/newystats/gld/,TRUE,https://github.com/newystats/gld,1040775,0,2022-06-29T08:27:23Z,NA
glinvci,"A framework for analytically computing the asymptotic confidence intervals and maximum-likelihood estimates of a class of continuous-time Gaussian branching processes defined by Mitov V, Bartoszek K, Asimomitis G, Stadler T (2019) <doi:10.1016/j.tpb.2019.11.005>. The class of model includes the widely used Ornstein-Uhlenbeck and Brownian motion branching processes. The framework is designed to be flexible enough so that the users can easily specify their own sub-models, or re-parameterizations, and obtain the maximum-likelihood estimates and confidence intervals of their own custom models.",2022-03-16,Hao Chi Kiang,"https://git.sr.ht/~hckiang/glinvci,
https://github.com/hckiang/glinvci",TRUE,https://github.com/hckiang/glinvci,2757,0,2022-03-14T22:59:59Z,NA
gllvm,"Analysis of multivariate data using generalized linear latent variable models (gllvm). 
      Estimation is performed using either Laplace approximation method or variational approximation method implemented via TMB (Kristensen et al., (2016), <doi:10.18637/jss.v070.i05>). 
      For details see Niku et al. (2019a) <doi:10.1371/journal.pone.0216129> and 
      Niku et al. (2019b) <doi:10.1111/2041-210X.13303>.",2021-07-28,Jenni Niku,https://github.com/JenniNiku/gllvm,TRUE,https://github.com/jenniniku/gllvm,23797,28,2022-06-13T09:03:22Z,849.8928571428571
glmm.hp,"Conducts hierarchical partitioning to calculate individual contributions of each fixed effects towards marginal R2 for generalized mixed-effect model based on output of r.squaredGLMM() in 'MuMIn', applying the algorithm of Lai J.,Zou Y., Zhang J.,Peres-Neto P.(2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution,13:782-788<DOI:10.1111/2041-210X.13800>.",2022-05-01,Jiangshan Lai,https://github.com/laijiangshan/glmm.hp,TRUE,https://github.com/laijiangshan/glmm.hp,2824,0,2022-04-30T13:12:50Z,NA
GLMMadaptive,"Fits generalized linear mixed models for a single grouping factor under
    maximum likelihood approximating the integrals over the random effects with an 
    adaptive Gaussian quadrature rule; Jose C. Pinheiro and Douglas M. Bates (1995) 
    <doi:10.1080/10618600.1995.10474663>.  ",2022-02-07,Dimitris Rizopoulos,"https://drizopoulos.github.io/GLMMadaptive/,
https://github.com/drizopoulos/GLMMadaptive",TRUE,https://github.com/drizopoulos/glmmadaptive,125546,48,2022-02-08T10:10:06Z,2615.5416666666665
glmmfields,"Implements Bayesian spatial and spatiotemporal
    models that optionally allow for extreme spatial deviations through
    time. 'glmmfields' uses a predictive process approach with random
    fields implemented through a multivariate-t distribution instead of
    the usual multivariate normal.  Sampling is conducted with 'Stan'.
    References: Anderson and Ward (2019) <doi:10.1002/ecy.2403>.",2020-07-09,Sean C. Anderson,https://github.com/seananderson/glmmfields,TRUE,https://github.com/seananderson/glmmfields,16618,38,2021-10-15T22:08:10Z,437.3157894736842
glmmTMB,"Fit linear and generalized linear mixed models with various
    extensions, including zero-inflation. The models are fitted using maximum
    likelihood estimation via 'TMB' (Template Model Builder). Random effects are
    assumed to be Gaussian on the scale of the linear predictor and are integrated
    out using the Laplace approximation. Gradients are calculated using automatic
    differentiation.",2022-03-13,Mollie Brooks,https://github.com/glmmTMB/glmmTMB,TRUE,https://github.com/glmmtmb/glmmtmb,402329,191,2022-06-30T13:34:42Z,2106.434554973822
glmnetSE,"Builds a LASSO, Ridge, or Elastic Net model with 'glmnet' or
    'cv.glmnet' with bootstrap inference statistics (SE, CI, and p-value)
    for selected coefficients with no shrinkage applied for them. Model
    performance can be evaluated on test data and an automated alpha
    selection is implemented for Elastic Net. Parallelized computation is
    used to speed up the process. The methods are described in Friedman et
    al. (2010) <doi:10.18637/jss.v033.i01> and Simon et al. (2011)
    <doi:10.18637/jss.v039.i05>.",2021-11-05,Sebastian Bahr,https://github.com/sebastianbahr/glmnetSE,TRUE,https://github.com/sebastianbahr/glmnetse,2036,2,2021-11-05T09:02:53Z,1018
globals,"Identifies global (""unknown"" or ""free"") objects in R expressions
    by code inspection using various strategies (ordered, liberal, or
    conservative).  The objective of this package is to make it as simple as
    possible to identify global objects for the purpose of exporting them in
    parallel, distributed compute environments.",2022-06-24,Henrik Bengtsson,"https://globals.futureverse.org,
https://github.com/HenrikBengtsson/globals",TRUE,https://github.com/henrikbengtsson/globals,7423690,25,2022-06-29T22:11:49Z,296947.6
globaltrends,"Google offers public access to global search volumes from its
    search engine through the Google Trends portal. The package downloads
	these search volumes provided by Google Trends and uses them to measure
	and analyze the distribution of search scores across countries or
    within countries. The package allows researchers and analysts to use these
    search scores to investigate global trends based on patterns within these
    scores. This offers insights such as degree of internationalization of
    firms and organizations or dissemination of political, social, or
    technological trends across the globe or within single countries.
	An outline of the package's methodological foundations and potential
	applications is available as a working paper:
	<https://www.ssrn.com/abstract=3969013>.",2022-06-23,Harald Puhr,https://github.com/ha-pu/globaltrends/,TRUE,https://github.com/ha-pu/globaltrends,158,12,2022-07-07T09:46:04Z,13.166666666666666
glossr,"Read examples with interlinear glosses from files
    or from text and print them in a way compatible with both
    Latex and HTML outputs.",2022-06-08,Mariana Montes,"https://montesmariana.github.io/glossr/,
https://github.com/montesmariana/glossr",TRUE,https://github.com/montesmariana/glossr,272,3,2022-06-08T12:17:47Z,90.66666666666667
glottospace,"Streamlined workflows for geolinguistic analysis, including:
    accessing global linguistic and cultural databases, data import, data
    entry, data cleaning, data exploration, mapping, visualization and
    export.",2022-04-12,Sietze Norder,https://github.com/SietzeN/glottospace,TRUE,https://github.com/sietzen/glottospace,1130,10,2022-07-01T13:03:05Z,113
glue,"An implementation of interpreted string literals, inspired by
    Python's Literal String Interpolation
    <https://www.python.org/dev/peps/pep-0498/> and Docstrings
    <https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted
    String Literals
    <https://docs.julialang.org/en/v1.3/manual/strings/#Triple-Quoted-String-Literals-1>.",2022-02-24,Jim Hester,"https://github.com/tidyverse/glue, https://glue.tidyverse.org/",TRUE,https://github.com/tidyverse/glue,38661361,610,2022-02-24T16:05:45Z,63379.28032786885
gm,"Provides a simple and intuitive high-level language, with which
    you can create music easily. Takes care of all the dirty technical
    details in converting your music to musical scores and audio files.
    Works in 'R Markdown' documents <https://rmarkdown.rstudio.com/>,
    R 'Jupyter Notebooks' <https://jupyter.org/>, and 'RStudio'
    <https://www.rstudio.com/>, so you can embed generated music
    anywhere. Internally, uses 'MusicXML' <https://www.musicxml.com/> to
    represent musical scores, and 'MuseScore' <https://musescore.org/> to
    convert 'MusicXML'.",2021-04-17,Renfei Mao,"https://github.com/flujoo/gm, https://flujoo.github.io/gm/",TRUE,https://github.com/flujoo/gm,6759,115,2022-06-03T14:52:41Z,58.77391304347826
gmailr,"An interface to the 'Gmail' 'RESTful' API.  Allows access to
    your 'Gmail' messages, threads, drafts and labels.",2021-11-30,Jennifer Bryan,"https://gmailr.r-lib.org, https://github.com/r-lib/gmailr",TRUE,https://github.com/r-lib/gmailr,5750982,221,2021-12-03T16:32:54Z,26022.54298642534
gmapsdistance,"Get distance and travel time between two points from Google Maps.
    Four possible modes of transportation (bicycling, walking, driving and
    public transportation).",2022-04-26,Rodrigo Azuero Melo & David Zarruk,https://github.com/jlacko/gmapsdistance,TRUE,https://github.com/jlacko/gmapsdistance,27040,0,2022-04-26T11:48:46Z,NA
gmat,"Simulation of correlation matrices possibly constrained by a given undirected or acyclic directed graph. In particular, the package provides functions that implement the simulation methods described in Córdoba et al. (2018) <doi:10.1007/978-3-030-03493-1_13> and Córdoba et al. (2020) <doi:10.1016/j.ijar.2020.07.007>.",2020-08-30,Irene Córdoba,https://github.com/gherardovarando/gmat,TRUE,https://github.com/gherardovarando/gmat,14156,0,2022-05-03T14:22:15Z,NA
GMCM,"Unsupervised Clustering and Meta-analysis using Gaussian Mixture
    Copula Models.",2019-11-05,Anders Ellern Bilgrau,https://github.com/AEBilgrau/GMCM,TRUE,https://github.com/aebilgrau/gmcm,25860,9,2021-11-04T22:28:46Z,2873.3333333333335
Gmisc,"Tools for making the descriptive ""Table 1"" used in medical
    articles, a transition plot for showing changes between categories
    (also known as a Sankey diagram), flow charts by extending the grid package,
    a method for variable selection based on the SVD, Bézier lines with arrows
    complementing the ones in the 'grid' package, and more.",2022-01-03,Max Gordon,https://gforge.se,TRUE,https://github.com/gforge/gmisc,77160,45,2022-01-03T18:23:19Z,1714.6666666666667
gMOIP,"Make 2D and 3D plots of linear programming (LP), 
    integer linear programming (ILP), or mixed integer linear programming (MILP) models 
    with up to three objectives. Plots of both the solution and criterion space are possible.
    For instance the non-dominated (Pareto) set for bi-objective LP/ILP/MILP programming models 
    (see vignettes for an overview). The package also contains an function for checking if a point
    is inside the convex hull.",2021-08-23,Lars Relund Nielsen,"https://relund.github.io/gMOIP/, https://github.com/relund/gMOIP/",TRUE,https://github.com/relund/gmoip,20449,3,2021-08-23T11:16:27Z,6816.333333333333
gmpoly,Symbolic calculation (addition or multiplication) and evaluation of multivariate polynomials with rational coefficients.,2022-03-20,Stéphane Laurent,https://github.com/stla/gmpoly,TRUE,https://github.com/stla/gmpoly,1599,0,2022-03-20T03:34:15Z,NA
gms,"A collection of tools to create, use and maintain modularized model code written in the modeling 
    language 'GAMS' (<https://www.gams.com/>). Out-of-the-box 'GAMS' does not come with support for modularized
    model code. This package provides the tools necessary to convert a standard 'GAMS' model to a modularized one
    by introducing a modularized code structure together with a naming convention which emulates local
    environments. In addition, this package provides tools to monitor the compliance of the model code with
    modular coding guidelines.",2020-07-01,Jan Philipp Dietrich,https://github.com/pik-piam/gms,TRUE,https://github.com/pik-piam/gms,7309,0,2022-07-07T14:00:58Z,NA
GMSE,"Integrates game theory and ecological theory to construct 
    social-ecological models that simulate the management of populations and 
    stakeholder actions. These models build off of a previously developed 
    management strategy evaluation (MSE) framework to simulate all aspects of 
    management: population dynamics, manager observation of populations, manager
    decision making, and stakeholder responses to management decisions. The 
    newly developed generalised management strategy evaluation (GMSE) 
    framework uses genetic algorithms to mimic the decision-making process of 
    managers and stakeholders under conditions of change, uncertainty, and 
    conflict. Simulations can be run using gmse(), gmse_apply(), and
    gmse_gui() functions.",2022-06-16,A. Bradley Duthie,https://confoobio.github.io/gmse/,TRUE,https://github.com/confoobio/gmse,16442,9,2022-06-15T13:46:21Z,1826.888888888889
gmvarkit,"Unconstrained and constrained maximum likelihood estimation of structural and reduced form 
    Gaussian mixture vector autoregressive, Student's t mixture vector autoregressive, and Gaussian and Student's t
    mixture vector autoregressive models, quantile residual tests, graphical diagnostics,
    simulations, forecasting, and estimation of generalized impulse response function and generalized 
    forecast error variance decomposition.
    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2016) <doi:10.1016/j.jeconom.2016.02.012>,
    Savi Virolainen (2022) <arXiv:2007.04713>,
    Savi Virolainen (2022) <arXiv:2109.13648>.",2022-06-03,Savi Virolainen,NA,TRUE,https://github.com/saviviro/gmvarkit,23597,2,2022-06-03T12:25:48Z,11798.5
gnm,"Functions to specify and fit generalized nonlinear models, including models with multiplicative interaction terms such as the UNIDIFF model from sociology and the AMMI model from crop science, and many others.  Over-parameterized representations of models are used throughout; functions are provided for inference on estimable parameter combinations, as well as standard methods for diagnostics etc.",2022-04-29,Heather Turner,https://github.com/hturner/gnm,TRUE,https://github.com/hturner/gnm,211507,8,2022-04-29T09:14:16Z,26438.375
GOCompare,Supports the assessment of functional enrichment analyses obtained for several lists of genes and provides a workflow to analyze them between two species via weighted graphs. Methods are described in Sosa et al. (2022) (to be submitted).,2022-04-29,Chrystian Camilo Sosa,https://github.com/ccsosa/GOCompare,TRUE,https://github.com/ccsosa/gocompare,1822,2,2022-03-09T22:42:53Z,911
gofar,"Divide and conquer approach for estimating low-rank and sparse coefficient matrix in the generalized co-sparse factor regression. Please refer the manuscript 'Mishra, Aditya, Dipak K. Dey, Yong Chen, and Kun Chen. Generalized co-sparse factor regression. Computational Statistics & Data Analysis 157 (2021): 107127' for more details. ",2022-03-02,Aditya Mishra,"https://github.com/amishra-stats/gofar,
https://www.sciencedirect.com/science/article/pii/S0167947320302188",TRUE,https://github.com/amishra-stats/gofar,1037,1,2022-02-27T13:59:07Z,1037
goffda,"Implementation of several goodness-of-fit tests for functional
    data. Currently, mostly related with the functional linear model with
    functional/scalar response and functional/scalar predictor. The package
    allows for the replication of the data applications considered in
    García-Portugués, Álvarez-Liébana, Álvarez-Pérez and González-Manteiga
    (2021) <doi:10.1111/sjos.12486>.",2021-08-19,Eduardo García-Portugués,https://github.com/egarpor/goffda,TRUE,https://github.com/egarpor/goffda,14749,8,2021-10-18T11:14:41Z,1843.625
golem,"An opinionated framework for building a production-ready
    'Shiny' application. This package contains a series of tools for
    building a robust 'Shiny' application from start to finish.",2022-03-04,Colin Fay,https://github.com/ThinkR-open/golem,TRUE,https://github.com/thinkr-open/golem,185334,737,2022-02-24T19:36:28Z,251.4708276797829
googleAnalyticsR,"Interact with the Google Analytics 
  APIs <https://developers.google.com/analytics/>, including 
  the Core Reporting API (v3 and v4), Management API, User Activity API
  GA4's Data API and Admin API and Multi-Channel Funnel API.",2021-10-07,Mark Edmondson,https://code.markedmondson.me/googleAnalyticsR/,TRUE,https://github.com/markedmondson1234/googleanalyticsr,268684,236,2022-06-29T09:09:22Z,1138.4915254237287
googleAuthR,"Create R functions that interact with OAuth2 Google APIs 
    <https://developers.google.com/apis-explorer/> easily,
    with auto-refresh and Shiny compatibility.",2022-01-28,Mark Edmondson,https://code.markedmondson.me/googleAuthR/,TRUE,https://github.com/markedmondson1234/googleauthr,450092,158,2022-02-02T07:06:17Z,2848.6835443037976
googleCloudRunner,"Tools to easily enable R scripts in the Google Cloud Platform.
  Utilise cloud services such as Cloud Run <https://cloud.google.com/run/> for R 
  over HTTP, Cloud Build <https://cloud.google.com/build> for Continuous 
  Delivery and Integration services and 
  Cloud Scheduler <https://cloud.google.com/scheduler/> for scheduled scripts.",2022-02-28,Mark Edmondson,https://code.markedmondson.me/googleCloudRunner/,TRUE,https://github.com/markedmondson1234/googlecloudrunner,16292,71,2022-03-26T19:59:26Z,229.46478873239437
googleCloudStorageR,"Interact with Google Cloud Storage <https://cloud.google.com/storage/> 
  API in R. Part of the 'cloudyr' <https://cloudyr.github.io/> project.",2021-12-16,Mark Edmondson,https://code.markedmondson.me/googleCloudStorageR/,TRUE,https://github.com/cloudyr/googlecloudstorager,147369,94,2022-07-07T07:54:48Z,1567.7553191489362
googleComputeEngineR,"Interact with the 'Google Compute Engine' API in R. Lets you create, 
  start and stop instances in the 'Google Cloud'.  Support for preconfigured instances, 
  with templates for common R needs. ",2019-05-04,Mark Edmondson,https://cloudyr.github.io/googleComputeEngineR/,TRUE,https://github.com/cloudyr/googlecomputeenginer,54078,147,2022-01-19T16:01:01Z,367.8775510204082
googledrive,Manage Google Drive files from R.,2021-07-08,Jennifer Bryan,"https://googledrive.tidyverse.org,
https://github.com/tidyverse/googledrive",TRUE,https://github.com/tidyverse/googledrive,7599984,267,2022-06-15T19:43:41Z,28464.3595505618
GoogleImage2Array,"Images are provided as an array dataset of 2D image thumbnails from Google Image Search <https://www.google.com/search>.
  This array data may be suitable for a training data of machine learning or deep learning as a first trial.",2021-09-29,Satoshi Kume,https://github.com/kumeS/GoogleImage2Array,TRUE,https://github.com/kumes/googleimage2array,2147,2,2021-12-03T13:18:13Z,1073.5
googlePubsubR,"Provides an easy to use interface to the 'Google
	Pub/Sub' REST API <https://cloud.google.com/pubsub/docs/reference/rest>.",2022-01-16,Andrea Dodet,https://github.com/andodet/googlePubsubR,TRUE,https://github.com/andodet/googlepubsubr,3149,7,2022-01-16T20:14:07Z,449.85714285714283
googlesheets4,"Interact with Google Sheets through the Sheets API v4
    <https://developers.google.com/sheets/api>. ""API"" is an acronym for
    ""application programming interface""; the Sheets API allows users to
    interact with Google Sheets programmatically, instead of via a web
    browser. The ""v4"" refers to the fact that the Sheets API is currently
    at version 4. This package can read and write both the metadata and
    the cell data in a Sheet.",2021-07-21,Jennifer Bryan,"https://googlesheets4.tidyverse.org,
https://github.com/tidyverse/googlesheets4",TRUE,https://github.com/tidyverse/googlesheets4,7511539,303,2022-04-04T15:56:08Z,24790.55775577558
googleVis,"R interface to Google's chart tools, allowing users
    to create interactive charts based on data frames. Charts
    are displayed locally via the R HTTP help server. A modern
    browser with an Internet connection is required. The data 
    remains local and is not uploaded to Google.",2022-05-10,Markus Gesmann,https://mages.github.io/googleVis/,TRUE,https://github.com/mages/googlevis,434026,349,2022-05-13T10:57:59Z,1243.6275071633238
googleway,"Provides a mechanism to plot a 'Google Map' from 'R' and overlay
    it with shapes and markers. Also provides access to 'Google Maps' APIs,
    including places, directions, roads, distances, geocoding, elevation and
    timezone.",2022-01-24,David Cooley,NA,TRUE,https://github.com/symbolixau/googleway,145921,212,2022-06-07T23:57:26Z,688.3066037735849
gosset,"Toolkit for a workflow to analyse experimental agriculture data, 
    from data synthesis to model selection and visualisation. 
    The package is named after W.S. Gosset aka ‘Student’, a pioneer 
    of modern statistics in small sample experimental design and analysis.",2022-06-28,Kauê de Sousa,https://agrdatasci.github.io/gosset/,TRUE,https://github.com/agrdatasci/gosset,1206,2,2022-07-08T16:21:26Z,603
gotop,"Add a scroll back to top 'Font Awesome' icon 
    <https://fontawesome.com/> in 'rmarkdown' documents and 'shiny'
    apps thanks to 'jQuery GoTop' <https://scottdorman.blog/jquery-gotop/>.",2020-10-31,Félix Luginbuhl,"https://felixluginbuhl.com/gotop, https://github.com/lgnbhl/gotop",TRUE,https://github.com/lgnbhl/gotop,12353,12,2021-09-20T21:41:05Z,1029.4166666666667
gower,"Compute Gower's distance (or similarity) coefficient between records. Compute 
    the top-n matches between records. Core algorithms are executed in parallel on systems
    supporting OpenMP.",2022-02-03,Mark van der Loo,https://github.com/markvanderloo/gower,TRUE,https://github.com/markvanderloo/gower,3711073,27,2022-02-03T13:55:06Z,137447.14814814815
goxygen,"A collection of tools which extract a model documentation from 'GAMS' code and comments. 
             In order to use the package you need to install 'pandoc' and 'pandoc-citeproc' 
             first (<https://pandoc.org/>).",2020-08-16,Jan Philipp Dietrich,"https://github.com/pik-piam/goxygen,
https://doi.org/10.5281/zenodo.1411404",TRUE,https://github.com/pik-piam/goxygen,8258,3,2022-06-08T08:24:02Z,2752.6666666666665
GPareto,"Gaussian process regression models, a.k.a. Kriging models, are
    applied to global multi-objective optimization of black-box functions.
    Multi-objective Expected Improvement and Step-wise Uncertainty Reduction
    sequential infill criteria are available. A quantification of uncertainty
    on Pareto fronts is provided using conditional simulations.",2022-06-24,Mickael Binois,https://github.com/mbinois/GPareto,TRUE,https://github.com/mbinois/gpareto,61429,12,2022-06-24T13:46:30Z,5119.083333333333
GPBayes,"Gaussian processes (GPs) have been widely used to model spatial data, spatio-temporal data, and computer experiments in diverse areas of statistics including spatial statistics, spatio-temporal statistics, uncertainty quantification, and machine learning. This package creates basic tools for fitting and prediction based on GPs with spatial data, spatio-temporal data, and computer experiments. Key characteristics for this GP tool include: (1) the comprehensive implementation of various covariance functions including the Matérn family and the Confluent Hypergeometric family with isotropic form, tensor form, and automatic relevance determination form, where the isotropic form is widely used in spatial statistics, the tensor form is widely used in design and analysis of computer experiments and uncertainty quantification, and the automatic relevance determination form is widely used in machine learning; (2) implementations via Markov chain Monte Carlo (MCMC) algorithms and optimization algorithms for GP models with all the implemented covariance functions. The methods for fitting and prediction are mainly implemented in a Bayesian framework; (3) model evaluation via Fisher information and predictive metrics such as predictive scores; (4) built-in functionality for simulating GPs with all the implemented covariance functions; (5) unified implementation to allow easy specification of various GPs. ",2021-12-03,Pulong Ma,NA,TRUE,https://github.com/pulongma/gpbayes,3735,0,2021-10-15T19:45:46Z,NA
gpboost,An R package that allows for combining tree-boosting with Gaussian process and mixed effects models. It also allows for independently doing tree-boosting as well as inference and prediction for Gaussian process and mixed effects models. See <https://github.com/fabsig/GPBoost> for more information on the software and Sigrist (2020) <arXiv:2004.02653> and Sigrist (2021) <arXiv:2105.08966> for more information on the methodology.,2022-07-08,Fabio Sigrist,https://github.com/fabsig/GPBoost,TRUE,https://github.com/fabsig/gpboost,20595,332,2022-07-08T13:01:28Z,62.03313253012048
gpbStat,"Performs statistical data analysis of various Plant Breeding experiments. Contains functions for Line by Tester analysis as per Arunachalam, V.(1974) <http://repository.ias.ac.in/89299/> and Diallel analysis as per Griffing, B. (1956) <https://www.publish.csiro.au/bi/pdf/BI9560463>.  ",2021-10-30,Nandan Patil,https://github.com/nandp1/gpbStat/,TRUE,https://github.com/nandp1/gpbstat,14229,0,2021-08-14T08:01:42Z,NA
GPCERF,"Provides a non-parametric Bayesian framework based on Gaussian process priors for estimating causal effects of a continuous exposure and detecting change points in the causal exposure response curves using observational data. Ren, B., Wu, X., Braun, D., Pillai, N., & Dominici, F.(2021). ""Bayesian modeling for exposure response curve via gaussian processes: Causal effects of exposure to air pollution on health outcomes."" arXiv preprint <arXiv:2105.03454>.",2022-07-02,Naeem Khoshnevis  (<https://orcid.org/0000-0003-4315-1426>,https://github.com/NSAPH-Software/GPCERF,TRUE,https://github.com/nsaph-software/gpcerf,102,3,2022-07-05T15:04:15Z,34
gpclib,General polygon clipping routines for R based on Alan Murta's C library.,2020-02-28,Roger D. Peng <rpeng@jhsph.edu> with contributions from Duncan Murdoch and Barry Rowlingson; GPC library by Alan Murta,"http://www.cs.man.ac.uk/~toby/gpc/,
http://github.com/rdpeng/gpclib",TRUE,https://github.com/rdpeng/gpclib,86659,11,2022-03-01T21:40:31Z,7878.090909090909
gpg,"Bindings to GnuPG for working with OpenGPG (RFC4880) cryptographic 
    methods. Includes utilities for public key encryption, creating and verifying
    digital signatures, and managing your local keyring. Some functionality 
    depends on the version of GnuPG that is installed on the system. On Windows
    this package can be used together with 'GPG4Win' which provides a GUI for 
    managing keys and entering passphrases.",2022-05-29,Jeroen Ooms,https://github.com/jeroen/gpg,TRUE,https://github.com/jeroen/gpg,23663,18,2022-05-29T07:53:22Z,1314.611111111111
GPGame,"Sequential strategies for finding a game equilibrium are proposed in a black-box setting (expensive pay-off evaluations, no derivatives). The algorithm handles noiseless or noisy evaluations. Two acquisition functions are available. Graphical outputs can be generated automatically. V. Picheny, M. Binois, A. Habbal (2018) <doi:10.1007/s10898-018-0688-0>. M. Binois, V. Picheny, P. Taillandier, A. Habbal (2020) <arXiv:1902.06565v2>.",2022-01-23,Victor Picheny,https://github.com/vpicheny/GPGame,TRUE,https://github.com/vpicheny/gpgame,11615,0,2022-01-25T13:59:16Z,NA
gpindex,"A small package for calculating lots of different price indexes, and by extension quantity indexes. Provides tools to build and work with any type of bilateral generalized-mean index (of which most price indexes are), along with a few important indexes that don't belong to the generalized-mean family (e.g., superlative quadratic-mean indexes, GEKS). Implements and extends many of the methods in Balk (2008, ISBN:978-1-107-40496-0), von der Lippe (2001, ISBN:3-8246-0638-0), and the CPI manual (2020, ISBN:978-1-51354-298-0) for bilateral price indexes.",2022-05-01,Steve Martin,https://github.com/marberts/gpindex,TRUE,https://github.com/marberts/gpindex,14190,2,2022-04-21T18:49:51Z,7095
gplots,"Various R programming tools for plotting data, including:
  - calculating and plotting locally smoothed summary function as
    ('bandplot', 'wapply'),
  - enhanced versions of standard plots ('barplot2', 'boxplot2',
    'heatmap.2', 'smartlegend'),
  - manipulating colors ('col2hex', 'colorpanel', 'redgreen',
    'greenred', 'bluered', 'redblue', 'rich.colors'),
  - calculating and plotting two-dimensional data summaries ('ci2d',
    'hist2d'),
  - enhanced regression diagnostic plots ('lmplot2', 'residplot'),
  - formula-enabled interface to 'stats::lowess' function ('lowess'),
  - displaying textual data in plots ('textplot', 'sinkplot'),
  - plotting a matrix where each cell contains a dot whose size
    reflects the relative magnitude of the elements ('balloonplot'),
  - plotting ""Venn"" diagrams ('venn'),
  - displaying Open-Office style plots ('ooplot'),
  - plotting multiple data on same region, with separate axes
    ('overplot'),
  - plotting means and confidence intervals ('plotCI', 'plotmeans'),
  - spacing points in an x-y plot so they don't overlap ('space').",2022-04-25,Gregory R. Warnes,https://github.com/talgalili/gplots,TRUE,https://github.com/talgalili/gplots,4205431,10,2022-04-24T18:44:57Z,420543.1
graDiEnt,"An optim-style implementation of the Stochastic Quasi-Gradient Differential Evolution (SQG-DE) optimization algorithm first published by Sala, Baldanzini, and Pierini (2018; <doi:10.1007/978-3-319-72926-8_27>). This optimization algorithm fuses the robustness of the population-based global optimization algorithm ""Differential Evolution"" with the efficiency of gradient-based optimization. The derivative-free algorithm uses population members to build stochastic gradient estimates, without any additional objective function evaluations. Sala, Baldanzini, and Pierini argue this algorithm is useful for 'difficult optimization problems under a tight function evaluation budget.' This package can run SQG-DE in parallel and sequentially.",2022-05-10,Brendan Matthew Galdo,https://github.com/bmgaldo/graDiEnt,TRUE,https://github.com/bmgaldo/gradient,452,3,2022-05-09T20:08:44Z,150.66666666666666
grafify,"Easily explore data by generating different kinds of graphs with few lines of code. Use these ggplot() wrappers to quickly draw graphs of scatter/dots with box-whiskers, violins or SD error bars, data distributions, before-after graphs, factorial ANOVA and more. Customise graphs in many ways. Choose from colourblind-friendly 12 discreet , 3 continuous (3 palettes) and 3 divergent colour palettes. Simple code for ANOVA as ordinary (lm()) or mixed-effects linear models (lmer()), including randomised-block or repeated-measures designs. Obtain estimated marginal means and perform post-hoc comparisons on fitted models (via emmeans() wrappers). Also includes small datasets for practicing code and teaching basics before users move on to more complex designs. See vignettes for details on usage <https://grafify-vignettes.netlify.app/>. Citation: <doi:10.5281/zenodo.5136508>.",2022-05-30,Avinash R Shenoy,https://github.com/ashenoy-cmbi/grafify,TRUE,https://github.com/ashenoy-cmbi/grafify,3121,26,2022-05-30T07:48:25Z,120.03846153846153
gramEvol,"A native R implementation of grammatical evolution (GE).
    GE facilitates the discovery of programs that can achieve a desired goal.
    This is done by performing an evolutionary optimisation over a population
    of R expressions generated via a user-defined context-free grammar (CFG)
    and cost function.",2020-07-18,Farzad Noorian,https://github.com/fnoorian/gramEvol/,TRUE,https://github.com/fnoorian/gramevol,27861,24,2022-01-23T02:37:30Z,1160.875
grantham,"A minimal set of routines to calculate the 'Grantham' distance
    <doi:10.1126/science.185.4154.862>. The 'Grantham' distance attempts to
    provide a proxy for the evolutionary distance between two amino acids
    based on three key chemical properties: composition, polarity and
    molecular volume. In turn, evolutionary distance is used as a proxy for
    the impact of missense mutations. The higher the distance, the more
    deleterious the substitution is expected to be.",2022-01-07,Ramiro Magno,"https://maialab.org/grantham/, https://github.com/maialab/grantham",TRUE,https://github.com/maialab/grantham,2252,2,2022-01-20T13:26:04Z,1126
grapherator,"Set of functions for step-wise generation of (weighted) graphs. Aimed for research in the field of single- and multi-objective combinatorial optimization. Graphs are generated adding nodes, edges and weights. Each step may be repeated multiple times with different predefined and custom generators resulting in high flexibility regarding the graph topology and structure of edge weights.",2017-12-21,Jakob Bossek,https://github.com/jakobbossek/grapherator,TRUE,https://github.com/jakobbossek/grapherator,14318,7,2021-09-29T11:21:47Z,2045.4285714285713
graphhopper,"Provides a quick and easy access to the 'GraphHopper' Directions API.
  'GraphHopper' <https://www.graphhopper.com/> itself is a routing engine based on 'OpenStreetMap' data.
  API responses can be converted to simple feature (sf) objects in a convenient way. ",2021-02-06,Stefan Kuethe,https://github.com/crazycapivara/graphhopper-r,TRUE,https://github.com/crazycapivara/graphhopper-r,6772,15,2021-07-17T10:38:55Z,451.46666666666664
graphlayouts,"Several new layout algorithms to visualize networks are provided which are not part of 'igraph'. 
    Most are based on the concept of stress majorization by Gansner et al. (2004) <doi:10.1007/978-3-540-31843-9_25>. 
    Some more specific algorithms allow to emphasize hidden group structures in networks or focus on specific nodes.",2022-01-03,David Schoch,"http://graphlayouts.schochastics.net/,
https://github.com/schochastics/graphlayouts",TRUE,https://github.com/schochastics/graphlayouts,1168210,225,2022-01-16T22:36:24Z,5192.044444444445
graphsim,"Functions to develop simulated continuous data (e.g., gene expression) from a sigma covariance matrix derived from a graph structure in 'igraph' objects. Intended to extend 'mvtnorm' to take 'igraph'  structures rather than sigma matrices as input. This allows the use of simulated data that correctly accounts for pathway relationships and correlations. This allows the use of simulated data that correctly accounts for pathway relationships and correlations. Here we present a versatile statistical framework to simulate  correlated gene expression data from biological pathways, by sampling from a multivariate normal distribution derived from a graph structure. This package allows the simulation of biological pathways from a graph structure based on a statistical model of gene expression. For example methods to infer biological pathways and gene regulatory networks from gene expression data can be tested on simulated datasets using this framework. This also allows for pathway structures to be considered as a confounding variable when simulating gene expression data to test the performance of genomic analyses.",2021-07-30,S. Thomas Kelly,https://github.com/TomKellyGenetics/graphsim/,TRUE,https://github.com/tomkellygenetics/graphsim,15447,16,2022-05-25T04:44:32Z,965.4375
grates,"Provides a coherent interface and implementation for creating
  grouped date classes. This package is part of the RECON
  (<https://www.repidemicsconsortium.org/>) toolkit for outbreak analysis.",2021-10-21,Tim Taylor,"https://www.reconverse.org/grates/,
https://github.com/reconverse/grates",TRUE,https://github.com/reconverse/grates,16620,12,2021-10-21T20:38:31Z,1385
gratia,"Graceful 'ggplot'-based graphics and utility functions for working with generalized additive models (GAMs) fitted using the 'mgcv' package. Provides a reimplementation of the plot() method for GAMs that 'mgcv' provides, as well as 'tidyverse' compatible representations of estimated smooths.",2022-05-09,Gavin L. Simpson,https://gavinsimpson.github.io/gratia/,TRUE,https://github.com/gavinsimpson/gratia,38872,149,2022-07-06T18:50:58Z,260.8859060402685
graticule,"Create graticule lines and labels for maps. Control the creation
    of lines by setting their placement (at particular meridians and parallels)
    and extent (along parallels and meridians). Labels are created independently of
    lines.",2021-05-04,Michael D. Sumner,https://github.com/mdsumner/graticule,TRUE,https://github.com/mdsumner/graticule,18715,19,2021-08-28T11:00:39Z,985
gratis,"
  Generates synthetic time series based on various univariate time series models 
  including MAR and ARIMA processes. Kang, Y., Hyndman, R.J., Li, F.(2020) <doi:10.1002/sam.11461>.",2022-01-14,Yanfei Kang,https://github.com/ykang/gratis,TRUE,https://github.com/ykang/gratis,11149,67,2022-04-21T23:38:34Z,166.40298507462686
grattan,"Utilities to cost and evaluate Australian tax policy, including fast
    projections of personal income tax collections, high-performance tax and 
    transfer calculators, and an interface to common indices from the Australian
    Bureau of Statistics.  Written to support Grattan Institute's Australian 
    Perspectives program, and related projects. Access to the Australian Taxation
    Office's sample files of personal income tax returns is assumed. ",2022-06-27,Hugh Parsonage,"https://github.com/HughParsonage/grattan,
https://hughparsonage.github.io/grattan/",TRUE,https://github.com/hughparsonage/grattan,24766,20,2022-06-27T06:24:41Z,1238.3
gravitas,"Provides tools for systematically exploring large quantities of 
             temporal data across cyclic temporal granularities
             (deconstructions of time) by visualizing probability distributions.
             Cyclic time granularities can be circular, quasi-circular or 
             aperiodic. 'gravitas' computes cyclic
             single-order-up or multiple-order-up granularities, check the
             feasibility of creating plots for any two cyclic granularities
             and recommend probability distributions plots for exploring
             periodicity in the data.",2020-06-25,Sayani Gupta,https://github.com/Sayani07/gravitas/,TRUE,https://github.com/sayani07/gravitas,15368,14,2022-06-14T01:25:28Z,1097.7142857142858
gravity,"A wrapper of different standard estimation methods for gravity models. 
  This package provides estimation methods for log-log models and multiplicative models.",2022-01-05,Mauricio Vargas,https://pacha.dev/gravity/,TRUE,https://github.com/pachadotdev/gravity,27775,24,2022-02-23T07:35:06Z,1157.2916666666667
greatR,"A tool for registering (aligning) gene expression profiles
    between two species (reference data and data to transform).",2022-06-08,Ruth Kristianingsih,"https://ruthkr.github.io/greatR/,
https://github.com/ruthkr/greatR/",TRUE,https://github.com/ruthkr/greatr,1569,0,2022-06-26T22:50:09Z,NA
greed,"An ensemble of algorithms that enable the clustering of networks and data matrices (such as counts, categorical or continuous) with different type of generative models. Model selection and clustering is performed in combination by optimizing the Integrated Classification Likelihood (which is equivalent to minimizing the description length). Several models are available such as: Stochastic Block Model, degree corrected Stochastic Block Model, Mixtures of Multinomial, Latent Block Model. The optimization is performed thanks to a combination of greedy local search and a genetic algorithm (see <arXiv:2002:11577> for more details).",2022-03-18,Etienne Côme,"https://comeetie.github.io/greed/,
https://github.com/comeetie/greed",TRUE,https://github.com/comeetie/greed,5983,9,2022-03-18T10:33:47Z,664.7777777777778
GREENeR,"Tools and methods to apply the model Geospatial Regression Equation
    for European Nutrient losses (GREEN); 
    Grizzetti et al. (2005) <doi:10.1016/j.jhydrol.2004.07.036>; 
    Grizzetti et al. (2008);
    Grizzetti et al. (2012) <doi:10.1111/j.1365-2486.2011.02576.x>; 
    Grizzetti et al. (2021) <doi:10.1016/j.gloenvcha.2021.102281>. ",2022-01-27,C. Alfaro,https://github.com/calfarog/GREENeR,TRUE,https://github.com/calfarog/greener,1337,1,2022-02-18T16:22:47Z,1337
gremlin,"Fit linear mixed-effects models using restricted (or residual)
    maximum likelihood (REML) and with generalized inverse matrices to specify
    covariance structures for random effects. In particular, the package is
    suited to fit quantitative genetic mixed models, often referred to as
    'animal models'. Implements the average information algorithm as the main
    tool to maximize the restricted log-likelihood, but with other algorithms
    available.",2020-06-25,Matthew Wolak,http://github.com/matthewwolak/gremlin,TRUE,https://github.com/matthewwolak/gremlin,12594,3,2022-01-25T23:26:11Z,4198
greta,"Write statistical models in R and fit them by MCMC and
    optimisation on CPUs and GPUs, using Google 'TensorFlow'.  greta lets
    you write your own model like in BUGS, JAGS and Stan, except that you
    write models right in R, it scales well to massive datasets, and it’s
    easy to extend and build on.  See the website for more information,
    including tutorials, examples, package documentation, and the greta
    forum.",2022-03-22,Nick Golding,https://greta-stats.org,TRUE,https://github.com/greta-dev/greta,29684,490,2022-06-29T00:55:51Z,60.57959183673469
gretlR,"It allows running 'gretl' (<http://gretl.sourceforge.net/index.html>) program from R, R Markdown and Quarto. 'gretl' ('Gnu' Regression, 'Econometrics', and Time-series Library) is a statistical software for Econometric analysis.  This package does not only integrate 'gretl' and 'R' but also serves  as a 'gretl' Knit-Engine for 'knitr' package. Write all your 'gretl' commands in 'R', R Markdown chunk.",2022-05-01,Sagiru Mati,https://CRAN.R-project.org/package=gretlR,TRUE,https://github.com/sagirumati/gretlr,7484,4,2022-07-07T07:42:02Z,1871
grex,"Convert 'Ensembl' gene identifiers from Genotype-Tissue
    Expression (GTEx) data to identifiers in other annotation systems,
    including 'Entrez', 'HGNC', and 'UniProt'.",2019-05-17,Nan Xiao,"https://nanx.me/grex/, https://github.com/nanxstats/grex",TRUE,https://github.com/nanxstats/grex,16104,6,2021-12-21T04:09:57Z,2684
greybox,"Implements functions and instruments for regression model building and its
             application to forecasting. The main scope of the package is in variables selection
             and models specification for cases of time series data. This includes promotional
             modelling, selection between different dynamic regressions with non-standard
             distributions of errors, selection based on cross validation, solutions to the fat
             regression model problem and more. Models developed in the package are tailored
             specifically for forecasting purposes. So as a results there are several methods
             that allow producing forecasts from these models and visualising them.",2022-03-25,"Ivan Svetunkov  (Lecturer at Centre for Marketing Analytics
    and Forecasting",https://github.com/config-i1/greybox,TRUE,https://github.com/config-i1/greybox,440508,22,2022-07-04T10:14:10Z,20023.090909090908
grf,"A pluggable package for forest-based statistical estimation and inference.
    GRF currently provides methods for non-parametric least-squares regression,
    quantile regression, survival regression and treatment effect estimation (optionally using instrumental
    variables), with support for missing values.",2022-03-17,Julie Tibshirani,https://github.com/grf-labs/grf,TRUE,https://github.com/grf-labs/grf,108575,729,2022-07-08T17:12:04Z,148.93689986282578
gridGeometry,"Functions for performing polygon geometry with 'grid' grobs.
             This allows complex shapes to be defined by combining simpler
             shapes.  ",2022-03-20,Paul Murrell,"https://github.com/pmur002/gridgeometry,
https://stattech.wordpress.fos.auckland.ac.nz/2019/03/04/2019-01-a-geometry-engine-interface-for-grid/",TRUE,https://github.com/pmur002/gridgeometry,23310,10,2022-05-25T04:17:48Z,2331
gridpattern,"Provides 'grid' grobs that fill in a user-defined area with various patterns.  Includes enhanced versions of the geometric and image-based patterns originally contained in the 'ggpattern' package as well as original 'pch', 'polygon_tiling', 'regular_polygon', 'rose', 'text', 'wave', and 'weave' patterns plus support for custom user-defined patterns.",2022-03-22,Mike FC,"https://trevorldavis.com/R/gridpattern/,
https://github.com/trevorld/gridpattern",TRUE,https://github.com/trevorld/gridpattern,31860,24,2022-06-17T17:38:01Z,1327.5
gridtext,"Provides support for rendering of formatted text using 'grid' graphics. Text can be
    formatted via a minimal subset of 'Markdown', 'HTML', and inline 'CSS' directives, and it can be
    rendered both with and without word wrap.",2020-12-10,Claus O. Wilke,https://wilkelab.org/gridtext/,TRUE,https://github.com/wilkelab/gridtext,1440386,92,2022-04-22T19:11:54Z,15656.369565217392
groundhog,"Make R scripts that rely on packages reproducible, by ensuring that
    every time a given script is run, the same version of the used packages are
    loaded (instead of whichever version the user running the script happens to
    have installed). This is achieved by using the new command
    groundhog.library() instead of the base command library(), and including a
    date in the call. The date is used to call on the same version of the
    package every time (the most recent version available on CRAN at that date).",2021-09-07,Uri Simonsohn,"https://groundhogr.com/,
https://github.com/CredibilityLab/groundhog",TRUE,https://github.com/credibilitylab/groundhog,19187,45,2022-07-10T10:19:49Z,426.3777777777778
groupdata2,"Methods for dividing data into groups. 
    Create balanced partitions and cross-validation folds. 
    Perform time series windowing and general grouping and splitting of data. 
    Balance existing groups with up- and downsampling or collapse them to fewer groups.",2021-10-24,Ludvig Renbo Olsen,https://github.com/ludvigolsen/groupdata2,TRUE,https://github.com/ludvigolsen/groupdata2,73135,22,2021-10-24T16:41:36Z,3324.318181818182
GroupSeq,"Computes probabilities related to group sequential designs for
    normally distributed test statistics. Enables to derive critical
    boundaries, power, drift, and confidence intervals of such designs.
    Supports the alpha spending approach by Lan-DeMets.",2022-02-05,Roman Pahl,https://rpahl.github.io/GroupSeq/,TRUE,https://github.com/rpahl/groupseq,19924,1,2022-02-05T22:52:27Z,19924
groupwalk,A procedure that uses target-decoy competition (or knockoffs) to reject multiple hypotheses in the presence of group structure. The procedure controls the false discovery rate (FDR) at a user-specified threshold.,2022-06-18,Jack Freestone,"https://www.biorxiv.org/content/10.1101/2022.01.30.478144v1,
https://github.com/freejstone/groupwalk",TRUE,https://github.com/freejstone/groupwalk,1318,0,2022-06-17T23:49:25Z,NA
growthrates,"A collection of methods to determine growth rates from
    experimental data, in particular from batch experiments and
    plate reader trials.",2020-11-02,Thomas Petzoldt,https://github.com/tpetzoldt/growthrates,TRUE,https://github.com/tpetzoldt/growthrates,33357,20,2021-11-23T21:07:15Z,1667.85
grpreg,"Efficient algorithms for fitting the regularization path of linear
  regression, GLM, and Cox regression models with grouped penalties.  This
  includes group selection methods such as group lasso, group MCP, and
  group SCAD as well as bi-level selection methods such as the group
  exponential lasso, the composite MCP, and the group bridge.  For more
  information, see Breheny and Huang (2009) <doi:10.4310/sii.2009.v2.n3.a10>,
  Huang, Breheny, and Ma (2012) <doi:10.1214/12-sts392>, Breheny and Huang
  (2015) <doi:10.1007/s11222-013-9424-2>, and Breheny (2015)
  <doi:10.1111/biom.12300>, or visit the package homepage
  <https://pbreheny.github.io/grpreg/>.",2021-07-26,Patrick Breheny,"https://pbreheny.github.io/grpreg/,
https://github.com/pbreheny/grpreg",TRUE,https://github.com/pbreheny/grpreg,514180,28,2022-05-11T13:56:27Z,18363.571428571428
grpsel,"Provides tools for sparse regression modelling with grouped predictors using the group 
    subset selection penalty. Uses coordinate descent and local search algorithms to rapidly deliver 
    near optimal estimates. The group subset penalty can be combined with a group lasso or ridge 
    penalty for added shrinkage. Linear and logistic regression are supported, as are overlapping 
    groups.",2022-06-18,Ryan Thompson,https://github.com/ryan-thompson/grpsel,TRUE,https://github.com/ryan-thompson/grpsel,5213,2,2022-06-18T06:32:01Z,2606.5
grpSLOPE,"Group SLOPE is a penalized linear regression method that is used
    for adaptive selection of groups of significant predictors in a
    high-dimensional linear model.
    The Group SLOPE method can control the (group) false discovery rate at a
    user-specified level (i.e., control the expected proportion of irrelevant
    among all selected groups of predictors).",2022-05-16,Alexej Gossmann,https://github.com/agisga/grpSLOPE,TRUE,https://github.com/agisga/grpslope,18861,3,2022-05-20T01:59:50Z,6287
grwat,"River hydrograph separation and daily runoff time series analysis. Provides
  various filters to separate baseflow and quickflow using methods by 
  Lyne and Hollick (1979) <https://www.researchgate.net/publication/272491803_Stochastic_Time-Variable_Rainfall-Runoff_Modeling>, 
  Chapman (1991) <doi:10.1029/91WR01007>, 
  Boughton (1993) <https://cir.nii.ac.jp/crid/1572543026556977024>, 
  Jakeman and Hornberger (1993) <doi:10.1029/93WR00877>, 
  Chapman and Maxwell (1996) <https://search.informit.org/doi/10.3316/informit.360361071346753>,
  and Kudelin (1960) <https://www.worldcat.org/title/printsipy-regionalnoi-otsenki-estestvennykh-resursov-podzemnykh-vod/>.
  Implements advanced separation technique by Rets et al. (2022) <doi:10.1134/S0097807822010146> 
  which involves meteorological data to reveal genetic components of the runoff: 
  ground, rain, thaw and spring (seasonal thaw). High-performance C++17 computation, 
  annually aggregated variables, statistical testing and numerous plotting functions 
  for high-quality visualization.",2022-05-18,Timofey Samsonov,https://github.com/tsamsonov/grwat,TRUE,https://github.com/tsamsonov/grwat,441,3,2022-07-06T11:47:19Z,147
gscounts,"Design and analysis of group sequential designs for negative
    binomial outcomes, as described by T Mütze, E Glimm, H Schmidli, T Friede (2018) <doi:10.1177/0962280218773115>.",2021-11-02,Tobias Mütze,https://github.com/tobiasmuetze/gscounts,TRUE,https://github.com/tobiasmuetze/gscounts,12286,1,2021-11-01T16:14:35Z,12286
gsDesign,"Derives group sequential clinical trial designs and describes
    their properties. Particular focus on time-to-event, binary, and
    continuous outcomes. Largely based on methods described in
    Jennison, Christopher and Turnbull, Bruce W., 2000,
    ""Group Sequential Methods with Applications to Clinical Trials""
    ISBN: 0-8493-0316-8.",2022-05-27,Keaven Anderson,"https://keaven.github.io/gsDesign/,
https://github.com/keaven/gsDesign",TRUE,https://github.com/keaven/gsdesign,43980,30,2022-06-28T19:37:08Z,1466
gsignal,"R implementation of the 'Octave' package 'signal', containing
    a variety of signal processing tools, such as signal generation and
    measurement, correlation and convolution, filtering, filter design,
    filter analysis and conversion, power spectrum analysis, system
    identification, decimation and sample rate change, and windowing.",2022-05-15,Geert van Boxtel,https://github.com/gjmvanboxtel/gsignal,TRUE,https://github.com/gjmvanboxtel/gsignal,9070,10,2022-06-19T19:32:44Z,907
gsl,"
 An R wrapper for some of the functionality of the
 Gnu Scientific Library.",2021-11-02,Robin K. S. Hankin,https://github.com/RobinHankin/gsl,TRUE,https://github.com/robinhankin/gsl,677583,10,2021-11-03T07:34:43Z,67758.3
gslnls,"An R interface to nonlinear least-squares optimization with the GNU Scientific Library (GSL), see M. Galassi et al. (2009, ISBN:0954612078). The available trust region methods include the Levenberg-Marquadt algorithm with and without geodesic acceleration, the Steihaug-Toint conjugate gradient algorithm for large systems and several variants of Powell's dogleg algorithm. Bindings are provided to tune a number of parameters affecting the low-level aspects of the trust region algorithms. The interface mimics R's nls() function and returns model objects inheriting from the same class.",2021-12-13,Joris Chau,https://github.com/JorisChau/gslnls,TRUE,https://github.com/jorischau/gslnls,4601,8,2022-06-15T07:20:25Z,575.125
gsloid,"Contains published data sets for global benthic d18O data for 
    0-5.3 Myr <doi:10.1029/2004PA001071> and global sea levels based 
    on marine sediment core data for 0-800 ka <doi:10.5194/cp-12-1-2016>.",2022-05-14,Ben Marwick,https://github.com/benmarwick/gsloid,TRUE,https://github.com/benmarwick/gsloid,14090,5,2022-05-14T22:46:09Z,2818
GSODR,"Provides automated downloading, parsing, cleaning, unit conversion
    and formatting of Global Surface Summary of the Day ('GSOD') weather data
    from the from the USA National Centers for Environmental Information
    ('NCEI').  Units are converted from from United States Customary System
    ('USCS') units to International System of Units ('SI').  Stations may be
    individually checked for number of missing days defined by the user, where
    stations with too many missing observations are omitted.  Only stations with
    valid reported latitude and longitude values are permitted in the final
    data.  Additional useful elements, saturation vapour pressure ('es'), actual
    vapour pressure ('ea') and relative humidity ('RH') are calculated from the
    original data using the improved August-Roche-Magnus approximation (Alduchov
    & Eskridge 1996) and included in the final data set.  The resulting metadata
    include station identification information, country, state, latitude,
    longitude, elevation, weather observations and associated flags.  For
    information on the 'GSOD' data from 'NCEI', please see the 'GSOD'
    'readme.txt' file available from,
    <https://www1.ncdc.noaa.gov/pub/data/gsod/readme.txt>.",2022-05-07,Adam H. Sparks,https://docs.ropensci.org/GSODR/,TRUE,https://github.com/ropensci/gsodr,35988,78,2022-05-08T01:05:35Z,461.38461538461536
gstat,"Variogram modelling; simple, ordinary and universal point or block (co)kriging; spatio-temporal kriging; sequential Gaussian or indicator (co)simulation; variogram and variogram map plotting utility functions; supports sf and stars.",2022-03-14,Edzer Pebesma,https://github.com/r-spatial/gstat/,TRUE,https://github.com/r-spatial/gstat,630596,158,2022-05-01T18:57:47Z,3991.1139240506327
gt,"Build display tables from tabular data with an easy-to-use set of
    functions. With its progressive approach, we can construct display tables
    with a cohesive set of table parts. Table values can be formatted using any
    of the included formatting functions. Footnotes and cell styles can be 
    precisely added through a location targeting system. The way in which 'gt'
    handles things for you means that you don't often have to worry about the
    fine details.",2022-05-24,Richard Iannone,"https://gt.rstudio.com/, https://github.com/rstudio/gt",TRUE,https://github.com/rstudio/gt,680554,1522,2022-07-09T21:04:02Z,447.14454664914587
gtable,"Tools to make it easier to work with ""tables"" of
    'grobs'. The 'gtable' package defines a 'gtable' grob class that specifies a
    grid along with a list of grobs and their placement in the grid. Further the
    package makes it easy to manipulate and combine 'gtable' objects so that 
    complex compositions can be build up sequentially.",2019-03-25,Hadley Wickham,https://github.com/r-lib/gtable,TRUE,https://github.com/r-lib/gtable,15663526,70,2021-10-28T06:15:54Z,223764.65714285715
gtExtras,"Provides additional functions for creating beautiful tables
    with 'gt'. The functions are generally wrappers around boilerplate or
    adding capabilities that are currently not built into 'gt'.",2022-06-09,Thomas Mock,"https://github.com/jthomasmock/gtExtras,
https://jthomasmock.github.io/gtExtras/",TRUE,https://github.com/jthomasmock/gtextras,2696,114,2022-06-26T17:19:05Z,23.649122807017545
gtfs2gps,Convert general transit feed specification (GTFS) data to global positioning system (GPS) records in 'data.table' format. It also has some functions to subset GTFS data in time and space and to convert both representations to simple feature format.,2022-03-10,Rafael H. M. Pereira,https://github.com/ipeaGIT/gtfs2gps,TRUE,https://github.com/ipeagit/gtfs2gps,16293,58,2022-07-07T18:24:50Z,280.91379310344826
gtfsio,"Tools for the development of packages related to General
    Transit Feed Specification (GTFS) files. Establishes a standard for
    representing GTFS feeds using R data types. Provides fast and flexible
    functions to read and write GTFS feeds while sticking to this
    standard. Defines a basic 'gtfs' class which is meant to be extended
    by packages that depend on it. And offers utility functions that
    support checking the structure of GTFS objects.",2021-11-06,Daniel Herszenhut,"https://r-transit.github.io/gtfsio/,
https://github.com/r-transit/gtfsio",TRUE,https://github.com/r-transit/gtfsio,9815,8,2022-06-30T14:13:37Z,1226.875
gtfsrouter,"Use GTFS (General Transit Feed Specification) data for
    routing from nominated start and end stations, and for extracting
    isochrones from nominated start station.",2021-06-11,Mark Padgham,https://github.com/ATFutures/gtfs-router,TRUE,https://github.com/atfutures/gtfs-router,15567,53,2022-06-29T11:50:22Z,293.7169811320755
gtfstools,"Utility functions to read, manipulate, analyse and write
    transit feeds in the General Transit Feed Specification (GTFS) data
    format.",2022-05-24,Daniel Herszenhut,"https://ipeagit.github.io/gtfstools/,
https://github.com/ipeaGIT/gtfstools",TRUE,https://github.com/ipeagit/gtfstools,6877,26,2022-06-30T12:59:33Z,264.5
gtools,"Functions to assist in R programming, including:
  - assist in developing, updating, and maintaining R and R packages ('ask', 'checkRVersion',
    'getDependencies', 'keywords', 'scat'),
  - calculate the logit and inverse logit transformations ('logit', 'inv.logit'),
  - test if a value is missing, empty or contains only NA and NULL values ('invalid'),
  - manipulate R's .Last function ('addLast'),
  - define macros ('defmacro'),
  - detect odd and even integers ('odd', 'even'),
  - convert strings containing non-ASCII characters (like single quotes) to plain ASCII ('ASCIIfy'),
  - perform a binary search ('binsearch'),
  - sort strings containing both numeric and character components ('mixedsort'),
  - create a factor variable from the quantiles of a continuous variable ('quantcut'),
  - enumerate permutations and combinations ('combinations', 'permutation'),
  - calculate and convert between fold-change and log-ratio ('foldchange',
    'logratio2foldchange', 'foldchange2logratio'),
  - calculate probabilities and generate random numbers from Dirichlet distributions
    ('rdirichlet', 'ddirichlet'),
  - apply a function over adjacent subsets of a vector ('running'),
  - modify the TCP\_NODELAY ('de-Nagle') flag for socket objects,
  - efficient 'rbind' of data frames, even if the column names don't match ('smartbind'),
  - generate significance stars from p-values ('stars.pval'),
  - convert characters to/from ASCII codes ('asc', 'chr'),
  - convert character vector to ASCII representation ('ASCIIfy'),
  - apply title capitalization rules to a character vector ('capwords').",2022-06-13,Gregory R. Warnes,https://github.com/r-gregmisc/gtools,TRUE,https://github.com/r-gregmisc/gtools,8555471,11,2022-07-09T17:58:34Z,777770.0909090909
gtrendsR,"An interface for retrieving and displaying the information
        returned online by Google Trends is provided. Trends (number of
        hits) over the time as well as geographic representation of the
        results can be displayed.",2022-05-23,Philippe Massicotte,https://github.com/PMassicotte/gtrendsR,TRUE,https://github.com/pmassicotte/gtrendsr,1491021,310,2022-05-26T12:30:44Z,4809.745161290322
gtsummary,"Creates presentation-ready tables summarizing data
    sets, regression models, and more. The code to create the tables is
    concise and highly customizable. Data frames can be summarized with
    any function, e.g. mean(), median(), even user-written functions.
    Regression models are summarized and include the reference rows for
    categorical variables. Common regression models, such as logistic
    regression and Cox proportional hazards regression, are automatically
    identified and the tables are pre-filled with appropriate column
    headers.",2022-06-22,Daniel D. Sjoberg,"https://github.com/ddsjoberg/gtsummary,
https://www.danieldsjoberg.com/gtsummary/",TRUE,https://github.com/ddsjoberg/gtsummary,280082,684,2022-07-05T19:20:49Z,409.4766081871345
guaguas,"Datos de nombres inscritos en Chile
    entre 1920 y 2021, de acuerdo al Servicio de Registro Civil.
    English: Chilean baby names registered from 1920 to 2021
    by the Civil Registry Service.",2022-03-09,Riva Quiroga,https://github.com/rivaquiroga/guaguas,TRUE,https://github.com/rivaquiroga/guaguas,10329,34,2022-03-09T12:53:31Z,303.79411764705884
Guerry,"Maps of France in 1830, multivariate datasets from A.-M. Guerry and others, and statistical and 
	graphic methods related to Guerry's ""Moral Statistics of France"". The goal is to facilitate the exploration and
	development of statistical and graphic methods for multivariate data in a geospatial context of historical interest.",2021-09-29,Michael Friendly,https://github.com/friendly/Guerry,TRUE,https://github.com/friendly/guerry,61548,0,2021-11-29T21:10:36Z,NA
guess,"Adjust Estimates of Learning for Guessing. The package provides 
    standard guessing correction, and a latent class model that leverages
    informative pre-post transitions. For details of the latent class model,
    see <http://gsood.com/research/papers/guess.pdf>.",2016-02-08,Gaurav Sood,http://github.com/soodoku/guess,TRUE,https://github.com/soodoku/guess,14012,2,2021-12-16T01:22:38Z,7006
GUILDS,"A collection of sampling formulas for the unified neutral model of biogeography and biodiversity. Alongside the sampling formulas, it includes methods to perform maximum likelihood optimization of the sampling formulas, methods to generate data given the neutral model, and methods to estimate the expected species abundance distribution. Sampling formulas included in the GUILDS package are the Etienne Sampling Formula (Etienne 2005), the guild sampling formula, where guilds are assumed to differ in dispersal ability (Janzen et al. 2015), and  the guilds sampling formula conditioned on guild size (Janzen et al. 2015).",2022-03-24,Thijs Janzen,https://github.com/thijsjanzen/GUILDS,TRUE,https://github.com/thijsjanzen/guilds,23428,1,2022-03-14T09:37:40Z,23428
guix.install,"This 'R' package provides a single procedure guix.install(),
  which allows users to install 'R' packages via 'Guix' right from within
  their running 'R' session.  If the requested 'R' package does not exist
  in 'Guix' at this time, the package and all its missing dependencies
  will be imported recursively and the generated package definitions
  will be written to ~/.Rguix/packages.scm.  This record of imported
  packages can be used later to reproduce the environment, and to add
  the packages in question to a proper 'Guix' channel (or 'Guix' itself).
  guix.install() not only supports installing packages from CRAN, but
  also from Bioconductor or even arbitrary 'git' or 'mercurial'
  repositories, replacing the need for installation via 'devtools'.",2022-04-28,Ricardo Wurmus,https://github.com/BIMSBbioinfo/guix.install,TRUE,https://github.com/bimsbbioinfo/guix.install,639,2,2022-06-03T17:28:23Z,319.5
gustave,"Provides a toolkit for analytical variance estimation in survey sampling. Apart from the implementation of standard variance estimators, its main feature is to help the sampling expert produce easy-to-use variance estimation ""wrappers"", where systematic operations (linearization, domain estimation) are handled in a consistent and transparent way.",2021-11-10,Martin Chevalier,https://github.com/martinchevalier/gustave,TRUE,https://github.com/martinchevalier/gustave,14039,4,2021-11-10T09:39:28Z,3509.75
gvc,"Several tools for Global Value Chain ('GVC') analysis are
    implemented.",2022-06-19,Bastiaan Quast,"https://qua.st/gvc, https://github.com/bquast/gvc",TRUE,https://github.com/bquast/gvc,23165,11,2022-06-19T17:35:06Z,2105.909090909091
gwasforest,"Extract and reform data from GWAS (genome-wide association study) results, and then make a single integrated forest plot containing multiple windows of which each shows the result of individual SNPs (or other items of interest).",2020-11-24,Yili Xu,https://github.com/yilixu/gwasforest,TRUE,https://github.com/yilixu/gwasforest,6096,3,2022-04-01T18:31:37Z,2032
gwasrapidd,"'GWAS' R 'API' Data Download.
    This package provides easy access to the 'NHGRI'-'EBI' 'GWAS' Catalog data by
    accessing the 'REST' 'API' <https://www.ebi.ac.uk/gwas/rest/docs/api/>.",2021-11-29,Ramiro Magno,https://github.com/ramiromagno/gwasrapidd,TRUE,https://github.com/ramiromagno/gwasrapidd,2966,45,2021-11-26T02:06:54Z,65.91111111111111
gwavr,"Provides methods to Get Water Attributes Visually in R ('gwavr'). This allows the user to point and click on areas within the United States and get back hydrological data, e.g. flowlines, catchments, basin boundaries, comids, etc.",2022-03-28,Joshua Erickson,https://github.com/joshualerickson/gwavr/,TRUE,https://github.com/joshualerickson/gwavr,1763,8,2022-03-28T20:56:38Z,220.375
gWidgets2,"Re-implementation of the 'gWidgets' API. The API is defined in this
    package. A second, toolkit-specific package is required to use it. At this point only 'gWidgets2tcltk' is viable.",2022-01-10,John Verzani,https://github.com/gWidgets3/gWidgets2,TRUE,https://github.com/gwidgets3/gwidgets2,88520,1,2022-01-10T22:06:51Z,88520
gwpcormapper,"An interactive mapping tool for geographically weighted correlation and partial correlation. Geographically weighted partial correlation coefficients are calculated following (Percival and Tsutsumida, 2017)<doi:10.1553/giscience2017_01_s36> and are described in greater detail in (Tsutsumida et al., 2019)<doi:10.5194/ica-abs-1-372-2019> and (Percival et al., 2021)<arXiv:2101.03491>.",2021-12-09,Joseph Emile Honour Percival,https://github.com/gwpcor/gwpcormapper,TRUE,https://github.com/gwpcor/gwpcormapper,5266,1,2021-12-09T13:25:45Z,5266
GWPR.light,"Geographically weighted panel regression is grounded in a branch of spatial statistics. Using geographically weights, the geographically weighted panel regression is try to solve the residuals from panel regression clustering spatially. To investigate whether the residuals cluster spatially, the Moran's I test is also improved. Furthermore, three local statistic tests are contained to help the users select model. The major references are Fotheringham et al. (2003, ISBN:978-0-470-85525-6) and Beenstock and Felsenstein (2019, ISBN:978-3-030-03614-0).",2022-06-21,Chao Li,https://github.com/MichaelChaoLi-cpu/GWPR.light,TRUE,https://github.com/michaelchaoli-cpu/gwpr.light,3592,0,2022-06-21T05:09:05Z,NA
gyro,Hyperbolic geometry in the Minkowski model and the Poincaré model. The methods are based on the gyrovector space theory developed by A. A. Ungar that can be found in the book 'Analytic Hyperbolic Geometry: Mathematical Foundations And Applications' <doi:10.1142/5914>. The package provides functions to plot three-dimensional hyperbolic polyhedra and to plot hyperbolic tilings of the Poincaré disk.,2022-06-13,Stéphane Laurent,https://github.com/stla/gyro,TRUE,https://github.com/stla/gyro,1910,1,2022-06-15T12:09:21Z,1910
hacksig,"A collection of cancer transcriptomics gene signatures as well as a 
    simple and tidy interface to compute single sample enrichment scores either 
    with the original procedure or with three alternatives:
    the ""combined z-score"" of Lee et al. (2008) <doi:10.1371/journal.pcbi.1000217>,
    the ""single sample GSEA"" of Barbie et al. (2009) <doi:10.1038/nature08460> and 
    the ""singscore"" of Foroutan et al. (2018) <doi:10.1186/s12859-018-2435-4>.
    The 'get_sig_info()' function can be used to retrieve information about each 
    signature implemented.",2022-02-17,Andrea Carenzo,https://github.com/Acare/hacksig,TRUE,https://github.com/acare/hacksig,1784,9,2022-02-17T15:06:08Z,198.22222222222223
hagis,"Analysis of plant pathogen pathotype survey data.  Functions
  provided calculate distribution of susceptibilities, distribution of
  complexities with statistics, pathotype frequency distribution, as well as
  diversity indices for pathotypes.  This package is meant to be a direct
  replacement for Herrmann, Löwer and Schachtel's (1999)
  <doi:10.1046/j.1365-3059.1999.00325.x> Habgood-Gilmour Spreadsheet, 'HaGiS',
  previously used for pathotype analysis.",2021-10-14,Austin G. McCoy,"https://github.com/openplantpathology/hagis,
https://openplantpathology.github.io/hagis/",TRUE,https://github.com/openplantpathology/hagis,15263,5,2022-05-13T07:13:48Z,3052.6
hakaiApi,"Initializes a class that obtains API credentials and provides
    a method to use those credentials to make GET requests to the 'Hakai'
    API server. Usage instructions are documented at
    <https://hakaiinstitute.github.io/hakai-api/>.",2022-04-18,Taylor Denouden,https://github.com/HakaiInstitute/hakai-api-client-r,TRUE,https://github.com/hakaiinstitute/hakai-api-client-r,5213,2,2022-04-18T20:58:53Z,2606.5
hal9001,"A scalable implementation of the highly adaptive lasso algorithm,
  including routines for constructing sparse matrices of basis functions of the
  observed data, as well as a custom implementation of Lasso regression tailored
  to enhance efficiency when the matrix of predictors is composed exclusively of
  indicator functions. For ease of use and increased flexibility, the Lasso
  fitting routines invoke code from the 'glmnet' package by default. The highly
  adaptive lasso was first formulated and described by MJ van der Laan (2017)
  <doi:10.1515/ijb-2015-0097>, with practical demonstrations of its performance
  given by Benkeser and van der Laan (2016) <doi:10.1109/DSAA.2016.93>. This
  implementation of the highly adaptive lasso algorithm was described by Hejazi,
  Coyle, and van der Laan (2020) <doi:10.21105/joss.02526>.",2022-02-09,Jeremy Coyle,https://github.com/tlverse/hal9001,TRUE,https://github.com/tlverse/hal9001,15985,44,2022-02-09T21:50:04Z,363.29545454545456
haldensify,"An algorithm for flexible conditional density estimation based on
    application of pooled hazard regression to an artificial repeated measures
    dataset constructed by discretizing the support of the outcome variable. To
    facilitate non/semi-parametric estimation of the conditional density, the
    highly adaptive lasso, a nonparametric regression function shown to reliably
    estimate a large class of functions at a fast convergence rate, is utilized.
    The pooled hazards data augmentation formulation implemented was first
    described by Díaz and van der Laan (2011) <doi:10.2202/1557-4679.1356>. To
    complement the conditional density estimation utilities, tools for efficient
    nonparametric inverse probability weighted (IPW) estimation of the causal
    effects of stochastic shift interventions (modified treatment policies),
    directly utilizing the density estimation technique for construction of the
    generalized propensity score, are provided. These IPW estimators utilize
    undersmoothing (sieve estimation) of the conditional density estimators in
    order to achieve the non/semi-parametric efficiency bound.",2022-02-09,Nima Hejazi,https://github.com/nhejazi/haldensify,TRUE,https://github.com/nhejazi/haldensify,13789,10,2022-05-23T05:18:28Z,1378.9
handlr,"Converts among many citation formats, including 'BibTeX',
    'Citeproc', 'Codemeta', 'RDF XML', 'RIS', 'Schema.org', and
    'Citation File Format'. A low level 'R6' class is provided, as well
    as stand-alone functions for each citation format for both read
    and write.",2020-10-15,Scott Chamberlain,"https://github.com/ropensci/handlr (devel),
https://docs.ropensci.org/handlr/ (docs)",TRUE,https://github.com/ropensci/handlr,16467,34,2022-04-22T14:07:07Z,484.3235294117647
hansard,"Provides functions to download data from the 
  <http://www.data.parliament.uk/> APIs. Because of the structure of the API, 
  there is a named function for each type of available data for ease of use, 
  as well as some functions designed to retrieve specific pieces of commonly 
  used data. Functions for each new API will be added as and when they become
  available.",2019-11-13,Evan Odell,https://docs.evanodell.com/hansard,TRUE,https://github.com/evanodell/hansard,18456,24,2021-10-07T15:29:03Z,769
haplo.ccs,"Haplotype and covariate relative risks in case-control data are estimated by weighted logistic regression. Diplotype probabilities, which are estimated by EM computation with progressive insertion of loci, are utilized as weights. French et al. (2006) <doi:10.1002/gepi.20161>.",2022-04-28,Benjamin French,https://github.com/vubiostat/haplo.ccs,TRUE,https://github.com/vubiostat/haplo.ccs,2299,0,2022-04-26T14:40:53Z,NA
hardhat,"Building modeling packages is hard. A large amount of effort
    generally goes into providing an implementation for a new method that
    is efficient, fast, and correct, but often less emphasis is put on the
    user interface. A good interface requires specialized knowledge about
    S3 methods and formulas, which the average package developer might not
    have.  The goal of 'hardhat' is to reduce the burden around building
    new modeling packages by providing functionality for preprocessing,
    predicting, and validating input.",2022-06-30,Davis Vaughan,"https://github.com/tidymodels/hardhat,
https://hardhat.tidymodels.org",TRUE,https://github.com/tidymodels/hardhat,1421823,88,2022-06-30T14:17:43Z,16157.079545454546
hashr,"Apply an adaptation of the SuperFastHash algorithm to any R
    object. Hash whole R objects or, for vectors or lists, hash R objects to obtain
    a set of hash values that is stored in a structure equivalent to the input. See
    <http://www.azillionmonkeys.com/qed/hash.html> for a description of the hash
    algorithm.",2021-09-02,Mark van der Loo,https://github.com/markvanderloo/hashr,TRUE,https://github.com/markvanderloo/hashr,21286,8,2021-09-01T14:42:11Z,2660.75
haven,"Import foreign statistical formats into R via the embedded
    'ReadStat' C library, <https://github.com/WizardMac/ReadStat>.",2022-04-15,Hadley Wickham,"https://haven.tidyverse.org, https://github.com/tidyverse/haven,
https://github.com/WizardMac/ReadStat",TRUE,https://github.com/tidyverse/haven,15638305,375,2022-06-27T08:58:19Z,41702.14666666667
hBayesDM,"
    Fit an array of decision-making tasks with computational models in
    a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of
    various computational models with a single line of coding
    (Ahn et al., 2017) <doi:10.1162/CPSY_a_00002>.",2021-05-03,Woo-Young Ahn,https://github.com/CCS-Lab/hBayesDM,TRUE,https://github.com/ccs-lab/hbayesdm,24389,156,2021-09-17T04:41:16Z,156.3397435897436
hdf5r,"'HDF5' is a data model, library and file format for storing
    and managing large amounts of data. This package provides a nearly
    feature complete, object oriented  wrapper for the 'HDF5' API
    <https://support.hdfgroup.org/HDF5/doc/RM/RM_H5Front.html> using R6 classes.
    Additionally, functionality is added so that 'HDF5' objects behave very
    similar to their corresponding R counterparts.",2021-11-15,Holger Hoefling,"https://hhoeflin.github.io/hdf5r/,
https://github.com/hhoeflin/hdf5r/",TRUE,https://github.com/hhoeflin/hdf5r,261238,58,2022-02-10T16:08:38Z,4504.103448275862
hdImpute,"A correlation-based batch process for fast imputation for 
    high dimensional missing data problems via chained random forests.
    See Stekhoven and Bühlmann (2012) <doi:10.1093/bioinformatics/btr597> 
    for more on missForest, and Mayer (2022) 
    <https://github.com/mayer79/missRanger> for more on missRanger.",2022-04-20,Philip Waggoner,NA,TRUE,https://github.com/pdwaggoner/hdimpute,1209,2,2022-04-21T16:48:14Z,604.5
hdme,"Penalized regression for generalized linear models for
  measurement error problems (aka. errors-in-variables). The package
  contains a version of the lasso (L1-penalization) which corrects
  for measurement error (Sorensen et al. (2015) <doi:10.5705/ss.2013.180>). 
  It also contains an implementation of the Generalized Matrix Uncertainty 
  Selector, which is a version the (Generalized) Dantzig Selector for the 
  case of measurement error (Sorensen et al. (2018) <doi:10.1080/10618600.2018.1425626>).",2022-07-03,Oystein Sorensen,https://github.com/osorensen/hdme,TRUE,https://github.com/osorensen/hdme,17411,6,2022-07-03T19:02:10Z,2901.8333333333335
hdnom,"Creates nomogram visualizations for penalized Cox regression
    models, with the support of reproducible survival model building,
    validation, calibration, and comparison for high-dimensional data.",2022-05-18,Nan Xiao,"https://nanx.me/hdnom/, https://github.com/nanxstats/hdnom",TRUE,https://github.com/nanxstats/hdnom,21211,33,2022-05-18T07:59:55Z,642.7575757575758
HDPenReg,"Algorithms for lasso and fused-lasso problems: implementation of
    the lars algorithm for lasso and fusion penalization and EM-based
    algorithms for (logistic) lasso  and fused-lasso penalization.",2022-05-14,Quentin Grimonprez,NA,TRUE,https://github.com/modal-inria/hdpenreg,19573,2,2022-05-15T15:01:05Z,9786.5
hdpGLM,"Implementation of MCMC algorithms to estimate the Hierarchical Dirichlet Process Generalized Linear Model (hdpGLM) presented in the paper Ferrari (2020) Modeling Context-Dependent Latent Heterogeneity, Political Analysis <DOI:10.1017/pan.2019.13>.",2022-05-07,Diogo Ferrari,"https://github.com/DiogoFerrari/hdpGLM,
http://www.diogoferrari.com/hdpGLM/index.html",TRUE,https://github.com/diogoferrari/hdpglm,5049,5,2022-05-06T23:20:34Z,1009.8
HDShOP,"Constructs shrinkage estimators of high-dimensional mean-variance portfolios and performs 
    high-dimensional tests on optimality of a given portfolio. The techniques developed in 
    Bodnar et al. (2018) <doi:10.1016/j.ejor.2017.09.028>, Bodnar et al. (2019) 
    <doi:10.1109/TSP.2019.2929964>, Bodnar et al. (2020) <doi:10.1109/TSP.2020.3037369> 
    are central to the package. They provide simple and feasible estimators and tests for optimal 
    portfolio weights, which are applicable for 'large p and large n' situations where p is the 
    portfolio dimension (number of stocks) and n is the sample size. The package also includes tools
    for constructing portfolios based on shrinkage estimators of the mean vector and covariance matrix
    as well as a new Bayesian estimator for the Markowitz efficient frontier recently developed by 
    Bauder et al. (2021) <doi:10.1080/14697688.2020.1748214>.",2021-10-23,Taras Bodnar,https://github.com/Otryakhin-Dmitry/global-minimum-variance-portfolio,TRUE,https://github.com/otryakhin-dmitry/global-minimum-variance-portfolio,4390,3,2022-02-08T22:18:13Z,1463.3333333333333
HDStIM,"A method for identifying responses to experimental stimulation in mass or flow cytometry that uses high dimensional analysis of measured parameters and can be performed with an end-to-end unsupervised approach. In the context of in vitro stimulation assays where high-parameter cytometry was used to monitor intracellular response markers, using cell populations annotated either through automated clustering or manual gating for a combined set of stimulated and unstimulated samples, 'HDStIM' labels cells as responding or non-responding. The package also provides auxiliary functions to rank intracellular markers based on their contribution to identifying responses and generating diagnostic plots.",2022-06-24,Rohit Farmer,"https://github.com/niaid/HDStIM, https://niaid.github.io/HDStIM/",TRUE,https://github.com/niaid/hdstim,158,2,2022-06-23T18:05:31Z,79
HDTSA,"Procedures for high-dimensional time series analysis including factor analysis proposed by Lam and Yao (2012) <doi:10.1214/12-AOS970> and Chang, Guo and Yao (2015) <doi:10.1016/j.jeconom.2015.03.024>, martingale difference test proposed by Chang, Jiang and Shao (2021) preprint, principal component analysis proposed by Chang, Guo and Yao (2018) <doi:10.1214/17-AOS1613>, unit root test proposed by Chang, Cheng and Yao (2021) <arXiv:2006.07551> and white noise test proposed by Chang, Yao and Zhou (2017) <doi:10.1093/biomet/asw066>.",2021-11-08,Chen Lin,https://github.com/Linc2021/HDTSA,TRUE,https://github.com/linc2021/hdtsa,5637,0,2022-07-04T12:35:15Z,NA
headliner,"Create dynamic, data-driven text. Given two values, a list of 
    talking points is generated and can be combined using string
    interpolation. Based on the 'glue' package.",2022-06-26,Jake Riley,https://github.com/rjake/headliner,TRUE,https://github.com/rjake/headliner,401,19,2022-06-30T02:36:10Z,21.105263157894736
healthyR,"
    Hospital data analysis workflow tools, modeling, and automations. This library
    provides many useful tools to review common administrative hospital data. Some 
    of these include average length of stay, readmission rates, average net pay
    amounts by service lines just to name a few. The aim is to provide a simple
    and consistent verb framework that takes the guesswork out of everything.",2022-04-25,Steven Sanderson,https://github.com/spsanderson/healthyR,TRUE,https://github.com/spsanderson/healthyr,9131,19,2022-05-10T18:51:49Z,480.57894736842104
healthyR.ai,"
    Hospital machine learning and ai data analysis workflow tools, modeling, and automations. 
    This library provides many useful tools to review common administrative 
    hospital data. Some of these include predicting length of stay, and readmits.
    The aim is to provide a simple and consistent verb framework that takes the 
    guesswork out of everything.",2022-07-04,Steven Sanderson,https://github.com/spsanderson/healthyR.ai,TRUE,https://github.com/spsanderson/healthyr.ai,5099,4,2022-07-05T14:42:55Z,1274.75
healthyR.data,Provides data for functions typically used in the 'healthyR' package.,2021-04-09,Steven Sanderson,https://github.com/spsanderson/healthyR.data,TRUE,https://github.com/spsanderson/healthyr.data,9861,1,2022-01-24T16:53:49Z,9861
healthyR.ts,"
    Hospital time series data analysis workflow tools, modeling, and automations. 
    This library provides many useful tools to review common administrative time 
    series hospital data. Some of these include average length of stay, and 
    readmission rates. The aim is to provide a simple and consistent verb 
    framework that takes the guesswork out of everything.",2022-06-09,Steven Sanderson,https://github.com/spsanderson/healthyR.ts,TRUE,https://github.com/spsanderson/healthyr.ts,8421,8,2022-07-08T19:32:15Z,1052.625
healthyverse,"The 'healthyverse' is a set of packages that work in
    harmony because they share common data representations and 'API'
    design. This package is designed to make it easy to install and load
    multiple 'healthyverse' packages in a single step.",2022-01-21,Steven Sanderson,https://github.com/spsanderson/healthyverse,TRUE,https://github.com/spsanderson/healthyverse,6099,5,2022-03-23T15:23:31Z,1219.8
heapsofpapers,"Makes it easy to download a large number of files such as PDF files 
    and CSV files, while automatically slowing down requests, letting you know 
    where it is up to, and adjusting for files that have already been downloaded.",2021-08-23,Rohan Alexander,https://github.com/RohanAlexander/heapsofpapers,TRUE,https://github.com/rohanalexander/heapsofpapers,3414,2,2021-08-23T20:36:35Z,1707
heatmaply,"Create interactive cluster 'heatmaps' that can be saved as a stand-
    alone HTML file, embedded in 'R Markdown' documents or in a 'Shiny' app, and
    available in the 'RStudio' viewer pane. Hover the mouse pointer over a cell to
    show details or drag a rectangle to zoom. A 'heatmap' is a popular graphical
    method for visualizing high-dimensional data, in which a table of numbers
    are encoded as a grid of colored cells. The rows and columns of the matrix
    are ordered to highlight patterns and are often accompanied by 'dendrograms'.
    'Heatmaps' are used in many fields for visualizing observations, correlations,
    missing values patterns, and more. Interactive 'heatmaps' allow the inspection
    of specific value by hovering the mouse over a cell, as well as zooming into
    a region of the 'heatmap' by dragging a rectangle around the relevant area.
    This work is based on the 'ggplot2' and 'plotly.js' engine. It produces
    similar 'heatmaps' to 'heatmap.2' with the advantage of speed
    ('plotly.js' is able to handle larger size matrix), the ability to zoom from
    the 'dendrogram' panes, and the placing of factor variables in the sides of the
    'heatmap'.",2021-10-09,Tal Galili,"https://talgalili.github.io/heatmaply/,
https://cran.r-project.org/package=heatmaply,
https://github.com/talgalili/heatmaply/,
https://www.r-statistics.com/tag/heatmaply/",TRUE,https://github.com/talgalili/heatmaply,237993,318,2021-10-09T13:50:43Z,748.4056603773585
heatwaveR,"The different methods for defining, detecting, and categorising the extreme events 
    known as heatwaves or cold-spells, as first proposed in Hobday et al. (2016) <doi: 10.1016/j.pocean.2015.12.014> 
    and Hobday et al. (2018) <https://www.jstor.org/stable/26542662>. The functions in this package work on both air 
    and water temperature data. These detection algorithms may be used on non-temperature data as well.",2021-10-27,Robert W. Schlegel,"https://robwschlegel.github.io/heatwaveR/index.html,
https://github.com/robwschlegel/heatwaveR",TRUE,https://github.com/robwschlegel/heatwaver,19685,28,2022-06-23T13:27:24Z,703.0357142857143
hedgehog,"Hedgehog will eat all your bugs.
  'Hedgehog' is a property-based testing package in the spirit
  of 'QuickCheck'. With 'Hedgehog', one can test properties
  of their programs against randomly generated input, providing
  far superior test coverage compared to unit testing. One of the
  key benefits of 'Hedgehog' is integrated shrinking of
  counterexamples, which allows one to quickly find the cause of
  bugs, given salient examples when incorrect behaviour occurs.",2018-08-22,Huw Campbell,https://hedgehog.qa,TRUE,https://github.com/hedgehogqa/r-hedgehog,13594,42,2021-07-13T03:45:15Z,323.6666666666667
heemod,"An implementation of the modelling and reporting features described 
    in reference textbook and guidelines (Briggs, Andrew, et al. Decision 
    Modelling for Health Economic Evaluation. Oxford Univ. Press, 2011;
    Siebert, U. et al. State-Transition Modeling. Medical Decision Making 
    32, 690-700 (2012).): deterministic and probabilistic sensitivity analysis, 
    heterogeneity analysis, time dependency on state-time and model-time 
    (semi-Markov and non-homogeneous Markov models), etc.",2021-10-06,Kevin Zarca,NA,TRUE,https://github.com/pierucci/heemod,28296,37,2022-07-04T14:32:54Z,764.7567567567568
helminthR,"Access to large host-parasite data is often hampered by the 
  availability of data and difficulty in obtaining it in a programmatic way
  to encourage analyses. 'helminthR' provides a programmatic interface to the 
  London Natural History Museum's host-parasite database, one of the largest 
  host-parasite databases existing currently <https://www.nhm.ac.uk/research-curation/scientific-resources/taxonomy-systematics/host-parasites/>. The package allows the user
  to query by host species, parasite species, and geographic location.",2021-08-16,Tad Dallas,"https://docs.ropensci.org/helminthR/,
https://github.com/rOpenSci/helminthR/",TRUE,https://github.com/ropensci/helminthr,14205,6,2021-08-16T19:39:47Z,2367.5
helsinki,"Tools for accessing various open data sources in the Helsinki
    region in Finland. Current data sources include
    the Real Estate Department (<http://ptp.hel.fi/avoindata/>),
    Service Map API (<http://api.hel.fi/servicemap/v2/>),
    Linked Events API (<http://api.hel.fi/linkedevents/v1/>),
    Helsinki Region Infoshare statistics API (<https://dev.hel.fi/stats/>).",2021-09-29,Juuso Parkkinen,"http://ropengov.github.io/helsinki/,
https://github.com/rOpenGov/helsinki",TRUE,https://github.com/ropengov/helsinki,18405,6,2021-09-30T10:36:08Z,3067.5
heplots,"Provides HE plot and other functions for visualizing hypothesis
    tests in multivariate linear models. HE plots represent sums-of-squares-and-products 
    matrices for linear hypotheses and for error using ellipses (in two
    dimensions) and ellipsoids (in three dimensions). The related 'candisc' package
    provides visualizations in a reduced-rank canonical discriminant space when
    there are more than a few response variables.",2021-10-06,Michael Friendly,http://friendly.github.io/heplots/,TRUE,https://github.com/friendly/heplots,220323,4,2022-04-04T19:16:22Z,55080.75
here,"Constructs paths to your project's files.
    Declare the relative path of a file within your project with 'i_am()'.
    Use the 'here()' function as a drop-in replacement for 'file.path()',
    it will always locate the files relative to your project root.",2020-12-13,Kirill Müller,"https://here.r-lib.org/, https://github.com/r-lib/here",TRUE,https://github.com/r-lib/here,2902680,340,2022-05-14T02:34:24Z,8537.29411764706
hereR,"Interface to the 'HERE' REST APIs <https://developer.here.com/develop/rest-apis>:
  (1) geocode and autosuggest addresses or reverse geocode POIs using the 'Geocoder' API;
  (2) route directions, travel distance or time matrices and isolines using the 'Routing', 'Matrix Routing' and 'Isoline Routing' APIs;
  (3) request real-time traffic flow and incident information from the 'Traffic' API;
  (4) find request public transport connections and nearby stations from the 'Public Transit' API;
  (5) request intermodal routes using the 'Intermodal Routing' API;
  (6) get weather forecasts, reports on current weather conditions, astronomical
  information and alerts at a specific location from the 'Destination Weather' API.
  Locations, routes and isolines are returned as 'sf' objects.",2021-11-19,Merlin Unterfinger,"https://munterfi.github.io/hereR/,
https://github.com/munterfi/hereR/",TRUE,https://github.com/munterfi/herer,31507,72,2022-07-01T15:20:33Z,437.59722222222223
hermiter,"Facilitates estimation of full univariate and bivariate 
  probability density functions and cumulative distribution functions along with
  full quantile functions (univariate) and nonparametric correlation 
  (bivariate) using Hermite series based estimators. These estimators are 
  particularly useful in the sequential setting (both stationary and 
  non-stationary) and one-pass batch estimation setting for large data sets. 
  Based on: Stephanou, Michael, Varughese, Melvin and Macdonald, Iain. ""Sequential quantiles via Hermite series density estimation."" Electronic Journal of Statistics 11.1 (2017): 570-607 <doi:10.1214/17-EJS1245>, 
  Stephanou, Michael and Varughese, Melvin. ""On the properties of Hermite series based distribution function estimators."" Metrika (2020) <doi:10.1007/s00184-020-00785-z> and Stephanou, Michael and Varughese, Melvin. ""Sequential estimation of Spearman rank correlation using Hermite series estimators."" Journal of Multivariate Analysis (2021) <doi:10.1016/j.jmva.2021.104783>.",2021-11-16,Michael Stephanou,https://github.com/MikeJaredS/hermiter,TRUE,https://github.com/mikejareds/hermiter,8767,12,2022-06-10T06:02:19Z,730.5833333333334
hesim,"A modular and computationally efficient R package for  
  parameterizing, simulating, and analyzing health economic simulation 
  models. The package supports cohort discrete time state transition models 
  (Briggs et al. 1998) <doi:10.2165/00019053-199813040-00003>,
  N-state partitioned survival models (Glasziou et al. 1990)
  <doi:10.1002/sim.4780091106>, and individual-level continuous 
  time state transition models (Siebert et al. 2012) <doi:10.1016/j.jval.2012.06.014>,
  encompassing both Markov (time-homogeneous and time-inhomogeneous) and 
  semi-Markov processes. Decision uncertainty from a cost-effectiveness analysis is 
  quantified with standard graphical and tabular summaries of a probabilistic 
  sensitivity analysis (Claxton et al. 2005, Barton et al. 2008) <doi:10.1002/hec.985>, 
  <doi:10.1111/j.1524-4733.2008.00358.x>. Use of C++ and data.table
  make individual-patient simulation, probabilistic sensitivity analysis, 
  and incorporation of patient heterogeneity fast.",2022-03-31,Devin Incerti,"https://hesim-dev.github.io/hesim/,
https://github.com/hesim-dev/hesim",TRUE,https://github.com/hesim-dev/hesim,24480,45,2022-03-30T23:46:00Z,544
hettx,"Implements methods developed by Ding, Feller, and Miratrix (2016) <doi:10.1111/rssb.12124> <arXiv:1412.5000>,
    and Ding, Feller, and Miratrix (2018) <doi:10.1080/01621459.2017.1407322> <arXiv:1605.06566>
    for testing whether there is unexplained variation in treatment effects across observations, and for characterizing
    the extent of the explained and unexplained variation in treatment effects. The package includes wrapper functions
    implementing the proposed methods, as well as helper functions for analyzing and visualizing the results of the test.",2019-03-06,Ben Fifield,NA,TRUE,https://github.com/bfifield/detect_heteffects,12046,8,2022-02-07T14:50:56Z,1505.75
hetu,"Structural handling of Finnish identity codes (natural persons and 
    organizations); extract information, check ID validity and diagnostics.",2022-05-21,Pyry Kantanen,"https://ropengov.github.io/hetu/, https://github.com/ropengov/hetu",TRUE,https://github.com/ropengov/hetu,5339,2,2022-06-22T10:58:53Z,2669.5
heuristica,"Implements various heuristics like Take The Best and
    unit-weight linear, which do two-alternative choice: which of
    two objects will have a higher criterion?  Also offers functions
    to assess performance, e.g. percent correct across all row pairs
    in a data set and finding row pairs where models disagree.
    New models can be added by implementing a fit and predict function--
    see vignette.  Take The Best was first described in: Gigerenzer, G.
    & Goldstein, D. G. (1996) <doi:10.1037/0033-295X.103.4.650>.  All
    of these heuristics were run on many data sets and analyzed in:
    Gigerenzer, G., Todd, P. M., & the ABC Group (1999).
    <ISBN:978-0195143812>.",2021-09-08,Jean Whitmore,https://github.com/jeanimal/heuristica,TRUE,https://github.com/jeanimal/heuristica,16206,5,2021-09-08T14:36:14Z,3241.2
heuristicsmineR,"Provides the heuristics miner algorithm for process discovery 
   as proposed by Weijters et al. (2011) <doi:10.1109/CIDM.2011.5949453>. The
   algorithm builds a causal net from an event log created with the 'bupaR' 
   package. Event logs are a set of ordered sequences of events for which 
   'bupaR' provides the S3 class eventlog(). The discovered causal nets 
   can be visualised as 'htmlwidgets' and it is possible to annotate them with
   the occurrence frequency or processing and waiting time of process 
   activities.  ",2021-10-11,Felix Mannhardt,https://github.com/bupaverse/heuristicsmineR,TRUE,https://github.com/bupaverse/heuristicsminer,16188,13,2021-10-11T15:33:37Z,1245.2307692307693
hexSticker,Helper functions for creating reproducible hexagon sticker purely in R.,2020-12-05,Guangchuang Yu,https://github.com/GuangchuangYu/hexSticker,TRUE,https://github.com/guangchuangyu/hexsticker,31240,597,2022-06-20T02:17:02Z,52.32830820770519
hgnc,"A set of routines to quickly download and import the 'HGNC'
    data set on mapping of gene symbols to gene entries in other popular
    databases or resources.",2022-06-08,Ramiro Magno,"https://github.com/maialab/hgnc, https://maialab.org/hgnc/",TRUE,https://github.com/maialab/hgnc,1099,1,2022-06-08T17:01:50Z,1099
HGNChelper,"Contains functions for
 identifying and correcting HGNC human gene symbols and MGI mouse gene symbols 
 which have been converted to date format by Excel, withdrawn, or aliased.
 Also contains functions for reversibly converting between HGNC
 symbols and valid R names.",2019-10-24,Levi Waldron and Markus Riester,https://github.com/waldronlab/HGNChelper,TRUE,https://github.com/waldronlab/hgnchelper,31892,35,2022-04-05T16:40:44Z,911.2
hhsmm,"Develops algorithms for fitting, prediction, simulation 
  and initialization of the hidden hybrid Markov/semi-Markov model, 
  introduced by Guedon (2005) <doi:10.1016/j.csda.2004.05.033>, 
  which also includes several tools for handling missing data, 
  nonparametric mixture of B-splines emissions (Langrock et al., 2015
  <doi:10.1111/biom.12282>), fitting regime switching regression 
  (Kim et al., 2008 <doi:10.1016/j.jeconom.2007.10.002>) and auto-regressive 
  hidden hybrid Markov/semi-Markov model, spline-based nonparametric 
  estimation of additive state-switching models  
  (Langrock et al., 2018 <doi:10.1111/stan.12133>)
  and many other useful tools 
  (read for more description: <arXiv:2109.12489>). ",2022-05-29,Morteza Amini,NA,TRUE,https://github.com/mortamini/hhsmm,5220,0,2022-02-12T03:33:02Z,NA
hibayes,"A user-friendly tool to fit Bayesian regression models. It can fit 3 types of Bayesian models using individual-level, summary-level, and individual plus pedigree-level (single-step) data for both Genomic prediction/selection (GS) and Genome-Wide Association Study (GWAS), it was designed to estimate joint effects and genetic parameters for a complex trait, including:
    (1) fixed effects and coefficients of covariates,
    (2) environmental random effects, and its corresponding variance, 
    (3) genetic variance, 
    (4) residual variance, 
    (5) heritability, 
    (6) genomic estimated breeding values (GEBV) for both genotyped and non-genotyped individuals,
    (7) SNP effect size, 
    (8) phenotype/genetic variance explained (PVE) for single or multiple SNPs, 
    (9) posterior probability of association of the genomic window (WPPA), 
    (10) posterior inclusive probability (PIP). 
    The functions are not limited, we will keep on going in enriching it with more features. 
    References: Meuwissen et al. (2001) <doi:10.1093/genetics/157.4.1819>; Gustavo et al. (2013) <doi:10.1534/genetics.112.143313>; Habier et al. (2011) <doi:10.1186/1471-2105-12-186>; Yi et al. (2008) <doi:10.1534/genetics.107.085589>; Zhou et al. (2013) <doi:10.1371/journal.pgen.1003264>; Moser et al. (2015) <doi:10.1371/journal.pgen.1004969>; Lloyd-Jones et al. (2019) <doi:10.1038/s41467-019-12653-0>; Henderson (1976) <doi:10.2307/2529339>; Fernando et al. (2014) <doi:10.1186/1297-9686-46-50>.",2022-05-25,Lilin Yin,https://github.com/YinLiLin/hibayes,TRUE,https://github.com/yinlilin/hibayes,2189,29,2022-06-21T14:23:07Z,75.48275862068965
HiClimR,"A tool for Hierarchical Climate Regionalization applicable to any correlation-based clustering.
             It adds several features and a new clustering method (called, 'regional' linkage) to hierarchical
             clustering in R ('hclust' function in 'stats' library): data regridding, coarsening spatial resolution,
             geographic masking, contiguity-constrained clustering, data filtering by mean and/or variance
             thresholds, data preprocessing (detrending, standardization, and PCA), faster correlation function
             with preliminary big data support, different clustering methods, hybrid hierarchical clustering,
             multivariate clustering (MVC), cluster validation, visualization of regionalization results, and
             exporting region map and mean timeseries into NetCDF-4 file.
             The technical details are described in Badr et al. (2015) <doi:10.1007/s12145-015-0221-7>.",2022-01-20,Hamada S. Badr,"https://hsbadr.github.io/HiClimR/,
https://github.com/hsbadr/HiClimR",TRUE,https://github.com/hsbadr/hiclimr,36704,11,2022-07-04T12:14:10Z,3336.7272727272725
hierfstat,"Estimates hierarchical F-statistics from haploid or
    diploid genetic data with any numbers of levels in the hierarchy, following the
    algorithm of Yang (Evolution(1998), 52:950).
    Tests via randomisations the significance
    of each F and variance components, using the likelihood-ratio statistics G
    (Goudet et al. (1996) <https://academic.oup.com/genetics/article/144/4/1933/6017091>).
    Estimates genetic diversity statistics
    for haploid and diploid genetic datasets in various formats, including inbreeding and
    coancestry coefficients, and population specific F-statistics following
    Weir and Goudet (2017) <https://academic.oup.com/genetics/article/206/4/2085/6072590>.",2022-05-05,Jerome Goudet,"https://www.r-project.org, https://github.com/jgx65/hierfstat",TRUE,https://github.com/jgx65/hierfstat,78654,20,2022-05-05T21:07:24Z,3932.7
HierPortfolios,"Machine learning portfolio allocation strategies based on hierarchical clustering methods. 
 The implemented methods are:
  Hierarchical risk parity (De Prado, 2016) <DOI: 10.3905/jpm.2016.42.4.059> and
  Hierarchical clustering-based asset allocation (Raffinot, 2017) 
  <DOI: 10.3905/jpm.2018.44.2.089>.",2021-11-09,Carlos Trucios,https://github.com/ctruciosm/HierPortfolios,TRUE,https://github.com/ctruciosm/hierportfolios,2134,4,2021-11-27T16:24:00Z,533.5
hierSDR,Provides semiparametric sufficient dimension reduction for central mean subspaces for heterogeneous data defined by combinations of binary factors (such as chronic conditions). Subspaces are estimated to be hierarchically nested to respect the structure of subpopulations with overlapping characteristics. This package is an implementation of the proposed methodology of Huling and Yu (2021) <doi:10.1111/biom.13546>.,2021-09-23,Jared Huling,NA,TRUE,https://github.com/jaredhuling/hiersdr,3095,1,2021-09-23T16:46:29Z,3095
highcharter,"A wrapper for the 'Highcharts' library including
    shortcut functions to plot R objects. 'Highcharts'
    <https://www.highcharts.com/> is a charting library offering
    numerous chart types with a simple configuration syntax.",2022-01-03,Joshua Kunst,"https://jkunst.com/highcharter/,
https://github.com/jbkunst/highcharter",TRUE,https://github.com/jbkunst/highcharter,361283,653,2022-04-22T23:22:00Z,553.2664624808576
highfrequency,"Provide functionality to manage, clean and match highfrequency
    trades and quotes data, calculate various liquidity measures, estimate and
    forecast volatility, detect price jumps and investigate microstructure noise and intraday
    periodicity.",2022-05-03,Kris Boudt,https://github.com/jonathancornelissen/highfrequency,TRUE,https://github.com/jonathancornelissen/highfrequency,44097,93,2022-05-05T16:59:46Z,474.16129032258067
hilbert,"Provides utilities for encoding and decoding coordinates to/from Hilbert curves
  based on the iterative encoding implementation described in Chen et al. (2006) <doi:10.1002/spe.793>.",2022-04-08,Justin Singh-Mohudpur,"https://hilbert.justinsingh.me,
https://github.com/program--/hilbert",TRUE,https://github.com/program--/hilbert,637,2,2022-04-06T17:49:31Z,318.5
hillR,"Calculate taxonomic, functional and phylogenetic diversity measures 
    through Hill Numbers proposed by Chao, Chiu and Jost (2014) 
    <doi:10.1146/annurev-ecolsys-120213-091540>.",2021-03-02,Daijiang Li,https://github.com/daijiang/hillR,TRUE,https://github.com/daijiang/hillr,17993,24,2021-10-27T17:15:37Z,749.7083333333334
HIMA,"Allows to estimate and test high-dimensional mediation effects based on advanced mediator screening and penalized regression techniques. Methods used in the package refer to Zhang H, Zheng Y, Hou L, Zheng C, Liu L. Mediation Analysis for Survival Data with High-Dimensional Mediators. (2021) <doi: 10.1093/bioinformatics/btab564>.",2022-02-03,Yinan Zheng,https://github.com/YinanZheng/HIMA/,TRUE,https://github.com/yinanzheng/hima,16077,7,2022-02-03T07:28:20Z,2296.714285714286
himach,"For supersonic aircraft, flying subsonic over land,
    High Mach finds the best route between airports. Allows for coastal buffer and
    potentially closed regions. Uses a minimal model of aircraft
    performance: the focus is on time saved versus subsonic flight, rather
    than on vertical flight profile. For modelling and forecasting, not for planning your
    flight!",2022-06-09,David Marsh,https://github.com/david6marsh/himach,TRUE,https://github.com/david6marsh/himach,6898,1,2022-06-20T12:49:07Z,6898
hint,"Hypergeometric Intersection distributions are a
    broad group of distributions that describe the probability of picking
    intersections when drawing independently from two (or more) urns
    containing variable numbers of balls belonging to the same n
    categories. <arXiv:1305.0717>.",2022-02-02,Alex T. Kalinka,https://github.com/alextkalinka/hint,TRUE,https://github.com/alextkalinka/hint,18701,0,2022-02-02T14:54:15Z,NA
hIRT,"Implementation of a class of hierarchical item response
  theory (IRT) models where both the mean and the variance of latent preferences
  (ability parameters) may depend on observed covariates. The current
  implementation includes both the two-parameter latent trait model for binary data and the
  graded response model for ordinal data. Both are fitted via the Expectation-Maximization (EM)
  algorithm. Asymptotic standard errors are derived from the observed information
  matrix.",2020-03-26,Xiang Zhou,http://github.com/xiangzhou09/hIRT,TRUE,https://github.com/xiangzhou09/hirt,15369,7,2021-12-14T21:14:23Z,2195.5714285714284
historydata,"These sample data sets are intended for historians
    learning R. They include population, institutional, religious,
    military, and prosopographical data suitable for mapping,
    quantitative analysis, and network analysis.",2014-12-24,Lincoln Mullen,https://github.com/ropensci/historydata,TRUE,https://github.com/ropensci/historydata,20019,74,2021-10-13T21:39:51Z,270.52702702702703
hitandrun,"The ""Hit and Run"" Markov Chain Monte Carlo method for sampling uniformly from convex shapes defined by linear constraints, and the ""Shake and Bake"" method for sampling from the boundary of such shapes. Includes specialized functions for sampling normalized weights with arbitrary linear constraints. Tervonen, T., van Valkenhoef, G., Basturk, N., and Postmus, D. (2012) <doi:10.1016/j.ejor.2012.08.026>. van Valkenhoef, G., Tervonen, T., and Postmus, D. (2014) <doi:10.1016/j.ejor.2014.06.036>.",2022-05-27,Gert van Valkenhoef,https://github.com/gertvv/hitandrun,TRUE,https://github.com/gertvv/hitandrun,37348,11,2022-05-27T11:31:04Z,3395.2727272727275
hkdatasets,"Datasets related to Hong Kong, including information on the 2019 elected District Councillors (<https://www.districtcouncils.gov.hk> and <https://dce2019.hk01.com/>) and traffic collision data from the Hong Kong Department of Transport (<https://www.td.gov.hk/>). All
    of the data in this package is available in the public domain.",2021-09-04,Martin Chan,https://hong-kong-districts-info.github.io/hkdatasets/,TRUE,https://github.com/hong-kong-districts-info/hkdatasets,7190,12,2021-09-04T16:10:43Z,599.1666666666666
hlaR,"A streamlined tool for eplet analysis of donor and recipient HLA (human leukocyte antigen) mismatch. Messy, low-resolution HLA typing data is cleaned, and imputed to high-resolution using the NMDP (National Marrow Donor Program) haplotype reference database <https://haplostats.org/haplostats>. High resolution data is analyzed for overall or single antigen eplet mismatch using a reference table (currently supporting 'HLAMatchMaker' <http://www.epitopes.net> versions 2 and 3). Data can enter or exit the workflow at different points depending on the user's aims and initial data quality.",2022-05-13,Joan Zhang,"https://pubmed.ncbi.nlm.nih.gov/35101308/,
https://emory-larsenlab.shinyapps.io/hlar_shiny/",TRUE,https://github.com/larsenlab/hlar,7120,2,2022-06-03T15:15:34Z,3560
hlidacr,"Provides access to datasets published by 'Hlídač státu' <https://www.hlidacstatu.cz/>, 
    a Czech watchdog, via their API. ",2021-09-16,Michael Škvrňák,https://github.com/skvrnami/hlidacr,TRUE,https://github.com/skvrnami/hlidacr,5513,9,2021-09-16T13:24:12Z,612.5555555555555
HMDHFDplus,"Utilities for reading data from the Human Mortality Database (<https://www.mortality.org>), Human Fertility Database (<https://www.humanfertility.org>), and similar databases from the web or locally into an R session as data.frame objects. These are the two most widely used sources of demographic data to study basic demographic change, trends, and develop new demographic methods. Other supported databases at this time include the Human Fertility Collection (<https://www.fertilitydata.org>), The Japanese Mortality Database (<https://www.ipss.go.jp/p-toukei/JMD/index-en.html>), and the Canadian Human Mortality Database (<http://www.bdlc.umontreal.ca/chmd/>). Arguments and data are standardized.",2022-06-18,Tim Riffe,https://github.com/timriffe/TR1,TRUE,https://github.com/timriffe/tr1,20146,3,2022-06-16T13:09:40Z,6715.333333333333
hmer,"A set of objects and functions for Bayes Linear emulation and history matching.
  Core functionality includes automated training of emulators to data, diagnostic functions
  to ensure suitability, and a variety of proposal methods for generating 'waves' of points.
  For details on the mathematical background, there are many papers available on the topic
  (see references attached to function help files); for details of the functions in this package,
  consult the manual or help files.",2022-05-17,Andrew Iskauskas,https://github.com/andy-iskauskas/hmer,TRUE,https://github.com/andy-iskauskas/hmer,885,9,2022-07-06T08:27:41Z,98.33333333333333
hms,"Implements an S3 class for storing and formatting time-of-day
    values, based on the 'difftime' class.",2021-09-26,Kirill Müller,"https://hms.tidyverse.org/, https://github.com/tidyverse/hms",TRUE,https://github.com/tidyverse/hms,23261461,127,2022-05-14T02:33:05Z,183161.11023622047
Hmsc,"Hierarchical Modelling of Species Communities (HMSC) is
   a model-based approach for analyzing community ecological data. 
   This package implements it in the Bayesian framework with Gibbs
   Markov chain Monte Carlo (MCMC) sampling (Tikhonov et al. (2020)
   <doi:10.1111/2041-210X.13345>).",2021-02-24,Otso Ovaskainen,https://www.helsinki.fi/en/researchgroups/statistical-ecology/hmsc,TRUE,https://github.com/hmsc-r/hmsc,24994,76,2022-06-11T16:16:48Z,328.86842105263156
hockeystick,"Provides easy access to essential climate change datasets to non-climate experts. Users can download the latest raw data from authoritative sources and view it via pre-defined 'ggplot2' charts. Datasets include atmospheric CO2, emissions, instrumental and proxy temperature records, sea levels, Arctic/Antarctic sea-ice, Hurricanes, and Paleoclimate data. Sources include: NOAA Mauna Loa Laboratory <https://gml.noaa.gov/ccgg/trends/data.html>, Global Carbon Project <https://www.globalcarbonproject.org/carbonbudget/20/data.htm>, NASA GISTEMP <https://data.giss.nasa.gov/gistemp/>, National Snow and Sea Ice Data Center <https://nsidc.org/data/seaice_index/archives>, CSIRO <https://research.csiro.au/slrwavescoast/sea-level/measurements-and-data/sea-level-data/>, NOAA Laboratory for Satellite Altimetry <https://www.star.nesdis.noaa.gov/socd/lsa/SeaLevelRise/> and HURDAT Atlantic Hurricane Database <https://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html>, Vostok Paleo carbon dioxide and temperature data: <https://cdiac.ess-dive.lbl.gov/trends/co2/vostok.html>.",2021-09-20,Hernando Cortina,"https://cortinah.github.io/hockeystick/,
https://github.com/cortinah/hockeystick",TRUE,https://github.com/cortinah/hockeystick,6930,34,2022-03-31T03:59:28Z,203.8235294117647
homologene,"A wrapper for the homologene database by the National Center for
    Biotechnology Information ('NCBI'). It allows searching for gene homologs across 
    species. Data in this package can be found at <ftp://ftp.ncbi.nih.gov/pub/HomoloGene/build68/>.
    The package also includes an updated version of the homologene database where 
    gene identifiers and symbols are replaced with their latest (at the time of
    submission) version and functions to fetch latest annotation data to keep updated.",2019-03-28,Ogan Mancarci,https://github.com/oganm/homologene,TRUE,https://github.com/oganm/homologene,16365,28,2022-07-10T07:06:34Z,584.4642857142857
homomorpheR,"Homomorphic computations in R for privacy-preserving applications. Currently only
             the Paillier Scheme is implemented.",2019-01-23,Balasubramanian Narasimhan,http://github.com/bnaras/homomorpheR,TRUE,https://github.com/bnaras/homomorpher,15112,4,2022-03-31T00:42:50Z,3778
hoopR,"A utility to quickly obtain clean and tidy men's
    basketball play by play data. Provides functions to access
    live play by play and box score data from ESPN<https://www.espn.com> with shot locations
    when available. It is also a full NBA Stats API<https://www.nba.com/stats/> wrapper.
    It is also a scraping and aggregating interface for Ken Pomeroy's 
    men's college basketball statistics website<https://kenpom.com>. It provides users with an
    active subscription the capability to scrape the website tables and
    analyze the data for themselves.",2022-06-17,Saiem Gilani,"https://github.com/sportsdataverse/hoopR,
http://hoopr.sportsdataverse.org/",TRUE,https://github.com/sportsdataverse/hoopr,3348,33,2022-06-17T06:18:26Z,101.45454545454545
hopkins,Calculate Hopkins statistic to assess the clusterability of data. See Hopkins and Skellam (1954) <doi:10.1093/oxfordjournals.aob.a083391>.,2022-01-17,Kevin Wright,https://kwstat.github.io/hopkins/,TRUE,https://github.com/kwstat/hopkins,3442,0,2022-01-09T15:37:03Z,NA
hospitals,A data set of the Portuguese 'NHS' hospitals.,2021-11-26,Ramiro Magno,https://github.com/nhs-pt/hospitals,TRUE,https://github.com/nhs-pt/hospitals,1938,1,2021-11-26T11:05:47Z,1938
HostSwitch,"Using a simulation-based approach, the 'HostSwitch' package provides functions to investigate host switches by consumers.
    The individual-based model is based on the concept of ecological fitting.
    The mockup model is published by Araujo et al. 2015. Understanding Host-Switching by Ecological Fitting (<doi:10.1371/journal.pone.0139225>).
    The package provides an R-friendly and modified version of this model which can be applied to different consumer-resource scenarios.",2022-05-24,Bernd Panassiti,https://github.com/berndpanassiti/HostSwitch,TRUE,https://github.com/berndpanassiti/hostswitch,7580,2,2022-07-08T18:24:04Z,3790
Hotelling,A set of R functions which implements Hotelling's T^2 test and some variants of it. Functions are also included for Aitchison's additive log ratio and centred log ratio transformations.,2021-09-09,James Curran,https://github.com/jmcurran/Hotelling,TRUE,https://github.com/jmcurran/hotelling,39755,1,2021-09-09T01:20:30Z,39755
HotellingEllipse,Functions to compute the semi-axes lengths and coordinate points of Hotelling ellipse. Bro and Smilde (2014) <DOI:10.1039/c3ay41907j>. Brereton (2016) <DOI:10.1002/cem.2763>.,2022-06-24,Christian L. Goueguel,https://github.com/ChristianGoueguel/HotellingEllipse,TRUE,https://github.com/christiangoueguel/hotellingellipse,4363,3,2022-06-28T04:09:33Z,1454.3333333333333
howManyImputations,"When performing multiple imputations, while 5-10 imputations are
             sufficient for obtaining point estimates, a larger number of
             imputations are needed for proper standard error estimates.
             This package allows you to calculate how many imputations are
             needed, following the work of von Hippel (2020)
             <doi:10.1177/0049124117747303>.",2022-05-31,Josh Errickson,https://errickson.net/howManyImputations/,TRUE,https://github.com/josherrickson/howmanyimputations,983,7,2022-06-01T00:54:59Z,140.42857142857142
hrbrthemes,"A compilation of extra 'ggplot2' themes, scales and utilities, including a 
    spell check function for plot label fields and an overall emphasis on typography. 
    A copy of the 'Google' font 'Roboto Condensed' <https://github.com/google/roboto/> 
    is also included along with a copy of the 'IBM' 'Plex Sans' <https://github.com/IBM/type>,
    'Titillium Web' <https://fonts.google.com/specimen/Titillium+Web>, and
    'Public Sans' <https://github.com/uswds/public-sans/> fonts
    are also included to support their respective typography-oriented themes.",2020-03-06,Bob Rudis,http://github.com/hrbrmstr/hrbrthemes,TRUE,https://github.com/hrbrmstr/hrbrthemes,735761,1042,2021-07-21T11:46:10Z,706.1046065259117
hrqglas,"A program that conducts group variable selection for quantile and robust mean 
              regression (Sherwood and Li, 2021). The group lasso penalty (Yuan and Lin, 2006) is used for
              group-wise variable selection. Both of the quantile and mean regression models are based on the Huber loss.
              Specifically, with the tuning parameter in the Huber loss approaching to 0, the quantile check 
              function can be approximated by the Huber loss for the median and the tilted version of 
              Huber loss at other quantiles. Such approximation provides computational efficiency and stability, and
              has also been shown to be statistical consistent.",2021-08-16,Shaobo Li,GitHub: https://github.com/shaobo-li/hrqglas,TRUE,https://github.com/shaobo-li/hrqglas,4254,1,2021-09-21T19:47:30Z,4254
hsstan,"Linear and logistic regression models penalized with hierarchical
  shrinkage priors for selection of biomarkers (or more general variable
  selection), which can be fitted using Stan (Carpenter et al. (2017)
  <doi:10.18637/jss.v076.i01>). It implements the horseshoe and regularized
  horseshoe priors (Piironen and Vehtari (2017) <doi:10.1214/17-EJS1337SI>),
  as well as the projection predictive selection approach to recover a sparse
  set of predictive biomarkers (Piironen, Paasiniemi and Vehtari (2020)
  <doi:10.1214/20-EJS1711>).",2021-09-16,Marco Colombo,https://github.com/mcol/hsstan,TRUE,https://github.com/mcol/hsstan,11701,4,2021-11-21T15:54:15Z,2925.25
htm2txt,Convert a html document to plain texts by stripping off all html tags.,2022-06-12,Sangchul Park,https://github.com/replicable/htm2txt,TRUE,https://github.com/replicable/htm2txt,29635,2,2022-06-12T10:02:53Z,14817.5
htmldf,"Simple tools for scraping webpages, extracting common html tags and parsing contents to a tidy, tabular format.  Tools help with extraction of page titles, links, images, rss feeds, social media handles and page metadata.",2022-07-09,Alastair Rushworth,https://github.com/alastairrushworth/htmldf/,TRUE,https://github.com/alastairrushworth/htmldf,9051,79,2022-07-09T16:07:29Z,114.56962025316456
htmltab,"HTML tables are a valuable data source but extracting and recasting
    these data into a useful format can be tedious. This package allows to collect
    structured information from HTML tables. It is similar to `readHTMLTable()`
    of the XML package but provides three major advantages. First, the function
    automatically expands row and column spans in the header and body cells.
    Second, users are given more control over the identification of header and body
    rows which will end up in the R table, including semantic header information
    that appear throughout the body. Third, the function preprocesses table code,
    corrects common types of malformations, removes unneeded parts and so helps to
    alleviate the need for tedious post-processing.",2021-09-16,Christian Rubba,https://github.com/htmltab/htmltab,TRUE,https://github.com/htmltab/htmltab,93938,1,2021-09-16T11:05:57Z,93938
htmlTable,"Tables with state-of-the-art layout elements such as row spanners,
    column spanners, table spanners, zebra striping, and more. While allowing
    advanced layout, the underlying css-structure is simple in order to maximize
    compatibility with common word processors.  The package also contains a few 
    text formatting functions that help outputting text compatible with HTML/LaTeX.",2022-07-07,Max Gordon,https://gforge.se/packages/,TRUE,https://github.com/gforge/htmltable,5941461,70,2022-07-07T18:14:47Z,84878.0142857143
htmltools,Tools for HTML generation and output.,2021-08-25,Carson Sievert,https://github.com/rstudio/htmltools,TRUE,https://github.com/rstudio/htmltools,20935177,158,2022-06-16T05:10:00Z,132501.12025316455
htmlwidgets,"A framework for creating HTML widgets that render in various
    contexts including the R console, 'R Markdown' documents, and 'Shiny'
    web applications.",2021-09-08,Carson Sievert,https://github.com/ramnathv/htmlwidgets,TRUE,https://github.com/ramnathv/htmlwidgets,11918960,729,2021-11-17T22:27:18Z,16349.739368998627
hts,"Provides methods for analysing and forecasting hierarchical and 
    grouped time series. The available forecast methods include bottom-up,
    top-down, optimal combination reconciliation (Hyndman et al. 2011) 
    <doi:10.1016/j.csda.2011.03.006>, and trace minimization reconciliation
    (Wickramasuriya et al. 2018) <doi:10.1080/01621459.2018.1448825>.",2021-05-30,Rob Hyndman,https://pkg.earo.me/hts/,TRUE,https://github.com/earowang/hts,441282,100,2021-11-23T22:43:38Z,4412.82
httk,"Generic models and chemical-specific data for simulation and
             statistical analysis of chemical toxicokinetics (""TK"") as
             described by Pearce et al. (2017) <doi:10.18637/jss.v079.i04>.
             Chemical-specific in vitro data have been obtained from relatively
             high-throughput experiments. Both physiologically-based (""PBTK"")
             and empirical (for example, one compartment) ""TK"" models can be
             parameterized with the data provided for thousands of chemicals,
             multiple exposure routes, and various species. The models consist
             of systems of ordinary differential equations which are solved
             using compiled (C-based) code for speed. A Monte Carlo sampler is
             included, which allows for simulating human biological variability
             (Ring et al., 2017 <doi:10.1016/j.envint.2017.06.004>)
             and propagating parameter uncertainty. Calibrated methods are
             included for predicting tissue:plasma partition coefficients and
             volume of distribution
             (Pearce et al., 2017 <doi:10.1007/s10928-017-9548-7>).
             These functions and data provide a set of tools for
             in vitro-in vivo extrapolation (""IVIVE"") of high-throughput
             screening data (for example, Tox21, ToxCast) to real-world
             exposures via reverse dosimetry (also known as ""RTK"")
             (Wetmore et al., 2015 <doi:10.1093/toxsci/kfv171>).",2022-03-26,John Wambaugh,https://www.epa.gov/chemical-research/rapid-chemical-exposure-and-dose-research,TRUE,https://github.com/usepa/comptox-expocast-httk,30913,9,2022-04-24T13:37:47Z,3434.777777777778
httpgd,"A graphics device for R that is accessible via network protocols.
    This package was created to make it easier to embed live R graphics in 
    integrated development environments and other applications.
    The included 'HTML/JavaScript' client (plot viewer) aims to provide a better overall user experience when dealing with R graphics.
    The device asynchronously serves graphics via 'HTTP' and 'WebSockets'.",2022-02-02,Florian Rupprecht,"https://github.com/nx10/httpgd, https://nx10.github.io/httpgd/",TRUE,https://github.com/nx10/httpgd,25469,211,2022-05-28T22:35:38Z,120.70616113744076
httptest,"Testing and documenting code that communicates with remote servers
    can be painful. Dealing with authentication, server state,
    and other complications can make testing seem too costly to
    bother with. But it doesn't need to be that hard. This package enables one
    to test all of the logic on the R sides of the API in your package without
    requiring access to the remote service. Importantly, it provides three
    contexts that mock the network connection in different ways, as well as
    testing functions to assert that HTTP requests were---or were
    not---made. It also allows one to safely record real API responses to use as
    test fixtures. The ability to save responses and load them offline also
    enables one to write vignettes and other dynamic documents that can be
    distributed without access to a live server.",2021-09-22,Neal Richardson,"https://enpiar.com/r/httptest/,
https://github.com/nealrichardson/httptest",TRUE,https://github.com/nealrichardson/httptest,51999,76,2022-04-27T16:50:37Z,684.1973684210526
httptest2,"Testing and documenting code that communicates with remote servers
    can be painful. This package helps with writing tests for packages that
    use 'httr2'. It enables testing all of the logic
    on the R sides of the API without requiring access to the
    remote service, and it also allows recording real API responses to use as
    test fixtures. The ability to save responses and load them offline also
    enables writing vignettes and other dynamic documents that can be
    distributed without access to a live server.",2022-01-10,Neal Richardson,"https://enpiar.com/httptest2/,
https://github.com/nealrichardson/httptest2",TRUE,https://github.com/nealrichardson/httptest2,2967,12,2022-01-05T02:15:07Z,247.25
httpuv,"Provides low-level socket and protocol support for handling
    HTTP and WebSocket requests directly from within R. It is primarily
    intended as a building block for other packages, rather than making it
    particularly easy to create complete web applications using httpuv alone.
    httpuv is built on top of the libuv and http-parser C libraries, both of
    which were developed by Joyent, Inc. (See LICENSE file for libuv and
    http-parser license information.)",2022-01-05,Winston Chang,https://github.com/rstudio/httpuv,TRUE,https://github.com/rstudio/httpuv,10494972,196,2022-04-15T16:37:36Z,53545.77551020408
httr,"Useful tools for working with HTTP organised by HTTP verbs
    (GET(), POST(), etc). Configuration functions make it easy to control
    additional request components (authenticate(), add_headers() and so
    on).",2022-05-04,Hadley Wickham,"https://httr.r-lib.org/, https://github.com/r-lib/httr",TRUE,https://github.com/r-lib/httr,24393112,951,2022-05-04T12:18:50Z,25649.96004206099
httr2,"Tools for creating and modifying HTTP requests, then
    performing them and processing the results. 'httr2' is a modern
    re-imagining of 'httr' that uses a pipe-based interface and solves
    more of the problems that API wrapping packages face.",2022-05-10,Hadley Wickham,"https://httr2.r-lib.org, https://github.com/r-lib/httr2",TRUE,https://github.com/r-lib/httr2,19600,141,2022-06-23T22:41:56Z,139.00709219858157
huito,"An open-source R package to deploys flexible and reproducible labels using layers. 
  The 'huito' package is part of the 'inkaverse' project for developing different procedures and
  tools used in plant science and experimental designs. 
  Learn more about the 'inkaverse' project at <https://inkaverse.com/>.",2022-06-24,Flavio Lozano-Isla,"https://huito.inkaverse.com/, https://github.com/flavjack/huito",TRUE,https://github.com/flavjack/huito,2612,1,2022-07-08T09:09:05Z,2612
HuraultMisc,"Contains various functions for data analysis, notably helpers and diagnostics for Bayesian modelling using Stan.",2021-09-06,Guillem Hurault,https://github.com/ghurault/HuraultMisc,TRUE,https://github.com/ghurault/huraultmisc,2951,0,2021-11-24T09:50:22Z,NA
HurreconR,"The HURRECON model estimates wind speed, wind direction, enhanced 
    Fujita scale wind damage, and duration of EF0 to EF5 winds as a function 
    of hurricane location and maximum sustained wind speed. Results may be 
    generated for a single site or an entire region. Hurricane track and 
    intensity data may be imported directly from the US National Hurricane 
    Center's HURDAT2 database. For details on the original version of the 
    model written in Borland Pascal, see: Boose, Chamberlin, and Foster (2001) 
    <doi:10.1890/0012-9615(2001)071[0027:LARIOH]2.0.CO;2> and Boose, Serrano, 
    and Foster (2004) <doi:10.1890/02-4057>.",2022-07-08,Emery Boose,https://github.com/hurrecon-model/HurreconR,TRUE,https://github.com/hurrecon-model/hurreconr,6,2,2022-07-06T21:52:18Z,3
hutils,"Provides utility functions for, and drawing on, the 'data.table' package. The package also collates useful miscellaneous functions extending base R not available elsewhere. The name is a portmanteau of 'utils' and the author.",2022-04-13,Hugh Parsonage,"https://github.com/hughparsonage/hutils,
https://hughparsonage.github.io/hutils/",TRUE,https://github.com/hughparsonage/hutils,63658,8,2022-04-13T14:44:27Z,7957.25
hutilscpp,"Provides utility functions that are simply, frequently used, 
    but may require higher performance that what can be obtained from base R.
    Incidentally provides support for 'reverse geocoding', such as matching a point
    with its nearest neighbour in another array. Used as a complement to package
    'hutils' by sacrificing compilation or installation time for higher running 
    speeds. The name is a portmanteau of the author and 'Rcpp'.",2022-04-17,Hugh Parsonage,https://github.com/hughparsonage/hutilscpp,TRUE,https://github.com/hughparsonage/hutilscpp,18930,6,2022-05-15T23:57:27Z,3155
huxtable,"Creates styled tables for data presentation. Export to HTML, LaTeX,
  RTF, 'Word', 'Excel', and 'PowerPoint'. Simple, modern interface to manipulate 
  borders, size, position, captions, colours, text styles and number formatting.
  Table cells can span multiple rows and/or columns.
  Includes  a 'huxreg' function for creation of regression tables, and 'quick_*' 
  one-liners to print data to a new document.",2022-06-15,David Hugh-Jones,https://hughjonesd.github.io/huxtable/,TRUE,https://github.com/hughjonesd/huxtable,225025,288,2022-06-17T21:47:13Z,781.3368055555555
hwep,"Inference concerning equilibrium and random mating in 
    autopolyploids. Methods are available to test for equilibrium 
    and random mating at any even ploidy level (>2) in the presence
    of double reduction at biallelic loci. For autopolyploid populations
    in equilibrium, methods are available to estimate the degree of 
    double reduction. We also provide functions to calculate genotype 
    frequencies at equilibrium, or after one or several rounds of 
    random mating, given rates of double reduction. The main function is
    hwefit(). This material is based upon work supported by the
    National Science Foundation under Grant No. 2132247. The opinions,
    findings, and conclusions or recommendations expressed are those of
    the author and do not necessarily reflect the views of the National
    Science Foundation. For details of these methods, see 
    Gerard (2021) <doi:10.1101/2021.09.24.461731>.",2022-05-02,David Gerard,https://dcgerard.github.io/hwep/,TRUE,https://github.com/dcgerard/hwep,3262,2,2022-05-02T13:24:00Z,1631
hwsdr,"Programmatic interface to the Harmonized World Soil Database 
    'HWSD' web services (<https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1247>).
    Allows for easy downloads of 'HWSD' soil data directly to your R workspace 
    or your computer. Routines for both single pixel data downloads and
    gridded data are provided.",2021-06-30,Koen Hufkens,https://github.com/bluegreen-labs/hwsdr,TRUE,https://github.com/bluegreen-labs/hwsdr,4276,7,2022-05-07T19:24:37Z,610.8571428571429
hydraulics,"Functions for basic hydraulic calculations related to 
    water flow in circular pipes both flowing full (under pressure), and 
    partially full (gravity flow), and trapezoidal open channels. For 
    pressure flow this includes friction loss calculations by solving 
    the Darcy-Weisbach equation for head loss, flow or diameter, 
    plotting a Moody diagram, matching a pump characteristic curve to a system 
    curve, and solving for flows in a pipe network using the Hardy-Cross method. 
    The Darcy-Weisbach friction factor is calculated using the Colebrook 
    (or Colebrook-White equation), the basis of the Moody diagram, the original 
    citation being Colebrook (1939) <doi:10.1680/ijoti.1939.13150>. For gravity 
    flow, the Manning equation is used, again solving for missing parameters. 
    The derivation of and solutions using the Darcy-Weisbach equation and the
    Manning equation are outlined in many fluid mechanics texts such as 
    Finnemore and Franzini (2002, ISBN:978-0072432022). For the Manning equation
    solutions, this package uses modifications of original code from the 'iemisc' 
    package by Irucka Embry.",2022-03-07,Ed Maurer,"https://github.com/EdM44/hydraulics,
https://edm44.github.io/hydraulics/",TRUE,https://github.com/edm44/hydraulics,11487,5,2022-03-07T00:42:29Z,2297.4
hydroGOF,"S3 functions implementing both statistical and graphical goodness-of-fit measures between observed and simulated values, mainly oriented to be used during the calibration, validation, and application of hydrological models. Missing values in observed and/or simulated values can be removed before computations. Comments / questions / collaboration of any kind are very welcomed.",2020-03-12,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/hydroGOF,TRUE,https://github.com/hzambran/hydrogof,83068,26,2022-07-08T15:46:16Z,3194.923076923077
hydroPSO,"State-of-the-art version of the Particle Swarm Optimisation (PSO) algorithm (SPSO-2011 and SPSO-2007 capable). hydroPSO can be used as a replacement of the 'optim' R function for (global) optimization of non-smooth and non-linear functions. However, the main focus of hydroPSO is the calibration of environmental and other real-world models that need to be executed from the system console. hydroPSO is model-independent, allowing the user to easily interface any computer simulation model with the calibration engine (PSO). hydroPSO  communicates with the model through the model's own input and output files, without requiring access to the model's source code. Several PSO variants and controlling options are included to fine-tune the performance of the calibration engine to different calibration problems. An advanced sensitivity analysis function together with user-friendly plotting summaries facilitate the interpretation and assessment of the calibration results. hydroPSO is parallel-capable, to alleviate the computational burden of complex models with ""long"" execution time. Bugs reports/comments/questions are very welcomed (in English, Spanish or Italian). See Zambrano-Bigiarini and Rojas (2013) <doi:10.1016/j.envsoft.2013.01.004> for more details.",2020-04-29,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/hydroPSO,TRUE,https://github.com/hzambran/hydropso,23561,28,2022-02-04T21:59:58Z,841.4642857142857
hydrorecipes,"Additional steps to be used with the 'recipes' package. New steps
  were designed for regression deconvolution on datasets with millions of rows 
  with applications to signal decomposition and response 
  characterization. The methods in this package were developed as part of 
  PhD thesis titled High Frequency Water Level Responses to Natural 
  Signals <http://hdl.handle.net/10214/17890> by Jonathan Kennel in 2020.",2022-06-27,Jonathan Kennel,https://github.com/jkennel/hydrorecipes,TRUE,https://github.com/jkennel/hydrorecipes,155,3,2022-06-30T10:16:37Z,51.666666666666664
hydrostats,Calculates a suite of hydrologic indices for daily time series data that are widely used in hydrology and stream ecology.,2022-06-01,Nick Bond,https://github.com/nickbond/hydrostats,TRUE,https://github.com/nickbond/hydrostats,20905,20,2022-05-31T06:50:18Z,1045.25
hydroTSM,"S3 functions for management, analysis, interpolation and plotting of time series used in hydrology and related environmental sciences. In particular, this package is highly oriented to hydrological modelling tasks. The focus of this package has been put in providing a collection of tools useful for the daily work of hydrologists (although an effort was made to optimise each function as much as possible, functionality has had priority over speed). Bugs / comments / questions / collaboration of any kind are very welcomed, and in particular, datasets that can be included in this package for academic purposes.",2020-03-11,Mauricio Zambrano-Bigiarini,https://github.com/hzambran/hydroTSM,TRUE,https://github.com/hzambran/hydrotsm,101472,31,2022-07-08T13:22:06Z,3273.2903225806454
hyper2,A suite of routines for the hyperdirichlet distribution; supersedes the 'hyperdirichlet' package.,2022-03-23,Robin K. S. Hankin,https://github.com/RobinHankin/hyper2,TRUE,https://github.com/robinhankin/hyper2,18636,3,2022-07-09T10:32:15Z,6212
hyperbrick,"Read and execute preprocessing procedures on hyper-spectral images. 
    These type of sensor data are usually recorded in a raw format. This package
    contains some easy-to-use functions to promptly build the image with
    some basic radiometric calibrations, setting up the geographic information. 
    Geometric correction can be done with band-to-band registration (translation 
    and rotation). Further functionalities allow to compute sliding windows
    statistics over the image.",2022-04-01,Anderson Rodrigo da Silva,https://github.com/arsilva87/hyperbrick,TRUE,https://github.com/arsilva87/hyperbrick,849,0,2022-03-30T16:48:56Z,NA
HypergeoMat,"Evaluates the hypergeometric functions of a matrix argument, which appear in random matrix theory. This is an implementation of Koev & Edelman's algorithm (2006) <doi:10.1090/S0025-5718-06-01824-2>. ",2022-02-03,Stéphane Laurent,https://github.com/stla/HypergeoMat,TRUE,https://github.com/stla/hypergeomat,15578,1,2022-02-02T14:15:06Z,15578
hyperSpec,"Comfortable ways to work with hyperspectral data sets.
    I.e. spatially or time-resolved spectra, or spectra with any other kind
    of information associated with each of the spectra. The spectra can be data
    as obtained in XRF, UV/VIS, Fluorescence, AES, NIR, IR, Raman, NMR, MS,
    etc. More generally, any data that is recorded over a discretized variable,
    e.g. absorbance = f(wavelength), stored as a vector of absorbance values
    for discrete wavelengths is suitable.",2021-09-13,Claudia Beleites,"https://r-hyperspec.github.io/hyperSpec/ (documentation),
https://github.com/r-hyperspec/hyperSpec (code)",TRUE,https://github.com/r-hyperspec/hyperspec,40854,3,2022-04-06T10:44:56Z,13618
hypr,"Translation between experimental null hypotheses, hypothesis matrices, and contrast matrices as used in linear regression models. The package is based on the method described in Schad, Vasishth, Hohenstein, and Kliegl (2019) <doi:10.1016/j.jml.2019.104038> and Rabe, Vasishth, Hohenstein, Kliegl, and Schad (2020) <doi:10.21105/joss.02134>.",2021-07-19,Maximilian M. Rabe,https://maxrabe.com/hypr,TRUE,https://github.com/mmrabe/hypr,18426,11,2022-02-02T15:28:30Z,1675.090909090909
hystReet,An R API wrapper for the 'Hystreet' project <https://hystreet.com>. 'Hystreet' provides pedestrian counts in different cities in Germany.,2020-06-14,Johannes Friedrich,https://github.com/JohannesFriedrich/hystReet,TRUE,https://github.com/johannesfriedrich/hystreet,11629,12,2022-03-26T17:59:44Z,969.0833333333334
i18n,"Up-to-date data from the 'Unicode CLDR Project' (where 'CLDR'
    stands for 'Common Locale Data Repository') are available here as a series
    of easy-to-parse datasets. Several functions are provided for extracting
    key elements from the tabular datasets.",2022-03-29,Richard Iannone,https://github.com/rich-iannone/i18n,TRUE,https://github.com/rich-iannone/i18n,864,3,2022-05-16T20:07:47Z,288
i2extras,"Provides functions to work with 'incidence2' objects, including a
  simplified interface for trend fitting and peak estimation. This package is
  part of the RECON (<https://www.repidemicsconsortium.org/>) toolkit for 
  outbreak analysis (<https://www.reconverse.org/).",2021-07-08,Tim Taylor,https://www.reconverse.org/i2extras/,TRUE,https://github.com/reconverse/i2extras,14711,2,2021-10-14T13:32:52Z,7355.5
ib,"An implementation of the iterative bootstrap procedure of 
    Kuk (1995) <doi:10.1111/j.2517-6161.1995.tb02035.x> to correct the estimation bias of a fitted model object. This
    procedure has better bias correction properties than the 
    bootstrap bias correction technique.",2022-04-04,Samuel Orso,https://github.com/SMAC-Group/ib/,TRUE,https://github.com/smac-group/ib,4858,1,2022-04-04T13:47:57Z,4858
ibawds,"A collection of useful functions and datasets for the Data Science
  Course at IBAW in Lucerne.",2022-06-17,Stefan Lanz,https://stibu81.github.io/ibawds/,TRUE,https://github.com/stibu81/ibawds,6206,2,2022-07-04T16:10:40Z,3103
ibdsim2,"Simulation of segments shared identical-by-descent (IBD) by
    pedigree members. Using sex specific recombination rates along the
    human genome (Halldorsson et al. (2019)
    <doi:10.1126/science.aau1043>), phased chromosomes are simulated for
    all pedigree members. Applications include calculation of realised
    relatedness coefficients and IBD segment distributions. 'ibdsim2' is
    part of the 'ped suite' collection of packages for pedigree analysis.
    A detailed presentation of the 'ped suite', including a separate
    chapter on 'ibdsim2', is available in the book 'Pedigree analysis in
    R' (Vigeland, 2021, ISBN:9780128244302). A 'shiny' app for visualising
    and comparing IBD distributions is available at
    <https://magnusdv.shinyapps.io/ibdsim2-shiny/>.",2022-06-07,Magnus Dehli Vigeland,"https://github.com/magnusdv/ibdsim2,
https://magnusdv.github.io/pedsuite/,
https://magnusdv.shinyapps.io/ibdsim2-shiny/",TRUE,https://github.com/magnusdv/ibdsim2,9888,4,2022-06-07T15:13:09Z,2472
iBreakDown,"Model agnostic tool for decomposition of predictions from black boxes.
    Supports additive attributions and attributions with interactions.
    The Break Down Table shows contributions of every variable to a final prediction. 
    The Break Down Plot presents variable contributions in a concise graphical way. 
    This package works for classification and regression models. 
    It is an extension of the 'breakDown' package (Staniak and Biecek 2018) <doi:10.32614/RJ-2018-072>,
    with new and faster strategies for orderings. 
    It supports interactions in explanations and has interactive visuals (implemented with 'D3.js' library). 
    The methodology behind is described in the 'iBreakDown' article (Gosiewska and Biecek 2019) <arXiv:1903.11420>
    This package is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.",2021-05-07,Przemyslaw Biecek,"https://ModelOriented.github.io/iBreakDown/,
https://github.com/ModelOriented/iBreakDown",TRUE,https://github.com/modeloriented/ibreakdown,102196,73,2022-02-06T00:02:56Z,1399.945205479452
iCAMP,"To implement a general framework to quantitatively infer Community Assembly Mechanisms by Phylogenetic-bin-based null model analysis, abbreviated as 'iCAMP' (Ning et al 2020) <doi:10.1038/s41467-020-18560-z>. It can quantitatively assess the relative importance of different community assembly processes, such as selection, dispersal, and drift, for both communities and each phylogenetic group ('bin'). Each bin usually consists of different taxa from a family or an order. The package also provides functions to implement some other published methods, including neutral taxa percentage (Burns et al 2016) <doi:10.1038/ismej.2015.142> based on neutral theory model and quantifying assembly processes based on entire-community null models ('QPEN', Stegen et al 2013) <doi:10.1038/ismej.2013.93>. It also includes some handy functions, particularly for big datasets, such as phylogenetic and taxonomic null model analysis at both community and bin levels, between-taxa niche difference and phylogenetic distance calculation, phylogenetic signal test within phylogenetic groups, midpoint root of big trees, etc. Version 1.3.x mainly improved the function for 'QPEN' and added function 'icamp.cate()' to summarize 'iCAMP' results for different categories of taxa (e.g. core versus rare taxa).",2022-06-01,Daliang Ning,https://github.com/DaliangNing/iCAMP1,TRUE,https://github.com/daliangning/icamp1,11137,28,2022-07-05T16:01:59Z,397.75
ICAMS,"Analysis and visualization of experimentally elucidated mutational
    signatures -- the kind of analysis and visualization in Boot et al.,
    ""In-depth characterization of the cisplatin mutational signature in 
    human cell lines and in esophageal and liver tumors"", Genome Research 2018, 
    <doi:10.1101/gr.230219.117> and
    ""Characterization of colibactin-associated mutational signature in an 
    Asian oral squamous cell carcinoma and in other mucosal tumor types"",
    Genome Research 2020 <doi:10.1101/gr.255620.119>.
    'ICAMS' stands for In-depth Characterization 
    and Analysis of Mutational Signatures. 'ICAMS' has functions to read in 
    variant call files (VCFs) and to collate the corresponding catalogs of 
    mutational spectra and to analyze and plot catalogs of mutational spectra
    and signatures. Handles both ""counts-based"" and ""density-based"" catalogs
    of mutational spectra or signatures.",2021-04-03,Steve Rozen,https://github.com/steverozen/ICAMS,TRUE,https://github.com/steverozen/icams,13556,8,2022-01-13T09:08:53Z,1694.5
ICC,"Assist in the estimation of the Intraclass Correlation Coefficient
    (ICC) from variance components of a one-way analysis of variance and also
    estimate the number of individuals or groups necessary to obtain an ICC
    estimate with a desired confidence interval width.",2022-05-20,Matthew Wolak,https://github.com/matthewwolak/ICC,TRUE,https://github.com/matthewwolak/icc,46594,5,2022-05-20T13:06:21Z,9318.8
ICD10gm,"Provides convenient access to the German modification of the International Classification of Diagnoses, 10th revision (ICD-10-GM). It provides functionality to aid in the identification, specification and historisation of ICD-10 codes. Its intended use is the analysis of routinely collected data in the context of epidemiology, medical research and health services research. The underlying metadata are released by the German Institute for Medical Documentation and Information <https://www.dimdi.de>, and are redistributed in accordance with their license.",2021-12-05,Ewan Donnachie,"https://edonnachie.github.io/ICD10gm/,
https://doi.org/10.5281/zenodo.2542833",TRUE,https://github.com/edonnachie/icd10gm,16073,7,2021-12-04T15:03:10Z,2296.1428571428573
icecream,"Provides user-friendly and configurable print debugging via a
    single function, ic(). Wrap an expression in ic() to print the
    expression, its value and (where available) its source location.
    Debugging output can be toggled globally without modifying code.",2021-10-03,Lewin Appleton-Fox,"https://www.lewinfox.com/icecream/,
https://github.com/lewinfox/icecream",TRUE,https://github.com/lewinfox/icecream,4832,13,2021-10-03T10:12:42Z,371.6923076923077
iCellR,"A toolkit that allows scientists to work with data from single cell sequencing technologies such as scRNA-seq, scVDJ-seq, scATAC-seq, CITE-Seq and Spatial Transcriptomics (ST). Single (i) Cell R package ('iCellR') provides unprecedented flexibility at every step of the analysis pipeline, including normalization, clustering, dimensionality reduction, imputation, visualization, and so on. Users can design both unsupervised and supervised models to best suit their research. In addition, the toolkit provides 2D and 3D interactive visualizations, differential expression analysis, filters based on cells, genes and clusters, data merging, normalizing for dropouts, data imputation methods, correcting for batch differences, pathway analysis, tools to find marker genes for clusters and conditions, predict cell types and pseudotime analysis. See Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.05.05.078550>  and Khodadadi-Jamayran, et al (2020) <doi:10.1101/2020.03.31.019109> for more details.",2021-10-09,Alireza Khodadadi-Jamayran,https://github.com/rezakj/iCellR,TRUE,https://github.com/rezakj/icellr,25662,102,2022-06-20T15:30:04Z,251.58823529411765
icesAdvice,"A collection of functions that facilitate computational steps
  related to advice for fisheries management, according to ICES guidelines.
  These include methods for calculating reference points and model diagnostics.",2022-02-18,Colin Millar,"https://ices.dk/advice,
https://github.com/ices-tools-prod/icesAdvice",TRUE,https://github.com/ices-tools-prod/icesadvice,22488,7,2022-02-17T19:00:17Z,3212.5714285714284
IceSat2R,"Programmatic connection to the 'OpenAltimetry API' <https://openaltimetry.org/data/swagger-ui/> to download and process 'ATL03' (Global Geolocated Photon Data), 'ATL06' (Land Ice Height), 'ATL07' (Sea Ice Height), 'ATL08' (Land and Vegetation Height), 'ATL10' (Sea Ice Freeboard), 'ATL12' (Ocean Surface Height) and 'ATL13' (Inland Water Surface Height) 'ICESat-2' Altimeter Data. The user has the option to download the data by selecting a bounding box from a 1- or 5-degree grid globally utilizing a shiny application. The 'ICESat-2' mission collects altimetry data of the Earth's surface. The sole instrument on 'ICESat-2' is the Advanced Topographic Laser Altimeter System (ATLAS) instrument that measures ice sheet elevation change and sea ice thickness, while also generating an estimate of global vegetation biomass. 'ICESat-2' continues the important observations of ice-sheet elevation change, sea-ice freeboard, and vegetation canopy height begun by 'ICESat' in 2003.",2022-07-04,Lampros Mouselimis,https://github.com/mlampros/IceSat2R,TRUE,https://github.com/mlampros/icesat2r,1724,2,2022-07-08T14:29:03Z,862
icesDatras,"R interface to access the web services of the ICES (International
             Council for the Exploration of the Sea) DATRAS trawl survey
             database <https://datras.ices.dk/WebServices/Webservices.aspx>.",2022-02-10,Colin Millar,"https://datras.ices.dk/WebServices/Webservices.aspx,
https://github.com/ices-tools-prod/icesDatras",TRUE,https://github.com/ices-tools-prod/icesdatras,17826,10,2022-05-26T13:32:47Z,1782.6
icesDatsu,"Functions to Interact with the ICES Data Submission Utility (DATSU)
  <https://datsu.ices.dk/web/index.aspx>.",2022-02-17,Colin Millar,"https://datsu.ices.dk/web/index.aspx,
https://github.com/ices-tools-prod/icesDatsu",TRUE,https://github.com/ices-tools-prod/icesdatsu,1334,1,2022-02-17T13:46:57Z,1334
icesDatsuQC,"Run quality checks on data sets using the same checks that are conducted
  on the ICES Data Submission Utility (DATSU) <https://datsu.ices.dk/web/index.aspx>.",2022-02-18,Colin Millar,"https://datsu.ices.dk/web/index.aspx,
https://github.com/ices-tools-prod/icesDatsuQC",TRUE,https://github.com/ices-tools-prod/icesdatsuqc,1139,1,2022-04-18T22:43:49Z,1139
icesSAG,"R interface to access the web services of the ICES Stock Assessment
             Graphs database <https://sg.ices.dk>.",2022-02-17,Colin Millar,"https://sg.ices.dk, https://github.com/ices-tools-prod/icesSAG",TRUE,https://github.com/ices-tools-prod/icessag,8787,7,2022-02-17T15:49:19Z,1255.2857142857142
icesSD,R interface to access the web services of the ICES Stock Database <https://sd.ices.dk>.,2022-02-18,Colin Millar,"https://sd.ices.dk, https://github.com/ices-tools-prod/icesDatsuQC",TRUE,https://github.com/ices-tools-prod/icesdatsuqc,1157,1,2022-04-18T22:43:49Z,1157
icesVocab,"R interface to access the RECO POX web services of the ICES
  (International Council for the Exploration of the Sea) Vocabularies database
  <https://vocab.ices.dk/services/POX.aspx>.",2022-02-10,Colin Millar,https://vocab.ices.dk/services/POX.aspx,TRUE,https://github.com/ices-tools-prod/icesvocab,18395,4,2022-02-10T20:14:35Z,4598.75
ichimoku,"An implementation of 'Ichimoku Kinko Hyo', also commonly known as
    'cloud charts'. Static and interactive visualizations with tools for
    creating, backtesting and development of quantitative 'ichimoku' strategies.
    As described in Sasaki (1996, ISBN:4925152009), the technique is a refinement
    on candlestick charting, originating from Japan and now in widespread use in
    technical analysis worldwide. Translating as 'one-glance equilibrium chart',
    it allows the price action and market structure of financial securities to
    be determined 'at-a-glance'. Incorporates an interface with the OANDA
    fxTrade API <https://developer.oanda.com/> for retrieving historical and
    live streaming price data for major currencies, metals, commodities,
    government bonds and stock indices.",2022-07-04,Charlie Gao,"https://shikokuchuo.net/ichimoku/,
https://github.com/shikokuchuo/ichimoku/",TRUE,https://github.com/shikokuchuo/ichimoku,13232,22,2022-07-05T11:45:26Z,601.4545454545455
iconr,"Set of formal methods for studying archaeological iconographic datasets (rock-art, pottery decoration, stelae, etc.) using network and spatial analysis (Alexander 2008 <doi:10.11588/propylaeumdok.00000512>; Huet 2018 <https://hal.archives-ouvertes.fr/hal-02913656>).",2021-02-16,Thomas Huet,https://zoometh.github.io/iconr/,TRUE,https://github.com/zoometh/iconr,5900,9,2022-05-25T16:21:18Z,655.5555555555555
icr,"Provides functions to compute and plot Krippendorff's inter-coder 
    reliability coefficient alpha and bootstrapped uncertainty estimates 
    (Krippendorff 2004, ISBN:0761915443). The bootstrap routines are set up to
    make use of parallel threads where supported.",2020-03-20,Alexander Staudt,https://github.com/staudtlex/icr,TRUE,https://github.com/staudtlex/icr,18784,0,2021-10-16T13:08:49Z,NA
ICvectorfields,"Functions for converting time series of spatial abundance or density 
    data in raster format to vector fields of population movement using the digital 
    image correlation technique. More specifically, the functions in the package 
    compute cross-covariance using discrete fast Fourier transforms for computational 
    efficiency. Vectors in vector fields point in the direction of highest two 
    dimensional cross-covariance. The package has a novel implementation of the 
    digital image correlation algorithm that is designed to detect persistent 
    directional movement when image time series extend beyond a sequence of 
    two raster images. ",2022-02-26,Devin Goodsman,NA,TRUE,https://github.com/goodsman/icvectorfields,5130,1,2022-02-26T22:07:43Z,5130
IDConverter,"Identifiers in biological databases connect different levels
    of metadata, phenotype data or genotype data. This tool is designed to
    easily convert identifiers within or between different biological
    databases (Wang, Shixiang, et al. (2021) <DOI:10.1371/journal.pgen.1009557>).",2022-06-03,Shixiang Wang,https://github.com/ShixiangWang/IDConverter,TRUE,https://github.com/shixiangwang/idconverter,1006,6,2022-06-08T05:51:06Z,167.66666666666666
IDE,"The Integro-Difference Equation model is a linear, dynamical model used to model
   phenomena that evolve in space and in time; see, for example, Cressie and Wikle (2011,
   ISBN:978-0-471-69274-4) or Dewar et al. (2009) <doi:10.1109/TSP.2008.2005091>. At the
   heart of the model is the kernel, which dictates how the process evolves from one time
   point to the next. Both process and parameter reduction are used to facilitate computation,
   and spatially-varying kernels are allowed. Data used to estimate the parameters are assumed
   to be readings of the process corrupted by Gaussian measurement error. Parameters are fitted
   by maximum likelihood, and estimation is carried out using an evolution algorithm. ",2022-05-30,Andrew Zammit-Mangion,NA,TRUE,https://github.com/andrewzm/ide,14373,0,2022-05-29T22:47:49Z,NA
IDEAFilter,"When added to an existing shiny app, users may subset any
    developer-chosen R data.frame on the fly. That is, users are empowered to
    slice & dice data by applying multiple (order specific) filters using the
    AND (&) operator between each, and getting real-time updates on the number
    of rows effected/available along the way. Thus, any downstream processes
    that leverage this data source (like tables, plots, or statistical procedures)
    will re-render after new filters are applied. The shiny module’s user interface has
    a 'minimalist' aesthetic so that the focus can be on the data &
    other visuals. In addition to returning a reactive (filtered) data.frame,
    'IDEAFilter' as also returns 'dplyr' filter statements used to actually slice
    the data.",2022-06-28,Aaron Clark,https://biogen-inc.github.io/IDEAFilter/,TRUE,https://github.com/biogen-inc/ideafilter,181,4,2022-07-05T13:45:04Z,45.25
idefix,"Generates efficient designs for discrete choice experiments based on the multinomial logit model, and individually adapted designs for the mixed multinomial logit model. The generated designs can be presented on screen and choice data can be gathered using a shiny application. Traets F, Sanchez G, and Vandebroek M (2020) <doi:10.18637/jss.v096.i03>.",2022-03-28,Frits Traets,https://github.com/traets/idefix,TRUE,https://github.com/traets/idefix,22902,11,2022-03-28T08:45:03Z,2082
idem,"In randomized studies involving severely ill patients, functional
    outcomes are often unobserved due to missed clinic visits, premature
    withdrawal or death. It is well known that if these unobserved functional
    outcomes are not handled properly, biased treatment comparisons can be
    produced. In this package, we implement a procedure for comparing treatments
    that is based on the composite endpoint of both the functional outcome and
    survival. The procedure was proposed in Wang et al. (2016) <DOI:10.1111/biom.12594>
    and Wang et al. (2020) <DOI:10.18637/jss.v093.i12>. It considers missing data
    imputation with different sensitivity
    analysis strategies to handle the unobserved functional outcomes not due to
    death.",2021-01-27,Chenguang Wang,https://github.com/olssol/idem/,TRUE,https://github.com/olssol/idem,17683,0,2021-10-19T23:53:55Z,NA
ids,Generate random or human readable and pronounceable identifiers.,2017-05-31,Rich FitzJohn,https://github.com/richfitz/ids,TRUE,https://github.com/richfitz/ids,7122822,85,2021-12-03T12:24:31Z,83797.90588235293
IDSL.IPA,"A sophisticated pipeline for processing LC/HRMS data to extract signals of organic compounds. The package performs isotope pairing, peak detection, alignment, RT correction, gap filling, peak annotation and visualization of extracted ion chromatograms and total ion chromatograms.",2022-07-07,Sadjad Fakouri-Baygi,"https://ipa.idsl.me, https://github.com/idslme/idsl.ipa",TRUE,https://github.com/idslme/idsl.ipa,5007,7,2022-07-07T19:32:35Z,715.2857142857143
IDSL.SUFA,A simplified version of the 'IDSL.UFA' package to calculate isotopic profiles and adduct formulas from molecular formulas with no dependency on other R packages for online tools.,2022-03-21,Sadjad Fakouri-Baygi,"https://ufa.idsl.me, https://github.com/idslme/idsl.ufa",TRUE,https://github.com/idslme/idsl.ufa,1206,4,2022-06-28T16:29:00Z,301.5
IDSL.UFA,A pipeline to annotate peaklists from the IDSL.IPA package with molecular formula using an isotopic profile matching approach. The IDSL.UFA pipeline is especially beneficial when MS/MS data are not available. The IDSL.UFA package has functions to process user-defined adduct formulas.,2022-06-13,Sadjad Fakouri-Baygi,"https://ufa.idsl.me, https://github.com/idslme/idsl.ufa",TRUE,https://github.com/idslme/idsl.ufa,2054,4,2022-06-28T16:29:00Z,513.5
IDSL.UFAx,"A pipeline to annotate a number of peaks from the IDSL.IPA peaklists using an exhaustive chemical enumeration-based approach. This package can perform elemental composition calculations using the following 15 elements : C, B, Br, Cl, K, S, Se, Si, N, H, As, F, I, Na, O, and P.",2022-06-29,Sadjad Fakouri-Baygi,"https://ufa.idsl.me, https://github.com/idslme/idsl.ufa",TRUE,https://github.com/idslme/idsl.ufa,1969,4,2022-06-28T16:29:00Z,492.25
IFAA,This package offers a robust approach to make inference on the association of covariates with the absolute abundance (AA) of microbiome in an ecosystem. It can be also directly applied to relative abundance (RA) data to make inference on AA because the ratio of two RA is equal ratio of their AA. This algorithm can estimate and test the associations of interest while adjusting for potential confounders. High-dimensional covariates are handled with regularization. The estimates of this method have easy interpretation like a typical regression analysis. High-dimensional covariates are handled with regularization and it is implemented by parallel computing. False discovery rate is automatically controlled by this approach. Zeros do not need to be imputed by a positive value for the analysis. The IFAA package also offers the 'MZILN' function for estimating and testing associations of abundance ratios with covariates.,2022-07-07,Zhigang Li,"https://pubmed.ncbi.nlm.nih.gov/35241863/,
https://pubmed.ncbi.nlm.nih.gov/30923584/,
https://github.com/gitlzg/IFAA",TRUE,https://github.com/gitlzg/ifaa,8170,3,2022-07-06T02:23:04Z,2723.3333333333335
IFC,"Contains several tools to treat imaging flow cytometry data from 'ImageStream®' and 'FlowSight®' cytometers ('Amnis®', part of 'Luminex®'). Provides an easy and simple way to read and write .fcs, .rif, .cif and .daf files. Information such as masks, features, regions and populations set within these files can be retrieved for each single cell. In addition, raw data such as images stored can also be accessed. Users, may hopefully increase their productivity thanks to dedicated functions to extract, visualize, manipulate and export 'IFC' data. Toy data example can be installed through the 'IFCdata' package of approximately 32 MB, which is available in a 'drat' repository <https://gitdemont.github.io/IFCdata/>. See file 'COPYRIGHTS' and file 'AUTHORS' for a list of copyright holders and authors.",2022-05-24,Yohann Demont,NA,TRUE,https://github.com/gitdemont/ifc,9487,2,2022-07-06T07:36:43Z,4743.5
ifCNVR,"Automatically detects Copy Number Variations (CNV) from Next Generation Sequencing data using a machine learning algorithm, Isolation forest. More details about the method can be found in the paper by Cabello-Aguilar (2022) <doi:10.1101/2022.01.03.474771>.",2022-02-15,Simon Cabello-Aguilar,https://github.com/SimCab-CHU/ifCNVR,TRUE,https://github.com/simcab-chu/ifcnvr,1138,2,2022-07-05T15:06:11Z,569
igoR,"Tools to extract information from the Intergovernmental
    Organizations ('IGO') Database , version 3, provided by the Correlates
    of War Project <https://correlatesofwar.org/>. See also Pevehouse, J.
    C. et al. (2020), <doi:10.1177/0022343319881175>.  Version 3 includes
    information from 1815 to 2014.",2021-10-20,Diego Hernangómez,"https://dieghernan.github.io/igoR/,
https://github.com/dieghernan/igoR",TRUE,https://github.com/dieghernan/igor,6470,5,2022-07-04T19:46:29Z,1294
igraph,"Routines for simple graphs and network analysis. It can
  handle large graphs very well and provides functions for generating random
  and regular graphs, graph visualization, centrality methods and much more.",2022-06-13,See AUTHORS file.,"https://igraph.org, https://igraph.discourse.group/",TRUE,https://github.com/igraph/rigraph,8687230,438,2022-07-08T21:41:37Z,19833.858447488583
iGraphMatch,"Versatile tools and data for graph matching analysis with various forms of prior information
    that supports working with 'igraph' objects, matrix objects, or lists of either.",2021-11-10,Daniel Sussman,"https://github.com/dpmcsuss/iGraphMatch/,
https://rdrr.io/github/dpmcsuss/iGraphMatch/",TRUE,https://github.com/dpmcsuss/igraphmatch,6524,6,2021-11-10T22:26:43Z,1087.3333333333333
igrf,"The 13th generation International Geomagnetic Reference Field (IGRF).
 A standard spherical harmonic representation of the Earth's main field.",2022-01-07,Koen Hufkens,https://github.com/bluegreen-labs/igrf,TRUE,https://github.com/bluegreen-labs/igrf,1516,3,2022-05-07T19:34:37Z,505.3333333333333
iheiddown,"A set of tools for writing documents
    according to Geneva Graduate Institute conventions and regulations.
    The most common use is for writing and compiling theses or thesis
    chapters, as drafts or for examination with correct preamble formatting. 
    However, the package also offers users to create HTML presentation
    slides with 'xaringan', complete problem sets, format posters, and, 
    for course instructors, prepare a syllabus.
    The package includes additional functions for institutional color palettes,
    an institutional 'ggplot' theme, a function for counting manuscript words,
    and a bibliographical analysis toolkit.",2022-05-13,James Hollway,https://github.com/jhollway/iheiddown,TRUE,https://github.com/jhollway/iheiddown,4726,10,2022-05-17T23:01:02Z,472.6
ILSE,"Linear regression when covariates include missing values by embedding the 
    correlation information between covariates. Especially for block missing data,
    it works well. 'ILSE' conducts imputation and regression simultaneously and iteratively. 
    More details can be referred to 
    Huazhen Lin, Wei Liu and Wei Lan. (2021) <doi:10.1080/07350015.2019.1635486>.",2022-01-31,Wei Liu,https://github.com/feiyoung/ILSE,TRUE,https://github.com/feiyoung/ilse,1749,1,2022-02-05T11:52:19Z,1749
imabc,"Provides functionality to perform a likelihood-free method for estimating the parameters of complex models
    that results in a simulated sample from the posterior distribution of model parameters given targets. The method begins
    with a accept/reject approximate bayes computation (ABC) step applied to a sample of points from the prior distribution
    of model parameters. Accepted points result in model predictions that are within the initially specified tolerance
    intervals around the target points. The sample is iteratively updated by drawing additional points from a mixture of
    multivariate normal distributions, accepting points within tolerance intervals. As the algorithm proceeds, the
    acceptance intervals are narrowed. The algorithm returns a set of points and sampling weights that account for the
    adaptive sampling scheme. For more details see Rutter, Ozik, DeYoreo, and Collier (2018) <arXiv:1804.02090>.",2021-04-12,Christopher,https://github.com/carolyner/imabc,TRUE,https://github.com/carolyner/imabc,3731,3,2022-04-06T00:05:45Z,1243.6666666666667
image.CannyEdges,An implementation of the Canny Edge Detector for detecting edges in images. The package provides an interface to the algorithm available at <https://github.com/Neseb/canny>.,2020-08-01,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,8089,235,2021-11-17T12:19:57Z,34.42127659574468
image.ContourDetector,"An implementation of the Unsupervised Smooth Contour Detection algorithm for digital images as described in the paper: ""Unsupervised Smooth Contour Detection"" by Rafael Grompone von Gioi, and Gregory Randall (2016). 
    The algorithm is explained at <doi:10.5201/ipol.2016.175>.",2021-11-17,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,9125,235,2021-11-17T12:19:57Z,38.829787234042556
image.CornerDetectionF9,"An implementation of the ""FAST-9"" corner detection algorithm explained in the paper 'FASTER and better: A machine learning approach to corner detection' by Rosten E., Porter R. and Drummond T. (2008), available at <arXiv:0810.2434>.
    The package allows to detect corners in digital images.",2020-07-27,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,7734,235,2021-11-17T12:19:57Z,32.91063829787234
image.CornerDetectionHarris,"An implementation of the Harris Corner Detection as described in the paper ""An Analysis and Implementation of the Harris Corner Detector"" by Sánchez J. et al (2018) available at <doi:10.5201/ipol.2018.229>. 
    The package allows to detect relevant points in images which are characteristic to the digital image.",2020-08-03,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,8366,235,2021-11-17T12:19:57Z,35.6
image.dlib,"Facility wrappers around the image processing functionality of
    'dlib'. 'Dlib' <http://dlib.net> is a 'C++' toolkit containing machine learning
    algorithms and computer vision tools. Currently the package allows to find feature
    descriptors of digital images, in particular 'SURF' and 'HOG' descriptors.",2020-07-27,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,7857,235,2021-11-17T12:19:57Z,33.43404255319149
image.libfacedetection,"An open source library for face detection in images. 
    Provides a pretrained convolutional neural network based on <https://github.com/ShiqiYu/libfacedetection> which can be used to detect faces which have size greater than 10x10 pixels.",2020-07-27,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,8466,235,2021-11-17T12:19:57Z,36.02553191489362
image.LineSegmentDetector,"An implementation of the Line Segment Detector on digital images described in the paper: ""LSD: A Fast Line Segment Detector with a False Detection Control"" by Rafael Grompone von Gioi et al (2012). 
    The algorithm is explained at <doi:10.5201/ipol.2012.gjmr-lsd>.",2020-07-27,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,8029,235,2021-11-17T12:19:57Z,34.16595744680851
image.Otsu,"An implementation of the Otsu's Image Segmentation Method described in the paper: ""A C++ Implementation of Otsu's Image Segmentation Method"". The algorithm is explained at <doi:10.5201/ipol.2016.158>.",2020-07-27,Jan Wijffels,https://github.com/bnosac/image,TRUE,https://github.com/bnosac/image,7730,235,2021-11-17T12:19:57Z,32.8936170212766
image.textlinedetector,"Find text lines in scanned images and segment the lines into words.
    Includes implementations of the paper 'Novel A* Path Planning Algorithm for Line Segmentation of Handwritten Documents' by Surinta O. et al (2014) <doi:10.1109/ICFHR.2014.37> available at <https://github.com/smeucci/LineSegm>,
    an implementation of 'A Statistical approach to line segmentation in handwritten documents' by Arivazhagan M. et al (2007) <doi:10.1117/12.704538>, 
    and a wrapper for an image segmentation technique to detect words in text lines as described in the paper 'Scale Space Technique for Word Segmentation in Handwritten Documents' by Manmatha R. and Srimal N. (1999) paper at <doi:10.1007/3-540-48236-9_3>, wrapper for code available at <https://github.com/arthurflor23/text-segmentation>.",2021-09-03,Jan Wijffels,https://github.com/DIGI-VUB/image.textlinedetector,TRUE,https://github.com/digi-vub/image.textlinedetector,10248,6,2021-11-25T08:40:22Z,1708
imagefluency,"Get image statistics based on processing fluency theory. The
    functions provide scores for several basic aesthetic principles that
    facilitate fluent cognitive processing of images: contrast,
    complexity / simplicity, self-similarity, symmetry, and typicality.
    See Mayer & Landwehr (2018) <doi:10.1037/aca0000187> and Mayer & Landwehr
    (2018) <doi:10.31219/osf.io/gtbhw> for the theoretical background of the methods.",2020-01-09,Stefan Mayer,https://stm.github.io/imagefluency,TRUE,https://github.com/stm/imagefluency,18271,2,2021-11-05T09:34:21Z,9135.5
imageseg,"A general-purpose workflow for image segmentation using TensorFlow models based on the U-Net architecture by Ronneberger et al. (2015) <arXiv:1505.04597> and the U-Net++ architecture by Zhou et al. (2018) <arXiv:1807.10165>. We provide pre-trained models for assessing canopy density and understory vegetation density from vegetation photos. In addition, the package provides a workflow for easily creating model input and model architectures for general-purpose image segmentation based on grayscale or color images, both for binary and multi-class image segmentation.",2022-05-29,Juergen Niedballa,NA,TRUE,https://github.com/ecodynizw/imageseg,2118,8,2022-05-25T10:47:04Z,264.75
imaginator,"Simulate general insurance policies, losses and loss emergence. The functions contemplate 
  deterministic and stochastic policy retention and growth scenarios. Retention and growth rates are percentages relative
  to the expiring portfolio. Claims are simulated for each policy. This is accomplished either be assuming a frequency
  distribution per development lag or by generating random wait times until claim emergence and settlement. Loss simulation 
  uses standard loss distributions for claim amounts.",2022-01-27,Brian Fannin,https://github.com/casact/imaginator,TRUE,https://github.com/casact/imaginator,1800,10,2022-01-14T18:06:15Z,180
IMD,"Index of Multiple Deprivation for UK nations at various 
    geographical levels. In England, deprivation data is for Lower Layer Super
    Output Areas, Middle Layer Super Output Areas, Wards, and Local Authorities
    based on data from <https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019>.
    In Wales, deprivation data is for Lower Layer Super Output Areas, Middle 
    Layer Super Output Areas, Wards, and Local Authorities based on data from
    <https://gov.wales/welsh-index-multiple-deprivation-full-index-update-ranks-2019>.
    In Scotland, deprivation data is for Data Zones, Intermediate Zones, and 
    Council Areas based on data from <https://simd.scot>. In Northern Ireland,
    deprivation data is for Super Output Areas and Local Government Districts
    based on data from <https://www.nisra.gov.uk/statistics/deprivation/northern-ireland-multiple-deprivation-measure-2017-nimdm2017>.
    The 'IMD' package also provides the composite UK index developed by
    <https://github.com/mysociety/composite_uk_imd>.",2021-08-10,Matthew Gwynfryn Thomas,https://github.com/matthewgthomas/IMD,TRUE,https://github.com/matthewgthomas/imd,5600,5,2021-08-19T10:59:34Z,1120
imgrec,Provides an interface for image recognition using the 'Google Vision API' <https://cloud.google.com/vision/> .  Converts API data for features such as object detection and optical character recognition to data frames. The package also includes functions for analyzing image annotations.,2021-12-09,Carsten Schwemmer,https://github.com/cschwem2er/imgrec,TRUE,https://github.com/cschwem2er/imgrec,13191,12,2021-12-09T11:16:44Z,1099.25
IMIFA,"Provides flexible Bayesian estimation of Infinite Mixtures of Infinite Factor Analysers and related models, for nonparametrically clustering high-dimensional data, introduced by Murphy et al. (2020) <doi:10.1214/19-BA1179>. The IMIFA model conducts Bayesian nonparametric model-based clustering with factor analytic covariance structures without recourse to model selection criteria to choose the number of clusters or cluster-specific latent factors, mostly via efficient Gibbs updates. Model-specific diagnostic tools are also provided, as well as many options for plotting results, conducting posterior inference on parameters of interest, posterior predictive checking, and quantifying uncertainty.",2021-12-19,Keefe Murphy,https://cran.r-project.org/package=IMIFA,TRUE,https://github.com/keefe-murphy/imifa,23394,5,2021-12-20T16:20:26Z,4678.8
iml,"Interpretability methods to analyze the behavior and
    predictions of any machine learning model.  Implemented methods are:
    Feature importance described by Fisher et al. (2018)
    <arXiv:1801.01489>, accumulated local effects plots described by Apley
    (2018) <arXiv:1612.08468>, partial dependence plots described by
    Friedman (2001) <www.jstor.org/stable/2699986>, individual conditional
    expectation ('ice') plots described by Goldstein et al.  (2013)
    <doi:10.1080/10618600.2014.907095>, local models (variant of 'lime')
    described by Ribeiro et. al (2016) <arXiv:1602.04938>, the Shapley
    Value described by Strumbelj et. al (2014)
    <doi:10.1007/s10115-013-0679-x>, feature interactions described by
    Friedman et. al <doi:10.1214/07-AOAS148> and tree surrogate models.",2022-05-12,Christoph Molnar,"https://christophm.github.io/iml/,
https://github.com/christophM/iml/",TRUE,https://github.com/christophm/iml,126513,458,2022-05-30T19:45:51Z,276.2292576419214
immcp,"Toolkit for Poly-pharmacology Research of Traditional Chinese Medicine. Based on the
    biological descriptors and drug-disease interaction networks, it can
    analyze the potential poly-pharmacological mechanisms of Traditional Chinese Medicine and be
    used for drug-repositioning in Traditional Chinese Medicine.",2022-05-12,Yuanlong Hu,https://github.com/YuanlongHu/immcp,TRUE,https://github.com/yuanlonghu/immcp,5726,3,2022-05-28T06:24:34Z,1908.6666666666667
immer,"
    Implements some item response models for multiple
    ratings, including the hierarchical rater model, 
    conditional maximum likelihood estimation of linear 
    logistic partial credit model and a wrapper function
    to the commercial FACETS program. See Robitzsch and
    Steinfeld (2018) for a description of the functionality
    of the package. 
    See Wang, Su and Qiu (2014; <doi:10.1111/jedm.12045>)
    for an overview of modeling alternatives.",2022-05-17,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/immer,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/immer,21270,3,2022-05-18T08:29:07Z,7090
immunarch,"A comprehensive framework for bioinformatics exploratory analysis of bulk and single-cell
    T-cell receptor and antibody repertoires. It provides seamless data loading, analysis and
    visualisation for AIRR (Adaptive Immune Receptor Repertoire) data, both bulk immunosequencing (RepSeq)
    and single-cell sequencing (scRNAseq). It implements most of the widely used AIRR analysis methods,
    such as: clonality analysis, estimation of repertoire similarities in distribution of clonotypes
    and gene segments, repertoire diversity analysis, annotation of clonotypes using external immune receptor
    databases and clonotype tracking in vaccination and cancer studies. A successor to our
    previously published 'tcR' immunoinformatics package (Nazarov 2015) <doi:10.1186/s12859-015-0613-1>.",2022-05-30,Vadim I. Nazarov,"https://immunarch.com/, https://github.com/immunomind/immunarch",TRUE,https://github.com/immunomind/immunarch,17835,194,2022-05-31T15:52:33Z,91.93298969072166
imola,"Allows easy creation of CSS layouts (grid and flexbox)
  directly from R without added CSS.",2022-04-19,Pedro Silva,https://github.com/pedrocoutinhosilva/imola,TRUE,https://github.com/pedrocoutinhosilva/imola,2528,48,2022-04-19T12:05:07Z,52.666666666666664
impactr,"Functions to read, process and analyse accelerometer
    data related to mechanical loading variables. This package is
    developed and tested for use with raw accelerometer data from
    triaxial 'ActiGraph' <https://actigraphcorp.com> accelerometers.",2022-01-16,Lucas Veras,https://lveras.com/impactr/,TRUE,https://github.com/verasls/impactr,4166,1,2022-01-25T22:31:44Z,4166
implyr,"'SQL' back-end to 'dplyr' for Apache Impala, the massively
    parallel processing query engine for Apache 'Hadoop'. Impala enables
    low-latency 'SQL' queries on data stored in the 'Hadoop' Distributed
    File System '(HDFS)', Apache 'HBase', Apache 'Kudu', Amazon Simple 
    Storage Service '(S3)', Microsoft Azure Data Lake Store '(ADLS)', 
    and Dell 'EMC' 'Isilon'. See <https://impala.apache.org> for more
    information about Impala.",2021-03-29,Ian Cook,https://github.com/ianmcook/implyr,TRUE,https://github.com/ianmcook/implyr,23631,74,2022-01-24T18:00:26Z,319.3378378378378
import,"Alternative mechanism for importing objects from packages
    and R modules. The syntax allows for importing multiple objects with a single
    command in an expressive way. The import package bridges some of the gap
    between using library (or require) and direct (single-object) imports.
    Furthermore the imported objects are not placed in the current environment.",2022-05-23,Magnus Thor Torfason,https://github.com/rticulate/import,TRUE,https://github.com/rticulate/import,151728,188,2022-06-05T21:07:06Z,807.063829787234
imputeFin,"Missing values often occur in financial data due to a variety 
    of reasons (errors in the collection process or in the processing stage, 
    lack of asset liquidity, lack of reporting of funds, etc.). However, 
    most data analysis methods expect complete data and cannot be employed 
    with missing values. One convenient way to deal with this issue without 
    having to redesign the data analysis method is to impute the missing 
    values. This package provides an efficient way to impute the missing 
    values based on modeling the time series with a random walk or an 
    autoregressive (AR) model, convenient to model log-prices and log-volumes 
    in financial data. In the current version, the imputation is 
    univariate-based (so no asset correlation is used). In addition,
    outliers can be detected and removed.
    The package is based on the paper:
    J. Liu, S. Kumar, and D. P. Palomar (2019). Parameter Estimation of 
    Heavy-Tailed AR Model With Missing Data Via Stochastic EM. IEEE Trans. on 
    Signal Processing, vol. 67, no. 8, pp. 2159-2172. <doi:10.1109/TSP.2019.2899816>.",2021-02-20,Daniel P. Palomar,"https://CRAN.R-project.org/package=imputeFin,
https://github.com/dppalomar/imputeFin,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2019.2899816,
https://doi.org/10.1109/TSP.2020.3033378",TRUE,https://github.com/dppalomar/imputefin,17411,17,2021-09-27T06:43:44Z,1024.1764705882354
imputeGeneric,"The general workflow of most imputation methods is quite
    similar. The aim of this package is to provide parts of this general
    workflow to make the implementation of imputation methods easier. The
    heart of an imputation method is normally the used model. These models
    can be defined using the 'parsnip' package or customized
    specifications. The rest of an imputation method are more technical
    specification e.g. which columns and rows should be used for
    imputation and in which order. These technical specifications can be
    set inside the imputation functions.",2022-03-03,Tobias Rockel,https://github.com/torockel/imputeGeneric,TRUE,https://github.com/torockel/imputegeneric,1044,1,2022-03-03T10:27:03Z,1044
imputeR,"Multivariate Expectation-Maximization (EM) based imputation framework that offers several different algorithms. These include regularisation methods like Lasso and Ridge regression, tree-based models and dimensionality reduction methods like PCA and PLS.",2020-01-20,Steffen Moritz,http://github.com/SteffenMoritz/imputeR,TRUE,https://github.com/steffenmoritz/imputer,46622,13,2021-07-21T14:08:33Z,3586.3076923076924
imputeTS,"Imputation (replacement) of missing values 
             in univariate time series. 
             Offers several imputation functions
             and missing data plots. 
             Available imputation algorithms include: 
            'Mean', 'LOCF', 'Interpolation', 
            'Moving Average', 'Seasonal Decomposition', 
            'Kalman Smoothing on Structural Time Series models',
            'Kalman Smoothing on ARIMA models'. Published in Moritz and Bartz-Beielstein (2017) 
            <doi: 10.32614/RJ-2017-009>.",2021-01-16,Steffen Moritz,"https://github.com/SteffenMoritz/imputeTS,
https://steffenmoritz.github.io/imputeTS/",TRUE,https://github.com/steffenmoritz/imputets,1175666,142,2022-01-02T04:27:58Z,8279.338028169013
incidence2,"Provides functions and classes to compute, handle and visualise 
  incidence from dated events for a defined time interval. Dates can be 
  provided in various standard formats. The class 'incidence2' is used to store
  computed incidence and can be easily manipulated, subsetted, and plotted.
  This package is part of the RECON (<https://www.repidemicsconsortium.org/>) 
  toolkit for outbreak analysis (<https://www.reconverse.org>).",2021-11-07,Tim Taylor,https://github.com/reconverse/incidence2,TRUE,https://github.com/reconverse/incidence2,20202,15,2021-11-07T21:23:29Z,1346.8
incidentally,"Functions to generate incidence matrices and bipartite graphs that have (1) a fixed fill rate, (2) given marginal sums, (3) marginal sums that follow given distributions, or (4) represent bill sponsorships in the US Congress <doi:10.31219/osf.io/ectms>. It can also generate an incidence matrix from an adjacency matrix, or bipartite graph from a unipartite graph, via a social process mirroring team, group, or organization formation <doi:10.48550/arXiv.2204.13670>.",2022-05-31,Zachary Neal,"https://www.zacharyneal.com/backbone,
https://github.com/zpneal/incidentally",TRUE,https://github.com/zpneal/incidentally,790,3,2022-06-03T11:43:37Z,263.3333333333333
IndexNumR,"Computes bilateral and multilateral index numbers. 
    It has support for many standard bilateral indexes as well as
    multilateral index number methods such as GEKS, GEKS-Tornqvist 
    (or CCDI), Geary-Khamis and the weighted time product dummy
    (for details on these methods see Diewert and Fox (2020) 
    <doi:10.1080/07350015.2020.1816176>). 
    It also supports updating of multilateral indexes using 
    several splicing methods.",2022-02-07,Graham White,https://github.com/grahamjwhite/IndexNumR,TRUE,https://github.com/grahamjwhite/indexnumr,24860,9,2022-02-12T11:04:47Z,2762.222222222222
indiedown,"Simplifies the generation of customized R Markdown PDF templates.
    A template may include an individual logo, typography, geometry or color
    scheme. The package provides a skeleton with detailed instructions for
    customizations. The skeleton can be modified by changing defaults in the
    'YAML' header, by adding additional 'LaTeX' commands or by applying dynamic
    adjustments in R. Individual corporate design elements, such as a title page, can be added as R functions that produce 'LaTeX' code.",2021-03-22,Christoph Sax,"https://cynkra.github.io/indiedown/,
https://github.com/cynkra/indiedown",TRUE,https://github.com/cynkra/indiedown,10806,24,2022-05-18T00:44:05Z,450.25
individual,"A framework which provides users a set of useful primitive elements for
  specifying individual based simulation models, with special attention models for
  infectious disease epidemiology. Users build models by specifying variables for
  each characteristic of individuals in the simulated population by using data
  structures exposed by the package. The package provides efficient methods for
  finding subsets of individuals based on these variables, or cohorts. Cohorts can
  then be targeted for variable updates or scheduled for events. Variable updates
  queued during a time step are executed at the end of a discrete time step, and
  the code places no restrictions on how individuals are allowed to interact.
  These data structures are designed to provide an intuitive way for users to turn
  their conceptual model of a system into executable code, which is fast and
  memory efficient.",2021-10-25,Giovanni Charles,"https://github.com/mrc-ide/individual,
https://mrc-ide.github.io/individual/",TRUE,https://github.com/mrc-ide/individual,4795,23,2022-01-05T16:35:34Z,208.47826086956522
industRial,"Companion package to the book ""industRial data science"", 
    J.Ramalho (2021) <https://j-ramalho.github.io/industRial/>. 
    Provides data sets and functions to complete the case studies and contains 
    the book original Rmd files and tutorials.",2021-06-11,Joao Ramalho,https://github.com/J-Ramalho/industRial,TRUE,https://github.com/j-ramalho/industrial,4319,0,2022-04-16T07:16:52Z,NA
infer,"The objective of this package is to perform
    inference using an expressive statistical grammar that coheres with
    the tidy design framework.",2022-06-10,Chester Ismay,"https://github.com/tidymodels/infer,
https://infer.tidymodels.org/, https://infer.tidymodels.org",TRUE,https://github.com/tidymodels/infer,835360,647,2022-06-12T20:09:47Z,1291.1282843894899
influential,"Contains functions for the classification and ranking of top candidate features, reconstruction of networks from
    adjacency matrices and data frames, analysis of the topology of the network 
    and calculation of centrality measures, and identification of the most
    influential nodes. Also, a function is provided for running SIRIR model, which 
    is the combination of leave-one-out cross validation technique and the conventional SIR model, on a network to unsupervisedly rank the true influence of vertices. Additionally, some functions have been provided for the assessment 
    of dependence and correlation of two network centrality measures as well as 
    the conditional probability of deviation from their corresponding means in opposite direction.
    Fred Viole and David Nawrocki (2013, ISBN:1490523995).
    Csardi G, Nepusz T (2006). ""The igraph software package for complex network research."" InterJournal, Complex Systems, 1695.
    Adopted algorithms and sources are referenced in function document.",2022-04-14,Abbas (Adrian) Salavaty,"https://github.com/asalavaty/influential,
https://asalavaty.github.io/influential/",TRUE,https://github.com/asalavaty/influential,18336,13,2022-04-14T12:51:22Z,1410.4615384615386
influxdbclient,"
  InfluxDB 2.x time-series database client. Supports both InfluxDB OSS (<https://portal.influxdata.com/downloads/>) and Cloud (<https://cloud2.influxdata.com/>) version.",2021-07-21,Ales Pour,https://github.com/influxdata/influxdb-client-r,TRUE,https://github.com/influxdata/influxdb-client-r,4405,7,2021-09-07T13:36:58Z,629.2857142857143
ingredients,"Collection of tools for assessment of feature importance and feature effects.
    Key functions are:
    feature_importance() for assessment of global level feature importance,
    ceteris_paribus() for calculation of the what-if plots,
    partial_dependence() for partial dependence plots,
    conditional_dependence() for conditional dependence plots,
    accumulated_dependence() for accumulated local effects plots,
    aggregate_profiles() and cluster_profiles() for aggregation of ceteris paribus profiles,
    generic print() and plot() for better usability of selected explainers,
    generic plotD3() for interactive, D3 based explanations, and
    generic describe() for explanations in natural language.
    The package 'ingredients' is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.",2021-04-10,Przemyslaw Biecek,"https://ModelOriented.github.io/ingredients/,
https://github.com/ModelOriented/ingredients",TRUE,https://github.com/modeloriented/ingredients,103948,35,2021-10-09T22:09:00Z,2969.942857142857
inlabru,"Facilitates spatial and general latent Gaussian modeling using
  integrated nested Laplace approximation via the INLA package (<https://www.r-inla.org>).
  Additionally, extends the GAM-like model class to more general nonlinear predictor
  expressions, and implements a log Gaussian Cox process likelihood for 
  modeling univariate and spatial point processes based on ecological survey data.
  Model components are specified with general inputs and mapping methods to the
  latent variables, and the predictors are specified via general R expressions,
  with separate expressions for each observation likelihood model in
  multi-likelihood models. A prediction method based on fast Monte Carlo sampling
  allows posterior prediction of general expressions of the latent variables.
  Ecology-focused introduction in Bachl, Lindgren, Borchers, and Illian (2019)
  <doi:10.1111/2041-210X.13168>.",2022-03-30,Finn Lindgren,"http://www.inlabru.org, https://inlabru-org.github.io/inlabru/",TRUE,https://github.com/inlabru-org/inlabru,22213,44,2022-07-01T09:22:15Z,504.84090909090907
inline,"Functionality to dynamically define R functions and S4 methods
 with 'inlined' C, C++ or Fortran code supporting the .C and .Call calling
 conventions.",2021-05-31,Oleg Sklyar,"https://github.com/eddelbuettel/inline,
https://dirk.eddelbuettel.com/code/inline.html",TRUE,https://github.com/eddelbuettel/inline,1900592,33,2021-11-09T03:20:35Z,57593.69696969697
inlinedocs,"Generates Rd files from R source code with comments.
 The main features of the default syntax are that
 (1) docs are defined in comments near the relevant code,
 (2) function argument names are not repeated in comments, and
 (3) examples are defined in R code, not comments.
 It is also easy to define a new syntax.",2019-12-05,Toby Dylan Hocking,http://github.com/tdhock/inlinedocs,TRUE,https://github.com/tdhock/inlinedocs,78613,2,2022-02-08T18:35:17Z,39306.5
inlmisc,"A collection of functions for creating high-level graphics,
    performing raster-based analysis, processing MODFLOW-based models,
    selecting subsets using a genetic algorithm, creating interactive web maps,
    accessing color palettes, etc. Used to support packages and scripts written
    by researchers at the United States Geological Survey (USGS)
    Idaho National Laboratory (INL) Project Office.",2022-01-24,Jason C. Fisher,https://github.com/USGS-R/inlmisc,TRUE,https://github.com/usgs-r/inlmisc,37842,19,2022-01-24T20:56:17Z,1991.6842105263158
innsight,"Interpretability methods to analyze the behavior and
    individual predictions of modern neural networks. Implemented methods
    are: 'Connection Weights' described by Olden et al. (2004)
    <doi:10.1016/j.ecolmodel.2004.03.013>, Layer-wise Relevance
    Propagation ('LRP') described by Bach et al. (2015)
    <doi:10.1371/journal.pone.0130140>, Deep Learning Important Features
    ('DeepLIFT') described by Shrikumar et al.  (2017) <arXiv:1704.02685>
    and gradient-based methods like 'SmoothGrad' described by Smilkov et
    al. (2017) <arXiv:1706.03825>, 'Gradient x Input' described by
    Baehrens et al. (2009) <arXiv:0912.1128> or 'Vanilla Gradient'.",2021-11-22,Niklas Koenen,"https://bips-hb.github.io/innsight/,
https://github.com/bips-hb/innsight/",TRUE,https://github.com/bips-hb/innsight,2112,21,2022-02-01T11:12:04Z,100.57142857142857
insane,"A user-friendly interface, using Shiny, to analyse glucose-stimulated insulin secretion (GSIS) 
    assays in pancreatic beta cells or islets.
    The package allows the user to import several sets of experiments from different spreadsheets 
    and to perform subsequent steps: summarise in a tidy format, visualise data quality 
    and compare experimental conditions without omitting to account for technical confounders 
    such as the date of the experiment or the technician.
    Together, insane is a comprehensive method that optimises pre-processing and analyses of 
    GSIS experiments in a friendly-user interface.
    The Shiny App was initially designed for EndoC-betaH1 cell line following method described 
    in Ndiaye et al., 2017 (<doi:10.1016/j.molmet.2017.03.011>).",2020-11-04,Mickaël Canouil,"https://github.com/mcanouil/insane,
https://mcanouil.github.io/insane/",TRUE,https://github.com/mcanouil/insane,6497,1,2022-03-28T18:35:28Z,6497
insect,Provides tools for probabilistic taxon assignment with informatic sequence classification trees. See Wilkinson et al (2018) <doi:10.7287/peerj.preprints.26812v1>.,2021-08-09,Shaun Wilkinson,https://github.com/shaunpwilkinson/insect/,TRUE,https://github.com/shaunpwilkinson/insect,20331,12,2021-08-06T07:54:33Z,1694.25
insee,"Using embedded sdmx queries, get the data of more than 150 000 insee series from bdm database. Have a look at the detailed sdmx web service page with the following link : <https://www.insee.fr/en/information/2868055>.",2022-03-10,Hadrien Leclerc,https://pyr-opendatafr.github.io/R-Insee-Data/,TRUE,https://github.com/pyr-opendatafr/r-insee-data,12975,3,2022-07-10T11:33:25Z,4325
insiderTrades,"Download insider trading transactions and insider holdings
             from a public NoSQL SEC database
             (<https://www.sec.gov/Archives/edgar/full-index/>) using 
             keyword criteria and generate a relational dataframe. ",2021-10-04,Joseph Hancuch,https://github.com/US-Department-of-the-Treasury/insiderTrades,TRUE,https://github.com/us-department-of-the-treasury/insidertrades,3018,1,2021-10-04T14:52:55Z,3018
insight,"A tool to provide an easy, intuitive and consistent
    access to information contained in various R models, like model
    formulas, model terms, information about random effects, data that was
    used to fit the model or data from response variables. 'insight'
    mainly revolves around two types of functions: Functions that find
    (the names of) information, starting with 'find_', and functions that
    get the underlying data, starting with 'get_'.  The package has a
    consistent syntax and works with many different model objects, where
    otherwise functions to access these information are missing.",2022-07-05,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>,https://easystats.github.io/insight/,TRUE,https://github.com/easystats/insight,2491076,301,2022-07-05T12:55:14Z,8276
InSilicoVA,"Computes individual causes of death and population cause-specific mortality fractions using the 'InSilicoVA' algorithm from McCormick et al. (2016) <DOI:10.1080/01621459.2016.1152191>. It uses data derived from verbal autopsy (VA) interviews, in a format similar to the input of the widely used 'InterVA' method. This package provides general model fitting and customization for 'InSilicoVA' algorithm and basic graphical visualization of the output.",2022-03-11,Zehang Richard Li,https://github.com/verbal-autopsy-software/InSilicoVA,TRUE,https://github.com/verbal-autopsy-software/insilicova,24707,3,2022-06-17T04:47:39Z,8235.666666666666
inspectdf,"A collection of utilities for columnwise summary, comparison and visualisation of data frames.  Functions report missingness, categorical levels, numeric distribution, correlation, column types and memory usage.",2021-04-02,Alastair Rushworth,https://alastairrushworth.github.io/inspectdf/,TRUE,https://github.com/alastairrushworth/inspectdf,48417,234,2021-12-10T17:45:51Z,206.9102564102564
installr,"R is great for installing software.  Through the 'installr'
    package you can automate the updating of R (on Windows, using updateR())
    and install new software. Software installation is initiated through a
    GUI (just run installr()), or through functions such as: install.Rtools(),
    install.pandoc(), install.git(), and many more. The updateR() command
    performs the following: finding the latest R version, downloading it,
    running the installer, deleting the installation file, copy and updating
    old packages to the new R installation.",2021-05-08,Tal Galili,"https://talgalili.github.io/installr/,
https://github.com/talgalili/installr/,
https://www.r-statistics.com/tag/installr/",TRUE,https://github.com/talgalili/installr,1524174,243,2022-03-30T19:09:10Z,6272.320987654321
insurancerating,"Methods for insurance rating. It helps actuaries to implement GLMs within all relevant steps needed to construct
 a risk premium from raw data. It provides a data driven strategy for the construction of insurance tariff classes.
 This strategy is based on the work by Antonio and Valdez (2012) <doi:10.1007/s10182-011-0152-7>. It also provides recipes
 on how to easily perform one-way, or univariate, analyses on an insurance portfolio. In addition it adds functionality
 to include reference categories in the levels of the coefficients in the output of a generalized linear regression analysis.",2022-07-08,Martin Haringa,"https://github.com/mharinga/insurancerating,
https://mharinga.github.io/insurancerating/",TRUE,https://github.com/mharinga/insurancerating,21414,37,2022-07-08T09:00:51Z,578.7567567567568
interactionR,"Produces a publication-ready table that includes all effect estimates necessary for full reporting effect modification and interaction analysis as recommended by Knol and Vanderweele (2012) [<doi:10.1093/ije/dyr218>].
    It also estimates confidence interval for the trio of additive interaction measures using the delta method (see Hosmer and Lemeshow (1992), [<doi:10.1097/00001648-199209000-00012>]), variance recovery method (see Zou (2008), [<doi:10.1093/aje/kwn104>]), or percentile bootstrapping (see Assmann et al. (1996), [<doi:10.1097/00001648-199605000-00012>]). ",2022-06-04,Babatunde Alli,https://github.com/epi-zen/interactionR,TRUE,https://github.com/epi-zen/interactionr,14994,13,2022-06-04T18:01:11Z,1153.3846153846155
interactions,"A suite of functions for conducting and interpreting analysis 
  of statistical interaction in regression models that was formerly part of the 
  'jtools' package. Functionality includes visualization of two- and three-way
  interactions among continuous and/or categorical variables as well as 
  calculation of ""simple slopes"" and Johnson-Neyman intervals (see e.g., 
  Bauer & Curran, 2005 <doi:10.1207/s15327906mbr4003_5>). These
  capabilities are implemented for generalized linear models in addition to the 
  standard linear regression context.",2021-07-02,Jacob A. Long,https://interactions.jacob-long.com,TRUE,https://github.com/jacob-long/interactions,133105,105,2022-04-18T02:57:16Z,1267.6666666666667
interplex,"Computational topology, which includes topological data analysis
    (TDA), makes pervasive use of abstract mathematical objects called
    simplicial complexes; see Edelsbrunner and Harer (2010)
    <doi:10.1090/mbk/069>.
    Several R packages and other software libraries used through an R interface
    construct and use data structures that represent simplicial complexes,
    including mathematical graphs viewed as 1-dimensional complexes.
    This package provides coercers (converters) between these data structures.
    Currently supported structures are complete lists of simplices as used by
    'TDA'; the simplex trees of Boissonnat and Maria (2014)
    <doi:10.1007/s00453-014-9887-3> as implemented in 'simplextree' and in
    Python GUDHI (by way of 'reticulate'); and the graph classes of 'igraph' and
    'network', by way of the 'intergraph' package.",2022-06-21,Jason Cory Brunson,https://github.com/corybrunson/interplex,TRUE,https://github.com/corybrunson/interplex,185,0,2022-06-21T13:16:25Z,NA
interpretCI,"Estimate confidence intervals for mean, proportion, mean difference 
   for unpaired and paired samples and proportion difference. Plot the confidence 
   intervals. Generate documents explaining the statistical result step by step.",2022-01-28,Keon-Woong Moon,"https://github.com/cardiomoon/interpretCI,
https://cardiomoon.github.io/interpretCI/",TRUE,https://github.com/cardiomoon/interpretci,1393,3,2022-02-08T03:20:56Z,464.3333333333333
inters,A set of functions to estimate interactions flexibly in the face of possibly many controls. Implements the procedures described in Blackwell and Olson (2022) <doi:10.1093/restud/rdt044>.,2022-04-22,Matthew Blackwell,https://mattblackwell.github.io/inters/,TRUE,https://github.com/mattblackwell/inters,512,10,2022-04-27T14:57:48Z,51.2
inTextSummaryTable,"Creation of tables of summary statistics or counts for clinical data (for 'TLFs'). 
  These tables can be exported as in-text table (with the 'flextable' package) for a Clinical Study Report 
  (Word format) or a 'topline' presentation (PowerPoint format), 
  or as interactive table (with the 'DT' package) to an html document for clinical data review.",2022-02-22,Laure Cougnaud,https://github.com/openanalytics/inTextSummaryTable,TRUE,https://github.com/openanalytics/intextsummarytable,5126,0,2022-02-22T10:24:47Z,NA
inti,"The 'inti' package is part of the 'inkaverse' project for developing 
    different procedures and tools used in plant science and experimental designs. 
    The mean aim of the package is to support researchers during the planning of
    experiments and data collection (tarpuy()), data analysis and graphics (yupana())
    , and technical writing. 
    Learn more about the 'inkaverse' project at <https://inkaverse.com/>.",2022-05-19,Flavio Lozano-Isla,"https://inkaverse.com/, https://github.com/flavjack/inti",TRUE,https://github.com/flavjack/inti,12461,1,2022-06-26T19:43:39Z,12461
inTrees,"For tree ensembles such as random forests, regularized random forests and gradient boosted trees, this package provides functions for: extracting, measuring and pruning rules; selecting a compact rule set; summarizing rules into a learner; calculating frequent variable interactions; formatting rules in latex code.  Reference: Interpreting tree ensembles with inTrees (Houtao Deng, 2019, <doi:10.1007/s41060-018-0144-8>).",2022-05-31,Houtao Deng,NA,TRUE,https://github.com/softwaredeng/intrees,27436,31,2022-05-31T17:18:13Z,885.0322580645161
intRinsic,"Provides functions to estimate the intrinsic dimension of a dataset 
  via likelihood-based approaches. Specifically, the package implements the 
  'TWO-NN' and 'Gride' estimators and the 'Hidalgo' Bayesian mixture model. 
  In addition, the first reference contains an extended vignette on the usage of 
  the 'TWO-NN' and 'Hidalgo' models. References: 
    Denti (2022+, <arXiv:2102.11425>); 
    Allegra et al. (2020, <doi:10.1038/s41598-020-72222-0>); 
    Denti et al. (2022+, <arXiv:2104.13832>);
    Facco et al. (2017, <doi:10.1038/s41598-017-11873-y>); 
    Santos-Fernandez et al. (2021, <arXiv:1902.10459>).",2022-05-31,Francesco Denti,https://github.com/Fradenti/intRinsic,TRUE,https://github.com/fradenti/intrinsic,1726,9,2022-05-31T13:36:53Z,191.77777777777777
intsvy,"
  Provides tools for importing, merging, and analysing data from 
  international assessment studies (TIMSS, PIRLS, PISA, ICILS, and PIAAC).",2021-01-23,Daniel Caro,"http://danielcaro.net/r-intsvy/,
https://github.com/eldafani/intsvy",TRUE,https://github.com/eldafani/intsvy,25696,14,2021-08-20T08:40:23Z,1835.4285714285713
invertiforms,"Provides composable invertible transforms for
    (sparse) matrices.",2022-02-09,Alex Hayes,"https://rohelab.github.io/invertiforms/,
https://github.com/RoheLab/invertiforms",TRUE,https://github.com/rohelab/invertiforms,1310,1,2022-02-16T19:37:48Z,1310
investr,"Functions to facilitate inverse estimation (e.g., calibration) in
    linear, generalized linear, nonlinear, and (linear) mixed-effects models. A
    generic function is also provided for plotting fitted regression models with
    or without confidence/prediction bands that may be of use to the general
    user. For a general overview of these methods, see Greenwell and Schubert 
    Kabban (2014) <doi:10.32614/RJ-2014-009>.",2022-03-31,Brandon M. Greenwell,https://github.com/bgreenwell/investr,TRUE,https://github.com/bgreenwell/investr,43666,18,2022-03-31T17:28:52Z,2425.8888888888887
iNZightMR,"Interaction and analysis of multiple response data,
    along with other tools for analysing these types of data including
    missing value analysis and calculation of standard errors for
    a range of covariance matrix results (proportions, multinomial,
    independent samples, and multiple response).",2022-01-19,Tom Elliott,https://inzight.nz,TRUE,https://github.com/inzightvit/inzightmr,9353,0,2022-05-30T23:25:02Z,NA
iNZightPlots,"Simple plotting function(s) for exploratory data analysis with flexible options allowing for easy plot customisation. The goal is to make it easy for beginners to start exploring a dataset through simple R function calls, as well as provide a similar interface to summary statistics and inference information. Includes functionality to generate interactive HTML-driven graphs. Used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions.",2022-01-24,Tom Elliott,https://inzight.nz,TRUE,https://github.com/inzightvit/inzightplots,10227,1,2022-05-08T23:40:45Z,10227
iNZightRegression,"Provides a suite of functions to use with regression models, including summaries, residual plots, and factor comparisons. Used as part of the Model Fitting module of 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions.",2022-02-07,Tom Elliott,http://inzight.nz,TRUE,https://github.com/inzightvit/inzightregression,7778,0,2022-02-08T00:46:17Z,NA
iNZightTools,"Provides a collection of wrapper functions for common variable and dataset manipulation workflows primarily used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions. Additionally, many of the functions return the 'tidyverse' code used to obtain the result in an effort to bridge the gap between GUI and coding.",2022-01-18,Tom Elliott,http://inzight.nz,TRUE,https://github.com/inzightvit/inzighttools,17785,1,2022-05-31T08:00:39Z,17785
iNZightTS,"Provides a collection of functions for working with time series data, including functions for drawing, decomposing, and forecasting. Includes capabilities to compare multiple series and fit both additive and multiplicative models. Used by 'iNZight', a graphical user interface providing easy exploration and visualisation of data for students of statistics, available in both desktop and online versions. Holt (1957) <doi:10.1016/j.ijforecast.2003.09.015>, Winters (1960) <doi:10.1287/mnsc.6.3.324>, Cleveland, Cleveland, & Terpenning (1990) ""STL: A Seasonal-Trend Decomposition Procedure Based on Loess"".",2022-01-31,Tom Elliott,http://inzight.nz,TRUE,https://github.com/inzightvit/inzightts,11032,0,2022-01-31T21:42:07Z,NA
IOHanalyzer,"The data analysis module for the Iterative Optimization Heuristics
    Profiler ('IOHprofiler'). This module provides statistical analysis methods for the 
    benchmark data generated by optimization heuristics, which can be visualized through a 
    web-based interface. The benchmark data is usually generated by the 
    experimentation module, called 'IOHexperimenter'. 'IOHanalyzer' also supports
    the widely used 'COCO' (Comparing Continuous Optimisers) data format for benchmarking.",2022-03-09,Hao Wang,"http://iohprofiler.liacs.nl,
https://github.com/IOHprofiler/IOHAnalyzer",TRUE,https://github.com/iohprofiler/iohanalyzer,15389,13,2022-06-29T11:38:00Z,1183.7692307692307
IOHexperimenter,"The benchmarking module for the Iterative Optimization Heuristics
    Profiler ('IOHprofiler'). This module provides benchmarking in the 'IOHprofiler'
    format, which can be visualized using the 'IOHanalyzer' module.",2020-09-01,Diederick Vermetten,https://github.com/IOHprofiler/IOHexperimenter,TRUE,https://github.com/iohprofiler/iohexperimenter,9177,29,2022-06-17T13:48:40Z,316.44827586206895
iotables,"Pre-processing and basic analytical tasks related to working
    with Eurostat's symmetric input-output tables and provide basic
    input-output economics calculations. The package is part of rOpenGov
    <http://ropengov.github.io/> to open source open government initiatives.",2022-02-10,Daniel Antal,https://iotables.dataobservatory.eu/,TRUE,https://github.com/ropengov/iotables,14988,14,2022-02-10T14:50:24Z,1070.5714285714287
ip2location,"Enables the user to find the country, region, city, coordinates, zip code, time zone, ISP, domain name, connection type, area code, weather station code, weather station name, mobile, usage type, address type and IAB category that any IP address or hostname originates from. Supported IPv4 and IPv6.
        Please visit <https://www.ip2location.com> to learn more. You may also want to visit <https://lite.ip2location.com> for free database download.
        This package requires 'IP2Location Python' module. At the terminal, please run 'pip install IP2Location' to install the module.",2021-06-03,IP2Location,https://github.com/ip2location/ip2location-r,TRUE,https://github.com/ip2location/ip2location-r,13842,6,2022-06-22T05:49:11Z,2307
ipaddress,"Classes and functions for working with IP (Internet Protocol)
    addresses and networks, inspired by the Python 'ipaddress' module.
    Offers full support for both IPv4 and IPv6 (Internet Protocol versions
    4 and 6) address spaces. It is specifically designed to work well with
    the 'tidyverse'.",2022-01-11,David Hall,"https://davidchall.github.io/ipaddress/,
https://github.com/davidchall/ipaddress",TRUE,https://github.com/davidchall/ipaddress,19068,20,2022-01-14T05:17:32Z,953.4
ipdw,"Functions are provided to interpolate geo-referenced point data via
    Inverse Path Distance Weighting. Useful for coastal marine applications where
    barriers in the landscape preclude interpolation with Euclidean distances.",2022-07-01,Jemma Stachelek,https://github.com/jsta/ipdw,TRUE,https://github.com/jsta/ipdw,21707,7,2022-06-23T15:36:51Z,3101
ipeadatar,"Allows direct access to the macroeconomic, 
             financial and regional database maintained by 
             Brazilian Institute for Applied Economic Research ('Ipea').
             This R package uses the 'Ipeadata' API. For more information, 
             see <http://www.ipeadata.gov.br/>.",2022-02-03,Luiz Eduardo S. Gomes,https://github.com/gomesleduardo/ipeadatar,TRUE,https://github.com/gomesleduardo/ipeadatar,19952,20,2022-02-01T01:54:33Z,997.6
IPEDSuploadables,"Starting from user-supplied institutional data, these scripts 
    transform, aggregate, and reshape the information to produce 
    key-value pair data files that are able to be uploaded to IPEDS (Integrated Postsecondary Education Data System) 
    through their submission portal <https://surveys.nces.ed.gov/ipeds/>. Starting data specifications can be found in the vignettes.  
    Final files are saved locally to a location of the user's choice. 
    User-friendly readable files can also be produced for purposes of data review and validation. ",2022-05-12,Alison Lanski,"https://github.com/AlisonLanski/IPEDSuploadables,
https://alisonlanski.github.io/IPEDSuploadables/",TRUE,https://github.com/alisonlanski/ipedsuploadables,430,4,2022-06-16T21:40:01Z,107.5
ipfp,"A fast (C) implementation of the iterative proportional fitting
    procedure.",2022-05-05,Alexander W Blocker,https://github.com/awblocker/ipfp,TRUE,https://github.com/awblocker/ipfp,20872,13,2022-05-04T18:33:06Z,1605.5384615384614
IPLGP,"
    Combining genomic prediction with Monte Carlo simulation, three different 
    strategies are implemented to select parental lines for multiple traits in plant 
    breeding. The selection strategies include (i) GEBV-O considers only genomic 
    estimated breeding values (GEBVs) of the candidate individuals; (ii) GD-O 
    considers only genomic diversity (GD) of the candidate individuals; and (iii) 
    GEBV-GD considers both GEBV and GD. The above method can be seen in Chung PY, 
    Liao CT (2020) <doi:10.1371/journal.pone.0243159>. Multi-trait genomic best 
    linear unbiased prediction (MT-GBLUP) model is used to simultaneously estimate 
    GEBVs of the target traits, and then a selection index is adopted to evaluate 
    the composite performance of an individual.",2022-06-21,Ping-Yuan Chung,https://github.com/py-chung/IPLGP,TRUE,https://github.com/py-chung/iplgp,6522,0,2022-06-21T10:28:21Z,NA
iplots,Interactive plots for R.,2022-05-01,Simon Urbanek,http://www.iPlots.org/,TRUE,https://github.com/s-u/iplots,51325,2,2022-04-29T06:18:06Z,25662.5
IPMbook,Provides functions and data sets to accompany the  book 'Integrated Population Models: Theory and Ecological Applications with R and JAGS' by Michael Schaub and Marc Kéry (ISBN: 9780128205648).,2021-12-10,Mike Meredith,https://www.vogelwarte.ch/de/projekte/publikationen/ipm/,TRUE,https://github.com/mikemeredith/ipmbook,5415,6,2021-12-10T08:57:47Z,902.5
ipmr,"Flexibly implements Integral Projection Models using a
  mathematical(ish) syntax. This package will not help with the vital rate
  modeling process, but will help convert those regression models into an
  IPM. 'ipmr' handles density dependence and environmental stochasticity, with a
  couple of options for implementing the latter. In addition, provides functions
  to avoid unintentional eviction of individuals from models. Additionally, 
  provides model diagnostic tools, plotting functionality, 
  stochastic/deterministic simulations, and analysis tools.
  Integral projection models are described in depth by Easterling et al. (2000) 
  <doi:10.1890/0012-9658(2000)081[0694:SSSAAN]2.0.CO;2>, Merow et al. (2013) 
  <doi:10.1111/2041-210X.12146>, Rees et al. (2014) <doi:10.1111/1365-2656.12178>,
  and Metcalf et al. (2015) <doi:10.1111/2041-210X.12405>. 
  Williams et al. (2012) <doi:10.1890/11-2147.1> discuss the problem of 
  unintentional eviction.",2022-04-28,Sam Levin,"https://levisc8.github.io/ipmr/, https://github.com/levisc8/ipmr",TRUE,https://github.com/levisc8/ipmr,7366,3,2022-05-16T15:00:28Z,2455.3333333333335
iprior,"Provides methods to perform and analyse I-prior regression models.
    Estimation is done either via direct optimisation of the log-likelihood or 
    an EM algorithm.",2019-03-20,Haziq Jamil,https://github.com/haziqj/iprior,TRUE,https://github.com/haziqj/iprior,16870,1,2021-08-27T04:33:53Z,16870
ipsecr,"Estimates the density of a spatially distributed animal population sampled with an array of passive detectors, such as traps. Models incorporating distance-dependent detection are fitted by simulation and inverse prediction as proposed by Efford (2004) <doi:10.1111/j.0030-1299.2004.13043.x>.",2022-06-26,Murray Efford,"https://github.com/MurrayEfford/ipsecr/,
https://www.otago.ac.nz/density/",TRUE,https://github.com/murrayefford/ipsecr,257,0,2022-07-07T08:57:07Z,NA
iptools,"A toolkit for manipulating, validating and testing 'IP' addresses and
    ranges, along with datasets relating to 'IP' addresses. Tools are also provided
    to map 'IPv4' blocks to country codes. While it primarily has support for the 'IPv4'
    address space, more extensive 'IPv6' support is intended.",2021-09-10,Bob Rudis,https://github.com/hrbrmstr/iptools,TRUE,https://github.com/hrbrmstr/iptools,28134,48,2021-08-27T16:31:52Z,586.125
ipumsr,"An easy way to import census, survey and geographic data provided by 'IPUMS'
    into R plus tools to help use the associated metadata to make analysis easier. 'IPUMS'
    data describing 1.4 billion individuals drawn from over 750 censuses and surveys is
    available free of charge from our website <https://www.ipums.org>.",2022-06-04,Derek Burk,"https://www.ipums.org, https://github.com/ipums/ipumsr",TRUE,https://github.com/ipums/ipumsr,82713,0,2022-06-23T17:09:52Z,NA
IPV,"Generate plots based on the Item Pool Visualization concept for
    latent constructs. Item Pool Visualizations are used to display the
    conceptual structure of a set of items (self-report or psychometric).
    Dantlgraber, Stieger, & Reips (2019) <doi:10.1177/2059799119884283>.",2021-12-14,Nils Petras,https://github.com/NilsPetras/IPV,TRUE,https://github.com/nilspetras/ipv,12161,1,2021-12-30T20:09:30Z,12161
iq,"An implementation of the MaxLFQ algorithm by
    Cox et al. (2014) <doi:10.1074/mcp.M113.031591> in a comprehensive
    pipeline for processing proteomics data in data-independent acquisition mode
    (Pham et al. 2020 <doi:10.1093/bioinformatics/btz961>).
    It offers additional options for protein quantification using
    the N most intense fragment ions, using all fragment ions, and
    a wrapper for the median polish algorithm by Tukey (1977, ISBN:0201076160).
    In general, the tool can be used to integrate multiple 
    proportional observations into a single quantitative value.",2022-04-26,Thang Pham,https://github.com/tvpham/iq,TRUE,https://github.com/tvpham/iq,16470,6,2022-05-12T13:24:18Z,2745
irace,"Iterated race is an extension of the Iterated F-race method for
             the automatic configuration of optimization algorithms, that is,
             (offline) tuning their parameters by finding the most appropriate
             settings given a set of instances of an optimization problem.
             M. López-Ibáñez, J. Dubois-Lacoste, L. Pérez Cáceres, T. Stützle,
             and M. Birattari (2016) <doi:10.1016/j.orp.2016.09.002>.",2020-03-31,Manuel López-Ibáñez,"http://iridia.ulb.ac.be/irace,
https://github.com/MLopez-Ibanez/irace",TRUE,https://github.com/mlopez-ibanez/irace,80143,25,2022-07-04T15:37:24Z,3205.72
IRdisplay,"
    An interface to the rich display capabilities of 'Jupyter' front-ends (e.g. 'Jupyter Notebook') <https://jupyter.org>.
    Designed to be used from a running 'IRkernel' session <https://irkernel.github.io>.",2022-01-04,Thomas Kluyver,https://github.com/IRkernel/IRdisplay,TRUE,https://github.com/irkernel/irdisplay,746741,42,2022-01-04T12:51:56Z,17779.54761904762
IRexamples,Provides examples of code for analyzing data or accomplishing tasks that may be useful to institutional or educational researchers.,2021-09-06,Vinh Nguyen,https://github.com/vinhdizzo/IRexamples,TRUE,https://github.com/vinhdizzo/irexamples,3321,1,2022-06-06T17:07:48Z,3321
irg,"Fits a double logistic function to NDVI time series and calculates 
             instantaneous rate of green (IRG) according to methods described
             in Bischoff et al. (2012) <doi:10.1086/667590>. ",2021-12-22,Alec L. Robitaille,"https://github.com/robitalec/irg, https://robitalec.github.io/irg/",TRUE,https://github.com/robitalec/irg,12848,2,2022-02-18T01:57:34Z,6424
iriR,"Researchers and analysts have access to more than 7,500 innovative companies worldwide, which are or have been part of the top 1,000 innovative companies. They can access the six parameters that compose the global IRI Scoreboard's data on R&D: Country, Year, Company's name, Industry, Indicator and Company's rank. Please cite: Warin, Th. (2020) ""iiriR: An R Package for the EU Industrial R&D Investment Scoreboard"", <doi:10.6084/m9.figshare.11774640.v5>.",2021-04-22,Thierry Warin,https://github.com/warint/iriR/,TRUE,https://github.com/warint/irir,7030,1,2021-08-20T14:11:39Z,7030
IRkernel,"
    The R kernel for the 'Jupyter' environment executes R code which the front-end
    ('Jupyter Notebook' or other front-ends) submits to the kernel via the network.",2022-01-03,Thomas Kluyver,https://irkernel.github.io,TRUE,https://github.com/irkernel/irkernel,456656,1501,2022-06-24T09:09:04Z,304.234510326449
irlba,"Fast and memory efficient methods for truncated singular value
    decomposition and principal components analysis of large sparse and dense
    matrices.",2021-12-06,B. W. Lewis,NA,TRUE,https://github.com/bwlewis/irlba,790665,102,2021-12-06T02:41:16Z,7751.617647058823
IRon,"Imbalanced domain learning has almost exclusively focused on solving 
    classification tasks, where the objective is to predict cases labelled with a 
    rare class accurately. Such a well-defined approach for regression tasks lacked 
    due to two main factors. First, standard regression tasks assume that each value 
    is equally important to the user. Second, standard evaluation metrics focus on 
    assessing the performance of the model on the most common cases. This package 
    contains methods to tackle imbalanced domain learning problems in regression 
    tasks, where the objective is to predict extreme (rare) values.
    The methods contained in this package are: 1) an automatic and non-parametric 
    method to obtain such relevance functions; 2) visualisation tools; 3) suite of 
    evaluation measures for optimisation/validation processes; 4) the squared-error 
    relevance area measure, an evaluation metric tailored for imbalanced regression tasks.
    More information can be found in Ribeiro and Moniz (2020) <doi:10.1007/s10994-020-05900-9>.",2022-06-14,Nuno Moniz,https://github.com/nunompmoniz/IRon,TRUE,https://github.com/nunompmoniz/iron,380,6,2022-05-27T00:20:59Z,63.333333333333336
irtplay,"Fit unidimensional item response theory (IRT) models to a mixture 
    of dichotomous and polytomous data, calibrate online item parameters 
    (i.e., pretest and operational items), estimate examinees' abilities, 
    and examine the IRT model-data fit on item-level in different ways 
    as well as provide useful functions related to unidimensional IRT models. 
    For the item parameter estimation, the marginal maximum likelihood estimation 
    via the expectation-maximization (MMLE-EM) algorithm 
    (Bock & Aitkin (1981) <doi:10.1007/BF02294168>) is used. 
    For the online calibration, the fixed item parameter calibration method 
    (Kim (2006) <doi:10.1111/j.1745-3984.2006.00021.x>) and 
    the fixed ability parameter calibration method
    (Ban, Hanson, Wang, Yi, & Harris (2011) <doi:10.1111/j.1745-3984.2001.tb01123.x>) 
    are provided. For the ability estimation, several popular scoring methods 
    (e.g., MLE, EAP, and MAP) are implemented. In terms of assessing the IRT 
    model-data fit, one of distinguished features of this package is that it 
    gives not only well-known item fit statistics (e.g., chi-square (X2), 
    likelihood ratio chi-square (G2), infit and oufit statistics, and 
    S-X2 statistic (Ames & Penfield (2015) <doi:10.1111/emip.12067>)) 
    but also graphical displays to look at residuals between the observed 
    data and model-based predictions 
    (Hambleton, Swaminathan, & Rogers (1991, ISBN:9780803936478)). 
    In addition, there are many useful functions such as analyzing differential item 
    functioning, computing asymptotic variance-covariance matrices of item parameter 
    estimates (Li & Lissitz (2004) <doi:10.1111/j.1745-3984.2004.tb01109.x>), 
    importing item and/or ability parameters from popular IRT software, 
    running 'flexMIRT' (Cai, 2017) through R, generating simulated data, 
    computing the conditional distribution of observed scores using 
    the Lord-Wingersky recursion formula (Lord & Wingersky (1984) 
    <doi:10.1177/014662168400800409>), computing the loglikelihood of individual 
    items, computing the loglikelihood of abilities, computing item and test 
    information functions, computing item and test characteristic curve functions, 
    and plotting item and test characteristic curves and item and test information functions.",2022-03-30,Hwanggyu Lim,https://github.com/hwangQ/irtplay,TRUE,https://github.com/hwangq/irtplay,22578,0,2022-04-14T19:31:29Z,NA
isaeditor,"
  ISA-Tab (Investigation/Study/Assay (ISA) tab-delimited (TAB) format) is a
  general purpose framework for storing complex metadata in omics
  applications. It is notoriously hard to manipulate due to the fact that
  it is a graph rather than a tab-delimited data frame. The 'isaeditor' package is meant
  to facilitate reading, writing, displaying, manipulating, modifying and populating
  ISA-Tab files in R.",2021-09-29,January Weiner,https://github.com/bihealth/isaeditor/,TRUE,https://github.com/bihealth/isaeditor,3130,0,2021-09-28T16:32:13Z,NA
isatabr,"ISA is a metadata framework to manage an increasingly diverse set 
    of life science, environmental and biomedical experiments. In isatabr 
    methods for reading, modifying and writing of files in the ISA-Tab format
    are implemented. It also contains methods for processing assay data.",2021-07-16,Bart-Jan van Rossum,https://github.com/Biometris/isatabr/,TRUE,https://github.com/biometris/isatabr,3739,0,2021-07-16T07:12:41Z,NA
iscoCrosswalks,"Allows the user to perform approximate
 matching between the occupational classifications using concordances provided by
 the Institute for Structural Research and Faculty of Economics, University of
 Warsaw, <doi:10.1111/ecot.12145>. The crosswalks offer a complete
 step-by-step mapping of Standard Occupational Classification (2010) data to the
 International Standard Classification of Occupations (2008). We propose a
 mapping method based on the aforementioned research that converts measurements
 to the smallest possible unit of the target taxonomy, and then performs an
 aggregation/estimate to the requested degree Occupational Hierarchical level.",2022-05-17,Alexandros Kouretsis,https://github.com/eworx-org/iscoCrosswalks,TRUE,https://github.com/eworx-org/iscocrosswalks,379,2,2022-05-17T08:43:20Z,189.5
isoband,"A fast C++ implementation to generate contour lines (isolines) and
  contour polygons (isobands) from regularly spaced grids containing elevation data.",2021-07-13,Claus O. Wilke,https://wilkelab.org/isoband/,TRUE,https://github.com/wilkelab/isoband,20438564,114,2021-09-06T21:51:19Z,179285.64912280702
isobxr,"A set of functions to run simple and composite box-models to describe the 
    dynamic or static distribution of stable isotopes in open 
    or closed systems. The package also allows the sweeping of many 
    parameters in both static and dynamic conditions. It also comes 
    with a post-run plotting interface built under shiny.
    The mathematical models used in this package are derived from Albarede, 1995, 
    Introduction to Geochemical Modelling, Cambridge University Press,
    Cambridge <doi:10.1017/CBO9780511622960>.",2021-09-07,Theo Tacail,"https://github.com/ttacail/isobxr,
https://ttacail.github.io/isobxr_web/,
https://ttacail.github.io/isobxr/",TRUE,https://github.com/ttacail/isobxr,3540,0,2021-09-10T07:52:57Z,NA
isocalcR,"Perform common calculations based on published stable isotope theory, such as calculating carbon isotope discrimination and intrinsic water use efficiency from wood or leaf carbon isotope composition. See Farquhar, O'Leary, and Berry (1982) <doi:10.1071/PP9820121>.  ",2021-07-31,Justin Mathias,https://github.com/justinmathias/isocalcR,TRUE,https://github.com/justinmathias/isocalcr,3569,0,2022-07-09T01:06:21Z,NA
isodistrreg,"Distributional regression under stochastic order restrictions for
    numeric and binary response variables and partially ordered covariates. See
    Henzi, Ziegel, Gneiting (2020) <arXiv:1909.03725>.",2021-03-22,Alexander Henzi,https://github.com/AlexanderHenzi/isodistrreg,TRUE,https://github.com/alexanderhenzi/isodistrreg,4605,8,2022-05-11T15:18:16Z,575.625
isogeochem,"
    This toolbox makes working with carbonate oxygen,
    carbon, and clumped isotope data reproducible and straightforward.
    Use it to quickly calculate isotope fractionation factors,
    and apply paleothermometry equations.",2021-11-07,David Bajnai,https://davidbajnai.github.io/isogeochem/,TRUE,https://github.com/davidbajnai/isogeochem,2514,5,2022-07-08T14:59:04Z,502.8
isokernel,Implementation of Isolation kernel (Qin et al. (2019) <doi:10.1609/aaai.v33i01.33014755>).,2021-10-04,Ye Zhu,https://github.com/zhuye88/isokernel,TRUE,https://github.com/zhuye88/isokernel,2942,0,2021-10-05T03:36:58Z,NA
IsoMemo,API wrapper that contains functions to retrieve data from the 'IsoMemo' partnership databases. Web services for API: <https://isomemodb.com/api/v1/iso-data>. ,2022-06-16,Jianyin Roachell,NA,TRUE,https://github.com/pandora-isomemo/isomemo-data,350,0,2022-06-16T11:37:51Z,NA
IsoplotR,"Plots U-Pb data on Wetherill and Tera-Wasserburg concordia diagrams. Calculates concordia and discordia ages. Performs linear regression of measurements with correlated errors using 'York', 'Titterington' and 'Ludwig' approaches. Generates Kernel Density Estimates (KDEs) and Cumulative Age Distributions (CADs). Produces Multidimensional Scaling (MDS) configurations and Shepard plots of multi-sample detrital datasets using the Kolmogorov-Smirnov distance as a dissimilarity measure. Calculates 40Ar/39Ar ages, isochrons, and age spectra. Computes weighted means accounting for overdispersion. Calculates U-Th-He (single grain and central) ages, logratio plots and ternary diagrams. Processes fission track data using the external detector method and LA-ICP-MS, calculates central ages and plots fission track and other data on radial (a.k.a. 'Galbraith') plots. Constructs total Pb-U, Pb-Pb, Th-Pb, K-Ca, Re-Os, Sm-Nd, Lu-Hf, Rb-Sr and 230Th-U isochrons as well as 230Th-U evolution plots.",2022-05-21,Pieter Vermeesch,"https://www.ucl.ac.uk/~ucfbpve/isoplotr/,
https://github.com/pvermees/IsoplotR/",TRUE,https://github.com/pvermees/isoplotr,35868,41,2022-05-21T10:28:29Z,874.829268292683
IsoplotRgui,"Provides a graphical user interface to the 'IsoplotR' package for radiometric geochronology. The GUI runs in an internet browser and can either be used offline, or hosted on a server to provide online access to the 'IsoplotR' toolbox.",2022-05-21,Pieter Vermeesch,"https://www.ucl.ac.uk/~ucfbpve/isoplotr/,
https://github.com/pvermees/IsoplotRgui/",TRUE,https://github.com/pvermees/isoplotrgui,10168,15,2022-05-21T11:44:15Z,677.8666666666667
isotree,"Fast and multi-threaded implementation of
	isolation forest (Liu, Ting, Zhou (2008) <doi:10.1109/ICDM.2008.17>),
	extended isolation forest (Hariri, Kind, Brunner (2018) <arXiv:1811.02141>),
	SCiForest (Liu, Ting, Zhou (2010) <doi:10.1007/978-3-642-15883-4_18>),
	fair-cut forest (Cortes (2021) <arXiv:2110:13402>),
	robust random-cut forest (Guha, Mishra, Roy, Schrijvers (2016) <http://proceedings.mlr.press/v48/guha16.html>),
	and customizable variations of them, for isolation-based outlier detection, clustered outlier detection,
	distance or similarity approximation (Cortes (2019) <arXiv:1910.12362>),
	isolation kernel calculation (Ting, Zhu, Zhou (2018) <doi:10.1145/3219819.3219990>),
	and imputation of missing values (Cortes (2019) <arXiv:1911.06646>),
	based on random or guided decision tree splitting, and providing different metrics for
	scoring anomalies based on isolation depth or density (Cortes (2021) <arXiv:2111.11639>).
	Provides simple heuristics for fitting the model to categorical columns and handling missing data,
	and offers options for varying between random and guided splits, and for using different splitting criteria.",2022-03-31,David Cortes,https://github.com/david-cortes/isotree,TRUE,https://github.com/david-cortes/isotree,27670,124,2022-06-14T19:10:55Z,223.1451612903226
itan,"Functions for analyzing multiple choice items. These analyses include
  the convertion of student response into binaty data (correct/incorrect),
  the computation of the number of corrected responses and grade for each subject,
  the calculation of item difficulty and discrimination, the computation of the
  frecuency and point-biserial correlation for each distractor and the graphical
  analysis of each item.",2022-02-10,Ariel Armijo,https://github.com/arielarmijo/itan,TRUE,https://github.com/arielarmijo/itan,16316,0,2022-02-12T12:24:40Z,NA
iTensor,"Some functions for performing ICA, MICA, and Multilinear ICA are implemented.
    ICA, MICA, and Multilinear ICA extract statistically independent components from single matrix, multiple matrices, and single tensor, respectively.
    For the details of these methods, see the reference section of GitHub README.md <https://github.com/rikenbit/iTensor>.",2022-06-14,Koki Tsuyuzaki,https://github.com/rikenbit/mwTensor,TRUE,https://github.com/rikenbit/mwtensor,255,0,2022-06-15T01:20:07Z,NA
iterators,"Support for iterators, which allow a programmer to traverse
    through all the elements of a vector, list, or other collection of data.",2022-02-05,Folashade Daniel,https://github.com/RevolutionAnalytics/iterators,TRUE,https://github.com/revolutionanalytics/iterators,5782790,5,2022-02-15T18:22:31Z,1156558
itp,"Implements the Interpolate, Truncate, Project (ITP) root-finding 
    algorithm developed by Oliveira and Takahashi (2021) <doi:10.1145/3423597>.
    The user provides the function, from the real numbers to the real numbers, 
    and an interval with the property that the values of the function at its 
    endpoints have different signs. If the function is continuous over this 
    interval then the ITP method estimates the value at which the function is 
    equal to zero. If the function is discontinuous then a point of 
    discontinuity at which the function changes sign may be found. 
    The function can be supplied using either an R function or an external 
    pointer to a C++ function. Tuning parameters of the ITP algorithm can be 
    set by the user. Default values are set based on arguments in Oliveira and 
    Takahashi (2021). ",2022-07-02,Paul J. Northrop,"https://paulnorthrop.github.io/itp/,
https://github.com/paulnorthrop/itp",TRUE,https://github.com/paulnorthrop/itp,383,0,2022-07-09T21:15:55Z,NA
itraxR,"Parse, trim, join, visualise and analyse data from Itrax sediment core multi-parameter 
    scanners manufactured by Cox Analytical Systems, Sweden. Functions are provided for parsing 
    XRF-peak area files, line-scan optical images, and radiographic images, alongside accompanying metadata. 
    A variety of data wrangling tasks like trimming, joining and reducing XRF-peak area data are simplified. 
    Principle component analysis (PCA), cluster analysis and associated multivariate methods are 
    implemented with appropriate data transformation. ",2021-08-17,Thomas Bishop,https://thomasbishop.uk,TRUE,https://github.com/tombishop1/itraxr,6008,3,2022-04-07T20:49:45Z,2002.6666666666667
itsdm,"Collection of R functions to do purely presence-only species
    distribution modeling with isolation forest (iForest) and its
    variations such as Extended isolation forest and SCiForest. See the
    details of these methods in references: Liu, F.T., Ting, K.M. and
    Zhou, Z.H. (2008) <doi:10.1109/ICDM.2008.17>, Hariri, S., Kind, M.C.
    and Brunner, R.J. (2019) <doi:10.1109/TKDE.2019.2947676>, Liu, F.T.,
    Ting, K.M. and Zhou, Z.H. (2010) <doi:10.1007/978-3-642-15883-4_18>,
    Guha, S., Mishra, N., Roy, G. and Schrijvers, O. (2016)
    <https://proceedings.mlr.press/v48/guha16.html>, Cortes, D. (2021)
    <arXiv:2110.13402>. Additionally, Shapley values are used to explain
    model inputs and outputs. See details in references: Shapley, L.S.
    (1953) <doi:10.1515/9781400881970-018>, Lundberg, S.M. and Lee, S.I.
    (2017) <https://dl.acm.org/doi/abs/10.5555/3295222.3295230>, Molnar,
    C.  (2020) <ISBN:978-0-244-76852-2>, Štrumbelj, E. and Kononenko, I.
    (2014) <doi:10.1007/s10115-013-0679-x>. itsdm also provides functions
    to diagnose variable response, analyze variable importance, draw
    spatial dependence of variables and examine variable contribution. As
    utilities, the package includes a few functions to download
    bioclimatic variables including 'WorldClim' version 2.0 (see Fick,
    S.E. and Hijmans, R.J. (2017) <doi:10.1002/joc.5086>) and
    'CMCC-BioClimInd' (see Noce, S., Caporaso, L. and Santini, M. (2020)
    <doi:10.1038/s41597-020-00726-5>.",2022-06-20,Lei Song,"https://github.com/LLeiSong/itsdm,
https://lleisong.github.io/itsdm/",TRUE,https://github.com/lleisong/itsdm,1704,0,2022-06-21T15:00:17Z,NA
ivdoctr,"Uses data and researcher's beliefs on measurement error and
    instrumental variable (IV) endogeneity to generate the space of consistent 
    beliefs across measurement error, instrument endogeneity, and instrumental 
    relevance for IV regressions. 
    Package based on DiTraglia and Garcia-Jimeno (2020) <doi:10.1080/07350015.2020.1753528>.",2021-12-05,Mallick Hossain,NA,TRUE,https://github.com/emallickhossain/ivdoctr,7395,0,2021-12-05T11:31:21Z,NA
ivgets,"Provides facilities of general to specific model selection for
    exogenous regressors in 2SLS models. Furthermore, indicator saturation
    methods can be used to detect outliers and structural breaks in the sample.",2022-07-08,Kurle Jonas,https://github.com/jkurle/ivgets,TRUE,https://github.com/jkurle/ivgets,7,0,2022-07-09T17:15:45Z,NA
ivreg,"Instrumental variable estimation for linear models by two-stage least-squares (2SLS) regression or by robust-regression via M-estimation (2SM) or MM-estimation (2SMM). The main ivreg() model-fitting function is designed to provide a workflow as similar as possible to standard lm() regression. A wide range of methods is provided for fitted ivreg model objects, including extensive functionality for computing and graphing regression diagnostics in addition to other standard model tools.",2021-10-15,John Fox,https://john-d-fox.github.io/ivreg/,TRUE,https://github.com/john-d-fox/ivreg,82817,10,2022-04-18T11:46:01Z,8281.7
ivs,"Provides a library for generic interval manipulations using a
    new interval vector class. Capabilities include: locating various
    kinds of relationships between two interval vectors, merging overlaps
    within a single interval vector, splitting an interval vector on its
    overlapping endpoints, and applying set theoretical operations on
    interval vectors. Many of the operations in this package were inspired
    by James Allen's interval algebra, Allen (1983)
    <doi:10.1145/182.358434>.",2022-04-05,Davis Vaughan,"https://github.com/DavisVaughan/ivs,
https://davisvaughan.github.io/ivs/",TRUE,https://github.com/davisvaughan/ivs,943,20,2022-06-09T18:25:04Z,47.15
ixplorer,"Create and view tickets in 'gitea', a self-hosted git service <https://gitea.io>, using an 'RStudio' addin, and use helper functions to publish documentation and use git.",2022-07-02,Frans van Dunne,https://github.com/ixpantia/ixplorer,TRUE,https://github.com/ixpantia/ixplorer,109,0,2022-06-19T16:14:57Z,NA
IxPopDyMod,"Code to specify, run, and then visualize and analyze the results of 
    Ixodidae (hard-bodied ticks) population and infection dynamics models. Such 
    models exist in the literature, but the source code to run them is not 
    always available. 'IxPopDyMod' provides an easy way for these models to be 
    written and shared.",2022-02-08,Myles Stokowski,https://github.com/dallenmidd/IxPopDyMod,TRUE,https://github.com/dallenmidd/ixpopdymod,2477,0,2022-05-03T21:31:04Z,NA
jaatha,"An estimation method that can use computer simulations to
    approximate maximum-likelihood estimates even when the likelihood function can not
    be evaluated directly. It can be applied whenever it is feasible to conduct many
    simulations, but works best when the data is approximately Poisson distributed.
    It was originally designed for demographic inference in evolutionary
    biology (Naduvilezhath et al., 2011 <doi:10.1111/j.1365-294X.2011.05131.x>,
    Mathew et al., 2013 <doi:10.1002/ece3.722>).
    It has optional support for conducting coalescent simulation using
    the 'coala' package.",2022-02-15,Paul Staab,https://github.com/statgenlmu/jaatha,TRUE,https://github.com/statgenlmu/jaatha,18677,3,2022-02-15T17:03:43Z,6225.666666666667
jack,"Symbolic calculation and evaluation of the Jack polynomials, zonal polynomials, and Schur polynomials. Mainly based on Demmel & Koev's paper (2006) <doi:10.1090/S0025-5718-05-01780-1>. Zonal polynomials and Schur polynomials are particular cases of Jack polynomials. Zonal polynomials appear in random matrix theory. Schur polynomials appear in the field of combinatorics.",2022-03-20,Stéphane Laurent,https://github.com/stla/jackR,TRUE,https://github.com/stla/jackr,13766,0,2022-02-21T13:12:52Z,NA
jacobi,"Evaluation of the Jacobi theta functions and related
    functions: Weierstrass elliptic function, Weierstrass sigma function,
    Klein j-function, Dedekind eta function, lambda modular function,
    Jacobi elliptic functions, Neville theta functions, and Eisenstein
    series. Complex values of the variable are supported.",2022-06-22,Stéphane Laurent,https://github.com/stla/jacobi,TRUE,https://github.com/stla/jacobi,188,0,2022-07-09T18:47:07Z,NA
jagstargets,"Bayesian data analysis usually incurs long runtimes
  and cumbersome custom code.
  A pipeline toolkit tailored to Bayesian statisticians,
  the 'jagstargets' R package is leverages
  'targets' and 'R2jags' to ease this burden.
  'jagstargets' makes it super easy to set up scalable
  JAGS pipelines that automatically parallelize the computation
  and skip expensive steps when the results are already up to date.
  Minimal custom code is required, and there is no need to manually
  configure branching, so usage is much easier than 'targets' alone.
  For the underlying methodology, please refer
  to the documentation of 'targets' <doi:10.21105/joss.02959> and 'JAGS'
  (Plummer 2003) <https://www.r-project.org/conferences/DSC-2003/Proceedings/Plummer.pdf>.",2022-06-24,William Michael Landau,"https://docs.ropensci.org/jagstargets/,
https://github.com/ropensci/jagstargets",TRUE,https://github.com/ropensci/jagstargets,2414,7,2022-06-24T14:52:28Z,344.85714285714283
jagsUI,"A set of wrappers around 'rjags' functions to run Bayesian analyses in 'JAGS' (specifically, via 'libjags').  A single function call can control adaptive, burn-in, and sampling MCMC phases, with MCMC chains run in sequence or in parallel. Posterior distributions are automatically summarized (with the ability to exclude some monitored nodes if desired) and functions are available to generate figures based on the posteriors (e.g., predictive check plots, traceplots). Function inputs, argument syntax, and output format are nearly identical to the 'R2WinBUGS'/'R2OpenBUGS' packages to allow easy switching between MCMC samplers.",2021-06-18,Ken Kellner,https://github.com/kenkellner/jagsUI,TRUE,https://github.com/kenkellner/jagsui,94585,30,2021-09-27T16:56:20Z,3152.8333333333335
jalcal,"Jalali, also known as Persian, Solar Hijri and Hijri Shamsi calendar is 
    the official calendar of Iran and Afghanistan. It begins on Nowruz, the March equinox, 
    as determined by astronomical calculation and has years of 365 or 366 days. 
    Adapting the algorithms in <https://jdf.scr.ir/>, this package provides tools 
    for converting the Jalali and Gregorian dates.",2021-09-07,Abdollah Jalilian,https://github.com/jalilian/jalcal,TRUE,https://github.com/jalilian/jalcal,4037,3,2022-06-07T08:27:22Z,1345.6666666666667
JamendoR,"Provides an interface to 'Jamendo' API <https://developer.jamendo.com/v3.0>.
              Pull audio, features and other information for a given 
              'Jamendo' user (including yourself!) or enter an artist's -, album's -, 
              or track's name and retrieve the available information in seconds.",2021-11-07,Maximilian Greil,https://github.com/MaxGreil/JamendoR,TRUE,https://github.com/maxgreil/jamendor,12558,2,2021-11-07T14:16:58Z,6279
janitor,"The main janitor functions can: perfectly format data.frame column
    names; provide quick counts of variable combinations (i.e., frequency
    tables and crosstabs); and isolate duplicate records. Other janitor functions
    nicely format the tabulation results. These tabulate-and-report functions
    approximate popular features of SPSS and Microsoft Excel. This package
    follows the principles of the ""tidyverse"" and works well with the pipe function
    %>%. janitor was built with beginning-to-intermediate R users in mind and is
    optimized for user-friendliness. Advanced R users can already do everything
    covered here, but with janitor they can do it faster and save their thinking for
    the fun stuff.",2021-01-05,Sam Firke,https://github.com/sfirke/janitor,TRUE,https://github.com/sfirke/janitor,2498796,1148,2022-05-16T15:06:35Z,2176.651567944251
jaod,"Client for the Directory of Open Access Journals ('DOAJ')
    (<https://doaj.org/>). API documentation at
    <https://doaj.org/api/v1/docs>. Methods included for working with
    all 'DOAJ' API routes: fetch article information by identifier,
    search for articles, fetch journal information by identifier,
    and search for journals.",2020-12-02,Scott Chamberlain,"https://docs.ropensci.org/jaod/, https://github.com/ropensci/jaod",TRUE,https://github.com/ropensci/jaod,16143,9,2022-05-10T13:56:03Z,1793.6666666666667
japanmesh,"Functions for the Japanese regional mesh codes defined in 'JIS
    X 0410'
    (<https://www.jisc.go.jp/app/jis/general/GnrJISNumberNameSearchList?show&jisStdNo=X0410>).
    Conversion between regional mesh codes and longitude/latitude, and
    between mesh codes of different scales.",2021-12-02,Mizuki Uchida,https://github.com/UchidaMizuki/japanmesh,TRUE,https://github.com/uchidamizuki/japanmesh,2151,4,2022-06-22T11:41:11Z,537.75
japanstat,"Provides tools for using the API of 'e-Stat' (<https://www.e-stat.go.jp/>), a portal site for Japanese government statistics.
    Includes functions for automatic query generation, data collection and formatting.",2021-11-29,Mizuki Uchida,https://github.com/UchidaMizuki/japanstat,TRUE,https://github.com/uchidamizuki/japanstat,2065,1,2022-05-22T08:46:38Z,2065
JBrowseR,"Provides an R interface to the JBrowse 2 genome browser.
    Enables embedding a JB2 genome browser in a Shiny app or R Markdown
    document. The browser can also be launched from an interactive R console.
    The browser can be loaded with a variety of common genomics data types,
    and can be used with a custom theme.",2021-10-17,Elliot Hershberg,https://gmod.github.io/JBrowseR/ https://github.com/GMOD/JBrowseR,TRUE,https://github.com/gmod/jbrowser,8406,22,2021-10-17T23:23:33Z,382.09090909090907
jds.rmd,"
    Customized R Markdown templates for authoring articles
    for Journal of Data Science.",2022-07-05,Wenjie Wang,https://github.com/wenjie2wang/jds.rmd,TRUE,https://github.com/wenjie2wang/jds.rmd,3195,1,2022-07-05T17:03:52Z,3195
jetpack,"Manage project dependencies from your DESCRIPTION file. Create a reproducible virtual environment with minimal additional files in your project. Provides tools to add, remove, and update dependencies as well as install existing dependencies with a single function.",2022-01-28,Andrew Kane,https://github.com/ankane/jetpack,TRUE,https://github.com/ankane/jetpack,16649,225,2022-03-06T20:40:27Z,73.99555555555555
jfa,"Provides statistical audit sampling methods as implemented in JASP for Audit (Derks et al., 2021 <doi:10.21105/joss.02733>). The package makes it easy for an auditor to plan a statistical sample, select the sample from the population, and evaluate the misstatement in the sample compliant with the International Standards on Auditing. Next to classical audit sampling methodology, the package implements Bayesian equivalents of these methods whose statistical underpinnings are described in Derks et al. (2021) <doi:10.1111/ijau.12240>, Derks et al. (2021) <doi:10.31234/osf.io/kzqp5>, and Derks et al. (2022) <doi:10.31234/osf.io/8nf3e>.",2022-06-16,Koen Derks,"https://koenderks.github.io/jfa/, https://github.com/koenderks/jfa",TRUE,https://github.com/koenderks/jfa,18646,5,2022-07-03T21:16:48Z,3729.2
jgcricolors,Color palettes used by the Pacific Northwest National Laboratory - Joint Global Change Research Institute for maps and charts.,2021-09-23,Zarrar Khan,https://github.com/JGCRI/jgcricolors,TRUE,https://github.com/jgcri/jgcricolors,3513,2,2022-01-14T22:43:24Z,1756.5
jinjar,"Template engine powered by the 'inja' C++ library. Users
    write a template document, using syntax inspired by the 'Jinja' Python
    package, and then render the final document by passing data from R.
    The template syntax supports features such as variables, loops,
    conditions and inheritance.",2022-06-25,David Hall,"https://davidchall.github.io/jinjar/,
https://github.com/davidchall/jinjar",TRUE,https://github.com/davidchall/jinjar,3351,17,2022-07-09T22:13:34Z,197.11764705882354
jipApprox,"Approximate joint-inclusion probabilities in Unequal Probability Sampling, or compute Monte Carlo approximations of the first and second-order inclusion probabilities of a general sampling design as in Fattorini (2006) <doi:10.1093/biomet/93.2.269>.",2022-06-12,Roberto Sichera,NA,TRUE,https://github.com/rhobis/jipapprox,13369,0,2022-06-12T06:38:05Z,NA
JLPM,"Estimation of extended joint models with shared random effects. Longitudinal data are handled in latent process models for continuous (Gaussian or curvilinear) and ordinal outcomes while proportional hazard models are used for the survival part. We propose a frequentist approach using maximum likelihood estimation. See Saulnier et al, 2021 <arXiv:2110.02612>.",2022-03-31,Viviane Philipps,NA,TRUE,https://github.com/vivianephilipps/jlpm,798,0,2022-03-30T12:42:55Z,NA
JMbayes2,"Fit joint models for longitudinal and time-to-event data under the Bayesian approach. Multiple longitudinal outcomes of mixed type (continuous/categorical) and multiple event times (competing risks and multi-state processes) are accommodated. Rizopoulos (2012, ISBN:9781439872864).",2022-07-05,Dimitris Rizopoulos,"https://drizopoulos.github.io/JMbayes2/,
https://github.com/drizopoulos/JMbayes2",TRUE,https://github.com/drizopoulos/jmbayes2,9785,31,2022-07-05T10:44:53Z,315.64516129032256
jmcm,"Fit joint mean-covariance models for longitudinal data. The models
    and their components are represented using S4 classes and methods. The core
    computational algorithms are implemented using the 'Armadillo' C++ library
    for numerical linear algebra and 'RcppArmadillo' glue.",2021-01-12,Jianxin Pan,https://github.com/ypan1988/jmcm/,TRUE,https://github.com/ypan1988/jmcm,19424,4,2021-08-24T20:39:42Z,4856
jmv,"A suite of common statistical methods such as descriptives,
    t-tests, ANOVAs, regression, correlation matrices, proportion tests,
    contingency tables, and factor analysis. This package is also useable from
    the 'jamovi' statistical spreadsheet (see <https://www.jamovi.org> for more
    information).",2022-03-29,Ravi Selker,NA,TRUE,https://github.com/jamovi/jmv,88516,43,2022-06-21T16:37:17Z,2058.5116279069766
jmvcore,"A framework for creating rich interactive analyses for the jamovi
    platform (see <https://www.jamovi.org> for more information).",2022-05-31,Jonathon Love,https://www.jamovi.org,TRUE,https://github.com/jamovi/jmvcore,117140,4,2022-06-11T07:36:36Z,29285
jmvReadWrite,"The free and open a statistical spreadsheet 'jamovi' (www.jamovi.org)
    aims to make statistical analyses easy and intuitive. 'jamovi' produces
    syntax that can directly be used in R (in connection with the R-package 'jmv').
    Having import / export routines for the data files 'jamovi' produces ('.omv')
    permits an easy transfer of analyses between 'jamovi' and R.",2022-05-21,Sebastian Jentschke,https://sjentsch.github.io/jmvReadWrite/,TRUE,https://github.com/sjentsch/jmvreadwrite,9420,2,2022-05-30T20:11:25Z,4710
joineR,"Analysis of repeated measurements and time-to-event data via random
    effects joint models. Fits the joint models proposed by Henderson and colleagues
    <doi:10.1093/biostatistics/1.4.465> (single event time) and by Williamson and
    colleagues (2008) <doi:10.1002/sim.3451> (competing risks events time) to a
    single continuous repeated measure. The time-to-event data is modelled using a 
    (cause-specific) Cox proportional hazards regression model with time-varying 
    covariates. The longitudinal outcome is modelled using a linear mixed effects
    model. The association is captured by a latent Gaussian process. The model is 
    estimated using am Expectation Maximization algorithm. Some plotting functions 
    and the variogram are also included. This project is funded by the Medical 
    Research Council (Grant numbers G0400615 and MR/M013227/1).",2021-06-01,Graeme L. Hickey,https://github.com/graemeleehickey/joineR/,TRUE,https://github.com/graemeleehickey/joiner,39575,13,2022-02-16T16:50:09Z,3044.230769230769
joineRML,"Fits the joint model proposed by Henderson and colleagues (2000) 
    <doi:10.1093/biostatistics/1.4.465>, but extended to the case of multiple 
    continuous longitudinal measures. The time-to-event data is modelled using a 
    Cox proportional hazards regression model with time-varying covariates. The 
    multiple longitudinal outcomes are modelled using a multivariate version of the 
    Laird and Ware linear mixed model. The association is captured by a multivariate
    latent Gaussian process. The model is estimated using a Monte Carlo Expectation 
    Maximization algorithm. This project was funded by the Medical Research Council 
    (Grant number MR/M013227/1).",2021-01-05,Graeme L. Hickey,https://github.com/graemeleehickey/joineRML,TRUE,https://github.com/graemeleehickey/joinerml,61861,22,2021-08-24T16:59:51Z,2811.8636363636365
joinet,"Implements high-dimensional multivariate regression by stacked generalisation (Rauschenberger 2021 <doi:10.1093/bioinformatics/btab576>). For positively correlated outcomes, a single multivariate regression is typically more predictive than multiple univariate regressions. Includes functions for model fitting, extracting coefficients, outcome prediction, and performance measurement. If required, install MRCE or remMap from GitHub (<https://github.com/cran/MRCE>, <https://github.com/cran/remMap>).",2021-08-09,Armin Rauschenberger,https://github.com/rauschenberger/joinet,TRUE,https://github.com/rauschenberger/joinet,15833,3,2022-02-17T14:38:41Z,5277.666666666667
JointAI,"Joint analysis and imputation of incomplete data in the Bayesian
    framework, using (generalized) linear (mixed) models and extensions there of,
    survival models, or joint models for longitudinal and survival data, as
    described in Erler, Rizopoulos and Lesaffre (2021) <doi:10.18637/jss.v100.i20>.
    Incomplete covariates, if present, are automatically imputed.
    The package performs some preprocessing of the data and creates a 'JAGS'
    model, which will then automatically be passed to 'JAGS' 
    <https://mcmc-jags.sourceforge.io/> with the help of 
    the package 'rjags'.",2021-11-28,Nicole S. Erler,https://nerler.github.io/JointAI/,TRUE,https://github.com/nerler/jointai,22201,20,2022-05-26T09:21:23Z,1110.05
jordan,"A Jordan algebra is an algebraic object originally
   designed to study observables in quantum mechanics.  Jordan
   algebras are commutative but non-associative; they satisfy the
   Jordan identity.  The package follows the ideas and notation of
   K. McCrimmon (2004, ISBN:0-387-95447-3) ""A Taste of Jordan
   Algebras"".",2021-04-08,Robin K. S. Hankin,https://github.com/RobinHankin/jordan,TRUE,https://github.com/robinhankin/jordan,4401,0,2022-07-02T09:37:42Z,NA
josaplay,"Josa in Korean is often determined by judging the previous word. 
            When writing reports using Rmd, a function that prints the 
            appropriate investigation for each case is helpful. 
            The 'josaplay' package then evaluates the previous word 
            to determine which josa is appropriate.",2019-05-16,Chanyub Park,https://github.com/mrchypark/josaplay,TRUE,https://github.com/mrchypark/josaplay,11215,1,2022-07-08T17:42:29Z,11215
joyn,"Tool for diagnosing table joins. It combines the speed
    `data.table`, the flexibility of `dplyr`, and the diagnosis and features of
    the `merge` command in `Stata`.",2021-12-14,R.Andres Castaneda,https://github.com/randrescastaneda/joyn,TRUE,https://github.com/randrescastaneda/joyn,5342,1,2021-12-13T17:26:51Z,5342
jpgrid,"Provides functions for grid square codes in Japan
    (<https://www.stat.go.jp/english/data/mesh/index.html>).
    Generates the grid square codes from longitude/latitude, geometries, and 
    the grid square codes of different scales, and vice versa.",2022-05-03,Mizuki Uchida,https://github.com/UchidaMizuki/jpgrid,TRUE,https://github.com/uchidamizuki/jpgrid,490,4,2022-06-22T11:41:11Z,122.5
jpmesh,"Helpful functions for using mesh code (80km to 100m) data in Japan. Visualize mesh code using 'ggplot2' and 'leaflet', etc.",2022-01-10,Shinya Uryu,https://uribo.github.io/jpmesh/,TRUE,https://github.com/uribo/jpmesh,31056,33,2022-01-10T08:09:13Z,941.0909090909091
jpstat,"Provides tools for using the API of 'e-Stat' (<https://www.e-stat.go.jp/>), a portal site for Japanese government statistics.
    Includes functions for automatic query generation, data collection and formatting.",2022-05-10,Mizuki Uchida,"https://github.com/UchidaMizuki/jpstat,
https://uchidamizuki.github.io/jpstat/",TRUE,https://github.com/uchidamizuki/jpstat,1290,1,2022-05-22T08:46:38Z,1290
jqr,"Client for 'jq', a 'JSON' processor (<https://stedolan.github.io/jq/>), 
    written in C. 'jq' allows the following with 'JSON' data: index into, parse, 
    do calculations, cut up and filter, change key names and values, perform 
    conditionals and comparisons, and more.",2022-03-10,Jeroen Ooms,"https://docs.ropensci.org/jqr/ (docs),
https://github.com/ropensci/jqr (devel)",TRUE,https://github.com/ropensci/jqr,564978,130,2022-03-10T18:51:25Z,4345.984615384616
jrc,An 'httpuv' based bridge between R and 'JavaScript'. Provides an easy way to exchange commands and data between a web page and a currently running R session. ,2022-01-04,Svetlana Ovchinnikova,https://github.com/anders-biostat/jrc,TRUE,https://github.com/anders-biostat/jrc,18209,16,2022-01-04T14:43:18Z,1138.0625
jrvFinance,"Implements the basic financial analysis
    functions similar to (but not identical to) what
    is available in most spreadsheet software. This
    includes finding the IRR and NPV of regularly
    spaced cash flows and annuities. Bond pricing and
    YTM calculations are included. In addition, Black
    Scholes option pricing and Greeks are also
    provided.",2021-11-05,Jayanth Varma,https://github.com/jrvarma/jrvFinance,TRUE,https://github.com/jrvarma/jrvfinance,30959,10,2021-11-05T13:48:58Z,3095.9
jScore,"The jscore() function in the package calculates the J-Score metric between two clustering
    assignments. The score is designed to address some problems with existing common metrics such 
    as problem of matching. The details of J-score is described in Ahmadinejad and Liu. (2021) <arXiv:2109.01306>.",2021-09-17,Navid Ahmadinejad,https://github.com/liliulab/jscore,TRUE,https://github.com/liliulab/jscore,3125,0,2021-09-06T22:59:51Z,NA
jSDM,"Fits joint species distribution models ('jSDM')
    in a hierarchical Bayesian framework (Warton et al. 2015
    <doi:10.1016/j.tree.2015.09.007>). The Gibbs sampler is written
    in C++. It uses 'Rcpp', 'Armadillo' and 'GSL' to maximize computation
    efficiency.",2022-03-21,Jeanne Clément,"https://ecology.ghislainv.fr/jSDM/,
https://github.com/ghislainv/jSDM",TRUE,https://github.com/ghislainv/jsdm,12879,8,2022-07-08T15:40:27Z,1609.875
jshintr,"Allow to run 'jshint' on 'JavaScript' files with a 'R'
    command or a 'RStudio' addin. The report appears in the 'RStudio'
    viewer pane.",2022-06-10,Stéphane Laurent,https://github.com/stla/jshintr,TRUE,https://github.com/stla/jshintr,234,1,2022-06-10T09:18:20Z,234
jskm,The function 'jskm()' creates publication quality Kaplan-Meier plot with at risk tables below. 'svyjskm()' provides plot for weighted Kaplan-Meier estimator. ,2021-10-11,Jinseob Kim,https://github.com/jinseob2kim/jskm,TRUE,https://github.com/jinseob2kim/jskm,21056,6,2021-12-06T05:02:10Z,3509.3333333333335
JSmediation,"A set of helper functions to conduct joint-significance tests
    for mediation analysis, as recommended by Yzerbyt, Muller, Batailler,
    & Judd. (2018) <doi:10.1037/pspa0000132>.",2021-09-02,Cédric Batailler,"https://jsmediation.cedricbatailler.me/,
https://github.com/cedricbatailler/JSmediation",TRUE,https://github.com/cedricbatailler/jsmediation,14989,6,2021-09-06T10:21:16Z,2498.1666666666665
jsmodule,"'RStudio' addins and 'Shiny' modules for descriptive statistics, regression and survival analysis.",2022-01-06,Jinseob Kim,https://github.com/jinseob2kim/jsmodule,TRUE,https://github.com/jinseob2kim/jsmodule,24431,16,2022-01-07T13:59:21Z,1526.9375
jsonlite,"A reasonably fast JSON parser and generator, optimized for statistical 
    data and the web. Offers simple, flexible tools for working with JSON in R, and
    is particularly powerful for building pipelines and interacting with a web API. 
    The implementation is based on the mapping described in the vignette (Ooms, 2014).
    In addition to converting JSON data from/to R objects, 'jsonlite' contains 
    functions to stream, validate, and prettify JSON data. The unit tests included 
    with the package verify that all edge cases are encoded and decoded consistently 
    for use with dynamic data in systems and applications.",2022-02-22,Jeroen Ooms,https://arxiv.org/abs/1403.2805 (paper),TRUE,https://github.com/jeroen/jsonlite,42132671,323,2022-06-19T10:26:26Z,130441.70588235294
jsonStrings,"Fast manipulation of JSON strings. Allows to extract or delete an element in a JSON string, merge two JSON strings, and more.",2022-04-05,Stéphane Laurent,https://github.com/stla/jsonStrings,TRUE,https://github.com/stla/jsonstrings,4550,3,2022-04-05T12:36:17Z,1516.6666666666667
jsonvalidate,"Uses the node library 'is-my-json-valid' or 'ajv' to
    validate 'JSON' against a 'JSON' schema.  Drafts 04, 06 and 07 of
    'JSON' schema are supported.",2021-11-03,Rich FitzJohn,"https://docs.ropensci.org/jsonvalidate/,
https://github.com/ropensci/jsonvalidate",TRUE,https://github.com/ropensci/jsonvalidate,216821,43,2021-12-20T17:06:58Z,5042.3488372093025
jstable,"Create regression tables from generalized linear model(GLM), generalized estimating equation(GEE), generalized linear mixed-effects model(GLMM), Cox proportional hazards model, survey-weighted generalized linear model(svyglm) and survey-weighted Cox model results for publication.",2021-10-19,Jinseob Kim,https://github.com/jinseob2kim/jstable,TRUE,https://github.com/jinseob2kim/jstable,27577,6,2021-12-06T05:03:00Z,4596.166666666667
jstor,"Functions and helpers to import metadata, ngrams and full-texts 
    delivered by Data for Research by JSTOR. ",2021-12-08,Thomas Klebel,"https://github.com/ropensci/jstor,
https://docs.ropensci.org/jstor/",TRUE,https://github.com/ropensci/jstor,15314,44,2021-12-08T20:12:17Z,348.04545454545456
jsTreeR,"Creates interactive trees that can be included in 'Shiny'
    apps and R markdown documents. A tree allows to represent hierarchical
    data (e.g. the contents of a directory). Similar to the 'shinyTree'
    package but offers more features and options, such as the grid
    extension, restricting the drag-and-drop behavior, and settings for
    the search functionality. It is possible to attach some data to the
    nodes of a tree and then to get these data in 'Shiny' when a node is
    selected. Also provides a 'Shiny' gadget allowing to manipulate one or
    more folders, and a 'Shiny' module allowing to navigate in the server
    side file system.",2022-07-06,Stéphane Laurent,https://github.com/stla/jsTreeR,TRUE,https://github.com/stla/jstreer,10621,28,2022-07-06T21:57:36Z,379.32142857142856
jti,"Minimal and memory efficient implementation of the junction tree
	     algorithm using the Lauritzen-Spiegelhalter scheme;
	     S. L. Lauritzen and D. J. Spiegelhalter (1988) 
	     <https://www.jstor.org/stable/2345762?seq=1>.",2022-04-12,Mads Lindskou,https://github.com/mlindsk/jti,TRUE,https://github.com/mlindsk/jti,9373,1,2022-04-11T18:48:21Z,9373
jtools,"This is a collection of tools for more efficiently understanding 
  and sharing the results of (primarily) regression analyses. There are also a
  number of miscellaneous functions for statistical and programming purposes. 
  Support for models produced by the survey and lme4 packages are points of 
  emphasis.",2022-04-25,Jacob A. Long,https://jtools.jacob-long.com,TRUE,https://github.com/jacob-long/jtools,485623,139,2022-06-22T19:55:28Z,3493.6906474820144
Julia,Generates image data for fractals (Julia and Mandelbrot sets) on the complex plane in the given region and resolution. Benoit B Mandelbrot (1982).,2022-04-19,Mehmet Suzen,https://github.com/msuzen/Julia,TRUE,https://github.com/msuzen/julia,20853,0,2022-04-20T03:43:53Z,NA
JuliaCall,"Provides an R interface to 'Julia',
    which is a high-level, high-performance dynamic programming language
    for numerical computing, see <https://julialang.org/> for more information.
    It provides a high-level interface as well as a low-level interface.
    Using the high level interface, you could call any 'Julia' function just like
    any R function with automatic type conversion. Using the low level interface,
    you could deal with C-level SEXP directly while enjoying the convenience of
    using a high-level programming language like 'Julia'.",2021-05-16,Changcheng Li,https://github.com/Non-Contradiction/JuliaCall,TRUE,https://github.com/non-contradiction/juliacall,177036,215,2022-02-15T11:46:58Z,823.4232558139535
junctions,"Individual based simulations of hybridizing populations,
    where the accumulation of junctions is tracked. Furthermore,
    mathematical equations are provided to verify simulation outcomes.
    Both simulations and mathematical equations are based on Janzen
    (2018, <doi:10.1101/058107>) and Janzen (2020,
    <doi:10.1101/2020.09.10.292441>).",2022-02-24,Thijs Janzen,https//github.com/thijsjanzen/junctions,TRUE,https://github.com/thijsjanzen/junctions,14906,1,2022-02-24T11:19:27Z,14906
JWileymisc,"Miscellaneous tools and functions,
    including: generate descriptive statistics tables,
    format output, visualize relations among variables or check
    distributions, and generic functions for residual and
    model diagnostics. ",2022-05-10,Joshua F. Wiley,"https://joshuawiley.com/JWileymisc/,
https://github.com/JWiley/JWileymisc",TRUE,https://github.com/jwiley/jwileymisc,28569,4,2022-05-10T10:10:05Z,7142.25
kableExtra,"Build complex HTML or 'LaTeX' tables using 'kable()' from 'knitr' 
    and the piping syntax from 'magrittr'. Function 'kable()' is a light weight 
    table generator coming from 'knitr'. This package simplifies the way to 
    manipulate the HTML or 'LaTeX' codes generated by 'kable()' and allows 
    users to construct complex tables and customize styles using a readable 
    syntax. ",2021-02-20,Hao Zhu,"http://haozhu233.github.io/kableExtra/,
https://github.com/haozhu233/kableExtra",TRUE,https://github.com/haozhu233/kableextra,2503926,571,2022-05-26T18:17:45Z,4385.159369527145
kaigiroku,Search and download data from the API for Japanese Diet Proceedings (see the reference at <https://kokkai.ndl.go.jp/api.html>).,2022-06-01,Akitaka Matsuo,https://github.com/amatsuo/kaigiroku,TRUE,https://github.com/amatsuo/kaigiroku,298,7,2022-06-14T13:02:45Z,42.57142857142857
kairos,"A toolkit for absolute dating and analysis of chronological
    patterns. This package includes functions for chronological modeling
    and dating of archaeological assemblages from count data. It provides
    methods for matrix seriation. It also allows to compute time point 
    estimates and density estimates of the occupation and duration of an 
    archaeological site.",2022-06-18,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>,"https://packages.tesselle.org/kairos/,
https://github.com/tesselle/kairos",TRUE,https://github.com/tesselle/kairos,9984,12,2022-06-18T13:17:06Z,832
karel,"This is the R implementation of Karel the robot, a programming 
  language created by Dr. R. E. Pattis at Stanford University in 1981. Karel is 
  an useful tool to teach introductory concepts about general programming, such 
  as algorithmic decomposition, conditional statements, loops, etc., in an 
  interactive and fun way, by writing programs to make Karel the robot achieve 
  certain tasks in the world she lives in. Originally based on Pascal, Karel 
  was implemented in many languages through these decades, including 'Java', 'C++', 
  'Ruby' and 'Python'. This is the first package implementing Karel in R.",2022-03-26,Marcos Prunello,https://mpru.github.io/karel/,TRUE,https://github.com/mpru/karel,4091,3,2022-03-29T12:38:27Z,1363.6666666666667
kayadata,"Provides data for Kaya identity variables (population, gross 
             domestic product, primary energy consumption, and energy-related 
             CO2 emissions) for the world and for individual nations, and 
             utility functions for looking up data,  plotting trends of 
             Kaya variables, and plotting the fuel mix for a given country
             or region. The Kaya identity (Yoichi Kaya and Keiichi Yokobori, 
             ""Environment, Energy, and Economy: Strategies for Sustainability"" 
             (United Nations University Press, 1998) and 
             <https://en.wikipedia.org/wiki/Kaya_identity>) expresses a nation's 
             or region's greenhouse gas emissions in terms of its population, 
             per-capita Gross Domestic Product, the energy intensity of its 
             economy, and the carbon-intensity of its energy supply.",2022-04-14,Jonathan Gilligan,"https://jonathan-g.github.io/kayadata/,
https://github.com/jonathan-g/kayadata",TRUE,https://github.com/jonathan-g/kayadata,15033,0,2022-04-14T23:34:17Z,NA
kde1d,"Provides an efficient implementation of univariate local polynomial
    kernel density estimators that can handle bounded and discrete data. See 
    Geenens (2014) <arXiv:1303.4121>, 
    Geenens and Wang (2018) <arXiv:1602.04862>, 
    Nagler (2018a) <arXiv:1704.07457>, 
    Nagler (2018b) <arXiv:1705.05431>.",2022-03-17,Thomas Nagler,https://github.com/tnagler/kde1d,TRUE,https://github.com/tnagler/kde1d,21433,11,2022-03-16T23:53:37Z,1948.4545454545455
kdtools,"Provides various tools for working with multidimensional
  data in R and C++, including extremely fast nearest-neighbor- and range-
  queries without the overhead of linked tree nodes.",2021-10-08,Timothy Keitt,https://github.com/thk686/kdtools,TRUE,https://github.com/thk686/kdtools,12904,11,2022-06-22T15:15:20Z,1173.090909090909
keras,"Interface to 'Keras' <https://keras.io>, a high-level neural
  networks 'API'. 'Keras' was developed with a focus on enabling fast experimentation,
  supports both convolution based networks and recurrent networks (as well as
  combinations of the two), and runs seamlessly on both 'CPU' and 'GPU' devices.",2022-05-23,Tomasz Kalinowski [ctb,https://keras.rstudio.com,TRUE,https://github.com/rstudio/keras,992115,749,2022-06-28T15:15:41Z,1324.5861148197596
kerastuneR,"'Keras Tuner' <https://keras-team.github.io/keras-tuner/> is a hypertuning framework made for humans. 
             It aims at making the life of AI practitioners, hypertuner 
             algorithm creators and model designers as simple as possible by 
             providing them with a clean and easy to use API for hypertuning. 
             'Keras Tuner' makes moving from a base model to a hypertuned one quick and 
             easy by only requiring you to change a few lines of code.",2022-03-25,Turgut Abdullayev,https://github.com/EagerAI/kerastuneR/,TRUE,https://github.com/eagerai/kerastuner,15039,28,2022-03-25T07:31:00Z,537.1071428571429
kernelboot,"Smoothed bootstrap and functions for random generation from
             univariate and multivariate kernel densities. It does not
             estimate kernel densities.",2020-02-13,Tymoteusz Wolodzko,https://github.com/twolodzko/kernelboot,TRUE,https://github.com/twolodzko/kernelboot,18281,2,2022-06-05T17:45:03Z,9140.5
KernelKnn,Extends the simple k-nearest neighbors algorithm by incorporating numerous kernel functions and a variety of distance metrics. The package takes advantage of 'RcppArmadillo' to speed up the calculation of distances between observations.,2021-10-29,Lampros Mouselimis,https://github.com/mlampros/KernelKnn,TRUE,https://github.com/mlampros/kernelknn,94437,14,2022-02-09T07:09:57Z,6745.5
kernscr,"Kernel Machine Score Test for Pathway Analysis in the Presence of 
    Semi-Competing Risks. Method is detailed in: Neykov, Hejblum & Sinnott (2018) 
    <doi: 10.1177/0962280216653427>.",2019-08-20,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/kernscr,14559,0,2022-04-28T09:02:11Z,NA
kesernetwork,"A shiny app to visualize the knowledge networks for the code concepts. Using co-occurrence matrices of EHR codes from Veterans Affairs (VA) and Massachusetts General Brigham (MGB), the knowledge extraction via sparse embedding regression (KESER) algorithm was used to construct knowledge networks for the code concepts. Background and details about the method can be found at Chuan et al. (2021) <doi:10.1038/s41746-021-00519-z>.",2022-03-03,Su-Chun Cheng,https://github.com/celehs/kesernetwork,TRUE,https://github.com/celehs/kesernetwork,1043,1,2022-06-06T13:35:50Z,1043
keyATM,"Fits keyword assisted topic models (keyATM) using collapsed Gibbs samplers. The keyATM combines the latent dirichlet allocation (LDA) models with a small number of keywords selected by researchers in order to improve the interpretability and topic classification of the LDA. The keyATM can also incorporate covariates and directly model time trends. The keyATM is proposed in Eshima, Imai, and Sasaki (2020) <arXiv:2004.05964>.",2022-06-11,Shusei Eshima,https://keyatm.github.io/keyATM/,TRUE,https://github.com/keyatm/keyatm,13237,59,2022-05-30T05:50:18Z,224.35593220338984
KeyboardSimulator,Control your keyboard and mouse with R code by simulating key presses and mouse clicks. The input simulation is implemented with the Windows API.,2021-01-13,Jim Chen,https://github.com/ChiHangChen/KeyboardSimulator,TRUE,https://github.com/chihangchen/keyboardsimulator,14686,23,2022-04-29T00:37:04Z,638.5217391304348
keyholder,"Tools for keeping track of information, named
    ""keys"", about rows of data frame like objects. This is done by
    creating special attribute ""keys"" which is updated after every change
    in rows (subsetting, ordering, etc.).  This package is designed to
    work tightly with 'dplyr' package.",2021-12-04,Evgeni Chasnovski,"https://echasnovski.github.io/keyholder/,
https://github.com/echasnovski/keyholder/",TRUE,https://github.com/echasnovski/keyholder,15845,7,2021-12-05T08:18:03Z,2263.5714285714284
keys,"Assign and listen to keyboard shortcuts in 'shiny' using the 
  'Mousetrap' Javascript library.",2021-07-11,Tyler Littlefield,https://github.com/r4fun/keys,TRUE,https://github.com/r4fun/keys,8673,31,2022-01-16T22:36:21Z,279.7741935483871
kfa,"Provides functions to explore possible factor structures for a set of variables and
	helps identify plausible and replicable structures via k-fold cross validation. The process 
	combines the exploratory and confirmatory factor analytic approach to scale development 
	(Flora & Flake, 2017) <doi:10.1037/cbs0000069> with a cross validation technique that 
	maximizes the available data. Also available are functions to determine k by drawing on 
	power analytic techniques for covariance structures (MacCallum, Browne, & Sugawara, 1996) 
	<doi:10.1037/1082-989X.1.2.130>, generate model syntax, and summarize results in a report.",2022-02-21,Kyle Nickodem  and Peter Halpin,https://github.com/knickodem/kfa,TRUE,https://github.com/knickodem/kfa,3764,2,2022-04-28T16:43:08Z,1882
KFAS,"State space modelling is an efficient and flexible framework for 
    statistical inference of a broad class of time series and other data. KFAS 
    includes computationally efficient functions for Kalman filtering, smoothing, 
    forecasting, and simulation of multivariate exponential family state space models, 
    with observations from Gaussian, Poisson, binomial, negative binomial, and gamma 
    distributions. See the paper by Helske (2017) <doi:10.18637/jss.v078.i10> for details.",2021-06-07,Jouni Helske,https://github.com/helske/KFAS,TRUE,https://github.com/helske/kfas,649264,50,2022-04-01T07:45:44Z,12985.28
kgrams,"
        Tools for training and evaluating k-gram language models in R, 
        supporting several probability smoothing techniques, 
        perplexity computations, random text generation and more.",2021-11-16,Valerio Gherardi,"https://vgherard.github.io/kgrams/,
https://github.com/vgherard/kgrams",TRUE,https://github.com/vgherard/kgrams,5984,3,2021-11-15T17:00:55Z,1994.6666666666667
KHQ,"The King's Health Questionnaire (KHQ) is a disease-specific, 
  self-administered questionnaire designed specific to assess the impact of 
  Urinary Incontinence (UI) on Quality of Life. The questionnaire was developed 
  by Kelleher and collaborators (1997) <doi:10.1111/j.1471-0528.1997.tb11006.x>. 
  It is a simple, acceptable and reliable measure to use in the clinical setting 
  and a research tool that is useful in evaluating UI treatment outcomes. 
  The KHQ five dimensions (KHQ5D) is a condition-specific preference-based 
  measure developed by Brazier and collaborators (2008) <doi:10.1177/0272989X07301820>. 
  Although not as popular as the SF6D <doi:10.1016/S0895-4356(98)00103-6> and 
  EQ-5D <https://euroqol.org/>, the KHQ5D measures health-related quality of 
  life (HRQoL) specifically for UI, not general conditions like the others 
  two instruments mentioned. The KHQ5D ca be used in the clinical and economic 
  evaluation of health care. The subject self-rates their health in terms of 
  five dimensions: Role Limitation (RL), Physical Limitations (PL), Social 
  Limitations (SL), Emotions (E), and Sleep (S). Frequently the states on these 
  five dimensions are converted to a single utility index using country specific 
  value sets, which can be used in the clinical and economic evaluation of 
  health care as well as in population health surveys. This package provides 
  methods to calculate scores for each dimension of the KHQ; converts KHQ item 
  scores to KHQ5D scores; and also calculates the utility index of the KHQ5D.",2021-08-06,Luiz Augusto Brusaca,https://github.com/augustobrusaca/KHQ,TRUE,https://github.com/augustobrusaca/khq,3560,0,2021-08-09T01:31:21Z,NA
khroma,"Colour schemes ready for each type of data (qualitative,
    diverging or sequential), with colours that are distinct for all
    people, including colour-blind readers. This package provides an
    implementation of Paul Tol (2018) and Fabio Crameri (2018) 
    <doi:10.5194/gmd-11-2541-2018> colour schemes for use with 'graphics' or
    'ggplot2'. It provides tools to simulate colour-blindness and to test
    how well the colours of any palette are identifiable. Several
    scientific thematic schemes (geologic timescale, land cover, FAO
    soils, etc.) are also implemented.",2022-06-18,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>,"https://packages.tesselle.org/khroma/,
https://github.com/tesselle/khroma",TRUE,https://github.com/tesselle/khroma,23669,161,2022-06-18T13:50:51Z,147.01242236024845
kibior,"An interface to store, retrieve, search, join and share datasets, based on Elasticsearch (ES) API. As a decentralized, FAIR and collaborative search engine and database effort, it proposes a simple push/pull/search mechanism only based on ES, a tool which can be deployed on nearly any hardware. It is a high-level R-ES binding to ease data usage using 'elastic' package (S. Chamberlain (2020)) <https://docs.ropensci.org/elastic/>, extends joins from 'dplyr' package (H. Wickham et al. (2020)) <https://dplyr.tidyverse.org/> and integrates specific biological format importation with Bioconductor packages such as 'rtracklayer' (M. Lawrence and al. (2009) <doi:10.1093/bioinformatics/btp328>) <http://bioconductor.org/packages/rtracklayer>, 'Biostrings' (H. Pagès and al. (2020) <doi:10.18129/B9.bioc.Biostrings>) <http://bioconductor.org/packages/Biostrings>, and 'Rsamtools' (M. Morgan and al. (2020) <doi:10.18129/B9.bioc.Rsamtools>) <http://bioconductor.org/packages/Rsamtools>, but also a long list of more common ones with 'rio' (C-h. Chan and al. (2018)) <https://cran.r-project.org/package=rio>.",2021-01-28,Régis Ongaro-Carcy,https://github.com/regisoc/kibior,TRUE,https://github.com/regisoc/kibior,5103,1,2021-08-10T14:47:30Z,5103
kim,"A collection of functions for analyzing data typically collected 
    or used by behavioral scientists. Examples of the functions include
    a function that compares groups in a factorial experimental design,
    a function that conducts (robust) two-way analysis of variance (ANOVA),
    and a function that cleans a data set generated by Qualtrics surveys.
    Some of the functions will require installing additional package(s).
    Such packages and other references are cited within the section
    describing the relevant functions. Many functions in this package
    rely heavily on these two popular R packages:
    Dowle et al. (2021) <https://CRAN.R-project.org/package=data.table>.
    Wickham et al. (2021) <https://CRAN.R-project.org/package=ggplot2>.",2022-07-08,Jin Kim,"https://github.com/jinkim3/kim, https://jinkim.science",TRUE,https://github.com/jinkim3/kim,8956,3,2022-07-10T04:40:29Z,2985.3333333333335
kindisperse,"Functions for simulating and estimating kinship-related dispersal. Based
    on the methods described in M. Jasper, T.L. Schmidt., N.W. Ahmad, S.P. Sinkins & A.A. 
    Hoffmann (2019) <doi:10.1111/1755-0998.13043> ""A genomic approach to inferring kinship 
    reveals limited intergenerational dispersal in the yellow fever mosquito"".
    Assumes an additive variance model of dispersal in two dimensions, compatible with 
    Wright's neighbourhood area. Simple and composite dispersal simulations are supplied, 
    as well as the functions needed to estimate parent-offspring dispersal for simulated or 
    empirical data, and to undertake sampling design for future field studies of dispersal. 
    For ease of use an integrated Shiny app is also included. ",2021-07-28,Moshe-Elijah Jasper,https://github.com/moshejasper/kindisperse,TRUE,https://github.com/moshejasper/kindisperse,5556,1,2021-10-12T03:30:03Z,5556
kit,"Basic functions, implemented in C, for large data manipulation. Fast vectorised ifelse()/nested if()/switch() functions, psum()/pprod() functions equivalent to pmin()/pmax() plus others which are missing from base R. Most of these functions are callable at C level.",2022-03-27,Morgan Jacob,NA,TRUE,https://github.com/2005m/kit,43721,34,2022-05-15T21:30:28Z,1285.9117647058824
kiwisR,"A wrapper for querying 'WISKI' databases via the 'KiWIS' 'REST' API. 'WISKI' is an 'SQL' relational database 
  used for the collection and storage of water data developed by KISTERS and 'KiWIS' is a 'REST' service that provides
  access to 'WISKI' databases via HTTP requests (<https://water.kisters.de/en/technology-trends/kisters-and-open-data/>). 
  Contains a list of default databases (called 'hubs') and also allows users to provide their own 'KiWIS' URL. 
  Supports the entire query process- from metadata to specific time series values. All data is returned as tidy tibbles.",2020-07-13,Ryan Whaley,https://github.com/rywhale/kiwisR,TRUE,https://github.com/rywhale/kiwisr,15218,7,2022-03-21T14:06:34Z,2174
klassR,"Functions to search, retrieve and apply classifications 
  and codelists using Statistics Norway's API <https://www.ssb.no/klass> 
  from the system 'KLASS'. Retrieves classifications by date with options 
  to choose language, hierarchical level and formatting.",2022-06-08,Susie Jentoft,NA,TRUE,https://github.com/statisticsnorway/klassr,17028,2,2022-06-01T06:23:52Z,8514
klausuR,"A set of functions designed to quickly generate results of a multiple choice
          test. Generates detailed global results, lists for anonymous feedback and
          personalised result feedback (in LaTeX and/or PDF format), as well as item
          statistics like Cronbach's alpha or disciminatory power. 'klausuR' also
          includes a plugin for the R GUI and IDE RKWard, providing graphical dialogs for
          its basic features. The respective R package 'rkward' cannot be installed
          directly from a repository, as it is a part of RKWard. To make full use of this
          feature, please install RKWard from <https://rkward.kde.org> (plugins are
          detected automatically). Due to some restrictions on CRAN, the full package
          sources are only available from the project homepage.",2022-04-04,m.eik michalke,https://reaktanz.de/?c=hacking&s=klausuR,TRUE,https://github.com/undocumeantit/klausur,15960,0,2022-04-12T15:21:11Z,NA
klexdatr,"Six relational 'tibbles' from the Kootenay Lake Large Trout Exploitation study.
  The study which ran from 2008 to 2014 caught, tagged and released large Rainbow Trout and Bull Trout
  in Kootenay Lake by boat angling. 
  The fish were tagged with internal acoustic tags and/or high reward external tags
  and subsequently detected by an acoustic receiver array as well as reported by anglers.
  The data are analysed by Thorley and Andrusak (1994) <doi:10.7717/peerj.2874>
  to estimate the natural and fishing mortality of both species.",2021-05-29,Joe Thorley,https://github.com/poissonconsulting/klexdatr,TRUE,https://github.com/poissonconsulting/klexdatr,9540,0,2021-09-09T21:16:08Z,NA
KLexp,"Provides the function to calculate the kernel-lasso expansion, Z-score, and max-min-scale standardization.It can increase the dimension of existed dataset and remove abundant features by lasso. Z Dai, L Jiayi, T Gong, C Wang (2021) <doi:10.1088/1742-6596/1955/1/012047>.",2021-08-21,Zongrui Dai,https://github.com/Zongrui-Dai/Kernel-lasso-feature-expansion,TRUE,https://github.com/zongrui-dai/kernel-lasso-feature-expansion,3301,1,2021-08-24T03:26:03Z,3301
kmscv,An 'rsample' extension to create cluster based stratified resamples for cross-validation. ,2022-06-28,Samet Sokel,NA,TRUE,https://github.com/sametsoekel/kmscv,144,1,2022-06-20T10:29:03Z,144
KMunicate,"Produce Kaplan–Meier plots in the style recommended
    following the KMunicate study by Morris et al. (2019)
    <doi:10.1136/bmjopen-2019-030215>. The KMunicate style consists of
    Kaplan-Meier curves with confidence intervals to quantify uncertainty
    and an extended risk table (per treatment arm) depicting the number of
    study subjects at risk, events, and censored observations over time.
    The resulting plots are built using 'ggplot2' and can be further
    customised to a certain extent, including themes, fonts, and colour
    scales.",2021-04-23,Alessandro Gasparini,https://ellessenne.github.io/KMunicate-package/,TRUE,https://github.com/ellessenne/kmunicate-package,9496,5,2021-12-01T08:48:10Z,1899.2
knitr,"Provides a general-purpose tool for dynamic report generation in R
    using Literate Programming techniques.",2022-04-26,Yihui Xie,https://yihui.org/knitr/,TRUE,https://github.com/yihui/knitr,27846881,2195,2022-06-30T15:36:15Z,12686.506150341685
knitrdata,"Implements a data language engine for incorporating data directly in 
    'rmarkdown' documents so that they can be made completely standalone.",2020-12-08,David M. Kaplan,https://github.com/dmkaplan2000/knitrdata,TRUE,https://github.com/dmkaplan2000/knitrdata,11493,5,2021-11-05T15:12:38Z,2298.6
knnwtsim,"Functions to implement K Nearest Neighbor forecasting using a weighted similarity metric tailored to the problem of forecasting univariate time series where recent observations, seasonal patterns, and exogenous predictors are all relevant in predicting future observations of the series in question. For more information on the formulation of this similarity metric please see Trupiano (2021) <arXiv:2112.06266>.",2022-03-05,Matthew Trupiano,https://github.com/mtrupiano1/knnwtsim,TRUE,https://github.com/mtrupiano1/knnwtsim,2145,1,2022-03-06T17:02:10Z,2145
KoboconnectR,"Wrapper for 'Kobotoolbox' APIs ver 2 mentioned at <https://support.kobotoolbox.org/api.html>, to download data from 'Kobotoolbox' to R. Small and simple package that adds immense convenience for the data professionals using 'Kobotoolbox'.",2022-05-23,Asitav Sen,https://github.com/asitav-sen/KoboconnectR,TRUE,https://github.com/asitav-sen/koboconnectr,1257,4,2022-05-26T18:07:41Z,314.25
kofdata,"Read Swiss time series data from the 'KOF Data' API, <https://datenservice.kof.ethz.ch>. The API provides macro economic time series data mostly about Switzerland. The package itself is a set of wrappers around the 'KOF Datenservice' API. The 'kofdata' package is able to consume public information as well as data that requires an API token. ",2022-04-29,Matthias Bannert,https://github.com/KOF-ch/kofdata,TRUE,https://github.com/kof-ch/kofdata,14355,3,2022-04-29T07:37:46Z,4785
komaletter,"Write beautiful yet customizable letters in R Markdown and
  directly obtain the finished PDF. Smooth generation of PDFs is realized by
  'rmarkdown', the 'pandoc-letter' template and the 'KOMA-Script' letter class.
  'KOMA-Script' provides enhanced replacements for the standard 'LaTeX' classes
  with emphasis on typography and versatility. 'KOMA-Script' is particularly
  useful for international writers as it handles various paper formats well, 
  provides layouts for many common window envelope types (e.g. German, US, 
  French, Japanese) and lets you define your own layouts. The package comes 
  with a default letter layout based on 'DIN 5008B'.",2021-02-02,Robert Nuske,https://github.com/rnuske/komaletter,TRUE,https://github.com/rnuske/komaletter,16787,77,2022-01-21T15:11:35Z,218.01298701298703
konfound,"Statistical methods that quantify the conditions necessary to alter
    inferences, also known as sensitivity analysis, are becoming increasingly
    important to a variety of quantitative sciences. A series of recent works,
    including Frank (2000) <doi:10.1177/0049124100029002001> and Frank et al.
    (2013) <doi:10.3102/0162373713493129> extend previous sensitivity analyses
    by considering the characteristics of omitted variables or unobserved cases
    that would change an inference if such variables or cases were observed. These
    analyses generate statements such as ""an omitted variable would have to be
    correlated at xx with the predictor of interest (e.g., treatment) and outcome
    to invalidate an inference of a treatment effect"". Or ""one would have to replace
    pp percent of the observed data with null hypothesis cases to invalidate the
    inference"". We implement these recent developments of sensitivity analysis and
    provide modules to calculate these two robustness indices and generate such
    statements in R. In particular, the functions konfound(), pkonfound() and 
    mkonfound() allow users to calculate the robustness of inferences for a user's 
    own model, a single published study and multiple studies respectively.",2021-06-01,Joshua M Rosenberg,https://github.com/jrosen48/konfound,TRUE,https://github.com/jrosen48/konfound,20848,12,2022-03-24T04:49:43Z,1737.3333333333333
kselection,"Selection of k in k-means clustering based on Pham et al. paper
    ``Selection of k in k-means clustering''.",2022-05-16,Daniel Rodriguez,https://github.com/drodriguezperez/kselection,TRUE,https://github.com/drodriguezperez/kselection,16215,7,2022-05-17T16:15:12Z,2316.4285714285716
ksharp,"Clustering typically assigns data points into discrete groups, but the clusters can sometimes be indistinct. Cluster sharpening adjusts an existing clustering to create contrast between groups. This package provides a general interface for cluster sharpening along with several implementations based on different excision criteria.",2020-01-26,Tomasz Konopka,https://github.com/tkonopka/ksharp,TRUE,https://github.com/tkonopka/ksharp,11186,3,2021-12-10T08:10:01Z,3728.6666666666665
kssa,"Implements the Known Sub-Sequence Algorithm <doi:10.1016/j.aaf.2021.12.013>, which helps to automatically identify and validate the best method for missing data imputation in a time series. Supports the comparison of multiple state-of-the-art algorithms.",2022-06-21,Iván Felipe Benavides,https://github.com/pipeben/kssa,TRUE,https://github.com/pipeben/kssa,179,0,2022-06-16T20:02:38Z,NA
labelled,"Work with labelled data imported from 'SPSS'
    or 'Stata' with 'haven' or 'foreign'. This package
    provides useful functions to deal with ""haven_labelled"" and
    ""haven_labelled_spss"" classes introduced by 'haven' package.",2022-05-05,Joseph Larmarange,http://larmarange.github.io/labelled/,TRUE,https://github.com/larmarange/labelled,1961285,60,2022-06-15T15:38:35Z,32688.083333333332
lablaster,"Imports a data frame containing a single time resolved laser ablation mass spectrometry analysis of a foraminifera (or other carbonate shell), then detects when the laser has burnt through the foraminifera test as a function of change in signal over time.",2022-06-23,Alex Searle-Barnes  (<https://orcid.org/0000-0003-0389-7717>,https://github.com/alexsb1/lablaster,TRUE,https://github.com/alexsb1/lablaster,153,0,2022-06-24T12:07:05Z,NA
labourR,"Allows the user to map multilingual free-text of occupations to a broad range
    of standardized classifications. The package facilitates automatic occupation coding
    (see, e.g., Gweon et al. (2017) <doi:10.1515/jos-2017-0006> and Turrell et al. (2019)
    <doi:10.3386/w25837>), where the ISCO to ESCO mapping is exploited to extend the
    occupations hierarchy, Le Vrang et al. (2014) <doi:10.1109/mc.2014.283>. Document
    vectorization is performed using the multilingual ESCO corpus. A method based on the 
    nearest neighbor search is used to suggest the closest ISCO occupation.",2020-07-18,Alexandros Kouretsis,https://github.com/AleKoure/labourR,TRUE,https://github.com/alekoure/labourr,10404,21,2022-02-09T21:17:52Z,495.42857142857144
lacrmr,"Connect to the 'Less Annoying CRM' API with ease to get your crm data in a clean and tidy format. 'Less Annoying CRM' is a simple CRM built for small businesses, more information is available on their website <https://www.lessannoyingcrm.com/>.",2022-05-25,Ronny Hernández Mora,https://ixpantia.github.io/lacrmr/,TRUE,https://github.com/ixpantia/lacrmr,7073,1,2022-06-13T01:33:10Z,7073
lacunaritycovariance,"Functions for estimating the gliding box lacunarity (GBL),
    covariance, and pair-correlation of a random closed set (RACS) in 2D
    from a binary coverage map (e.g. presence-absence land cover maps).
    Contains a number of newly-developed covariance-based estimators of
    GBL (Hingee et al., 2019) <doi:10.1007/s13253-019-00351-9> and
    balanced estimators, proposed by Picka (2000)
    <http://www.jstor.org/stable/1428408>, for covariance, centred
    covariance, and pair-correlation.  Also contains methods for
    estimating contagion-like properties of RACS and simulating 2D Boolean
    models.  Binary coverage maps are usually represented as raster images
    with pixel values of TRUE, FALSE or NA, with NA representing
    unobserved pixels.  A demo for extracting such a binary map from a
    geospatial data format is provided.  Binary maps may also be
    represented using polygonal sets as the foreground, however for most
    computations such maps are converted into raster images.  The package
    is based on research conducted during the author's PhD studies.",2022-02-15,Kassel Liam Hingee,https://github.com/kasselhingee/lacunaritycovariance,TRUE,https://github.com/kasselhingee/lacunaritycovariance,14756,1,2022-02-02T06:37:26Z,14756
LAGOSNE,"Client for programmatic access to the Lake
    Multi-scaled Geospatial and Temporal database <https://lagoslakes.org>, with functions
    for accessing lake water quality and ecological context data for the US.",2020-11-29,Joseph Stachelek,https://github.com/cont-limno/LAGOSNE,TRUE,https://github.com/cont-limno/lagosne,17218,10,2021-09-08T02:19:01Z,1721.8
Lahman,"Provides the tables from the 'Sean Lahman Baseball Database' as
    a set of R data.frames. It uses the data on pitching, hitting and fielding
    performance and other tables from 1871 through 2021, as recorded in the 2022
    version of the database. Documentation examples show how many baseball
    questions can be investigated.",2022-04-26,Chris Dalzell,https://CRAN.R-project.org/package=Lahman,TRUE,https://github.com/cdalzell/lahman,760193,63,2022-04-26T00:14:31Z,12066.555555555555
lakemorpho,"Lake morphometry metrics are used by limnologists to understand,
    among other things, the ecological processes in a lake. Traditionally, these
    metrics are calculated by hand, with planimeters, and increasingly with
    commercial GIS products. All of these methods work; however, they are either
    outdated, difficult to reproduce, or require expensive licenses to use. The
    'lakemorpho' package provides the tools to calculate a typical suite
    of these metrics from an input elevation model and lake polygon. The metrics
    currently supported are: fetch, major axis, minor axis, major/minor axis 
    ratio, maximum length, maximum width, mean width, maximum depth, mean depth, 
    shoreline development, shoreline length, surface area, and volume.",2021-09-23,Jeffrey W. Hollister,https://github.com/jhollist/lakemorpho/,TRUE,https://github.com/jhollist/lakemorpho,15546,11,2022-04-25T16:50:14Z,1413.2727272727273
LAM,"
    Includes some procedures for latent variable modeling with a 
    particular focus on multilevel data.
    The 'LAM' package contains mean and covariance structure modelling
    for multivariate normally distributed data (mlnormal(); Longford, 1987;
    <doi:10.1093/biomet/74.4.817>), a general Metropolis-Hastings algorithm 
    (amh(); Roberts & Rosenthal, 2001, <doi:10.1214/ss/1015346320>) and 
    penalized maximum likelihood estimation (pmle(); Cole, Chu & Greenland, 
    2014; <doi:10.1093/aje/kwt245>).",2022-05-18,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/LAM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/lam,19837,4,2022-05-19T10:21:37Z,4959.25
lambdr,"Runtime for serving containers that can execute R code on the 
    'AWS Lambda' serverless compute service <https://aws.amazon.com/lambda/>.
    Provides the necessary functionality for handling the various endpoints
    required for accepting new input and sending responses.",2022-04-23,David Neuzerling,"https://lambdr.mdneuzerling.com/,
https://github.com/mdneuzerling/lambdr",TRUE,https://github.com/mdneuzerling/lambdr,2308,84,2022-05-29T00:21:32Z,27.476190476190474
lamW,"Implements both real-valued branches of the Lambert-W function
    (Corless et al, 1996) <doi:10.1007/BF02124750> without the need for
    installing the entire GSL.",2022-01-19,Avraham Adler,https://github.com/aadler/lamW,TRUE,https://github.com/aadler/lamw,464457,1,2022-04-24T14:32:22Z,464457
Landmarking,"The landmark approach allows survival predictions to be
	updated dynamically as new measurements from an individual are recorded.
	The idea is to set predefined time points, known as ""landmark times"",
	and form a model at each landmark time using only the individuals in the
	risk set. This package allows the longitudinal data to be modelled
	either using the last observation carried forward or linear mixed
	effects modelling. There is also the option to model competing risks,
	either through cause-specific Cox regression or Fine-Gray regression.
	To find out more about the methods in this package, please see 
	<https://isobelbarrott.github.io/Landmarking/articles/Landmarking>.",2022-02-15,Isobel Barrott,https://github.com/isobelbarrott/Landmarking/,TRUE,https://github.com/isobelbarrott/landmarking,1207,1,2022-06-02T06:11:29Z,1207
landscapemetrics,"Calculates landscape metrics for categorical landscape patterns in 
    a tidy workflow. 'landscapemetrics' reimplements the most common metrics from
    'FRAGSTATS' (<https://www.umass.edu/landeco/research/fragstats/fragstats.html>) 
    and new ones from the current literature on landscape metrics.
    This package supports 'raster' spatial objects and takes 
    RasterLayer, RasterStacks, RasterBricks or lists of RasterLayer from the
    'raster' package as input arguments. It further provides utility functions
    to visualize patches, select metrics and building blocks to develop new 
    metrics.",2021-09-03,Maximillian H.K. Hesselbarth,https://r-spatialecology.github.io/landscapemetrics/,TRUE,https://github.com/r-spatialecology/landscapemetrics,54848,190,2022-01-18T08:37:36Z,288.6736842105263
landscapetools,"Provides utility functions for some of the less-glamorous tasks involved
    in landscape analysis. It includes functions to coerce raster data to the
    common tibble format and vice versa, it helps with flexible reclassification
    tasks of raster data and it provides a function to merge multiple raster.
    Furthermore, 'landscapetools' helps landscape scientists to visualize their
    data by providing optional themes and utility functions to plot single
    landscapes, rasterstacks, -bricks and lists of raster.",2019-02-25,Marco Sciaini,https://ropensci.github.io/landscapetools/,TRUE,https://github.com/ropensci/landscapetools,21028,45,2022-03-28T20:19:18Z,467.2888888888889
langevitour,"
    An HTML widget that randomly tours 2D projections of numerical data. A random walk through projections of the data is shown. The user can manipulate the plot to use specified axes, or turn on projection pursuit to find an informative projection of the data. Groups within the data can be hidden or shown, as can particular axes. Known projections of interest can be added as ""extra axes"" and also manipulated. The underlying method to produce the random walk and projection pursuit uses Langevin dynamics. The widget can be used from within R, or included in a self-contained Rmarkdown document, or used in a Shiny app.",2022-05-09,Paul Harrison,https://logarithmic.net/langevitour/,TRUE,https://github.com/pfh/langevitour,1204,7,2022-07-09T23:10:43Z,172
languageserver,"An implementation of the Language Server Protocol
    for R. The Language Server protocol is used by an editor client to
    integrate features like auto completion. See
    <https://microsoft.github.io/language-server-protocol/> for details.",2022-05-24,Randy Lai,https://github.com/REditorSupport/languageserver/,TRUE,https://github.com/reditorsupport/languageserver,197608,452,2022-06-28T00:44:51Z,437.1858407079646
LaplacesDemon,Provides a complete environment for Bayesian inference using a variety of different samplers (see ?LaplacesDemon for an overview).,2021-07-09,Henrik Singmann,https://github.com/LaplacesDemonR/LaplacesDemon,TRUE,https://github.com/laplacesdemonr/laplacesdemon,233427,78,2022-06-07T13:40:16Z,2992.653846153846
lares,"Auxiliary package for better/faster analytics, visualization, data mining, and machine
    learning tasks. With a wide variety of family functions, like Machine Learning, Data Wrangling,
    Exploratory, API, and Scrapper, it helps the analyst or data scientist to get quick and robust
    results, without the need of repetitive coding or extensive R programming skills.",2022-04-05,Bernardo Lares,"https://github.com/laresbernardo/lares,
https://laresbernardo.github.io/lares/",TRUE,https://github.com/laresbernardo/lares,33221,205,2022-06-01T16:53:22Z,162.05365853658537
latentnet,"Fit and simulate latent position and cluster models for statistical networks. See Krivitsky and Handcock (2008) <doi:10.18637/jss.v024.i05> and Krivitsky, Handcock, Raftery, and Hoff (2009) <doi:10.1016/j.socnet.2009.04.001>.",2022-05-11,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/latentnet,74869,16,2022-05-13T06:07:14Z,4679.3125
later,"Executes arbitrary R or C functions some time after the current
    time, after the R execution stack has emptied. The functions are scheduled
    in an event loop.",2021-08-18,Winston Chang,https://github.com/r-lib/later,TRUE,https://github.com/r-lib/later,12606302,130,2022-02-14T14:30:21Z,96971.55384615385
latex2exp,"Parses and converts LaTeX math formulas to R's plotmath
    expressions, used to enter mathematical formulas and symbols to be rendered as
    text, axis labels, etc. throughout R's plotting system.",2022-03-02,Stefano Meschiari,"https://www.stefanom.io/latex2exp/,
https://github.com/stefano-meschiari/latex2exp",TRUE,https://github.com/stefano-meschiari/latex2exp,216529,166,2022-03-02T23:26:36Z,1304.3915662650602
latrend,"A framework for clustering longitudinal datasets in a standardized way. 
    The package provides an interface to existing R packages for clustering longitudinal univariate trajectories, facilitating reproducible and transparent analyses. 
    Additionally, standard tools are provided to support cluster analyses, including repeated estimation, model validation, and model assessment. 
    The interface enables users to compare results between methods, and to implement and evaluate new methods with ease.",2022-07-04,Niek Den Teuling,https://github.com/philips-software/latrend,TRUE,https://github.com/philips-software/latrend,6973,14,2022-07-04T10:09:21Z,498.07142857142856
lattice,"A powerful and elegant high-level data visualization
  system inspired by Trellis graphics, with an emphasis on
  multivariate data. Lattice is sufficient for typical graphics needs,
  and is also flexible enough to handle most nonstandard requirements.
  See ?Lattice for an introduction.",2021-09-22,Deepayan Sarkar,http://lattice.r-forge.r-project.org/,TRUE,https://github.com/deepayan/lattice,2883043,50,2021-10-12T15:20:41Z,57660.86
lava,"A general implementation of Structural Equation Models
	with latent variables (MLE, 2SLS, and composite likelihood
	estimators) with both continuous, censored, and ordinal
	outcomes (Holst and Budtz-Joergensen (2013) <doi:10.1007/s00180-012-0344-y>).
	Mixture latent variable models and non-linear latent variable models
	(Holst and Budtz-Joergensen (2019) <doi:10.1093/biostatistics/kxy082>).
	The package also provides methods for graph exploration (d-separation,
	back-door criterion), simulation of general non-linear latent variable
	models, and estimation of influence functions for a broad range of
	statistical models.",2021-09-02,Klaus K. Holst,https://kkholst.github.io/lava/,TRUE,https://github.com/kkholst/lava,3579772,27,2022-04-30T14:15:35Z,132584.14814814815
lavaanPlot,"Plots path diagrams from models in 'lavaan' using the plotting
    functionality from the 'DiagrammeR' package. 'DiagrammeR' provides nice path diagrams 
    via 'Graphviz', and these functions make it easy to generate these diagrams from a
    'lavaan' path model without having to write the DOT language graph specification.",2021-08-13,Alex Lishinski,https://github.com/alishinski/lavaanPlot,TRUE,https://github.com/alishinski/lavaanplot,45483,31,2022-04-14T13:54:49Z,1467.1935483870968
lavacreg,"Estimation of a multi-group count regression models (i.e., Poisson, 
    negative binomial) with latent covariates. This packages provides two extensions
    compared to ordinary count regression models based on a generalized linear model:
    First, measurement models for the predictors can be specified allowing to account 
    for measurement error. Second, the count regression can be simultaneously estimated 
    in multiple groups with stochastic group weights. The marginal maximum likelihood 
    estimation is described in Kiefer & Mayer (2020) <doi:10.1080/00273171.2020.1751027>.",2021-08-19,Christoph Kiefer,https://github.com/chkiefer/lavacreg,TRUE,https://github.com/chkiefer/lavacreg,5735,3,2021-08-20T12:53:28Z,1911.6666666666667
lavaSearch2,"Tools for model specification in the latent variable framework
    (add-on to the 'lava' package). The package contains three main functionalities:
    Wald tests/F-tests with improved control of the type 1 error in small samples,
    adjustment for multiple comparisons when searching for local dependencies,
    and adjustment for multiple comparisons when doing inference for multiple latent variable models. ",2020-07-31,Brice Ozenne,https://github.com/bozenne/lavaSearch2,TRUE,https://github.com/bozenne/lavasearch2,62577,0,2022-02-01T13:14:57Z,NA
LAWBL,"A variety of models to analyze latent variables based on Bayesian learning: the partially CFA (Chen, Guo, Zhang, & Pan, 2020) <DOI: 10.1037/met0000293>; generalized PCFA; partially confirmatory IRM (Chen, 2020) <DOI: 10.1007/s11336-020-09724-3>; Bayesian regularized EFA <DOI: 10.1080/10705511.2020.1854763>; Fully and partially EFA.",2022-05-16,Jinsong Chen,"https://github.com/Jinsong-Chen/LAWBL,
https://jinsong-chen.github.io/LAWBL/",TRUE,https://github.com/jinsong-chen/lawbl,10999,2,2022-06-28T11:43:47Z,5499.5
lax,"Performs adjusted inferences based on model objects fitted, using 
    maximum likelihood estimation, by the extreme value analysis packages
    'eva' <https://cran.r-project.org/package=eva>, 
    'evd' <https://cran.r-project.org/package=evd>, 
    'evir' <https://cran.r-project.org/package=evir>, 
    'extRemes' <https://cran.r-project.org/package=extRemes>, 
    'fExtremes' <https://cran.r-project.org/package=fExtremes>, 
    'ismev' <https://cran.r-project.org/package=ismev>, 
    'mev' <https://cran.r-project.org/package=mev>, 
    'POT' <https://cran.r-project.org/package=POT> and
    'texmex' <https://cran.r-project.org/package=texmex>. 
    Adjusted standard errors and an adjusted loglikelihood are provided, using    
    the 'chandwich' package <https://cran.r-project.org/package=chandwich>
    and the object-oriented features of the 'sandwich' package 
    <https://cran.r-project.org/package=sandwich>. The adjustment is based on a 
    robust sandwich estimator of the parameter covariance matrix, based on the 
    methodology in Chandler and Bate (2007) <doi:10.1093/biomet/asm015>. This 
    can be used for cluster correlated data when interest lies in the 
    parameters of the marginal distributions, or for performing inferences that 
    are robust to certain types of model misspecification.  Univariate extreme 
    value models, including regression models, are supported.  ",2021-07-20,Paul J. Northrop,"https://paulnorthrop.github.io/lax/,
https://github.com/paulnorthrop/lax",TRUE,https://github.com/paulnorthrop/lax,12908,2,2022-04-03T15:17:10Z,6454
lazyraster,"Read raster data at a specified resolution on-demand via 'GDAL' 
 (the Geospatial Data Abstraction Library <https://gdal.org/>). Augments the 
 'raster' package by never reading data from a raster source until necessary for 
 generating an in-memory 'raster' object. A 'lazyraster' object may be cropped 
 and converted to 'raster' object, and by default will only read a small amount 
 of data sufficient for an overall summary. The amount of data read can be 
 controlled by specifying the output dimensions. ",2021-10-07,Michael Sumner,https://github.com/hypertidy/lazyraster,TRUE,https://github.com/hypertidy/lazyraster,12707,26,2021-09-07T01:47:19Z,488.7307692307692
lazysf,"Lazy read for drawings. A 'dplyr' back end for data sources supported by 
    'GDAL' vector drivers, that allows working with local or remote sources as if they 
    are in-memory data frames. Basic features works with any drawing format ('GDAL vector 
    data source') supported by the 'sf' package. ",2020-11-14,Michael Sumner,https://github.com/mdsumner/lazysf,TRUE,https://github.com/mdsumner/lazysf,6277,16,2021-11-17T04:12:56Z,392.3125
lazytrade,"Provide sets of functions and methods to learn and practice data science using idea of algorithmic trading.
    Main goal is to process information within ""Decision Support System"" to come up with analysis or predictions.
    There are several utilities such as dynamic and adaptive risk management using reinforcement learning
    and even functions to generate predictions of price changes using pattern recognition deep regression learning.
    Summary of Methods used: Awesome H2O tutorials: <https://github.com/h2oai/awesome-h2o>, 
    Market Type research of Van Tharp Institute: <https://www.vantharp.com/>,
    Reinforcement Learning R package: <https://CRAN.R-project.org/package=ReinforcementLearning>.",2021-12-15,Vladimir Zhbanko,"https://vladdsm.github.io/myblog_attempt/topics/lazy%20trading/,
https://github.com/vzhomeexperiments/lazytrade",TRUE,https://github.com/vzhomeexperiments/lazytrade,21087,19,2021-12-18T08:40:36Z,1109.842105263158
lba,"Latent budget analysis is a method for the analysis of a two-way
    contingency table with an exploratory variable and a response variable. It is
    specially designed for compositional data.",2022-05-12,Enio G. Jelihovschi,https://github.com/ivanalaman/lba,TRUE,https://github.com/ivanalaman/lba,16693,1,2022-05-12T21:21:35Z,16693
LBSPR,"Simulate expected equilibrium length composition, yield-per-recruit, and
    the spawning potential ratio (SPR) using the length-based SPR (LBSPR) model. Fit the LBSPR
    model to length data to estimate  selectivity, relative apical fishing mortality, and
    the spawning potential ratio for data-limited fisheries.
    See Hordyk et al (2016) <doi:10.1139/cjfas-2015-0422> for more information about the
    LBSPR assessment method.",2021-10-06,Adrian Hordyk,https://github.com/AdrianHordyk/LBSPR,TRUE,https://github.com/adrianhordyk/lbspr,17688,5,2022-05-16T16:53:35Z,3537.6
lcmm,"Estimation of various extensions of the mixed models including latent class mixed models, joint latent latent class mixed models, mixed models for curvilinear outcomes, mixed models for multivariate longitudinal outcomes using a maximum likelihood estimation method (Proust-Lima, Philipps, Liquet (2017) <doi:10.18637/jss.v078.i02>).",2022-06-24,Cecile Proust-Lima,NA,TRUE,https://github.com/cecileproust-lima/lcmm,66997,18,2022-07-08T13:32:56Z,3722.0555555555557
lconnect,"Provides functions to upload vectorial data and derive landscape
    connectivity metrics in habitat or matrix systems. Additionally, includes an 
    approach to assess individual patch contribution to the overall landscape 
    connectivity, enabling the prioritization of habitat patches. The computation
    of landscape connectivity and patch importance are very useful in Landscape 
    Ecology research. The metrics available are: number of components, number of 
    links, size of the largest component, mean size of components, class coincidence
    probability, landscape coincidence probability, characteristic path length, 
    expected cluster size, area-weighted flux and integral index of connectivity.
    Pascual-Hortal, L., and Saura, S. (2006) <doi:10.1007/s10980-006-0013-z>
    Urban, D., and Keitt, T. (2001) <doi:10.2307/2679983>
    Laita, A., Kotiaho, J., Monkkonen, M. (2011) <doi:10.1007/s10980-011-9620-4>.",2021-02-06,Frederico Mestre,NA,TRUE,https://github.com/fmestre1/lconnect,13265,4,2021-09-02T11:14:10Z,3316.25
lcopula,"Collections of functions allowing random number generations and
    estimation of 'Liouville' copulas, as described in Belzile and Neslehova (2017) <doi:10.1016/j.jmva.2017.05.008>.",2022-04-25,Leo Belzile,NA,TRUE,https://github.com/lbelzile/lcopula,62861,0,2022-04-25T17:41:45Z,NA
lcra,"For fitting Bayesian joint latent class and regression models using
    Gibbs sampling. See the documentation for the model.
    The technical details of the model implemented here are described in Elliott,
    Michael R., Zhao, Zhangchen, Mukherjee, Bhramar, Kanaya, Alka, Needham,
    Belinda L., ""Methods to account for uncertainty in latent class assignments when
    using latent classes as predictors in regression models, with application to
    acculturation strategy measures"" (2020) In press at Epidemiology
    <doi:10.1097/EDE.0000000000001139>.",2020-08-07,Michael Kleinsasser,https://github.com/umich-biostatistics/lcra,TRUE,https://github.com/umich-biostatistics/lcra,7624,0,2021-09-22T13:41:12Z,NA
lcsm,"Helper functions to implement univariate and bivariate latent change score models in R using the 'lavaan' package.
  For details about Latent Change Score Modeling (LCSM) see McArdle (2009) <doi:10.1146/annurev.psych.60.110707.163612> and Grimm, An, McArdle, Zonderman and Resnick (2012) <doi:10.1080/10705511.2012.659627>.
  The package automatically generates 'lavaan' syntax for different model specifications and varying timepoints.
  The 'lavaan' syntax generated by this package can be returned and further specifications can be added manually.
  Longitudinal plots as well as simplified path diagrams can be created to visualise data and model specifications.
  Estimated model parameters and fit statistics can be extracted as data frames.
  Data for different univariate and bivariate LCSM can be simulated by specifying estimates for model parameters to explore their effects.
  This package combines the strengths of other R packages like 'lavaan', 'broom', and 'semPlot' by generating 'lavaan' syntax that helps these packages work together.",2020-07-24,Milan Wiedemann,https://milanwiedemann.github.io/lcsm/,TRUE,https://github.com/milanwiedemann/lcsm,11397,9,2021-12-13T19:49:24Z,1266.3333333333333
ldaPrototype,"Determine a Prototype from a number of runs of Latent Dirichlet Allocation (LDA) measuring its similarities with S-CLOP: A procedure to select the LDA run with highest mean pairwise similarity, which is measured by S-CLOP (Similarity of multiple sets by Clustering with Local Pruning), to all other runs. LDA runs are specified by its assignments leading to estimators for distribution parameters. Repeated runs lead to different results, which we encounter by choosing the most representative LDA run as prototype.",2021-09-02,Jonas Rieger,https://github.com/JonasRieger/ldaPrototype,TRUE,https://github.com/jonasrieger/ldaprototype,14049,7,2022-04-02T16:14:02Z,2007
ldatuning,"For this first version only metrics to estimate the best fitting
    number of topics are implemented.",2020-04-21,Murzintcev Nikita,https://github.com/nikita-moor/ldatuning,TRUE,https://github.com/nikita-moor/ldatuning,49867,60,2022-03-01T15:24:10Z,831.1166666666667
LDlinkR,"Provides access to the 'LDlink' API (<https://ldlink.nci.nih.gov/?tab=apiaccess>)
    using the R console.  This programmatic access facilitates researchers who are 
    interested in performing batch queries in 1000 Genomes Project (2015) <doi:10.1038/nature15393> 
    data using 'LDlink'. 'LDlink' is an interactive and powerful suite of web-based tools for querying 
    germline variants in human population groups of interest. For more details, please see 
    Machiela et al. (2015) <doi:10.1093/bioinformatics/btv402>.",2022-06-07,Timothy A. Myers,https://ldlink.nci.nih.gov,TRUE,https://github.com/cbiit/ldlinkr,20221,24,2022-06-10T15:09:37Z,842.5416666666666
ldsep,"Estimate haplotypic or composite pairwise linkage disequilibrium
    (LD) in polyploids, using either genotypes or genotype likelihoods. 
    Support is provided to estimate the popular measures of LD: the LD 
    coefficient D, the standardized LD coefficient D', and the Pearson 
    correlation coefficient r. All estimates are returned with corresponding 
    standard errors. These estimates and standard errors can then be used
    for shrinkage estimation. The main functions are ldfast(), ldest(), mldest(),
    sldest(), plot.lddf(), format_lddf(), and ldshrink(). Details of the methods
    are available in Gerard (2021a) <doi:10.1111/1755-0998.13349>
    and Gerard (2021b) <doi:10.1038/s41437-021-00462-5>.",2022-02-11,David Gerard,NA,TRUE,https://github.com/dcgerard/ldsep,10153,5,2022-03-29T18:19:18Z,2030.6
leafem,"Provides extensions for packages 'leaflet' & 'mapdeck', 
    many of which are used by package 'mapview'. 
    Focus is on functionality readily available in 
    Geographic Information Systems such as 'Quantum GIS'. Includes functions
    to display coordinates of mouse pointer position, query image values via 
    mouse pointer and zoom-to-layer buttons. Additionally, provides a feature 
    type agnostic function to add points, lines, polygons to a map.",2022-04-16,Tim Appelhans,"https://github.com/r-spatial/leafem,
https://r-spatial.github.io/leafem/",TRUE,https://github.com/r-spatial/leafem,898990,95,2022-07-03T15:31:05Z,9463.052631578947
leaflegend,"Provides extensions to the 'leaflet' package to 
    customize legends with images, text styling, orientation, sizing,
    and symbology.",2022-03-03,Thomas Roh,"https://leaflegend.roh.engineering,
https://github.com/tomroh/leaflegend",TRUE,https://github.com/tomroh/leaflegend,10903,16,2022-03-03T03:35:41Z,681.4375
leaflet,"Create and customize interactive maps using the 'Leaflet'
    JavaScript library and the 'htmlwidgets' package. These maps can be used
    directly from the R console, from 'RStudio', in Shiny applications and R Markdown
    documents.",2022-03-23,Joe Cheng,https://rstudio.github.io/leaflet/,TRUE,https://github.com/rstudio/leaflet,2485195,730,2022-07-02T18:59:56Z,3404.376712328767
leaflet.esri,"An add-on package to the 'leaflet' package, which provides bindings for 'ESRI' services. This package allows a user to add 'ESRI' provided services such as 'MapService', 'ImageMapService', 'TiledMapService' etc. to a 'leaflet' map.",2018-04-23,Bhaskar Karambelkar,"https://github.com/bhaskarvk/leaflet.esri,https://bhaskarvk.github.io/leaflet.esri/",TRUE,https://github.com/bhaskarvk/leaflet.esri,18833,31,2021-09-30T14:38:14Z,607.516129032258
leaflet.extras,"The 'leaflet' JavaScript library provides many plugins some of which
    are available in the core 'leaflet' package, but there are many more. It is not
    possible to support them all in the core 'leaflet' package. This package serves
    as an add-on to the 'leaflet' package by providing extra functionality via 'leaflet'
    plugins.",2018-04-21,Bhaskar Karambelkar,"https://github.com/bhaskarvk/leaflet.extras,
https://bhaskarvk.github.io/leaflet.extras/",TRUE,https://github.com/bhaskarvk/leaflet.extras,228771,198,2021-09-30T14:37:13Z,1155.409090909091
leaflet.extras2,"Several 'leaflet' plugins are integrated, which are available as extension to the 'leaflet' package.",2022-05-10,Gatscha Sebastian,"https://trafficonese.github.io/leaflet.extras2/,
https://github.com/trafficonese/leaflet.extras2",TRUE,https://github.com/trafficonese/leaflet.extras2,69974,59,2022-05-10T19:21:36Z,1186
leaflet.providers,"Contains third-party map tile provider information from
    'Leaflet.js', <https://github.com/leaflet-extras/leaflet-providers>, to be
    used with the 'leaflet' R package. Additionally, 'leaflet.providers'
    enables users to retrieve up-to-date provider information between package
    updates.",2019-11-09,Leslie Huang,https://github.com/rstudio/leaflet.providers,TRUE,https://github.com/rstudio/leaflet.providers,1625195,9,2021-11-19T16:16:15Z,180577.22222222222
leafpop,"Creates 'HTML' strings to embed tables, images or graphs in pop-ups
  of interactive maps created with packages like 'leaflet' or 'mapview'. Handles
  local images located on the file system or via remote URL. Handles graphs created 
  with 'lattice' or 'ggplot2' as well as interactive plots created with 'htmlwidgets'.",2021-05-22,Tim Appelhans,https://github.com/r-spatial/leafpop,TRUE,https://github.com/r-spatial/leafpop,617465,89,2022-06-14T16:16:28Z,6937.808988764045
leafsync,"Create small multiples of several leaflet web maps with (optional) 
    synchronised panning and zooming control. When syncing is enabled all maps 
    respond to mouse actions on one map. This allows side-by-side comparisons
    of different attributes of the same geometries. Syncing can be adjusted
    so that any combination of maps can be synchronised.",2019-03-05,Tim Appelhans,https://github.com/r-spatial/leafsync,TRUE,https://github.com/r-spatial/leafsync,410288,30,2022-03-03T11:13:25Z,13676.266666666666
learningtower,"The Programme for International Student Assessment (PISA) is a global study conducted by the Organization for Economic Cooperation and Development (OECD) in member and non-member countries to assess educational systems by assessing 15-year-old school students academic performance in mathematics, science, and reading. This datasets contains information on their scores and other socioeconomic characteristics, information about their school and its infrastructure, as well as the countries that are taking part in the program.",2021-09-06,Kevin Wang,"https://kevinwang09.github.io/learningtower/,
https://github.com/kevinwang09/learningtower",TRUE,https://github.com/kevinwang09/learningtower,3415,19,2021-09-07T07:46:39Z,179.73684210526315
LearnPCA,Principal component analysis (PCA) is one of the most widely used data analysis techniques.  This package provides a series of vignettes explaining PCA starting from basic concepts. The primary purpose is to serve as a self-study resource for anyone wishing to understand PCA better. A few convenience functions are provided as well.,2022-05-02,Bryan A. Hanson,https://bryanhanson.github.io/LearnPCA/,TRUE,https://github.com/bryanhanson/learnpca,2047,2,2022-05-02T03:51:30Z,1023.5
learnr,"Create interactive tutorials using R Markdown. Use a combination
  of narrative, figures, videos, exercises, and quizzes to create self-paced
  tutorials for learning about R and R packages.",2020-02-13,Barret Schloerke,"https://rstudio.github.io/learnr/,
https://github.com/rstudio/learnr",TRUE,https://github.com/rstudio/learnr,496893,526,2022-07-07T20:54:44Z,944.6634980988593
learnrbook,"Data, scripts and code from chunks used as examples in the book 
   ""Learn R: As a Language"" by Pedro J. Aphalo.
   ISBN 9780367182533 (pbk); ISBN 9780367182557 (hbk); ISBN 9780429060342 (ebk).",2021-07-04,Pedro J. Aphalo,https://docs.r4photobiology.info/learnrbook/,TRUE,https://github.com/aphalo/learnrbook-pkg,17168,1,2021-12-29T19:03:11Z,17168
ledger,"Utilities for querying plain text accounting files from 'Ledger', 'HLedger', and 'Beancount'.",2021-11-12,Trevor L Davis,"https://github.com/trevorld/r-ledger,
https://trevorldavis.com/R/ledger/",TRUE,https://github.com/trevorld/r-ledger,15143,32,2021-11-12T06:05:19Z,473.21875
leem,"Educational tool for teaching of statistics 
    and mathematics in primary and higher education. The objective is 
    to assist in teaching/learning for both student study planning 
    and teacher teaching strategies. The 'leem' package will try to bring, 
    in a simple and at the same time in-depth, 
    knowledge of statistics and mathematics to everyone 
    who wants to study these areas of knowledge. The main function of the 
    package is 'leem()' function.",2022-03-02,Ben Deivide,"https://bendeivide.github.io/project/leem/,
https://github.com/bendeivide/leem",TRUE,https://github.com/bendeivide/leem,1477,1,2022-06-08T01:20:49Z,1477
legco,"Fetching data from Hong Kong Legislative Council's open data API in R. 
    Functions correspond to the data endpoints of the API. 
    Documentations of supported API databases:
    <https://www.legco.gov.hk/odata/english/billsdb.html>, 
    <https://www.legco.gov.hk/odata/english/hansard-db.html>,
    <https://www.legco.gov.hk/odata/english/attendance-db.html>,
    <https://www.legco.gov.hk/odata/english/schedule-db.html> and
    <https://www.legco.gov.hk/odata/english/vrdb.html>.",2021-10-16,Elgar Teo,https://github.com/elgarteo/legco,TRUE,https://github.com/elgarteo/legco,9538,0,2022-01-27T00:49:29Z,NA
legion,"Functions implementing multivariate state space models for purposes of time series analysis and forecasting.
             The focus of the package is on multivariate models, such as Vector Exponential Smoothing,
             Vector ETS (Error-Trend-Seasonal model) etc. It currently includes Vector Exponential
             Smoothing (VES, de Silva et al., 2010, <doi:10.1177/1471082X0901000401>), Vector ETS and
             simulation function for VES.",2022-02-15,"Ivan Svetunkov  (Lecturer at Centre for Marketing Analytics
    and Forecasting",https://github.com/config-i1/legion,TRUE,https://github.com/config-i1/legion,5959,8,2022-05-10T23:05:21Z,744.875
lehdr,"Designed to query Longitudinal Employer-Household Dynamics (LEHD) 
    workplace/residential association and origin-destination flat files and 
    optionally aggregate Census block-level data to block group, tract, county, 
    or state. Data comes from the LODES FTP server <https://lehd.ces.census.gov/data/lodes/LODES7/>.",2022-02-04,Jamaal Green,https://github.com/jamgreen/lehdr/,TRUE,https://github.com/jamgreen/lehdr,2871,41,2022-02-02T15:32:43Z,70.02439024390245
leiden,"Implements the 'Python leidenalg' module to be called in R.
    Enables clustering using the leiden algorithm for partition a graph into communities.
    See the 'Python' repository for more details: <https://github.com/vtraag/leidenalg>
    Traag et al (2018) From Louvain to Leiden: guaranteeing well-connected communities. <arXiv:1810.08473>.",2022-05-09,S. Thomas Kelly,https://github.com/TomKellyGenetics/leiden,TRUE,https://github.com/tomkellygenetics/leiden,437183,26,2022-05-25T04:47:49Z,16814.73076923077
leidenAlg,"An R interface to the Leiden algorithm, an iterative community detection algorithm on networks. The algorithm is designed to converge to a partition in which all subsets of all communities are locally optimally assigned, yielding communities guaranteed to be connected. The implementation proves to be fast, scales well, and can be run on graphs of millions of nodes (as long as they can fit in memory). The original implementation was constructed as a python interface ""leidenalg"" found here: <https://github.com/vtraag/leidenalg>. The algorithm was originally described in Traag, V.A., Waltman, L. & van Eck, N.J. ""From Louvain to Leiden: guaranteeing well-connected communities"". Sci Rep 9, 5233 (2019) <doi:10.1038/s41598-019-41695-z>.",2022-04-11,Evan Biederstedt,https://github.com/kharchenkolab/leidenAlg,TRUE,https://github.com/kharchenkolab/leidenalg,15403,3,2022-04-11T18:29:27Z,5134.333333333333
leidenbase,"An R to C/C++ interface that runs the Leiden community
    detection algorithm to find a basic partition (). It runs the
    equivalent of the 'leidenalg' find_partition() function, which is
    given in the 'leidenalg' distribution file
    'leiden/src/functions.py'. This package includes the
    required source code files from the official 'leidenalg'
    distribution and functions from the R 'igraph'
    package.  The 'leidenalg' distribution is available from
    <https://github.com/vtraag/leidenalg/>
    and the R 'igraph' package is available from
    <https://igraph.org/r/>.
    The Leiden algorithm is described in the article by
    Traag et al. (2019) <doi:10.1038/s41598-019-41695-z>.",2022-03-28,Brent Ewing,https://github.com/cole-trapnell-lab/leidenbase,TRUE,https://github.com/cole-trapnell-lab/leidenbase,14219,10,2022-03-09T01:45:14Z,1421.9
lemna,"The reference implementation of model equations and default
    parameters for the toxicokinetic-toxicodynamic (TKTD) model of the Lemna
    (duckweed) aquatic plant. Lemna is a standard test macrophyte used in ecotox
    effect studies. The model was described and published by the SETAC Europe
    Interest Group Effect Modeling. It is a refined description of the Lemna
    TKTD model published by Schmitt et al. (2013)
    <doi:10.1016/j.ecolmodel.2013.01.017>.",2022-05-10,Nils Kehrein,https://github.com/nkehrein/lemna,TRUE,https://github.com/nkehrein/lemna,2012,0,2022-05-10T10:02:52Z,NA
letsR,"Handling, processing, and analyzing geographic
    data on species' distributions and environmental variables. 
    Read Vilela & Villalobos (2015) <doi: 10.1111/2041-210X.12401> for details.",2020-10-26,Bruno Vilela & Fabricio Villalobos,"https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12401,
https://github.com/macroecology/letsR",TRUE,https://github.com/macroecology/letsr,19930,18,2021-08-18T22:22:03Z,1107.2222222222222
levitate,"Provides string similarity calculations inspired by the
    Python 'fuzzywuzzy' package. Compare strings by edit distance,
    similarity ratio, best matching substring, ordered token matching and
    set-based token matching. A range of edit distance measures are
    available thanks to the 'stringdist' package.",2021-05-25,Lewin Appleton-Fox,"https://lewinfox.github.io/levitate/,
https://github.com/lewinfox/levitate/",TRUE,https://github.com/lewinfox/levitate,4407,29,2021-11-20T22:44:58Z,151.9655172413793
LexFindR,"Implements code to identify lexical competitors in a given list
  of words. We include many of the standard competitor types used in spoken word
  recognition research, such as functions to find cohorts, neighbors, and
  rhymes, amongst many others. The package includes documentation for using a
  variety of lexicon files, including those with form codes made up of multiple
  letters (i.e., phoneme codes) and also basic orthographies. Importantly, the
  code makes use of multiple CPU cores and vectorization when possible, making
  it extremely fast and able to handle large lexicons. Additionally, the package
  contains documentation for users to easily write new functions, allowing
  researchers to examine other relationships within a lexicon. 
  Preprint: <https://psyarxiv.com/8dyru/>. Open access: <https://link.springer.com/epdf/10.3758/s13428-021-01667-6?sharing_token=9WlO9soCc9y0uSuwWSUYfJAH0g46feNdnc402WrhzyrdKcK8uzZx_hDEtgbYzn3gvxdG5Cuj0j0cC4lVMFBqYCGTQmE2blN2Gwo74LJ8ro1pEOAYDRFy6Lhf1nc719vD-zU7GDvKOQxDAwPbrisvPBeXSIu0NkqXF7Jx3IuUwIs%3D>. 
  Citation: Li, Z., Crinnion, A.M. & Magnuson, J.S. (2021). 
  <doi:10.3758/s13428-021-01667-6>.",2021-10-29,ZhaoBin Li,https://github.com/maglab-uconn/LexFindR,TRUE,https://github.com/maglab-uconn/lexfindr,3939,3,2021-11-13T02:07:51Z,1313
lexicon,"A collection of lexical hash tables, dictionaries, and word lists.",2019-03-21,Tyler Rinker,https://github.com/trinker/lexicon,TRUE,https://github.com/trinker/lexicon,303296,101,2021-10-12T00:19:51Z,3002.930693069307
LexisNexisTools,"My PhD supervisor once told me that everyone doing newspaper
    analysis starts by writing code to read in files from the 'LexisNexis' newspaper
    archive (retrieved e.g., from <http://www.nexis.com/> or any of the partner
    sites). However, while this is a nice exercise I do recommend, not everyone has
    the time. This package takes files downloaded from the newspaper archive of
    'LexisNexis', reads them into R and offers functions for further processing.",2022-01-04,Johannes Gruber,https://github.com/JBGruber/LexisNexisTools,TRUE,https://github.com/jbgruber/lexisnexistools,22064,77,2022-05-25T15:29:31Z,286.54545454545456
LFApp,"Shiny apps for the quantitative analysis of images from lateral flow assays (LFAs). The images are segmented and background corrected and color intensities are extracted. The apps can be used to import and export intensity data and to calibrate LFAs by means of linear, loess, or gam models. The calibration models can further be saved and applied to intensity data from new images for determining concentrations.",2021-07-28,Filip Paskali,https://github.com/fpaskali/LFApp,TRUE,https://github.com/fpaskali/lfapp,3257,2,2022-02-19T15:02:06Z,1628.5
lfc,"Ratios of count data such as obtained from RNA-seq are modelled
    using Bayesian statistics to derive posteriors for effects sizes. This
    approach is described in Erhard & Zimmer (2015) <doi:10.1093/nar/gkv696> 
    and Erhard (2018) <doi:10.1093/bioinformatics/bty471>.",2022-04-27,Florian Erhard,https://github.com/erhard-lab/lfc,TRUE,https://github.com/erhard-lab/lfc,412,7,2022-05-02T16:24:23Z,58.857142857142854
lfe,"Transforms away factors with many levels prior to doing an OLS.
  Useful for estimating linear models with multiple group fixed effects, and for
  estimating linear models which uses factors with many levels as pure control variables. See Gaure (2013) <doi:10.1016/j.csda.2013.03.024>
  Includes support for instrumental variables, conditional F statistics for weak instruments,
  robust and multi-way clustered standard errors, as well as limited mobility bias correction (Gaure 2014 <doi:10.1002/sta4.68>). 
  WARNING: This package is NOT under active development anymore, no further improvements are to be expected, and the package is at risk of being removed from CRAN.",2022-05-04,Simen Gaure,https://github.com/MatthieuStigler/lfe,TRUE,https://github.com/matthieustigler/lfe,271100,1,2022-05-04T20:34:49Z,271100
lglasso,"For high-dimensional correlated observations, this package carries out the L_1 penalized maximum likelihood 
            estimation of the precision matrix (network) and the correlation parameters. The correlated data can be 
            longitudinal data (may be irregularly spaced) with dampening correlation or clustered data with uniform correlation.  
            For the details of the algorithms, please see the paper Jie Zhou et al. Identifying Microbial Interaction Networks Based on Irregularly Spaced 
            Longitudinal 16S rRNA sequence data <doi:10.1101/2021.11.26.470159>.",2022-01-15,Jie Zhou,https://github.com/jiezhou-2/lglasso,TRUE,https://github.com/jiezhou-2/lglasso,1499,0,2021-12-20T16:54:54Z,NA
lgpr,"Interpretable nonparametric modeling of longitudinal data
    using additive Gaussian process regression. Contains functionality
    for inferring covariate effects and assessing covariate relevances.
    Models are specified using a convenient formula syntax, and can include
    shared, group-specific, non-stationary, heterogeneous and temporally
    uncertain effects. Bayesian inference for model parameters is performed
    using 'Stan'. The modeling approach and methods are described in detail in
    Timonen et al. (2021) <doi:10.1093/bioinformatics/btab021>.",2021-09-23,Juho Timonen,https://github.com/jtimonen/lgpr,TRUE,https://github.com/jtimonen/lgpr,3920,22,2021-09-23T12:49:14Z,178.1818181818182
lgr,"A flexible, feature-rich yet light-weight logging
    framework based on 'R6' classes. It supports hierarchical loggers,
    custom log levels, arbitrary data fields in log events, logging to
    plaintext, 'JSON', (rotating) files, memory buffers. For extra
    appenders that support logging to databases, email and push
    notifications see the the package lgr.app.",2021-09-16,Stefan Fleck,https://s-fleck.github.io/lgr/,TRUE,https://github.com/s-fleck/lgr,566416,63,2022-05-31T06:17:48Z,8990.730158730159
lhs,Provides a number of methods for creating and augmenting Latin Hypercube Samples and Orthogonal Array Latin Hypercube Samples.,2022-03-22,Rob Carnell,https://github.com/bertcarnell/lhs,TRUE,https://github.com/bertcarnell/lhs,1065168,21,2022-03-30T00:59:15Z,50722.28571428572
libgeos,"Provides the Open Source Geometry Engine ('GEOS') as a
  C API that can be used to write high-performance C and C++
  geometry operations using R as an interface. Headers are provided
  to make linking to and using these functions from C++ code as
  easy and as safe as possible. This package contains an internal
  copy of the 'GEOS' library to guarantee the best possible
  consistency on multiple platforms.",2021-10-28,Dewey Dunnington,"https://paleolimbot.github.io/libgeos/,
https://github.com/paleolimbot/libgeos",TRUE,https://github.com/paleolimbot/libgeos,16390,16,2022-07-09T16:47:50Z,1024.375
libr,"Contains a set of functions to create data libraries,
    generate data dictionaries, and simulate a data step.
    The libname() function will load a directory of data into 
    a library in one line of code.  The dictionary() function
    will generate data dictionaries for individual
    data frames or an entire library.  And the datestep() function
    will perform row-by-row data processing.",2022-06-23,David J. Bosak,https://libr.r-sassy.org,TRUE,https://github.com/dbosak01/libr,8946,22,2022-06-25T13:01:06Z,406.6363636363636
librarian,"Automatically install, update, and load 'CRAN', 'GitHub', and 'Bioconductor' 
    packages in a single function call. By accepting bare unquoted names for packages, 
    it's easy to add or remove packages from the list.",2021-07-12,Desi Quintans,https://github.com/DesiQuintans/librarian,TRUE,https://github.com/desiquintans/librarian,27534,37,2021-07-14T04:29:42Z,744.1621621621622
libsoc,"Handle 'PharmML' (Pharmacometrics Markup Language) standard output (SO) XML files.
    SO files can be created, read, manipulated and written through a
    data binding from the XML structure to a tree structure of R objects.",2022-02-03,Rikard Nordgren,https://github.com/rikardn/libsoc,TRUE,https://github.com/rikardn/libsoc,13229,8,2022-02-03T10:15:15Z,1653.625
lidR,"Airborne LiDAR (Light Detection and Ranging) interface for data
    manipulation and visualization. Read/write 'las' and 'laz' files, computation
    of metrics in area based approach, point filtering, artificial point reduction,
    classification from geographic data, normalization, individual tree segmentation
    and other manipulations.",2022-05-04,Jean-Romain Roussel,https://github.com/r-lidar/lidR,TRUE,https://github.com/r-lidar/lidr,93004,398,2022-06-28T01:22:12Z,233.678391959799
lifecontingencies,"Classes and methods that allow the user to manage life table,
    actuarial tables (also multiple decrements tables). Moreover, functions to easily
    perform demographic, financial and actuarial mathematics on life contingencies
    insurances calculations are contained therein. See Spedicato (2013)	<doi:10.18637/jss.v055.i10>.",2022-06-10,Giorgio Alfredo Spedicato,https://github.com/spedygiorgio/lifecontingencies,TRUE,https://github.com/spedygiorgio/lifecontingencies,51361,45,2022-01-06T19:02:49Z,1141.3555555555556
lifecycle,"Manage the life cycle of your exported functions
    with shared conventions, documentation badges, and user-friendly
    deprecation warnings.",2021-09-24,Lionel Henry,"https://lifecycle.r-lib.org/, https://github.com/r-lib/lifecycle",TRUE,https://github.com/r-lib/lifecycle,41216476,75,2022-03-02T14:49:34Z,549553.0133333333
liftr,Persistent reproducible reporting by containerization of R Markdown documents.,2019-06-19,Nan Xiao,"https://nanx.me/liftr/, https://github.com/nanxstats/liftr",TRUE,https://github.com/nanxstats/liftr,17835,165,2021-12-19T05:14:51Z,108.0909090909091
lightgbm,"Tree based algorithms can be improved by introducing boosting frameworks. 
    'LightGBM' is one such framework, based on Ke, Guolin et al. (2017) <https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision>.
    This package offers an R interface to work with it.
    It is designed to be distributed and efficient with the following advantages:
        1. Faster training speed and higher efficiency.
        2. Lower memory usage.
        3. Better accuracy.
        4. Parallel learning supported.
        5. Capable of handling large-scale data.
    In recognition of these advantages, 'LightGBM' has been widely-used in many winning solutions of machine learning competitions.
    Comparison experiments on public datasets suggest that 'LightGBM' can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. In addition, parallel experiments suggest that in certain circumstances, 'LightGBM' can achieve a linear speed-up in training time by using multiple machines.",2022-01-14,Yu Shi,https://github.com/Microsoft/LightGBM,TRUE,https://github.com/microsoft/lightgbm,87327,13962,2022-07-07T22:28:38Z,6.254619681993984
lightr,"Parse various reflectance/transmittance/absorbance spectra file
    formats to extract spectral data and metadata, as described in Gruson, White
    & Maia (2019) <doi:10.21105/joss.01857>. Among other formats, it can import
    files from 'Avantes' <https://www.avantes.com/>, 'CRAIC' 
    <https://www.microspectra.com/>, and 'OceanInsight' (formerly 'OceanOptics') 
    <https://www.oceaninsight.com/> brands.",2022-05-14,Hugo Gruson,"https://docs.ropensci.org/lightr/,
https://github.com/ropensci/lightr",TRUE,https://github.com/ropensci/lightr,22978,9,2022-07-04T12:26:07Z,2553.1111111111113
likert,"An approach to analyzing Likert response items, with an emphasis on visualizations. 
    The stacked bar plot is the preferred method for presenting Likert results. Tabular results
    are also implemented along with density plots to assist researchers in determining whether 
    Likert responses can be used quantitatively instead of qualitatively. See the likert(), 
    summary.likert(), and plot.likert() functions to get started.",2016-12-31,Jason Bryer,"http://jason.bryer.org/likert, http://github.com/jbryer/likert",TRUE,https://github.com/jbryer/likert,106894,262,2022-05-05T15:52:56Z,407.99236641221376
LimnoPalettes,"Palettes generated from limnology based field and laboratory photos. Palettes can be used to generate color values to be used in any functions that calls for a color (i.e. ggplot(), plot(), flextable(), etc.). ",2020-10-19,Paul Julian,https://github.com/SwampThingPaul/LimnoPalettes,TRUE,https://github.com/swampthingpaul/limnopalettes,8569,8,2021-10-28T12:55:23Z,1071.125
limorhyde,"A flexible approach, inspired by cosinor regression, for
  differential analysis of rhythmic transcriptome data. See Singer and Hughey
  (2018) <doi:10.1177/0748730418813785>.",2022-02-18,Jake Hughey,"https://limorhyde.hugheylab.org,
https://github.com/hugheylab/limorhyde",TRUE,https://github.com/hugheylab/limorhyde,1175,2,2022-05-18T16:35:51Z,587.5
limorhyde2,"Fit linear models based on periodic splines, moderate model
  coefficients using multivariate adaptive shrinkage, then compute properties of
  the moderated curves.",2022-03-08,Jake Hughey,"https://limorhyde2.hugheylab.org,
https://github.com/hugheylab/limorhyde2",TRUE,https://github.com/hugheylab/limorhyde2,849,0,2022-06-02T19:08:02Z,NA
linconGaussR,"Sample truncated multivariate Normal distribution following Gessner, A., Kanjilal, O., & Hennig, P. (2019). Integrals over Gaussians under Linear Domain Constraints. 108. <arxiv:1910.09328>.",2021-10-26,Yunyi Shen,https://github.com/YunyiShen/linconGaussR,TRUE,https://github.com/yunyishen/lincongaussr,2607,2,2021-10-26T16:46:12Z,1303.5
linelist,"Provides tools to help storing and handling case line list data. The 'linelist' class adds a tagging system to classical 'data.frame' objects to identify key epidemiological data such as dates of symptom onset, epidemiological case definition, age, gender or disease outcome. Once tagged, these variables can be seamlessly used in downstream analyses, making data pipelines more robust and reliable. ",2022-05-13,Thibaut Jombart,https://github.com/epiverse-trace/linelist,TRUE,https://github.com/epiverse-trace/linelist,982,2,2022-06-28T13:53:21Z,491
linemap,"Create maps made of lines. The package contains two functions:
    linemap() and getgrid(). linemap() displays a map made of lines using a
    data frame of gridded data. getgrid() transforms a set of polygons
    (sf objects) into a suitable data frame for linemap().",2021-01-19,Timothée Giraud,https://github.com/riatelab/linemap,TRUE,https://github.com/riatelab/linemap,15417,108,2022-04-11T10:07:31Z,142.75
lineup,"Tools for detecting and correcting sample mix-ups between two sets
    of measurements, such as between gene expression data on two tissues.
    Broman et al. (2015) <doi:10.1534/g3.115.019778>.",2022-07-10,Karl W Broman,https://github.com/kbroman/lineup,TRUE,https://github.com/kbroman/lineup,18580,3,2022-07-10T10:40:37Z,6193.333333333333
lingglosses,"Helps to render interlinear glossed linguistic examples in html 
    'rmarkdown' documents and then semi-automatically compiles the list of
    glosses at the end of the document. It also provides a database of linguistic
    glosses.",2022-05-27,George Moroz,"https://CRAN.R-project.org/package=phonfieldwork,
https://agricolamz.github.io/lingglosses/",TRUE,https://github.com/agricolamz/lingglosses,1345,5,2022-06-21T03:11:56Z,269
lingmatch,"Measure similarity between texts. Offers a variety of processing
  tools and similarity metrics to facilitate flexible representation of texts and matching.
  Implements forms of Language Style Matching (Ireland & Pennebaker, 2010) <doi:10.1037/a0020386>
  and Latent Semantic Analysis (Landauer & Dumais, 1997) <doi:10.1037/0033-295X.104.2.211>.",2022-01-25,Micah Iserman,https://github.com/miserman/lingmatch,TRUE,https://github.com/miserman/lingmatch,6019,4,2022-05-17T06:58:05Z,1504.75
lingtypology,"Provides R with the Glottolog database <https://glottolog.org/> and some more abilities for purposes of linguistic mapping. The Glottolog database contains the catalogue of languages of the world. This package helps researchers to make a linguistic maps, using philosophy of the Cross-Linguistic Linked Data project <https://clld.org/>, which allows for while at the same time facilitating uniform access to the data across publications. A tutorial for this package is available on GitHub pages <https://docs.ropensci.org/lingtypology/> and package vignette. Maps created by this package can be used both for the investigation and linguistic teaching. In addition, package provides an ability to download data from typological databases such as WALS, AUTOTYP and some others and to create your own database website.",2022-06-24,George Moroz,"https://CRAN.R-project.org/package=lingtypology,
https://github.com/ropensci/lingtypology/,
https://ropensci.github.io/lingtypology/",TRUE,https://github.com/ropensci/lingtypology,24422,43,2022-06-24T08:10:42Z,567.953488372093
link2GI,Functions to simplify the linking of open source GIS and remote sensing related command line interfaces.,2021-09-03,Chris Reudenbach,"https://github.com/r-spatial/link2GI/,
https://r-spatial.github.io/link2GI/",TRUE,https://github.com/r-spatial/link2gi,27425,20,2022-06-14T06:42:12Z,1371.25
linkprediction,"Implementations of most of the existing proximity-based methods of 
  link prediction in graphs. Among the 20 implemented methods are e.g.:
  Adamic L. and Adar E. (2003) <doi:10.1016/S0378-8733(03)00009-1>,
  Leicht E., Holme P., Newman M. (2006) <doi:10.1103/PhysRevE.73.026120>,
  Zhou T. and Zhang Y (2009) <doi:10.1140/epjb/e2009-00335-8>, and
  Fouss F., Pirotte A., Renders J., and Saerens M. (2007) <doi:10.1109/TKDE.2007.46>.",2018-10-19,Michal Bojanowski,https://github.com/recon-icm/linkprediction,TRUE,https://github.com/recon-icm/linkprediction,12287,10,2022-01-29T21:15:09Z,1228.7
linkspotter,"Compute and visualize using the 'visNetwork' package all the bivariate correlations of a dataframe.
  Several and different types of correlation coefficients (Pearson's r, Spearman's rho, Kendall's tau,
  distance correlation, maximal information coefficient and 
  equal-freq discretization-based maximal normalized mutual information) are used according to 
  the variable couple type (quantitative vs categorical, quantitative vs quantitative, categorical vs categorical).",2020-07-23,Alassane Samba,https://github.com/sambaala/linkspotter,TRUE,https://github.com/sambaala/linkspotter,12808,7,2021-11-29T10:39:59Z,1829.7142857142858
linl,"A 'LaTeX' Letter class for 'rmarkdown', using the
 'pandoc-letter' template adapted for use with 'markdown'.",2019-10-23,Dirk Eddelbuettel and Aaron Wolen,http://dirk.eddelbuettel.com/code/linl.html,TRUE,https://github.com/eddelbuettel/linl,16948,108,2021-11-11T03:08:04Z,156.92592592592592
linne,Conveniently generate 'CSS' using R code.,2020-10-26,John Coene,https://linne.john-coene.com/,TRUE,https://github.com/johncoene/linne,6432,73,2022-01-15T20:58:45Z,88.10958904109589
lintools,"Variable elimination (Gaussian elimination, Fourier-Motzkin elimination), 
    Moore-Penrose pseudoinverse, reduction to reduced row echelon form, value substitution,  
    projecting a vector on the convex polytope described by a system of (in)equations, 
    simplify systems by removing spurious columns and rows and collapse implied equalities, 
    test if a matrix is totally unimodular, compute variable ranges implied by linear
    (in)equalities.",2022-06-16,Mark van der Loo,https://github.com/data-cleaning/lintools,TRUE,https://github.com/data-cleaning/lintools,21761,1,2022-06-08T14:57:47Z,21761
lintr,"Checks adherence to a given style, syntax errors and possible semantic issues.
    Supports on the fly checking of R code edited with 'RStudio IDE', 'Emacs', 'Vim', 'Sublime Text',
    'Atom' and 'Visual Studio Code'.",2022-06-13,Jim Hester,"https://github.com/r-lib/lintr, https://lintr.r-lib.org",TRUE,https://github.com/r-lib/lintr,1228684,980,2022-07-06T00:57:14Z,1253.7591836734694
listcomp,"An implementation of list comprehensions as purely syntactic
  sugar with a minor runtime overhead. It constructs nested for-loops and
  executes the byte-compiled loops to collect the results.",2022-01-31,Dirk Schumacher,https://github.com/dirkschumacher/listcomp,TRUE,https://github.com/dirkschumacher/listcomp,19117,18,2022-02-01T08:35:08Z,1062.0555555555557
listcompr,"Syntactic shortcuts for creating synthetic lists, vectors, 
    data frames, and matrices using list comprehension.",2021-10-02,Patrick Roocks,https://github.com/patrickroocks/listcompr,TRUE,https://github.com/patrickroocks/listcompr,6897,4,2021-10-02T15:35:43Z,1724.25
listdown,Programmatically create R Markdown documents from lists.,2020-12-07,Michael J. Kane,https://github.com/kaneplusplus/listdown,TRUE,https://github.com/kaneplusplus/listdown,9222,20,2022-04-11T14:47:41Z,461.1
listenv,"List environments are environments that have list-like properties.  For instance, the elements of a list environment are ordered and can be accessed and iterated over using index subsetting, e.g. 'x <- listenv(a = 1, b = 2); for (i in seq_along(x)) x[[i]] <- x[[i]] ^ 2; y <- as.list(x)'.",2019-12-05,Henrik Bengtsson,https://github.com/HenrikBengtsson/listenv,TRUE,https://github.com/henrikbengtsson/listenv,4516595,20,2022-05-28T18:52:39Z,225829.75
lite,"Performs likelihood-based inference for stationary time series 
    extremes.  The general approach follows Fawcett and Walshaw (2012)
    <doi:10.1002/env.2133>.  Marginal extreme value inferences are adjusted for 
    cluster dependence in the data using the methodology in Chandler and Bate 
    (2007) <doi:10.1093/biomet/asm015>, producing an adjusted log-likelihood 
    for the model parameters.  A log-likelihood for the extremal index is 
    produced using the K-gaps model of Suveges and Davison (2010) 
    <doi:10.1214/09-AOAS292>. These log-likelihoods are combined to make 
    inferences about return levels.",2022-04-08,Paul J. Northrop,"https://paulnorthrop.github.io/lite/,
https://github.com/paulnorthrop/lite",TRUE,https://github.com/paulnorthrop/lite,639,1,2022-06-30T20:07:25Z,639
littler,"A scripting and command-line front-end
 is provided by 'r' (aka 'littler') as a lightweight binary wrapper around
 the GNU R language and environment for statistical computing and graphics.
 While R can be used in batch mode, the r binary adds full support for
 both 'shebang'-style scripting (i.e. using a  hash-mark-exclamation-path
 expression as the first line in scripts) as well as command-line use in
 standard Unix pipelines. In other words, r provides the R language without
 the environment.",2021-12-03,Dirk Eddelbuettel and Jeff Horner,"https://github.com/eddelbuettel/littler,
https://dirk.eddelbuettel.com/code/littler.html,
https://eddelbuettel.github.io/littler/",TRUE,https://github.com/eddelbuettel/littler,86651,272,2022-04-04T00:17:44Z,318.56985294117646
LLSR,"Originally design to characterise Aqueous Two Phase Systems, LLSR provide a simple way to analyse experimental data and obtain phase diagram parameters, among other properties, systematically. The package will include (every other update) new functions in order to comprise useful tools in liquid-liquid extraction research.",2021-02-17,Diego F Coelho,https://CRAN.R-project.org/package=LLSR,TRUE,https://github.com/diegofcoelho/llsr,18582,0,2022-05-24T17:26:36Z,NA
lme4,"Fit linear and generalized linear mixed-effects models.
    The models and their components are represented using S4 classes and
    methods.  The core computational algorithms are implemented using the
    'Eigen' C++ library for numerical linear algebra and 'RcppEigen' ""glue"".",2022-07-08,Douglas Bates,https://github.com/lme4/lme4/,TRUE,https://github.com/lme4/lme4,12762231,511,2022-07-09T20:18:36Z,24975.011741682974
lmeInfo,"Provides analytic derivatives and information matrices for
    fitted linear mixed effects (lme) models and generalized least squares (gls) models
    estimated using lme() (from package 'nlme') and gls() (from package 'nlme'), respectively.
    The package includes functions for estimating the sampling variance-covariance of variance
    component parameters using the inverse Fisher information. The variance components include
    the parameters of the random effects structure (for lme models), the variance structure,
    and the correlation structure. The expected and average forms of the Fisher information matrix
    are used in the calculations, and models estimated by full maximum likelihood or
    restricted maximum likelihood are supported. The package also includes a function for estimating
    standardized mean difference effect sizes (Pustejovsky, Hedges, and Shadish (2014) <DOI:10.3102/1076998614547577>)
    based on fitted lme or gls models.",2022-07-06,James Pustejovsky,https://jepusto.github.io/lmeInfo/,TRUE,https://github.com/jepusto/lmeinfo,32566,1,2022-07-06T15:47:43Z,32566
lmeresampler,"Bootstrap routines for nested linear mixed effects models fit using
    either 'lme4' or 'nlme'. The provided 'bootstrap()' function implements the
    parametric, residual, cases, random effect block (REB), and wild bootstrap 
    procedures. An overview of these procedures can be found 
    in Van der Leeden et al. (2008) <doi: 10.1007/978-0-387-73186-5_11>, 
    Carpenter, Goldstein & Rasbash (2003) <doi: 10.1111/1467-9876.00415>,
    and Chambers & Chandra (2013) <doi: 10.1080/10618600.2012.681216>.",2022-04-29,Adam Loy,https://github.com/aloy/lmeresampler,TRUE,https://github.com/aloy/lmeresampler,17329,34,2022-06-24T18:41:11Z,509.6764705882353
lmm,"It implements Expectation/Conditional Maximization Either (ECME)
             and rapidly converging algorithms as well as
             Bayesian inference for linear mixed models, 
             which is described in Schafer, J.L. (1998)
             ""Some improved procedures for linear mixed models"".
             Dept. of Statistics, The Pennsylvania State University.",2020-07-06,Original by Joseph L. Schafer,https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,26444,6,2022-07-08T17:10:26Z,4407.333333333333
LMMstar,"Companion R package for the course ""Statistical analysis of correlated and repeated measurements for health science researchers""
	     taught by the section of Biostatistics of the University of Copenhagen.
	     It implements linear mixed models where the model for the variance-covariance of the residuals is specified via patterns (compound symmetry, unstructured, ...).
	     Statistical inference for mean, variance, and correlation parameters is performed based on the observed information and a Satterthwaite degrees of freedom.
	     Normalized residuals are provided to assess model misspecification.
	     Statistical inference can be performed for arbitrary linear or non-linear combination(s) of model coefficients.
	     Predictions can be computed conditional to covariates only or also to outcome values. ",2022-06-03,Brice Ozenne,https://github.com/bozenne/LMMstar,TRUE,https://github.com/bozenne/lmmstar,4179,3,2022-07-06T11:49:08Z,1393
LMN,"Efficient Frequentist profiling and Bayesian marginalization of parameters for which the conditional likelihood is that of a multivariate linear regression model.  Arbitrary inter-observation error correlations are supported, with optimized calculations provided for independent-heteroskedastic and stationary dependence structures.",2022-02-28,Martin Lysy,https://github.com/mlysy/LMN/,TRUE,https://github.com/mlysy/lmn,1286,1,2022-02-25T01:35:11Z,1286
lmtp,"Non-parametric estimators for casual effects based on longitudinal modified treatment 
  policies as described in Diaz, Williams, Hoffman, and Schenck <doi:10.1080/01621459.2021.1955691>, traditional point treatment, 
  and traditional longitudinal effects. Continuous, binary, and categorical treatments are allowed as well are 
  censored outcomes. The treatment mechanism is estimated via a density ratio classification procedure 
  irrespective of treatment variable type. For both continuous and binary outcomes, additive treatment effects 
  can be calculated and relative risks and odds ratios may be calculated for binary outcomes.  ",2022-05-21,Nicholas Williams,https://github.com/nt-williams/lmtp,TRUE,https://github.com/nt-williams/lmtp,9487,31,2022-05-27T19:20:31Z,306.03225806451616
loadflux,"A collection of functions created to study water discharge
    (Q) and suspended sediment concentration (SSC) relationship.",2021-11-05,Anatoly Tsyplenkov,"https://github.com/atsyplenkov/loadflux,
https://atsyplenkov.github.io/loadflux/",TRUE,https://github.com/atsyplenkov/loadflux,2455,4,2021-11-08T14:31:41Z,613.75
lobstr,"A set of tools for inspecting and understanding R data
    structures inspired by str(). Includes ast() for visualizing abstract
    syntax trees, ref() for showing shared references, cst() for showing
    call stack trees, and obj_size() for computing object sizes.",2022-06-22,Hadley Wickham,"https://lobstr.r-lib.org/, https://github.com/r-lib/lobstr",TRUE,https://github.com/r-lib/lobstr,898644,271,2022-06-23T13:34:01Z,3316.029520295203
localModel,"Local explanations of machine learning models describe, how features contributed to a single prediction. 
    This package implements an explanation method based on LIME 
    (Local Interpretable Model-agnostic Explanations, 
    see Tulio Ribeiro, Singh, Guestrin (2016) <doi:10.1145/2939672.2939778>) in which interpretable
    inputs are created based on local rather than global behaviour of each original feature.",2021-09-14,Przemyslaw Biecek,https://github.com/ModelOriented/localModel,TRUE,https://github.com/modeloriented/localmodel,14306,13,2021-09-19T17:56:00Z,1100.4615384615386
log,Logger to keep track of informational events and errors useful for debugging.,2022-02-24,John Coene,NA,TRUE,https://github.com/devopifex/log,8179,13,2022-02-24T19:20:37Z,629.1538461538462
log4r,"The log4r package is meant to provide a fast, lightweight,
  object-oriented approach to logging in R based on the widely-emulated
  'log4j' system and etymology.",2021-11-04,Aaron Jacobs,https://github.com/johnmyleswhite/log4r,TRUE,https://github.com/johnmyleswhite/log4r,366057,78,2021-11-03T20:22:58Z,4693.038461538462
logbin,"Methods for fitting log-link GLMs and GAMs to binomial data,
    including EM-type algorithms with more stable convergence properties than standard methods.",2021-08-09,Mark W. Donoghoe,https://github.com/mdonoghoe/logbin,TRUE,https://github.com/mdonoghoe/logbin,19963,11,2021-08-09T21:20:40Z,1814.8181818181818
logger,"Inspired by the the 'futile.logger' R package and 'logging' Python module, this utility provides a flexible and extensible way of formatting and delivering log messages with low overhead.",2021-10-19,Gergely Daróczi,https://daroczig.github.io/logger/,TRUE,https://github.com/daroczig/logger,549211,216,2022-05-27T20:20:25Z,2542.6435185185187
loggit,"
    An effortless 'ndjson' (newline-delimited 'JSON') logger, with two primary
    log-writing interfaces. It provides a set of wrappings for base R's
    message(), warning(), and stop() functions that maintain identical
    functionality, but also log the handler message to an 'ndjson' log file.
    'loggit' also exports its internal 'loggit()' function for powerful and
    configurable custom logging. No change in existing code is necessary to use
    this package, and should only require additions to fully leverage the power
    of the logging system. 'loggit' also provides a log reader for reading an
    'ndjson' log file into a data frame, log rotation, and live echo of the
    'ndjson' log messages to terminal 'stdout' for log capture by external
    systems (like containers). 'loggit' is ideal for Shiny apps, data pipelines,
    modeling work flows, and more. Please see the vignettes for detailed example
    use cases.",2021-02-28,Ryan Price,https://github.com/ryapric/loggit,TRUE,https://github.com/ryapric/loggit,109405,33,2022-04-12T17:08:07Z,3315.3030303030305
logistf,"Fit a logistic regression model using Firth's bias reduction method, equivalent to penalization of the log-likelihood by the Jeffreys 
	prior. Confidence intervals for regression coefficients can be computed by penalized profile likelihood. Firth's method was proposed as ideal
	solution to the problem of separation in logistic regression, see Heinze and Schemper (2002) <doi:10.1002/sim.1047>. If needed, the bias reduction can be turned off such that ordinary
	maximum likelihood logistic regression is obtained. Two new modifications of Firth's method, FLIC and FLAC, lead to unbiased predictions and are now available
	in the package as well, see Puhr et al (2017) <doi:10.1002/sim.7273>.",2022-01-18,Georg Heinze,https://cemsiis.meduniwien.ac.at/en/kb/science-research/software/statistical-software/firth-correction/,TRUE,https://github.com/georgheinze/logistf,517280,5,2022-03-14T13:36:15Z,103456
logitr,"Fast estimation of multinomial (MNL) and mixed logit (MXL) models in R. Models can be estimated using ""Preference"" space or ""Willingness-to-pay"" (WTP) space utility parameterizations. Weighted models can also be estimated. An option is available to run a parallelized multistart optimization loop with random starting points in each iteration, which is useful for non-convex problems like MXL models or models with WTP space utility parameterizations. The main optimization loop uses the 'nloptr' package to minimize the negative log-likelihood function. Additional functions are available for computing and comparing WTP from both preference space and WTP space models and for predicting expected choices and choice probabilities for sets of alternatives based on an estimated model. Mixed logit models can include uncorrelated or correlated heterogeneity covariances and are estimated using maximum simulated likelihood based on the algorithms in Train (2009) ""Discrete Choice Methods with Simulation, 2nd Edition"" <doi:10.1017/CBO9780511805271>.",2022-06-16,John Helveston,https://github.com/jhelvy/logitr,TRUE,https://github.com/jhelvy/logitr,8337,22,2022-07-08T01:05:46Z,378.95454545454544
logmult,"Functions to fit log-multiplicative models using 'gnm', with
  support for convenient printing, plots, and jackknife/bootstrap
  standard errors. For complex survey data, models can be fitted from
  design objects from the 'survey' package. Currently supported models
  include UNIDIFF (Erikson & Goldthorpe, 1992),
  a.k.a. log-multiplicative layer effect model (Xie, 1992)
  <doi:10.2307/2096242>, and several association models:
  Goodman (1979) <doi:10.2307/2286971>
  row-column association models of the RC(M) and RC(M)-L families
  with one or several dimensions; two skew-symmetric association
  models proposed by Yamaguchi (1990) <doi:10.2307/271086>
  and by van der Heijden & Mooijaart (1995) <doi:10.1177/0049124195024001002>
  Functions allow computing the intrinsic association coefficient
  (see Bouchet-Valat (2022) <doi:10.1177/0049124119852389>)
  and the Altham (1970) index <doi:10.1111/j.2517-6161.1970.tb00816.x>,
  including via the Bayes shrinkage estimator proposed
  by Zhou (2015) <doi:10.1177/0081175015570097>;
  and the RAS/IPF/Deming-Stephan algorithm.",2022-02-23,Milan Bouchet-Valat,https://github.com/nalimilan/logmult,TRUE,https://github.com/nalimilan/logmult,20505,3,2022-02-22T17:56:47Z,6835
logr,"Contains functions to help create log files.  The 
    package aims to overcome the difficulty of the base R sink() command.  The
    log_print() function will print to both the console and the file log, 
    without interfering in other write operations.",2022-06-21,David Bosak,https://logr.r-sassy.org,TRUE,https://github.com/dbosak01/logr,21459,10,2022-06-25T12:51:53Z,2145.9
logrx,A utility to facilitate the logging and review of R programs in clinical trial programming workflows.,2022-06-17,Nathan Kosiba,https://github.com/atorus-research/logrx,TRUE,https://github.com/atorus-research/logrx,236,21,2022-06-22T17:29:54Z,11.238095238095237
LongDat,"This tool takes longitudinal dataset as input and analyzes if there is significant 
             change of the features over time (a proxy for treatments), while detects and controls 
             for 'covariates' simultaneously. 'LongDat' is able to take in several data types as input, 
             including count, proportion, binary, ordinal and continuous data. The output table contains 
              p values, effect sizes and 'covariates' of each feature, making the downstream analysis easy.",2022-06-21,Chia-Yu Chen,https://github.com/CCY-dev/LongDat,TRUE,https://github.com/ccy-dev/longdat,2034,0,2022-06-09T15:42:37Z,NA
longmixr,"An adaption of the consensus clustering approach from
    'ConsensusClusterPlus' for longitudinal data. The longitudinal data is
    clustered with flexible mixture models from 'flexmix', while the consensus
    matrices are hierarchically clustered as in 'ConsensusClusterPlus'. By using
    the flexibility from 'flexmix' and 'FactoMineR', one can use mixed data
    types for the clustering.",2022-01-13,Jonas Hagenberg,https://cellmapslab.github.io/longmixr/,TRUE,https://github.com/cellmapslab/longmixr,1202,2,2022-01-18T09:15:07Z,601
loo,"Efficient approximate leave-one-out cross-validation (LOO)
    for Bayesian models fit using Markov chain Monte Carlo, as 
    described in Vehtari, Gelman, and Gabry (2017) 
    <doi:10.1007/s11222-016-9696-4>. 
    The approximation uses Pareto smoothed importance sampling (PSIS), 
    a new procedure for regularizing importance weights. 
    As a byproduct of the calculations, we also obtain approximate 
    standard errors for estimated predictive errors and for the comparison 
    of predictive errors between models. The package also provides methods 
    for using stacking and other model weighting techniques to average 
    Bayesian predictive distributions.",2022-03-24,Jonah Gabry,"https://mc-stan.org/loo/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/loo,1855779,119,2022-03-23T19:16:31Z,15594.781512605043
lookup,Simple functions to lookup items in key-value pairs. See  Mehta (2021) <doi:10.1007/978-1-4842-6613-7_6>.,2021-04-14,Kevin Wright,https://kwstat.github.io/lookup/,TRUE,https://github.com/kwstat/lookup,12918,2,2021-10-20T15:07:35Z,6459
loon,An extendable toolkit for interactive data visualization and exploration.,2022-03-13,R. Wayne Oldford,https://great-northern-diver.github.io/loon/,TRUE,https://github.com/great-northern-diver/loon,26364,41,2022-03-14T15:00:12Z,643.0243902439024
loon.ggplot,Provides a bridge between the 'loon' and  'ggplot2' packages.  Extends the grammar of ggplot to add clauses to create interactive 'loon' plots. Existing ggplot(s) can be turned into interactive 'loon' plots and 'loon' plots into static ggplot(s); the function 'loon.ggplot()' is the bridge from one plot structure to the other.,2022-02-07,Zehao Xu,NA,TRUE,https://github.com/great-northern-diver/loon.ggplot,12213,19,2022-02-07T14:34:10Z,642.7894736842105
loon.tourr,Implement tour algorithms in interactive graphical system 'loon'.,2021-10-27,Zehao Xu,NA,TRUE,https://github.com/z267xu/loon.tourr,6194,0,2021-09-25T15:25:18Z,NA
lorentz,"The Lorentz transform in special relativity; also the gyrogroup structure of three-velocities.  Includes active and passive transforms and the ability to use units in which the speed of light is not one.  For general relativity, see the
  'schwarzschild' package.",2020-09-24,Robin K. S. Hankin,https://github.com/RobinHankin/lorentz,TRUE,https://github.com/robinhankin/lorentz,13743,2,2022-07-01T03:06:44Z,6871.5
lotri,"Provides a simple mechanism to specify a symmetric block
    diagonal matrices (often used for covariance matrices).  This is based
    on the domain specific language implemented in 'nlmixr2' but expanded
    to create matrices in R generally instead of specifying parts of
    matrices to estimate.",2022-06-18,Matthew L. Fidler,https://github.com/nlmixr2/lotri,TRUE,https://github.com/nlmixr2/lotri,30825,2,2022-06-18T16:16:12Z,15412.5
LPDynR,"It uses 'phenological' and productivity-related variables derived from time series of vegetation 
    indexes, such as the Normalized Difference Vegetation Index, to assess ecosystem dynamics and change, which 
    eventually might drive to land degradation. The final result of the Land Productivity Dynamics indicator 
    is a categorical map with 5 classes of land productivity dynamics, ranging from declining to increasing 
    productivity. See <https://eartharxiv.org/repository/view/2294/> for a description of the methods used in 
    the package to calculate the indicator.",2021-05-19,Xavier Rotllan-Puig,https://github.com/xavi-rp/LPDynR,TRUE,https://github.com/xavi-rp/lpdynr,5801,5,2021-11-23T07:37:16Z,1160.2
lpirfs,"Provides functions to estimate and visualize linear as well as nonlinear impulse 
             responses based on local projections by Jordà (2005) <doi:10.1257/0002828053828518>.
             The methods and the package are explained in detail in Adämmer (2019) <doi:10.32614/RJ-2019-052>.",2022-05-30,Philipp Adämmer,NA,TRUE,https://github.com/adaemmerp/lpirfs,26529,22,2022-05-30T10:59:21Z,1205.8636363636363
LREP,"The programs were developed for estimation of parameters and testing exponential versus Pareto distribution during our work on hydrologic extremes. See Kozubowski, T.J., A.K. Panorska, F. Qeadan, and A. Gershunov (2007) <doi:10.1080/03610910802439121>, and Panorska, A.K., A. Gershunov, and T.J. Kozubowski (2007) <doi:10.1007/978-0-387-34918-3_26>.",2021-08-17,Jiqiang Wu,NA,TRUE,https://github.com/jiqiaingwu/lrep,3963,0,2021-08-17T03:34:49Z,NA
lrgs,"Implements a Gibbs sampler to do linear regression with multiple covariates, multiple responses, Gaussian measurement errors on covariates and responses, Gaussian intrinsic scatter, and a covariate prior distribution which is given by either a Gaussian mixture of specified size or a Dirichlet process with a Gaussian base distribution. Described further in Mantz (2016) <DOI:10.1093/mnras/stv3008>.",2020-08-11,Adam Mantz,https://github.com/abmantz/lrgs,TRUE,https://github.com/abmantz/lrgs,18119,14,2022-02-04T19:15:51Z,1294.2142857142858
LRMF3,"Provides S3 classes to represent low rank matrix
    decompositions.",2022-02-09,Alex Hayes,https://github.com/RoheLab/LRMF3,TRUE,https://github.com/rohelab/lrmf3,1321,2,2022-02-09T19:26:08Z,660.5
lsasim,"Provides functions to simulate data from large-scale educational
  assessments, including background questionnaire data and cognitive item
  responses that adhere to a multiple-matrix sampled design. The theoretical
  foundation can be found on
  Matta, T.H., Rutkowski, L., Rutkowski, D. et al. (2018)
  <doi:10.1186/s40536-018-0068-8>.",2021-11-10,Waldir Leoncio,NA,TRUE,https://github.com/tmatta/lsasim,17261,5,2021-11-17T05:35:02Z,3452.2
LSE,"The solution of equality constrained least squares problem (LSE) is
    given through four analytics methods (Generalized QR Factorization, Lagrange 
    Multipliers, Direct Elimination and Null Space method). We expose the 
    orthogonal decomposition called Generalized QR Factorization (GQR) and also RQ 
    factorization. Finally some codes for the solution of LSE applied in 
    quaternions.",2022-02-02,Sergio Andrés Cabrera Miranda,https://github.com/sergio05acm/LSE,TRUE,https://github.com/sergio05acm/lse,1399,0,2022-02-02T20:03:31Z,NA
lsr,"A collection of tools intended to make introductory 
    statistics easier to teach, including wrappers for common 
    hypothesis tests and basic data manipulation. It accompanies 
    Navarro, D. J. (2015). Learning Statistics with R: A Tutorial 
    for Psychology Students and Other Beginners, Version 0.6. ",2021-12-01,Danielle Navarro,https://github.com/djnavarro/lsr,TRUE,https://github.com/djnavarro/lsr,340132,12,2021-12-01T05:23:14Z,28344.333333333332
LSTS,A set of functions that allow stationary analysis and locally stationary time series analysis.,2021-07-29,Mauricio Vargas,https://pacha.dev/LSTS/,TRUE,https://github.com/pachadotdev/lsts,12395,1,2021-08-31T02:35:44Z,12395
LSX,"A word embeddings-based semisupervised model for document scaling Watanabe (2020) <doi:10.1080/19312458.2020.1832976>.
    LSS allows users to analyze large and complex corpora on arbitrary dimensions with seed words exploiting efficiency of word embeddings (SVD, Glove).
    It can generate word vectors on a users-provided corpus or incorporate a pre-trained word vectors.",2022-02-26,Kohei Watanabe,NA,TRUE,https://github.com/koheiw/lsx,12101,42,2022-06-15T11:26:44Z,288.1190476190476
ltm,"Analysis of multivariate dichotomous and polytomous data using latent trait models under the Item Response Theory approach. It includes the Rasch, the Two-Parameter Logistic, the Birnbaum's Three-Parameter, the Graded Response, and the Generalized Partial Credit Models.",2022-02-18,Dimitris Rizopoulos,https://github.com/drizopoulos/ltm,TRUE,https://github.com/drizopoulos/ltm,205377,25,2022-03-06T19:07:34Z,8215.08
ltxsparklines,"Sparklines are small plots (about one line of text high),
  made popular by Edward Tufte.  This package is the interface from R
  to the LaTeX package sparklines by Andreas Loeffer and Dan Luecking
  (<http://www.ctan.org/pkg/sparklines>).  It can work with Sweave or
  knitr or other engines that produce TeX.  The package can be used to
  plot vectors, matrices, data frames, time series (in ts or zoo format).",2022-04-06,Boris Veytsman,https://github.com/borisveytsman/ltxsparklines,TRUE,https://github.com/borisveytsman/ltxsparklines,14276,4,2022-04-06T02:05:21Z,3569
lubridate,"Functions to work with date-times and time-spans:
    fast and user friendly parsing of date-time data, extraction and
    updating of components of a date-time (years, months, days, hours,
    minutes, and seconds), algebraic manipulation on date-time and
    time-span objects. The 'lubridate' package has a consistent and
    memorable syntax that makes working with dates easy and fun.  Parts of
    the 'CCTZ' source code, released under the Apache 2.0 License, are
    included in this package. See <https://github.com/google/cctz> for
    more details.",2021-10-07,Vitalie Spinu,"https://lubridate.tidyverse.org,
https://github.com/tidyverse/lubridate",TRUE,https://github.com/tidyverse/lubridate,23495638,645,2022-05-24T14:57:17Z,36427.34573643411
LUCIDus,"An implementation of LUCID model (Peng (2019) <doi:10.1093/bioinformatics/btz667>).
  LUCID conducts integrated clustering using exposures, omics data (and outcome 
  of interest). An EM algorithm is implemented to estimate MLE of LUCID model.
  LUCID features integrated variable selection, incorporation of missing omics
  data, bootstrap inference and visualization via Sankey diagram.",2022-06-01,Yinqi Zhao,https://github.com/USCbiostats/LUCIDus,TRUE,https://github.com/uscbiostats/lucidus,14977,2,2022-07-07T04:10:05Z,7488.5
ludic,"Probabilistic record linkage without direct identifiers using only 
    diagnosis codes. Method is detailed in: Hejblum, Weber, Liao, Palmer, 
    Churchill, Szolovits, Murphy, Kohane & Cai (2019) <doi: 10.1038/sdata.2018.298> ;
    Zhang, Hejblum, Weber, Palmer, Churchill, Szolovits, Murphy, Liao, Kohane 
    & Cai (2021) <doi: 10.1101/2021.05.02.21256490>.",2021-08-18,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/ludic,20321,0,2021-08-18T10:55:29Z,NA
lumberjack,"A framework that allows for easy logging of changes in data.
    Main features: start tracking changes by adding a single line of code to 
    an existing script. Track changes in multiple datasets, using multiple 
    loggers. Add custom-built loggers or use loggers offered by other 
    packages. <doi:10.18637/jss.v098.i01>.",2021-05-27,Mark van der Loo,https://github.com/markvanderloo/lumberjack,TRUE,https://github.com/markvanderloo/lumberjack,24474,58,2021-07-28T14:50:49Z,421.9655172413793
Luminescence,"A collection of various R functions for the purpose of Luminescence
    dating data analysis. This includes, amongst others, data import, export,
    application of age models, curve deconvolution, sequence analysis and
    plotting of equivalent dose distributions.",2022-03-10,Sebastian Kreutzer,https://CRAN.R-project.org/package=Luminescence,TRUE,https://github.com/r-lum/luminescence,50915,12,2022-03-10T18:49:00Z,4242.916666666667
lutz,"Input latitude and longitude values or an 'sf/sfc' POINT 
    object and get back the time zone in which they exist. Two methods are implemented. 
    One is very fast and uses 'Rcpp' in conjunction with data from the 'Javascript' library
    (<https://github.com/darkskyapp/tz-lookup/>). This method also works outside of countries' 
    borders and in international waters, however speed comes at the cost of accuracy - near time 
    zone borders away from populated centres there is a chance that it will return the incorrect
    time zone. The other method is slower but more accurate - it uses the 'sf' package to intersect 
    points with a detailed map of time zones from here: 
    <https://github.com/evansiroky/timezone-boundary-builder/>. The package also 
    contains several utility functions for helping to understand and visualize 
    time zones, such as listing of world time zones, including information about 
    daylight savings times and their offsets from UTC. You can also plot a 
    time zone to visualize the UTC offset over a year and when daylight savings 
    times are in effect.",2019-07-19,Andy Teucher,https://andyteucher.ca/lutz,TRUE,https://github.com/ateucher/lutz,109614,53,2021-07-17T00:30:57Z,2068.188679245283
luz,"A high level interface for 'torch' providing utilities to reduce the
    the amount of code needed for common tasks, abstract away torch details and 
    make the same code work on both the 'CPU' and 'GPU'. It's flexible enough to
    support expressing a large range of models. It's heavily inspired by 'fastai' by 
    Howard et al. (2020) <arXiv:2002.04688>, 'Keras' by Chollet et al. (2015) and 
    'Pytorch Lightning' by Falcon et al. (2019) <doi:10.5281/zenodo.3828935>.",2021-10-07,Daniel Falbel,"https://mlverse.github.io/luz/, https://github.com/mlverse/luz",TRUE,https://github.com/mlverse/luz,7006,43,2022-05-25T12:17:58Z,162.93023255813952
LWFBrook90R,"Provides a flexible and easy-to use interface for the soil vegetation 
    atmosphere transport (SVAT) model LWF-BROOK90, written in Fortran.
    The model simulates daily transpiration, interception, soil and snow evaporation, 
    streamflow and soil water fluxes through a soil profile covered with vegetation, 
    as described in Hammel & Kennel (2001, ISBN:978-3-933506-16-0) and Federer et al. (2003) 
    <doi:10.1175/1525-7541(2003)004%3C1276:SOAETS%3E2.0.CO;2>. A set of high-level functions
    for model set up, execution and parallelization provides easy access to plot-level SVAT 
    simulations, as well as multi-run and large-scale applications. ",2022-06-13,Paul Schmidt-Walter,"pschmidtwalter.github.io/lwfbrook90r/,
https://github.com/pschmidtwalter/LWFBrook90R",TRUE,https://github.com/pschmidtwalter/lwfbrook90r,6695,5,2022-06-28T09:41:36Z,1339
lwgeom,"Access to selected functions found in 'liblwgeom' <https://github.com/postgis/postgis/tree/master/liblwgeom>, the light-weight geometry library used by 'PostGIS' <http://postgis.net/>.",2021-10-06,Edzer Pebesma,https://github.com/r-spatial/lwgeom/,TRUE,https://github.com/r-spatial/lwgeom,990211,49,2022-03-29T07:25:22Z,20208.38775510204
m61r,"Data manipulation in one package and in base R.
  Minimal. No dependencies.
  'dplyr' and 'tidyr'-like in one place.
  Nothing else than base R to build the package.",2022-05-06,Jean-Marie Lepioufle,https://github.com/pv71u98h1/m61r/,TRUE,https://github.com/pv71u98h1/m61r,5543,1,2022-05-06T14:00:37Z,5543
MAAPER,"A computational method developed for model-based analysis of alternative polyadenylation (APA) using 3' end-linked reads. It accurately assigns 3' RNA-seq reads to polyA sites through statistical modeling, and generates multiple statistics for APA analysis. Please also see Li WV, Zheng D, Wang R, Tian B (2021) <doi:10.1186/s13059-021-02429-5>.",2021-08-14,Wei Vivian Li,"https://github.com/Vivianstats/MAAPER,
https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02429-5",TRUE,https://github.com/vivianstats/maaper,3932,5,2021-08-14T05:18:35Z,786.4
maat,"Provides an extension of the shadow-test approach to computerized adaptive
    testing (CAT) implemented in the 'TestDesign' package for the assessment framework
    involving multiple tests administered periodically throughout the year. This framework
    is referred to as the Multiple Administrations Adaptive Testing (MAAT) and supports
    multiple item pools vertically scaled and multiple phases (stages) of CAT within each test.
    Between phases and tests, transitioning from one item pool (and associated constraints)
    to another is allowed as deemed necessary to enhance the quality of measurement.",2022-05-18,Seung W. Choi,https://choi-phd.github.io/maat/,TRUE,https://github.com/choi-phd/maat,3675,0,2022-06-26T20:47:28Z,NA
MACER,"To assist biological researchers in assembling taxonomically and marker focused molecular sequence data sets. 'MACER' accepts a list of genera as a user input and uses NCBI-GenBank and BOLD as resources to download and assemble molecular sequence datasets. These datasets are then assembled by marker, aligned, trimmed, and cleaned. The use of this package allows the publication of specific parameters to ensure reproducibility. The 'MACER' package has four core functions and an example run through using all of these functions can be found in the associated repository <https://github.com/rgyoung6/MACER_example>.",2021-09-08,Robert G Young,<https://github.com/rgyoung6/MACER>,TRUE,https://github.com/rgyoung6/macer,9084,1,2021-12-13T03:07:16Z,9084
MachineShop,"Meta-package for statistical and machine learning with a unified
    interface for model fitting, prediction, performance assessment, and
    presentation of results.  Approaches for model fitting and prediction of
    numerical, categorical, or censored time-to-event outcomes include
    traditional regression models, regularization methods, tree-based methods,
    support vector machines, neural networks, ensembles, data preprocessing,
    filtering, and model tuning and selection.  Performance metrics are provided
    for model assessment and can be estimated with independent test sets, split
    sampling, cross-validation, or bootstrap resampling.  Resample estimation
    can be executed in parallel for faster processing and nested in cases of
    model tuning and selection.  Modeling results can be summarized with
    descriptive statistics; calibration curves; variable importance; partial
    dependence plots; confusion matrices; and ROC, lift, and other performance
    curves.",2022-06-03,Brian J Smith,https://brian-j-smith.github.io/MachineShop/,TRUE,https://github.com/brian-j-smith/machineshop,24354,58,2022-06-03T12:25:49Z,419.8965517241379
macleish,"Download data from the Ada and Archibald MacLeish Field 
    Station in Whately, MA. The Ada 
    and Archibald MacLeish Field Station is a 260-acre patchwork of 
    forest and farmland located in West Whately, MA that provides opportunities 
    for faculty and students to pursue environmental research, outdoor 
    education, and low-impact recreation 
    (see <https://www.smith.edu/about-smith/sustainable-smith/macleish> for more information). 
    This package contains 
    weather data over several years, and spatial data on various man-made and 
    natural structures.",2022-07-06,Benjamin S. Baumer,https://github.com/beanumber/macleish,TRUE,https://github.com/beanumber/macleish,20285,2,2022-07-06T20:04:47Z,10142.5
maditr,"Provides pipe-style interface for 'data.table'. Package preserves all 'data.table' features without
              significant impact on performance. 'let' and 'take' functions are simplified interfaces for most common data
              manipulation tasks. For example, you can write 'take(mtcars, mean(mpg), by = am)' for aggregation or 
              'let(mtcars, hp_wt = hp/wt, hp_wt_mpg = hp_wt/mpg)' for modification. Use 'take_if/let_if' for conditional
              aggregation/modification. Additionally there are some conveniences such as automatic 'data.frame' 
              conversion to 'data.table'.",2022-04-02,Gregory Demin,https://github.com/gdemin/maditr,TRUE,https://github.com/gdemin/maditr,82649,58,2022-04-02T14:36:26Z,1424.9827586206898
madrat,"Provides a framework which should improve reproducibility and transparency in data processing. It provides functionality such as automatic meta data creation and management, rudimentary quality management, data caching, work-flow management and data aggregation.
    * The title is a wish not a promise. By no means we expect this package to deliver everything what is needed to achieve full reproducibility and transparency, but we believe that it supports efforts in this direction.",2021-10-11,Jan Philipp Dietrich,"https://github.com/pik-piam/madrat,
https://doi.org/10.5281/zenodo.1115490",TRUE,https://github.com/pik-piam/madrat,17541,11,2022-07-08T13:24:31Z,1594.6363636363637
magclass,"Data class for increased interoperability working with spatial-
    temporal data together with corresponding functions and methods (conversions,
    basic calculations and basic data manipulation). The class distinguishes
    between spatial, temporal and other dimensions to facilitate the development
    and interoperability of tools build for it. Additional features are name-based
    addressing of data and internal consistency checks (e.g. checking for the right
    data order in calculations).",2021-09-30,Jan Philipp Dietrich,"https://github.com/pik-piam/magclass,
https://doi.org/10.5281/zenodo.1158580",TRUE,https://github.com/pik-piam/magclass,24799,2,2022-07-05T08:04:58Z,12399.5
magic,"A collection of functions for the manipulation and
 analysis of arbitrarily dimensioned arrays.  The original motivation
 for the package was the development of efficient, vectorized
 algorithms for the creation and investigation of magic squares and
 high-dimensional magic hypercubes.",2022-02-09,Robin K. S. Hankin,https://github.com/RobinHankin/magic,TRUE,https://github.com/robinhankin/magic,510679,1,2022-02-07T01:03:16Z,510679
magickGUI,Enables us to use the functions of the package 'magick' interactively.,2021-07-12,Shota Ochi,https://github.com/ShotaOchi/magickGUI,TRUE,https://github.com/shotaochi/magickgui,16866,6,2021-08-14T16:04:42Z,2811
MagmaClustR,"An implementation for the multi-task Gaussian processes with common 
    mean framework. Two main algorithms, called 'Magma' and 'MagmaClust', 
    are available to perform predictions for supervised learning problems, in
    particular for time series or any functional/continuous data applications.
    The corresponding articles has been respectively proposed by Arthur Leroy, 
    Pierre Latouche, Benjamin Guedj and Servane Gey (2022) 
    <doi:10.1007/s10994-022-06172-1>, and Arthur Leroy, Pierre Latouche, 
    Benjamin Guedj and Servane Gey (2020) <arXiv:2011.07866>.
    Theses approaches leverage the learning of cluster-specific mean processes,
    which are common across similar tasks, to provide enhanced prediction
    performances (even far from data) at a linear computational cost (in
    the number of tasks).  'MagmaClust' is a generalisation of 'Magma'
    where the tasks are simultaneously clustered into groups, each being
    associated to a specific mean process.  User-oriented functions in the
    package are decomposed into training, prediction and plotting
    functions. Some basic features (classic kernels, training, prediction) of
    standard Gaussian processes are also implemented. ",2022-06-06,Arthur Leroy,"https://github.com/ArthurLeroy/MagmaClustR,
https://arthurleroy.github.io/MagmaClustR/",TRUE,https://github.com/arthurleroy/magmaclustr,261,4,2022-07-05T14:28:02Z,65.25
magrittr,"Provides a mechanism for chaining commands with a new
    forward-pipe operator, %>%. This operator will forward a value, or the
    result of an expression, into the next function call/expression.
    There is flexible support for the type of right-hand side expressions.
    For more information, see package vignette.  To quote Rene Magritte,
    ""Ceci n'est pas un pipe.""",2022-03-30,Lionel Henry,"https://magrittr.tidyverse.org,
https://github.com/tidyverse/magrittr",TRUE,https://github.com/tidyverse/magrittr,61734632,898,2022-03-30T11:46:10Z,68746.80623608019
maic,"A generalised workflow for generation of subject weights to be 
    used in Matching-Adjusted Indirect Comparison (MAIC) per Signorovitch et 
    al. (2012) <doi:10.1016/j.jval.2012.05.004>, Signorovitch et al (2010) 
    <doi:10.2165/11538370-000000000-00000>. In MAIC, unbiased 
    comparison between outcomes of two trials is facilitated by weighting the
    subject-level outcomes of one trial with weights derived such that the 
    weighted aggregate measures of the prognostic or effect modifying variables 
    are equal to those of the sample in the comparator trial. The functions and
    classes included in this package wrap and abstract the process demonstrated
    in the UK National Institute for Health and Care Excellence Decision 
    Support Unit (NICE DSU)'s example (Phillippo et al, (2016) [see URL]),
    providing a repeatable and easily specifiable workflow for producing 
    multiple comparison variable sets against a variety of target studies, with
    preprocessing for a number of aggregate target forms (e.g. mean, median, 
    domain limits).",2022-04-27,Rob Young,"https://github.com/heorltd/maic,
https://nicedsu.sites.sheffield.ac.uk/tsds/population-adjusted-indirect-comparisons-maic-and-stc",TRUE,https://github.com/heorltd/maic,10083,5,2022-04-29T14:05:17Z,2016.6
mailmerge,"Perform a mail merge (mass email) using the message defined in 
    markdown, the recipients in a 'csv' file, and gmail as the mailing engine. 
    With this package you can parse markdown documents as the body of email, and 
    the 'yaml' header to specify the subject line of the email.  Any '{}' braces 
    in the email will be encoded with 'glue::glue()'. You can preview the email 
    in the RStudio viewer pane, and send (draft) email using 'gmailr'.",2022-03-07,Andrie de Vries,"https://andrie.github.io/mailmerge/,
https://github.com/andrie/mailmerge",TRUE,https://github.com/andrie/mailmerge,6438,40,2022-03-07T16:28:17Z,160.95
mailR,"Interface to Apache Commons Email to send emails
    from R.",2021-12-03,Rahul Premraj,https://github.com/rpremrajGit/mailR,TRUE,https://github.com/rpremrajgit/mailr,771578,10,2021-11-04T22:12:38Z,77157.8
makePalette,"Functions that allow you to create your own color palette from an image, using mathematical algorithms.",2022-06-23,Jorge L. C. Musaja,https://github.com/musajajorge/makePalette,TRUE,https://github.com/musajajorge/makepalette,162,1,2022-06-25T00:12:34Z,162
makepipe,"A suite of tools for transforming an existing workflow into a
    self-documenting pipeline with very minimal upfront costs. Segments of
    the pipeline are specified in much the same way a 'Make' rule is, by
    declaring an executable recipe (which might be an R script), along
    with the corresponding targets and dependencies. When the entire
    pipeline is run through, only those recipes that need to be executed
    will be. Meanwhile, execution metadata is captured behind the scenes
    for later inspection.",2022-05-13,Kinto Behr,"https://kinto-b.github.io/makepipe/,
https://github.com/kinto-b/makepipe",TRUE,https://github.com/kinto-b/makepipe,3372,21,2022-05-13T07:51:31Z,160.57142857142858
maketools,"A collection of helper functions that interface with the appropriate
    system utilities to learn about the build environment. Lets you explore 'make' 
    rules to test the local configuration, or query 'pkg-config' to find compiler
    flags and libs needed for building packages with external dependencies. Also
    contains tools to analyze which libraries that a installed R package linked to
    by inspecting output from 'ldd' in combination with information from your
    distribution package manager, e.g. 'rpm' or 'dpkg'. Finally the package provides
    Windows-specific utilities to automatically find or install the suitable version
    of the 'Rtools' build environment, and diagnose some common problems.",2022-02-25,Jeroen Ooms,https://github.com/jeroen/maketools,TRUE,https://github.com/jeroen/maketools,8056,11,2022-02-25T10:18:14Z,732.3636363636364
malariaAtlas,"A suite of tools to allow you to download all 
  publicly available parasite rate survey points, mosquito occurrence points and raster surfaces from 
  the 'Malaria Atlas Project' <https://malariaatlas.org/> servers as well as utility functions for plotting
  the downloaded data.",2020-06-01,Daniel Pfeffer,https://github.com/malaria-atlas-project/malariaAtlas,TRUE,https://github.com/malaria-atlas-project/malariaatlas,16780,30,2021-08-03T01:36:09Z,559.3333333333334
malaytextr,"It is designed to work with text written in Bahasa Malaysia. We provide 
    functions and data sets that will make working with Bahasa Malaysia text much easier. 
    For word stemming in particular, we will look up the Malay words in a dictionary and
    then proceed to remove ""extra suffix"" as explained in Khan, Rehman Ullah, 
    Fitri Suraya Mohamad, Muh Inam UlHaq, Shahren Ahmad Zadi Adruce, 
    Philip Nuli Anding, Sajjad Nawaz Khan, and Abdulrazak Yahya Saleh Al-Hababi
    (2017) <https://ijrest.net/vol-4-issue-12.html> . This package includes
    a dictionary of Malay words that may be used to perform word stemming.",2021-10-23,Zahier Nasrudin,https://github.com/zahiernasrudin/malaytextr,TRUE,https://github.com/zahiernasrudin/malaytextr,3749,3,2021-10-23T11:14:03Z,1249.6666666666667
MALDIrppa,Provides methods for quality control and robust pre-processing and analysis of MALDI mass spectrometry data (Palarea-Albaladejo et al. (2018) <doi:10.1093/bioinformatics/btx628>).,2022-03-29,Javier Palarea-Albaladejo,https://github.com/Japal/MALDIrppa,TRUE,https://github.com/japal/maldirppa,18315,2,2022-03-26T18:13:48Z,9157.5
manipulateWidget,"Like package 'manipulate' does for static graphics, this package
    helps to easily add controls like sliders, pickers, checkboxes, etc. that 
    can be used to modify the input data or the parameters of an interactive 
    chart created with package 'htmlwidgets'.",2021-10-05,Veronique Bachelier,https://github.com/rte-antares-rpackage/manipulateWidget,TRUE,https://github.com/rte-antares-rpackage/manipulatewidget,1210773,123,2021-10-05T08:21:24Z,9843.682926829268
MAnorm2,"Chromatin immunoprecipitation followed by high-throughput
    sequencing (ChIP-seq) is the premier technology for profiling genome-wide
    localization of chromatin-binding proteins, including transcription
    factors and histones with various modifications.
    This package provides a robust method for normalizing ChIP-seq
    signals across individual samples or groups of samples. It also designs
    a self-contained system of statistical models for calling differential
    ChIP-seq signals between two or more biological conditions as well as
    for calling hypervariable ChIP-seq signals across samples. Refer to
    Tu et al. (2021) <doi:10.1101/gr.262675.120> and
    Chen et al. (2021) <doi:10.1101/2021.07.27.453915>
    for associated statistical details.",2021-09-13,Shiqi Tu,https://github.com/tushiqi/MAnorm2,TRUE,https://github.com/tushiqi/manorm2,3388,15,2021-11-08T12:18:27Z,225.86666666666667
MANOVA.RM,"Implemented are various tests for semi-parametric repeated measures
    and general MANOVA designs that do neither assume multivariate normality nor
    covariance homogeneity, i.e., the procedures are applicable for a wide range
    of general multivariate factorial designs. In addition to asymptotic inference
    methods, novel bootstrap and permutation approaches are implemented as well. These provide more
    accurate results in case of small to moderate sample sizes. Furthermore, post-hoc 
    comparisons are provided for the multivariate analyses.
    Friedrich, S., Konietschke, F. and Pauly, M. (2019) <doi:10.32614/RJ-2019-051>.",2022-01-18,Sarah Friedrich,https://github.com/smn74/MANOVA.RM,TRUE,https://github.com/smn74/manova.rm,27275,4,2021-11-16T14:33:05Z,6818.75
manydata,"This is the core package for the many packages universe.
    It includes functions to help researchers work with and contribute to 
    event datasets on global governance.",2022-06-07,James Hollway,https://github.com/globalgov/manydata,TRUE,https://github.com/globalgov/manydata,1043,6,2022-06-07T09:49:06Z,173.83333333333334
manymodelr,"Frequently one needs a convenient way to build and tune
             several models in one go.The goal is to provide a number of machine learning convenience 
             functions. It provides the ability to build, tune and obtain predictions of 
             several models in one function. The models are built using functions from
             'caret' with easier to read syntax.
             Kuhn(2014) <arXiv:1405.6974>.",2021-11-15,Nelson Gonzabato,https://github.com/Nelson-Gon/manymodelr,TRUE,https://github.com/nelson-gon/manymodelr,16333,2,2021-12-27T15:50:28Z,8166.5
maotai,"Matrix is an universal and sometimes primary object/unit in applied mathematics and statistics. We provide a number of algorithms for selected problems in optimization and statistical inference. For general exposition to the topic with focus on statistical context, see the book by Banerjee and Roy (2014, ISBN:9781420095388).",2022-02-03,Kisung You,https://github.com/kisungyou/maotai,TRUE,https://github.com/kisungyou/maotai,45489,7,2022-03-05T03:48:39Z,6498.428571428572
mapbayr,"Performs maximum a posteriori Bayesian estimation of individual pharmacokinetic parameters from a model defined in 'mrgsolve', typically for model-based therapeutic drug monitoring. Internally computes an objective function value from model and data, performs optimization and returns predictions in a convenient format. The performance of the package was described by Le Louedec et al (2021) <doi:10.1002/psp4.12689>.",2022-05-26,Felicien Le Louedec,https://github.com/FelicienLL/mapbayr,TRUE,https://github.com/felicienll/mapbayr,5902,12,2022-05-27T08:32:43Z,491.8333333333333
mapboxer,"Makes 'Mapbox GL JS' <https://docs.mapbox.com/mapbox-gl-js/api/>,
  an open source JavaScript library that uses WebGL to render interactive maps,
  available within R via the 'htmlwidgets' package. Visualizations can be used from the R console,
  in R Markdown documents and in Shiny apps.",2020-11-04,Stefan Kuethe,https://github.com/crazycapivara/mapboxer,TRUE,https://github.com/crazycapivara/mapboxer,7229,39,2021-11-11T12:30:20Z,185.35897435897436
mapdeck,"Provides a mechanism to plot an interactive map using 'Mapbox GL' 
		(<https://docs.mapbox.com/mapbox-gl-js/api/>), a javascript library for interactive maps,
		and 'Deck.gl' (<https://deck.gl/>), a javascript library which uses 'WebGL' for 
		visualising large data sets.",2020-09-04,David Cooley,https://symbolixau.github.io/mapdeck/articles/mapdeck.html,TRUE,https://github.com/symbolixau/mapdeck,220090,334,2022-06-10T03:38:27Z,658.9520958083832
mapedit,"Suite of interactive functions and helpers for selecting and editing
    geospatial data.",2020-02-02,Tim Appelhans,https://github.com/r-spatial/mapedit,TRUE,https://github.com/r-spatial/mapedit,135686,202,2022-03-19T09:12:27Z,671.7128712871287
mapfit,"Estimation methods for phase-type
  distribution (PH) and Markovian arrival process (MAP) from
  empirical data (point and grouped data) and density function.",2022-05-30,Hiroyuki Okamura,https://github.com/okamumu/mapfit,TRUE,https://github.com/okamumu/mapfit,15196,0,2022-07-04T23:44:47Z,NA
mapiso,"Regularly spaced grids containing continuous data are transformed
    to contour polygons. A grid can be defined by a data.frame (x, y, value),
    an 'sf' object or a raster from 'terra'.",2022-07-07,Timothée Giraud,https://github.com/riatelab/mapiso,TRUE,https://github.com/riatelab/mapiso,192,8,2022-07-07T07:38:28Z,24
mapme.biodiversity,"Biodiversity areas, especially primary forest, serve a
    multitude of functions for local economy, regional functionality of
    the ecosystems as well as the global health of our planet. Recently,
    adverse changes in human land use practices and climatic responses to
    increased greenhouse gas emissions, put these biodiversity areas under
    a variety of different threats. The present package helps to analyse a
    number of biodiversity indicators based on freely available
    geographical datasets. It supports computational efficient routines
    that allow the analysis of potentially global biodiversity portfolios.
    The primary use case of the package is to support evidence based
    reporting of an organization's effort to protect biodiversity areas
    under threat and to identify regions were intervention is most duly
    needed.",2022-06-24,Darius A. Görgen,"https://mapme-initiative.github.io/mapme.biodiversity/index.html,
https://github.com/mapme-initiative/mapme.biodiversity/",TRUE,https://github.com/mapme-initiative/mapme.biodiversity,882,10,2022-06-24T09:51:38Z,88.2
mapping,"Maps are an important tool to visualise variables distribution across different spatial object. The mapping process require to link the data with coordinates and then generate the correspondent map. This package provide coordinates, linking and mapping functions for an automatic, flexible and easy approach of mapping workflow of different geographical statistical unit.Geographical coordinates are provided in the package and automatically linked with the input data to generate maps with internal provided functions or external functions.provide an easy, flexible and automatic approach to potentially download updated coordinates, to link statistical units with coordinates and to aggregate variables based on the spatial hierarchy of units. The object returned from the package can be used for thematic maps with the build-in functions provided in mapping or with other packages already available.",2021-07-22,Alessio Serafini,https://github.com/serafinialessio/mapping,TRUE,https://github.com/serafinialessio/mapping,7704,2,2021-07-22T17:21:07Z,3852
mappoly,"Construction of genetic maps in autopolyploid full-sib populations. 
             Uses pairwise recombination fraction estimation as the first 
             source of information to sequentially position allelic variants 
             in specific homologues. For situations where pairwise analysis has 
             limited power, the algorithm relies on the multilocus likelihood 
             obtained through a hidden Markov model (HMM). For more detail,
             please see  Mollinari and Garcia (2019) <doi:10.1534/g3.119.400378> 
             and Mollinari et al. (2020) <doi:10.1534/g3.119.400620>.",2022-07-06,Marcelo Mollinari,https://github.com/mmollina/MAPpoly,TRUE,https://github.com/mmollina/mappoly,8770,14,2022-07-06T03:35:13Z,626.4285714285714
mappp,"Provides one function, which is a wrapper around purrr::map() with some extras on top, including parallel computation, progress bars, error handling, and result caching.",2022-01-25,Cole Brokamp,https://github.com/cole-brokamp/mappp,TRUE,https://github.com/cole-brokamp/mappp,1468,10,2022-01-25T13:41:58Z,146.8
mapsapi,"Interface to the 'Google Maps' APIs: (1) routing directions based on the 'Directions' API, returned as 'sf' objects, either as single feature per alternative route, or a single feature per segment per alternative route; (2) travel distance or time matrices based on the 'Distance Matrix' API; (3) geocoded locations based on the 'Geocode' API, returned as 'sf' objects, either points or bounds; (4) map images using the 'Maps Static' API, returned as 'stars' objects.",2022-01-13,Michael Dorman,"https://michaeldorman.github.io/mapsapi/,
https://github.com/michaeldorman/mapsapi/",TRUE,https://github.com/michaeldorman/mapsapi,33316,47,2022-01-13T12:42:54Z,708.8510638297872
mapscanner,"Enables preparation of maps to be printed and drawn on.
    Modified maps can then be scanned back in, and hand-drawn marks
    converted to spatial objects.",2021-11-25,Mark Padgham,https://github.com/ropensci/mapscanner,TRUE,https://github.com/ropensci/mapscanner,2287,83,2022-03-23T14:57:22Z,27.55421686746988
mapsf,"Create and integrate thematic maps in your workflow. This package
    helps to design various cartographic representations such as proportional
    symbols, choropleth or typology maps. It also offers several functions to
    display layout elements that improve the graphic presentation of maps
    (e.g. scale bar, north arrow, title, labels). 'mapsf' maps 'sf' objects on
    'base' graphics.",2022-05-30,Timothée Giraud,"https://github.com/riatelab/mapsf/,
https://riatelab.github.io/mapsf/",TRUE,https://github.com/riatelab/mapsf,16010,180,2022-05-31T15:59:43Z,88.94444444444444
mapSpain,"Administrative Boundaries of Spain at several levels
    (Autonomous Communities, Provinces, Municipalities) based on the
    'GISCO' 'Eurostat' database <https://ec.europa.eu/eurostat/web/gisco>
    and 'CartoBase SIANE' from 'Instituto Geografico Nacional'
    <https://www.ign.es/>.  It also provides a 'leaflet' plugin and the
    ability of downloading and processing static tiles.",2022-02-25,Diego Hernangómez,"https://ropenspain.github.io/mapSpain/,
https://github.com/rOpenSpain/mapSpain",TRUE,https://github.com/ropenspain/mapspain,13445,23,2022-07-04T19:42:12Z,584.5652173913044
mapsPERU,"Information of the centroids and geographical limits of the regions, departments, provinces and districts of Peru.",2021-12-03,Jorge L. C. Musaja,https://github.com/musajajorge/mapsPERU,TRUE,https://github.com/musajajorge/mapsperu,3045,3,2022-02-22T04:17:41Z,1015
maptiles,"To create maps from tiles, 'maptiles' downloads, composes and
    displays tiles from a large number of providers (e.g. 'OpenStreetMap',
    'Stamen', 'Esri', 'CARTO', or 'Thunderforest').",2021-09-24,Timothée Giraud,https://github.com/riatelab/maptiles/,TRUE,https://github.com/riatelab/maptiles,12492,65,2022-02-18T11:02:06Z,192.1846153846154
mapview,"Quickly and conveniently create interactive
    visualisations of spatial data with or without background maps.
    Attributes of displayed features are fully queryable via pop-up
    windows. Additional functionality includes methods to visualise true-
    and false-color raster images and bounding boxes.",2022-04-16,Tim Appelhans,https://github.com/r-spatial/mapview,TRUE,https://github.com/r-spatial/mapview,738180,432,2022-05-08T09:12:35Z,1708.75
margaret,The target of 'margaret' is help to extract data from Minciencias to analyze scientific production in Colombia.,2022-04-27,Sebastian Robledo,https://github.com/coreofscience/margaret,TRUE,https://github.com/coreofscience/margaret,1319,0,2022-04-27T20:07:05Z,NA
mark,"Miscellaneous functions and wrappers for development in other 
    packages created, maintained by Jordan Mark Barbone.",2022-03-09,Jordan Mark Barbone,"https://github.com/jmbarbone/mark,
https://jmbarbone.github.io/mark/",TRUE,https://github.com/jmbarbone/mark,5484,3,2022-07-06T02:40:44Z,1828
markets,"Provides estimation methods for markets in equilibrium and
    disequilibrium. Supports the estimation of an equilibrium and
    four disequilibrium models with both correlated and independent shocks.
    Also provides post-estimation analysis tools, such as aggregation,
    marginal effect, and shortage calculations. The estimation methods are
    based on full information maximum likelihood techniques given in
    Maddala and Nelson (1974) <doi:10.2307/1914215>. They are implemented
    using the analytic derivative expressions calculated in
    Karapanagiotis (2020) <doi:10.2139/ssrn.3525622>. Standard
    errors can be estimated by adjusting for heteroscedasticity or clustering.
    The equilibrium estimation constitutes a case of a system of linear,
    simultaneous equations. Instead, the disequilibrium models replace the
    market-clearing condition with a non-linear,
    short-side rule and allow for different specifications of price dynamics. ",2022-07-05,Pantelis Karapanagiotis,"https://github.com/pi-kappa-devel/markets/,
https://markets.pikappa.eu/",TRUE,https://github.com/pi-kappa-devel/markets,502,1,2022-07-09T13:28:54Z,502
markovchain,"Functions and S4 methods to create and manage discrete time Markov
    chains more easily. In addition functions to perform statistical (fitting
    and drawing random variates) and probabilistic (analysis of their structural
    proprieties) analysis are provided. See Spedicato (2017) <doi:10.32614/RJ-2017-036>.",2022-07-01,Giorgio Alfredo Spedicato,https://github.com/spedygiorgio/markovchain/,TRUE,https://github.com/spedygiorgio/markovchain,619445,92,2022-07-01T11:30:32Z,6733.097826086957
marmap,"Import xyz data from the NOAA (National Oceanic and Atmospheric Administration, <https://www.noaa.gov>), GEBCO (General Bathymetric Chart of the Oceans, <https://www.gebco.net>) and other sources, plot xyz data to prepare publication-ready figures, analyze xyz data to extract transects, get depth / altitude based on geographical coordinates, or calculate z-constrained least-cost paths.",2021-11-10,Eric Pante,https://github.com/ericpante/marmap,TRUE,https://github.com/ericpante/marmap,54992,22,2022-03-25T14:30:44Z,2499.6363636363635
marqLevAlg,"This algorithm provides a numerical solution to the
        problem of unconstrained local minimization (or maximization). It is particularly suited for complex problems and more efficient than
        the Gauss-Newton-like algorithm when starting from points very
        far from the final minimum (or maximum). Each iteration is parallelized and convergence relies on a stringent stopping criterion based on the first and second derivatives. See Philipps et al, 2021 <doi:10.32614/RJ-2021-089>.",2022-07-08,Viviane Philipps,NA,TRUE,https://github.com/vivianephilipps/marqlevalgparallel,27336,3,2022-07-08T12:23:12Z,9112
MARSS,"The MARSS package provides maximum-likelihood parameter estimation for constrained and unconstrained linear multivariate autoregressive state-space (MARSS) models fit to multivariate time-series data.  Fitting is primarily via an Expectation-Maximization (EM) algorithm, although fitting via the BFGS algorithm (using the optim function) is also provided.  MARSS models are a class of dynamic linear model (DLM) and vector autoregressive model (VAR) model.  Functions are provided for parametric and innovations bootstrapping, Kalman filtering and smoothing, bootstrap model selection criteria (AICb), confidences intervals via the Hessian approximation and via bootstrapping and calculation of auxiliary residuals for detecting outliers and shocks.  The user guide shows examples of using MARSS for parameter estimation for a variety of applications, model selection, dynamic factor analysis, outlier and shock detection, and addition of covariates.  Online workshops (lectures, eBook, and computer labs) at <https://atsa-es.github.io/>  See the NEWS file for update information.",2021-12-15,Elizabeth Eli Holmes,https://atsa-es.github.io/MARSS/,TRUE,https://github.com/atsa-es/marss,56074,41,2022-05-26T05:05:28Z,1367.658536585366
mashr,"Implements the multivariate adaptive shrinkage (mash)
    method of Urbut et al (2019) <DOI:10.1038/s41588-018-0268-8> for
    estimating and testing large numbers of effects in many conditions
    (or many outcomes). Mash takes an empirical Bayes approach to
    testing and effect estimation; it estimates patterns of similarity
    among conditions, then exploits these patterns to improve accuracy
    of the effect estimates. The core linear algebra is implemented in
    C++ for fast model fitting and posterior computation.",2022-01-25,Peter Carbonetto,https://github.com/stephenslab/mashr,TRUE,https://github.com/stephenslab/mashr,10344,67,2022-04-19T15:28:04Z,154.38805970149255
Matching,"Provides functions for multivariate and propensity score matching 
             and for finding optimal balance based on a genetic search algorithm. 
             A variety of univariate and multivariate metrics to
             determine if balance has been obtained are also provided. For
             details, see the paper by Jasjeet Sekhon 
             (2007, <doi:10.18637/jss.v042.i07>).",2022-04-14,Jasjeet Singh Sekhon,https://github.com/JasjeetSekhon/Matching,TRUE,https://github.com/jasjeetsekhon/matching,360342,14,2022-04-14T02:15:31Z,25738.714285714286
MatchIt,"Selects matched samples of the original treated and
    control groups with similar covariate distributions -- can be
    used to match exactly on covariates, to match on propensity
    scores, or perform a variety of other matching procedures.  The
    package also implements a series of recommendations offered in
    Ho, Imai, King, and Stuart (2007) <DOI:10.1093/pan/mpl013>. (The 
    'gurobi' package, which is not on CRAN, is optional and comes with 
    an installation of the Gurobi Optimizer, available at 
    <https://www.gurobi.com>.)",2022-05-18,Daniel Ho,"https://kosukeimai.github.io/MatchIt/,
https://github.com/kosukeimai/MatchIt",TRUE,https://github.com/kosukeimai/matchit,841018,115,2022-06-20T02:53:27Z,7313.2
MatchThem,"Provides the necessary tools for the pre-processing techniques of matching and weighting multiply imputed datasets to control for effects of confounders and to reduce the degree of dependence on certain modeling assumptions in studying the causal associations between an exposure and an outcome. This package includes functions to perform matching within and across the multiply imputed datasets using several matching methods, to estimate weights of units in the imputed datasets using several weighting methods, to calculate the causal effect estimate in each matched or weighted dataset using parametric or non-parametric statistical models, and to pool the obtained estimates from these models according to Rubin's rules (please see <https://journal.r-project.org/archive/2021/RJ-2021-073/> for details).",2021-08-23,Farhad Pishgar,https://github.com/FarhadPishgar/MatchThem,TRUE,https://github.com/farhadpishgar/matchthem,25082,6,2021-11-10T19:51:55Z,4180.333333333333
materialmodifier,"You can apply image processing effects that modifies the perceived material properties of objects
    in photos, such as gloss, smoothness, and blemishes. This is an implementation of the algorithm proposed by
    Boyadzhiev et al. (2015) ""Band-Sifting Decomposition for Image Based Material Editing"".
    Documentation and practical tips of the package is available at <https://github.com/tsuda16k/materialmodifier>.",2021-08-11,Hiroyuki Tsuda,https://github.com/tsuda16k/materialmodifier,TRUE,https://github.com/tsuda16k/materialmodifier,4918,3,2021-11-07T12:48:33Z,1639.3333333333333
mathjaxr,Provides 'MathJax' and macros to enable its use within Rd files for rendering equations in the HTML help files.,2022-02-28,Wolfgang Viechtbauer,https://github.com/wviechtb/mathjaxr,TRUE,https://github.com/wviechtb/mathjaxr,527853,41,2022-02-28T18:15:02Z,12874.463414634147
mathpix,"Given an image of a formula (typeset or handwritten) this package
    provides calls to the 'Mathpix' service to produce the 'LaTeX' code which should
    generate that image, and pastes it into a (e.g. an 'rmarkdown') document. 
    See <https://docs.mathpix.com/> for full details. 'Mathpix' is an external service 
    and use of the API is subject to their terms and conditions.",2022-04-02,Jonathan Carroll,https://github.com/jonocarroll/mathpix,TRUE,https://github.com/jonocarroll/mathpix,20188,239,2022-04-02T11:34:59Z,84.46861924686192
matlib,"A collection of matrix functions for teaching and learning matrix
    linear algebra as used in multivariate statistical methods. These functions are
    mainly for tutorial purposes in learning matrix algebra ideas using R. In some
    cases, functions are provided for concepts available elsewhere in R, but where
    the function call or name is not obvious. In other cases, functions are provided
    to show or demonstrate an algorithm. In addition, a collection of functions are
    provided for drawing vector diagrams in 2D and 3D.",2021-08-21,Michael Friendly,https://github.com/friendly/matlib,TRUE,https://github.com/friendly/matlib,186647,55,2021-08-21T08:18:52Z,3393.581818181818
MatrixCorrelation,"Computation and visualization of matrix correlation coefficients.
    The main method is the Similarity of Matrices Index, while various related
    measures like r1, r2, r3, r4, Yanai's GCD, RV, RV2, adjusted RV, Rozeboom's
    linear correlation and Coxhead's coefficient are included
    for comparison and flexibility.",2022-04-18,Kristian Hovde Liland,https://github.com/khliland/MatrixCorrelation/,TRUE,https://github.com/khliland/matrixcorrelation,20920,0,2022-04-18T18:48:02Z,NA
MatrixEQTL,"Matrix eQTL is designed for fast eQTL analysis on large datasets.
        Matrix eQTL can test for association between genotype 
        and gene expression using linear regression 
        with either additive or ANOVA genotype effects.
        The models can include covariates to account for factors 
        as population stratification, gender, and clinical variables. 
        It also supports models with heteroscedastic and/or correlated errors,
        false discovery rate estimation and 
        separate treatment of local (cis) and distant (trans) eQTLs.
        For more details see Shabalin (2012) <doi:10.1093/bioinformatics/bts163>.",2019-12-22,Andrey A Shabalin,http://www.bios.unc.edu/research/genomic_software/Matrix_eQTL/,TRUE,https://github.com/andreyshabalin/matrixeqtl,383764,31,2022-05-09T07:28:16Z,12379.483870967742
MatrixExtra,"Extends sparse matrix and vector classes from the 'Matrix' package by providing: 
  (a) Methods and operators that work natively on CSR formats (compressed sparse row, 
  a.k.a. 'RsparseMatrix') such as slicing/sub-setting, assignment, rbind(), 
  mathematical operators for CSR and COO such as addition (""+"") or sqrt(), and methods such as diag(); 
  (b) Multi-threaded matrix multiplication and cross-product for many <sparse, dense> types, 
  including the 'float32' type from 'float'; 
  (c) Coercion methods between pairs of classes which are not present in 'Matrix', 
  such as 'dgCMatrix' -> 'ngRMatrix', as well as convenience conversion functions; 
  (d) Utility functions for sparse matrices such as sorting the indices or removing 
  zero-valued entries; 
  (e) Fast transposes that work by outputting in the opposite storage format;
  (f) Faster replacements for many 'Matrix' methods for all sparse types, such as
  slicing and elementwise multiplication.
  (g) Convenience functions for sparse objects, such as 'mapSparse' or a shorter 'show' method.",2022-05-15,David Cortes,https://github.com/david-cortes/MatrixExtra,TRUE,https://github.com/david-cortes/matrixextra,65980,13,2022-06-26T14:28:14Z,5075.384615384615
matrixNormal,"Computes densities, probabilities, and random deviates of the Matrix Normal (Iranmanesh et al. (2010) <doi:10.7508/ijmsi.2010.02.004>). Also includes simple but useful matrix functions. See the vignette for more information. ",2022-01-03,Paul M. Hargarten,NA,TRUE,https://github.com/phargarten2/matrixnormal,18919,1,2021-12-30T15:44:04Z,18919
matrixprofiler,"This is the core functions needed by the 'tsmp' package.  The
    low level and carefully checked mathematical functions are here.
    These are implementations of the Matrix Profile concept that was
    created by CS-UCR <http://www.cs.ucr.edu/~eamonn/MatrixProfile.html>.",2021-11-23,Francisco Bischoff,https://github.com/matrix-profile-foundation/matrixprofiler,TRUE,https://github.com/matrix-profile-foundation/matrixprofiler,6420,6,2021-11-26T05:03:48Z,1070
matrixStats,"High-performing functions operating on rows and columns of matrices, e.g. col / rowMedians(), col / rowRanks(), and col / rowSds().  Functions optimized per data type and for subsetted calculations such that both memory usage and processing time is minimized.  There are also optimized vector-based methods, e.g. binMeans(), madDiff() and weightedMedian().",2022-04-19,Henrik Bengtsson,https://github.com/HenrikBengtsson/matrixStats,TRUE,https://github.com/henrikbengtsson/matrixstats,10410719,172,2022-04-19T15:24:04Z,60527.436046511626
matrixTests,"Functions to perform fast statistical hypothesis tests on rows/columns of matrices.
  The main goals are: 1) speed via vectorization, 2) output that is detailed and easy to use,
  3) compatibility with tests implemented in R (like those available in the 'stats' package).",2021-10-12,Karolis Koncevičius,https://github.com/karoliskoncevicius/matrixTests,TRUE,https://github.com/karoliskoncevicius/matrixtests,30447,29,2022-03-01T21:23:51Z,1049.896551724138
matsbyname,"An implementation of matrix mathematics wherein operations are performed ""by name.""",2022-04-01,Matthew Heun,https://github.com/MatthewHeun/matsbyname,TRUE,https://github.com/matthewheun/matsbyname,23840,0,2022-04-01T19:43:55Z,NA
matsindf,"Provides functions to collapse a tidy data frame into matrices in a data frame
    and expand a data frame of matrices into a tidy data frame.",2022-05-19,Matthew Heun,https://github.com/MatthewHeun/matsindf,TRUE,https://github.com/matthewheun/matsindf,18926,3,2022-05-19T15:44:51Z,6308.666666666667
mau,"Provides functions for the creation, evaluation and test of decision models based in
    Multi Attribute Utility Theory (MAUT). Can process and evaluate local risk aversion utilities
    for a set of indexes, compute utilities and weights for the whole decision tree defining the
    decision model and simulate weights employing Dirichlet distributions under addition constraints 
    in weights.",2018-01-17,Pedro Guarderas,https://github.com/pedroguarderas/mau,TRUE,https://github.com/pedroguarderas/mau,14080,1,2022-05-25T21:25:45Z,14080
maybe,"
    The maybe type represents the possibility of some value or nothing. 
    It is often used instead of throwing an error or returning `NULL`.
    The advantage of using a maybe type over `NULL` is that it is both composable 
    and requires the developer to explicitly acknowledge the potential absence 
    of a value, helping to avoid the existence of unexpected behaviour.",2022-05-28,Andrew McNeil,"https://github.com/armcn/maybe, https://armcn.github.io/maybe/",TRUE,https://github.com/armcn/maybe,1561,41,2022-06-07T02:09:40Z,38.073170731707314
MazamaCoreUtils,"A suite of utility functions providing functionality commonly
    needed for production level projects such as logging, error handling,
    cache management and date-time parsing. Functions for date-time parsing and 
    formatting require that time zones be specified explicitly, avoiding a common 
    source of error when working with environmental time series.",2021-11-11,Jonathan Callahan,https://github.com/MazamaScience/MazamaCoreUtils,TRUE,https://github.com/mazamascience/mazamacoreutils,24984,3,2021-11-19T13:54:53Z,8328
MazamaLocationUtils,"Utility functions for discovering and managing metadata 
    associated with spatially unique ""known locations"". Applications include
    all fields of environmental monitoring (e.g. air and water quality) where 
    data are collected at stationary sites.",2022-02-11,Jonathan Callahan,https://github.com/MazamaScience/MazamaLocationUtils,TRUE,https://github.com/mazamascience/mazamalocationutils,17461,0,2022-05-06T18:51:20Z,NA
MazamaRollUtils,"A suite of compiled functions calculating rolling mins, means, 
    maxes and other statistics. This package is designed to meet the needs of
    data processing systems for environmental time series.",2021-09-23,Jonathan Callahan,https://github.com/MazamaScience/MazamaRollUtils,TRUE,https://github.com/mazamascience/mazamarollutils,3182,1,2021-09-23T15:40:32Z,3182
MazamaSpatialPlots,"A suite of convenience functions for generating US state and county
    thematic maps using datasets from the MazamaSpatialUtils package.",2021-09-16,Jonathan Callahan,https://github.com/MazamaScience/MazamaSpatialPlots,TRUE,https://github.com/mazamascience/mazamaspatialplots,3523,0,2021-09-15T20:11:59Z,NA
MazamaSpatialUtils,"A suite of conversion functions to create internally standardized
    spatial polygons data frames. Utility functions use these data sets to
    return values such as country, state, time zone, watershed, etc. associated
    with a set of longitude/latitude pairs. (They also make cool maps.)",2021-09-15,Jonathan Callahan,https://github.com/MazamaScience/MazamaSpatialUtils,TRUE,https://github.com/mazamascience/mazamaspatialutils,26432,4,2021-11-12T19:11:19Z,6608
MazamaTimeSeries,"Utility functions for working with environmental time series data from known 
    locations. The compact data model is structured as a list with two dataframes. A 
    'meta' dataframe contains spatial and measuring device metadata associated with 
    deployments at known locations. A 'data' dataframe contains a 'datetime' column 
    followed by columns of measurements associated with each ""device-deployment"".
    Ephemerides calculations are based on code originally found in NOAA's
    ""Solar Calculator"" <https://gml.noaa.gov/grad/solcalc/>.",2022-04-05,Jonathan Callahan,https://github.com/MazamaScience/MazamaTimeSeries,TRUE,https://github.com/mazamascience/mazamatimeseries,1596,0,2022-06-17T19:45:31Z,NA
mazing,"Functionality for generating and plotting random mazes. The mazes are based on matrices, so can only consist of vertical and horizontal lines along a regular grid. But there is no need to use every possible space, so they can take on many different shapes.",2021-10-05,Kelly Street,NA,TRUE,https://github.com/kstreet13/mazing,3788,2,2021-09-30T17:33:03Z,1894
mbbefd,"Distributions that are typically used for exposure rating in
             general insurance, in particular to price reinsurance contracts.
             The vignette shows code snippets to fit the distribution to
             empirical data. See, e.g., Bernegger (1997) <doi:10.2143/AST.27.1.563208>
             freely available on-line.",2021-06-08,Christophe Dutang,https://github.com/spedygiorgio/mbbefd,TRUE,https://github.com/spedygiorgio/mbbefd,22177,11,2021-07-31T12:28:10Z,2016.090909090909
mbend,"Bending non-positive-definite (symmetric) matrices to positive-definite, using weighted and unweighted methods.
   Jorjani, H., et al. (2003) <doi:10.3168/jds.S0022-0302(03)73646-7>.
   Schaeffer, L. R. (2014) <http://animalbiosciences.uoguelph.ca/~lrs/ELARES/PDforce.pdf>.",2020-10-11,Mohammad Ali Nilforooshan,https://github.com/nilforooshan/mbend,TRUE,https://github.com/nilforooshan/mbend,31908,3,2022-04-01T01:04:05Z,10636
mboost,"Functional gradient descent algorithm
  (boosting) for optimizing general risk functions utilizing
  component-wise (penalised) least squares estimates or regression
  trees as base-learners for fitting generalized linear, additive
  and interaction models to potentially high-dimensional data.
  Models and algorithms are described in <doi:10.1214/07-STS242>,
  a hands-on tutorial is available from <doi:10.1007/s00180-012-0382-5>.
  The package allows user-specified loss functions and base-learners.",2022-04-26,Torsten Hothorn,https://github.com/boost-R/mboost,TRUE,https://github.com/boost-r/mboost,209944,67,2022-04-25T10:09:45Z,3133.492537313433
mbRes,"Compute and visualize the ps-index, a new integrated index for
    multiple biomarker responses, as described in Pham & Sokolova
    (2022, unpublished).",2022-01-28,Duy Nghia Pham,NA,TRUE,https://github.com/phamdn/mbres,4122,0,2022-06-24T20:13:22Z,NA
mclogit,"Provides estimators for multinomial logit models in their
    conditional logit and baseline logit variants, with or without random effects,
    with or without overdispersion. 
    Random effects models are estimated using the PQL technique (based on a Laplace approximation)
    or the MQL technique (based on a Solomon-Cox approximation). Estimates should be treated
    with caution if the group sizes are small.",2022-04-19,Martin Elff,"http://mclogit.elff.eu,https://github.com/melff/mclogit/",TRUE,https://github.com/melff/mclogit,56076,18,2022-05-21T22:05:38Z,3115.3333333333335
mcmcderive,"Generates derived parameter(s) from Monte Carlo Markov Chain
    (MCMC) samples using R code. This allows Bayesian models to be fitted
    without the inclusion of derived parameters which add unnecessary
    clutter and slow model fitting. For more information on MCMC samples
    see Brooks et al. (2011) <isbn:978-1-4200-7941-8>.",2021-08-06,Joe Thorley,https://github.com/poissonconsulting/mcmcderive,TRUE,https://github.com/poissonconsulting/mcmcderive,15432,0,2021-11-08T18:47:58Z,NA
mcmcensemble,"Provides ensemble samplers for
    affine-invariant Monte Carlo Markov Chain, which allow a faster
    convergence for badly scaled estimation problems. Two samplers are
    proposed: the 'differential.evolution' sampler from ter Braak and
    Vrugt (2008) <doi:10.1007/s11222-008-9104-9> and the 'stretch' sampler
    from Goodman and Weare (2010) <doi:10.2140/camcos.2010.5.65>.",2021-04-28,Hugo Gruson,"https://github.com/Bisaloo/mcmcensemble,
https://bisaloo.github.io/mcmcensemble/",TRUE,https://github.com/bisaloo/mcmcensemble,8771,1,2022-01-27T09:52:53Z,8771
mcmcr,"Functions and classes to store, manipulate and summarise
    Monte Carlo Markov Chain (MCMC) samples. For more information see
    Brooks et al. (2011) <isbn:978-1-4200-7941-8>.",2021-09-06,Joe Thorley,https://github.com/poissonconsulting/mcmcr,TRUE,https://github.com/poissonconsulting/mcmcr,21834,17,2022-06-21T03:07:26Z,1284.3529411764705
MCMCvis,"Performs key functions for MCMC analysis using minimal code - visualizes, manipulates, and summarizes MCMC output. Functions support simple and straightforward subsetting of model parameters within the calls, and produce presentable and 'publication-ready' output. MCMC output may be derived from Bayesian model output fit with 'Stan', 'NIMBLE', 'JAGS', and other software.",2022-02-08,Casey Youngflesh,https://github.com/caseyyoungflesh/MCMCvis,TRUE,https://github.com/caseyyoungflesh/mcmcvis,36656,29,2022-02-08T20:53:33Z,1264
mcp,"Flexible and informed regression with Multiple Change Points. 'mcp' can infer change points in means, variances, autocorrelation structure, and any combination of these, as well as the parameters of the segments in between. All parameters are estimated with uncertainty and prediction intervals are supported - also near the change points. 'mcp' supports hypothesis testing via Savage-Dickey density ratio, posterior contrasts, and cross-validation. 'mcp' is described in Lindeløv (submitted) <doi:10.31219/osf.io/fzqxv> and generalizes the approach described in Carlin, Gelfand, & Smith (1992) <doi:10.2307/2347570> and Stephens (1994) <doi:10.2307/2986119>.",2022-02-18,Jonas Kristoffer Lindeløv,https://lindeloev.github.io/mcp/,TRUE,https://github.com/lindeloev/mcp,16937,91,2022-02-18T00:07:42Z,186.12087912087912
mctq,"A complete toolkit to process the Munich ChronoType 
    Questionnaire (MCTQ) for its three versions (standard, micro, and shift). 
    MCTQ is a quantitative and validated tool to assess chronotypes using 
    peoples' sleep behavior, originally presented by Till Roenneberg, Anna 
    Wirz-Justice, and Martha Merrow (2003, <doi:10.1177/0748730402239679>).",2022-05-09,Daniel Vartanian,"https://docs.ropensci.org/mctq/, https://github.com/ropensci/mctq/",TRUE,https://github.com/ropensci/mctq,2425,8,2022-07-07T01:14:07Z,303.125
mde,"Correct identification and handling of missing data is one of the most important steps in any analysis. To aid this process, 'mde' provides a very easy to use yet robust framework to quickly get an idea of where the missing data
             lies and therefore find the most appropriate action to take.
             Graham WJ (2009) <doi:10.1146/annurev.psych.58.110405.085530>. ",2022-02-10,Nelson Gonzabato,https://github.com/Nelson-Gon/mde,TRUE,https://github.com/nelson-gon/mde,13967,4,2022-02-09T20:21:59Z,3491.75
mdgc,"Provides functions to impute missing values using Gaussian 
    copulas for mixed data types as described by Christoffersen et al. 
    (2021) <arXiv:2102.02642>. The method is related to Hoff (2007) 
    <doi:10.1214/07-AOAS107> and Zhao and Udell (2019) <arXiv:1910.12845> 
    but differs by making a direct approximation of the log marginal likelihood 
    using an extended version of the Fortran code created by Genz and Bretz 
    (2002) <doi:10.1198/106186002394> in addition to also support multinomial 
    variables.",2021-06-14,Benjamin Christoffersen,https://github.com/boennecd/mdgc,TRUE,https://github.com/boennecd/mdgc,6582,4,2021-09-02T14:37:19Z,1645.5
mdmb,"
    Contains model-based treatment of missing data for regression 
    models with missing values in covariates or the dependent 
    variable using maximum likelihood or Bayesian estimation 
    (Ibrahim et al., 2005; <doi:10.1198/016214504000001844>;
    Luedtke, Robitzsch, & West, 2020a, 2020b;
    <doi:10.1080/00273171.2019.1640104><doi:10.1037/met0000233>).
    The regression model can be nonlinear (e.g., interaction 
    effects, quadratic effects or B-spline functions). 
    Multilevel models with missing data in predictors are
    available for Bayesian estimation. Substantive-model compatible 
    multiple imputation can be also conducted.",2022-05-17,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/mdmb,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/mdmb,73888,2,2022-05-18T08:32:49Z,36944
MDplot,"Provides automatization for plot generation succeeding common molecular dynamics analyses.
             This includes straightforward plots, such as RMSD (Root-Mean-Square-Deviation) and
             RMSF (Root-Mean-Square-Fluctuation) but also more sophisticated ones such as
             dihedral angle maps, hydrogen bonds, cluster bar plots and
             DSSP (Definition of Secondary Structure of Proteins) analysis. Currently able to load
             GROMOS, GROMACS and AMBER formats, respectively.",2017-07-04,Christian Margreitter,https://github.com/MDplot/MDplot,TRUE,https://github.com/mdplot/mdplot,15841,16,2022-03-23T15:47:32Z,990.0625
meanr,"Sentiment analysis is a popular technique in text mining that
    attempts to determine the emotional state of some text. We provide a new
    implementation of a common method for computing sentiment, whereby words are
    scored as positive or negative according to a dictionary lookup. Then the
    sum of those scores is returned for the document. We use the 'Hu' and 'Liu'
    sentiment dictionary ('Hu' and 'Liu', 2004) <doi:10.1145/1014052.1014073>
    for determining sentiment. The scoring function is 'vectorized' by document,
    and scores for multiple documents are computed in parallel via 'OpenMP'.",2022-03-05,Drew Schmidt,https://github.com/wrathematics/meanr,TRUE,https://github.com/wrathematics/meanr,23369,21,2022-03-05T23:14:13Z,1112.8095238095239
meanShiftR,"Performs mean shift classification using linear and 
  k-d tree based nearest neighbor implementations for the Gaussian,
  Epanechnikov, and biweight product kernels. ",2021-09-21,Jonathan Lisic,http://meanmean.me/meanshift/r/cran/2016/08/28/meanShiftR.html,TRUE,https://github.com/jlisic/meanshiftr,25105,4,2021-09-06T14:30:36Z,6276.25
measurementProtocol,"Send server-side tracking data from R.
  The Measurement Protocol version 2 
  <https://developers.google.com/analytics/devguides/collection/protocol/ga4>
  allows sending HTTP tracking events from R code.",2021-04-15,Mark Edmondson,https://code.markedmondson.me/measurementProtocol/,TRUE,https://github.com/markedmondson1234/measurementprotocol,96842,2,2022-02-08T08:52:13Z,48421
mecor,"Covariate measurement error correction is implemented by means of regression calibration by Carroll RJ, Ruppert D, Stefanski LA & Crainiceanu CM (2006, ISBN:1584886331), efficient regression calibration by Spiegelman D, Carroll RJ & Kipnis V (2001) <doi:10.1002/1097-0258(20010115)20:1%3C139::AID-SIM644%3E3.0.CO;2-K> and maximum likelihood estimation by Bartlett JW, Stavola DBL & Frost C (2009) <doi:10.1002/sim.3713>. Outcome measurement error correction is implemented by means of the method of moments by Buonaccorsi JP (2010, ISBN:1420066560) and efficient method of moments by Keogh RH, Carroll RJ, Tooze JA, Kirkpatrick SI & Freedman LS (2014) <doi:10.1002/sim.7011>. Standard error estimation of the corrected estimators is implemented by means of the Delta method by Rosner B, Spiegelman D & Willett WC (1990) <doi:10.1093/oxfordjournals.aje.a115715> and Rosner B, Spiegelman D & Willett WC (1992) <doi:10.1093/oxfordjournals.aje.a116453>, the Fieller method described by Buonaccorsi JP (2010, ISBN:1420066560), and the Bootstrap by Carroll RJ, Ruppert D, Stefanski LA & Crainiceanu CM (2006, ISBN:1584886331).",2021-12-01,Linda Nab,https://github.com/LindaNab/mecor,TRUE,https://github.com/lindanab/mecor,6089,5,2021-12-01T16:12:21Z,1217.8
medfate,Functions to simulate Mediterranean forest functioning and dynamics using cohort-based description of vegetation [De Caceres et al. (2015) <doi:10.1016/j.agrformet.2015.06.012>; De Caceres et al. (2021) <doi:10.1016/j.agrformet.2020.108233>].,2022-05-09,Miquel De Cáceres,https://emf-creaf.github.io/medfate/,TRUE,https://github.com/emf-creaf/medfate,19861,3,2022-06-17T18:09:01Z,6620.333333333333
medicaldata,"Provides access to well-documented medical datasets for teaching.
    Featuring several from the Teaching of Statistics in the Health Sciences 
    website <https://www.causeweb.org/tshs/category/dataset/>, a few reconstructed datasets of historical significance in medical
    research, some reformatted and extended from existing R packages, 
    and some data donations. ",2021-08-16,Peter Higgins,"https://higgi13425.github.io/medicaldata/,
https://github.com/higgi13425/medicaldata/",TRUE,https://github.com/higgi13425/medicaldata,5786,22,2022-04-30T22:45:35Z,263
MEDseq,"Implements a model-based clustering method for categorical life-course sequences relying on mixtures of exponential-distance models introduced by Murphy et al. (2021) <doi:10.1111/rssa.12712>. A range of flexible precision parameter settings corresponding to weighted generalisations of the Hamming distance metric are considered, along with the potential inclusion of a noise component. Gating covariates can be supplied in order to relate sequences to baseline characteristics. Sampling weights are also accommodated. The models are fitted using the EM algorithm and tools for visualising the results are also provided.",2022-03-28,Keefe Murphy,https://cran.r-project.org/package=MEDseq,TRUE,https://github.com/keefe-murphy/medseq,14093,3,2022-03-28T15:20:24Z,4697.666666666667
mefa,"A framework package aimed to provide standardized computational environment for specialist work via object classes to represent the data coded by samples, taxa and segments (i.e. subpopulations, repeated measures). It supports easy processing of the data along with cross tabulation and relational data tables for samples and taxa. An object of class `mefa' is a project specific compendium of the data and can be easily used in further analyses. Methods are provided for extraction, aggregation, conversion, plotting, summary and reporting of `mefa' objects. Reports can be generated in plain text or LaTeX format. Vignette contains worked examples.",2021-10-07,Peter Solymos,https://github.com/psolymos/mefa,TRUE,https://github.com/psolymos/mefa,36612,1,2021-10-07T01:48:21Z,36612
mefa4,"An S4 update of the 'mefa' package
  using sparse matrices for enhanced efficiency.
  Sparse array-like objects are supported via
  lists of sparse matrices.",2021-10-06,Peter Solymos,https://github.com/psolymos/mefa4,TRUE,https://github.com/psolymos/mefa4,37183,0,2021-10-06T19:46:37Z,NA
MEGENA,"Co-Expression Network Analysis by adopting network embedding technique. Song W.-M., Zhang B. (2015) Multiscale Embedded Gene Co-expression Network Analysis. PLoS Comput Biol 11(11): e1004574. <doi: 10.1371/journal.pcbi.1004574>.",2018-09-10,Won-Min Song,https://github.com/songw01/MEGENA,TRUE,https://github.com/songw01/megena,15062,33,2022-03-10T16:11:49Z,456.42424242424244
meifly,"Exploratory model analysis with <http://ggobi.org>.  
    Fit and graphical explore ensembles of linear models.",2022-05-20,Hadley Wickham,https://github.com/hadley/meifly,TRUE,https://github.com/hadley/meifly,16923,17,2022-05-20T16:42:34Z,995.4705882352941
melt,"Performs multiple empirical likelihood tests for linear and
    generalized linear models. The core computational routines are
    implemented using the 'Eigen' C++ library and 'RcppEigen' interface,
    with OpenMP for parallel computation. Details of multiple testing
    procedures are given in Kim, MacEachern, and Peruggia (2021)
    <arxiv:2112.09206>.",2022-07-10,Eunseop Kim,"https://github.com/markean/melt, https://markean.github.io/melt/",TRUE,https://github.com/markean/melt,9142,1,2022-07-10T09:06:14Z,9142
meltr,"The goal of 'meltr' is to provide a fast and friendly way to
    read non-rectangular data, such as ragged forms of csv (comma-separated
    values), tsv (tab-separated values), and fwf (fixed-width format) files.",2021-08-23,Duncan Garmonsway,https://github.com/r-lib/meltr,TRUE,https://github.com/r-lib/meltr,3870,25,2021-11-19T14:52:30Z,154.8
mem,"The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week.",2022-04-13,Jose E. Lozano,https://github.com/lozalojo/mem,TRUE,https://github.com/lozalojo/mem,23794,9,2022-04-14T08:47:36Z,2643.777777777778
memapp,"The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week. 'memapp' is a web application created in the Shiny framework for the 'mem' R package.",2022-04-24,Jose E. Lozano,https://github.com/lozalojo/memapp,TRUE,https://github.com/lozalojo/memapp,17583,2,2022-04-24T06:35:48Z,8791.5
memisc,"An infrastructure for the management of survey data including
        value labels, definable missing values, recoding of variables,
        production of code books, and import of (subsets of) 'SPSS' and
        'Stata' files is provided. Further, the package allows to produce
        tables and data frames of arbitrary descriptive statistics and
        (almost) publication-ready tables of regression model
        estimates, which can be exported to 'LaTeX' and HTML.",2021-10-08,Martin Elff (with contributions from Christopher N. Lawrence,"http://memisc.elff.eu,https://github.com/melff/memisc/",TRUE,https://github.com/melff/memisc,350422,37,2022-06-29T20:28:42Z,9470.864864864865
memoiR,"Producing high-quality documents suitable for publication directly from R is made possible by the R Markdown ecosystem.
  'memoiR' makes it easy.
  It provides templates to knit memoirs, articles and slideshows with helpers to publish the documents on GitHub Pages and activate continuous integration.",2022-07-10,Eric Marcon,https://github.com/EricMarcon/memoiR,TRUE,https://github.com/ericmarcon/memoir,6826,7,2022-07-10T11:36:21Z,975.1428571428571
memoise,"Cache the results of a function so that when you
    call it again with the same arguments it returns the previously computed
    value.",2021-11-26,Winston Chang,"https://memoise.r-lib.org, https://github.com/r-lib/memoise",TRUE,https://github.com/r-lib/memoise,7488092,290,2021-11-29T13:58:57Z,25821.006896551724
memuse,"How much ram do you need to store a 100,000 by 100,000 matrix?
    How much ram is your current R session using? How much ram do you even have?
    Learn the scintillating answer to these and many more such questions with
    the 'memuse' package.",2021-10-20,Drew Schmidt,https://github.com/shinra-dev/memuse,TRUE,https://github.com/shinra-dev/memuse,115744,40,2021-10-17T19:38:47Z,2893.6
merDeriv,"Compute case-wise and cluster-wise derivative for mixed effects models with respect to fixed effects parameter, random effect (co)variances, and residual variance. This material is partially based on work supported by the National Science Foundation under Grant Number 1460719.",2022-03-11,Ting Wang,https://github.com/nctingwang/merDeriv,TRUE,https://github.com/nctingwang/merderiv,65843,2,2022-03-03T15:10:18Z,32921.5
MESS,"A mixed collection of useful and semi-useful diverse
    statistical functions, some of which may even be referenced in
    The R Primer book.",2022-06-20,Claus Thorn Ekstrøm,https://github.com/ekstroem/MESS,TRUE,https://github.com/ekstroem/mess,63181,4,2022-06-30T16:41:50Z,15795.25
metaBMA,"Computes the posterior model probabilities for standard meta-analysis models 
    (null model vs. alternative model assuming either fixed- or random-effects, respectively).
    These posterior probabilities are used to estimate the overall mean effect size 
    as the weighted average of the mean effect size estimates of the random- and 
    fixed-effect model as proposed by Gronau, Van Erp, Heck, Cesario, Jonas, & 
    Wagenmakers (2017, <doi:10.1080/23743603.2017.1326760>). The user can define 
    a wide range of non-informative or informative priors for the mean effect size 
    and the heterogeneity coefficient. Moreover, using pre-compiled Stan models, 
    meta-analysis with continuous and discrete moderators with Jeffreys-Zellner-Siow (JZS) 
    priors can be fitted and tested. This allows to compute Bayes factors and 
    perform Bayesian model averaging across random- and fixed-effects meta-analysis 
    with and without moderators. For a primer on Bayesian model-averaged meta-analysis, 
    see Gronau, Heck, Berkhout, Haaf, & Wagenmakers (2020, <doi:10.31234/osf.io/97qup>).",2021-03-17,Daniel W. Heck,https://github.com/danheck/metaBMA,TRUE,https://github.com/danheck/metabma,138268,18,2022-04-28T15:32:59Z,7681.555555555556
metaboData,"Data sets from a variety of biological sample matrices, 
    analysed using a number of mass spectrometry based metabolomic analytical techniques.
    The example data sets are stored remotely using GitHub releases 
    <https://github.com/aberHRML/metaboData/releases> which can be accessed from R using the package.
    The package also includes the 'abr1' FIE-MS data set from the 'FIEmspro' package <https://users.aber.ac.uk/jhd/> <doi:10.1038/nprot.2007.511>.",2022-02-15,Jasen Finch,https://aberhrml.github.io/metaboData/,TRUE,https://github.com/aberhrml/metabodata,3841,0,2022-02-15T22:38:32Z,NA
metabolighteR,Access to the 'Metabolights' REST API <https://www.ebi.ac.uk/metabolights/index>. Retrieve elements of publicly available 'Metabolights' studies.  ,2022-02-09,Tom Wilson,https://github.com/aberHRML/metabolighteR,TRUE,https://github.com/aberhrml/metabolighter,12033,4,2022-02-11T10:01:11Z,3008.25
metabolomicsR,"Tools to preprocess, analyse, and visualize metabolomics data. 
  We included a set of functions for sample and metabolite quality control, 
  outlier detection, missing value imputation, dimensional reduction, normalization, 
  data integration, regression, metabolite annotation, enrichment analysis, 
  and visualization of data and results. The package is designed to be a comprehensive R package 
  that can be easily used by researchers with basic R programming skills. 
  The framework designed here is versatile and is extensible to other various methods.",2022-04-29,Xikun Han,https://github.com/XikunHan/metabolomicsR,TRUE,https://github.com/xikunhan/metabolomicsr,463,0,2022-06-07T22:24:30Z,NA
metacoder,"A set of tools for parsing, manipulating, and graphing data
    classified by a hierarchy (e.g. a taxonomy).",2021-06-23,Zachary Foster,https://grunwaldlab.github.io/metacoder_documentation/,TRUE,https://github.com/grunwaldlab/metacoder,34030,113,2022-05-10T16:54:25Z,301.1504424778761
metaconfoundr,"Visualize 'confounder' control in meta-analysis.
    'metaconfoundr' is an approach to evaluating bias in studies used in
    meta-analyses based on the causal inference framework. Study groups
    create a causal diagram displaying their assumptions about the
    scientific question. From this, they develop a list of important
    'confounders'. Then, they evaluate whether studies controlled for
    these variables well. 'metaconfoundr' is a toolkit to facilitate this
    process and visualize the results as heat maps, traffic light plots,
    and more.",2021-10-12,Malcolm Barrett,https://github.com/malcolmbarrett/metaconfoundr,TRUE,https://github.com/malcolmbarrett/metaconfoundr,3062,6,2022-01-03T00:42:56Z,510.3333333333333
metadat,"A collection of meta-analysis datasets for teaching purposes, illustrating/testing meta-analytic methods, and validating published analyses.",2022-04-06,Thomas White,https://github.com/wviechtb/metadat,TRUE,https://github.com/wviechtb/metadat,51735,19,2022-04-06T12:37:11Z,2722.8947368421054
metafolio,"A tool to simulate salmon metapopulations and apply financial
    portfolio optimization concepts. The package accompanies the paper 
    Anderson et al. (2015) <doi:10.1101/2022.03.24.485545>.",2022-04-11,Sean C. Anderson,https://github.com/seananderson/metafolio,TRUE,https://github.com/seananderson/metafolio,17758,2,2022-04-11T19:25:53Z,8879
metagam,"Meta-analysis of generalized additive
    models and generalized additive mixed models. A typical use case is
    when data cannot be shared across locations, and an overall meta-analytic
    fit is sought. 'metagam' provides functionality for removing individual
    participant data from models computed using the 'mgcv' and 'gamm4' packages such
    that the model objects can be shared without exposing individual data.
    Furthermore, methods for meta-analysing these fits are provided. The implemented
    methods are described in Sorensen et al. (2020), <doi:10.1016/j.neuroimage.2020.117416>,
    extending previous works by Schwartz and Zanobetti (2000)
    and Crippa et al. (2018) <doi:10.6000/1929-6029.2018.07.02.1>.",2021-11-14,Oystein Sorensen,"https://lifebrain.github.io/metagam/,
https://github.com/Lifebrain/metagam",TRUE,https://github.com/lifebrain/metagam,15054,7,2022-01-24T11:32:17Z,2150.5714285714284
MetaIntegration,"An ensemble meta-prediction framework to integrate multiple regression 
    models into a current study. Gu, T., Taylor, J.M.G. and Mukherjee, B. (2020) 
    <arXiv:2010.09971>.
    A meta-analysis framework along with two weighted estimators as the ensemble 
    of empirical Bayes estimators, which combines the estimates from the different 
    external models. The proposed framework is flexible and robust in the ways 
    that (i) it is capable of incorporating external models that use a slightly 
    different set of covariates; (ii) it is able to identify the most relevant 
    external information and diminish the influence of information that is less 
    compatible with the internal data; and (iii) it nicely balances the bias-variance 
    trade-off while preserving the most efficiency gain. The proposed estimators 
    are more efficient than the naive analysis of the internal data and other 
    naive combinations of external estimators.",2021-03-17,Michael Kleinsasser,https://github.com/umich-biostatistics/MetaIntegration,TRUE,https://github.com/umich-biostatistics/metaintegration,6344,0,2021-09-22T14:10:52Z,NA
metajam,"A set of tools to foster the development of reproducible analytical workflow by simplifying the download of data and 
    metadata from 'DataONE' (<https://www.dataone.org>) and easily importing this information into R.",2020-11-03,Julien Brun,https://github.com/nceas/metajam,TRUE,https://github.com/nceas/metajam,7068,12,2022-04-11T05:45:19Z,589
metamedian,"Implements several methods to meta-analyze studies that report the 
    sample median of the outcome. When the primary studies are one-group 
    studies, the methods of McGrath et al. (2019) <doi:10.1002/sim.8013> can 
    be applied to estimate the pooled median. In the two-group context, the 
    methods of McGrath et al. (2020) <doi:10.1002/bimj.201900036> can be 
    applied to estimate the pooled raw difference of medians across groups.",2022-06-19,Sean McGrath,https://github.com/stmcg/metamedian,TRUE,https://github.com/stmcg/metamedian,14802,4,2022-06-18T17:56:15Z,3700.5
metamer,"Creates data with identical statistics (metamers) using an iterative 
   algorithm proposed by Matejka & Fitzmaurice (2017) <DOI:10.1145/3025453.3025912>.",2022-06-23,Elio Campitelli,https://eliocamp.github.io/metamer/,TRUE,https://github.com/eliocamp/metamer,11166,16,2022-06-23T20:44:53Z,697.875
metan,"Performs stability analysis of multi-environment trial data
    using parametric and non-parametric methods. Parametric methods
    includes Additive Main Effects and Multiplicative Interaction (AMMI)
    analysis by Gauch (2013) <doi:10.2135/cropsci2013.04.0241>, Ecovalence
    by Wricke (1965), Genotype plus Genotype-Environment (GGE) biplot
    analysis by Yan & Kang (2003) <doi:10.1201/9781420040371>, geometric
    adaptability index by Mohammadi & Amri (2008)
    <doi:10.1007/s10681-007-9600-6>, joint regression analysis by Eberhart
    & Russel (1966) <doi:10.2135/cropsci1966.0011183X000600010011x>,
    genotypic confidence index by Annicchiarico (1992), Murakami & Cruz's
    (2004) method, power law residuals (POLAR) statistics by Doring et al.
    (2015) <doi:10.1016/j.fcr.2015.08.005>, scale-adjusted coefficient of
    variation by Doring & Reckling (2018) <doi:10.1016/j.eja.2018.06.007>,
    stability variance by Shukla (1972) <doi:10.1038/hdy.1972.87>,
    weighted average of absolute scores by Olivoto et al. (2019a)
    <doi:10.2134/agronj2019.03.0220>, and multi-trait stability index by
    Olivoto et al. (2019b) <doi:10.2134/agronj2019.03.0221>.
    Non-parametric methods includes superiority index by Lin & Binns
    (1988) <doi:10.4141/cjps88-018>, nonparametric measures of phenotypic
    stability by Huehn (1990)
    <https://link.springer.com/article/10.1007/BF00024241>, TOP third
    statistic by Fox et al. (1990) <doi:10.1007/BF00040364>. Functions for
    computing biometrical analysis such as path analysis, canonical
    correlation, partial correlation, clustering analysis, and tools for
    inspecting, manipulating, summarizing and plotting typical
    multi-environment trial data are also provided.",2022-06-10,Tiago Olivoto,https://github.com/TiagoOlivoto/metan,TRUE,https://github.com/tiagoolivoto/metan,51934,20,2022-07-04T13:38:24Z,2596.7
metapack,"Contains functions performing Bayesian inference for meta-analytic and network meta-analytic models through Markov chain Monte Carlo algorithm. Currently, the package implements Hui Yao, Sungduk Kim, Ming-Hui Chen, Joseph G. Ibrahim, Arvind K. Shah, and Jianxin Lin (2015) <doi:10.1080/01621459.2015.1006065> and Hao Li, Daeyoung Lim, Ming-Hui Chen, Joseph G. Ibrahim, Sungduk Kim, Arvind K. Shah, Jianxin Lin (2021) <doi:10.1002/sim.8983>. For maximal computational efficiency, the Markov chain Monte Carlo samplers for each model, written in C++, are fine-tuned. This software has been developed under the auspices of the National Institutes of Health and Merck & Co., Inc., Kenilworth, NJ, USA.",2022-05-30,Daeyoung Lim,http://merlot.stat.uconn.edu/packages/metapack/,TRUE,https://github.com/daeyounglim/metapack,7607,0,2022-06-02T17:06:34Z,NA
metarep,"User-friendly package for reporting replicability-analysis methods, affixed to meta-analyses summary. This package implements the methods introduced in Jaljuli et. al. (2022) <doi:10.1080/19466315.2022.2050291>. The replicability-analysis output provides an assessment of the investigated intervention, where it offers quantification of effect replicability and assessment of the consistency of findings.
 - Replicability-analysis for fixed-effects and random-effect meta analysis: 
 - r(u)-value;
 - lower bounds on the number of studies with replicated positive and\or negative effect;
 - Allows detecting inconsistency of signals;
 - forest plots with the summary of replicability analysis results;
 - Allows Replicability-analysis with or without the common-effect assumption. ",2022-03-14,Iman Jaljuli,https://github.com/IJaljuli/metarep,TRUE,https://github.com/ijaljuli/metarep,9332,3,2022-04-27T05:03:30Z,3110.6666666666665
metaSEM,"A collection of functions for conducting meta-analysis using a
             structural equation modeling (SEM) approach via the 'OpenMx' and
             'lavaan' packages. It also implements various procedures to
			 perform meta-analytic structural equation modeling on the
             correlation and covariance matrices,
			 see Cheung (2015) <doi:10.3389/fpsyg.2014.01521>.",2021-05-17,Mike Cheung,https://github.com/mikewlcheung/metasem,TRUE,https://github.com/mikewlcheung/metasem,33093,24,2022-04-30T03:31:20Z,1378.875
MetaStan,"Performs Bayesian meta-analysis, meta-regression and model-based meta-analysis 
             using 'Stan'. Includes binomial-normal hierarchical models and option to use 
             weakly informative priors for the heterogeneity parameter and the treatment effect 
             parameter which are described in Guenhan, Roever, and Friede (2020) <doi:10.1002/jrsm.1370>.",2022-01-22,Burak Kuersad Guenhan,https://github.com/gunhanb/MetaStan,TRUE,https://github.com/gunhanb/metastan,17164,7,2022-01-22T13:11:38Z,2452
metaSurvival,"To assess a summary survival curve from survival probabilities and number of at-risk patients collected at various points in time in various studies, and to test the between-strata heterogeneity.",2020-12-07,Shubhram Pandey,https://github.com/shubhrampandey/metaSurvival,TRUE,https://github.com/shubhrampandey/metasurvival,6516,4,2022-04-26T17:34:49Z,1629
metathis,"Create meta tags for 'R Markdown' HTML documents and 'Shiny'
    apps for customized social media cards, for accessibility, and quality
    search engine indexing. 'metathis' currently supports HTML documents
    created with 'rmarkdown', 'shiny', 'xaringan', 'pagedown', 'bookdown',
    and 'flexdashboard'.",2021-06-29,Garrick Aden-Buie,"https://pkg.garrickadenbuie.com/metathis/,
https://github.com/gadenbuie/metathis",TRUE,https://github.com/gadenbuie/metathis,19417,59,2022-06-12T03:20:35Z,329.10169491525426
metavcov,"Collection of functions to compute covariances for different effect sizes, data visualization, and single and multiple imputations for missing data. Effect sizes include correlation (r), mean difference (MD), standardized mean difference (SMD), log odds ratio (logOR), log risk ratio (logRR), and risk difference (RD).",2021-10-25,Min Lu,https://github.com/luminwin/metavcov,TRUE,https://github.com/luminwin/metavcov,22006,0,2021-10-09T13:38:03Z,NA
meteospain,"Access to different Spanish meteorological stations data services and APIs (AEMET, SMC, MG, 
  Meteoclimatic...).",2022-05-25,Victor Granda,"https://emf-creaf.github.io/meteospain/,
https://github.com/emf-creaf/meteospain",TRUE,https://github.com/emf-creaf/meteospain,4119,1,2022-05-24T12:13:20Z,4119
metR,"Many useful functions and extensions for dealing
    with meteorological data in the tidy data framework. Extends 'ggplot2'
    for better plotting of scalar and vector fields and provides commonly
    used analysis methods in the atmospheric sciences.",2022-02-15,Elio Campitelli,https://github.com/eliocamp/metR,TRUE,https://github.com/eliocamp/metr,63039,121,2022-02-15T18:52:41Z,520.9834710743802
metrica,"A compilation of more than 80 functions designed to quantitatively and visually evaluate prediction performance of regression (continuous variables) and classification (categorical variables) of point-forecast models (e.g. APSIM, DSSAT, DNDC, supervised Machine Learning). For regression, it includes functions to generate plots (scatter, tiles, density, & Bland-Altman plot), and to estimate error metrics (e.g. MBE, MAE, RMSE), error decomposition (e.g. lack of accuracy-precision), model efficiency (e.g. NSE, E1, KGE), indices of agreement (e.g. d, RAC), goodness of fit (e.g. r, R2), adjusted correlation coefficients (e.g. CCC, dcorr), symmetric regression coefficients (intercept, slope), and mean absolute scaled error (MASE) for time series predictions. For classification (binomial and multinomial), it offers functions to generate and plot confusion matrices, and to estimate performance metrics such as accuracy, precision, recall, specificity, F-score, Cohen's Kappa, G-mean, and many more. For more details visit the vignettes <https://adriancorrendo.github.io/metrica/>.",2022-07-05,Adrian A. Correndo,https://adriancorrendo.github.io/metrica/,TRUE,https://github.com/adriancorrendo/metrica,654,42,2022-07-09T15:20:04Z,15.571428571428571
MetricsWeighted,"Provides weighted versions of several metrics, scoring
    functions and performance measures used in machine learning, including
    average unit deviances of the Bernoulli, Tweedie, Poisson, and Gamma
    distributions, see Jorgensen B. (1997, ISBN: 978-0412997112). The
    package also contains a weighted version of generalized R-squared, see
    e.g. Cohen, J. et al. (2002, ISBN: 978-0805822236). Furthermore,
    'dplyr' chains are supported.",2022-01-23,Michael Mayer,https://github.com/mayer79/MetricsWeighted,TRUE,https://github.com/mayer79/metricsweighted,24654,8,2022-02-10T06:25:15Z,3081.75
mets,"Implementation of various statistical models for multivariate
    event history data <doi:10.1007/s10985-013-9244-x>. Including multivariate
    cumulative incidence models <doi:10.1002/sim.6016>, and  bivariate random
    effects probit models (Liability models) <doi:10.1016/j.csda.2015.01.014>.
    Also contains two-stage binomial modelling that can do pairwise odds-ratio
    dependence modelling based marginal logistic regression models. This is an
    alternative to the alternating logistic regression approach (ALR).",2021-09-06,Klaus K. Holst,https://kkholst.github.io/mets/,TRUE,https://github.com/kkholst/mets,153862,6,2022-07-08T09:34:24Z,25643.666666666668
mev,"Various tools for the analysis of univariate, multivariate and functional extremes. Exact simulation from max-stable processes [Dombry, Engelke and Oesting (2016) <doi:10.1093/biomet/asw008>, R-Pareto processes for various parametric models, including Brown-Resnick (Wadsworth and Tawn, 2014, <doi:10.1093/biomet/ast042>) and Extremal Student (Thibaud and Opitz, 2015, <doi:10.1093/biomet/asv045>). Threshold selection methods, including Wadsworth (2016) <doi:10.1080/00401706.2014.998345>, and Northrop and Coleman (2014) <doi:10.1007/s10687-014-0183-z>. Multivariate extreme diagnostics. Estimation and likelihoods for univariate extremes, e.g., Coles (2001) <doi:10.1007/978-1-4471-3675-0>.",2022-04-25,Leo Belzile,"https://lbelzile.github.io/mev/, https://github.com/lbelzile/mev/",TRUE,https://github.com/lbelzile/mev,65315,3,2022-04-25T20:49:51Z,21771.666666666668
mexicolors,"A color palette generator inspired by Mexican politics, with 
    colors ranging from red on the left to gray in the middle and green on the 
    right. Palette options range from only a few colors to several colors, but with
    discrete and continuous options to offer greatest flexibility to the user. 
    This package allows for a range of applications, from mapping brief discrete scales 
    (e.g., four colors for Morena, PRI, and PAN) to continuous interpolated arrays 
    including dozens of shades graded from red to green.",2021-09-07,Alejandro Platas-López,NA,TRUE,https://github.com/alexplatasl/mexicolors,3968,1,2021-09-17T03:54:10Z,3968
mFD,"Computing functional traits-based distances between pairs of 
    species for species gathered in assemblages allowing to build several
    functional spaces. The package allows to compute functional diversity
    indices assessing the distribution of species (and of their dominance) in a
    given functional space for each assemblage and the overlap between
    assemblages in a given functional space, see: Chao et al. (2018)
    <doi:10.1002/ecm.1343>, Maire et al. (2015) <doi:10.1111/geb.12299>,
    Mouillot et al. (2013) <doi:10.1016/j.tree.2012.10.004>, Mouillot et al.
    (2014) <doi:10.1073/pnas.1317625111>, Ricotta and Szeidl (2009)
    <doi:10.1016/j.tpb.2009.10.001>. Graphical outputs are included.
    Visit the 'mFD' website for more information, documentation and examples.",2021-12-16,Camille Magneville,"https://cmlmagneville.github.io/mFD/,
https://github.com/CmlMagneville/mFD",TRUE,https://github.com/cmlmagneville/mfd,3884,10,2022-06-09T11:58:58Z,388.4
mfe,"Extracts meta-features from datasets to support the design of 
  recommendation systems based on Meta-Learning. The meta-features, also called 
  characterization measures, are able to characterize the complexity of datasets
  and to provide estimates of algorithm performance. The package contains not 
  only the standard characterization measures, but also more recent 
  characterization measures. By making available a large set of meta-feature 
  extraction functions, tasks like comprehensive data characterization, deep 
  data exploration and large number of Meta-Learning based data analysis can be
  performed. These concepts are described in the paper: Rivolli A., Garcia L., 
  Soares c., Vanschoren J. and Carvalho A. (2018) <arXiv:1808.10406>.",2020-05-05,Adriano Rivolli,https://github.com/rivolli/mfe,TRUE,https://github.com/rivolli/mfe,14272,25,2022-03-25T19:23:38Z,570.88
mFLICA,"A leadership-inference framework for multivariate time series. The framework for multiple-faction-leadership inference from coordinated activities or 'mFLICA' uses a notion of a leader as an individual who initiates collective patterns that everyone in a group follows. Given a set of time series of individual activities, our goal is to identify periods of coordinated activity, find factions of coordination if more than one exist, as well as identify leaders of each faction. For each time step, the framework infers following relations between individual time series, then identifying a leader of each faction whom many individuals follow but it follows no one. A faction is defined as a group of individuals that everyone follows the same leader. 'mFLICA' reports following relations, leaders of factions, and members of each faction for each time step. Please see Chainarong Amornbunchornvej and Tanya Berger-Wolf (2018) <doi:10.1137/1.9781611975321.62> for methodology and Chainarong Amornbunchornvej (2021) <doi:10.1016/j.softx.2021.100781> for software when referring to this package in publications.",2022-01-24,Chainarong Amornbunchornvej,https://github.com/DarkEyes/mFLICA,TRUE,https://github.com/darkeyes/mflica,12638,3,2022-01-24T05:53:09Z,4212.666666666667
MFO,"Calculate the maximal fat oxidation, the exercise intensity that elicits the 
              maximal fat oxidation and the SIN model to represent the fat oxidation kinetics. 
              Three variables can be obtained from the SIN model: dilatation, symmetry and translation. 
              Examples of these methods can be found in Montes de Oca et al (2021) <doi:10.1080/17461391.2020.1788650>
              and Chenevière et al. (2009) <doi:10.1249/MSS.0b013e31819e2f91>.",2022-02-11,Jorge R Fernandez-Santos,https://github.com/JorgeDelro/MFO,TRUE,https://github.com/jorgedelro/mfo,1148,0,2022-02-10T18:14:23Z,NA
mfp,"Fractional polynomials are used to represent curvature in regression models. A key reference is Royston and Altman, 1994.",2022-01-20,Georg Heinze,NA,TRUE,https://github.com/georgheinze/mfp,51393,0,2022-01-20T09:10:31Z,NA
MFPCA,"Calculate a multivariate functional principal component analysis
    for data observed on different dimensional domains. The estimation algorithm
    relies on univariate basis expansions for each element of the multivariate
    functional data  (Happ & Greven, 2018) <doi:10.1080/01621459.2016.1273115>. 
    Multivariate and univariate functional data objects are
    represented by S4 classes for this type of data implemented in the package
    'funData'. For more details on the general concepts of both packages and a case 
    study, see Happ-Kurz (2020) <doi:10.18637/jss.v093.i05>.",2021-10-17,Clara Happ-Kurz,https://github.com/ClaraHapp/MFPCA,TRUE,https://github.com/clarahapp/mfpca,18303,22,2021-11-07T18:10:30Z,831.9545454545455
mgcViz,"Extension of the 'mgcv' package, providing visual tools for Generalized Additive Models that exploit the additive structure of such models, scale to large data sets and can be used in conjunction with a wide range of response distributions. The focus is providing visual methods for better understanding the model output and for aiding model checking and development beyond simple exponential family regression. The graphical framework is based on the layering system provided by 'ggplot2'.",2021-10-05,Matteo Fasiolo,https://github.com/mfasiolo/mgcViz,TRUE,https://github.com/mfasiolo/mgcviz,46716,71,2022-07-01T09:41:09Z,657.9718309859155
mgm,Estimation of k-Order time-varying Mixed Graphical Models and mixed VAR(p) models via elastic-net regularized neighborhood regression. For details see Haslbeck & Waldorp (2020) <doi:10.18637/jss.v093.i08>.,2022-07-07,Jonas Haslbeck,https://www.jstatsoft.org/article/view/v093i08,TRUE,https://github.com/jmbh/mgm,49716,21,2022-07-07T10:51:24Z,2367.4285714285716
mgsub,"Designed to enable simultaneous substitution in strings in a safe fashion.
    Safe means it does not rely on placeholders (which can cause errors in same length matches).",2021-07-28,Mark Ewing,NA,TRUE,https://github.com/bmewing/mgsub,401865,10,2021-10-06T19:54:05Z,40186.5
mhcnuggetsr,"
    MHCnuggets (<https://github.com/KarchinLab/mhcnuggets>) is a Python
    tool to predict MHC class I and MHC class II epitopes.
    This package allows one to call MHCnuggets from R.",2020-11-04,Richèl J.C. Bilderbeek,https://github.com/richelbilderbeek/mhcnuggetsr/,TRUE,https://github.com/richelbilderbeek/mhcnuggetsr,6753,2,2022-03-14T15:43:52Z,3376.5
MHTmult,"A Comprehensive tool for almost all existing multiple testing
    methods for multiple families. The package summarizes the existing methods for multiple families multiple testing procedures (MTPs) such as double FDR, group Benjamini-Hochberg (GBH) procedure and average FDR controlling procedure. The package also provides some novel multiple testing procedures using selective inference idea.",2017-05-01,Yalin Zhu,NA,TRUE,https://github.com/allenzhuaz/mhtmult,13621,0,2021-11-02T21:56:19Z,NA
mi4p,"A framework for multiple imputation for proteomics is proposed by Marie Chion, Christine Carapito and Frederic Bertrand (2021) <arxiv:2108.07086>. It is dedicated to dealing with multiple imputation for proteomics.",2022-06-13,Marie Chion,"https://mariechion.github.io/mi4p/,
https://github.com/mariechion/mi4p/",TRUE,https://github.com/mariechion/mi4p,2466,4,2022-06-13T01:27:59Z,616.5
micar,"'Mica' is a server application used to create data web portals for 
    large-scale epidemiological studies or multiple-study consortia. 'Mica' helps
    studies to provide scientifically robust data visibility and web presence 
    without significant information technology effort. 'Mica' provides a 
    structured description of consortia, studies, annotated and searchable data
    dictionaries, and data access request management. This 'Mica' client allows
    to perform data extraction for reporting purposes.",2021-04-16,Yannick Marcon,"https://www.obiba.org/ https://www.obiba.org/pages/products/mica/
https://doi.org/10.1093/ije/dyx180",TRUE,https://github.com/obiba/micar,12553,0,2022-05-16T13:12:29Z,NA
mice,"Multiple imputation using Fully Conditional Specification (FCS)
    implemented by the MICE algorithm as described in Van Buuren and
    Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>. Each variable has
    its own imputation model. Built-in imputation models are provided for
    continuous data (predictive mean matching, normal), binary data (logistic
    regression), unordered categorical data (polytomous logistic regression)
    and ordered categorical data (proportional odds). MICE can also impute
    continuous two-level data (normal model, pan, second-level variables).
    Passive imputation can be used to maintain consistency between variables.
    Various diagnostic plots are available to inspect the quality of the
    imputations.",2021-11-24,Stef van Buuren,"https://github.com/amices/mice, https://amices.org/mice/,
https://stefvanbuuren.name/fimd/",TRUE,https://github.com/amices/mice,2541081,296,2022-05-09T14:12:50Z,8584.733108108108
miceadds,"
    Contains functions for multiple imputation which
    complements existing functionality in R.
    In particular, several imputation methods for the
    mice package (van Buuren & Groothuis-Oudshoorn, 2011,
    <doi:10.18637/jss.v045.i03>) are included.
    Main features of the miceadds package include
    plausible value imputation (Mislevy, 1991,
    <doi:10.1007/BF02294457>), multilevel imputation for
    variables at any level or with any number of hierarchical
    and non-hierarchical levels (Grund, Luedtke & Robitzsch,
    2018, <doi:10.1177/1094428117703686>; van Buuren, 2018, 
    Ch.7, <doi:10.1201/9780429492259>), imputation using 
    partial least squares (PLS) for high dimensional 
    predictors (Robitzsch, Pham & Yanagida, 2016), 
    nested multiple imputation (Rubin, 2003, 
    <doi:10.1111/1467-9574.00217>), substantive model
    compatible imputation (Bartlett et al., 2015,
    <doi:10.1177/0962280214521348>), and features
    for the generation of synthetic datasets
    (Reiter, 2005, <doi:10.1111/j.1467-985X.2004.00343.x>;
    Nowok, Raab, & Dibben, 2016, <doi:10.18637/jss.v074.i11>).",2022-06-01,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/miceadds,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/miceadds,175115,13,2022-06-01T16:06:12Z,13470.384615384615
miceafter,"
   Statistical Analyses and Pooling after Multiple Imputation. A large variety 
   of repeated statistical analysis can be performed and finally pooled. Statistical analysis 
   that are available are, among others, Levene's test, Odds and Risk Ratios, One sample 
   proportions, difference between proportions and linear and logistic regression models. 
   Functions can also be used in combination with the Pipe operator. 
   More and more statistical analyses and pooling functions will be added over time.
   Heymans (2007) <doi:10.1186/1471-2288-7-33>.
   Eekhout (2017) <doi:10.1186/s12874-017-0404-7>.
	 Wiel (2009) <doi:10.1093/biostatistics/kxp011>.
	 Marshall (2009) <doi:10.1186/1471-2288-9-57>.
	 Sidi (2021) <doi:10.1080/00031305.2021.1898468>.
	 Lott (2018) <doi:10.1080/00031305.2018.1473796>.
	 Grund (2021) <doi:10.31234/osf.io/d459g>.",2021-12-16,Martijn Heymans,https://mwheymans.github.io/miceafter/,TRUE,https://github.com/mwheymans/miceafter,1537,0,2022-07-10T15:00:29Z,NA
miceFast,"
  Fast imputations under the object-oriented programming paradigm. 	
  Moreover there are offered a few functions built to work with popular R packages such as 'data.table' or 'dplyr'.
  The biggest improvement in time performance could be achieve for a calculation where a grouping variable have to be used.
  A single evaluation of a quantitative model for the multiple imputations is another major enhancement.
  A new major improvement is one of the fastest predictive mean matching in the R world because of presorting and binary search.",2022-03-14,Maciej Nasinski,https://github.com/Polkas/miceFast,TRUE,https://github.com/polkas/micefast,18075,12,2022-03-29T19:47:01Z,1506.25
miceRanger,"Multiple Imputation has been shown to 
  be a flexible method to impute missing values by 
  Van Buuren (2007) <doi:10.1177/0962280206074463>. 
  Expanding on this, random forests have been shown 
  to be an accurate model by Stekhoven and Buhlmann 
  <arXiv:1105.0828> to impute missing values in datasets. 
  They have the added benefits of returning out of bag 
  error and variable importance estimates, as well as 
  being simple to run in parallel.",2021-09-06,Sam Wilson,https://github.com/FarrellDay/miceRanger,TRUE,https://github.com/farrellday/miceranger,17327,44,2022-05-19T19:38:03Z,393.79545454545456
micompr,"A procedure for comparing multivariate samples associated with
    different groups. It uses principal component analysis to convert
    multivariate observations into a set of linearly uncorrelated statistical
    measures, which are then compared using a number of statistical methods. The
    procedure is independent of the distributional properties of samples and
    automatically selects features that best explain their differences, avoiding
    manual selection of specific points or summary statistics. It is appropriate
    for comparing samples of time series, images, spectrometric measures or
    similar multivariate observations.",2022-05-24,Nuno Fachada,https://github.com/nunofachada/micompr,TRUE,https://github.com/nunofachada/micompr,17283,2,2022-05-24T18:59:29Z,8641.5
microbenchmark,"Provides infrastructure to accurately measure and compare
        the execution time of R expressions.",2021-11-09,Joshua M. Ulrich,https://github.com/joshuaulrich/microbenchmark/,TRUE,https://github.com/joshuaulrich/microbenchmark,1056500,74,2022-03-06T16:22:49Z,14277.027027027027
microeco,"A series of statistical and plotting approaches in microbial community ecology based on the R6 class. The classes are designed for data preprocessing, taxa abundance plotting, alpha diversity analysis, beta diversity analysis, differential abundance test, null model analysis, network analysis, machine learning, environmental data analysis and functional analysis.",2022-06-22,Chi Liu,https://github.com/ChiLiubio/microeco,TRUE,https://github.com/chiliubio/microeco,14661,82,2022-07-06T12:38:07Z,178.79268292682926
MicroMoB,"Provides a framework based on S3 dispatch for constructing models
  of mosquito-borne pathogen transmission which are constructed from submodels of various
  components (i.e. immature and adult mosquitoes, human populations). A consistent mathematical
  expression for the distribution of bites on hosts means that different models
  (stochastic, deterministic, etc.) can be coherently incorporated and updated
  over a discrete time step.",2022-07-01,Sean L. Wu,"https://dd-harp.github.io/MicroMoB/,
https://github.com/dd-harp/MicroMoB",TRUE,https://github.com/dd-harp/micromob,1773,1,2022-07-01T18:44:59Z,1773
microservices,"'Microservice' architectural style is an approach to developing a 
    single application as a suite of small services, each running in its own 
    process and communicating with lightweight mechanisms, often an 'HTTP' 
    resource 'API'. These services are built around business capabilities and 
    independently deployable by fully automated deployment machinery. There 
    is a bare minimum of centralized management of these services, which may 
    be written in different programming languages and use different data storage 
    technologies.",2021-06-12,Harel Lustiger,https://github.com/tidylab/microservices,TRUE,https://github.com/tidylab/microservices,6457,13,2021-08-16T08:14:45Z,496.6923076923077
microsimulation,"Discrete event simulation using both R and C++ (Karlsson et al 2016; <doi:10.1109/eScience.2016.7870915>). The C++ code is adapted from the SSIM library <https://www.inf.usi.ch/carzaniga/ssim/>, allowing for both event-oriented and process-oriented simulation. The code includes a SummaryReport class for reporting events and costs by age and other covariates. The C++ code is available as a static library for linking to other packages. A priority queue implementation is given in C++ together with an S3 closure and a reference class implementation. Finally, some tools are provided for cost-effectiveness analysis.",2022-04-04,Mark Clements,https://github.com/mclements/microsimulation,TRUE,https://github.com/mclements/microsimulation,5920,25,2022-04-04T14:55:10Z,236.8
midasml,"The 'midasml' package implements estimation and prediction methods for high-dimensional mixed-frequency (MIDAS) time-series and panel data regression models. The regularized MIDAS models are estimated using orthogonal (e.g. Legendre) polynomials and sparse-group LASSO (sg-LASSO) estimator. For more information on the 'midasml' approach see Babii, Ghysels, and Striaukas (2021, JBES forthcoming) <doi:10.1080/07350015.2021.1899933>. The package is equipped with the fast implementation of the sg-LASSO estimator by means of proximal block coordinate descent. High-dimensional mixed frequency time-series data can also be easily manipulated with functions provided in the package.",2022-04-29,Jonas Striaukas,NA,TRUE,https://github.com/jstriaukas/midasml,19443,30,2022-07-01T07:04:10Z,648.1
midasr,"Methods and tools for mixed frequency time series data analysis.
    Allows estimation, model selection and forecasting for MIDAS regressions.",2021-02-23,Virmantas Kvedaras,http://mpiktas.github.io/midasr/,TRUE,https://github.com/mpiktas/midasr,27303,51,2021-07-11T12:59:21Z,535.3529411764706
migest,"Tools for estimating, measuring and working with migration data.",2021-12-02,Guy J. Abel,http://guyabel.github.io/migest/,TRUE,https://github.com/guyabel/migest,31729,25,2022-07-07T11:29:38Z,1269.16
migraph,"A set of tools for analysing multimodal networks.
   All functions operate with matrices, edge lists, 
   and 'igraph', 'network', and 'tidygraph' objects,
   and on one-mode, two-mode (bipartite), and sometimes three-mode networks.
   It includes functions for measuring 
   centrality, centralization, cohesion, closure, and constraint,
   as well as for network block-modelling and regression.
   The package is released as a complement to 
   'Multimodal Political Networks' (2021, ISBN:9781108985000),
   and includes various datasets used in the book in addition to other network data.",2022-07-03,James Hollway [cph,https://github.com/snlab-ch/migraph,TRUE,https://github.com/snlab-ch/migraph,7467,19,2022-07-03T14:27:38Z,393
migrate,"Tools to help convert credit risk data at two time points 
    into traditional credit state migration (aka, ""transition"") matrices.
    At a higher level, 'migrate' is intended to help an analyst understand 
    how risk moved in their credit portfolio over a time interval. 
    References to this methodology include: 
    1. Schuermann, T. (2008) <doi:10.1002/9780470061596.risk0409>.
    2. Perederiy, V. (2017) <arXiv:1708.00062>.",2021-10-15,Michael Thomas,https://github.com/mthomas-ketchbrook/migrate,TRUE,https://github.com/mthomas-ketchbrook/migrate,7185,5,2021-10-28T19:51:59Z,1437
miic,"We report an information-theoretic method which learns a large
    class of causal or non-causal graphical models from purely observational
    data, while including the effects of unobserved latent variables, commonly
    found in many datasets. Starting from a complete graph, the method
    iteratively removes dispensable edges, by uncovering significant information
    contributions from indirect paths, and assesses edge-specific confidences
    from randomization of available data. The remaining edges are then oriented
    based on the signature of causality in observational data. This approach can
    be applied on a wide range of datasets and provide new biological insights
    on regulatory networks from single cell expression data, genomic alterations
    during tumor development and co-evolving residues in protein structures.
    For more information you can refer to:
    Cabeli et al. PLoS Comp. Bio. 2020 <doi:10.1371/journal.pcbi.1007866>,
    Verny et al. PLoS Comp. Bio. 2017 <doi:10.1371/journal.pcbi.1005662>.",2020-10-13,Vincent Cabeli,https://github.com/miicTeam/miic_R_package,TRUE,https://github.com/miicteam/miic_r_package,18059,14,2022-07-02T07:28:04Z,1289.9285714285713
MIIVsem,"Functions for estimating structural equation models using 
    instrumental variables.",2021-07-13,Zachary Fisher,https://github.com/zackfisher/MIIVsem,TRUE,https://github.com/zackfisher/miivsem,26363,7,2021-11-27T19:45:30Z,3766.1428571428573
mikropml,"An interface to build machine learning models for
    classification and regression problems. 'mikropml' implements the ML
    pipeline described by Topçuoğlu et al. (2020)
    <doi:10.1128/mBio.00434-20> with reasonable default options for data
    preprocessing, hyperparameter tuning, cross-validation, testing, model
    evaluation, and interpretation steps.  See the website
    <https://www.schlosslab.org/mikropml/> for more information,
    documentation, and examples.",2022-05-20,Begüm Topçuoğlu,"https://www.schlosslab.org/mikropml/,
https://github.com/SchlossLab/mikropml",TRUE,https://github.com/schlosslab/mikropml,9209,36,2022-07-08T19:20:04Z,255.80555555555554
mime,"Guesses the MIME type from a filename extension using the data
    derived from /etc/mime.types in UNIX-type systems.",2021-09-28,Yihui Xie,https://github.com/yihui/mime,TRUE,https://github.com/yihui/mime,19305671,29,2021-09-28T13:36:38Z,665712.7931034482
MinBAR,"A versatile tool that aims at (1) defining the minimum background extent necessary to fit Species Distribution Models reliable enough to extract ecologically relevant conclusions from them and (2) optimizing the modelling process in terms of computation demands. See Rotllan-Puig, X. & Traveset, A. (2021) <https://www.sciencedirect.com/science/article/pii/S0304380020304191>.",2022-01-11,Xavier Rotllan-Puig,https://github.com/xavi-rp/MinBAR,TRUE,https://github.com/xavi-rp/minbar,9624,4,2022-01-11T10:53:48Z,2406
mindr,"Convert Markdown ('.md') or R Markdown ('.Rmd') texts, R scripts, and directory structures, into mind map widgets or files ('.mm'), and vice versa. ""FreeMind"" mind map ('.mm') files can be opened by or imported to common mindmap software such as 'FreeMind' (<http://freemind.sourceforge.net/wiki/index.php/Main_Page>).",2021-11-22,Peng Zhao,https://github.com/pzhaonet/mindr,TRUE,https://github.com/pzhaonet/mindr,23720,551,2021-11-22T13:47:02Z,43.04900181488203
miniCRAN,"Makes it possible to create an internally consistent
    repository consisting of selected packages from CRAN-like repositories.
    The user specifies a set of desired packages, and 'miniCRAN' recursively
    reads the dependency tree for these packages, then downloads only this
    subset. The user can then install packages from this repository directly,
    rather than from CRAN.  This is useful in production settings, e.g. server
    behind a firewall, or remote locations with slow (or zero) Internet access.",2022-02-14,Andrie de Vries,https://github.com/andrie/miniCRAN,TRUE,https://github.com/andrie/minicran,97214,130,2022-03-11T17:44:33Z,747.8
minidown,"Create minimal, responsive, and style-agnostic HTML documents with
    the lightweight CSS frameworks such as 'sakura', 'Water.css', and 'spcss'.
    Powerful features include table of contents floating as a sidebar,
    folding codes and results, and more.",2022-02-08,Atsushi Yasumoto,"https://minidown.atusy.net, https://github.com/atusy/minidown",TRUE,https://github.com/atusy/minidown,37949,74,2022-02-13T14:05:46Z,512.8243243243244
minSNPs,"This is a R implementation of ""Minimum SNPs"" software as described in ""Price E.P., Inman-Bamber, J., Thiruvenkataswamy, V., Huygens, F and Giffard, P.M."" (2007) <doi:10.1186/1471-2105-8-278> ""Computer-aided identification of polymorphism sets diagnostic for groups of bacterial and viral genetic variants.""",2022-03-28,Ludwig Kian Soon Hoon,https://github.com/ludwigHoon/minSNPs,TRUE,https://github.com/ludwighoon/minsnps,3428,1,2022-05-17T07:06:09Z,3428
minval,"For a given set of stoichiometric reactions, this package
    evaluates the mass and charge balance, extracts all reactants, products, orphan
    metabolites, metabolite names and compartments. Also are included some options
    to characterize and write models in TSV and SBML formats.",2022-05-09,Daniel Osorio,https://github.com/gibbslab/minval,TRUE,https://github.com/gibbslab/minval,16712,3,2022-05-18T13:25:56Z,5570.666666666667
mipfp,"An implementation of the iterative proportional fitting (IPFP), 
    maximum likelihood, minimum chi-square and weighted least squares procedures
    for updating a N-dimensional array with respect to given target marginal 
    distributions (which, in turn can be multidimensional). The package also
    provides an application of the IPFP to simulate multivariate Bernoulli
    distributions.",2018-08-29,Johan Barthelemy,https://github.com/jojo-/mipfp,TRUE,https://github.com/jojo-/mipfp,39339,18,2021-07-16T03:12:28Z,2185.5
mirai,"Extremely simple and lightweight method for concurrent /
    parallel code execution, built on 'nanonext' and 'NNG' (Nanomsg Next Gen)
    technology.",2022-06-21,Charlie Gao,"https://shikokuchuo.net/mirai/,
https://github.com/shikokuchuo/mirai/",TRUE,https://github.com/shikokuchuo/mirai,2282,25,2022-06-21T08:57:22Z,91.28
mirt,"Analysis of dichotomous and polytomous response data using
    unidimensional and multidimensional latent trait models under the Item
    Response Theory paradigm (Chalmers (2012) <doi:10.18637/jss.v048.i06>). 
    Exploratory and confirmatory models can be estimated with quadrature (EM) 
    or stochastic (MHRM) methods. Confirmatory
    bi-factor and two-tier analyses are available for modeling item testlets.
    Multiple group analysis and mixed effects designs also are available for
    detecting differential item and test functioning as well as modeling
    item and person covariates. Finally, latent class models such as the DINA,
    DINO, multidimensional latent class, and several other discrete latent
    variable models, including mixture and zero-inflated response models, 
    are supported.",2022-03-22,Phil Chalmers,"https://github.com/philchalmers/mirt,
https://github.com/philchalmers/mirt/wiki,
https://groups.google.com/forum/#!forum/mirt-package",TRUE,https://github.com/philchalmers/mirt,201040,165,2022-07-07T17:27:30Z,1218.4242424242425
mirtCAT,"Provides tools to generate an HTML interface for creating adaptive
    and non-adaptive educational and psychological tests using the shiny
    package (Chalmers (2016) <doi:10.18637/jss.v071.i05>). 
    Suitable for applying unidimensional and multidimensional
    computerized adaptive tests (CAT) using item response theory methodology and for
    creating simple questionnaires forms to collect response data directly in R.
    Additionally, optimal test designs (e.g., ""shadow testing"") are supported
    for tests which contain a large number of item selection constraints.
    Finally, package contains tools useful for performing Monte Carlo simulations 
    for studying the behavior of computerized adaptive test banks.",2021-12-08,Phil Chalmers,"https://github.com/philchalmers/mirtCAT,
https://github.com/philchalmers/mirtCAT/wiki,
https://groups.google.com/forum/#!forum/mirt-package",TRUE,https://github.com/philchalmers/mirtcat,86099,76,2022-01-11T05:23:05Z,1132.8815789473683
mispitools,Open-source software for computing Likelihood ratios thresholds and error rates in DNA kinship testing. Marsico FL. et al (2021) <doi:10.1016/j.fsigen.2021.102519>.,2022-03-29,Franco Marsico,https://github.com/MarsicoFL/mispitools,TRUE,https://github.com/marsicofl/mispitools,2798,0,2022-04-11T14:36:53Z,NA
missDiag,Implements the computation of discrepancy statistics summarizing differences between the density of imputed and observed values and the construction of weights to balance covariates that are part of the missing data mechanism as described in Marbach (2021) <arXiv:2107.05427>. ,2021-08-06,Moritz Marbach,https://github.com/sumtxt/missDiag/,TRUE,https://github.com/sumtxt/missdiag,3442,3,2021-08-06T09:08:15Z,1147.3333333333333
missForest,"The function 'missForest' in this package is used to
        impute missing values particularly in the case of mixed-type
        data. It uses a random forest trained on the observed values of
        a data matrix to predict the missing values. It can be used to
        impute continuous and/or categorical data including complex
        interactions and non-linear relations. It yields an out-of-bag
        (OOB) imputation error estimate without the need of a test set
        or elaborate cross-validation. It can be run in parallel to 
        save computation time.",2022-04-14,Daniel J. Stekhoven,"https://www.r-project.org, https://github.com/stekhoven/missForest",TRUE,https://github.com/stekhoven/missforest,224639,56,2022-04-14T14:12:44Z,4011.410714285714
missMethods,"Supply functions for the creation and handling of missing
    data as well as tools to evaluate missing data methods. Nearly all
    possibilities of generating missing data discussed by Santos et al.
    (2019) <doi:10.1109/ACCESS.2019.2891360> and some additional are
    implemented.  Functions are supplied to compare parameter estimates
    and imputed values to true values to evaluate missing data methods.
    Evaluations of these types are done, for example, by Cetin-Berber et
    al. (2019) <doi:10.1177/0013164418805532> and Kim et al. (2005)
    <doi:10.1093/bioinformatics/bth499>.",2022-02-10,Tobias Rockel,https://github.com/torockel/missMethods,TRUE,https://github.com/torockel/missmethods,15525,4,2022-07-08T12:24:02Z,3881.25
missRanger,"Alternative implementation of the beautiful 'MissForest'
    algorithm used to impute mixed-type data sets by chaining random
    forests, introduced by Stekhoven, D.J. and Buehlmann, P. (2012)
    <doi:10.1093/bioinformatics/btr597>. Under the hood, it uses the
    lightning fast random jungle package 'ranger'. Between the iterative
    model fitting, we offer the option of using predictive mean matching.
    This firstly avoids imputation with values not already present in the
    original data (like a value 0.3334 in 0-1 coded variable).  Secondly,
    predictive mean matching tries to raise the variance in the resulting
    conditional distributions to a realistic level. This would allow e.g.
    to do multiple imputation when repeating the call to missRanger().  A
    formula interface allows to control which variables should be imputed
    by which.",2021-03-30,Michael Mayer,https://github.com/mayer79/missRanger,TRUE,https://github.com/mayer79/missranger,71262,42,2022-02-10T06:23:27Z,1696.7142857142858
missSBM,"When a network is partially observed (here, NAs in the adjacency matrix rather than 1 or 0 
  due to missing information between node pairs), it is possible to account for the underlying process
  that generates those NAs. 'missSBM', presented in 'Barbillon, Chiquet and Tabouy' (2021) <doi:10.18637/jss.v101.i12>,
  adjusts the popular stochastic block model from network data sampled under various missing data conditions, 
  as described in 'Tabouy, Barbillon and Chiquet' (2019) <doi:10.1080/01621459.2018.1562934>.",2022-02-01,Julien Chiquet,https://grosssbm.github.io/missSBM/,TRUE,https://github.com/grosssbm/misssbm,12661,9,2022-02-09T15:52:13Z,1406.7777777777778
mitml,"Provides tools for multiple imputation of missing data in multilevel
 modeling. Includes a user-friendly interface to the packages 'pan' and 'jomo',
 and several functions for visualization, data management and the analysis 
 of multiply imputed data sets.",2021-10-05,Simon Grund,NA,TRUE,https://github.com/simongrund1/mitml,245873,21,2022-07-05T09:31:58Z,11708.238095238095
MittagLeffleR,"Implements the Mittag-Leffler function, distribution,
  random variate generation, and estimation. Based on the Laplace-Inversion
  algorithm by Garrappa, R. (2015) <doi:10.1137/140971191>.",2021-09-06,Peter Straka,https://strakaps.github.io/MittagLeffleR/,TRUE,https://github.com/strakaps/mittagleffler,16006,4,2021-09-05T19:50:30Z,4001.5
MIWilson,"Implements the Wilson confidence interval 
    for binomial proportions given multiple imputations of missing data (detailed 
    theory provided in ""Wilson Confidence Intervals for Binomial
    Proportions With Multiple Imputation for Missing
    Data"" (A. Lott & J. Reiter, 2018)). Our package also implements a Wald confidence
    interval and allows for both MIDs object and proportion vector arguments. ",2021-08-23,Frances Hung,https://github.com/hungf8342/MIWilson,TRUE,https://github.com/hungf8342/miwilson,3366,0,2021-09-16T20:43:44Z,NA
mixAR,"Model time series using mixture autoregressive (MAR)
             models.  Implemented are frequentist (EM) and Bayesian
             methods for estimation, prediction and model
             evaluation. See Wong and Li (2002)
             <doi:10.1111/1467-9868.00222>, Boshnakov (2009)
             <doi:10.1016/j.spl.2009.04.009>), and the extensive
             references in the documentation.",2022-05-03,Georgi N. Boshnakov,"https://geobosh.github.io/mixAR/ (website),
https://github.com/GeoBosh/mixAR/ (devel)",TRUE,https://github.com/geobosh/mixar,14690,0,2022-05-05T09:22:44Z,NA
MixedPsy,"Tools for the analysis of psychophysical data in R. This package allows to estimate the Point of Subjective Equivalence (PSE) 
    and the Just Noticeable Difference (JND), either from a psychometric function or from a Generalized Linear Mixed Model (GLMM). 
    Additionally, the package allows plotting the fitted models and the response data, simulating psychometric functions of different shapes, and simulating data sets.
    For a description of the use of GLMMs applied to psychophysical data, refer to Moscatelli et al. (2012).",2021-11-08,Alessandro Moscatelli,https://mixedpsychophysics.wordpress.com,TRUE,https://github.com/moskante/mixedpsy,14697,1,2021-11-08T15:19:41Z,14697
MixfMRI,"Utilizing model-based clustering (unsupervised)
        for functional magnetic resonance imaging (fMRI) data.
        The developed methods (Chen and Maitra (2021) <arXiv:2102.03639>)
        include 2D and 3D clustering analyses
        (for p-values with voxel locations) and
        segmentation analyses (for p-values alone) for fMRI data where p-values
        indicate significant level of activation responding to stimulate
        of interesting. The analyses are mainly identifying active
        voxel/signal associated with normal brain behaviors.
        Analysis pipelines (R scripts) utilizing this package
        (see examples in 'inst/workflow/') is also implemented with high
        performance techniques.",2021-11-07,Wei-Chen Chen,https://github.com/snoweye/MixfMRI,TRUE,https://github.com/snoweye/mixfmri,12877,2,2022-04-19T00:38:13Z,6438.5
mixgb,"Multiple imputation using 'XGBoost', bootstrapping and predictive mean 
    matching as described in Deng and Lumley (2021) <arXiv:2106.01574>. It is built 
    under Fully Conditional Specification, where 'XGBoost' imputation models are
    built for each incomplete variable. It supports various types of variables and 
    offers different settings regarding bootstrapping and predictive mean matching. 
    Visual diagnostic functions are also provided for inspecting multiply imputed 
    values for incomplete variables.",2022-06-07,Yongshi Deng,"https://github.com/agnesdeng/mixgb,
https://agnesdeng.github.io/mixgb/",TRUE,https://github.com/agnesdeng/mixgb,268,7,2022-06-13T23:55:17Z,38.285714285714285
mixl,"Specification and estimation of multinomial logit
    models.  Large datasets and complex models are supported, with an
    intuitive syntax.  Multinomial Logit Models, Mixed models, random
    coefficients and Hybrid Choice are all supported.  For more
    information, see Molloy et al. (2019) <doi:10.3929/ethz-b-000334289>.",2021-12-08,Joseph Molloy,https://github.com/joemolloy/fast-mixed-mnl,TRUE,https://github.com/joemolloy/fast-mixed-mnl,16679,4,2021-12-08T12:44:06Z,4169.75
mixlm,"The main functions perform mixed models analysis by least squares
    or REML by adding the function r() to formulas of lm() and glm(). A collection of
    text-book statistics for higher education is also included, e.g. modifications
    of the functions lm(), glm() and associated summaries from the package 'stats'.",2022-02-24,Kristian Hovde Liland,https://github.com/khliland/mixlm/,TRUE,https://github.com/khliland/mixlm,47651,0,2022-02-24T18:03:43Z,NA
MixMatrix,"Provides sampling and density functions for matrix
    variate normal, t, and inverted t distributions;  ML estimation for matrix
    variate normal and t distributions using the EM algorithm,
    including some restrictions on the parameters; and classification by linear and
    quadratic discriminant analysis for matrix variate normal and t
    distributions described in Thompson et al. (2019) <doi:10.1080/10618600.2019.1696208>.
    Performs clustering with matrix variate normal and t mixture models.",2021-11-16,Geoffrey Thompson,"https://github.com/gzt/MixMatrix/,
https://gzt.github.io/MixMatrix/",TRUE,https://github.com/gzt/mixmatrix,17223,1,2021-11-15T13:21:50Z,17223
mixmeta,"A collection of functions to perform various meta-analytical models
  through a unified mixed-effects framework, including standard univariate
  fixed and random-effects meta-analysis and meta-regression, and non-standard
  extensions such as multivariate, multilevel, longitudinal, and dose-response
  models.",2021-10-16,Antonio Gasparrini,"https://github.com/gasparrini/mixmeta,
http://www.ag-myresearch.com/package-mixmeta",TRUE,https://github.com/gasparrini/mixmeta,45532,11,2021-10-16T14:21:13Z,4139.272727272727
mixsqp,"Provides an optimization method based on sequential
    quadratic programming (SQP) for maximum likelihood estimation of
    the mixture proportions in a finite mixture model where the
    component densities are known. The algorithm is expected to obtain
    solutions that are at least as accurate as the state-of-the-art
    MOSEK interior-point solver (called by function ""KWDual"" in the
    'REBayes' package), and they are expected to arrive at solutions
    more quickly when the number of samples is large and the number of
    mixture components is not too large. This implements the ""mix-SQP""
    algorithm, with some improvements, described in Y. Kim,
    P. Carbonetto, M. Stephens & M. Anitescu (2020)
    <DOI:10.1080/10618600.2019.1689985>.",2020-05-14,Peter Carbonetto,https://github.com/stephenslab/mixsqp,TRUE,https://github.com/stephenslab/mixsqp,70558,10,2022-05-04T13:13:09Z,7055.8
mixtox,"Curve Fitting of monotonic(sigmoidal) & non-monotonic(J-shaped) 
 dose-response data. Predicting mixture toxicity based on reference 
 models such as 'concentration addition', 'independent action', and 'generalized 
 concentration addition'.",2022-06-20,Xiangwei Zhu,https://github.com/ichxw/mixtox,TRUE,https://github.com/ichxw/mixtox,15156,0,2022-06-20T17:10:30Z,NA
mixtur,"A set of utility functions for analysing and modelling data from 
    continuous report short-term memory experiments using either the 2-component
    mixture model of Zhang and Luck (2008) <doi:10.1038/nature06860> or the 
    3-component mixture model of Bays et al. (2009) <doi:10.1167/9.10.7>. Users 
    are also able to simulate from these models.",2021-08-03,Jim Grange,https://github.com/JimGrange/mixtur,TRUE,https://github.com/jimgrange/mixtur,3097,5,2022-02-18T16:30:35Z,619.4
MixviR,"Tool for exploring DNA and amino acid variation and inferring the presence of target lineages from microbial high-throughput genomic DNA samples that potentially contain mixtures of variants/lineages. MixviR was originally created to help analyze environmental SARS-CoV-2/Covid-19 samples from environmental sources such as wastewater or dust, but can be applied to any microbial group. Inputs include reference genome information in commonly-used file formats (fasta, bed) and one or more variant call format (VCF) files, which can be generated with programs such as the Genome Analysis Toolkit or bcftools. See DePristo et al (2011) <doi:10.1038/ng.806> and Danecek et al (2021) <doi:10.1093/gigascience/giab008> for these tools, respectively. Available outputs include a table of mutations observed in the sample(s), estimates of proportions of target lineages in the sample(s), and an R Shiny dashboard to interactively explore the data. ",2022-05-04,Michael Sovic,https://github.com/mikesovic/MixviR,TRUE,https://github.com/mikesovic/mixvir,479,1,2022-05-10T02:12:05Z,479
mize,"Optimization algorithms implemented in R, including
    conjugate gradient (CG), Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the
    limited memory BFGS (L-BFGS) methods. Most internal parameters can be set 
    through the call interface. The solvers hold up quite well for 
    higher-dimensional problems.",2020-08-30,James Melville,https://github.com/jlmelville/mize,TRUE,https://github.com/jlmelville/mize,23121,9,2022-01-16T08:57:03Z,2569
mizer,"A set of classes and methods to set up and run multi-species, trait
    based and community size spectrum ecological models, focused on the marine
    environment.",2022-07-06,Gustav Delius,"https://sizespectrum.org/mizer/,
https://github.com/sizespectrum/mizer",TRUE,https://github.com/sizespectrum/mizer,22051,27,2022-07-06T07:12:08Z,816.7037037037037
mkin,"Calculation routines based on the FOCUS Kinetics Report (2006,
  2014).  Includes a function for conveniently defining differential equation
  models, model solution based on eigenvalues if possible or using numerical
  solvers.  If a C compiler (on windows: 'Rtools') is installed, differential
  equation models are solved using automatically generated C functions.
  Heteroscedasticity can be taken into account using variance by variable or
  two-component error models as described by Ranke and Meinecke (2018)
  <doi:10.3390/environments6120124>.  Interfaces to several nonlinear
  mixed-effects model packages are available, some of which are described by
  Ranke et al. (2021) <doi:10.3390/environments8080071>.  Please note that no
  warranty is implied for correctness of results or fitness for a particular
  purpose.",2022-03-14,Johannes Ranke,https://pkgdown.jrwb.de/mkin/,TRUE,https://github.com/jranke/mkin,37258,9,2022-07-08T17:29:17Z,4139.777777777777
MLDataR,"Contains a collection of datasets for working with machine learning tasks.
    It will contain datasets for supervised machine learning Jiang (2020)<doi:10.1016/j.beth.2020.05.002> and will include datasets for classification and regression.
    The aim of this package is to use data generated around health and other domains.",2022-03-08,Gary Hutson,NA,TRUE,https://github.com/statsgary/mldatar,2784,47,2022-04-29T10:09:40Z,59.234042553191486
mlfit,"The Iterative Proportional Fitting (IPF) algorithm operates on count data. 
    This package offers implementations for several algorithms that extend this to 
    nested structures: 'parent' and 'child' items for both of which constraints can be provided.
    The fitting algorithms include Iterative Proportional Updating <https://trid.trb.org/view/881554>,
    Hierarchical IPF <doi:10.3929/ethz-a-006620748>, Entropy Optimization <https://trid.trb.org/view/881144>,
    and Generalized Raking <doi:10.2307/2290793>. Additionally, a number of replication methods
    is also provided such as 'Truncate, replicate, sample' <doi:10.1016/j.compenvurbsys.2013.03.004>. ",2021-10-08,Kirill Müller,"https://mlfit.github.io/mlfit/, https://github.com/mlfit/mlfit",TRUE,https://github.com/mlfit/mlfit,4323,9,2022-05-14T02:32:25Z,480.3333333333333
MLGL,"It implements a new procedure of variable selection in the context of redundancy between explanatory variables, which holds true with high dimensional data (Grimonprez et al. (2018) <https://hal.inria.fr/hal-01857242>).",2022-05-25,Quentin Grimonprez,NA,TRUE,https://github.com/modal-inria/mlgl,13385,2,2021-08-24T15:18:57Z,6692.5
MLMusingR,"Convenience functions and datasets to be used with Practical Multilevel Modeling using R. The package includes functions for calculating group means, group mean centered variables, and displaying some basic missing data information. A function for computing robust standard errors for linear mixed models based on Liang and Zeger (1986) <doi:10.1093/biomet/73.1.13> and Bell and 'McCaffrey' (2002) <https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2002002/article/9058-eng.pdf?st=NxMjN1YZ> is included as well as a function for checking for level-one homoskedasticity (Raudenbush & Bryk, 2002, ISBN:076191904X).  ",2022-05-10,Francis Huang,https://github.com/flh3/MLMusingR,TRUE,https://github.com/flh3/mlmusingr,1748,2,2022-05-10T13:25:26Z,874
mlpack,"A fast, flexible machine learning library, written in C++, that
             aims to provide fast, extensible implementations of cutting-edge
             machine learning algorithms.  See also Curtin et al. (2018)
             <doi:10.21105/joss.00726>.",2020-12-18,Yashwant Singh Parihar,"https://www.mlpack.org/doc/mlpack-3.4.2/r_documentation.html,
https://github.com/mlpack/mlpack",TRUE,https://github.com/mlpack/mlpack,7974,4033,2022-07-08T19:07:05Z,1.9771881973716836
mlquantify,"Quantification is a prominent machine learning task that has received an 
    increasing amount of attention in the last years. The objective is to predict the 
    class distribution of a data sample. This package is a collection of machine learning 
    algorithms for class distribution estimation. This package include algorithms from
    different paradigms of quantification. These methods are described in the paper: 
    A. Maletzke, W. Hassan, D. dos Reis, and G. Batista. The importance of the test set 
    size in quantification assessment. In Proceedings of the Twenty-Ninth International 
    Joint Conference on Artificial Intelligence, IJCAI20, pages 2640–2646, 2020.
    <doi:10.24963/ijcai.2020/366>.",2022-01-20,Andre Maletzke,https://github.com/andregustavom/mlquantify,TRUE,https://github.com/andregustavom/mlquantify,7311,5,2022-01-20T13:36:12Z,1462.2
mlr3,"Efficient, object-oriented programming on the
    building blocks of machine learning. Provides 'R6' objects for tasks,
    learners, resamplings, and measures. The package is geared towards
    scalability and larger datasets by supporting parallelization and
    out-of-memory data-backends like databases. While 'mlr3' focuses on
    the core computational operations, add-on packages provide additional
    functionality.",2022-03-01,Michel Lang,"https://mlr3.mlr-org.com, https://github.com/mlr-org/mlr3",TRUE,https://github.com/mlr-org/mlr3,287286,665,2022-07-05T04:25:08Z,432.00902255639096
mlr3benchmark,"Implements methods for post-hoc analysis and
    visualisation of benchmark experiments, for 'mlr3' and beyond.",2021-10-04,Sonabend Raphael,"https://mlr3benchmark.mlr-org.com,
https://github.com/mlr-org/mlr3benchmark",TRUE,https://github.com/mlr-org/mlr3benchmark,8382,9,2022-06-24T12:13:22Z,931.3333333333334
mlr3cluster,Extends the 'mlr3' package with cluster analysis.,2022-04-06,Damir Pulatov,"https://mlr3cluster.mlr-org.com,
https://github.com/mlr-org/mlr3cluster",TRUE,https://github.com/mlr-org/mlr3cluster,24853,13,2022-03-29T16:13:01Z,1911.7692307692307
mlr3data,"A small collection of interesting and educational machine
    learning data sets which are used as examples in the 'mlr3' book
    (<https://mlr3book.mlr-org.com>), the use case gallery
    (<https://mlr3gallery.mlr-org.com>), or in other examples. All data
    sets are properly preprocessed and ready to be analyzed by most
    machine learning algorithms.  Data sets are automatically added to the
    dictionary of tasks if 'mlr3' is loaded.",2022-03-18,Michel Lang,https://github.com/mlr-org/mlr3data,TRUE,https://github.com/mlr-org/mlr3data,73021,3,2022-03-21T19:55:20Z,24340.333333333332
mlr3db,"Extends the 'mlr3' package with a backend to
    transparently work with databases. Includes two extra backends:
    One relies on relies on the abstraction of package 'dbplyr' to interact with
    one of the many supported database management systems (DBMS). The other one
    is specialized for package 'duckdb'.",2021-11-17,Michel Lang,"https:///mlr3db.mlr-org.com, https://github.com/mlr-org/mlr3db",TRUE,https://github.com/mlr-org/mlr3db,18444,19,2022-01-27T10:36:50Z,970.7368421052631
mlr3fairness,"
    Integrates fairness auditing and bias mitigation methods for the 'mlr3' ecosystem.
    This includes fairness metrics, reporting tools, visualizations and bias mitigation techniques such as 
    ""Reweighing"" described in 'Kamiran, Calders' (2012) <doi:10.1007/s10115-011-0463-8>  and 
    ""Equalized Odds"" described in 'Hardt et al.' (2016) <https://papers.nips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf>.
    Integration with 'mlr3' allows for auditing of ML models as well as convenient joint tuning of
    machine learning algorithms and debiasing methods.",2022-05-12,Florian Pfisterer,"https://mlr3fairness.mlr-org.com,
https://github.com/mlr-org/mlr3fairness",TRUE,https://github.com/mlr-org/mlr3fairness,424,11,2022-06-28T06:18:18Z,38.54545454545455
mlr3filters,"Extends 'mlr3' with filter methods for feature selection.
    Besides standalone filter methods built-in methods of any
    machine-learning algorithm are supported.  Partial scoring of
    multivariate filter methods is supported.",2022-01-25,Patrick Schratz,"https://mlr3filters.mlr-org.com,
https://github.com/mlr-org/mlr3filters",TRUE,https://github.com/mlr-org/mlr3filters,46228,12,2022-07-05T06:47:49Z,3852.3333333333335
mlr3fselect,"Implements methods for feature selection with
    'mlr3', e.g.  random search and sequential selection. Various
    termination criteria can be set and combined. The class
    'AutoFSelector' provides a convenient way to perform nested resampling
    in combination with 'mlr3'.",2022-05-03,Marc Becker,"https://mlr3fselect.mlr-org.com,
https://github.com/mlr-org/mlr3fselect",TRUE,https://github.com/mlr-org/mlr3fselect,26742,11,2022-05-03T10:02:54Z,2431.090909090909
mlr3hyperband,"Implements hyperband method for hyperparameter
    tuning.  Various termination criteria can be set and combined. The
    class 'AutoTuner' provides a convenient way to perform nested
    resampling in combination with 'mlr3'. The hyperband algorithm was
    proposed by Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin
    Rostamizadeh and Ameet Talwalkar (2018) <arXiv:1603.06560>.",2022-05-04,Marc Becker,"https://mlr3hyperband.mlr-org.com,
https://github.com/mlr-org/mlr3hyperband",TRUE,https://github.com/mlr-org/mlr3hyperband,14323,16,2022-05-04T08:13:45Z,895.1875
mlr3learners,"Recommended Learners for 'mlr3'. Extends 'mlr3'
    with interfaces to essential machine learning packages on
    CRAN.  This includes, but is not limited to: (penalized) linear and
    logistic regression, linear and quadratic discriminant analysis,
    k-nearest neighbors, naive Bayes, support vector machines, and
    gradient boosting.",2022-05-25,Michel Lang,"https://mlr3learners.mlr-org.com,
https://github.com/mlr-org/mlr3learners",TRUE,https://github.com/mlr-org/mlr3learners,83073,74,2022-06-29T21:43:22Z,1122.6081081081081
mlr3measures,"Implements multiple performance measures for
    supervised learning.  Includes over 40 measures for regression and
    classification. Additionally, meta information about the performance
    measures can be queried, e.g. what the best and worst possible
    performances scores are.",2022-01-13,Michel Lang,"https:///mlr3measures.mlr-org.com,
https://github.com/mlr-org/mlr3measures",TRUE,https://github.com/mlr-org/mlr3measures,273186,7,2022-03-15T19:11:33Z,39026.57142857143
mlr3misc,"Frequently used helper functions and assertions
    used in 'mlr3' and its companion packages. Comes with helper functions
    for functional programming, for printing, to work with 'data.table',
    as well as some generally useful 'R6' classes. This package also
    supersedes the package 'BBmisc'.",2022-01-11,Michel Lang,"https://mlr3misc.mlr-org.com, https://github.com/mlr-org/mlr3misc",TRUE,https://github.com/mlr-org/mlr3misc,308288,8,2022-04-27T18:26:47Z,38536
mlr3oml,"Provides an interface to 'OpenML.org' to list and
    download machine learning data and tasks. Data and tasks can be
    automatically converted to 'mlr3' tasks. For a more sophisticated
    interface which also allows uploading experiments, see the 'OpenML'
    package.",2021-09-24,Michel Lang,"https://mlr3oml.mlr-org.com, https://github.com/mlr-org/mlr3oml",TRUE,https://github.com/mlr-org/mlr3oml,14274,3,2022-05-18T08:47:37Z,4758
mlr3pipelines,"Dataflow programming toolkit that enriches 'mlr3' with a diverse
  set of pipelining operators ('PipeOps') that can be composed into graphs.
  Operations exist for data preprocessing, model fitting, and ensemble
  learning. Graphs can themselves be treated as 'mlr3' 'Learners' and can
  therefore be resampled, benchmarked, and tuned.",2022-05-15,Martin Binder,"https://mlr3pipelines.mlr-org.com,
https://github.com/mlr-org/mlr3pipelines",TRUE,https://github.com/mlr-org/mlr3pipelines,90722,117,2022-06-23T09:44:13Z,775.4017094017094
mlr3spatial,"Extends the 'mlr3' ML framework with methods for spatial
    objects. Data storage and prediction are supported for packages
    'terra', 'raster' and 'stars'.",2022-03-06,Marc Becker,"https://mlr3spatial.mlr-org.com,
https://github.com/mlr-org/mlr3spatial",TRUE,https://github.com/mlr-org/mlr3spatial,2854,37,2022-07-09T08:20:06Z,77.13513513513513
mlr3spatiotempcv,"Extends the mlr3 ML framework with spatio-temporal resampling
    methods to account for the presence of spatiotemporal autocorrelation
    (STAC) in predictor variables. STAC may cause highly biased
    performance estimates in cross-validation if ignored.",2022-06-22,Patrick Schratz,"https://mlr3spatiotempcv.mlr-org.com/,
https://github.com/mlr-org/mlr3spatiotempcv,
https://mlr3book.mlr-org.com",TRUE,https://github.com/mlr-org/mlr3spatiotempcv,10880,39,2022-07-08T09:50:11Z,278.97435897435895
mlr3tuning,"Implements methods for hyperparameter tuning with 'mlr3',
    e.g. grid search, random search, generalized simulated annealing and
    iterated racing.  Various termination criteria can be set and
    combined.  The class 'AutoTuner' provides a convenient way to perform
    nested resampling in combination with 'mlr3'.",2022-05-03,Marc Becker,"https://mlr3tuning.mlr-org.com,
https://github.com/mlr-org/mlr3tuning",TRUE,https://github.com/mlr-org/mlr3tuning,67820,42,2022-05-03T09:55:51Z,1614.7619047619048
mlr3tuningspaces,"Collection of search spaces for hyperparameter tuning.
    Includes various search spaces that can be directly applied on an
    `mlr3` learner. Additionally, meta information about the search space
    can be queried.",2022-06-28,Marc Becker,"https://mlr3tuningspaces.mlr-org.com,
https://github.com/mlr-org/mlr3tuningspaces",TRUE,https://github.com/mlr-org/mlr3tuningspaces,9750,7,2022-06-28T10:55:12Z,1392.857142857143
mlr3verse,"The 'mlr3' package family is a set of packages for
    machine-learning purposes built in a modular fashion. This wrapper
    package is aimed to simplify the installation and loading of the core
    'mlr3' packages. Get more information about the 'mlr3' project at
    <https://mlr3book.mlr-org.com/>.",2022-05-18,Michel Lang,"https://mlr3verse.mlr-org.com,
https://github.com/mlr-org/mlr3verse",TRUE,https://github.com/mlr-org/mlr3verse,32677,20,2022-05-18T08:14:16Z,1633.85
mlr3viz,"Provides visualizations for 'mlr3' objects such as tasks,
    predictions, resample results or benchmark results via the autoplot()
    generic of 'ggplot2'. The returned 'ggplot' objects are intended to
    provide sensible defaults, yet can easily be customized to create
    camera-ready figures. Visualizations include barplots, boxplots,
    histograms, ROC curves, and Precision-Recall curves.",2022-05-25,Michel Lang,"https://mlr3viz.mlr-org.com, https://github.com/mlr-org/mlr3viz",TRUE,https://github.com/mlr-org/mlr3viz,46879,33,2022-06-01T13:34:27Z,1420.5757575757575
mlrCPO,"Toolset that enriches 'mlr' with a diverse set of preprocessing
    operators. Composable Preprocessing Operators (""CPO""s) are first-class
    R objects that can be applied to data.frames and 'mlr' ""Task""s to modify
    data, can be attached to 'mlr' ""Learner""s to add preprocessing to machine
    learning algorithms, and can be composed to form preprocessing pipelines.",2021-11-10,Martin Binder,https://github.com/mlr-org/mlrCPO,TRUE,https://github.com/mlr-org/mlrcpo,24736,37,2021-11-10T02:10:54Z,668.5405405405405
mlrintermbo,"The 'mlrMBO' package can ordinarily not be used for optimization within 'mlr3', because of
  incompatibilities of their respective class systems. 'mlrintermbo' offers a compatibility
  interface that provides 'mlrMBO' as an 'mlr3tuning' 'Tuner' object, for tuning of machine
  learning algorithms within 'mlr3', as well as a 'bbotk' 'Optimizer' object for optimization
  of general objective functions using the 'bbotk' black box optimization framework. The
  control parameters of 'mlrMBO' are faithfully reproduced as a 'paradox' 'ParamSet'.",2021-03-01,Martin Binder,https://github.com/mb706/mlrintermbo,TRUE,https://github.com/mb706/mlrintermbo,4927,4,2021-09-18T01:42:09Z,1231.75
mlrMBO,"Flexible and comprehensive R toolbox for model-based optimization
    ('MBO'), also known as Bayesian optimization. It implements the Efficient
    Global Optimization Algorithm and is designed for both single- and multi-
    objective optimization with mixed continuous, categorical and conditional
    parameters. The machine learning toolbox 'mlr' provide dozens of regression
    learners to model the performance of the target algorithm with respect to
    the parameter settings. It provides many different infill criteria to guide
    the search process. Additional features include multi-point batch proposal,
    parallel execution as well as visualization and sophisticated logging
    mechanisms, which is especially useful for teaching and understanding of
    algorithm behavior. 'mlrMBO' is implemented in a modular fashion, such that
    single components can be easily replaced or adapted by the user for specific
    use cases.",2022-07-04,Bernd Bischl,https://github.com/mlr-org/mlrMBO,TRUE,https://github.com/mlr-org/mlrmbo,157790,177,2022-03-02T21:43:26Z,891.4689265536723
mltools,"A collection of machine learning helper functions, particularly assisting in the Exploratory Data Analysis phase. Makes heavy use of the 'data.table' package for optimal speed and memory efficiency. Highlights include a versatile bin_data() function, sparsify() for converting a data.table to sparse matrix format with one-hot encoding, fast evaluation metrics, and empirical_cdf() for calculating empirical Multivariate Cumulative Distribution Functions.",2018-05-12,Ben Gorman,https://github.com/ben519/mltools,TRUE,https://github.com/ben519/mltools,148978,70,2021-09-20T15:54:08Z,2128.2571428571428
MM,Various utilities for the Multiplicative Multinomial distribution.,2021-10-08,Robin K. S. Hankin and P. M. E. Altham,https://github.com/RobinHankin/MM,TRUE,https://github.com/robinhankin/mm,17051,0,2021-10-07T21:22:47Z,NA
mmaqshiny,"Mobile-monitoring or ""sensors on a mobile platform"", is an increasingly 
    popular approach to measure high-resolution pollution data at the street level. 
    Coupled with location data, spatial visualisation of air-quality parameters 
    helps detect localized areas of high air-pollution, also called hotspots. 
    In this approach, portable sensors are mounted on a vehicle and driven on 
    predetermined routes to collect high frequency data (1 Hz). 
    'mmaqshiny' is for analysing, visualising and spatial mapping of 
    high-resolution air-quality data collected by specific devices installed on 
    a moving platform. 1 Hz data of PM2.5 (mass concentrations of particulate  
    matter with size less than 2.5 microns), Black carbon mass concentrations 
    (BC), ultra-fine particle number concentrations, carbon dioxide along with 
    GPS coordinates and relative humidity (RH) data collected by popular 
    portable instruments (TSI DustTrak-8530, Aethlabs microAeth-AE51, TSI CPC3007, 
    LICOR Li-830, Garmin GPSMAP 64s, Omega USB RH probe respectively). It 
    incorporates device specific cleaning and correction algorithms. RH correction 
    is applied to DustTrak PM2.5 following the Chakrabarti et al., (2004) 
    <doi:10.1016/j.atmosenv.2004.03.007>. Provision is given to add linear 
    regression coefficients for correcting the PM2.5 data (if required). BC data
    will be cleaned for the vibration generated noise, by adopting the statistical 
    procedure as explained in Apte et al., (2011) <doi:10.1016/j.atmosenv.2011.05.028>, 
    followed by a loading correction as suggested by Ban-Weiss et al., (2009)  
    <doi:10.1021/es8021039>. For the number concentration data, provision is 
    given for dilution correction factor (if a diluter is used with CPC3007; 
    default value is 1). The package joins the raw, cleaned and corrected data 
    from the above said instruments and outputs as a downloadable csv file. ",2020-06-26,Adithi R. Upadhya,https://github.com/meenakshi-kushwaha/mmaqshiny,TRUE,https://github.com/meenakshi-kushwaha/mmaqshiny,7899,4,2022-05-10T08:43:00Z,1974.75
mmcif,"Fits the mixed cumulative incidence functions model suggested by 
    <doi:10.1093/biostatistics/kxx072> which decomposes within cluster 
    dependence of risk and timing. The estimation method supports computation in 
    parallel using a shared memory C++ implementation. A sandwich estimator of the 
    covariance matrix is available. Natural cubic splines are used to provide a 
    flexible model for the cumulative incidence functions.",2022-06-27,Benjamin Christoffersen,https://github.com/boennecd/mmcif,TRUE,https://github.com/boennecd/mmcif,141,0,2022-06-30T05:18:24Z,NA
MMDCopula,"Provides functions for the robust estimation of 
	parametric families of copulas using minimization of 
	the Maximum Mean Discrepancy, following the article
	Alquier, Chérief-Abdellatif, Derumigny and Fermanian (2022)
	<doi:10.1080/01621459.2021.2024836>.",2022-04-25,Alexis Derumigny,NA,TRUE,https://github.com/alexisderumigny/mmdcopula,7165,3,2022-04-25T09:16:00Z,2388.3333333333335
MMeM,"Analyzing data under multivariate mixed effects model using multivariate REML and multivariate Henderson3 methods. 
  See Meyer (1985) <doi:10.2307/2530651> and Wesolowska Janczarek (1984) <doi:10.1002/bimj.4710260613>.",2021-09-08,Luyao Peng,NA,TRUE,https://github.com/pengluyaoyao/mmem,11692,2,2021-09-07T15:18:54Z,5846
MMINP,"
     Implements a computational framework to predict microbial community-based 
     metabolic profiles with 'O2PLS' model. It provides procedures of model 
     training and prediction. Paired microbiome and metabolome data are needed 
     for modeling, and the trained model can be applied to predict metabolites 
     of analogous environments using new microbial feature abundances.",2022-07-04,Wenli Tang,https://github.com/YuLab-SMU/MMINP,TRUE,https://github.com/yulab-smu/mminp,39,7,2022-07-06T07:05:58Z,5.571428571428571
MMRcaseselection,"Researchers doing a mixed-methods analysis (nested analysis as
    developed by Lieberman (2005) <doi:10.1017/S0003055405051762>) can
    use the package for the classification of cases and case selection using
    results of a linear regression. One can designate cases 
    as typical, deviant, extreme and pathway case and use different case 
    selection strategies for the choice of a case belonging to one of
    these types.",2020-06-03,Ingo Rohlfing,https://github.com/ingorohlfing/MMRcaseselection,TRUE,https://github.com/ingorohlfing/mmrcaseselection,7011,1,2021-09-28T19:04:53Z,7011
mnlfa,"
    Conducts moderated nonlinear factor analysis (e.g., Curran et al., 2014,
    <doi:10.1080/00273171.2014.889594>). 
    Regularization methods are implemented for assessing non-invariant items. 
    Currently, the package includes dichotomous items and unidimensional
    item response models. Extensions will be included in future package
    versions.",2022-05-18,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/mnlfa,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/mnlfa,12242,2,2022-05-18T08:45:14Z,6121
MNP,"Fits the Bayesian multinomial probit model via Markov chain
 Monte Carlo.  The multinomial probit model is often used to analyze 
 the discrete choices made by individuals recorded in survey data. 
 Examples where the multinomial probit model may be useful include the 
 analysis of product choice by consumers in market research and the 
 analysis of candidate or party choice by voters in electoral studies.  
 The MNP package can also fit the model with different choice sets for 
 each individual, and complete or partial individual choice orderings 
 of the available alternatives from the choice set. The estimation is
 based on the efficient marginal data augmentation algorithm that is 
 developed by Imai and van Dyk (2005). ""A Bayesian Analysis of the 
 Multinomial Probit Model Using the Data Augmentation."" Journal of 
 Econometrics, Vol. 124, No. 2 (February), pp. 311-334. 
 <doi:10.1016/j.jeconom.2004.02.002>  Detailed examples are given in 
 Imai and van Dyk (2005). ""MNP: R Package for Fitting the Multinomial 
 Probit Model.""  Journal of Statistical Software, Vol. 14, No. 3 (May), 
 pp. 1-32. <doi:10.18637/jss.v014.i03>.",2022-04-07,Kosuke Imai,https://github.com/kosukeimai/MNP,TRUE,https://github.com/kosukeimai/mnp,45850,10,2022-04-07T01:29:59Z,4585
mockery,"The two main functionalities of this package are creating
    mock objects (functions) and selectively intercepting calls to a given
    function that originate in some other function. It can be used with
    any testing framework available for R. Mock objects can be injected
    with either this package's own stub() function or a similar
    with_mock() facility present in the 'testthat' package.",2022-02-20,Hadley Wickham,https://github.com/r-lib/mockery,TRUE,https://github.com/r-lib/mockery,767505,91,2022-02-20T13:24:57Z,8434.12087912088
mockr,"Provides a means to mock a package function, i.e.,
    temporarily substitute it for testing. Designed as a drop-in
    replacement for the now deprecated 'testthat::with_mock()' and
    'testthat::local_mock()'.",2022-04-02,Kirill Müller,"https://krlmlr.github.io/mockr/, https://github.com/krlmlr/mockr",TRUE,https://github.com/krlmlr/mockr,106520,14,2022-05-14T00:31:58Z,7608.571428571428
mockthat,"With the deprecation of mocking capabilities shipped with
    'testthat' as of 'edition 3' it is left to third-party packages to replace
    this functionality, which in some test-scenarios is essential in order to
    run unit tests in limited environments (such as no Internet connection).
    Mocking in this setting means temporarily substituting a function with a
    stub that acts in some sense like the original function (for example by
    serving a HTTP response that has been cached as a file). The only exported
    function 'with_mock()' is modeled after the eponymous 'testthat' function
    with the intention of providing a drop-in replacement.",2021-04-23,Nicolas Bennett,https://nbenn.github.io/mockthat/,TRUE,https://github.com/nbenn/mockthat,14796,12,2022-01-14T08:53:08Z,1233
modelbased,"Implements a general interface for model-based estimations
    for a wide variety of models (see list of supported models using the
    function 'insight::supported_models()'), used in the computation of
    marginal means, contrast analysis and predictions.",2022-05-30,Dominique Makowski  (<https://orcid.org/0000-0001-5375-9967>,https://easystats.github.io/modelbased/,TRUE,https://github.com/easystats/modelbased,85737,205,2022-06-25T06:58:04Z,418.22926829268295
modeldata,"Data sets used for demonstrating or testing model-related
    packages are contained in this package.",2022-07-01,Max Kuhn,"https://modeldata.tidymodels.org,
https://github.com/tidymodels/modeldata",TRUE,https://github.com/tidymodels/modeldata,966098,20,2022-07-01T18:01:07Z,48304.9
modeldb,Uses 'dplyr' and 'tidyeval' to fit statistical models inside the database. It currently supports KMeans and linear regression models.,2020-02-10,Max Kuhn,https://github.com/tidymodels/modeldb,TRUE,https://github.com/tidymodels/modeldb,44883,74,2021-10-28T17:58:48Z,606.527027027027
modeLLtest,"An implementation of the cross-validated difference in means (CVDM) test by Desmarais and Harden (2014) <doi:10.1007/s11135-013-9884-7> (see also Harden and Desmarais, 2011 <doi:10.1177/1532440011408929>) and the cross-validated median fit (CVMF) test by Desmarais and Harden (2012) <doi:10.1093/pan/mpr042>. These tests use leave-one-out cross-validated log-likelihoods to assist in selecting among model estimations. You can also utilize data from Golder (2010) <doi:10.1177/0010414009341714> and Joshi & Mason (2008) <doi:10.1177/0022343308096155> that are included to facilitate examples from real-world analysis.",2022-05-05,Shana Scogin,https://github.com/ShanaScogin/modeLLtest,TRUE,https://github.com/shanascogin/modelltest,13813,10,2022-05-05T20:33:06Z,1381.3
modelr,"Functions for modelling that help you seamlessly
    integrate modelling into a pipeline of data manipulation and
    visualisation.",2020-05-19,Hadley Wickham,"https://modelr.tidyverse.org, https://github.com/tidyverse/modelr",TRUE,https://github.com/tidyverse/modelr,13651127,388,2022-03-02T20:14:03Z,35183.31701030928
modelStudio,"Automate the explanatory analysis of machine learning predictive 
    models. Generate advanced interactive model explanations in the form of 
    a serverless HTML site with only one line of code. This tool is 
    model-agnostic, therefore compatible with most of the black-box predictive
    models and frameworks. The main function computes various (instance and 
    model-level) explanations and produces a customisable dashboard, which 
    consists of multiple panels for plots with their short descriptions. It is 
    possible to easily save the dashboard and share it with others. Tools for 
    Explanatory Model Analysis unite with tools for Exploratory Data Analysis 
    to give a broad overview of the model behavior.",2022-03-05,Hubert Baniecki,"https://modelstudio.drwhy.ai,
https://github.com/ModelOriented/modelStudio",TRUE,https://github.com/modeloriented/modelstudio,27829,265,2022-06-01T13:57:34Z,105.01509433962264
modelsummary,"Create beautiful and customizable tables to summarize several
    statistical models side-by-side. Draw coefficient plots, multi-level
    cross-tabs, dataset summaries, balance tables (a.k.a. ""Table 1s""), and
    correlation matrices. This package supports dozens of statistical models, and
    it can produce tables in HTML, LaTeX, Word, Markdown, PDF, PowerPoint, Excel,
    RTF, JPG, or PNG. Tables can easily be embedded in 'Rmarkdown' or 'knitr'
    dynamic documents. Details can be found in Arel-Bundock (2022)
    <doi:10.18637/jss.v103.i01>.",2022-06-29,Vincent Arel-Bundock,https://vincentarelbundock.github.io/modelsummary/,TRUE,https://github.com/vincentarelbundock/modelsummary,158852,618,2022-07-07T19:41:57Z,257.042071197411
modeltime,"
    The time series forecasting framework for use with the 'tidymodels' ecosystem. 
    Models include ARIMA, Exponential Smoothing, and additional time series models
    from the 'forecast' and 'prophet' packages. Refer to ""Forecasting Principles & Practice, Second edition"" 
    (<https://otexts.com/fpp2/>).
    Refer to ""Prophet: forecasting at scale"" 
    (<https://research.facebook.com/blog/2017/02/prophet-forecasting-at-scale/>.).",2022-06-07,Matt Dancho,"https://github.com/business-science/modeltime,
https://business-science.github.io/modeltime/",TRUE,https://github.com/business-science/modeltime,167570,383,2022-06-21T14:46:05Z,437.5195822454308
modeltime.ensemble,"
    A 'modeltime' extension that implements time series ensemble forecasting methods including model averaging, 
    weighted averaging, and stacking. These techniques are popular methods 
    to improve forecast accuracy and stability. Refer to papers such as 
    ""Machine-Learning Models for Sales Time Series Forecasting"" Pavlyshenko, B.M. (2019) <doi:10.3390>.",2022-06-09,Matt Dancho,https://github.com/business-science/modeltime.ensemble,TRUE,https://github.com/business-science/modeltime.ensemble,27671,62,2022-06-09T11:23:05Z,446.30645161290323
modeltime.gluonts,"
    Use the 'GluonTS' deep learning library inside of 'modeltime'.
    Available models include 'DeepAR', 'N-BEATS', and 'N-BEATS' Ensemble. 
    Refer to ""GluonTS - Probabilistic Time Series Modeling"" 
    (<https://ts.gluon.ai/index.html>).",2020-11-30,Matt Dancho,https://github.com/business-science/modeltime.gluonts,TRUE,https://github.com/business-science/modeltime.gluonts,9056,31,2021-12-17T03:03:58Z,292.1290322580645
modeltime.resample,"
    A 'modeltime' extension that implements forecast resampling tools
    that assess time-based model performance and stability for a single time series, 
    panel data, and cross-sectional time series analysis. ",2022-06-07,Matt Dancho,https://github.com/business-science/modeltime.resample,TRUE,https://github.com/business-science/modeltime.resample,54777,12,2022-06-07T12:57:09Z,4564.75
moderndive,"Datasets and wrapper functions for tidyverse-friendly introductory linear regression, used in ""Statistical Inference via Data Science: A ModernDive into R and the Tidyverse"" available at <https://moderndive.com/>.",2022-05-13,Albert Y. Kim,"https://moderndive.github.io/moderndive/,
https://github.com/moderndive/moderndive/",TRUE,https://github.com/moderndive/moderndive,82385,80,2022-06-02T21:34:49Z,1029.8125
MODISTools,"Programmatic interface to the Oak Ridge National Laboratories
    'MODIS Land Products Subsets' web services 
    (<https://modis.ornl.gov/data/modis_webservice.html>). Allows for easy
    downloads of 'MODIS' time series directly to your R workspace or
    your computer.",2022-04-04,Hufkens Koen,https://docs.ropensci.org/MODISTools/,TRUE,https://github.com/ropensci/modistools,27949,41,2022-04-07T14:41:53Z,681.6829268292682
MODIStsp,"Allows automating the creation of time series of rasters derived
    from MODIS satellite land products data. It performs several typical
    preprocessing steps such as download, mosaicking, reprojecting and resizing
    data acquired on a specified time period. All processing parameters
    can be set using a user-friendly GUI. Users can select which layers of
    the original MODIS HDF files they want to process, which additional
    quality indicators should be extracted from aggregated MODIS quality
    assurance layers and, in the case of surface reflectance products,
    which spectral indexes should be computed from the original reflectance
    bands. For each output layer, outputs are saved as single-band raster
    files corresponding to each available acquisition date. Virtual files
    allowing access to the entire time series as a single file are also created.
    Command-line execution exploiting a previously saved processing options
    file is also possible, allowing users to automatically update time series
    related to a MODIS product whenever a new image is available.
    For additional documentation refer to the following article: 
    Busetto and Ranghetti (2016) <doi:10.1016/j.cageo.2016.08.020>.",2022-04-25,Lorenzo Busetto,"https://github.com/ropensci/MODIStsp/,
https://docs.ropensci.org/MODIStsp/",TRUE,https://github.com/ropensci/modistsp,31467,137,2022-04-21T06:23:15Z,229.68613138686132
modnets,"Methods for modeling moderator variables in cross-sectional, temporal, and multi-level networks. Includes model selection techniques and a variety of plotting functions. Implements the methods described by Swanson (2020) <https://www.proquest.com/openview/d151ab6b93ad47e3f0d5e59d7b6fd3d3>.",2021-10-01,Trevor Swanson,https://github.com/tswanson222/modnets,TRUE,https://github.com/tswanson222/modnets,2649,0,2021-10-28T01:00:24Z,NA
modules,"Provides modules as an organizational unit for source code. Modules
    enforce to be more rigorous when defining dependencies and have
    a local search path. They can be used as a sub unit within packages
    or in scripts.",2021-02-06,Sebastian Warnholz,https://github.com/wahani/modules,TRUE,https://github.com/wahani/modules,65732,73,2022-04-21T07:56:03Z,900.4383561643835
MoEClust,"Clustering via parsimonious Gaussian Mixtures of Experts using the MoEClust models introduced by Murphy and Murphy (2020) <doi:10.1007/s11634-019-00373-8>. This package fits finite Gaussian mixture models with a formula interface for supplying gating and/or expert network covariates using a range of parsimonious covariance parameterisations from the GPCM family via the EM/CEM algorithm. Visualisation of the results of such models using generalised pairs plots and the inclusion of an additional noise component is also facilitated. A greedy forward stepwise search algorithm is provided for identifying the optimal model in terms of the number of components, the GPCM covariance parameterisation, and the subsets of gating/expert network covariates.",2022-03-28,Keefe Murphy,https://cran.r-project.org/package=MoEClust,TRUE,https://github.com/keefe-murphy/moeclust,21402,5,2022-03-28T14:55:03Z,4280.4
MolgenisArmadillo,"A set of functions to be able to manage data shared on a
  'MOLGENIS Armadillo' storage server ('MinIO').",2022-04-01,Mariska Slofstra,"https://github.com/molgenis/molgenis-r-armadillo/,
https://molgenis.github.io/molgenis-r-armadillo/",TRUE,https://github.com/molgenis/molgenis-r-armadillo,6405,1,2022-03-31T14:04:38Z,6405
MolgenisAuth,"Discover 'OpenID Connect' endpoints and authenticate
    using device flow. Used by 'MOLGENIS' packages.",2022-03-25,Fleur Kelpin,"https://github.com/molgenis/molgenis-r-auth/,
https://molgenis.github.io/molgenis-r-auth/",TRUE,https://github.com/molgenis/molgenis-r-auth,7792,3,2022-03-25T10:20:17Z,2597.3333333333335
molic,"Outlier detection in, possibly high-dimensional, categorical data following
	     Mads Lindskou et al. (2019) <doi:10.1111/sjos.12407>.",2021-06-02,Mads Lindskou,https://github.com/mlindsk/molic,TRUE,https://github.com/mlindsk/molic,8842,6,2022-03-04T07:10:54Z,1473.6666666666667
mombf,Bayesian model selection and averaging for regression and mixtures for non-local and selected local priors.,2022-04-01,David Rossell,https://github.com/davidrusi/mombf,TRUE,https://github.com/davidrusi/mombf,31390,4,2022-06-10T15:10:16Z,7847.5
momentuHMM,"Extended tools for analyzing telemetry data using generalized hidden Markov models. Features of momentuHMM (pronounced ``momentum'') include data pre-processing and visualization, fitting HMMs to location and auxiliary biotelemetry or environmental data, biased and correlated random walk movement models, hierarchical HMMs, multiple imputation for incorporating location measurement error and missing data, user-specified design matrices and constraints for covariate modelling of parameters, random effects, decoding of the state process, visualization of fitted models, model checking and selection, and simulation. See McClintock and Michelot (2018) <doi:10.1111/2041-210X.12995>.",2021-09-03,Brett McClintock,"https://github.com/bmcclintock/momentuHMM,
https://github.com/bmcclintock/momentuHMM/discussions",TRUE,https://github.com/bmcclintock/momentuhmm,25868,25,2021-09-02T21:48:35Z,1034.72
Momocs,"The goal of 'Momocs' is to provide a complete, convenient, 
       reproducible and open-source toolkit for 2D morphometrics.
       It includes most common 2D morphometrics approaches on outlines, open outlines, 
       configurations of landmarks, traditional morphometrics, and facilities for data preparation, 
       manipulation and visualization with a consistent grammar throughout.
       It allows reproducible, complex morphometrics analyses and other morphometrics approaches 
       should be easy to plug in, or develop from, on top of this canvas. ",2022-04-04,Vincent Bonhomme,https://github.com/MomX/Momocs/,TRUE,https://github.com/momx/momocs,27428,46,2022-04-05T09:27:38Z,596.2608695652174
monaco,"A HTML widget rendering the 'Monaco' editor. The 'Monaco' editor is the code editor which powers 'VS Code'. It is particularly well developed for 'JavaScript'. In addition to the built-in features of the 'Monaco' editor, the widget allows to prettify multiple languages, to view the 'HTML' rendering of 'Markdown' code, and to view and resize 'SVG' images.",2022-05-18,Stéphane Laurent,https://github.com/stla/monaco,TRUE,https://github.com/stla/monaco,7227,2,2022-05-18T08:52:10Z,3613.5
monashtipr,"An API wrapper for the 'Monash University Probabilistic Footy 
    Tipping Competition' <https://probabilistic-footy.monash.edu/~footy/index.shtml>. 
    Allows users to submit tips directly to the competition from R.",2022-03-21,James Day,"https://jimmyday12.github.io/monash_tipr/,
https://github.com/jimmyday12/monash_tipr",TRUE,https://github.com/jimmyday12/monash_tipr,891,0,2022-03-23T22:17:23Z,NA
Mondrian,"The unique function of this package allows representing in a single graph the relative occurrence and co-occurrence of events measured in a sample. 
  As examples, the package was applied to describe the occurrence and co-occurrence of different species of bacterial or viral symbionts infecting arthropods at the individual level. The graphics allows determining the prevalence of each symbiont and the patterns of multiple infections (i.e. how different symbionts share or not the same individual hosts). 
  We named the package after the famous painter as the graphical output recalls Mondrian’s paintings.",2020-05-22,Aurélie Siberchicot,"https://github.com/aursiber/Mondrian ;
http://lbbe-shiny.univ-lyon1.fr/MondrianShiny/",TRUE,https://github.com/aursiber/mondrian,17245,1,2021-12-10T14:31:43Z,17245
mongolite,"High-performance MongoDB client based on 'mongo-c-driver' and 'jsonlite'.
    Includes support for aggregation, indexing, map-reduce, streaming, encryption,
    enterprise authentication, and GridFS. The online user manual provides an overview 
    of the available methods in the package: <https://jeroen.github.io/mongolite/>.",2022-06-14,Jeroen Ooms,"https://github.com/jeroen/mongolite/ (devel)
https://jeroen.github.io/mongolite/ (user manual)
http://mongoc.org/ (upstream)",TRUE,https://github.com/jeroen/mongolite,261361,271,2022-06-14T09:37:03Z,964.4317343173432
monobin,"Performs monotonic binning of numeric risk factor in credit rating models (PD, LGD, EAD) 
	development. All functions handle both binary and continuous target variable. 
	Functions that use isotonic regression in the first stage of binning process have an additional 
	feature for correction of minimum percentage of observations and minimum target rate per bin. 	
	Additionally, monotonic trend can be identified based on raw data or, if known in advance,
	forced by functions' argument. Missing values and other possible special values are treated 
	separately from so-called complete cases.",2022-04-18,Andrija Djurovic,https://github.com/andrija-djurovic/monobin,TRUE,https://github.com/andrija-djurovic/monobin,6830,4,2022-03-31T07:06:29Z,1707.5
monobinShiny,"This is an add-on package to the 'monobin' package that simplifies its use. It provides shiny-based user interface (UI) 
	     that is especially handy for less experienced 'R' users as well as for those who intend to perform quick scanning 
	     of numeric risk factors when building credit rating models. The additional functions implemented in 
	     'monobinShiny' that do no exist in 'monobin' package are: descriptive statistics, special case and outliers imputation. 
	     The function descriptive statistics is exported and can be used in 'R' sessions independently from the user interface, 
	     while special case and outlier imputation functions are written to be used with shiny UI.",2021-11-22,Andrija Djurovic,https://github.com/andrija-djurovic/monobinShiny,TRUE,https://github.com/andrija-djurovic/monobinshiny,3536,0,2021-12-02T08:03:12Z,NA
monochromeR,"Generate a monochrome palette from a starting colour 
    for a specified number of colours. The package can also be used to display 
    colour palettes in the plot window, with or without hex colour code labels.",2021-12-20,Cara Thompson,https://github.com/cararthompson/monochromeR,TRUE,https://github.com/cararthompson/monochromer,1755,9,2022-01-14T15:05:32Z,195
monotonicity,"Test for monotonicity in financial variables sorted by portfolios. It is conventional practice in empirical research to form portfolios of assets ranked by a certain sort variable. A t-test is then used to consider the mean return spread between the portfolios with the highest and lowest values of the sort variable. Yet comparing only the average returns on the top and bottom portfolios does not provide a sufficient way to test for a monotonic relation between expected returns and the sort variable. This package provides nonparametric tests for the full set of monotonic patterns by Patton, A. and Timmermann, A. (2010) <doi:10.1016/j.jfineco.2010.06.006> and compares the proposed results with extant alternatives such as t-tests, Bonferroni bounds, and multivariate inequality tests through empirical applications and simulations.",2019-12-05,Siegfried Köstlmeier,https://github.com/skoestlmeier/monotonicity,TRUE,https://github.com/skoestlmeier/monotonicity,12783,6,2021-12-27T11:38:25Z,2130.5
moodleR,"A collection of functions to connect to a 'Moodle' database, cache relevant tables locally and generate learning analytics. 
    'Moodle' is an open source Learning Management System (LMS) developed by MoodleHQ. For more information about Moodle, visit <https://moodle.org>.",2022-03-23,Aleksander Dietrichson,"https://github.com/chi2labs/moodleR,
https://chi2labs.github.io/moodleR/",TRUE,https://github.com/chi2labs/moodler,4794,3,2022-03-24T13:58:04Z,1598
moonBook,"Several analysis-related functions for the book entitled ""R
    statistics and graph for medical articles"" (written in Korean), version 1,
    by Keon-Woong Moon with Korean demographic data with several plot
    functions.",2022-01-05,Keon-Woong Moon,https://github.com/cardiomoon/moonBook,TRUE,https://github.com/cardiomoon/moonbook,128232,25,2022-01-07T04:10:36Z,5129.28
morphemepiece,"Tokenize text into morphemes. The morphemepiece algorithm uses a 
  lookup table to determine the morpheme breakdown of words, and falls back on a 
  modified wordpiece tokenization algorithm for words not found in the lookup 
  table.",2022-04-16,Jonathan Bratt,https://github.com/macmillancontentscience/morphemepiece,TRUE,https://github.com/macmillancontentscience/morphemepiece,4274,5,2022-04-15T21:02:22Z,854.8
morphemepiece.data,"Provides data about morphemes, the smallest units of meaning in a 
    language.",2022-04-18,Jonathan Bratt,https://github.com/macmillancontentscience/morphemepiece.data,TRUE,https://github.com/macmillancontentscience/morphemepiece.data,3740,0,2022-04-18T16:04:39Z,NA
Morpho,"A toolset for Geometric Morphometrics and mesh processing. This
    includes (among other stuff) mesh deformations based on reference points,
    permutation tests, detection of outliers, processing of sliding
    semi-landmarks and semi-automated surface landmark placement.",2021-09-09,Stefan Schlager,https://github.com/zarquon42b/Morpho,TRUE,https://github.com/zarquon42b/morpho,46288,38,2022-06-20T06:24:04Z,1218.1052631578948
MorphoTools2,"Tools for multivariate analyses of morphological data, wrapped in one package, to make the workflow convenient and fast. Statistical and graphical tools provide a comprehensive framework for checking and manipulating input data, statistical analyses, and visualization of results. Several methods are provided for the analysis of raw data, to make the dataset ready for downstream analyses. Integrated statistical methods include hierarchical classification, principal component analysis, principal coordinates analysis, non-metric multidimensional scaling, and multiple discriminant analyses: canonical, stepwise, and classificatory (linear, quadratic, and the non-parametric k nearest neighbours). The philosophy of the package will be described in Šlenker et al. (in prep).",2022-05-26,Marek Šlenker,https://github.com/MarekSlenker/MorphoTools2,TRUE,https://github.com/marekslenker/morphotools2,2757,2,2022-05-24T16:29:03Z,1378.5
MortalityLaws,"Fit the most popular human mortality 'laws', and construct 
  full and abridge life tables given various input indices. A mortality
  law is a parametric function that describes the dying-out process of 
  individuals in a population during a significant portion of their 
  life spans. For a comprehensive review of the most important mortality 
  laws see Tabeau (2001) <doi:10.1007/0-306-47562-6_1>. 
  Practical functions for downloading data from various human mortality 
  databases are provided as well.  ",2022-07-01,Marius D. Pascariu,https://github.com/mpascariu/MortalityLaws,TRUE,https://github.com/mpascariu/mortalitylaws,38559,20,2022-02-04T16:50:44Z,1927.95
mosaic,"Data sets and utilities from Project MOSAIC (<http://www.mosaic-web.org>) used
    to teach mathematics, statistics, computation and modeling.  Funded by the
    NSF, Project MOSAIC is a community of educators working to tie together
    aspects of quantitative work that students in science, technology,
    engineering and mathematics will need in their professional lives, but
    which are usually taught in isolation, if at all.",2021-01-18,Randall Pruim,"https://github.com/ProjectMOSAIC/mosaic,
https://www.mosaic-web.org/mosaic/",TRUE,https://github.com/projectmosaic/mosaic,631381,92,2022-02-28T20:21:39Z,6862.836956521739
MOSS,"High dimensionality, noise and heterogeneity among
    samples and features challenge the omic integration task. Here we
    present an omic integration method based on sparse singular value
    decomposition (SVD) to deal with these limitations, by: a. obtaining
    the main axes of variation of the combined omics, b. imposing sparsity
    constraints at both subjects (rows) and features (columns) levels
    using Elastic Net type of shrinkage, and c. allowing both linear and
    non-linear projections (via t-Stochastic Neighbor Embedding) of the
    omic data to detect clusters in very convoluted data
    (Gonzalez-Reymundez et. al, 2022) <doi:10.1093/bioinformatics/btac179>.",2022-03-25,Agustin Gonzalez-Reymundez,https://github.com/agugonrey/MOSS,TRUE,https://github.com/agugonrey/moss,12030,4,2022-03-25T14:29:15Z,3007.5
motif,"Describes spatial patterns of categorical raster data for 
    any defined regular and irregular areas. 
    Patterns are described quantitatively using built-in signatures 
    based on co-occurrence matrices but also allows for 
    any user-defined functions. 
    It enables spatial analysis such as search, change detection,
    and clustering to be performed on spatial patterns (Nowosad (2021) <doi:10.1007/s10980-020-01135-0>).",2022-06-07,Jakub Nowosad,https://jakubnowosad.com/motif/,TRUE,https://github.com/nowosad/motif,7730,49,2022-06-14T22:25:49Z,157.75510204081633
motifcluster,"
    Tools for spectral clustering of weighted directed networks using motif
    adjacency matrices. Methods perform well on large and sparse networks, and
    random sampling methods for generating weighted directed networks are also
    provided. Based on methodology detailed in Underwood, Elliott and Cucuringu
    (2020) <arXiv:2004.01293>.",2022-07-01,William George Underwood,https://github.com/wgunderwood/motifcluster,TRUE,https://github.com/wgunderwood/motifcluster,9543,12,2022-07-01T20:41:25Z,795.25
mountainplot,"Lattice functions for drawing folded empirical cumulative
    distribution plots, or mountain plots. A mountain plot is similar
    to an empirical CDF plot, except that the curve increases from
    0 to 0.5, then decreases from 0.5 to 1 using an inverted scale at
    the right side. See Monti (1995) <doi:10.1080/00031305.1995.10476179>.",2022-05-02,Kevin Wright,https://kwstat.github.io/mountainplot/,TRUE,https://github.com/kwstat/mountainplot,14889,1,2022-05-02T00:16:41Z,14889
mousetrap,"Mouse-tracking, the analysis of mouse movements in computerized
    experiments, is a method that is becoming increasingly popular in the
    cognitive sciences. The mousetrap package offers functions for importing,
    preprocessing, analyzing, aggregating, and visualizing mouse-tracking data.
    An introduction into mouse-tracking analyses using mousetrap can be found
    in Wulff, Kieslich, Henninger, Haslbeck, & Schulte-Mecklenbeck (2021)
    <doi:10.31234/osf.io/v685r> (preprint: <https://psyarxiv.com/v685r>).",2022-01-03,Pascal J. Kieslich,https://github.com/pascalkieslich/mousetrap,TRUE,https://github.com/pascalkieslich/mousetrap,29523,34,2022-01-03T16:50:27Z,868.3235294117648
moveHMM,"Provides tools for animal movement modelling using hidden Markov
    models. These include processing of tracking data, fitting hidden Markov models
    to movement data, visualization of data and fitted model, decoding of the state
    process...",2022-05-13,Theo Michelot,"https://github.com/TheoMichelot/moveHMM,
https://cran.r-project.org/package=moveHMM",TRUE,https://github.com/theomichelot/movehmm,25175,26,2022-05-20T09:54:42Z,968.2692307692307
mpath,"Algorithms compute robust estimators for loss functions in the concave convex (CC) family by the iteratively reweighted convex optimization (IRCO), an extension of the iteratively reweighted least squares (IRLS). The IRCO reduces the weight of the observation that leads to a large loss; it also provides weights to help identify outliers. Applications include robust (penalized) generalized linear models and robust support vector machines. The package also contains penalized Poisson, negative binomial, zero-inflated Poisson, zero-inflated negative binomial regression models and robust models with non-convex loss functions. Wang et al. (2014) <doi:10.1002/sim.6314>,
      Wang et al. (2015) <doi:10.1002/bimj.201400143>,
      Wang et al. (2016) <doi:10.1177/0962280214530608>,
      Wang (2021) <doi:10.1007/s11749-021-00770-2>,
      Wang (2020) <arXiv:2010.02848>.",2022-02-22,Zhu Wang,https://github.com/zhuwang46/mpath,TRUE,https://github.com/zhuwang46/mpath,43258,1,2022-02-16T15:51:35Z,43258
MPI,"Computing package for Multidimensional Poverty Index (MPI) using Alkire-Foster method. Given N individuals, each person has D indicators of deprivation, the package compute MPI value to represent the degree of poverty in a population. The inputs are 1) an N by D matrix, which has the element (i,j) represents whether an individual i is deprived in an indicator j (1 is deprived and 0 is not deprived), and 2) the deprivation threshold.  The main output is the MPI value, which has the range between zero and one. MPI value is approaching one if almost all people are deprived in all indicators, and it is approaching zero if almost no people are deprived in any indicator.  Please see Alkire S., Chatterjee, M., Conconi, A., Seth, S. and Ana Vaz (2014) <doi:10.35648/20.500.12413/11781/ii039> for The Alkire-Foster methodology.",2022-04-05,Kittiya Kukiattikun,https://github.com/9POINTEIGHT/MPI,TRUE,https://github.com/9pointeight/mpi,807,2,2022-04-01T13:50:24Z,403.5
mplot,"Model stability and variable inclusion plots [Mueller and Welsh
    (2010, <doi:10.1111/j.1751-5823.2010.00108.x>); Murray, Heritier and Mueller
    (2013, <doi:10.1002/sim.5855>)] as well as the adaptive fence [Jiang et al.
    (2008, <doi:10.1214/07-AOS517>); Jiang et al. 
    (2009, <doi:10.1016/j.spl.2008.10.014>)] for linear and generalised linear models.",2021-07-10,Garth Tarr,"https://garthtarr.github.io/mplot/,
https://github.com/garthtarr/mplot",TRUE,https://github.com/garthtarr/mplot,189514,10,2021-07-10T10:36:39Z,18951.4
MplusAutomation,"Leverages the R language to automate latent variable model estimation
	and interpretation using 'Mplus', a powerful latent variable modeling program
	developed by Muthen and Muthen (<https://www.statmodel.com>). Specifically, this package
    provides routines for creating related groups of models, running batches of
    models, and extracting and tabulating model parameters and fit statistics.",2022-04-06,Michael Hallquist,https://michaelhallquist.github.io/MplusAutomation/,TRUE,https://github.com/michaelhallquist/mplusautomation,101576,72,2022-06-27T13:13:25Z,1410.7777777777778
mpoly,Symbolic computing with multivariate polynomials in R.,2020-02-20,David Kahle,https://github.com/dkahle/mpoly,TRUE,https://github.com/dkahle/mpoly,41716,9,2022-05-05T03:00:32Z,4635.111111111111
mrbayes,"Bayesian estimation of inverse variance weighted (IVW), Burgess 
    et al. (2013) <doi:10.1002/gepi.21758>, and MR-Egger, Bowden et 
    al. (2015) <doi:10.1093/ije/dyv080>, summary data models for Mendelian 
    randomization analyses.",2021-10-02,Okezie Uche-Ikonne,https://github.com/okezie94/mrbayes,TRUE,https://github.com/okezie94/mrbayes,14578,2,2021-10-08T12:22:23Z,7289
mrds,"Animal abundance estimation via conventional, multiple covariate
    and mark-recapture distance sampling (CDS/MCDS/MRDS). Detection function
    fitting is performed via maximum likelihood. Also included are diagnostics
    and plotting for fitted detection functions. Abundance estimation is via a
    Horvitz-Thompson-like estimator.",2022-03-17,Jeff Laake,https://github.com/DistanceDevelopment/mrds/,TRUE,https://github.com/distancedevelopment/mrds,44909,2,2022-06-23T20:11:22Z,22454.5
mreg,"Implements the methods described in Bond S, Farewell V, 2006, Exact Likelihood Estimation for a Negative Binomial Regression Model with Missing Outcomes, Biometrics.",2022-04-11,Simon Bond,https://github.com/shug0131/mreg,TRUE,https://github.com/shug0131/mreg,17711,0,2022-04-11T15:18:04Z,NA
mregions,"Tools to get marine regions data from
    <https://www.marineregions.org/>. Includes tools to get region metadata,
    as well as data in 'GeoJSON' format, as well as Shape files. Use cases
    include using data downstream to visualize 'geospatial' data by marine
    region, mapping variation among different regions, and more.",2022-04-11,Salvador Fernandez,"https://docs.ropensci.org/mregions/,
https://github.com/ropensci/mregions",TRUE,https://github.com/ropensci/mregions,16377,14,2022-04-26T14:12:49Z,1169.7857142857142
mrf,"Forecasting of univariate time series using feature extraction with variable prediction methods is provided. Feature extraction is done with a redundant Haar wavelet transform with filter h = (0.5, 0.5). The advantage of the approach compared to typical Fourier based methods is an dynamic adaptation to varying seasonalities. Currently implemented prediction methods based on the selected wavelets levels and scales are a regression and a multi-layer perceptron. Forecasts can be computed for horizon 1 or higher. Model selection is performed with an evolutionary optimization. Selection criteria are currently the AIC criterion, the Mean Absolute Error or the Mean Root Error. The data is split into three parts for model selection: Training, test, and evaluation dataset. The training data is for computing the weights of a parameter set. The test data is for choosing the best parameter set. The evaluation data is for assessing the forecast performance of the best parameter set on new data unknown to the model. This work is published in Stier, Q.; Gehlert, T.; Thrun, M.C. Multiresolution Forecasting for Industrial Applications. Processes 2021, 9, 1697. <doi:10.3390/pr9101697>.",2022-02-23,Quirin Stier,https://www.deepbionics.org,TRUE,https://github.com/quirinms/mrfr,4051,2,2021-09-23T09:16:02Z,2025.5
mrf2d,"Model fitting, sampling and visualization
    for the (Hidden) Markov Random Field model with pairwise interactions and 
    general interaction structure from 
    Freguglia, Garcia & Bicas (2020) <doi:10.1002/env.2613>,
    which has many popular models used in 2-dimensional lattices
    as particular cases, like the Ising Model and Potts Model.
    A complete manuscript describing the package is available in
    Freguglia & Garcia (2022) <doi:10.18637/jss.v101.i08>.",2022-01-25,Victor Freguglia,https://github.com/Freguglia/mrf2d,TRUE,https://github.com/freguglia/mrf2d,14620,6,2022-01-27T17:58:08Z,2436.6666666666665
MRFcov,"Approximate node interaction parameters of Markov Random Fields 
    graphical networks. Models can incorporate additional covariates, allowing users to estimate
    how interactions between nodes in the graph are predicted to change across
    covariate gradients. The general methods implemented in this package are described 
    in Clark et al. (2018) <doi:10.1002/ecy.2221>.",2021-03-18,Nicholas J Clark,https://github.com/nicholasjclark/MRFcov,TRUE,https://github.com/nicholasjclark/mrfcov,13665,21,2022-06-20T02:51:37Z,650.7142857142857
mrgsim.parallel,"Simulation from an 'mrgsolve' 
    <https://cran.r-project.org/package=mrgsolve> model using a parallel backend.  
    Input data sets are split (chunked) and simulated in parallel using 
    mclapply() or future_lapply() 
    <https://cran.r-project.org/package=future.apply>.",2022-03-17,Kyle Baron,https://github.com/kylebaron/mrgsim.parallel,TRUE,https://github.com/kylebaron/mrgsim.parallel,7539,5,2022-03-17T17:56:03Z,1507.8
mrgsim.sa,"Perform sensitivity analysis on ordinary differential equation 
    based models, including ad-hoc graphical analyses based on structured 
    sequences of parameters as well as local sensitivity analysis. Functions 
    are provided for creating inputs, simulating scenarios and plotting outputs.",2020-11-30,Kyle Baron,https://github.com/kylebaron/mrgsim.sa,TRUE,https://github.com/kylebaron/mrgsim.sa,6081,4,2022-04-10T03:26:11Z,1520.25
mrgsolve,"Fast simulation from ordinary differential equation
    (ODE) based models typically employed in quantitative pharmacology and
    systems biology.",2022-05-16,Kyle T Baron,https://github.com/metrumresearchgroup/mrgsolve,TRUE,https://github.com/metrumresearchgroup/mrgsolve,34497,90,2022-05-20T02:40:08Z,383.3
msaenet,"Multi-step adaptive elastic-net (MSAENet) algorithm for
    feature selection in high-dimensional regressions proposed in
    Xiao and Xu (2015) <DOI:10.1080/00949655.2015.1016944>,
    with support for multi-step adaptive MCP-net (MSAMNet) and
    multi-step adaptive SCAD-net (MSASNet) methods.",2019-05-17,Nan Xiao,"https://nanx.me/msaenet/, https://github.com/nanxstats/msaenet",TRUE,https://github.com/nanxstats/msaenet,25911,12,2021-12-18T23:30:58Z,2159.25
msaeOB,"Implements multivariate optimum benchmarking small area estimation. This package provides optimum benchmarking estimation for univariate and multivariate small area estimation and its MSE. In fact, MSE estimators for optimum benchmark are not readily available, so resampling method that called parametric bootstrap is applied. The optimum benchmark model and parametric bootstrap in this package are based on the model proposed in small area estimation. J.N.K Rao and Isabel Molina (2015, ISBN: 978-1-118-73578-7). ",2022-03-14,Muhammad Yasqi Imanda,https://github.com/yas-q/msaeOB,TRUE,https://github.com/yas-q/msaeob,935,0,2022-06-18T07:09:30Z,NA
MSbox,"Common mass spectrometry tools described in John Roboz (2013) <doi:10.1201/b15436>. It allows checking element
 isotopes, calculating (isotope labelled) exact monoisitopic mass, m/z values and mass accuracy, and inspecting possible contaminant mass peaks,
 examining possible adducts in electrospray ionization (ESI) and matrix-assisted laser desorption ionization (MALDI)
 ion sources. ",2022-02-24,Yonghui Dong,https://github.com/YonghuiDong/MSbox,TRUE,https://github.com/yonghuidong/msbox,18295,0,2022-03-31T19:12:57Z,NA
mschart,"Create native charts for 'Microsoft PowerPoint' and 'Microsoft Word' documents. 
 These can then be edited and annotated. Functions are provided to let users create charts, modify 
 and format their content. The chart's underlying data is automatically saved within the 
 'Word' document or 'PowerPoint' presentation. It extends package 'officer' that does 
 not contain any feature for 'Microsoft' native charts production. ",2021-09-02,David Gohel,"https://ardata-fr.github.io/officeverse/,
https://ardata-fr.github.io/mschart/",TRUE,https://github.com/ardata-fr/mschart,25389,114,2021-09-02T12:05:18Z,222.71052631578948
mscstts,"R Client for the Microsoft Cognitive Services 
  'Text-to-Speech' REST API, including voice synthesis. A valid account 
  must be registered at the Microsoft Cognitive Services website 
  <https://azure.microsoft.com/services/cognitive-services/> in order to 
  obtain a (free) API key. Without an API key, this package will not 
  work properly.",2022-06-10,John Muschelli,https://github.com/muschellij2/mscstts,TRUE,https://github.com/muschellij2/mscstts,27330,8,2022-06-10T12:33:17Z,3416.25
MSEtool,"Development, simulation testing, and implementation of management procedures for fisheries 
    (see Carruthers & Hordyk (2018) <doi:10.1111/2041-210X.13081>).",2022-06-07,Adrian Hordyk,NA,TRUE,https://github.com/blue-matter/msetool,24813,5,2022-07-06T17:12:20Z,4962.6
MSG,A companion to the Chinese book ``Modern Statistical Graphics''.,2021-07-21,Yihui Xie,https://github.com/yihui/MSG,TRUE,https://github.com/yihui/msg,21690,34,2021-08-15T17:14:36Z,637.9411764705883
MSGARCH,"Fit (by Maximum Likelihood or MCMC/Bayesian), simulate, and forecast various Markov-Switching GARCH models as described in Ardia et al. (2019) <doi:10.18637/jss.v091.i04>.",2022-01-16,David Ardia,https://github.com/keblu/MSGARCH,TRUE,https://github.com/keblu/msgarch,28761,62,2022-01-17T04:47:27Z,463.88709677419354
msigdbr,"Provides the 'Molecular Signatures Database' (MSigDB) gene
    sets typically used with the 'Gene Set Enrichment Analysis' (GSEA)
    software (Subramanian et al. 2005 <doi:10.1073/pnas.0506580102>,
    Liberzon et al. 2015 <doi:10.1016/j.cels.2015.12.004>) in a standard R
    data frame with key-value pairs. The package includes the human genes
    as listed in MSigDB as well as the corresponding symbols and IDs for
    frequently studied model organisms such as mouse, rat, pig, fly, and
    yeast.",2022-03-30,Igor Dolgalev,https://igordot.github.io/msigdbr/,TRUE,https://github.com/igordot/msigdbr,100238,50,2022-03-30T13:39:50Z,2004.76
mskcc.oncotree,"Programmatic access to 'OncoTree' API
    <http://oncotree.mskcc.org/>. Get access to tumor main types, identifiers
    and utility routines to map across to other tumor classification systems.",2022-04-21,Ramiro Magno,https://maialab.org/mskcc.oncotree/,TRUE,https://github.com/maialab/mskcc.oncotree,528,0,2022-04-21T19:28:01Z,NA
msm,"Functions for fitting continuous-time Markov and hidden
    Markov multi-state models to longitudinal data.  Designed for
    processes observed at arbitrary times in continuous time (panel data)
    but some other observation schemes are supported. Both Markov
    transition rates and the hidden Markov output process can be modelled
    in terms of covariates, which may be constant or piecewise-constant
    in time.",2021-09-27,Christopher Jackson,https://github.com/chjackson/msm,TRUE,https://github.com/chjackson/msm,426951,36,2022-05-05T18:27:28Z,11859.75
mssm,"Provides methods to perform parameter estimation and 
  make analysis of multivariate observed outcomes through time which depends 
  on a latent state variable. All methods scale well in the dimension 
  of the observed outcomes at each time point. The package contains an 
  implementation of a Laplace approximation, particle filters like 
  suggested by Lin, Zhang, Cheng, & Chen (2005)
  <doi:10.1198/016214505000000349>, and the gradient and observed information
  matrix approximation suggested by Poyiadjis, Doucet, & Singh (2011) 
  <doi:10.1093/biomet/asq062>.",2022-01-31,Benjamin Christoffersen,https://github.com/boennecd/mssm,TRUE,https://github.com/boennecd/mssm,16131,3,2022-01-28T14:34:06Z,5377
msSPChelpR,"A collection of helper functions for analyzing Second Primary Cancer data, 
    including functions to reshape data, to calculate patient states and analyze cancer incidence.",2022-06-10,Marian Eberl,https://marianschmidt.github.io/msSPChelpR/,TRUE,https://github.com/marianschmidt/msspchelpr,7090,1,2022-07-08T23:50:46Z,7090
mstate,"Contains functions for data preparation, descriptives, hazard estimation and prediction with Aalen-Johansen or simulation in competing risks and multi-state models, see Putter, Fiocco, Geskus (2007) <doi:10.1002/sim.2712>.",2021-11-08,Hein Putter,https://www.lumc.nl/org/bds/research/medische-statistiek/survival-analysis/,TRUE,https://github.com/hputter/mstate,176308,3,2022-01-12T11:57:41Z,58769.333333333336
mStats,"This is a tool for epidemiologist, medical data analyst, 
    medical or public health professionals. It contains three domains of functions:
    1) data management, 2) statistical analysis and 3) calculating 
    epidemiological measures.",2020-11-23,Myo Minn Oo,https://myominnoo.github.io/,TRUE,https://github.com/myominnoo/mstats,14023,1,2022-02-25T00:53:55Z,14023
mt,"Functions for metabolomics data analysis: data preprocessing, 
  orthogonal signal correction, PCA analysis, PCA-DA analysis, 
	PLS-DA analysis, classification, feature selection, correlation 
	analysis, data visualisation and re-sampling strategies.",2022-02-01,Wanchang Lin,https://github.com/wanchanglin/mt,TRUE,https://github.com/wanchanglin/mt,2373,0,2022-02-01T17:47:09Z,NA
MTA,Build multiscalar territorial analysis based on various contexts.,2022-06-03,Timothée Giraud,https://github.com/riatelab/MTA/,TRUE,https://github.com/riatelab/mta,16767,7,2022-06-03T08:43:07Z,2395.285714285714
mtb,"
    The purpose of this package is to share a collection of functions the author wrote during weekends for managing
    kitchen and garden tasks, e.g. making plant growth charts or Thanksgiving kitchen schedule charts, etc. 
    Functions might include but not limited to:
    (1) aiding summarizing time related data; 
    (2) generating axis transformation from data; and
    (3) aiding Markdown (with html output) and Shiny file editing.",2022-02-05,Y Hsu,https://github.com/yh202109/mtb,TRUE,https://github.com/yh202109/mtb,2746,0,2022-02-04T23:58:48Z,NA
MTE,"Several robust estimators for linear regression and variable selection are provided. 
              Included are Maximum tangent likelihood estimator (Qin, et al., 2017), 
              least absolute deviance estimator and Huber regression. The penalized version of each of these 
              estimator incorporates L1 penalty function, i.e., LASSO and Adaptive Lasso. They are able to 
              produce consistent estimates for both fixed and high-dimensional settings. ",2022-03-22,Shaobo Li,GitHub: https://github.com/shaobo-li/MTE,TRUE,https://github.com/shaobo-li/mte,11735,0,2022-03-20T07:46:09Z,NA
MuChPoint,"Nonparametric approach to estimate the location of block boundaries (change-points) of 
    non-overlapping blocks in a random symmetric matrix which consists of random variables whose 
    distribution changes from block to block.
    BRAULT Vincent, OUADAH Sarah, SANSONNET Laure and LEVY-LEDUC Celine (2017) <doi:10.1016/j.jmva.2017.12.005>.",2022-04-08,Brault Vincent,https://github.com/Lionning/MuChPoint,TRUE,https://github.com/lionning/muchpoint,11712,0,2022-04-08T15:04:25Z,NA
mully,"Allows the user to create graph with multiple layers. The user can also modify the layers, the nodes, and the edges. The graph can also be visualized.
    Zaynab Hammoud and Frank Kramer (2018) <doi:10.3390/genes9110519>.
    More about multilayered graphs and their usage can be found in our review paper:
    Zaynab Hammoud and Frank Kramer (2020) <doi:10.1186/s41044-020-00046-0>.",2021-10-14,Zaynab Hammoud,https://github.com/frankkramer-lab/mully,TRUE,https://github.com/frankkramer-lab/mully,8313,34,2021-10-14T15:11:57Z,244.5
multgee,"GEE solver for correlated nominal or ordinal multinomial responses
    using a local odds ratios parameterization.",2021-05-13,Anestis Touloumis,https://github.com/AnestisTouloumis/multgee,TRUE,https://github.com/anestistouloumis/multgee,57098,7,2021-10-07T16:04:11Z,8156.857142857143
multiActionButton,"Provides a multi action button for usage in 'shiny'
    applications.",2022-06-22,Stéphane Laurent,https://github.com/stla/multiActionButton,TRUE,https://github.com/stla/multiactionbutton,173,2,2022-06-20T11:12:09Z,86.5
multiblock,"Functions and datasets to support Smilde, Næs and Liland (2021, ISBN: 978-1-119-60096-1) 
   ""Multiblock Data Fusion in Statistics and Machine Learning - Applications in the Natural and Life Sciences"". 
   This implements and imports a large collection of methods for multiblock data analysis with common interfaces, result- and plotting 
   functions, several real data sets and six vignettes covering a range different applications.",2022-06-07,Kristian Hovde Liland,"https://khliland.github.io/multiblock/,
https://github.com/khliland/multiblock/",TRUE,https://github.com/khliland/multiblock,3627,3,2022-06-07T20:39:49Z,1209
multibridge,"Evaluate hypotheses concerning the distribution of multinomial
  proportions using bridge sampling. The bridge sampling routine is able to
  compute Bayes factors for hypotheses that entail inequality constraints,
  equality constraints, free parameters, and mixtures of all three. These
  hypotheses are tested against the encompassing hypothesis, that all parameters
  vary freely or against the null hypothesis that all category proportions are equal.
  For more information see Sarafoglou et al. (2020) <doi:10.31234/osf.io/bux7p>.",2021-02-23,Alexandra Sarafoglou,https://github.com/asarafoglou/multibridge/,TRUE,https://github.com/asarafoglou/multibridge,5618,0,2022-06-29T18:38:50Z,NA
multicolor,Add multiple colors to text that is printed to the console.,2021-11-04,Amanda Dobbyn,https://github.com/aedobbyn/multicolor/,TRUE,https://github.com/aedobbyn/multicolor,17032,60,2021-11-04T16:36:29Z,283.8666666666667
multid,"Estimation of multivariate differences between two groups (e.g., multivariate sex differences) with regularized regression methods and predictive approach. See Lönnqvist & Ilmarinen (2021) <doi:10.1007/s11109-021-09681-2> and Ilmarinen et al. (2022) <doi:10.1177/08902070221088155>.
    Includes tools that help in understanding difference score reliability, predictions of difference score variables, conditional intra-class correlations, and heterogeneity of variance estimates. Package development was supported by the Academy of Finland research grant 338891.",2022-06-08,Ville-Juhani Ilmarinen,NA,TRUE,https://github.com/vjilmari/multid,3621,0,2022-06-15T07:08:10Z,NA
multidplyr,"Partition a data frame across multiple worker
    processes to provide simple multicore parallelism.",2021-12-01,Hadley Wickham,"https://multidplyr.tidyverse.org,
https://github.com/tidyverse/multidplyr",TRUE,https://github.com/tidyverse/multidplyr,16736,606,2022-03-01T20:55:46Z,27.617161716171616
multifear,"A suite of functions for performing analyses, based on a multiverse approach, for conditioning data. Specifically, given the appropriate data, the functions are able to perform t-tests, analyses of variance, and mixed models for the provided data and return summary statistics and plots. The function is also able to return for all those tests p-values, confidence intervals, and Bayes factors. The methods are described in Lonsdorf, Gerlicher, Klingelhofer-Jens, & Krypotos <doi:10.31234/osf.io/2z6pd>.",2021-06-01,Angelos-Miltiadis Krypotos,https://github.com/AngelosPsy/multifear,TRUE,https://github.com/angelospsy/multifear,5212,1,2022-02-01T16:45:37Z,5212
multifunc,"Methods for the analysis of how ecological drivers affect the
    multifunctionality of an ecosystem based on methods of Byrnes et al. 
    2016 <doi:10.1111/2041-210X.12143> and Byrnes et al. 
    2022 <doi:10.1101/2022.03.17.484802>. Most standard
    methods in the literature are implemented (see vignettes) in a tidy
    format.",2022-05-25,Jarrett Byrnes,"https://jebyrnes.github.io/multifunc/,
https://github.com/jebyrnes/multifunc",TRUE,https://github.com/jebyrnes/multifunc,407,14,2022-05-23T15:37:01Z,29.071428571428573
multigraph,"Functions to plot and manipulate multigraphs, signed and valued graphs, bipartite graphs, multilevel graphs, and Cayley graphs with various layout options. ",2022-07-07,Antonio Rivero Ostoic,https://github.com/mplex/multigraph/,TRUE,https://github.com/mplex/multigraph,17784,18,2022-07-08T07:49:59Z,988
multigraphr,"Methods and models for analysing multigraphs as introduced by Shafie (2015) <doi:10.21307/joss-2019-011>, including methods to study local and global properties <doi:10.1080/0022250X.2016.1219732> and goodness of fit tests.",2021-09-16,Termeh Shafie,https://github.com/termehs/multigraphr,TRUE,https://github.com/termehs/multigraphr,3105,10,2022-03-15T13:58:51Z,310.5
multilateral,"A flexible, efficient implementation of multilateral price index calculations.
             Includes common methods focused on time product dummy regression and GEKS variations.
             Allows for extension of the methods through automatic window splicing.
             See Krsinich (2016) <doi: 10.1515/jos-2016-0021>.",2022-04-20,Matthew Stansfield,https://github.com/MjStansfi/multilateral,TRUE,https://github.com/mjstansfi/multilateral,619,0,2022-04-20T21:44:59Z,NA
multilevelmod,"Bindings for hierarchical regression models for use with the
    'parsnip' package. Models include longitudinal generalized linear
    models (Liang and Zeger, 1986) <doi:10.1093/biomet/73.1.13>, and
    mixed-effect models (Pinheiro and Bates)
    <doi:10.1007/978-1-4419-0318-1_1>.",2022-06-17,Max Kuhn,"https://github.com/tidymodels/multilevelmod,
http://multilevelmod.tidymodels.org/",TRUE,https://github.com/tidymodels/multilevelmod,2061,58,2022-06-17T12:14:17Z,35.53448275862069
multilinguer,"Provides install functions of other languages 
             such as 'java', 'python' for Windows and MacOS.
             (Trying to Others.)",2022-03-09,Chanyub Park,https://github.com/mrchypark/multilinguer,TRUE,https://github.com/mrchypark/multilinguer,106786,7,2022-01-19T13:55:46Z,15255.142857142857
multimorbidity,"Identifying comorbidities, frailty, and multimorbidity in claims 
    and administrative data is often a duplicative process.
    The functions contained in this package are meant to first prepare the data to a format
    acceptable by all other packages, then provide a uniform and simple approach to
    generate comorbidity and multimorbidity metrics based on these claims data. The package
    is ever evolving to include new metrics, and is always looking for new measures to include.
    The citations used in this package include the following publications: 
    Anne Elixhauser, Claudia Steiner, D. Robert Harris, Rosanna M. Coffey (1998) <doi:10.1097/00005650-199801000-00004>,
    Brian J Moore, Susan White, Raynard Washington, et al. (2017) <doi:10.1097/MLR.0000000000000735>,
    Mary E. Charlson, Peter Pompei, Kathy L. Ales, C. Ronald MacKenzie (1987) <doi:10.1016/0021-9681(87)90171-8>,
    Richard A. Deyo, Daniel C. Cherkin, Marcia A. Ciol (1992) <doi:10.1016/0895-4356(92)90133-8>,
    Hude Quan, Vijaya Sundararajan, Patricia Halfon, et al. (2005) <doi:10.1097/01.mlr.0000182534.19832.83>,
    Dae Hyun Kim, Sebastian Schneeweiss, Robert J Glynn, et al. (2018) <doi:10.1093/gerona/glx229>,
    Melissa Y Wei, David Ratz, Kenneth J Mukamal (2020) <doi:10.1111/jgs.16310>,
    Kathryn Nicholson, Amanda L. Terry, Martin Fortin, et al. (2015) <doi:10.15256/joc.2015.5.61>,
    Martin Fortin, José Almirall, and Kathryn Nicholson (2017)<doi:10.15256/joc.2017.7.122>.",2021-08-20,Wyatt Bensken,https://github.com/WYATTBENSKEN/multimorbidity,TRUE,https://github.com/wyattbensken/multimorbidity,3413,1,2022-03-23T17:02:37Z,3413
multinma,"Network meta-analysis and network meta-regression models for 
    aggregate data, individual patient data, and mixtures of both individual 
    and aggregate data using multilevel network meta-regression as described by
    Phillippo et al. (2020) <doi:10.1111/rssa.12579>. Models are estimated in a
    Bayesian framework using 'Stan'.",2022-03-02,David M. Phillippo,"https://dmphillippo.github.io/multinma/,
https://github.com/dmphillippo/multinma",TRUE,https://github.com/dmphillippo/multinma,11894,14,2022-05-31T16:47:17Z,849.5714285714286
multinomineq,"
    Implements Gibbs sampling and Bayes factors for multinomial models with
    linear inequality constraints on the vector of probability parameters. As
    special cases, the model class includes models that predict a linear order 
    of binomial probabilities (e.g., p[1] < p[2] < p[3] < .50) and mixture models 
    assuming that the parameter vector p must be inside the convex hull of a 
    finite number of predicted patterns (i.e., vertices). A formal definition of 
    inequality-constrained multinomial models and the implemented computational
    methods is provided in: Heck, D.W., & Davis-Stober, C.P. (2019). 
    Multinomial models with linear inequality constraints: Overview and improvements 
    of computational methods for Bayesian inference. Journal of Mathematical 
    Psychology, 91, 70-87. <doi:10.1016/j.jmp.2019.03.004>.
    Inequality-constrained multinomial models have applications in the area of 
    judgment and decision making to fit and test random utility models  
    (Regenwetter, M., Dana, J., & Davis-Stober, C.P. (2011). Transitivity of 
    preferences. Psychological Review, 118, 42–56, <doi:10.1037/a0021150>) or to 
    perform outcome-based strategy classification to select the decision strategy 
    that provides the best account for a vector of observed choice frequencies 
    (Heck, D.W., Hilbig, B.E., & Moshagen, M. (2017). From information 
    processing to decisions: Formalizing and comparing probabilistic choice models. 
    Cognitive Psychology, 96, 26–40. <doi:10.1016/j.cogpsych.2017.05.003>).",2022-02-28,Daniel W. Heck,https://github.com/danheck/multinomineq,TRUE,https://github.com/danheck/multinomineq,10925,2,2022-04-25T21:57:46Z,5462.5
multIntTestFunc,"Provides implementations of functions that can be used to test multivariate integration routines. The package covers five different integration domains (unit hypercube, unit ball, unit sphere, standard simplex and R^n). For each domain several functions with different properties (smooth, non-differentiable, ...) are available. The functions are available in all dimensions n >= 1. For each function the exact value of the integral is known and implemented to allow testing the accuracy of multivariate integration routines. Details on the available test functions can be found at on the development website.",2021-10-05,Klaus Herrmann,https://github.com/KlausHerrmann/multIntTestFunc,TRUE,https://github.com/klausherrmann/multinttestfunc,2858,0,2021-10-30T02:32:53Z,NA
multiplex,"Algebraic procedures for the analysis of multiple social networks are delivered with this 
	    package as described in Ostoic (2020) <DOI:10.18637/jss.v092.i11>. Among other things, it 
	    makes it possible to create and manipulate multiplex, multimode, and multilevel network data 
	    with different formats. There are effective ways available to treat multiple networks with 
	    routines that combine algebraic systems like the partially ordered semigroup or the semiring 
	    structure with the relational bundles occurring in different types of multivariate network 
	    data sets. It also provides an algebraic approach for affiliation networks through Galois 
	    derivations between families of the pairs of subsets in the two domains.",2022-06-30,Antonio Rivero Ostoic,https://github.com/mplex/multiplex/,TRUE,https://github.com/mplex/multiplex,36928,18,2022-07-06T18:08:45Z,2051.5555555555557
multivator,A multivariate generalization of the emulator package.,2021-10-11,Robin K. S. Hankin,https://github.com/RobinHankin/multivator,TRUE,https://github.com/robinhankin/multivator,15023,0,2021-10-11T00:18:49Z,NA
multiverse,"Implement 'multiverse' style analyses (Steegen S., Tuerlinckx F, Gelman A., Vanpaemal, W., 2016)
    <doi:10.1177/1745691616658637>, (Dragicevic P., Jansen Y., Sarma A., Kay M., Chevalier F., 2019) <doi:10.1145/3290605.3300295> 
    to show the robustness of statistical inference. 'Multiverse analysis' is a philosophy of 
    statistical reporting where paper authors report the outcomes of many different statistical 
    analyses in order to show how fragile or robust their findings are. 
    The 'multiverse' package (Sarma A., Kale A., Moon M., Taback N., Chevalier F., Hullman J., Kay M., 2021) <doi:10.31219/osf.io/yfbwm>
    allows users to concisely and flexibly implement 'multiverse-style' 
    analysis, which involve declaring alternate ways of performing an analysis step, in R and R Notebooks.",2022-07-04,Abhraneel Sarma,"https://mucollective.github.io/multiverse/,
https://github.com/mucollective/multiverse/",TRUE,https://github.com/mucollective/multiverse,4573,21,2022-07-02T18:05:05Z,217.76190476190476
MulvariateRandomForestVarImp,"Calculates two sets of post-hoc variable importance measures for multivariate random forests. The first set of variable importance measures are given by the sum of mean split improvements for splits defined by feature j measured on user-defined examples (i.e., training or testing samples). The second set of importance measures are calculated on a per-outcome variable basis as the sum of mean absolute difference of node values for each split defined by feature j measured on user-defined examples (i.e., training or testing samples). The user can optionally threshold both sets of importance measures to include only splits that are statistically significant as measured using an F-test. ",2021-12-15,Dogonadze Nika,https://github.com/Megatvini/VIM/,TRUE,https://github.com/megatvini/vim,1950,0,2021-12-14T13:04:46Z,NA
musclesyneRgies,"Provides a framework to factorise electromyography (EMG) data.
    Tools are provided for raw data pre-processing, non negative matrix factorisation,
    classification of factorised data and plotting of obtained outcomes.
    In particular, reading from ASCII files is supported, along with wide-used
    filtering approaches to process EMG data. All steps include one or more sensible
    defaults that aim at simplifying the workflow. Yet, all functions are largely
    tunable at need. Example data sets are included.",2022-02-10,Alessandro Santuz,https://github.com/alesantuz/musclesyneRgies,TRUE,https://github.com/alesantuz/musclesynergies,995,16,2022-06-30T06:05:02Z,62.1875
music,"An aid for learning and using music theory. You can build chords, scales, and chord progressions using 12-note equal temperament tuning (12-ET) or user-defined tuning. Includes functions to visualize notes on a piano using ASCII plots in the console and to plot waveforms using base graphics. It allows simple playback of notes and chords using the 'audio' package.",2019-04-20,Efstathios D. Gennatas,https://github.com/egenn/music,TRUE,https://github.com/egenn/music,12531,34,2022-07-10T10:20:19Z,368.55882352941177
mutualinf,"The Mutual Information Index (M) introduced to social science literature by
    Theil and Finizza (1971) <doi:10.1080/0022250X.1971.9989795> is a multigroup
    segregation measure that is highly decomposable and that according to Frankel
    and Volij (2011) <doi:10.1016/j.jet.2010.10.008> and Mora and Ruiz-Castillo
    (2011) <doi:10.1111/j.1467-9531.2011.01237.x> satisfies the Strong Unit
    Decomposability and Strong Group Decomposability properties. This package allows
    computing and decomposing the total index value into its ""between"" and
    ""within"" terms. These last terms can also be decomposed into their
    contributions, either by group or unit characteristics. The factors that produce
    each ""within"" term can also be displayed at the user's request. The results can
    be computed considering a variable or sets of variables that define separate
    clusters.",2021-10-28,Rafael Fuentealba-Chaura,https://github.com/RafaelFuentealbaC/mutualinf,TRUE,https://github.com/rafaelfuentealbac/mutualinf,4545,1,2021-10-28T17:53:03Z,4545
mverse,"Extends 'multiverse' package
    (Sarma A., Kale A., Moon M., Taback N., Chevalier F., Hullman J., Kay M., 2021)
    <doi:10.31219/osf.io/yfbwm>, which allows users perform to create explorable
    multiverse analysis in R. This extension provides an additional level of
    abstraction to the 'multiverse' package with the aim of creating
    user friendly syntax to researchers, educators, and students in statistics.
    The 'mverse' syntax is designed to allow piping and takes hints from
    the 'tidyverse' grammar. The package allows users to define and inspect
    multiverse analysis using familiar syntax in R.",2022-05-23,Michael Jongho Moon,"https://github.com/mverseanalysis/mverse/,
https://mverseanalysis.github.io/mverse/",TRUE,https://github.com/mverseanalysis/mverse,372,5,2022-05-20T13:46:03Z,74.4
mvgb,"Generates multivariate subgaussian stable probabilities using the QRSVN
    algorithm as detailed in Genz and Bretz (2002) <DOI:10.1198/106186002394>
    but by sampling positive stable variates not chi/sqrt(nu).",2022-06-22,Alan Genz,https://github.com/swihart/mvgb,TRUE,https://github.com/swihart/mvgb,1532,0,2022-06-22T16:22:34Z,NA
mvGPS,"
    Methods for estimating and utilizing the multivariate generalized
    propensity score (mvGPS) for multiple continuous exposures described in
    Williams, J.R, and Crespi, C.M. (2020) <arxiv:2008.13767>. The methods allow
    estimation of a dose-response surface relating the joint distribution of multiple
    continuous exposure variables to an outcome. Weights are constructed assuming a
    multivariate normal density for the marginal and conditional distribution of
    exposures given a set of confounders. Confounders can be different for different
    exposure variables. The weights are designed to achieve balance across all
    exposure dimensions and can be used to estimate dose-response surfaces.",2021-12-07,Justin Williams,https://github.com/williazo/mvGPS,TRUE,https://github.com/williazo/mvgps,8641,10,2021-12-08T00:56:35Z,864.1
mvMonitoring,"Use multi-state splitting to apply Adaptive-Dynamic PCA (ADPCA) to
    data generated from a continuous-time multivariate industrial or natural
    process. Employ PCA-based dimension reduction to extract linear combinations
    of relevant features, reducing computational burdens. For a description of 
    ADPCA, see <doi:10.1007/s00477-016-1246-2>, the 2016 paper from Kazor et al.
    The multi-state application of ADPCA is from a manuscript under current
    revision entitled ""Multi-State Multivariate Statistical Process Control"" by
    Odom, Newhart, Cath, and Hering, and is  expected to appear in Q1 of 2018.",2022-05-06,Gabriel Odom,https://github.com/gabrielodom/mvMonitoring,TRUE,https://github.com/gabrielodom/mvmonitoring,13913,3,2022-04-29T01:39:57Z,4637.666666666667
mvMORPH,"Fits multivariate (Brownian Motion, Early Burst, ACDC, Ornstein-Uhlenbeck and Shifts) models of continuous traits evolution on trees and time series. 'mvMORPH' also proposes high-dimensional multivariate comparative tools (linear models using Generalized Least Squares and multivariate tests) based on penalized likelihood.  See
    Clavel et al. (2015) <DOI:10.1111/2041-210X.12420>, Clavel et al. (2019) <DOI:10.1093/sysbio/syy045>, and Clavel & Morlon (2020) <DOI:10.1093/sysbio/syaa010>.",2022-05-09,Julien Clavel,https://github.com/JClavel/mvMORPH,TRUE,https://github.com/jclavel/mvmorph,33046,14,2022-05-10T10:23:35Z,2360.4285714285716
mvnimpute,"Implementing a multiple imputation algorithm for multivariate data with missing and censored values under a coarsening at random assumption (Heitjan and Rubin, 1991<doi:10.1214/aos/1176348396>). The multiple imputation algorithm is based on the data augmentation algorithm proposed by Tanner and Wong (1987)<doi:10.1080/01621459.1987.10478458>. The Gibbs sampling algorithm is adopted to to update the model parameters and draw imputations of the coarse data.",2022-07-06,Hesen Li,https://github.com/hli226/mvnimpute,TRUE,https://github.com/hli226/mvnimpute,172,0,2022-07-05T19:41:18Z,NA
mvnpermute,"Given a vector of multivariate normal data, a matrix of
    covariates and the data covariance matrix, generate new multivariate normal
    samples that have the same covariance matrix based on permutations of
    the transformed data residuals.",2022-04-21,Mark Abney,https://github.com/markabney/MVNpermute,TRUE,https://github.com/markabney/mvnpermute,17073,0,2022-04-21T13:40:54Z,NA
mvp,"Fast manipulation of symbolic multivariate polynomials
  using the 'Map' class of the Standard Template Library.  The package
  uses print and coercion methods from the 'mpoly' package (Kahle 2013,
  ""Multivariate polynomials in R"".  The R Journal, 5(1):162), but offers
  speed improvements.  It is comparable in speed to the 'spray' package
  for sparse arrays, but retains the symbolic benefits of 'mpoly'.",2022-01-12,Robin K. S. Hankin,https://github.com/RobinHankin/mvp,TRUE,https://github.com/robinhankin/mvp,15976,5,2022-06-22T22:39:54Z,3195.2
mvpd,"Estimates multivariate subgaussian stable densities 
    and probabilities as well as generates random variates using product 
    distribution theory.  A function for estimating the parameters from 
    data to fit a distribution to data is also provided, using the 
    method from Nolan (2013) <DOI:10.1007/s00180-013-0396-7>.",2022-06-20,Bruce Swihart,https://github.com/swihart/mvpd,TRUE,https://github.com/swihart/mvpd,1155,0,2022-06-21T14:39:34Z,NA
mvrsquared,"Compute the coefficient of determination for outcomes in n-dimensions. 
  May be useful for multidimensional predictions (such as a multinomial model) or
  calculating goodness of fit from latent variable models such as probabilistic
  topic models like latent Dirichlet allocation or deterministic topic models 
  like latent semantic analysis. Based on Jones (2019) <arXiv:1911.11061>.",2022-06-01,Tommy Jones,https://github.com/TommyJones/mvrsquared,TRUE,https://github.com/tommyjones/mvrsquared,14154,0,2022-06-01T17:58:54Z,NA
mvtsplot,A function for plotting multivariate time series data.,2022-05-10,Roger D. Peng,https://github.com/rdpeng/mvtsplot,TRUE,https://github.com/rdpeng/mvtsplot,20868,15,2022-05-10T13:43:54Z,1391.2
mwcsr,"Algorithms for solving various Maximum
    Weight Connected Subgraph Problems, including variants with
    budget constraints, cardinality constraints, weighted edges and signals.
    The package represents an R interface to high-efficient solvers based on
    relax-and-cut approach (Álvarez-Miranda E., Sinnl M. (2017) <doi:10.1016/j.cor.2017.05.015>)
    mixed-integer programming (Loboda A., Artyomov M., and Sergushichev A. (2016) <doi:10.1007/978-3-319-43681-4_17>)
    and simulated annealing.",2021-12-19,Alexander Loboda,https://github.com/ctlab/mwcsr,TRUE,https://github.com/ctlab/mwcsr,2063,6,2022-05-08T19:15:12Z,343.8333333333333
mwTensor,"For single tensor data, any matrix factorization method can be specified the matricised tensor in each dimension by Multi-way Component Analysis (MWCA). An originally extended MWCA is also implemented to specify and decompose multiple matrices and tensors simultaneously (CoupledMWCA). See the reference section of GitHub README.md <https://github.com/rikenbit/mwTensor>, for details of the methods.",2022-06-15,Koki Tsuyuzaki,https://github.com/rikenbit/mwTensor,TRUE,https://github.com/rikenbit/mwtensor,2930,0,2022-06-15T01:20:07Z,NA
myTAI,Investigate the evolution of biological processes by capturing evolutionary signatures in transcriptomes (Drost et al. (2017) <doi:10.1093/bioinformatics/btx835>). The aim of this tool is to provide a transcriptome analysis environment to quantify the average evolutionary age of genes contributing to a transcriptome of interest (Drost et al. (2016) <doi:10.1101/051565>).,2021-02-24,Hajk-Georg Drost,https://github.com/drostlab/myTAI,TRUE,https://github.com/drostlab/mytai,21258,26,2022-03-24T14:41:05Z,817.6153846153846
N2H4,"Provides some functions to get Korean text sample from news articles in
             Naver which is popular news portal service <https://news.naver.com/> in Korea.",2022-05-10,Chanyub Park,https://github.com/forkonlp/N2H4,TRUE,https://github.com/forkonlp/n2h4,12911,195,2022-05-09T09:19:17Z,66.2102564102564
N2R,"Implements methods to perform fast approximate K-nearest neighbor search on input matrix. Algorithm based on the 'N2' implementation of an approximate nearest neighbor search using hierarchical  Navigable Small World (NSW) graphs. The original algorithm is described in ""Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs"", Y. Malkov and D. Yashunin, <doi:10.1109/TPAMI.2018.2889473>, <arXiv:1603.09320>.",2022-01-18,Evan Biederstedt,https://github.com/kharchenkolab/N2R,TRUE,https://github.com/kharchenkolab/n2r,13275,6,2022-01-18T02:29:04Z,2212.5
"NACHO","NanoString nCounter data are gene expression assays
    where there is no need for the use of enzymes or amplification
    protocols and work with fluorescent barcodes (Geiss et al. (2018)
    <doi:10.1038/nbt1385>). Each barcode is assigned a
    messenger-RNA/micro-RNA (mRNA/miRNA) which after bonding with its
    target can be counted. As a result each count of a specific barcode
    represents the presence of its target mRNA/miRNA. 'NACHO' (NAnoString
    quality Control dasHbOard) is able to analyse the exported NanoString
    nCounter data and facilitates the user in performing a quality
    control. 'NACHO' does this by visualising quality control metrics,
    expression of control genes, principal components and sample specific
    size factors in an interactive web application.",2022-05-31,Mickaël Canouil,"https://github.com/mcanouil/NACHO/, https://m.canouil.fr/NACHO/",TRUE,https://github.com/mcanouil/nacho,14795,5,2022-05-31T09:13:42Z,2959
"NADA2","Contains methods described by Dennis Helsel in 
             his book ""Statistics for Censored Environmental Data
             using Minitab and R"" (2011) and courses and videos at 
             <https://practicalstats.com>. This package adds new functions to 
             the `NADA` Package.",2022-04-19,Paul Julian,https://github.com/SwampThingPaul/NADA2,TRUE,https://github.com/swampthingpaul/nada2,7045,6,2022-06-29T11:06:32Z,1174.1666666666667
naflex,"For use in summary functions to omit missing values 
    conditionally using specified checks.",2022-01-26,Danny Parsons,https://github.com/dannyparsons/naflex,TRUE,https://github.com/dannyparsons/naflex,1484,0,2022-01-27T09:35:40Z,NA
naijR,"A set of convenience functions as well as geographical/political
  data about Nigeria, aimed at simplifying work with data and information that
  are specific to the country.",2022-01-28,Victor Ordu,https://brovic.github.io/naijR/,TRUE,https://github.com/brovic/naijr,15575,4,2022-02-19T11:25:04Z,3893.75
nakagami,"Density, distribution function, quantile function and random 
    generation for the Nakagami distribution of Nakagami (1960) 
    <doi:10.1016/B978-0-08-009306-2.50005-4>.",2021-09-14,Jonas Moss,https://github.com/JonasMoss/nakagami,TRUE,https://github.com/jonasmoss/nakagami,52952,0,2021-09-14T07:35:47Z,NA
namedropR,"Provides 'visual citations' containing the metadata of a scientific paper and a 'QR' code.
    A 'visual citation' is a banner containing title, authors, journal and year of a publication.
    This package can create such banners based on 'BibTeX' and 'BibLaTeX' references
    and includes a QR code pointing to the 'DOI'.
    The resulting HTML object or PNG image can be included in a presentation to point the audience to good resources for further reading.
    Styling is possible via predefined designs or via custom 'CSS'.
    This package is not intended as replacement for proper reference manager packages, 
    but a tool to enrich scientific presentation slides.",2022-05-18,Christian A. Gebhard,https://github.com/nucleic-acid/namedropR,TRUE,https://github.com/nucleic-acid/namedropr,3473,36,2022-06-14T05:08:37Z,96.47222222222223
nandb,"Calculation of molecular number and brightness from
    fluorescence microscopy image series. The software was published in a
    2016 paper <doi:10.1093/bioinformatics/btx434>. The seminal paper for
    the technique is Digman et al. 2008 <doi:10.1529/biophysj.107.114645>.
    A review of the technique was published in 2017
    <doi:10.1016/j.ymeth.2017.12.001>.",2021-05-16,Rory Nolan,"https://rorynolan.github.io/nandb/,
https://github.com/rorynolan/nandb",TRUE,https://github.com/rorynolan/nandb,18022,2,2021-07-13T01:54:42Z,9011
naniar,"Missing values are ubiquitous in data and need to be explored and
    handled in the initial stages of analysis. 'naniar' provides data structures 
    and functions that facilitate the plotting of missing values and examination 
    of imputations. This allows missing data dependencies to be explored with 
    minimal deviation from the common work patterns of 'ggplot2' and tidy data. 
    The work is fully discussed at Tierney & Cook (2018) <arXiv:1809.02264>.",2021-05-14,Nicholas Tierney,https://github.com/njtierney/naniar,TRUE,https://github.com/njtierney/naniar,725083,598,2022-06-30T00:51:31Z,1212.5133779264213
nanonext,"R binding for NNG (Nanomsg Next Gen), a successor to ZeroMQ. NNG is 
    a socket library providing high-performance scalability protocols,
    implementing a cross-platform standard for messaging and communications.
    Serves as a concurrency framework for building distributed applications,
    utilising 'Aio' objects which automatically resolve upon completion of
    asynchronous operations.",2022-07-07,Charlie Gao,"https://shikokuchuo.net/nanonext/,
https://github.com/shikokuchuo/nanonext/",TRUE,https://github.com/shikokuchuo/nanonext,3080,21,2022-07-07T07:06:59Z,146.66666666666666
nanostringr,"Provides quality control (QC), normalization, and
    batch effect correction operations for 'NanoString nCounter' data,
    Talhouk et al. (2016) <doi:10.1371/journal.pone.0153844>.  Various
    metrics are used to determine which samples passed or failed QC.  Gene
    expression should first be normalized to housekeeping genes, before a
    reference-based approach is used to adjust for batch effects.  Raw
    NanoString data can be imported in the form of Reporter Code Count
    (RCC) files.",2022-05-24,Derek Chiu,"https://github.com/TalhoukLab/nanostringr/,
https://talhouklab.github.io/nanostringr/",TRUE,https://github.com/talhouklab/nanostringr,14234,5,2022-05-30T18:17:41Z,2846.8
nanotime,"Full 64-bit resolution date and time functionality with
 nanosecond granularity is provided, with easy transition to and from
 the standard 'POSIXct' type. Three additional classes offer interval,
 period and duration functionality for nanosecond-resolution timestamps.",2022-03-06,Dirk Eddelbuettel and Leonardo Silvestri,"https://github.com/eddelbuettel/nanotime,
https://eddelbuettel.github.io/nanotime/,
https://dirk.eddelbuettel.com/code/nanotime.html",TRUE,https://github.com/eddelbuettel/nanotime,289605,45,2022-03-06T17:57:11Z,6435.666666666667
narray,"Stacking arrays according to dimension names, subset-aware
    splitting and mapping of functions, intersecting along arbitrary
    dimensions, converting to and from data.frames, and many other helper
    functions.",2021-05-10,Michael Schubert,https://github.com/mschubert/narray,TRUE,https://github.com/mschubert/narray,37842,22,2022-02-17T18:40:10Z,1720.090909090909
nasapower,"Client for 'NASA' 'POWER' global meteorology, surface solar
    energy and climatology data 'API'.  'POWER' (Prediction Of Worldwide Energy 
    Resource) data are freely available for download with varying spatial
    resolutions dependent on the original data and with several temporal
    resolutions depending on the POWER parameter and community.  This work is
    funded through the 'NASA' Earth Science Directorate Applied Science Program.
    For more on the data themselves, the methodologies used in creating, a web-
    based data viewer and web access, please see <https://power.larc.nasa.gov/>.",2022-04-10,Adam H. Sparks,https://docs.ropensci.org/nasapower/,TRUE,https://github.com/ropensci/nasapower,30044,81,2022-04-10T02:04:36Z,370.91358024691357
NasdaqDataLink,"Functions for interacting directly with the Nasdaq Data Link API to offer data in a number of formats usable in R, downloading a zip with all data from a Nasdaq Data Link database, and the ability to search. This R package uses the Nasdaq Data Link API. For more information go to <https://docs.data.nasdaq.com/>. For more help on the package itself go to <https://data.nasdaq.com/tools/r>.",2022-06-22,Jamie Couture,https://github.com/nasdaq/data-link-r,TRUE,https://github.com/nasdaq/data-link-r,171,0,2022-06-20T18:17:08Z,NA
nat,"NeuroAnatomy Toolbox (nat) enables analysis and visualisation of 3D
    biological image data, especially traced neurons. Reads and writes 3D images
    in NRRD and 'Amira' AmiraMesh formats and reads surfaces in 'Amira' hxsurf
    format. Traced neurons can be imported from and written to SWC and 'Amira'
    LineSet and SkeletonGraph formats. These data can then be visualised in 3D
    via 'rgl', manipulated including applying calculated registrations, e.g.
    using the 'CMTK' registration suite, and analysed. There is also a simple
    representation for neurons that have been subjected to 3D skeletonisation
    but not formally traced; this allows morphological comparison between
    neurons including searches and clustering (via the 'nat.nblast' extension
    package).",2022-04-06,Gregory Jefferis,"https://github.com/natverse/nat, https://natverse.org/",TRUE,https://github.com/natverse/nat,30013,57,2022-05-20T18:21:20Z,526.5438596491229
natcpp,"Fast functions implemented in C++ via 'Rcpp' to support the
    'NeuroAnatomy Toolbox' ('nat') ecosystem. These functions provide large
    speed-ups for basic manipulation of neuronal skeletons over pure R
    functions found in the 'nat' package. The expectation is that end
    users will not use this package directly, but instead the 'nat'
    package will automatically use routines from this package when it is
    available to enable large performance gains.",2021-07-13,Gregory Jefferis,https://github.com/natverse/natcpp,TRUE,https://github.com/natverse/natcpp,3699,0,2022-01-05T17:50:21Z,NA
natstrat,"Natural strata can be used in observational studies to balance
    the distributions of many covariates across any number of treatment
    groups and any number of comparisons. These strata have proportional 
    amounts of units within each stratum across the treatments, allowing 
    for simple interpretation and aggregation across strata. Within each 
    stratum, the units are chosen using randomized rounding of a linear 
    program that balances many covariates.
    To solve the linear program, the 'Gurobi' commercial optimization software 
    is recommended, but not required. The 'gurobi' R package can be installed following the instructions 
    at <https://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html>.",2021-10-15,Katherine Brumberg,"https://github.com/kkbrum/natstrat,
https://kkbrum.github.io/natstrat/,
https://www.gurobi.com/documentation/9.1/refman/ins_the_r_package.html",TRUE,https://github.com/kkbrum/natstrat,4043,0,2022-01-27T15:57:35Z,NA
naturaList,"Classify occurrence records based on confidence
    levels of species identification. In addition, implement tools to filter
    occurrences inside grid cells and to manually check for possibles errors with 
	an interactive shiny application.",2022-04-20,Arthur Vinicius Rodrigues,https://github.com/avrodrigues/naturaList,TRUE,https://github.com/avrodrigues/naturalist,3946,0,2022-05-03T19:26:16Z,NA
NatureSounds,Collection of example animal sounds for bioacoustic analysis.,2021-04-23,Marcelo Araya-Salas,https://github.com/maRce10/NatureSounds,TRUE,https://github.com/marce10/naturesounds,22239,1,2022-07-01T17:01:36Z,22239
navigatr,"Provides a navigation menu to enable pipe-friendly data processing for hierarchical data structures.
    By activating the menu items, you can perform operations on each item while maintaining the overall structure in attributes.",2022-05-14,Mizuki Uchida,"https://github.com/UchidaMizuki/navigatr,
https://uchidamizuki.github.io/navigatr/",TRUE,https://github.com/uchidamizuki/navigatr,1846,1,2022-05-22T08:40:43Z,1846
nberwp,Catalogue of NBER working papers published between June 1973 and December 2021.,2022-03-27,Benjamin Davies,https://github.com/bldavies/nberwp,TRUE,https://github.com/bldavies/nberwp,4373,20,2022-03-27T04:13:50Z,218.65
nbfar,"We developed a negative binomial factor regression model to estimate structured (sparse) associations between a feature matrix X and overdispersed count data Y.  With 'nbfar', microbiome count data Y can be used, for example, to associate host or environmental covariates with microbial abundances. Currently, two models are available: a) Negative Binomial reduced rank regression (NB-RRR), b) Negative Binomial co-sparse factor regression (NB-FAR). Please refer the manuscript 'Mishra, A. K., & Müller, C. L. (2021). Negative Binomial factor regression with application to microbiome data analysis. bioRxiv.' for more details. ",2022-02-22,Aditya Mishra,"https://github.com/amishra-stats/nbfar,
https://www.biorxiv.org/content/10.1101/2021.11.29.470304v1",TRUE,https://github.com/amishra-stats/nbfar,1073,4,2022-04-07T14:50:05Z,268.25
ncdf4.helpers,"Contains a collection of helper functions for dealing with 
    'NetCDF' files <https://www.unidata.ucar.edu/software/netcdf/> 
    opened using 'ncdf4', particularly 'NetCDF' files that conform to the
    Climate and Forecast (CF) Metadata Conventions 
    <http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html>.",2021-10-15,"David Bronaugh <bronaugh@uvic.ca> for the Pacific Climate Impacts
    Consortium",https://www.r-project.org,TRUE,https://github.com/pacificclimate/ncdf4.helpers,37707,4,2022-06-09T15:37:15Z,9426.75
ncf,"Spatial (cross-)covariance and related geostatistical tools: the
        nonparametric (cross-)covariance function , the spline correlogram, the
        nonparametric phase coherence function, local indicators of spatial 
        association (LISA), (Mantel) correlogram, (Partial) Mantel test.",2022-05-07,Ottar N. Bjornstad,https://ento.psu.edu/directory/onb1,TRUE,https://github.com/objornstad/ncf,44438,3,2022-05-28T01:22:10Z,14812.666666666666
nCov2019,"Provides easy-to-use programming API to access real time and historical data of 'COVID'-19 cases, vaccine and therapeutics data, and a Shiny app to help users exploring the data.  Fetching data using API provided by <https://disease.sh> . ",2021-06-10,Guangchuang Yu,https://github.com/YuLab-SMU/nCov2019,TRUE,https://github.com/yulab-smu/ncov2019,8740,11,2021-12-13T16:08:51Z,794.5454545454545
ncvreg,"Fits regularization paths for linear regression, GLM, and Cox
  regression models using lasso or nonconvex penalties, in particular the
  minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD)
  penalty, with options for additional L2 penalties (the ""elastic net"" idea).
  Utilities for carrying out cross-validation as well as post-fitting
  visualization, summarization, inference, and prediction are also provided.
  For more information, see Breheny and Huang (2011) <doi:10.1214/10-AOAS388>
  or visit the ncvreg homepage <https://pbreheny.github.io/ncvreg/>.",2021-03-30,Patrick Breheny,"https://pbreheny.github.io/ncvreg/,
https://github.com/pbreheny/ncvreg",TRUE,https://github.com/pbreheny/ncvreg,110583,28,2022-07-07T15:08:33Z,3949.3928571428573
ndtv,"Renders dynamic network data from 'networkDynamic' objects as movies, interactive animations, or other representations of changing relational structures and attributes.",2021-11-02,Skye Bender-deMoll,https://github.com/statnet/ndtv,TRUE,https://github.com/statnet/ndtv,52342,42,2021-10-30T22:44:47Z,1246.2380952380952
neatmaps,"Simplify the exploratory data analysis process for multiple network
             data sets with the help of hierarchical clustering, consensus 
             clustering and heatmaps. Multiple network data consists of multiple
             disjoint networks that have common variables (e.g. ego networks). 
             This package contains the necessary tools for exploring such data,
             from the data pre-processing stage to the creation of dynamic
             visualizations.",2019-05-12,Philippe Boileau,https://github.com/PhilBoileau/neatmaps,TRUE,https://github.com/philboileau/neatmaps,10758,1,2022-04-12T00:31:45Z,10758
neatRanges,"Collapse, partition, combine, fill gaps in and expand date/time ranges.",2020-03-29,Aljaz Jelenko,https://github.com/arg0naut91/neatRanges,TRUE,https://github.com/arg0naut91/neatranges,11581,3,2022-06-09T14:37:56Z,3860.3333333333335
neatStats,"User-friendly, clear and simple statistics, primarily for
  publication in psychological science. The main functions are wrappers for
  other packages, but there are various additions as well. Every relevant step
  from data aggregation to reportable printed statistics is covered for basic
  experimental designs.",2022-05-06,Gáspár Lukács,https://github.com/gasparl/neatstats,TRUE,https://github.com/gasparl/neatstats,13289,2,2022-07-07T08:07:31Z,6644.5
negenes,"Estimating the number of essential genes in a genome on
    the basis of data from a random transposon mutagenesis experiment,
    through the use of a Gibbs sampler.
    Lamichhane et al. (2003) <doi:10.1073/pnas.1231432100>.",2019-08-05,Karl W Broman,https://github.com/kbroman/negenes,TRUE,https://github.com/kbroman/negenes,15984,1,2021-10-29T21:39:38Z,15984
neo2R,"The aim of the neo2R is to provide simple and low level connectors
   for querying neo4j graph databases (<https://neo4j.com/>).
   The objects returned by the query functions are either lists or data.frames
   with very few post-processing.
   It allows fast processing of queries returning many records.
   And it let the user handle post-processing according to the data model
   and his needs.",2022-04-15,Patrice Godard,https://github.com/patzaw/neo2r,TRUE,https://github.com/patzaw/neo2r,9199,4,2022-04-15T08:04:38Z,2299.75
NEONiso,"Functions for downloading,
    calibrating, and analyzing atmospheric isotope data bundled
    into the eddy covariance data products of the National Ecological
    Observatory Network (NEON) <https://www.neonscience.org>. 
    In this version, calibration tools are provided for only the 
    carbon isotope products. Tools for calibrating water isotope 
    products are under development. More details are found in Fiorella et al. (2021)
    <doi:10.1029/2020JG005862>, and the readme 
    file at <https://github.com/SPATIAL-Lab/NEONiso>.",2022-01-03,Rich Fiorella,https://github.com/SPATIAL-Lab/NEONiso,TRUE,https://github.com/spatial-lab/neoniso,5838,0,2022-03-03T22:23:52Z,NA
neonUtilities,"NEON data packages can be accessed through the NEON Data Portal <https://www.neonscience.org>
    or through the NEON Data API (see <https://data.neonscience.org/data-api> for documentation). Data delivered from
    the Data Portal are provided as monthly zip files packaged within a parent zip file, while individual files
    can be accessed from the API. This package provides tools that aid in discovering, downloading, and reformatting 
    data prior to use in analyses. This includes downloading data via the API, merging data tables by type, and 
    converting formats. For more information, see the readme file at <https://github.com/NEONScience/NEON-utilities>.",2022-04-14,Claire Lunch,https://github.com/NEONScience/NEON-utilities,TRUE,https://github.com/neonscience/neon-utilities,35406,52,2022-06-30T22:52:23Z,680.8846153846154
neptune,"An interface to Neptune. A metadata store for MLOps, built for teams that run a lot of experiments.
    It gives you a single place to log, store, display, organize, compare, and query all your model-building metadata.
    Neptune is used for:
    • Experiment tracking: Log, display, organize, and compare ML experiments in a single place.
    • Model registry: Version, store, manage, and query trained models, and model building metadata.
    • Monitoring ML runs live: Record and monitor model training, evaluation, or production runs live
    For more information see <https://neptune.ai/>.",2022-04-13,Rafal Jankowski,https://github.com/neptune-ai/neptune-r,TRUE,https://github.com/neptune-ai/neptune-r,10386,8,2022-04-13T09:16:46Z,1298.25
nestfs,"Implementation of forward selection based on cross-validated
             linear and logistic regression.",2022-05-09,Marco Colombo,https://github.com/mcol/nestfs,TRUE,https://github.com/mcol/nestfs,13826,1,2022-05-04T16:26:48Z,13826
net4pg,"In shotgun proteomics, shared peptides (i.e., peptides that might 
    originate from different proteins sharing homology, from different 
    proteoforms due to alternative mRNA splicing, post-translational 
    modifications, proteolytic cleavages, and/or allelic variants) represent a
    major source of ambiguity in protein identifications. The 'net4pg' package 
    allows to assess and handle ambiguity of protein identifications. It 
    implements methods for two main applications. First, it allows to represent
    and quantify ambiguity of protein identifications by means of graph 
    connected components (CCs). In graph theory, CCs are defined as the largest
    subgraphs in which any two vertices are connected to each other by a path 
    and not connected to any other of the vertices in the supergraph. Here, 
    proteins sharing one or more peptides are thus gathered in the same CC 
    (multi-protein CC), while unambiguous protein identifications constitute CCs 
    with a single protein vertex (single-protein CCs). Therefore, the proportion
    of single-protein CCs and the size of multi-protein CCs can be used to
    measure the level of ambiguity of protein identifications. The package
    implements a strategy to efficiently calculate graph connected
    components on large datasets and allows to visually inspect them.
    Secondly, the 'net4pg' package allows to exploit the increasing
    availability of matched transcriptomic and proteomic datasets to
    reduce ambiguity of protein identifications. More precisely, it
    implement a transcriptome-based filtering strategy fundamentally
    consisting in the removal of those proteins whose corresponding
    transcript is not expressed in the sample-matched transcriptome. The
    underlying assumption is that, according to the central dogma of
    biology, there can be no proteins without the corresponding
    transcript. Most importantly, the package allows to visually inspect
    the effect of the filtering on protein identifications and quantify
    ambiguity before and after filtering by means of graph connected
    components. As such, it constitutes a reproducible and transparent
    method to exploit transcriptome information to enhance protein
    identifications. All methods implemented in the 'net4pg' package are fully 
    described in Fancello and Burger (2021) <doi:10.1101/2021.09.07.459229>.",2021-09-20,Laura Fancello,https://github.com/laurafancello/net4pg,TRUE,https://github.com/laurafancello/net4pg,3644,1,2022-06-29T13:30:56Z,3644
netCoin,"Create interactive analytic networks. It joins the data analysis power of R to obtain coincidences, co-occurrences and correlations, and the visualization libraries of 'JavaScript' in one package.",2021-10-28,Modesto Escobar,https://modesto-escobar.github.io/netCoin-2.x/,TRUE,https://github.com/modesto-escobar/netcoin-2.x,19982,1,2022-06-22T11:56:02Z,19982
NetCoupler,"The 'NetCoupler' algorithm identifies potential direct effects of 
    correlated, high-dimensional variables formed as a network with an external 
    variable. The external variable may act as the dependent/response variable 
    or as an independent/predictor variable to the network. ",2022-04-08,Luke Johnston,https://github.com/NetCoupler/NetCoupler,TRUE,https://github.com/netcoupler/netcoupler,666,4,2022-04-29T14:39:05Z,166.5
netgsa,"Carry out network-based gene set analysis by incorporating external information about interactions among genes, as well as novel interactions learned from data. Implements methods described in Shojaie A, Michailidis G (2010) <doi:10.1093/biomet/asq038>, Shojaie A, Michailidis G (2009) <doi:10.1089/cmb.2008.0081>, and Ma J, Shojaie A, Michailidis G (2016) <doi:10.1093/bioinformatics/btw410>.",2021-12-07,Michael Hellstern,https://github.com/mikehellstern/netgsa,TRUE,https://github.com/mikehellstern/netgsa,16554,3,2021-12-07T18:46:18Z,5518
NetLogoR,"Build and run spatially explicit
    agent-based models using only the R platform. 'NetLogoR' follows the same
    framework as the 'NetLogo' software
    (Wilensky, 1999 <http://ccl.northwestern.edu/netlogo/>) and is a translation
    in R of the structure and functions of 'NetLogo'.
    'NetLogoR' provides new R classes to define model agents and functions to
    implement spatially explicit agent-based models in the R environment.
    This package allows benefiting of the fast and easy coding phase from the
    highly developed 'NetLogo' framework, coupled with the versatility, power
    and massive resources of the R software.
    Examples of three models (Ants <http://ccl.northwestern.edu/netlogo/models/Ants>,
    Butterfly (Railsback and Grimm, 2012) and Wolf-Sheep-Predation
    <http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation>) written using
    'NetLogoR' are available. The 'NetLogo' code of the original version of these
    models is provided alongside.
    A programming guide inspired from the 'NetLogo' Programming Guide
    (<https://ccl.northwestern.edu/netlogo/docs/programming.html>) and a dictionary
    of 'NetLogo' primitives (<https://ccl.northwestern.edu/netlogo/docs/dictionary.html>)
    equivalences are also available.
    NOTE: To increment 'time', these functions can use a for loop or can be
    integrated with a discrete event simulator, such as 'SpaDES'
    (<https://cran.r-project.org/package=SpaDES>).
    The suggested package 'fastshp' can be installed with
    'install.packages(""fastshp"", repos = ""https://rforge.net"", type = ""source"")'.",2022-02-18,Sarah Bauduin,"https://netlogor.predictiveecology.org,
https://github.com/PredictiveEcology/NetLogoR/,
https://groups.google.com/g/netlogor",TRUE,https://github.com/predictiveecology/netlogor,15902,30,2022-02-17T19:00:25Z,530.0666666666667
netmap,Represent 'network' or 'igraph' objects whose vertices can be represented by features in an 'sf' object as a network graph surmising a 'sf' plot. Fits into 'ggplot2' grammar.,2022-03-18,Matteo Dimai,https://github.com/artod83/netmap,TRUE,https://github.com/artod83/netmap,1447,6,2022-03-18T14:55:22Z,241.16666666666666
NetOrigin,"Performs network-based source estimation. Different approaches are available: effective distance median (Manitz et al., 2014; <doi:10.1371/currents.outbreaks.f3fdeb08c5b9de7c09ed9cbcef5f01f2>), recursive backtracking (Manitz et al., 2016; <doi:10.1111/rssc.12176>), and centrality-based source estimation (Li et al., 2021; <doi:10.1371/journal.pcbi.1008545>). Additionally, we provide public transportation network data as well as methods for data preparation, source estimation performance analysis and visualization.",2022-01-20,Juliane Manitz,https://netorigin.manitz.org/,TRUE,https://github.com/jmanitz/netorigin,14366,0,2022-01-19T22:42:24Z,NA
netplot,"A graph visualization engine that puts an emphasis on 
  aesthetics at the same time of providing default parameters that yield
  out-of-the-box-nice visualizations. The package is built on top of
  'The Grid Graphics Package' and seamlessly work with 'igraph' and 
  'network' objects.",2021-06-16,George Vega Yon,https://github.com/USCCANA/netplot,TRUE,https://github.com/usccana/netplot,4441,45,2022-06-09T22:36:41Z,98.68888888888888
netrankr,"Implements methods for centrality related analyses of networks. 
    While the package includes the possibility to build more than 20 indices, 
    its main focus lies on index-free assessment of centrality via partial 
    rankings obtained by neighborhood-inclusion or positional dominance. These 
    partial rankings can be analyzed with different methods, including 
    probabilistic methods like computing expected node ranks and relative 
    rank probabilities (how likely is it that a node is more central than another?).
    The methodology is described in depth in the vignettes and in
    Schoch (2018) <doi:10.1016/j.socnet.2017.12.003>.",2021-12-21,David Schoch,https://github.com/schochastics/netrankr/,TRUE,https://github.com/schochastics/netrankr,69688,39,2022-07-06T05:34:45Z,1786.871794871795
nettskjemar,"Enables users to retrieve data, meta-data, and codebooks 
    from <https://nettskjema.no/>. The data from the API is richer than from the
    online data portal. Mowinckel (2021) <doi:10.5281/zenodo.4745481>.",2021-05-20,Athanasia Mo Mowinckel,"https://github.com/LCBC-UiO/nettskjemar,
https://zenodo.org/badge/latestdoi/206264675",TRUE,https://github.com/lcbc-uio/nettskjemar,4450,2,2021-10-31T08:20:31Z,2225
networkABC,"We developed an inference tool based on approximate Bayesian computation to decipher network data and assess the strength of the inferred links between network's actors. It is a new multi-level approximate Bayesian computation (ABC) approach. At the first level, the method captures the global properties of the network, such as scale-freeness and clustering coefficients, whereas the second level is targeted to capture local properties, including the probability of each couple of genes being linked. Up to now, Approximate Bayesian Computation (ABC) algorithms have been scarcely used in that setting and, due to the computational overhead, their application was limited to a small number of genes. On the contrary, our algorithm was made to cope with that issue and has low computational cost. It can be used, for instance, for elucidating gene regulatory network, which is an important step towards understanding the normal cell physiology and complex pathological phenotype. Reverse-engineering consists in using gene expressions over time or over different experimental conditions to discover the structure of the gene network in a targeted cellular process. The fact that gene expression data are usually noisy, highly correlated, and have high dimensionality explains the need for specific statistical methods to reverse engineer the underlying network. ",2021-03-20,Frederic Bertrand,"https://fbertran.github.io/networkABC/,
https://github.com/fbertran/networkABC/",TRUE,https://github.com/fbertran/networkabc,13261,3,2021-07-14T22:05:26Z,4420.333333333333
NetworkChange,Network changepoint analysis for undirected network data. The package implements a hidden Markov network change point model (Park and Sohn (2020)). Functions for break number detection using the approximate marginal likelihood and WAIC are also provided.,2022-03-04,Jong Hee Park,https://github.com/jongheepark/NetworkChange,TRUE,https://github.com/jongheepark/networkchange,18727,3,2022-03-04T00:55:04Z,6242.333333333333
networktools,"Includes assorted tools for network analysis. Bridge centrality; goldbricker; MDS, PCA, & eigenmodel network plotting.",2022-06-03,Payton Jones,https://CRAN.R-project.org/package=networktools,TRUE,https://github.com/paytonjjones/networktools,45296,11,2022-06-03T21:55:19Z,4117.818181818182
NeuralNetTools,"Visualization and analysis tools to aid in the interpretation of
    neural network models.  Functions are available for plotting,
    quantifying variable importance, conducting a sensitivity analysis, and
    obtaining a simple list of model weights.",2022-01-06,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/neuralnettools,154787,69,2022-01-07T13:27:37Z,2243.289855072464
NeuralSens,"Analysis functions to quantify inputs importance in neural network models.
  Functions are available for calculating and plotting the inputs importance and obtaining
  the activation function of each neuron layer and its derivatives. The importance of a given
  input is defined as the distribution of the derivatives of the output with respect to that
  input in each training data point <doi:10.18637/jss.v102.i07>.",2022-06-21,José Portela González,https://github.com/JaiPizGon/NeuralSens,TRUE,https://github.com/jaipizgon/neuralsens,17819,8,2022-07-08T12:57:55Z,2227.375
neurohcp,"Downloads and reads data from Human 'Connectome' Project 
    <https://db.humanconnectome.org> using Amazon Web Services ('AWS') 
    'S3' buckets.",2020-10-14,John Muschelli,https://db.humanconnectome.org,TRUE,https://github.com/muschellij2/neurohcp,16494,6,2021-09-13T14:41:10Z,2749
nevada,"A flexible statistical framework for network-valued data analysis. 
    It leverages the complexity of the space of distributions on graphs by using 
    the permutation framework for inference as implemented in the 'flipr' package. 
    Currently, only the two-sample testing problem is covered and generalization 
    to k samples and regression will be added in the future as well. It is a 
    4-step procedure where the user chooses a suitable representation of the 
    networks, a suitable metric to embed the representation into a metric space, 
    one or more test statistics to target specific aspects of the distributions 
    to be compared and a formula to compute the permutation p-value. Two types 
    of inference are provided: a global test answering whether there is a 
    difference between the distributions that generated the two samples and a 
    local test for localizing differences on the network structure. The latter 
    is assumed to be shared by all networks of both samples. References: Lovato, 
    I., Pini, A., Stamm, A., Vantini, S. (2020) ""Model-free two-sample test for 
    network-valued data"" <doi:10.1016/j.csda.2019.106896>; Lovato, I., Pini, A., 
    Stamm, A., Taquet, M., Vantini, S. (2021) ""Multiscale null hypothesis 
    testing for network-valued data: Analysis of brain networks of patients with 
    autism"" <doi:10.1111/rssc.12463>.",2021-09-25,Aymeric Stamm,"https://astamm.github.io/nevada/,
https://github.com/astamm/nevada/",TRUE,https://github.com/astamm/nevada,3142,2,2022-04-02T10:24:21Z,1571
neverhpfilter,"In the working paper titled ""Why You Should Never Use the Hodrick-Prescott 
   Filter"", James D. Hamilton proposes a new alternative to economic time series 
   filtering. The neverhpfilter package provides functions and data for reproducing his work. Hamilton (2017) <doi:10.3386/w23429>.",2021-06-18,Justin M. Shea,https://justinmshea.github.io/neverhpfilter/,TRUE,https://github.com/justinmshea/neverhpfilter,14954,11,2021-12-23T03:07:54Z,1359.4545454545455
newscatcheR,"Programmatically collect normalized news from
    (almost) any website. An 'R' clone of the
    <https://github.com/kotartemiy/newscatcher> 'Python' module.",2022-04-29,Novica Nakov,https://github.com/discindo/newscatcheR/,TRUE,https://github.com/discindo/newscatcher,9202,21,2022-05-02T07:20:01Z,438.1904761904762
newsmap,"Semissupervised model for geographical document classification (Watanabe 2018) <doi:10.1080/21670811.2017.1293487>. 
    This package currently contains seed dictionaries in English, German, French, Spanish, Italian, Russian, Hebrew, Arabic Japanese and Chinese (Simplified and Traditional).",2022-05-09,Kohei Watanabe,https://github.com/koheiw/newsmap,TRUE,https://github.com/koheiw/newsmap,26079,50,2022-05-09T07:06:27Z,521.58
newsmd,"Adding updates (version or bullet points) to the NEWS.md
    file.",2022-02-16,Jakob Gepp,https://github.com/Dschaykib/newsmd,TRUE,https://github.com/dschaykib/newsmd,5316,4,2022-02-16T08:19:37Z,1329
nfl4th,"A set of functions to estimate outcomes of fourth down
    plays in the National Football League and obtain fourth down plays
    from <https://www.nfl.com/> and <https://www.espn.com/>.",2021-10-16,Ben Baldwin,"https://www.nfl4th.com/, https://github.com/nflverse/nfl4th/",TRUE,https://github.com/nflverse/nfl4th,6138,9,2022-02-15T10:18:38Z,682
nflfastR,"A set of functions to access National Football
    League play-by-play data from <https://www.nfl.com/>.",2021-10-06,Ben Baldwin,"https://www.nflfastr.com/, https://github.com/nflverse/nflfastR",TRUE,https://github.com/nflverse/nflfastr,31885,263,2022-06-30T11:20:36Z,121.23574144486692
nflplotR,"A set of functions to visualize National Football League
    analysis in 'ggplot2'.",2022-04-06,Sebastian Carl,"https://nflplotr.nflverse.com,
https://github.com/nflverse/nflplotR",TRUE,https://github.com/nflverse/nflplotr,2543,7,2022-07-08T18:03:55Z,363.2857142857143
nflreadr,"A minimal package for downloading data from 'GitHub'
    repositories of the 'nflverse' project.",2022-03-17,Tan Ho,"https://nflreadr.nflverse.com,
https://github.com/nflverse/nflreadr",TRUE,https://github.com/nflverse/nflreadr,15268,23,2022-07-07T17:10:05Z,663.8260869565217
nflseedR,"A set of functions to simulate National Football
    League seasons including the sophisticated tie-breaking procedures.",2022-07-07,Sebastian Carl,"https://nflseedr.com, https://github.com/nflverse/nflseedR",TRUE,https://github.com/nflverse/nflseedr,13653,10,2022-07-07T09:55:50Z,1365.3
nflverse,"The 'nflverse' is a set of packages dedicated to data of the
    National Football League. This package is designed to make it easy to
    install and load multiple 'nflverse' packages in a single step. Learn
    more about the 'nflverse' at <https://nflverse.nflverse.com/>.",2022-07-07,Sebastian Carl,"https://nflverse.nflverse.com/,
https://github.com/nflverse/nflverse",TRUE,https://github.com/nflverse/nflverse,1982,7,2022-07-07T15:25:30Z,283.14285714285717
ngboostForecast,Probabilistic time series forecasting via Natural Gradient Boosting for Probabilistic Prediction.,2022-05-03,Resul Akay,https://github.com/Akai01/ngboostForecast,TRUE,https://github.com/akai01/ngboostforecast,1290,3,2022-05-03T07:55:44Z,430
NGLVieweR,"Provides an 'htmlwidgets' <https://www.htmlwidgets.org/> interface to 'NGL.js' <http://nglviewer.org/ngl/api/>.
    'NGLvieweR' can be used to visualize and interact with protein databank ('PDB') and structural files in R and Shiny applications.
    It includes a set of API functions to manipulate the viewer after creation in Shiny.",2021-06-01,Niels van der Velden,https://github.com/nvelden/NGLVieweR,TRUE,https://github.com/nvelden/nglviewer,4677,21,2021-10-28T15:01:05Z,222.71428571428572
ngram,"An n-gram is a sequence of n ""words"" taken, in order, from a
    body of text.  This is a collection of utilities for creating,
    displaying, summarizing, and ""babbling"" n-grams.  The
    'tokenization' and ""babbling"" are handled by very efficient C
    code, which can even be built as its own standalone library.
    The babbler is a simple Markov chain.  The package also offers
    a vignette with complete example 'workflows' and information about
    the utilities offered in the package.",2022-03-13,Drew Schmidt,https://github.com/wrathematics/ngram,TRUE,https://github.com/wrathematics/ngram,105431,65,2022-03-13T22:50:58Z,1622.0153846153846
ngramr,"Retrieve and plot word frequencies through time from the ""Google
    Ngram Viewer"" <https://books.google.com/ngrams>.",2022-01-08,Sean Carmody,https://github.com/seancarmody/ngramr,TRUE,https://github.com/seancarmody/ngramr,11837,40,2022-01-09T01:11:10Z,295.925
NGSSEML,"Due to a large quantity of non-Gaussian time series and reliability data, the R-package non-Gaussian state-space with exact marginal likelihood is useful for modeling and forecasting non-Gaussian time series and reliability data via non-Gaussian state-space models with the exact marginal likelihood easily, see Gamerman, Santos and Franco (2013) <doi:10.1111/jtsa.12039> and Santos, Gamerman and Franco (2017) <doi:10.1109/TR.2017.2670142>. The package gives codes for formulating and specifying the non-Gaussian state-space models in the R language. Inferences for the parameters of the model can be made under the classical and Bayesian. Furthermore, prediction, filtering, and smoothing procedures can be used to perform inferences for the latent parameters. Applications include, e.g., count, volatility, piecewise exponential, and software reliability data.",2021-09-02,Thiago Rezende dos Santos,https://github.com/hadht/NGSSEML-R-Package,TRUE,https://github.com/hadht/ngsseml-r-package,15972,0,2021-09-02T18:15:06Z,NA
nhanesA,"Utility to retrieve data from the National Health and Nutrition 
	Examination Survey (NHANES) website <https://www.cdc.gov/nchs/nhanes/index.htm>.",2022-06-01,Christopher J. Endres,https://cran.r-project.org/package=nhanesA,TRUE,https://github.com/cjendres1/nhanes,26794,12,2022-06-21T23:50:54Z,2232.8333333333335
nhdR,"Tools for working with the National Hydrography Dataset, with 
    functions for querying, downloading, and networking both the NHD 
    <https://www.usgs.gov/national-hydrography> 
    and NHDPlus <https://www.epa.gov/waterdata/nhdplus-national-hydrography-dataset-plus> datasets. ",2022-01-03,Jemma Stachelek,https://github.com/jsta/nhdR,TRUE,https://github.com/jsta/nhdr,16114,29,2022-05-26T23:56:25Z,555.6551724137931
nhsnumber,"Provides functions for working with NHS number checksums.
    The UK's National Health Service issues NHS numbers to all users of its
    services and this package implements functions for verifying that the
    numbers are valid according to the checksum scheme the NHS use.
    Numbers can be validated and checksums created.",2021-12-06,Mark Sellors,https://github.com/sellorm/nhsnumber,TRUE,https://github.com/sellorm/nhsnumber,6061,6,2021-12-29T13:03:53Z,1010.1666666666666
NHSRdatasets,"Free United Kingdom National Health Service (NHS) and other healthcare, or population health-related data for education and training purposes. This package contains synthetic data based on real healthcare datasets, or cuts of open-licenced official data.  This package exists to support skills development in the NHS-R community: <https://nhsrcommunity.com/>.",2021-03-14,Tom Jemmett,"https://github.com/nhs-r-community/NHSRdatasets,
https://nhs-r-community.github.io/NHSRdatasets/",TRUE,https://github.com/nhs-r-community/nhsrdatasets,15375,51,2022-06-23T16:18:11Z,301.47058823529414
nic,"Color palettes based on nature inspired colours in ""Sri Lanka"".",2022-01-27,Thiyanga S. Talagala,https://github.com/thiyangt/nic,TRUE,https://github.com/thiyangt/nic,1415,2,2022-01-26T01:14:20Z,707.5
NicheBarcoding,"Species Identification using DNA Barcodes Integrated with 
             Environmental Niche Models.",2021-12-21,Cai-qing YANG,https://github.com/Yangcq-Ivy/NicheBarcoding,TRUE,https://github.com/yangcq-ivy/nichebarcoding,1774,0,2021-12-17T01:56:15Z,NA
NIMAA,"Functions for nominal data mining based on bipartite graphs, which build a pipeline for analysis and missing values imputation. Methods are mainly from the paper: Jafari, Mohieddin, et al. (2021) <doi:10.1101/2021.03.18.436040>, some new ones are also included.",2022-04-11,Mohieddin Jafari,https://github.com/jafarilab/NIMAA,TRUE,https://github.com/jafarilab/nimaa,3556,3,2022-04-07T09:44:55Z,1185.3333333333333
nimble,"A system for writing hierarchical statistical models largely
    compatible with 'BUGS' and 'JAGS', writing nimbleFunctions to operate models
    and do basic R-style math, and compiling both models and nimbleFunctions via
    custom-generated C++. 'NIMBLE' includes default methods for MCMC, Monte Carlo
    Expectation Maximization, and some other tools. The nimbleFunction system makes
    it easy to do things like implement new MCMC samplers from R, customize the
    assignment of samplers to different parts of a model from R, and compile the
    new samplers automatically via C++ alongside the samplers 'NIMBLE' provides.
    'NIMBLE' extends the 'BUGS'/'JAGS' language by making it extensible: New
    distributions and functions can be added, including as calls to external
    compiled code. Although most people think of MCMC as the main goal of the
    'BUGS'/'JAGS' language for writing models, one can use 'NIMBLE' for writing
    arbitrary other kinds of model-generic algorithms as well. A full User Manual is
    available at <https://r-nimble.org>.",2022-02-24,Christopher Paciorek,"https://r-nimble.org, https://github.com/nimble-dev/nimble",TRUE,https://github.com/nimble-dev/nimble,84412,119,2022-06-26T06:00:07Z,709.344537815126
nimbleAPT,"Functions for adaptive parallel tempering (APT) with NIMBLE models. Adapted from 'Lacki' & 'Miasojedow' (2016) <DOI:10.1007/s11222-015-9579-0> and 'Miasojedow, Moulines and Vihola' (2013) <DOI:10.1080/10618600.2013.778779>.",2021-11-22,David Pleydell,https://github.com/DRJP/nimbleAPT,TRUE,https://github.com/drjp/nimbleapt,1934,0,2022-03-31T09:56:46Z,NA
nimbleEcology,"Common ecological distributions for 'nimble' models in the form of nimbleFunction objects. 
  Includes Cormack-Jolly-Seber, occupancy, dynamic occupancy, hidden Markov, dynamic hidden Markov, and N-mixture models.
  (Jolly (1965) <DOI: 10.2307/2333826>, Seber (1965) <DOI: 10.2307/2333827>, Turek et al. (2016) <doi:10.1007/s10651-016-0353-z>).",2021-11-01,Benjamin R. Goldstein,https://github.com/nimble-dev/nimbleEcology,TRUE,https://github.com/nimble-dev/nimbleecology,18186,14,2021-11-01T17:10:15Z,1299
nimbleNoBounds,"A collection of common univariate bounded probability distributions transformed to the unbounded real line, for the purpose of increased MCMC efficiency.",2022-05-25,David Pleydell,https://github.com/DRJP/nimbleNoBounds,TRUE,https://github.com/drjp/nimblenobounds,324,0,2022-05-25T12:12:47Z,NA
nimbleSMC,"Includes five particle filtering algorithms for use with state space
    models in the 'nimble' system: 'Auxiliary', 'Bootstrap', 'Ensemble Kalman filter',
    'Iterated Filtering 2', and 'Liu-West', as described in Michaud et al. (2021),
    <doi:10.18637/jss.v100.i03>. A full User Manual is available at
    <https://r-nimble.org>.     ",2021-12-09,Christopher Paciorek,"https://r-nimble.org, https://github.com/nimble-dev/nimbleSMC",TRUE,https://github.com/nimble-dev/nimblesmc,6718,0,2021-12-14T00:41:49Z,NA
nipals,Principal Components Analysis of a matrix using Non-linear Iterative Partial Least Squares or weighted Expectation Maximization PCA with Gram-Schmidt orthogonalization of the scores and loadings. Optimized for speed. See Andrecut (2009) <doi:10.1089/cmb.2008.0221>.,2021-09-15,Kevin Wright,https://kwstat.github.io/nipals/,TRUE,https://github.com/kwstat/nipals,24266,6,2021-09-16T02:25:09Z,4044.3333333333335
njtr1,"Download and analyze motor vehicle crash data released by the New Jersey Department of Transportation (NJDOT).
  The data in this package is collected through the filing of NJTR-1 form by police officers, which provide a standardized way of documenting a motor vehicle crash that occurred in New Jersey.
  3 different data tables containing data on crashes, vehicles & pedestrians released from 2001 to the present can be downloaded & cleaned using this package.",2022-04-28,Gavin Rozzi,"https://gavinrozzi.github.io/njtr1/,
https://github.com/gavinrozzi/njtr1/,
https://www.gavinrozzi.com/project/njtr1/",TRUE,https://github.com/gavinrozzi/njtr1,6959,4,2022-04-28T21:49:08Z,1739.75
nlaR,"Client for programmatic access to the 2007 and 2012 National 
  Lakes Assessment database <https://www.epa.gov/national-aquatic-resource-surveys/nla> 
  containing data for hundreds of lakes in the lower 48 states of the contiguous US.",2019-01-22,Joseph Stachelek,https://github.com/jsta/nlaR,TRUE,https://github.com/jsta/nlar,11931,3,2021-08-03T13:48:25Z,3977
nlist,"Create and manipulate numeric list ('nlist') objects.  An
    'nlist' is an S3 list of uniquely named numeric objects.  An numeric
    object is an integer or double vector, matrix or array.  An 'nlists'
    object is a S3 class list of 'nlist' objects with the same names,
    dimensionalities and typeofs.  Numeric list objects are of interest
    because they are the raw data inputs for analytic engines such as
    'JAGS', 'STAN' and 'TMB'.  Numeric lists objects, which are useful for
    storing multiple realizations of of simulated data sets, can be
    converted to coda::mcmc and coda::mcmc.list objects.",2021-09-02,Joe Thorley,https://github.com/poissonconsulting/nlist,TRUE,https://github.com/poissonconsulting/nlist,30519,5,2022-06-21T03:07:07Z,6103.8
nlmixr,"Fit and compare nonlinear mixed-effects models in differential
    equations with flexible dosing information commonly seen in pharmacokinetics
    and pharmacodynamics (Almquist, Leander, and Jirstrand 2015 
    <doi:10.1007/s10928-015-9409-1>). Differential equation solving is 
    by compiled C code provided in the 'RxODE' package
    (Wang, Hallow, and James 2015 <doi:10.1002/psp4.12052>).",2022-03-27,Rik Schoemaker,https://github.com/nlmixrdevelopment/nlmixr,TRUE,https://github.com/nlmixrdevelopment/nlmixr,24255,102,2022-03-26T03:20:19Z,237.7941176470588
nlmixr2,"Fit and compare nonlinear mixed-effects models in differential
    equations with flexible dosing information commonly seen in pharmacokinetics
    and pharmacodynamics (Almquist, Leander, and Jirstrand 2015 
    <doi:10.1007/s10928-015-9409-1>). Differential equation solving is 
    by compiled C code provided in the 'rxode2' package
    (Wang, Hallow, and James 2015 <doi:10.1002/psp4.12052>).",2022-06-27,Matthew Fidler,"https://nlmixr2.org/, https://github.com/nlmixr2/nlmixr2/",TRUE,https://github.com/nlmixr2/nlmixr2,1125,9,2022-06-27T19:46:32Z,125
nlmixr2data,"Datasets for 'nlmixr2' and 'rxode2'. 'nlmixr2' is used for fitting and comparing
    nonlinear mixed-effects models in differential
    equations with flexible dosing information commonly seen in pharmacokinetics
    and pharmacodynamics (Almquist, Leander, and Jirstrand 2015 
    <doi:10.1007/s10928-015-9409-1>). Differential equation solving is 
    by compiled C code provided in the 'rxode2' package
    (Wang, Hallow, and James 2015 <doi:10.1002/psp4.12052>).",2022-04-22,Matthew Fidler,"https://nlmixr2.github.io/nlmixr2data/,
https://github.com/nlmixr2/nlmixr2data/",TRUE,https://github.com/nlmixr2/nlmixr2data,1613,0,2022-04-20T16:06:19Z,NA
nlmixr2est,"Fit and compare nonlinear mixed-effects models in
    differential equations with flexible dosing information commonly seen
    in pharmacokinetics and pharmacodynamics (Almquist, Leander, and
    Jirstrand 2015 <doi:10.1007/s10928-015-9409-1>). Differential equation
    solving is by compiled C code provided in the 'rxode2' package (Wang,
    Hallow, and James 2015 <doi:10.1002/psp4.12052>).",2022-06-22,Matthew Fidler,https://github.com/nlmixr2/nlmixr2est,TRUE,https://github.com/nlmixr2/nlmixr2est,1471,3,2022-06-28T20:17:49Z,490.3333333333333
nlmixr2extra,"Fit and compare nonlinear mixed-effects models in
    differential equations with flexible dosing information commonly seen
    in pharmacokinetics and pharmacodynamics (Almquist, Leander, and
    Jirstrand 2015 <doi:10.1007/s10928-015-9409-1>). Differential equation
    solving is by compiled C code provided in the 'rxode2' package (Wang,
    Hallow, and James 2015 <doi:10.1002/psp4.12052>). This package is for
    support functions like preconditioned fits
    <doi:10.1208/s12248-016-9866-5>, boostrap and stepwise covariate
    selection.",2022-05-17,Matthew Fidler,"https://nlmixr2.github.io/nlmixr2extra/,
https://github.com/nlmixr2/nlmixr2extra/",TRUE,https://github.com/nlmixr2/nlmixr2extra,1027,2,2022-06-17T04:40:12Z,513.5
nlmixr2plot,"Fit and compare nonlinear mixed-effects models in
    differential equations with flexible dosing information commonly seen
    in pharmacokinetics and pharmacodynamics (Almquist, Leander, and
    Jirstrand 2015 <doi:10.1007/s10928-015-9409-1>). Differential equation
    solving is by compiled C code provided in the 'rxode2' package (Wang,
    Hallow, and James 2015 <doi:10.1002/psp4.12052>). This package is for
    'ggplot2' plotting methods for 'nlmixr2' objects.",2022-05-23,Matthew Fidler,https://github.com/nlmixr2/nlmixr2plot,TRUE,https://github.com/nlmixr2/nlmixr2plot,1022,1,2022-05-23T15:18:41Z,1022
nloptr,"
    Solve optimization problems using an R interface to NLopt. NLopt is a 
    free/open-source library for nonlinear optimization, providing a common
    interface for a number of different free optimization routines available
    online as well as original implementations of various other algorithms.
    See <https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/> for more
    information on the available algorithms. Building from included sources 
    requires 'CMake'. On Linux and 'macOS', if a suitable system build of 
    NLopt (2.7.0 or later) is found, it is used; otherwise, it is built 
    from included sources via 'CMake'. On Windows, NLopt is obtained through 
    'rwinlib' for 'R <= 4.1.x' or grabbed from the 'Rtools42 toolchain' for 
    'R >= 4.2.0'.",2022-05-26,Jelmer Ypma,"https://astamm.github.io/nloptr/index.html,
https://github.com/astamm/nloptr",TRUE,https://github.com/astamm/nloptr,12055195,75,2022-06-21T21:27:11Z,160735.93333333332
nlraa,"Additional nonlinear regression functions using self-start (SS) algorithms. One of the functions is the Beta growth function proposed by Yin et al. (2003) <doi:10.1093/aob/mcg029>. There are several other functions with breakpoints (e.g. linear-plateau, plateau-linear, exponential-plateau, plateau-exponential, quadratic-plateau, plateau-quadratic and bilinear), a non-rectangular hyperbola and a bell-shaped curve. Twenty eight (28) new self-start (SS) functions in total. This package also supports the publication 'Nonlinear regression Models and applications in agricultural research' by Archontoulis and Miguez (2015) <doi:10.2134/agronj2012.0506>, a book chapter with similar material <doi:10.2134/appliedstatistics.2016.0003.c15> and a publication by Oddi et. al. (2019) in Ecology and Evolution <doi:10.1002/ece3.5543>. The function 'nlsLMList' uses 'nlsLM' for fitting, but it is otherwise almost identical to 'nlme::nlsList'.In addition, this release of the package provides functions for conducting simulations for 'nlme' and 'gnls' objects as well as bootstrapping. These functions are intended to work with the modeling framework of the 'nlme' package. It also provides four vignettes with extended examples.",2022-02-14,Fernando Miguez,NA,TRUE,https://github.com/femiguez/nlraa,18783,14,2022-06-02T13:57:57Z,1341.642857142857
nlrx,"Setup, run and analyze 'NetLogo' (<https://ccl.northwestern.edu/netlogo/>) model simulations in 'R'.
    'nlrx' experiments use a similar structure as 'NetLogos' Behavior Space experiments. 
    However, 'nlrx' offers more flexibility and additional tools for running and analyzing complex simulation designs and sensitivity analyses.
    The user defines all information that is needed in an intuitive framework, using class objects.
    Experiments are submitted from 'R' to 'NetLogo' via 'XML' files that are dynamically written, based on specifications defined by the user.
    By nesting model calls in future environments, large simulation design with many runs can be executed in parallel.
    This also enables simulating 'NetLogo' experiments on remote high performance computing machines.
    In order to use this package, 'Java' and 'NetLogo' (>= 5.3.1) need to be available on the executing system.",2021-09-20,Jan Salecker,"https://docs.ropensci.org/nlrx/, https://github.com/ropensci/nlrx/",TRUE,https://github.com/ropensci/nlrx,16173,61,2021-12-14T12:09:18Z,265.1311475409836
nlsic,"We solve non linear least squares problems with optional
    equality and/or inequality constraints. Non linear iterations are
    globalized with back-tracking method. Linear problems are solved by
    dense QR decomposition from 'LAPACK' which can limit the size of
    treated problems. On the other side, we avoid condition number
    degradation which happens in classical quadratic programming approach.
    Inequality constraints treatment on each non
    linear iteration is based on 'NNLS' method (by Lawson and Hanson).
    We provide an original function 'lsi_ln' for solving linear least squares
    problem with inequality constraints in least norm sens. Thus if Jacobian of
    the problem is rank deficient a solution still can be provided.
    However, truncation errors are probable in this case.
    Equality constraints are treated by using a basis of Null-space.
    User defined function calculating residuals must return a list having
    residual vector (not their squared sum) and Jacobian. If Jacobian is
    not in the returned list, package 'numDeriv' is used to calculated
    finite difference version of Jacobian. The 'NLSIC' method was fist
    published in Sokol et al. (2012) <doi:10.1093/bioinformatics/btr716>.",2022-04-12,Serguei Sokol,https://github.com/MathsCell/nlsic,TRUE,https://github.com/mathscell/nlsic,1913,0,2022-04-12T13:50:14Z,NA
nlstools,Several tools for assessing the quality of fit of a gaussian nonlinear model are provided.,2021-09-17,Aurelie Siberchicot,https://github.com/aursiber/nlstools,TRUE,https://github.com/aursiber/nlstools,63704,2,2021-10-06T06:55:31Z,31852
nltm,"Fits a non-linear transformation model ('nltm') for
        analyzing survival data, see Tsodikov (2003) <doi:10.1111/1467-9868.00414>. The
        class of 'nltm' includes the following currently supported
        models: Cox proportional hazard, proportional hazard cure,
        proportional odds, proportional hazard - proportional hazard
        cure, proportional hazard - proportional odds cure, Gamma
        frailty, and proportional hazard - proportional odds.",2022-04-11,Gilda Garibotti,https://github.com/mclements/nltm,TRUE,https://github.com/mclements/nltm,12197,0,2022-04-07T10:55:30Z,NA
nLTT,"Provides functions to calculate the normalised Lineage-Through-
    Time (nLTT) statistic, given two phylogenetic trees. The nLTT statistic measures
    the difference between two Lineage-Through-Time curves, where each curve is
    normalised both in time and in number of lineages.",2022-05-24,Thijs Janzen,https://github.com/thijsjanzen/nLTT,TRUE,https://github.com/thijsjanzen/nltt,21951,6,2022-05-24T11:11:37Z,3658.5
NMAoutlier,"A set of functions providing several outlier (i.e., studies with extreme findings) and influential detection measures and methodologies in network meta-analysis :
               - simple outlier and influential detection measures
               - outlier and influential detection measures by considering study deletion (shift the mean)
               - plots for outlier and influential detection measures
	       - Q-Q plot for network meta-analysis
               - Forward Search algorithm in network meta-analysis. 
               - forward plots to monitor statistics in each step of the forward search algorithm
               - forward plots for summary estimates and their confidence intervals in each step of forward search algorithm.   ",2021-10-11,Maria Petropoulou,https://github.com/petropouloumaria/NMAoutlier,TRUE,https://github.com/petropouloumaria/nmaoutlier,13585,2,2021-10-11T10:47:27Z,6792.5
nmarank,Derives the most frequent hierarchies along with their probability of occurrence. One can also define complex hierarchy criteria and calculate their probability. Methodology based on Papakonstantinou et al. (2021) <DOI:10.21203/rs.3.rs-858140/v1>.,2021-09-19,Guido Schwarzer,https://github.com/esm-ispm-unibe-ch/nmarank,TRUE,https://github.com/esm-ispm-unibe-ch/nmarank,3322,1,2022-01-12T14:19:34Z,3322
NMdata,"Efficient tools for preparation, checking and post-processing of data in PK/PD (pharmacokinetics/pharmacodynamics) modeling, with focus on use of Nonmem. Helps with trivial but tedious tasks and tries to identify errors to save time on debugging. Implemented in 'data.table', but easily integrated with 'base' and 'tidyverse'.",2022-06-06,Philip Delff,https://philipdelff.github.io/NMdata/,TRUE,https://github.com/philipdelff/nmdata,4253,8,2022-06-30T13:55:08Z,531.625
NMOF,"Functions, examples and data from the first and
  the second edition of ""Numerical Methods and Optimization
  in Finance"" by M. Gilli, D. Maringer and E. Schumann
  (2019, ISBN:978-0128150658).  The package provides
  implementations of optimisation heuristics (Differential
  Evolution, Genetic Algorithms, Particle Swarm
  Optimisation, Simulated Annealing and Threshold
  Accepting), and other optimisation tools, such as grid
  search and greedy search.  There are also functions for
  the valuation of financial instruments such as bonds and
  options, for portfolio selection and functions that help
  with stochastic simulations.",2022-05-13,Enrico Schumann,"http://enricoschumann.net/NMOF.htm, https://gitlab.com/NMOF,
https://github.com/enricoschumann/NMOF",TRUE,https://github.com/enricoschumann/nmof,45979,27,2022-06-29T08:59:02Z,1702.9259259259259
NMproject,"Industrialisation of 'NONMEM'
  <https://www.iconplc.com/innovation/nonmem/> via fully and rapidly reusable 
  model development 'workflows' entirely within 'RStudio'. Quickly get started
  with new models by importing 'NONMEM' templates from the built-in code
  library. Manipulate 'NONMEM' code from within R either via the tracked 
  'manual edit' interface or 'programmatically' via convenience functions. 
  Script 'workflows' by piping sequences of model building steps from control 
  file creation, to execution, to post-processing and evaluation. Run caching 
  makes 'workflows' R markdown friendly for easy documentation of thoughts and
  modelling decisions alongside executable code. Share, reuse and recycle
  'workflows' for new problems.",2021-10-17,Tarj Sahota,"https://tsahota.github.io/NMproject/,
https://github.com/tsahota/NMproject",TRUE,https://github.com/tsahota/nmproject,4255,23,2022-03-27T17:04:25Z,185
nmslibR,"A Non-Metric Space Library ('NMSLIB' <https://github.com/nmslib/nmslib>) wrapper, which according to the authors ""is an efficient cross-platform similarity search library and a toolkit for evaluation of similarity search methods. The goal of the 'NMSLIB' <https://github.com/nmslib/nmslib> Library is to create an effective and comprehensive toolkit for searching in generic non-metric spaces. Being comprehensive is important, because no single method is likely to be sufficient in all cases. Also note that exact solutions are hardly efficient in high dimensions and/or non-metric spaces. Hence, the main focus is on approximate methods"". The wrapper also includes Approximate Kernel k-Nearest-Neighbor functions based on the 'NMSLIB' <https://github.com/nmslib/nmslib> 'Python' Library.",2021-09-11,Lampros Mouselimis,https://github.com/mlampros/nmslibR,TRUE,https://github.com/mlampros/nmslibr,15449,10,2021-09-17T19:37:17Z,1544.9
NNbenchmark,"Datasets and functions to benchmark (convergence, speed, ease of use) R packages dedicated to regression with neural networks (no classification in this version). The templates for the tested packages are available in the R, R Markdown and HTML formats at <https://github.com/pkR-pkR/NNbenchmarkTemplates> and <https://theairbend3r.github.io/NNbenchmarkWeb/index.html>. The submitted article to the R-Journal can be read at <https://www.inmodelia.com/gsoc2020.html>.",2021-06-05,Patrice Kiener,https://github.com/pkR-pkR/NNbenchmark,TRUE,https://github.com/pkr-pkr/nnbenchmark,7852,3,2021-10-27T04:50:54Z,2617.3333333333335
nnfor,"Automatic time series modelling with neural networks. 
    Allows fully automatic, semi-manual or fully manual specification of networks. For details of the
	specification methodology see: (i) Crone and Kourentzes (2010) <doi:10.1016/j.neucom.2010.01.017>;
	and (ii) Kourentzes et al. (2014) <doi:10.1016/j.eswa.2013.12.011>.",2022-07-09,Nikolaos Kourentzes,https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/,TRUE,https://github.com/trnnick/nnfor,64638,27,2022-07-10T09:51:52Z,2394
nngeo,"K-nearest neighbor search for projected and non-projected 'sf' spatial layers. Nearest neighbor search uses (1) C code from 'GeographicLib' for lon-lat point layers, (2) function knn() from package 'nabor' for projected point layers, or (3) function st_distance() from package 'sf' for line or polygon layers. The package also includes several other utility functions for spatial analysis.",2022-05-29,Michael Dorman,"https://michaeldorman.github.io/nngeo/,
https://github.com/michaeldorman/nngeo/",TRUE,https://github.com/michaeldorman/nngeo,45272,67,2022-05-29T20:25:34Z,675.7014925373135
nnlib2Rcpp,"Contains a module to define neural networks from custom components and versions of Autoencoder, BP, LVQ, MAM NN.",2022-05-26,Vasilis Nikolaidis,https://github.com/VNNikolaidis/nnlib2Rcpp,TRUE,https://github.com/vnnikolaidis/nnlib2rcpp,10377,11,2022-05-26T16:16:11Z,943.3636363636364
NNS,"Nonlinear nonparametric statistics using partial moments.  Partial moments are the elements of variance and asymptotically approximate the area of f(x).  These robust statistics provide the basis for nonlinear analysis while retaining linear equivalences.  NNS offers: Numerical integration, Numerical differentiation, Clustering, Correlation, Dependence, Causal analysis, ANOVA, Regression, Classification, Seasonality, Autoregressive modeling, Normalization and Stochastic dominance.  All routines based on: Viole, F. and Nawrocki, D. (2013), Nonlinear Nonparametric Statistics: Using Partial Moments (ISBN: 1490523995).",2022-04-24,Fred Viole,NA,TRUE,https://github.com/ovvo-financial/nns,46299,27,2022-06-06T12:39:15Z,1714.7777777777778
nnTensor,"Some functions for performing non-negative matrix factorization, non-negative CANDECOMP/PARAFAC (CP) decomposition, non-negative Tucker decomposition, and generating toy model data. See Andrzej Cichock et al (2009) <doi:10.1002/9780470747278> and the reference section of GitHub README.md <https://github.com/rikenbit/nnTensor>, for details of the methods.",2022-06-17,Koki Tsuyuzaki,https://github.com/rikenbit/nnTensor,TRUE,https://github.com/rikenbit/nntensor,18929,11,2022-06-17T04:20:11Z,1720.8181818181818
noctua,"Designed to be compatible with the 'R' package 'DBI' (Database Interface)
    when connecting to Amazon Web Service ('AWS') Athena <https://aws.amazon.com/athena/>.
    To do this the 'R' 'AWS' Software Development Kit ('SDK') 'paws' 
    <https://github.com/paws-r/paws> is used as a driver.",2022-05-20,Dyfan Jones,https://github.com/DyfanJones/noctua,TRUE,https://github.com/dyfanjones/noctua,24393,28,2022-05-20T08:34:00Z,871.1785714285714
nodbi,"Simplified document database access and manipulation,
     providing a common API across supported 'NoSQL' databases 
     'Elasticsearch', 'CouchDB', 'MongoDB' as well as 
     'SQLite/JSON1' and 'PostgreSQL'.",2022-07-01,Ralf Herold,"https://docs.ropensci.org/nodbi/,
https://github.com/ropensci/nodbi",TRUE,https://github.com/ropensci/nodbi,19344,65,2022-06-26T18:08:23Z,297.6
nodeSub,"Simulate DNA sequences for the node substitution model.
    In the node substitution model, substitutions accumulate additionally 
    during a speciation event, providing a potential mechanistic explanation for 
    substitution rate variation. This package provides tools to simulate
    such a process, simulate a reference process with only substitutions along
    the branches, and provides tools to infer phylogenies from alignments. More
    information can be found in Janzen (2021) <doi:10.1093/sysbio/syab085>.",2022-05-24,Thijs Janzen,https://github.com/thijsjanzen/nodeSub,TRUE,https://github.com/thijsjanzen/nodesub,3832,1,2022-05-23T10:29:41Z,3832
nofrills,"Provides a compact variation of the usual syntax of function
  declaration, in order to support tidyverse-style quasiquotation of a
  function's arguments and body.",2022-02-03,Eugene Ha,https://github.com/egnha/nofrills,TRUE,https://github.com/egnha/nofrills,15297,37,2022-02-24T11:07:21Z,413.43243243243245
noisyr,"Quantifies and removes technical noise from high-throughput 
        sequencing data. Two approaches are used, one based on the count
        matrix, and one using the alignment BAM files directly.
        Contains several options for every step of the process, as well
        as tools to quality check and assess the stability of output.",2021-04-16,Ilias Moutsopoulos,https://github.com/Core-Bioinformatics/noisyR,TRUE,https://github.com/core-bioinformatics/noisyr,5129,7,2021-10-01T11:55:21Z,732.7142857142857
nombre,"Converts numeric vectors to character vectors of English
    number names. Provides conversion to cardinals, ordinals, numerators,
    and denominators. Supports negative and non-integer numbers.",2022-05-23,Alexander Rossell Hayes,"https://nombre.rossellhayes.com,
https://github.com/rossellhayes/nombre",TRUE,https://github.com/rossellhayes/nombre,10467,9,2022-05-23T08:46:08Z,1163
nominatimlite,"Lite interface for getting data from 'OSM' service
    'Nominatim' <https://nominatim.org/release-docs/latest/>. Extract
    coordinates from addresses, find places near a set of coordinates,
    search for amenities and return spatial objects on 'sf' format.",2022-06-10,Diego Hernangómez,"https://dieghernan.github.io/nominatimlite/,
https://github.com/dieghernan/nominatimlite",TRUE,https://github.com/dieghernan/nominatimlite,4661,10,2022-07-04T19:44:42Z,466.1
nomisr,"Access UK official statistics from the 'Nomis' database. 
    'Nomis' includes data from the Census, the Labour Force Survey, DWP benefit 
    statistics and other economic and demographic data from the Office for 
    National Statistics, based around statistical geographies. See 
    <https://www.nomisweb.co.uk/api/v01/help> for full API documentation.",2022-06-11,Evan Odell,"https://github.com/ropensci/nomisr,
https://docs.evanodell.com/nomisr",TRUE,https://github.com/ropensci/nomisr,17613,30,2022-06-11T15:13:58Z,587.1
nomnoml,"A tool for drawing sassy 'UML' diagrams based on a simple syntax,
  see <https://www.nomnoml.com>. Supports styling, R Markdown and exporting diagrams 
  in the PNG format.",2022-02-23,Andrie de Vries,https://github.com/rstudio/nomnoml,TRUE,https://github.com/rstudio/nomnoml,21653,202,2022-06-27T11:09:48Z,107.1930693069307
nonlinearTseries,"Functions for nonlinear time series analysis. This package permits
    the computation of the  most-used nonlinear statistics/algorithms
    including generalized correlation dimension, information dimension,
    largest Lyapunov exponent, sample entropy and Recurrence
    Quantification Analysis (RQA), among others. Basic routines
    for surrogate data testing are also included. Part of this work
    was based on the  book ""Nonlinear time series analysis"" by
    Holger Kantz and Thomas Schreiber (ISBN: 9780521529020).",2022-03-30,Constantino A. Garcia,https://github.com/constantino-garcia/nonlinearTseries,TRUE,https://github.com/constantino-garcia/nonlineartseries,46492,27,2022-03-30T17:24:17Z,1721.9259259259259
norgeo,"Regional granularity levels in Norway which are depicted by different codes, 
             have undergone several changes over the years. 
             Identifying when codes have changed and how many changes have taken place
             can be troublesome. This package will help to identify these changes and when the changes
             have taken place. One of the limitation of this package is that it is heavily depending 
             on the codes available from SSB website <https://data.ssb.no/api/klass/v1/api-guide.html>.",2022-02-01,Yusman Kamaleri,https://github.com/helseprofil/norgeo,TRUE,https://github.com/helseprofil/norgeo,1760,0,2022-07-06T17:02:41Z,NA
NormalityAssessment,"Package including an interactive Shiny application for
    testing normality visually.",2022-02-19,Christopher Casement,"https://github.com/ccasement/NormalityAssessment,
https://CRAN.R-project.org/package=NormalityAssessment",TRUE,https://github.com/ccasement/normalityassessment,2474,0,2022-02-19T16:39:46Z,NA
normalr,"The robustness of many of the statistical techniques, such as factor analysis, applied in 
          the social sciences rests upon the assumption of item-level normality. However, when dealing 
          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)
          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for 
          large datasets of continuous variables, its application in current software programs is cumbersome
          with analysts having to take several steps to normalise each variable. We present an R package 
          'normalr' that enables researchers to make convenient optimal transformations of multiple variables
          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their 
          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, 
          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their 
          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, 
          kurtosis, and other inferential assessments of normality.",2018-03-30,Kevin Chang,https://github.com/kcha193/normalr,TRUE,https://github.com/kcha193/normalr,18187,2,2021-12-05T02:06:26Z,9093.5
nortsTest,"Despite that several tests for normality in stationary processes have been proposed
   in the literature, consistent implementations of these tests in programming languages are limited. 
   Four normality test are implemented. The Lobato and Velasco's, Epps, Psaradakis and  Vavra, and the 
   random projections tests for stationary process. Some other diagnostics such as, unit root test for 
   stationarity, seasonal tests for seasonality, and arch effect test for volatility; are also performed. 
   The package also offers residual diagnostic for linear time series models developed in several packages.",2021-08-16,Asael Alonzo Matamoros,https://github.com/asael697/nortsTest,TRUE,https://github.com/asael697/nortstest,11677,3,2021-08-16T10:59:58Z,3892.3333333333335
nosoi,"The aim of 'nosoi' (pronounced no.si) is to provide a flexible agent-based stochastic transmission chain/epidemic simulator (Lequime et al. Methods in Ecology and Evolution 11:1002-1007). It is named after the daimones of plague, sickness and disease that escaped Pandora's jar in the Greek mythology. 'nosoi' is able to take into account the influence of multiple variable on the transmission process (e.g. dual-host systems (such as arboviruses), within-host viral dynamics, transportation, population structure), alone or taken together, to create complex but relatively intuitive epidemiological simulations.",2021-08-17,Sebastian Lequime,https://github.com/slequime/nosoi,TRUE,https://github.com/slequime/nosoi,13223,4,2022-03-07T09:16:50Z,3305.75
novelforestSG,"
    The dataset and model used in Lai et al. (2021) 
    Decoupled responses of native and exotic tree diversities to 
    distance from old-growth forest and soil phosphorous in 
    novel secondary forests. Applied Vegetation Science, 24, e12548.",2021-02-20,Hao Ran Lai,"https://hrlai.github.io/novelforestSG/,
https://github.com/hrlai/novelforestSG,
https://doi.org/10.1111/avsc.12548",TRUE,https://github.com/hrlai/novelforestsg,5014,1,2022-01-04T01:33:01Z,5014
NPflow,"Dirichlet process mixture of multivariate normal, skew normal or skew t-distributions
             modeling oriented towards flow-cytometry data preprocessing applications. Method is 
             detailed in: Hejblum, Alkhassimn, Gottardo, Caron & Thiebaut (2019) <doi: 10.1214/18-AOAS1209>.",2020-02-06,Boris P Hejblum,NA,TRUE,https://github.com/borishejblum/npflow,21686,3,2022-04-28T08:45:54Z,7228.666666666667
nphPower,"Performs combination tests and sample size calculation for 
   fixed design with survival endpoints using combination tests under either
   proportional hazards or non-proportional hazards. The combination tests 
   include maximum weighted log-rank test and projection test. The sample 
   size calculation procedure is very flexible, allowing for user-defined
   hazard ratio function and considering various trial conditions like 
   staggered entry, drop-out etc. Trial simulation function is also provided 
   to facilitate the empirical power calculation. The references for 
   projection test and maximum weighted logrank test include Brendel et al. (2014)
   <doi:10.1111/sjos.12059> and Cheng and He (2021) <arXiv:2110.03833>. The 
   references for sample size calculation under proportional hazard include
   Schoenfeld (1981) <doi:10.1093/biomet/68.1.316> and Freedman (1982) <doi:10.1002/sim.4780010204>.
   The references for calculation under non-proportional hazards include 
   Lakatos (1988) <doi:10.2307/2531910> and Cheng and He (2021) (under review).",2021-12-01,Huan Cheng,https://github.com/hcheng99/nphPower,TRUE,https://github.com/hcheng99/nphpower,1805,0,2021-11-30T21:19:38Z,NA
NSO1212,National Statistical Office of Mongolia (NSO) is the national statistical service and an organization of Mongolian government. NSO provides open access to official data via its API <http://opendata.1212.mn/en/doc>. The package NSO1212 has functions for accessing the API service. The functions are compatible with the API v2.0 and get data sets and its detailed informations from the API.,2021-09-29,Makhgal Ganbold,https://github.com/galaamn/NSO1212,TRUE,https://github.com/galaamn/nso1212,13059,7,2021-09-29T05:20:45Z,1865.5714285714287
nsrr,"Allows users to access data from the National Sleep
    Research Resource ('NSRR') <https://sleepdata.org/>.",2020-06-24,John Muschelli,https://github.com/muschellij2/nsrr,TRUE,https://github.com/muschellij2/nsrr,11752,4,2021-10-13T00:10:19Z,2938
NST,"To estimate ecological stochasticity in community assembly. Understanding the community assembly mechanisms controlling biodiversity patterns is a central issue in ecology. Although it is generally accepted that both deterministic and stochastic processes play important roles in community assembly, quantifying their relative importance is challenging. The new index, normalized stochasticity ratio (NST), is to estimate ecological stochasticity, i.e. relative importance of stochastic processes, in community assembly. With functions in this package, NST can be calculated based on different similarity metrics and/or different null model algorithms, as well as some previous indexes, e.g. previous Stochasticity Ratio (ST), Standard Effect Size (SES), modified Raup-Crick metrics (RC). Functions for permutational test and bootstrapping analysis are also included. Previous ST is published by Zhou et al (2014) <doi:10.1073/pnas.1324044111>. NST is modified from ST by considering two alternative situations and normalizing the index to range from 0 to 1 (Ning et al 2019) <doi:10.1073/pnas.1904623116>. A modified version, MST, is a special case of NST, used in some recent or upcoming publications, e.g. Liang et al (2020) <doi:10.1016/j.soilbio.2020.108023>. SES is calculated as described in Kraft et al (2011) <doi:10.1126/science.1208584>. RC is calculated as reported by Chase et al (2011) <doi:10.1890/ES10-00117.1> and Stegen et al (2013) <doi:10.1038/ismej.2013.93>. Version 3 added NST based on phylogenetic beta diversity, used by Ning et al (2020) <doi:10.1038/s41467-020-18560-z>.",2022-06-05,Daliang Ning,https://github.com/DaliangNing/NST,TRUE,https://github.com/daliangning/nst,14939,13,2022-04-11T01:42:45Z,1149.1538461538462
nsyllable,Counts syllables in character vectors for English words.  Imputes syllables as the number of vowel sequences for words not found.  ,2022-02-28,Kenneth Benoit,https://github.com/quanteda/nsyllable,TRUE,https://github.com/quanteda/nsyllable,48211,8,2022-02-28T17:38:21Z,6026.375
nucim,"
    Tools for 4D nucleome imaging. 
    Quantitative analysis of the 3D nuclear landscape recorded with super-resolved fluorescence microscopy. 
    See Volker J. Schmid, Marion Cremer, Thomas Cremer (2017) <doi:10.1016/j.ymeth.2017.03.013>.",2021-06-10,Volker Schmid,https://bioimaginggroup.github.io/nucim/,TRUE,https://github.com/bioimaginggroup/nucim,15709,2,2022-05-30T09:20:03Z,7854.5
nullabor,"Tools for visual inference. Generate null data sets
    and null plots using permutation and simulation. Calculate distance metrics
    for a lineup, and examine the distributions of metrics.",2020-02-25,Di Cook,http://github.com/dicook/nullabor,TRUE,https://github.com/dicook/nullabor,35022,51,2022-07-05T13:47:22Z,686.7058823529412
numform,"Format numbers and plots for publication; includes the removal of leading zeros,
           standardization of number of digits, addition of affixes, and a p-value formatter. These
           tools combine the functionality of several 'base' functions such as 'paste()',
           'format()', and 'sprintf()' into specific use case functions that are named in a way
           that is consistent with usage, making their names easy to remember and easy to deploy.",2021-10-09,Tyler Rinker,https://github.com/trinker/numform,TRUE,https://github.com/trinker/numform,33284,50,2021-10-08T20:17:46Z,665.68
nvctr,"The n-vector framework uses the normal vector to
    the Earth ellipsoid (called n-vector) as a non-singular position
    representation that turns out to be very convenient for practical
    position calculations.  The n-vector is simple to use and gives exact
    answers for all global positions, and all distances, for both
    ellipsoidal and spherical Earth models.  This package is a translation
    of the 'Matlab' library from FFI, the Norwegian Defence Research
    Establishment, as described in Gade (2010)
    <doi:10.1017/S0373463309990415>.",2020-10-28,Enrico Spinielli,https://github.com/euctrl-pru/nvctr,TRUE,https://github.com/euctrl-pru/nvctr,11898,9,2022-06-02T10:48:34Z,1322
nycflights13,"Airline on-time data for all flights departing NYC in 2013.
    Also includes useful 'metadata' on airlines, airports, weather, and
    planes.",2021-04-12,Hadley Wickham,https://github.com/hadley/nycflights13,TRUE,https://github.com/hadley/nycflights13,1359532,103,2022-03-02T20:14:22Z,13199.339805825242
o2geosocial,"Bayesian reconstruction of who infected whom during past outbreaks using routinely-collected surveillance data. Inference of transmission trees using genotype, age specific social contacts, distance between cases and onset dates of the reported cases. (Robert A, Kucharski AJ, Gastanaduy PA, Paul P, Funk S. 2020 <doi:10.1098/rsif.2020.0084>).",2021-09-11,Alexis Robert,https://github.com/alxsrobert/o2geosocial,TRUE,https://github.com/alxsrobert/o2geosocial,7862,6,2022-04-12T16:43:41Z,1310.3333333333333
oai,"A general purpose client to work with any 'OAI-PMH'
    (Open Archives Initiative Protocol for 'Metadata' Harvesting) service.
    The 'OAI-PMH' protocol is described at
    <http://www.openarchives.org/OAI/openarchivesprotocol.html>.
    Functions are provided to work with the 'OAI-PMH' verbs: 'GetRecord',
    'Identify', 'ListIdentifiers', 'ListMetadataFormats', 'ListRecords', and
    'ListSets'.",2021-05-13,Scott Chamberlain,"https://docs.ropensci.org/oai/, https://github.com/ropensci/oai",TRUE,https://github.com/ropensci/oai,147013,13,2022-06-06T15:12:56Z,11308.692307692309
OBIC,"The Open Bodem Index (OBI) is a method to evaluate the quality of soils of agricultural fields in The Netherlands and the sustainability of the current agricultural practices.
    The OBI score is based on four main criteria: chemical, physical, biological and management, which consist of more than 21 indicators. 
    By providing results of a soil analysis and management info the 'OBIC' package can be use to calculate he scores, indicators and derivatives that are used by the OBI.
    More information about the Open Bodem Index can be found at <https://www.openbodemindex.nl/>.",2022-04-05,Sven Verweij,https://github.com/AgroCares/Open-Bodem-Index-Calculator,TRUE,https://github.com/agrocares/open-bodem-index-calculator,869,6,2022-04-13T07:49:50Z,144.83333333333334
objectremover,"An 'RStudio' addin to assist with removing objects from the global environment. Features include removing objects according to name patterns and object type. During the course of an analysis, temporary objects are often created and this tool assists with removing them quickly. This can be useful when memory management within 'R' is important.",2021-08-16,Alan Yeung,https://github.com/alan-y/objectremover,TRUE,https://github.com/alan-y/objectremover,12051,1,2021-08-15T19:59:31Z,12051
occCite,"Facilitates the gathering of biodiversity occurrence data 
  from disparate sources. Metadata is managed throughout the process to facilitate 
  reporting and enhanced ability to repeat analyses.",2022-03-21,Hannah L. Owens,https://docs.ropensci.org/occCite/,TRUE,https://github.com/ropensci/occcite,9210,17,2022-07-06T07:48:37Z,541.7647058823529
oce,"Supports the analysis of Oceanographic data, including 'ADCP'
    measurements, measurements made with 'argo' floats, 'CTD' measurements,
    sectional data, sea-level time series, coastline and topographic data, etc.
    Provides specialized functions for calculating seawater properties such as
    potential temperature in either the 'UNESCO' or 'TEOS-10' equation of state.
    Produces graphical displays that conform to the conventions of the
    Oceanographic literature. This package is discussed extensively by
    Kelley (2018) ""Oceanographic Analysis with R"" <doi:10.1007/978-1-4939-8844-0>.",2022-07-05,Dan Kelley,https://dankelley.github.io/oce/,TRUE,https://github.com/dankelley/oce,101078,123,2022-07-06T09:41:16Z,821.7723577235772
oceanis,"Creating maps for statistical analysis such as proportional circles, chroropleth, typology and flows. Some functions use 'shiny' or 'leaflet' technologies for dynamism and interactivity.
	The great features are :
	- Create maps in a web environment where the parameters are modifiable on the fly ('shiny' and 'leaflet' technology).
	- Create interactive maps through zoom and pop-up ('leaflet' technology).
	- Create frozen maps with the possibility to add labels.",2021-11-25,Sébastien CALVET - PSAR-AT - DR Provence-Alpes-Cote dAzur - INSEE,https://github.com/insee-psar-at/oceanis-package/,TRUE,https://github.com/insee-psar-at/oceanis-package,19280,12,2022-07-07T15:17:01Z,1606.6666666666667
ocedata,"Several Oceanographic data sets are provided for use
    by the 'oce' package and for other purposes.",2022-03-14,Dan Kelley,https://dankelley.github.io/ocedata/,TRUE,https://github.com/dankelley/ocedata,25173,5,2022-04-07T20:07:11Z,5034.6
ocs4R,Provides an Interface to Open Collaboration Services 'OCS' (<https://www.open-collaboration-services.org/>) REST API.,2022-03-17,Emmanuel Blondel,https://github.com/eblondel/ocs4R,TRUE,https://github.com/eblondel/ocs4r,11466,4,2022-05-03T22:16:53Z,2866.5
OCSdata,"
    Provides functions to access and download data from the 'Open Case Studies' <https://www.opencasestudies.org/> 
    repositories on 'GitHub' <https://github.com/opencasestudies>. Different functions enable 
    users to grab the data they need at different sections in the case study, as well as 
    download the whole case study repository. All the user needs to do is input the name of 
    the case study being worked on. The package relies on the httr::GET() function to access
    files through the 'GitHub' API. The functions usethis::use_zip() and usethis::create_from_github() 
    are used to clone and/or download the case study repositories. To cite an individual case study,
    please see the respective 'README' file at <https://github.com/opencasestudies/>.
    <https://github.com/opencasestudies/ocs-bp-rural-and-urban-obesity> 
    <https://github.com/opencasestudies/ocs-bp-air-pollution>
    <https://github.com/opencasestudies/ocs-bp-vaping-case-study>
    <https://github.com/opencasestudies/ocs-bp-opioid-rural-urban>
    <https://github.com/opencasestudies/ocs-bp-RTC-wrangling>
    <https://github.com/opencasestudies/ocs-bp-RTC-analysis>
    <https://github.com/opencasestudies/ocs-bp-youth-disconnection>
    <https://github.com/opencasestudies/ocs-bp-youth-mental-health>
    <https://github.com/opencasestudies/ocs-bp-school-shootings-dashboard>
    <https://github.com/opencasestudies/ocs-bp-co2-emissions>
    <https://github.com/opencasestudies/ocs-bp-diet>.",2021-08-20,Carrie Wright,"https://github.com/opencasestudies/OCSdata,
https://doi.org/10.5281/zenodo.5214347,
https://www.opencasestudies.org/",TRUE,https://github.com/opencasestudies/ocsdata,3822,1,2022-04-29T01:00:39Z,3822
od,"The aim of 'od' is to provide tools and example datasets for working with
  origin-destination ('OD') datasets of the type used to describe aggregate
  urban mobility patterns (Carey et al. 1981) <doi:10.1287/trsc.15.1.32>.
  The package builds on functions for working with 'OD' data in the package 'stplanr',
  (Lovelace and Ellison 2018) <doi:10.32614/RJ-2018-053> with a focus on computational
  efficiency and support for  the 'sf' class system (Pebesma 2018) <doi:10.32614/RJ-2018-009>.
  With few dependencies and a simple class system based on data frames,
  the package is intended to facilitate efficient analysis of 'OD' datasets
  and to provide a place for developing new functions.
  The package enables the creation and analysis of geographic entities
  representing large scale mobility patterns,
  from daily travel between zones in cities to migration between countries.",2022-04-18,Robin Lovelace,"https://github.com/itsleeds/od, https://itsleeds.github.io/od/",TRUE,https://github.com/itsleeds/od,11930,21,2022-04-18T10:52:07Z,568.0952380952381
odbc,A DBI-compatible interface to ODBC databases.,2021-11-30,Hadley Wickham,"https://github.com/r-dbi/odbc, https://db.rstudio.com",TRUE,https://github.com/r-dbi/odbc,2858074,320,2022-03-03T20:00:25Z,8931.48125
oddsapiR,"A utility to quickly obtain clean and tidy sports
    odds from The Odds API <https://the-odds-api.com>.",2022-06-22,Saiem Gilani,"https://oddsapiR.sportsdataverse.org/ (docs),
https://github.com/sportsdataverse/oddsapiR (repo)",TRUE,https://github.com/sportsdataverse/oddsapir,241,1,2022-06-21T17:33:18Z,241
OddsPlotty,"Uses the outputs of a logistic regression model, from caret <https://CRAN.R-project.org/package=caret>, to build an odds plot.
    This allows for the rapid visualisation of odds plot ratios and works best with the outputs of CARET's GLM model class, by returning the final trained model. ",2021-11-13,Gary Hutson,https://github.com/StatsGary/OddsPlotty,TRUE,https://github.com/statsgary/oddsplotty,5874,13,2021-11-13T14:28:57Z,451.84615384615387
oddsratio,"Simplified odds ratio calculation of GAM(M)s &
    GLM(M)s. Provides structured output (data frame) of all predictors and
    their corresponding odds ratios and confident intervals for further
    analyses.  It helps to avoid false references of predictors and
    increments by specifying these parameters in a list instead of using
    'exp(coef(model))' (standard approach of odds ratio calculation for
    GLMs) which just returns a plain numeric output.  For GAM(M)s, odds
    ratio calculation is highly simplified with this package since it
    takes care of the multiple 'predict()' calls of the chosen predictor
    while holding other predictors constant. Also, this package allows
    odds ratio calculation of percentage steps across the whole predictor
    distribution range for GAM(M)s.  In both cases, confident intervals
    are returned additionally. Calculated odds ratio of GAM(M)s can be
    inserted into the smooth function plot.",2020-05-24,Patrick Schratz,https://github.com/pat-s/oddsratio,TRUE,https://github.com/pat-s/oddsratio,40941,28,2022-03-02T07:43:20Z,1462.1785714285713
odeGUTS,"Allows performing forwards prediction for the General Unified 
          Threshold model of Survival using compiled ode code. This package 
          was created to avoid dependency with the 'morse' package that requires 
          the installation of 'JAGS'. This package is based on functions from 
          the 'morse' package v3.3.1: Virgile Baudrot, Sandrine Charles, 
          Marie Laure Delignette-Muller, Wandrille Duchemin, Benoit Goussen, 
          Nils Kehrein, Guillaume Kon-Kam-King, Christelle Lopes, Philippe Ruiz, 
          Alexander Singer and Philippe Veber (2021) <https://CRAN.R-project.org/package=morse>.",2021-09-10,Benoit Goussen,https://github.com/bgoussen/odeGUTS,TRUE,https://github.com/bgoussen/odeguts,3671,2,2021-09-10T08:48:48Z,1835.5
odin,"Generate systems of ordinary differential equations
    (ODE) and integrate them, using a domain specific language
    (DSL).  The DSL uses R's syntax, but compiles to C in order to
    efficiently solve the system.  A solver is not provided, but
    instead interfaces to the packages 'deSolve' and 'dde' are
    generated.  With these, while solving the differential equations,
    no allocations are done and the calculations remain entirely in
    compiled code.  Alternatively, a model can be transpiled to R for
    use in contexts where a C compiler is not present.  After
    compilation, models can be inspected to return information about
    parameters and outputs, or intermediate values after calculations.
    'odin' is not targeted at any particular domain and is suitable
    for any system that can be expressed primarily as mathematical
    expressions.  Additional support is provided for working with
    delays (delay differential equations, DDE), using interpolated
    functions during interpolation, and for integrating quantities
    that represent arrays.",2022-04-28,Rich FitzJohn,https://github.com/mrc-ide/odin,TRUE,https://github.com/mrc-ide/odin,32767,82,2022-06-21T09:32:31Z,399.5975609756098
oenb,"Tools to access data from the data web service of the Oesterreichische Nationalbank (OeNB), <https://www.oenb.at/en/Statistics/User-Defined-Tables/webservice.html>.",2021-03-22,Franz X. Mohr,https://github.com/franzmohr/oenb,TRUE,https://github.com/franzmohr/oenb,11353,0,2021-11-05T21:31:18Z,NA
ohoegdm,"Perform a Bayesian estimation of the ordinal exploratory 
    Higher-order General Diagnostic Model (OHOEGDM) for Polytomous Data 
    described by Culpepper, S. A. and Balamuta, J. J. (In Press) <doi:10.1080/00273171.2021.1985949>.",2022-02-24,Steven Andrew Culpepper,"https://github.com/tmsalab/ohoegdm,
https://tmsalab.github.io/ohoegdm/",TRUE,https://github.com/tmsalab/ohoegdm,1177,0,2022-02-23T00:59:20Z,NA
OHPL,"Ordered homogeneity pursuit lasso (OHPL)
    algorithm for group variable selection proposed in Lin et al. (2017)
    <DOI:10.1016/j.chemolab.2017.07.004>. The OHPL method exploits the
    homogeneity structure in high-dimensional data and enjoys the
    grouping effect to select groups of important variables
    automatically. This feature makes it particularly useful for
    high-dimensional datasets with strongly correlated variables,
    such as spectroscopic data.",2019-05-18,Nan Xiao,"https://ohpl.io, https://ohpl.io/doc/,
https://github.com/nanxstats/OHPL",TRUE,https://github.com/nanxstats/ohpl,13395,4,2021-12-20T21:57:12Z,3348.75
ollg,"Computes the pdf, cdf, quantile function, hazard function and generating random numbers for Odd log-logistic family (OLL-G). This family have been developed by different authors in the recent years. See Alizadeh (2019) <doi:10.31801/cfsuasmas.542988> for example.",2022-03-14,Danial Mazarei,https://github.com/dmazarei/ollg,TRUE,https://github.com/dmazarei/ollg,1242,1,2022-03-15T19:41:22Z,1242
olsrr,"Tools designed to make it easier for users, particularly beginner/intermediate R users 
    to build ordinary least squares regression models. Includes comprehensive regression output, 
    heteroskedasticity tests, collinearity diagnostics, residual diagnostics, measures of influence, 
    model fit assessment and variable selection procedures.",2020-02-10,Aravind Hebbali,"https://olsrr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/olsrr",TRUE,https://github.com/rsquaredacademy/olsrr,333988,95,2022-03-15T03:22:36Z,3515.6631578947367
OmicNavigator,"
  A tool for interactive exploration of the results from 'omics'
  experiments to facilitate novel discoveries from high-throughput biology. The
  software includes R functions for the 'bioinformatician' to deposit study
  metadata and the outputs from statistical analyses (e.g. differential
  expression, enrichment). These results are then exported to an interactive
  JavaScript dashboard that can be interrogated on the user's local machine or
  deployed online to be explored by collaborators. The dashboard includes
  'sortable' tables, interactive plots including network visualization, and
  fine-grained filtering based on statistical significance.",2022-05-26,Terrence Ernst,https://github.com/abbvie-external/OmicNavigator,TRUE,https://github.com/abbvie-external/omicnavigator,4301,18,2022-06-10T19:39:41Z,238.94444444444446
omnibus,"An assortment of helper functions for managing data (e.g.,
	rotating values in matrices by a user-defined angle, switching from
	row- to column-indexing), dates (e.g., intuiting year from messy date
	strings), handling missing values (e.g., removing elements/rows across
	multiple vectors or matrices if any have an NA), and text (e.g.,
	flushing reports to the console in real-time).",2022-02-15,Adam B. Smith,https://github.com/adamlilith/omnibus,TRUE,https://github.com/adamlilith/omnibus,2094,3,2022-05-17T03:56:58Z,698
ompr,"Model mixed integer linear programs in an algebraic way directly in R.
             The model is solver-independent and thus offers the possibility
             to solve a model with different solvers. It currently only supports
             linear constraints and objective functions. See the 'ompr'
             website <https://dirkschumacher.github.io/ompr/> for more information,
             documentation and examples.",2022-01-31,Dirk Schumacher,https://github.com/dirkschumacher/ompr,TRUE,https://github.com/dirkschumacher/ompr,50825,241,2022-03-14T16:29:48Z,210.8921161825726
ompr.roi,"A solver for 'ompr' based on the R Optimization Infrastructure ('ROI').
  The package makes all solvers in 'ROI' available to solve 'ompr' models. Please see the
  'ompr' website <https://dirkschumacher.github.io/ompr/> and package docs for more information
  and examples on how to use it.",2022-01-27,Dirk Schumacher,https://github.com/dirkschumacher/ompr.roi,TRUE,https://github.com/dirkschumacher/ompr.roi,29440,8,2022-01-31T09:39:56Z,3680
onbrand,Automated reporting in Word and PowerPoint can require customization for each organizational template. This package works around this by adding standard reporting functions and an abstraction layer to facilitate automated reporting workflows that can be replicated across different organizational templates.,2021-12-20,John Harrold,https://onbrand.ubiquity.tools/,TRUE,https://github.com/john-harrold/onbrand,4975,9,2022-06-05T17:17:17Z,552.7777777777778
oneclust,"Maximum homogeneity clustering algorithm for one-dimensional data
    described in W. D. Fisher (1958) <doi:10.1080/01621459.1958.10501479>
    via dynamic programming.",2020-09-01,Nan Xiao,"https://nanx.me/oneclust/, https://github.com/nanxstats/oneclust",TRUE,https://github.com/nanxstats/oneclust,6970,5,2021-12-18T23:33:35Z,1394
OneSampleMR,"Useful functions for one-sample (individual level data)
    Mendelian randomization and instrumental variable analyses. The
    package includes implementations of; the Sanderson and Windmeijer
    (2016) <doi:10.1016/j.jeconom.2015.06.004> conditional F-statistic,
    the multiplicative structural mean model Hernán and Robins (2006)
    <doi:10.1097/01.ede.0000222409.00878.37>, and two-stage predictor
    substitution and two-stage residual inclusion estimators explained by
    Terza et al. (2008) <doi:10.1016/j.jhealeco.2007.09.009>.",2022-05-11,Tom Palmer,"https://github.com/remlapmot/OneSampleMR,
https://remlapmot.github.io/OneSampleMR/",TRUE,https://github.com/remlapmot/onesamplemr,2448,4,2022-06-28T12:23:59Z,612
ONEST,"
    This ONEST software implements the method of assessing the pathologist agreement in reading PD-L1 assays (Reisenbichler et al. (2020 <doi:10.1038/s41379-020-0544-x>)), to determine the minimum number of evaluators needed to estimate agreement involving a large number of raters. Input to the program should be binary(1/0) pathology data, where “0” may stand for negative and “1” for positive. Additional examples were given using the data from Rimm et al. (2017 <doi:10.1001/jamaoncol.2017.0013>). ",2021-07-26,Gang Han,https://github.com/hangangtrue/ONEST,TRUE,https://github.com/hangangtrue/onest,7377,2,2021-07-27T14:28:44Z,3688.5
onion,"
  Quaternions and Octonions are four- and eight- dimensional
  extensions of the complex numbers.  They are normed division
  algebras over the real numbers and find applications in spatial
  rotations (quaternions), and string theory and relativity
  (octonions).  The quaternions are noncommutative and the octonions
  nonassociative.  See the package vignette for more details.",2021-02-11,Robin K. S. Hankin,https://github.com/RobinHankin/onion,TRUE,https://github.com/robinhankin/onion,25448,4,2022-06-21T06:58:45Z,6362
onnx,"R Interface to 'ONNX' - Open Neural Network Exchange <https://onnx.ai/>. 
             'ONNX' provides an open source format for machine learning models. 
             It defines an extensible computation graph model, as well as definitions
             of built-in operators and standard data types.",2021-04-16,Yuan Tang,https://github.com/onnx/onnx-r,TRUE,https://github.com/onnx/onnx-r,12357,34,2021-07-24T14:59:53Z,363.44117647058823
onpoint,"
  Growing collection of helper functions for point pattern analysis. Most functions
  are designed to work with the 'spatstat' (<http://spatstat.org>) package. The focus of 
  most functions are either null models or summary functions for spatial point patterns. 
  For a detailed description of all null models and summary functions, see 
  Wiegand and Moloney (2014, ISBN:9781420082548).",2022-02-02,Maximillian H.K. Hesselbarth,https://r-spatialecology.github.io/onpoint/,TRUE,https://github.com/r-spatialecology/onpoint,3360,1,2022-02-02T20:50:29Z,3360
onsr,"Client for the 'Office of National Statistics'
    ('ONS') API <https://api.beta.ons.gov.uk/v1>.  ",2022-01-21,Kostas Vasilopoulos,https://kvasilopoulos.github.io/onsr/,TRUE,https://github.com/kvasilopoulos/onsr,4840,2,2022-01-21T19:55:25Z,2420
oolong,"Intended to create standard human-in-the-loop validity tests for typical automated content analysis such as topic modeling and dictionary-based methods. This package offers a standard workflow with functions to prepare, administer and evaluate a human-in-the-loop validity test. This package provides functions for validating topic models using word intrusion, topic intrusion (Chang et al. 2009,  <https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models>) and word set intrusion (Ying et al. 2021) <doi:10.1017/pan.2021.33> tests. This package also provides functions for generating gold-standard data which are useful for validating dictionary-based methods. The default settings of all generated tests match those suggested in Chang et al. (2009) and Song et al. (2020) <doi:10.1080/10584609.2020.1723752>.",2021-11-09,Chung-hong Chan,https://github.com/chainsawriot/oolong,TRUE,https://github.com/chainsawriot/oolong,10645,44,2022-06-28T12:53:16Z,241.9318181818182
ooplah,"Helper functions for coding object-oriented programming with
    a focus on R6. Includes functions for assertions and testing, looping,
    and re-usable design patterns including Abstract and Decorator
    classes.",2022-01-21,Raphael Sonabend,"https://xoopR.github.io/ooplah/, https://github.com/xoopR/ooplah",TRUE,https://github.com/xoopr/ooplah,27502,2,2022-03-25T21:50:10Z,13751
OOR,"Implementation of optimistic optimization methods for global optimization of deterministic or stochastic functions. The algorithms feature guarantees of the convergence to a global optimum. They require minimal assumptions on the (only local) smoothness, where the smoothness parameter does not need to be known. They are expected to be useful for the most difficult functions when we have no information on smoothness and the gradients are unknown or do not exist. Due to the weak assumptions, however, they can be mostly effective only in small dimensions, for example, for hyperparameter tuning.",2020-03-23,M. Binois,http://github.com/mbinois/OOR,TRUE,https://github.com/mbinois/oor,20661,0,2022-04-26T10:03:00Z,NA
oottest,"Implements the out-of-treatment testing from Kuelpmann and Kuzmics (2020) <doi:10.2139/ssrn.3441675> based on the Vuong Test introduced in Vuong (1989) <doi:10.2307/1912557>. 
    Out-of treatment testing allows for a direct, pairwise likelihood comparison of theories, calibrated with pre-existing data.",2022-04-27,Philipp Külpmann,https://github.com/PhilippKuelpmann/oottest,TRUE,https://github.com/philippkuelpmann/oottest,467,1,2022-04-25T09:07:03Z,467
opa,"Quantifies hypothesis to data fit for repeated measures 
    and longitudinal data, as described by Thorngate (1987) 
    <doi:10.1016/S0166-4115(08)60083-7> and Grice et al., (2015) 
    <doi:10.1177/2158244015604192>. Hypothesis and data are encoded as
    pairwise relative orderings which are then compared to determine the
    percentage of orderings in the data that are matched by the hypothesis.",2022-06-17,Timothy Beechey,https://github.com/timbeechey/opa,TRUE,https://github.com/timbeechey/opa,1490,0,2022-06-28T16:29:33Z,NA
opalr,"Data integration Web application for biobanks by 'OBiBa'. 'Opal' is
    the core database application for biobanks. Participant data, once
    collected from any data source, must be integrated and stored in a central
    data repository under a uniform model. 'Opal' is such a central repository.
    It can import, process, validate, query, analyze, report, and export data.
    'Opal' is typically used in a research center to analyze the data acquired at
    assessment centres. Its ultimate purpose is to achieve seamless
    data-sharing among biobanks. This 'Opal' client allows to interact with 'Opal'
    web services and to perform operations on the R server side. 'DataSHIELD'
    administration tools are also provided.",2022-06-09,Yannick Marcon,"https://github.com/obiba/opalr/, https://www.obiba.org/opalr/,
https://www.obiba.org/pages/products/opal/,
https://academic.oup.com/ije/article/46/5/1372/4102813,
https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008880,
https://www.datashield.org/",TRUE,https://github.com/obiba/opalr,27627,3,2022-06-17T14:55:11Z,9209
openai,"An R wrapper of OpenAI API endpoints (see
    <https://beta.openai.com/docs/introduction> for details). This package
    covers Engines, Completions, Edits, Files, Fine-tunes, Embeddings and legacy
    Searches, Classifications, and Answers endpoints.",2022-06-07,Iegor Rudnytskyi,"https://github.com/irudnyts/openai,
https://irudnyts.github.io/openai/",TRUE,https://github.com/irudnyts/openai,170,0,2022-06-06T20:33:22Z,NA
openair,"Tools to analyse, interpret and understand air
    pollution data. Data are typically hourly time series
    and both monitoring data and dispersion model output
    can be analysed.  Many functions can also be applied to
    other data, including meteorological and traffic data.",2022-06-21,David Carslaw,https://davidcarslaw.github.io/openair/,TRUE,https://github.com/davidcarslaw/openair,175892,230,2022-06-21T12:43:54Z,764.7478260869565
openalexR,A set of tools to extract bibliographic content from 'OpenAlex' database using API <https://docs.openalex.org/api/>.,2022-04-22,Massimo Aria,https://github.com/massimoaria/openalexR,TRUE,https://github.com/massimoaria/openalexr,584,14,2022-05-11T10:00:49Z,41.714285714285715
openbankeR,Creates a client with queries for the UK 'Open Banking' ('Open Data') API.,2022-02-22,Nik Lilovski,https://github.com/nik01010/openbankeR,TRUE,https://github.com/nik01010/openbanker,1121,3,2022-03-01T16:12:01Z,373.6666666666667
opencage,"Geocode with the OpenCage API, either from place name to longitude 
    and latitude (forward geocoding) or from longitude and latitude to the name 
    and address of a location (reverse geocoding), see 
    <https://opencagedata.com/>.",2021-02-20,Daniel Possenriede,"https://docs.ropensci.org/opencage/,
https://github.com/ropensci/opencage",TRUE,https://github.com/ropensci/opencage,19752,82,2022-06-09T19:42:38Z,240.8780487804878
openCR,Non-spatial and spatial open-population capture-recapture analysis.,2022-07-02,Murray Efford,https://www.otago.ac.nz/density/,TRUE,https://github.com/murrayefford/opencr,19427,0,2022-07-05T10:23:09Z,NA
opendatatoronto,"Access data from the ""City of Toronto
    Open Data Portal"" (<https://open.toronto.ca>) directly from R.",2022-04-13,Sharla Gelfand,"https://sharlagelfand.github.io/opendatatoronto/,
https://github.com/sharlagelfand/opendatatoronto/",TRUE,https://github.com/sharlagelfand/opendatatoronto,21638,57,2022-04-11T20:24:17Z,379.6140350877193
openeo,Access data and processing functionalities of 'openEO' compliant back-ends in R.,2022-06-24,Florian Lahn,https://github.com/Open-EO/openeo-r-client,TRUE,https://github.com/open-eo/openeo-r-client,6219,49,2022-06-24T07:58:37Z,126.91836734693878
OpenImageR,"Incorporates functions for image preprocessing, filtering and image recognition. The package takes advantage of 'RcppArmadillo' to speed up computationally intensive functions. The histogram of oriented gradients descriptor is a modification of the 'findHOGFeatures' function of the 'SimpleCV' computer vision platform, the average_hash(), dhash() and phash() functions are based on the 'ImageHash' python library. The Gabor Feature Extraction functions are based on 'Matlab' code of the paper, ""CloudID: Trustworthy cloud-based and cross-enterprise biometric identification"" by M. Haghighat, S. Zonouz, M. Abdel-Mottaleb, Expert Systems with Applications, vol. 42, no. 21, pp. 7905-7916, 2015, <doi:10.1016/j.eswa.2015.06.025>. The 'SLIC' and 'SLICO' superpixel algorithms were explained in detail in (i) ""SLIC Superpixels Compared to State-of-the-art Superpixel Methods"", Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Suesstrunk, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, num. 11, p. 2274-2282, May 2012, <doi:10.1109/TPAMI.2012.120> and (ii) ""SLIC Superpixels"", Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Suesstrunk, EPFL Technical Report no. 149300, June 2010.",2022-06-07,Lampros Mouselimis,https://github.com/mlampros/OpenImageR,TRUE,https://github.com/mlampros/openimager,98522,45,2022-06-12T08:05:36Z,2189.3777777777777
openintro,"Supplemental functions and data for 'OpenIntro' resources, which 
    includes open-source textbooks and resources for introductory statistics 
    (<https://www.openintro.org/>). The package contains data sets used in our 
    open-source textbooks along with custom plotting functions for reproducing 
    book figures. Note that many functions and examples include color 
    transparency; some plotting elements may not show up properly (or at all) 
    when run in some versions of Windows operating system.",2022-02-23,Mine Çetinkaya-Rundel,"http://openintrostat.github.io/openintro/,
https://github.com/OpenIntroStat/openintro/",TRUE,https://github.com/openintrostat/openintro,214993,210,2022-02-23T02:32:07Z,1023.7761904761904
OpenLand,"Tools for the analysis of land use and cover (LUC) time series. It 
    includes support for loading spatiotemporal raster data and synthesized 
    spatial plotting. Several LUC change (LUCC) metrics in regular or irregular 
    time intervals can be extracted and visualized through one- and multistep 
    sankey and chord diagrams. A complete intensity analysis according to 
    Aldwaik and Pontius (2012) <doi:10.1016/j.landurbplan.2012.02.010> is 
    implemented, including tools for the generation of standardized multilevel 
    output graphics.",2021-11-02,Reginal Exavier,https://github.com/reginalexavier/OpenLand,TRUE,https://github.com/reginalexavier/openland,9701,9,2022-02-05T04:00:44Z,1077.888888888889
openMSE,"The 'openMSE' package is designed for building operating models, 
    doing simulation modelling and management strategy evaluation for fisheries.
    'openMSE' is an umbrella package for the 'MSEtool' (Management Strategy Evaluation
    toolkit), 'DLMtool' (Data-Limited Methods toolkit), and 
    SAMtool (Stock Assessment Methods toolkit) packages. By loading and installing
    'openMSE', users have access to the full functionality contained within
    these packages. Learn more about 'openMSE' at <https://openmse.com/>.",2021-02-08,Adrian Hordyk,"https://openmse.com/, https://github.com/Blue-Matter/openMSE",TRUE,https://github.com/blue-matter/openmse,4175,1,2022-07-05T21:03:08Z,4175
OpenMx,"Create structural equation models that can be manipulated programmatically.
    Models may be specified with matrices or paths (LISREL or RAM)
    Example models include confirmatory factor, multiple group, mixture
    distribution, categorical threshold, modern test theory, differential
    Fit functions include full information maximum likelihood, maximum likelihood, and weighted least squares.
    equations, state space, and many others.
	Support and advanced package binaries available at <http://openmx.ssri.psu.edu>.
    The software is described in Neale, Hunter, Pritikin, Zahery, Brick,
    Kirkpatrick, Estabrook, Bates, Maes, & Boker (2016) <doi:10.1007/s11336-014-9435-8>.",2022-03-09,Joshua N. Pritikin,"http://openmx.ssri.psu.edu, https://github.com/OpenMx/OpenMx",TRUE,https://github.com/openmx/openmx,555222,69,2022-06-17T21:24:34Z,8046.695652173913
OpenRepGrid.ic,"Shiny UI to identify cliques of related constructs in repertory grid data. 
    See Burr, King, & Heckmann (2020) <doi:10.1080/14780887.2020.1794088> for a description 
    of the interpretive clustering (IC) method.",2021-06-26,Mark Heckmann,https://github.com/markheckmann/OpenRepGrid.ic,TRUE,https://github.com/markheckmann/openrepgrid.ic,9273,1,2022-05-08T19:11:19Z,9273
openSkies,"Provides functionalities and data structures to retrieve, analyze and visualize aviation 
    data. It includes a client interface to the 'OpenSky' API <https://opensky-network.org>. It allows 
    retrieval of flight information, as well as aircraft state vectors.",2021-12-19,Rafael Ayala,NA,TRUE,https://github.com/rafael-ayala/openskies,9687,4,2021-12-19T10:31:56Z,2421.75
OpenSpecy,"Raman and (FT)IR spectral analysis tool for plastic particles and
    other environmental samples (Cowger et al. 2021,
    <doi:10.1021/acs.analchem.1c00123>). Supported features include reading
    spectral data files (.asp, .csv, .jdx, .spc, .spa, .0), Savitzky-Golay
    smoothing of spectral intensities with smooth_intens(), correcting
    background noise with subtr_bg() in accordance with Zhao et al. (2007)
    <doi:10.1366/000370207782597003>, and identifying spectra using an onboard
    reference library (Cowger et al. 2020, <doi:10.1177/0003702820929064>).
    Analyzed spectra can be shared with the Open Specy community. A Shiny app is
    available via run_app() or online at
    <https://openanalysis.org/openspecy/>.",2022-07-06,Win Cowger,https://github.com/wincowgerDEV/OpenSpecy-package/,TRUE,https://github.com/wincowgerdev/openspecy-package,5199,8,2022-07-06T09:11:08Z,649.875
openssl,"Bindings to OpenSSL libssl and libcrypto, plus custom SSH key parsers.
    Supports RSA, DSA and EC curves P-256, P-384, P-521, and curve25519. Cryptographic
    signatures can either be created and verified manually or via x509 certificates. 
    AES can be used in cbc, ctr or gcm mode for symmetric encryption; RSA for asymmetric
    (public key) encryption or EC for Diffie Hellman. High-level envelope functions 
    combine RSA and AES for encrypting arbitrary sized data. Other utilities include key
    generators, hash functions (md5, sha1, sha256, etc), base64 encoder, a secure random
    number generator, and 'bignum' math methods for manually performing crypto 
    calculations on large multibyte integers.",2022-05-24,Jeroen Ooms,https://github.com/jeroen/openssl,TRUE,https://github.com/jeroen/openssl,19407090,57,2022-05-24T09:49:07Z,340475.2631578947
openSTARS,"An open source implementation of the 'STARS' toolbox
    (Peterson & Ver Hoef, 2014, <doi:10.18637/jss.v056.i02>) using 'R' and 'GRASS GIS'.
    It prepares the *.ssn object needed for the 'SSN' package.
    A Digital Elevation Model (DEM) is used to derive stream networks 
    (in contrast to 'STARS' that can clean an existing stream network).",2022-02-04,Mira Kattwinkel,https://github.com/MiKatt/openSTARS,TRUE,https://github.com/mikatt/openstars,18528,32,2022-06-13T14:41:25Z,579
opentimsr,"A free, open-source package designed for
    handling .tdf data files produced by Bruker's 'timsTOF' mass
    spectrometers.
    Fast, free, crossplatform, with no reading through
    EULAs or messing with binary .dll files involved.",2022-03-29,Michał Piotr Startek,https://github.com/michalsta/opentims,TRUE,https://github.com/michalsta/opentims,8345,23,2022-06-08T12:22:16Z,362.82608695652175
opentripplanner,"Setup and connect to 'OpenTripPlanner' (OTP) <http://www.opentripplanner.org/>.
    OTP is an open source platform for multi-modal and multi-agency
    journey planning written in 'Java'. The package allows you to manage a local version or 
    connect to remote OTP server to find walking, cycling, driving, or transit routes.
    This package has been peer-reviewed by rOpenSci (v. 0.2.0.0).",2022-01-20,Malcolm Morgan,"https://github.com/ropensci/opentripplanner,
https://docs.ropensci.org/opentripplanner/",TRUE,https://github.com/ropensci/opentripplanner,18707,61,2022-01-20T20:14:27Z,306.672131147541
openVA,"Implements multiple existing open-source algorithms for coding cause of death from verbal autopsies. The methods implemented include 'InterVA4' by Byass et al (2012) <doi:10.3402/gha.v5i0.19281>, 'InterVA5' by Byass at al (2019) <doi:10.1186/s12916-019-1333-6>, 'InSilicoVA' by McCormick et al (2016) <doi:10.1080/01621459.2016.1152191>, 'NBC' by Miasnikof et al (2015) <doi:10.1186/s12916-015-0521-2>, and a replication of 'Tariff' method by James et al (2011) <doi:10.1186/1478-7954-9-31> and Serina, et al. (2015) <doi:10.1186/s12916-015-0527-9>. It also provides tools for data manipulation tasks commonly used in Verbal Autopsy analysis and implements easy graphical visualization of individual and population level statistics. The 'NBC' method is implemented by the 'nbc4va' package that can be installed from <https://github.com/rrwen/nbc4va>. Note that this package was not developed by authors affiliated with the Institute for Health Metrics and Evaluation and thus unintentional discrepancies may exist in the implementation of the 'Tariff' method.",2022-03-14,Zehang Richard Li,https://github.com/verbal-autopsy-software/openVA,TRUE,https://github.com/verbal-autopsy-software/openva,21083,2,2022-03-31T17:22:07Z,10541.5
openxlsx,"Simplifies the creation of Excel .xlsx files by providing a
    high level interface to writing, styling and editing worksheets.
    Through the use of 'Rcpp', read/write times are comparable to the
    'xlsx' and 'XLConnect' packages with the added benefit of removing the
    dependency on Java.",2021-12-14,Philipp Schauberger,"https://ycphs.github.io/openxlsx/index.html,
https://github.com/ycphs/openxlsx",TRUE,https://github.com/ycphs/openxlsx,9156272,159,2022-07-10T09:14:35Z,57586.61635220126
opera,"Misc methods to form online predictions, for regression-oriented 
    time-series, by combining a finite set of forecasts provided by the user. See 
             Cesa-Bianchi and Lugosi (2006) <doi:10.1017/CBO9780511546921> for an overview. ",2021-12-06,Pierre Gaillard,http://pierre.gaillard.me/opera.html,TRUE,https://github.com/dralliag/opera,37815,37,2021-12-07T09:00:52Z,1022.027027027027
opitools,"Designed for performing impact analysis of
  opinions in a digital text document (DTD). The 
  package allows a user to assess the extent to which a theme
  or subject within a document impacts the overall opinion 
  expressed in the document. The package can be applied to a wide 
  range of opinion-based DTD, including commentaries on social media
  platforms (such as 'Facebook', 'Twitter' and 'Youtube'), 
  online products reviews, and so on. 
  The utility of 'opitools' was originally demonstrated 
  in Adepeju and Jimoh (2021) <doi:10.31235/osf.io/c32qh> in the 
  assessment of COVID-19 impacts on neighbourhood policing using 
  Twitter data. Further examples can be found in the vignette of 
  the package.",2021-07-29,Monsuru Adepeju,https://github.com/MAnalytics/opitools,TRUE,https://github.com/manalytics/opitools,4754,13,2022-02-08T23:44:51Z,365.6923076923077
oppr,"A decision support tool for prioritizing conservation projects.
    Prioritizations can be developed by maximizing expected feature richness,
    expected phylogenetic diversity, the number of features that meet
    persistence targets, or identifying a set of projects that meet persistence
    targets for minimal cost. Constraints (e.g. lock in specific actions) and
    feature weights can also be specified to further customize prioritizations.
    After defining a project prioritization problem, solutions can be obtained
    using exact algorithms, heuristic algorithms, or random processes. In
    particular, it is recommended to install the 'Gurobi' optimizer (available
    from <https://www.gurobi.com>) because it can identify optimal solutions
    very quickly. Finally, methods are provided for comparing different
    prioritizations and evaluating their benefits. For more information, see
    Hanson et al. (2019) <doi:10.1111/2041-210X.13264>.",2021-05-12,Jeffrey O Hanson,https://prioritizr.github.io/oppr/,TRUE,https://github.com/prioritizr/oppr,21423,5,2021-11-08T06:13:56Z,4284.6
optedr,"Calculates D-, Ds-, A- and I-optimal designs for non-linear models, via an implementation of the cocktail algorithm (Yu, 2011, <doi:10.1007/s11222-010-9183-2>). Compares designs via their efficiency, and D-augments any design with a controlled efficiency. An efficient rounding function has been provided to transform approximate designs to exact designs.",2022-01-20,Carlos de la Calle-Arroyo,https://github.com/kezrael/optedr,TRUE,https://github.com/kezrael/optedr,2098,1,2022-01-20T09:03:16Z,2098
optimall,"Functions for the design process of survey sampling, with specific tools for multi-wave and multi-phase designs. Perform optimum allocation using Neyman (1934) <doi:10.2307/2342192> or Wright (2012) <doi:10.1080/00031305.2012.733679> allocation, split strata based on quantiles or values of known variables, randomly select samples from strata, allocate sampling waves iteratively, and organize a complex survey design. Also includes a Shiny application for observing the effects of different strata splits.",2022-02-09,Jasper Yang,https://github.com/yangjasp/optimall,TRUE,https://github.com/yangjasp/optimall,3665,4,2022-01-27T22:29:46Z,916.25
optimg,"Provides general purpose tools for helping users to implement steepest
             gradient descent methods for function optimization; for details see
             Ruder (2016) <arXiv:1609.04747v2>. Currently, the Steepest 2-Groups
             Gradient Descent and the Adaptive Moment Estimation (Adam) are the
             methods implemented. Other methods will be implemented in the future.",2021-10-07,Vithor Rosa Franco,https://github.com/vthorrf/optimg,TRUE,https://github.com/vthorrf/optimg,3688,0,2022-04-11T23:44:25Z,NA
optimization,"Flexible optimizer with numerous input specifications for detailed
  parameterisation. Designed for complex loss functions with state and 
  parameter space constraints. Visualization tools for validation and analysis
  of the convergence are included.",2022-02-15,Kai Husmann,https://github.com/kaihusmann/optimization,TRUE,https://github.com/kaihusmann/optimization,57254,2,2022-02-15T12:20:52Z,28627
optmatch,"Distance based bipartite matching using minimum cost flow, oriented
    to matching of treatment and control groups in observational studies (Hansen
    and Klopfer 2006 <doi:10.1198/106186006X137047>). Routines are provided to
    generate distances from generalised linear models (propensity score
    matching), formulas giving variables on which to limit matched distances,
    stratified or exact matching directives, or calipers, alone or in
    combination.",2022-05-16,Josh Errickson,"https://github.com/markmfredrickson/optmatch,
https://markmfredrickson.github.io/optmatch/",TRUE,https://github.com/markmfredrickson/optmatch,218993,41,2022-05-26T13:27:12Z,5341.292682926829
optparse,"A command line parser inspired by Python's 'optparse' library to
    be used with Rscript to write ""#!"" shebang scripts that accept short and
    long flag/options.",2021-10-08,Trevor L Davis,https://github.com/trevorld/r-optparse,TRUE,https://github.com/trevorld/r-optparse,894682,117,2021-10-08T18:44:39Z,7646.854700854701
ordbetareg,"Implements ordered beta regression models, which are for modeling continuous variables with upper and lower bounds, such as
   survey sliders, dose-response relationships and indexes. For more information, see
   Kubinec (2022) <doi:10.31235/osf.io/2sx6y>. The package is a front-end to the R package 'brms', which 
   facilitates a range of regression specifications, including hierarchical, dynamic and
   multivariate modeling.",2022-02-25,Robert Kubinec,NA,TRUE,https://github.com/saudiwin/ordbetareg_pack,1689,0,2022-03-18T11:15:13Z,NA
orderly,"Order, create and store reports from R.  By defining a
    lightweight interface around the inputs and outputs of an
    analysis, a lot of the repetitive work for reproducible research
    can be automated.  We define a simple format for organising and
    describing work that facilitates collaborative reproducible
    research and acknowledges that all analyses are run multiple
    times over their lifespans.",2021-09-22,Rich FitzJohn,"https://www.vaccineimpact.org/orderly/,
https://github.com/vimc/orderly",TRUE,https://github.com/vimc/orderly,14792,104,2022-05-16T15:58:05Z,142.23076923076923
ordinalbayes,"Provides a function for fitting various penalized Bayesian
    cumulative link ordinal response models when the number of parameters
    exceeds the sample size. These models have been described in 
    Zhang and Archer (2021) <doi:10.1186/s12859-021-04432-w>.",2022-04-06,Kellie J. Archer,https://github.com/kelliejarcher/ordinalbayes,TRUE,https://github.com/kelliejarcher/ordinalbayes,1138,1,2022-04-19T12:11:14Z,1138
ore,"Provides an alternative to R's built-in functionality for handling
    regular expressions, based on the Onigmo library. Offers first-class
    compiled regex objects, partial matching and function-based substitutions,
    amongst other features.",2021-11-02,Jon Clayden,https://github.com/jonclayden/ore,TRUE,https://github.com/jonclayden/ore,91692,56,2021-11-08T15:53:35Z,1637.357142857143
orf,"An implementation of the Ordered Forest estimator as developed 
    in Lechner & Okasa (2019) <arXiv:1907.02436>. The Ordered Forest flexibly
    estimates the conditional probabilities of models with ordered categorical
    outcomes (so-called ordered choice models). Additionally to common machine 
    learning algorithms the 'orf' package provides functions for estimating
    marginal effects as well as statistical inference thereof and thus provides
    similar output as in standard econometric models for ordered choice. The
    core forest algorithm relies on the fast C++ forest implementation from
    the 'ranger' package (Wright & Ziegler, 2017) <arXiv:1508.04409>.",2020-01-31,Gabriel Okasa,https://github.com/okasag/orf,TRUE,https://github.com/okasag/orf,11160,10,2021-07-19T08:50:05Z,1116
origami,"A general framework for the application of cross-validation schemes
    to particular functions. By allowing arbitrary lists of results, origami
    accommodates a range of cross-validation applications. This implementation
    was first described by Coyle and Hejazi (2018) <doi:10.21105/joss.00512>.",2021-09-28,Jeremy Coyle,https://tlverse.org/origami/,TRUE,https://github.com/tlverse/origami,24391,25,2021-09-27T20:06:06Z,975.64
origin,"Automatically adding 'pkg::' to a function, i.e. mutate()
    becomes dplyr::mutate(). It is up to the user to determine which
    packages should be used explicitly, whether to include base R packages
    or use the functionality on selected text, a file, or a complete
    directory. User friendly logging is provided in the 'RStudio' Markers
    pane. Lives in the spirit of 'lintr' and 'styler'.",2021-09-22,Matthias Nistler,https://github.com/mnist91/origin,TRUE,https://github.com/mnist91/origin,3151,5,2021-09-22T09:34:03Z,630.2
oro.nifti,"Functions for the input/output and visualization of
    medical imaging data that follow either the 'ANALYZE', 'NIfTI' or 'AFNI'
    formats.  This package is part of the Rigorous Analytics bundle.",2022-06-10,Brandon Whitcher,https://rigorousanalytics.blogspot.com,TRUE,https://github.com/bjw34032/oro.nifti,67525,2,2022-06-17T13:17:49Z,33762.5
orthogonalsplinebasis,"Represents the basis functions for B-splines in a simple matrix
    formulation that facilitates, taking integrals, derivatives, and
    making orthogonal the basis functions.",2022-05-23,Andrew Redd,https://github.com/halpo/obsplines,TRUE,https://github.com/halpo/obsplines,21498,0,2022-05-23T20:42:33Z,NA
oscar,"Optimal Subset Cardinality Regression (OSCAR) models offer
    regularized linear regression using the L0-pseudonorm, conventionally
    known as the number of non-zero coefficients. The package estimates an
    optimal subset of features using the L0-penalization via
    cross-validation, bootstrapping and visual diagnostics. Effective
    Fortran implementations are offered along the package for finding
    optima for the DC-decomposition, which is used for transforming the
    discrete L0-regularized optimization problem into a continuous
    non-convex optimization task. These optimization modules include DBDC
    ('Double Bundle method for nonsmooth DC optimization' as described in
    Joki et al. (2018) <doi:10.1137/16M1115733>) and LMBM ('Limited
    Memory Bundle Method for large-scale nonsmooth optimization' as
    in Haarala et al. (2004) <doi:10.1080/10556780410001689225>).
    Multiple regression model families are supported: Cox, logistic,
    and Gaussian.",2022-05-23,Teemu Daniel Laajala,https://github.com/Syksy/oscar,TRUE,https://github.com/syksy/oscar,350,1,2022-06-01T14:18:32Z,350
osfr,"An interface for interacting with 'OSF' (<https://osf.io>). 'osfr' 
    enables you to access open research materials and data, or create and
    manage your own private or public projects.",2020-02-17,Aaron Wolen,"https://docs.ropensci.org/osfr, https://github.com/ropensci/osfr",TRUE,https://github.com/ropensci/osfr,16081,126,2022-05-02T13:17:53Z,127.62698412698413
osmextract,"Match, download, convert and import Open Street Map data extracts 
    obtained from several providers. ",2021-10-27,Andrea Gilardi,"https://docs.ropensci.org/osmextract/,
https://github.com/ropensci/osmextract",TRUE,https://github.com/ropensci/osmextract,15770,130,2022-06-19T18:52:21Z,121.3076923076923
osmplotr,"Bespoke images of 'OpenStreetMap' ('OSM') data and data
    visualisation using 'OSM' objects.",2021-03-28,Mark Padgham,"https://docs.ropensci.org/osmplotr/,
https://github.com/ropensci/osmplotr",TRUE,https://github.com/ropensci/osmplotr,29228,124,2022-03-23T15:00:30Z,235.70967741935485
osrm,"An interface between R and the 'OSRM' API. 'OSRM' is a routing
    service based on 'OpenStreetMap' data. See <http://project-osrm.org/> for more
    information. This package allows to compute routes, trips, isochrones and
    travel distances matrices (travel time and kilometric distance).",2022-01-24,Timothée Giraud,https://github.com/riatelab/osrm,TRUE,https://github.com/riatelab/osrm,57572,187,2022-07-07T12:47:32Z,307.8716577540107
Ostats,"O-statistics, or overlap statistics, measure the degree of community-level trait overlap. 
    They are estimated by fitting nonparametric kernel density functions to each species’ trait 
    distribution and calculating their areas of overlap. For instance, the median pairwise overlap 
    for a community is calculated by first determining the overlap of each species pair 
    in trait space, and then taking the median overlap of each species pair in a community. 
    This median overlap value is called the O-statistic (O for overlap).
    The Ostats() function calculates separate univariate overlap statistics for each trait, 
    while the Ostats_multivariate() function calculates a single multivariate overlap statistic for all traits. 
    O-statistics can be evaluated against null models to obtain standardized effect sizes. 
    'Ostats' is part of the collaborative Macrosystems Biodiversity Project ""Local- to continental-scale 
    drivers of biodiversity across the National Ecological Observatory Network (NEON)."" 
    For more information on this project, see the Macrosystems Biodiversity Website 
    (<https://neon-biodiversity.github.io/>). Calculation of O-statistics is described in
    Read et al. (2018) <doi:10.1111/ecog.03641>, and a teaching module for introducing the
    underlying biological concepts at an undergraduate level is described in Grady et al.
    (2018) <http://tiee.esa.org/vol/v14/issues/figure_sets/grady/abstract.html>.",2021-11-16,Quentin D. Read,https://neon-biodiversity.github.io/Ostats/,TRUE,https://github.com/neon-biodiversity/ostats,8318,7,2021-11-17T00:11:03Z,1188.2857142857142
otp,"Generating and validating One-time Password based on 
    Hash-based Message Authentication Code (HOTP) 
    and Time Based One-time Password (TOTP)
    according to RFC 4226 <https://tools.ietf.org/html/rfc4226> and
    RFC 6238 <https://tools.ietf.org/html/rfc6238>.",2020-05-05,Randy Lai,https://github.com/randy3k/otp,TRUE,https://github.com/randy3k/otp,7366,13,2021-11-09T17:22:14Z,566.6153846153846
otsad,"Implements a set of online fault detectors for time-series, called: PEWMA see M. Carter
             et al. (2012) <doi:10.1109/SSP.2012.6319708>, SD-EWMA and TSSD-EWMA see H. Raza et al. 
             (2015) <doi:10.1016/j.patcog.2014.07.028>, KNN-CAD see E. Burnaev et al. (2016)
             <arXiv:1608.04585>, KNN-LDCD see V. Ishimtsev et al. (2017) <arXiv:1706.03412> and 
             CAD-OSE see M. Smirnov (2018) <https://github.com/smirmik/CAD>. The first three 
             algorithms belong to prediction-based techniques and the last three belong to 
             window-based techniques. In addition, the SD-EWMA and PEWMA algorithms are algorithms 
             designed to work in stationary environments, while the other four 
             are algorithms designed to work in non-stationary environments.",2019-09-06,Alaiñe Iturria,https://github.com/alaineiturria/otsad,TRUE,https://github.com/alaineiturria/otsad,13785,23,2022-04-07T11:53:52Z,599.3478260869565
ottrpal,"Tools for converting Open-Source Tools for Training Resources (OTTR)
  courses into Leanpub or Coursera courses. 'ottrpal' is for use with the OTTR Template repository to create courses.",2022-03-03,Candace Savonen,https://github.com/jhudsl/ottrpal,TRUE,https://github.com/jhudsl/ottrpal,1123,1,2022-06-13T17:12:50Z,1123
otuSummary,"Summarizes the taxonomic composition, diversity contribution of the rare and abundant community by using OTU (operational taxonomic unit) table which was generated by analyzing pipeline of 'QIIME' or 'mothur'. The rare biosphere in this package is subset by the relative abundance threshold (for details about rare biosphere please see Lynch and Neufeld (2015) <doi:10.1038/nrmicro3400>).",2020-03-31,Sizhong Yang,https://github.com/cam315/otuSummary,TRUE,https://github.com/cam315/otusummary,12717,0,2022-05-28T09:04:56Z,NA
ouch,Fit and compare Ornstein-Uhlenbeck models for evolution along a phylogenetic tree.,2022-05-16,Aaron A. King,https://kingaa.github.io/ouch/,TRUE,https://github.com/kingaa/ouch,30391,10,2022-05-18T19:09:26Z,3039.1
outbreaks,"Empirical or simulated disease outbreak data, provided either as
    RData or as text files.",2020-09-28,Finlay Campbell,https://github.com/reconhub/outbreaks,TRUE,https://github.com/reconhub/outbreaks,37143,48,2021-08-06T09:03:21Z,773.8125
outerbase,"High-dimensional regression using outer product models.  Research on the methods is currently under investigation and published resources will be posted as they are available.  As the method is new, the website is the best resource for understanding the principals. Some of the core ideas are based on Plumlee and coauthors' work on analysis of grid-structured  experiments described in Plumlee (2014) <doi:10.1080/01621459.2014.900250> and  Plumlee, Erickson, Ankenman, Lawrence (2021) <doi:10.1093/biomet/asaa084>.  Some additional textbooks for additional information on Gaussian processes are Rasmussen and Williams (2005) <doi:10.7551/mitpress/3206.001.0001> and  Gramacy (2022) <doi:10.1201/9780367815493>.",2022-06-09,Matthew Plumlee,"https://mattplumlee.github.io/outerbase/,
https://github.com/MattPlumlee/outerbase/",TRUE,https://github.com/mattplumlee/outerbase,226,2,2022-06-08T16:21:53Z,113
outForest,"Provides a random forest based implementation of the method
    described in Chapter 7.1.2 (Regression model based anomaly detection)
    of Chandola et al. (2009) <doi:10.1145/1541880.1541882>. It works as
    follows: Each numeric variable is regressed onto all other variables
    by a random forest. If the scaled absolute difference between observed
    value and out-of-bag prediction of the corresponding random forest is
    suspiciously large, then a value is considered an outlier. The package
    offers different options to replace such outliers, e.g. by realistic
    values found via predictive mean matching. Once the method is trained
    on a reference data, it can be applied to new data.",2022-01-31,Michael Mayer,https://github.com/mayer79/outForest,TRUE,https://github.com/mayer79/outforest,13834,8,2022-02-10T06:25:56Z,1729.25
outliertree,"Outlier detection method that flags suspicious values within observations,
  constrasting them against the normal values in a user-readable format, potentially
  describing conditions within the data that make a given outlier more rare.
  Full procedure is described in Cortes (2020) <arXiv:2001.00636>.
  Loosely based on the 'GritBot' <https://www.rulequest.com/gritbot-info.html> software.",2022-02-17,David Cortes,https://github.com/david-cortes/outliertree,TRUE,https://github.com/david-cortes/outliertree,28111,43,2022-05-30T20:05:43Z,653.7441860465116
OUwie,Estimates rates for continuous character evolution under Brownian motion and a new set of Ornstein-Uhlenbeck based Hansen models that allow both the strength of the pull and stochastic motion to vary across selective regimes. Beaulieu et al (2012).,2022-06-15,Jeremy M. Beaulieu,https://github.com/thej022214/OUwie,TRUE,https://github.com/thej022214/ouwie,33541,5,2022-06-09T01:03:28Z,6708.2
overviewR,"Makes it easy to display descriptive information on a data
    set.  Getting an easy overview of a data set by displaying and
    visualizing sample information in different tables (e.g., time and
    scope conditions).  The package also provides publishable 'LaTeX' code
    to present the sample information.",2022-04-15,Cosima Meyer,https://github.com/cosimameyer/overviewR,TRUE,https://github.com/cosimameyer/overviewr,10169,26,2022-05-21T16:15:31Z,391.11538461538464
OwenQ,"Evaluates the Owen Q-function for an integer value of the degrees of freedom, by applying Owen's algorithm (1965) <doi:10.1093/biomet/52.3-4.437>. 
    It is useful for the calculation of the power of equivalence tests. ",2022-01-05,Stéphane Laurent,https://github.com/stla/OwenQ,TRUE,https://github.com/stla/owenq,13811,0,2022-01-05T14:19:00Z,NA
ows4R,"Provides an Interface to Web-Services defined as standards by the Open Geospatial Consortium (OGC), including Web Feature Service
 (WFS) for vector data, Web Coverage Service (WCS), Catalogue Service (CSW) for ISO/OGC metadata, and associated standards such as the common 
 web-service specification (OWS) and OGC Filter Encoding. Partial support is provided for the Web Map Service (WMS) and Web Processing Service (WPS). 
 The purpose is to add support for additional OGC service standards such as Web Coverage Processing Service (WCPS) or OGC API.",2022-07-05,Emmanuel Blondel,"https://github.com/eblondel/ows4R,
https://eblondel.github.io/ows4R/,
https://www.ogc.org/standards",TRUE,https://github.com/eblondel/ows4r,25791,30,2022-07-05T10:17:25Z,859.7
ox,"Short hand if-else function to easily switch the values depending
  on a logical condition.",2021-12-15,Dawid Kałędkowski,NA,TRUE,https://github.com/gogonzo/ox,1787,2,2021-12-13T21:03:25Z,893.5
ozmaps,"Maps of Australian coastline and administrative regions. Data 
 can be drawn or accessed directly as simple features objects. Includes
 simple functions for country or state maps of Australia and in-built data
 sets of administrative regions from the Australian Bureau of Statistics 
 <https://www.abs.gov.au/>. Layers include electoral divisions and local 
 government areas, simplified from the original sources but with sufficient 
 detail to allow mapping of a local municipality. ",2021-08-03,Michael Sumner,https://github.com/mdsumner/ozmaps,TRUE,https://github.com/mdsumner/ozmaps,25727,16,2021-07-25T11:42:46Z,1607.9375
packageRank,"Compute and visualize the cross-sectional and longitudinal number
    and rank percentile of package downloads from RStudio's CRAN mirror.",2022-03-17,Peter Li,https://github.com/lindbrook/packageRank,TRUE,https://github.com/lindbrook/packagerank,15710,16,2022-07-09T17:39:11Z,981.875
packcircles,Algorithms to find arrangements of non-overlapping circles.,2020-12-12,Michael Bedward,https://github.com/mbedward/packcircles,TRUE,https://github.com/mbedward/packcircles,87894,51,2021-10-21T01:46:51Z,1723.4117647058824
packDAMipd,"A collection of functions to construct Markov model for model-based 
    cost-effectiveness analysis. This includes creating Markov model (both time
    homogenous and time dependent models), decision analysis, sensitivity 
    analysis (deterministic and probabilistic). The package allows estimation 
    of parameters for the Markov model from a given individual patient level 
    data, provided the data file follows some standard data entry rules. ",2021-03-03,Sheeja Manchira Krishnan,https://github.com/sheejamk/packDAMipd,TRUE,https://github.com/sheejamk/packdamipd,5786,1,2022-02-23T23:50:11Z,5786
packer,"
  Enforces good practice and provides convenience functions to make work with 'JavaScript' 
  not just easier but also scalable. It is a robust wrapper to 'NPM', 'yarn', and 'webpack' that 
  enables to compartmentalize 'JavaScript' code, leverage 'NPM' and 'yarn' packages, include
  'TypeScript', 'React', or 'Vue' in web applications, and much more.",2022-05-28,John Coene,"https://github.com/JohnCoene/packer, https://packer.john-coene.com",TRUE,https://github.com/johncoene/packer,12661,123,2022-06-05T21:42:31Z,102.9349593495935
packrat,"Manage the R packages your project depends
    on in an isolated, portable, and reproducible way.",2022-06-29,Kevin Ushey,https://github.com/rstudio/packrat/,TRUE,https://github.com/rstudio/packrat,1763915,378,2022-06-30T16:03:13Z,4666.441798941799
pacotest,"Routines for two different test types, the Constant Conditional Correlation (CCC) test and the Vectorial Independence (VI) test are provided (Kurz and Spanhel (2017) <arXiv:1706.02338>). The tests can be applied to check whether a conditional copula coincides with its partial copula. Functions to test whether a regular vine copula satisfies the so-called simplifying assumption or to test a single copula within a regular vine copula to be a (j-1)-th order partial copula are available. The CCC test comes with a decision tree approach to allow testing in high-dimensional settings.",2021-11-08,Malte S. Kurz,NA,TRUE,https://github.com/maltekurz/pacotest,15645,2,2021-11-08T10:29:15Z,7822.5
pacs,"
  Supplementary utils for CRAN maintainers and R packages developers.
  Validating the library, packages and lock files.
  Exploring a complexity of a specific package like evaluating its size in bytes with all dependencies.
  The shiny app complexity could be explored too.
  Assessing the life duration of a specific package version.
  Checking a CRAN package check page status for any errors and warnings.
  Retrieving a DESCRIPTION or NAMESPACE file for any package version. 
  Comparing DESCRIPTION or NAMESPACE files between different package versions.
  Getting a list of all releases for a specific package.
  The Bioconductor is partly supported.",2022-06-28,Maciej Nasinski,"https://github.com/Polkas/pacs, https://polkas.github.io/pacs/",TRUE,https://github.com/polkas/pacs,5411,10,2022-06-28T19:03:38Z,541.1
Pade,"Given a vector of Taylor series coefficients of sufficient length
    as input, the function returns the numerator and denominator coefficients
    for the Padé approximant of appropriate order (Baker, 1975)
    <ISBN:9780120748556>.",2022-01-19,Avraham Adler,https://github.com/aadler/Pade,TRUE,https://github.com/aadler/pade,17511,0,2022-05-01T17:59:59Z,NA
padr,"Transforms datetime data into a format ready for analysis.
    It offers two core functionalities; aggregating data to a higher level interval
    (thicken) and imputing records where observations were absent (pad). ",2021-10-01,Edwin Thoen,https://github.com/EdwinTh/padr,TRUE,https://github.com/edwinth/padr,960744,121,2021-09-29T14:05:56Z,7940.033057851239
PAFit,Statistical methods for estimating preferential attachment and node fitness generative mechanisms in temporal complex networks are provided. Thong Pham et al. (2015) <doi:10.1371/journal.pone.0137796>. Thong Pham et al. (2016) <doi:10.1038/srep32558>. Thong Pham et al. (2020) <doi:10.18637/jss.v092.i03>. Thong Pham et al. (2021) <doi:10.1093/comnet/cnab024>.  ,2022-01-11,Thong Pham,https://github.com/thongphamthe/PAFit,TRUE,https://github.com/thongphamthe/pafit,25654,13,2022-03-16T04:58:37Z,1973.3846153846155
pagedown,"Use the paged media properties in CSS and the JavaScript
  library 'paged.js' to split the content of an HTML document into discrete
  pages. Each page can have its page size, page numbers, margin boxes, and
  running headers, etc. Applications of this package include books, letters,
  reports, papers, business cards, resumes, and posters.",2022-04-26,Yihui Xie,https://github.com/rstudio/pagedown,TRUE,https://github.com/rstudio/pagedown,114753,759,2022-05-04T16:27:53Z,151.1897233201581
pagemap,Quickly and easily add a mini map to your 'rmarkdown' html documents.,2021-09-02,Wei Su,https://github.com/swsoyee/pagemapR,TRUE,https://github.com/swsoyee/pagemapr,8000,15,2021-08-27T16:26:24Z,533.3333333333334
pagoda2,"Analyzing and interactively exploring large-scale single-cell RNA-seq datasets. 'pagoda2' primarily performs normalization and differential gene expression analysis, with an interactive application for exploring single-cell RNA-seq datasets. It performs basic tasks such as cell size normalization, gene variance normalization, and can be used to identify subpopulations and run differential expression within individual samples. 'pagoda2' was written to rapidly process modern large-scale scRNAseq datasets of approximately 1e6 cells. The companion web application allows users to explore which gene expression patterns form the different subpopulations within your data. The package also serves as the primary method for preprocessing data for conos, <https://github.com/kharchenkolab/conos>. This package interacts with data available through the 'p2data' package, which is available in a 'drat' repository. To access this data package, see the instructions at <https://github.com/kharchenkolab/pagoda2>. The size of the 'p2data' package is approximately 6 MB.",2022-04-19,Evan Biederstedt,https://github.com/kharchenkolab/pagoda2,TRUE,https://github.com/kharchenkolab/pagoda2,12726,134,2022-04-19T21:44:50Z,94.97014925373135
pagoo,"Provides an encapsulated, object-oriented class system for
  analyzing bacterial pangenomes. For a definition of this concept, see
  Tettelin, et al. (2005) <doi:10.1073/pnas.0506758102>. It uses the R6
  package as backend. It was designed in order to facilitate and speed-up
  the comparative analysis of multiple bacterial genomes, standardizing and
  optimizing routine tasks performed everyday. There are a handful of things
  done everyday when working with bacterial pangenomes: subset, summarize,
  extract, visualize and store data. So, 'pagoo' is intended to facilitate these
  tasks as much as possible. For a description of the implemented data structure
  and methods, see Ferres & Iraola (2020), <doi:10.1101/2020.07.29.226951>.",2022-02-01,Ignacio Ferres,"https://iferres.github.io/pagoo/, https://github.com/iferres/pagoo",TRUE,https://github.com/iferres/pagoo,5649,8,2022-05-30T17:55:12Z,706.125
painbow,"XKCD described a supposedly ""bad"" colormap that it called a ""Painbow"" (see <https://xkcd.com/2537/>). But simple tests demonstrate that under some circumstances, the colormap can perform very well, and people can find information that is difficult to detect with the ggplot2 default and even supposedly ""good"" colormaps like viridis. This library let's you use the Painbow in your own ggplot graphs.",2021-11-11,Steve Haroz,https://github.com/steveharoz/painbow,TRUE,https://github.com/steveharoz/painbow,2016,36,2022-02-09T20:11:41Z,56
pairsD3,"Creates an interactive scatterplot matrix using the D3 JavaScript
    library. See <https://d3js.org/> for more information on D3.",2022-06-06,Garth Tarr,https://github.com/garthtarr/pairsD3/,TRUE,https://github.com/garthtarr/pairsd3,20815,53,2022-06-05T09:47:52Z,392.7358490566038
pak,"The goal of 'pak' is to make package installation faster and
    more reliable. In particular, it performs all HTTP operations in parallel,
    so metadata resolution and package downloads are fast. Metadata and package
    files are cached on the local disk as well. 'pak' has a dependency solver,
    so it finds version conflicts before performing the installation. This
    version of 'pak' supports CRAN, 'Bioconductor' and 'GitHub' packages as well.",2022-04-11,Gábor Csárdi,https://pak.r-lib.org/,TRUE,https://github.com/r-lib/pak,259705,430,2022-06-29T07:56:49Z,603.9651162790698
pald,"Implementation of the Partitioned Local Depth (PaLD) 
    approach which provides a measure of local depth and the cohesion of a point 
    to another which  (together with a universal threshold for distinguishing 
    strong and weak ties) may be used to reveal local and global structure in 
    data, based on methods described in Berenhaut, Moore, and Melvin (2022)
    <doi:10.1073/pnas.2003634119>. No extraneous inputs, distributional 
    assumptions, iterative procedures nor optimization criteria are employed. 
    This package includes functions for computing local depths and cohesion as
    well as flexible functions for plotting community networks and displays of 
    cohesion against distance. ",2022-06-03,Lucy DAgostino McGowan,https://github.com/LucyMcGowan/pald,TRUE,https://github.com/lucymcgowan/pald,810,3,2022-06-08T13:37:07Z,270
paleobuddy,"Simulation of species diversification, fossil records, and phylogenies. While the literature on species birth-death simulators is extensive, including important software like 'paleotree' and 'APE', we concluded there were interesting gaps to be filled regarding possible diversification scenarios. Here we strove for flexibility over focus, implementing a large array of regimens for users to experiment with and combine. In this way, 'paleobuddy' can be used in complement to other simulators as a flexible jack of all trades, or, in the case of scenarios implemented only here, can allow for robust and easy simulations for novel situations. Environmental data modified from that in 'RPANDA': Morlon H. et al (2016) <doi:10.1111/2041-210X.12526>.",2021-12-21,Bruno do Rosario Petrucci,https://github.com/brpetrucci/paleobuddy,TRUE,https://github.com/brpetrucci/paleobuddy,1671,1,2022-06-07T22:01:23Z,1671
paleopop,"This extension of the poems pattern-oriented modeling (POM) framework
    provides a collection of modules and functions customized for paleontological
    time-scales, and optimized for single-generation transitions and large populations,
    across multiple generations.",2021-10-14,Julia Pilowsky,https://github.com/GlobalEcologyLab/paleopop/,TRUE,https://github.com/globalecologylab/paleopop,4942,4,2022-03-01T01:01:36Z,1235.5
paleotree,"Provides tools for transforming, a posteriori time-scaling, and
    modifying phylogenies containing extinct (i.e. fossil) lineages. In particular,
    most users are interested in the functions timePaleoPhy, bin_timePaleoPhy,
    cal3TimePaleoPhy and bin_cal3TimePaleoPhy, which date cladograms of
    fossil taxa using stratigraphic data. This package also contains a large number
    of likelihood functions for estimating sampling and diversification rates from
    different types of data available from the fossil record (e.g. range data,
    occurrence data, etc). paleotree users can also simulate diversification and
    sampling in the fossil record using the function simFossilRecord, which is a
    detailed simulator for branching birth-death-sampling processes composed of
    discrete taxonomic units arranged in ancestor-descendant relationships. Users
    can use simFossilRecord to simulate diversification in incompletely sampled
    fossil records, under various models of morphological differentiation (i.e.
    the various patterns by which morphotaxa originate from one another), and
    with time-dependent, longevity-dependent and/or diversity-dependent rates of
    diversification, extinction and sampling. Additional functions allow users to
    translate simulated ancestor-descendant data from simFossilRecord into standard
    time-scaled phylogenies or unscaled cladograms that reflect the relationships
    among taxon units.",2022-04-25,David W. Bapst,https://github.com/dwbapst/paleotree,TRUE,https://github.com/dwbapst/paleotree,33736,16,2022-05-06T14:34:59Z,2108.5
paletteer,"The choices of color palettes in R can be quite
    overwhelming with palettes spread over many packages with many
    different API's. This packages aims to collect all color palettes
    across the R ecosystem under the same package with a streamlined API.",2021-07-20,See AUTHORS file.,https://github.com/EmilHvitfeldt/paletteer,TRUE,https://github.com/emilhvitfeldt/paletteer,244546,673,2021-11-22T00:11:45Z,363.36701337295693
paletteknife,"Streamlines the steps for adding colour scales and associated legends 
         when working with base R graphics, especially for interactive use. Popular
         palettes are included and pretty legends produced when mapping a large 
         variety of vector classes to a colour scale. An additional helper for 
         adding axes and grid lines complements the base::plot() work flow.",2022-04-20,John Hobbs,https://github.com/johnxhobbs/paletteknife,TRUE,https://github.com/johnxhobbs/paletteknife,3292,0,2022-04-20T16:03:40Z,NA
palmerpenguins,"Size measurements, clutch observations, and blood isotope ratios for adult foraging Adélie, Chinstrap, and Gentoo penguins observed on islands in the Palmer Archipelago near Palmer Station, Antarctica. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station Long Term Ecological Research (LTER) Program. ",2020-07-23,Allison Horst,"https://allisonhorst.github.io/palmerpenguins/,
https://github.com/allisonhorst/palmerpenguins",TRUE,https://github.com/allisonhorst/palmerpenguins,520072,678,2022-04-21T15:15:33Z,767.0678466076696
palmid,"R Analysis suite for viral RNA dependent RNA polymerase (RdRP). 
    Statistical and meta-data analysis of 'palmscan' output and 'palmDB'/
    'DIAMOND' alignment files. Cross reference an input RNA virus against
    145,000 RdRP identified in the Serratus project.",2021-10-15,Artem Babaian,https://serratus.io/palmid,TRUE,https://github.com/ababaian/palmid,2822,4,2021-11-17T10:21:51Z,705.5
PALMO,"It is a platform for analyzing longitudinal data from bulk as well as single cell datasets. It allows to identify variations in molecular features within and across donors over longitudinal time points. The analysis can be done on bulk expression dataset without known cell type information or single cell with cell type/user-defined groups. It allows to infer stable and variable features in given donor and each cell type (or user defined group). The outlier analysis can be performed to identify technical/biological perturbed samples in donor/participant. Further, differential analysis can be performed to decipher time-wise changes in gene expression in a cell type.",2022-06-01,Suhas Vasaikar,https://github.com/aifimmunology/PALMO,TRUE,https://github.com/aifimmunology/palmo,485,0,2022-05-25T22:31:30Z,NA
pals,"A comprehensive collection of color palettes, colormaps, and tools to evaluate them.",2021-04-17,Kevin Wright,https://kwstat.github.io/pals/,TRUE,https://github.com/kwstat/pals,123282,65,2021-10-20T15:15:17Z,1896.6461538461538
pammtools,"The Piece-wise exponential (Additive Mixed) Model
    (PAMM; Bender and others (2018) <doi: 10.1177/1471082X17748083>) is a
    powerful model class for the analysis of survival (or time-to-event) data,
    based on Generalized Additive (Mixed) Models (GA(M)Ms). It offers intuitive specification and robust estimation of complex survival models with stratified baseline hazards, random effects, time-varying effects, time-dependent covariates and cumulative effects (Bender and others (2019)), as well as support for left-truncated, competing risks and recurrent events data.
    pammtools provides tidy workflow for survival analysis with PAMMs,
    including data simulation, transformation and other functions for data
    preprocessing and model post-processing as well as visualization.",2022-01-09,Andreas Bender,https://adibender.github.io/pammtools/,TRUE,https://github.com/adibender/pammtools,31018,39,2022-05-05T16:31:41Z,795.3333333333334
pander,"Contains some functions catching all messages, 'stdout' and other
    useful information while evaluating R code and other helpers to return user
    specified text elements (like: header, paragraph, table, image, lists etc.)
    in 'pandoc' markdown or several type of R objects similarly automatically
    transformed to markdown format. Also capable of exporting/converting (the
    resulting) complex 'pandoc' documents to e.g. HTML, 'PDF', 'docx' or 'odt'. This
    latter reporting feature is supported in brew syntax or with a custom reference
    class with a smarty caching 'backend'.",2022-03-18,Gergely Daróczi,https://rapporter.github.io/pander/,TRUE,https://github.com/rapporter/pander,1231959,278,2022-03-17T22:16:08Z,4431.507194244605
pandocfilters,"The document converter 'pandoc' <https://pandoc.org/> is widely used
    in the R community. One feature of 'pandoc' is that it can produce and consume
    JSON-formatted abstract syntax trees (AST). This allows to transform a given
    source document into JSON-formatted AST, alter it by so called filters and pass
    the altered JSON-formatted AST back to 'pandoc'. This package provides functions
    which allow to write such filters in native R code. 
    Although this package is inspired by the Python package 'pandocfilters' 
    <https://github.com/jgm/pandocfilters/>, it provides additional convenience functions which make it simple to use the 'pandocfilters' package as a 
    report generator. Since 'pandocfilters' inherits most of it's functionality
    from 'pandoc' it can create documents in many formats 
    (for more information see <https://pandoc.org/>) but is also bound to the same
    limitations as 'pandoc'.",2022-05-06,Florian Schwendinger,"https://pandoc.org/, https://github.com/jgm/pandocfilters/",TRUE,https://github.com/jgm/pandocfilters,24626,416,2021-09-14T03:49:12Z,59.19711538461539
PanelMatch,"Implements a set of methodological tools
	     that enable researchers to apply matching methods to
	     time-series cross-sectional data. Imai, Kim, and Wang
	     (2021) <http://web.mit.edu/insong/www/pdf/tscs.pdf> 
	     proposes a nonparametric generalization of the
	     difference-in-differences estimator, which does not rely
	     on the linearity assumption as often done in
	     practice. Researchers first select a method of matching
	     each treated observation for a given unit in a
	     particular time period with control observations from
	     other units in the same time period that have a similar
	     treatment and covariate history. These methods include
	     standard matching methods based on propensity score and
	     Mahalanobis distance, as well as weighting methods. Once 
	     matching is done, both short-term and long-term average 
	     treatment effects for the treated can be estimated with 
	     standard errors. The package also offers a visualization 
	     technique that allows researchers to assess the quality 
	     of matches by examining the resulting covariate balance.",2022-06-26,In Song Kim,NA,TRUE,https://github.com/insongkim/panelmatch,14864,70,2022-06-06T01:40:31Z,212.34285714285716
panelr,"Provides an object type and associated tools for storing and 
  wrangling panel data. Implements several methods for creating regression
  models that take advantage of the unique aspects of 
  panel data. Among other capabilities, automates the ""within-between"" 
  (also known as ""between-within"" and ""hybrid"") panel regression specification
  that combines the desirable aspects of both fixed effects and random effects 
  econometric models and fits them as multilevel models 
  (Allison, 2009 <doi:10.4135/9781412993869.d33>; 
  Bell & Jones, 2015 <doi:10.1017/psrm.2014.7>). These models can also be 
  estimated via generalized estimating equations 
  (GEE; McNeish, 2019 <doi:10.1080/00273171.2019.1602504>) and Bayesian 
  estimation is (optionally) supported via 'Stan'. 
  Supports estimation of asymmetric effects models via first differences
  (Allison, 2019 <doi:10.1177/2378023119826441>) as well as a generalized
  linear model extension thereof using GEE. ",2021-12-17,Jacob A. Long,https://panelr.jacob-long.com,TRUE,https://github.com/jacob-long/panelr,88493,84,2021-12-16T19:03:03Z,1053.4880952380952
panstarrs,"An interface to the API for 'Pan-STARRS1', a data archive of
    the PS1 wide-field astronomical survey.  The package allows access to
    the PS1 catalog and to the PS1 images.  (see
    <https://outerspace.stsci.edu/display/PANSTARRS/> for more
    information).  You can use it to plan astronomical observations, make
    guidance pictures, find magnitudes in five broadband filters (g, r, i,
    z, y) and more.",2022-02-07,Grigory Uskov,https://uskovgs.github.io/PanSTARRS/,TRUE,https://github.com/uskovgs/panstarrs,1391,0,2022-02-15T19:17:19Z,NA
papaja,"Tools to create dynamic, submission-ready manuscripts, which
  conform to American Psychological Association manuscript guidelines. We
  provide R Markdown document formats for manuscripts (PDF and Word) and
  revision letters (PDF). Helper functions facilitate reporting statistical
  analyses or create publication-ready tables and plots.",2022-07-05,Frederik Aust,https://github.com/crsh/papaja,TRUE,https://github.com/crsh/papaja,940,535,2022-06-28T21:26:25Z,1.7570093457943925
paradox,"Define parameter spaces, constraints and
    dependencies for arbitrary algorithms, to program on such spaces. Also
    includes statistical designs and random samplers. Objects are
    implemented as 'R6' classes.",2022-04-18,Michel Lang,"https://paradox.mlr-org.com, https://github.com/mlr-org/paradox",TRUE,https://github.com/mlr-org/paradox,287458,23,2022-06-24T12:47:19Z,12498.173913043478
parallelDist,"A fast parallelized alternative to R's native 'dist' function to
    calculate distance matrices for continuous, binary, and multi-dimensional
    input matrices, which supports a broad variety of 41 predefined distance
    functions from the 'stats', 'proxy' and 'dtw' R packages, as well as user-
    defined functions written in C++. For ease of use, the 'parDist' function
    extends the signature of the 'dist' function and uses the same parameter
    naming conventions as distance methods of existing R packages. The package
    is mainly implemented in C++ and leverages the 'RcppParallel' package to
    parallelize the distance computations with the help of the 'TinyThread'
    library. Furthermore, the 'Armadillo' linear algebra library is used for
    optimized matrix operations during distance calculations. The curiously
    recurring template pattern (CRTP) technique is applied to avoid virtual
    functions, which improves the Dynamic Time Warping calculations while
    the implementation stays flexible enough to support different DTW step
    patterns and normalization methods.",2022-02-03,Alexander Eckert,"https://github.com/alexeckert/parallelDist,
https://www.alexandereckert.com/projects/#r-packages",TRUE,https://github.com/alexeckert/paralleldist,38878,42,2022-02-14T18:47:29Z,925.6666666666666
ParallelLogger,"Support for parallel computation with progress bar, and option to stop or proceed on errors. Also provides logging to console and disk,
  and the logging persists in the parallel threads. Additional functions support function call automation with delayed execution (e.g. for executing functions in
  parallel).",2022-06-07,Martijn Schuemie,"https://ohdsi.github.io/ParallelLogger/,
https://github.com/OHDSI/ParallelLogger",TRUE,https://github.com/ohdsi/parallellogger,44091,9,2022-06-07T07:55:10Z,4899
parallelly,"Utility functions that enhance the 'parallel' package and support the built-in parallel backends of the 'future' package.  For example, availableCores() gives the number of CPU cores available to your R process as given by the operating system, 'cgroups' and Linux containers, R options, and environment variables, including those set by job schedulers on high-performance compute clusters. If none is set, it will fall back to parallel::detectCores(). Another example is makeClusterPSOCK(), which is backward compatible with parallel::makePSOCKcluster() while doing a better job in setting up remote cluster workers without the need for configuring the firewall to do port-forwarding to your local computer.",2022-06-07,Henrik Bengtsson,"https://parallelly.futureverse.org,
https://github.com/HenrikBengtsson/parallelly",TRUE,https://github.com/henrikbengtsson/parallelly,4365564,90,2022-06-08T21:33:09Z,48506.26666666667
param6,"By making use of 'set6', alongside the S3 and R6 paradigms, this package provides a fast and lightweight R6 interface for parameters and parameter sets.",2022-02-15,Raphael Sonabend,"https://xoopR.github.io/param6/, https://github.com/xoopR/param6/",TRUE,https://github.com/xoopr/param6,31378,8,2022-03-25T21:54:50Z,3922.25
parameters,"Utilities for processing the parameters of various
    statistical models. Beyond computing p values, CIs, and other indices
    for a wide variety of models (see list of supported models using the
    function 'insight::supported_models()'), this package implements
    features like bootstrapping or simulating of parameters and models,
    feature reduction (feature extraction and variable selection) as well
    as functions to describe data and variable characteristics (e.g.
    skewness, kurtosis, smoothness or distribution).",2022-05-29,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>,https://easystats.github.io/parameters/,TRUE,https://github.com/easystats/parameters,1187139,315,2022-07-07T08:51:47Z,3768.695238095238
ParamHelpers,"Functions for parameter descriptions and operations
    in black-box optimization, tuning and machine learning. Parameters can
    be described (type, constraints, defaults, etc.), combined to
    parameter sets and can in general be programmed on. A useful OptPath
    object (archive) to log function evaluations is also provided.",2022-07-04,Bernd Bischl,"https://paramhelpers.mlr-org.com,
https://github.com/mlr-org/ParamHelpers",TRUE,https://github.com/mlr-org/paramhelpers,688714,25,2022-03-09T07:32:10Z,27548.56
paramlink,"NOTE: 'PARAMLINK' HAS BEEN SUPERSEDED BY THE 'PED SUITE'
    PACKAGES (<https://magnusdv.github.io/pedsuite/>). 'PARAMLINK' IS
    MAINTAINED ONLY FOR LEGACY PURPOSES AND SHOULD NOT BE USED IN NEW
    PROJECTS. A suite of tools for analysing pedigrees with marker data,
    including parametric linkage analysis, forensic computations,
    relatedness analysis and marker simulations. The core of the package
    is an implementation of the Elston-Stewart algorithm for pedigree
    likelihoods, extended to allow mutations as well as complex
    inbreeding. Features for linkage analysis include singlepoint LOD
    scores, power analysis, and multipoint analysis (the latter through a
    wrapper to the 'MERLIN' software). Forensic applications include
    exclusion probabilities, genotype distributions and conditional
    simulations. Data from the 'Familias' software can be imported and
    analysed in 'paramlink'. Finally, 'paramlink' offers many utility
    functions for creating, manipulating and plotting pedigrees with or
    without marker data (the actual plotting is done by the 'kinship2'
    package).",2022-04-15,Magnus Dehli Vigeland,https://github.com/magnusdv/paramlink,TRUE,https://github.com/magnusdv/paramlink,19543,0,2022-04-15T07:41:04Z,NA
parcats,"Complex graphical representations of data are best explored using interactive elements.
  'parcats' adds interactive graphing capabilities to the 'easyalluvial' package.
  The 'plotly.js' parallel categories diagrams offer a good framework for
  creating interactive flow graphs that allow manual drag and drop sorting of dimensions
  and categories, highlighting single flows and displaying mouse over information. The
  'plotly.js' dependency is quite heavy and therefore is outsourced into a separate package.",2022-07-08,Bjoern Koneswarakantha,https://erblast.github.io/parcats/,TRUE,https://github.com/erblast/parcats,15802,19,2022-07-09T07:00:04Z,831.6842105263158
parglm,"Provides a parallel estimation method for generalized 
  linear models without compiling with a multithreaded LAPACK or BLAS.",2021-10-14,Benjamin Christoffersen,https://github.com/boennecd/parglm,TRUE,https://github.com/boennecd/parglm,14892,8,2021-10-14T14:57:50Z,1861.5
pARI,"It computes the All-Resolution Inference method in the permutation framework, i.e., simultaneous lower confidence bounds for the number of true discoveries. <arXiv:2012.00368>. ",2022-01-10,Angela Andreella  (Main author,https://github.com/angeella/pARI,TRUE,https://github.com/angeella/pari,2279,4,2022-02-09T08:58:46Z,569.75
parma,Provision of a set of models and methods for use in the allocation and management of capital in financial portfolios.,2022-06-13,Alexios Galanos,https://github.com/alexiosg/parma,TRUE,https://github.com/alexiosg/parma,20757,1,2022-06-13T22:16:39Z,20757
paropt,"Enable optimization of parameters of ordinary differential equations. Therefore, using 'SUNDIALS' to solve the ODE-System (see Hindmarsh, Alan C., Peter N. Brown, Keith E. Grant, Steven L. Lee, Radu Serban, Dan E. Shumaker, and Carol S. Woodward. (2005) <doi:10.1145/1089014.1089020>). Furthermore, for optimization the particle swarm algorithm is used (see: Akman, Devin, Olcay Akman, and Elsa Schaefer. (2018) <doi:10.1155/2018/9160793> and Sengupta, Saptarshi, Sanchita Basak, and Richard Peters. (2018) <doi:10.3390/make1010010>). The ODE-System has to be passed as 'Rcpp'-function. The information for the parameter boundaries and states are conveyed using data.frames.  ",2021-06-14,Krämer Konrad,NA,TRUE,https://github.com/konrad1991/paropt,7961,3,2022-04-06T09:29:18Z,2653.6666666666665
parqr,"Reads in multi-part parquet files. Will read in parquet files that have not been previously coalesced into one file. Convenient for reading in moderately sized, but split files. ",2021-07-15,John Waller,https://github.com/jhnwllr/parqr,TRUE,https://github.com/jhnwllr/parqr,3819,5,2022-01-26T14:46:14Z,763.8
parsedate,"Parse dates automatically, without the need of
    specifying a format. Currently it includes the git date parser.
    It can also recognize and parse all ISO 8601 formats.",2022-02-13,Gábor Csárdi,https://github.com/gaborcsardi/parsedate,TRUE,https://github.com/gaborcsardi/parsedate,726641,57,2022-02-13T12:18:17Z,12748.087719298246
parsel,"A system to increase the efficiency of dynamic web-scraping with 'RSelenium'
    by leveraging parallel processing. You provide a function wrapper for your 'RSelenium' 
    scraping routine with a set of inputs, and 'parsel' runs it in several browser instances. 
    Chunked input processing as well as error catching and logging ensures seamless 
    execution and minimal data loss, even when unforeseen 'RSelenium' errors occur. ",2022-06-08,Till Tietz,https://github.com/till-tietz/parsel,TRUE,https://github.com/till-tietz/parsel,1008,9,2022-06-08T20:14:37Z,112
parsermd,"An implementation of a formal grammar and parser for R Markdown documents
    using the Boost Spirit X3 library. It also includes a collection of high level
    functions for working with the resulting abstract syntax tree.",2021-05-20,Colin Rundel,"https://rundel.github.io/parsermd/,
https://github.com/rundel/parsermd",TRUE,https://github.com/rundel/parsermd,7775,57,2021-08-16T17:45:54Z,136.40350877192984
parsnip,"A common interface is provided to allow users to specify a
    model without having to remember the different argument names across
    different functions or computational engines (e.g. 'R', 'Spark',
    'Stan', etc).",2022-06-16,Max Kuhn,"https://github.com/tidymodels/parsnip,
https://parsnip.tidymodels.org/",TRUE,https://github.com/tidymodels/parsnip,942502,469,2022-06-27T18:44:32Z,2009.5991471215352
partialised,"Provides a 'partialised' class that extends the partialising 
    function of 'purrr' by making it easier to change the arguments. This is 
    similar to the function-like object in 'Julia' 
    (<https://docs.julialang.org/en/v1/manual/methods/#Function-like-objects>).",2022-05-04,Mizuki Uchida,https://github.com/UchidaMizuki/partialised,TRUE,https://github.com/uchidamizuki/partialised,443,1,2022-05-08T10:38:40Z,443
particles,"Simulating particle movement in 2D space has many application. The
    'particles' package implements a particle simulator based on the ideas 
    behind the 'd3-force' 'JavaScript' library. 'particles' implements all 
    forces defined in 'd3-force' as well as others such as vector fields, traps, 
    and attractors.",2019-01-14,Thomas Lin Pedersen,https://github.com/thomasp85/particles,TRUE,https://github.com/thomasp85/particles,12031,119,2021-08-02T10:41:37Z,101.10084033613445
partition,"A fast and flexible framework for agglomerative
    partitioning. 'partition' uses an approach called
    Direct-Measure-Reduce to create new variables that maintain the
    user-specified minimum level of information. Each reduced variable is
    also interpretable: the original variables map to one and only one
    variable in the reduced data set. 'partition' is flexible, as well:
    how variables are selected to reduce, how information loss is
    measured, and the way data is reduced can all be customized.
    'partition' is based on the Partition framework discussed in Millstein
    et al. (2020) <doi: 10.1093/bioinformatics/btz661>.",2021-10-05,Malcolm Barrett,"https://uscbiostats.github.io/partition/,
https://github.com/USCbiostats/partition",TRUE,https://github.com/uscbiostats/partition,15183,33,2021-10-05T12:48:02Z,460.09090909090907
partitions,"Additive partitions of integers.  Enumerates the
  partitions, unequal partitions, and restricted partitions of an
  integer; the three corresponding partition functions are also
  given.  Set partitions and now compositions are included.",2021-10-23,Robin K. S. Hankin,https://github.com/RobinHankin/partitions,TRUE,https://github.com/robinhankin/partitions,278063,7,2022-06-30T20:56:25Z,39723.28571428572
partR2,"Partitioning the R2 of GLMMs into variation explained by each 
    predictor and combination of predictors using semi-partial (part) R2 and
    inclusive R2. Methods are based on the R2 for GLMMs described in
    Nakagawa & Schielzeth (2013) <doi:10.1111/j.2041-210x.2012.00261.x> and
    Nakagawa, Johnson & Schielzeth (2017) <doi:10.1098/rsif.2017.0213>.",2021-01-18,Martin A. Stoffel,https://github.com/mastoffel/partR2,TRUE,https://github.com/mastoffel/partr2,7379,16,2021-08-05T13:29:17Z,461.1875
parzer,"Parse messy geographic coordinates from various character formats
    to decimal degree numeric values. Parse coordinates into
    their parts (degree, minutes, seconds); calculate hemisphere
    from coordinates; pull out individually degrees,
    minutes, or seconds; add and subtract degrees, minutes,
    and seconds. C++ code herein originally inspired from code
    written by Jeffrey D. Bogan, but then completely re-written.",2021-12-20,Scott Chamberlain,"https://github.com/ropensci/parzer (devel)
https://docs.ropensci.org/parzer/ (docs)",TRUE,https://github.com/ropensci/parzer,18731,54,2022-02-17T15:02:02Z,346.8703703703704
PAsso,"An implementation of the unified framework for assessing partial association 
            between ordinal variables after adjusting for a set of covariates (Dungang Liu, Shaobo 
            Li, Yan Yu and Irini Moustaki (2020), accepted by the Journal of the American 
            Statistical Association). This package provides a set of tools to quantify, visualize, 
            and test partial associations between multiple ordinal variables. It can produce a number
            of $phi$ measures, partial regression plots, 3-D plots, and $p$-values for testing 
            $H_0: phi=0$ or $H_0: phi <= delta$.",2021-06-18,Xiaorui (Jeremy) Zhu,GitHub: https://github.com/XiaoruiZhu/PAsso,TRUE,https://github.com/xiaoruizhu/passo,9490,2,2022-02-25T19:36:13Z,4745
pasteAsComment,Provides a 'RStudio' addin allowing to paste the content of the clipboard as a comment block or as 'roxygen' lines. This is very useful to insert an example in the 'roxygen' block.,2022-05-24,Stéphane Laurent,https://github.com/stla/pasteAsComment,TRUE,https://github.com/stla/pasteascomment,335,5,2022-05-21T07:03:58Z,67
pastecs,"Regularisation, decomposition and analysis of space-time series.
  The pastecs R package is a PNEC-Art4 and IFREMER (Benoit Beliaeff
  <Benoit.Beliaeff@ifremer.fr>) initiative to bring PASSTEC 2000 functionalities to R.",2018-03-15,Philippe Grosjean,https://github.com/phgrosjean/pastecs,TRUE,https://github.com/phgrosjean/pastecs,478519,3,2021-08-08T15:42:49Z,159506.33333333334
PASWR2,"Functions and data sets for the text Probability and Statistics
    with R, Second Edition.",2021-09-04,Alan T. Arnholt,"https://github.com/alanarnholt/PASWR2,
https://alanarnholt.github.io/PASWR2/",TRUE,https://github.com/alanarnholt/paswr2,33493,1,2022-05-14T23:54:59Z,33493
patentr,"Converts TXT and XML data curated by the United States Patent and
    Trademark Office (USPTO). Allows conversion of bulk data after downloading
    directly from the USPTO bulk data website, eliminating need for users to
    wrangle multiple data formats to get large patent databases in tidy,
    rectangular format. Data details can be found on the USPTO website
    <https://bulkdata.uspto.gov/>. Currently, all 3 formats: 1. TXT data
    (1976-2001); 2. XML format 1 data (2002-2004); and 3. XML format 2 data
    (2005-current) can be converted to rectangular, CSV format.
    Relevant literature that uses data from USPTO includes Wada (2020)
    <doi:10.1007/s11192-020-03674-4> and Plaza & Albert (2008)
    <doi:10.1007/s11192-007-1763-3>.",2021-09-12,Raoul Wadhwa,https://JYProjs.github.io/patentr/,TRUE,https://github.com/jyprojs/patentr,5365,5,2021-12-26T17:54:20Z,1073
patentsview,"Provides functions to simplify the 'PatentsView' API
    (<https://patentsview.org/apis/purpose>) query language,
    send GET and POST requests to the API's seven endpoints, and parse the data
    that comes back.",2021-09-25,Christopher Baker,https://docs.ropensci.org/patentsview/index.html,TRUE,https://github.com/ropensci/patentsview,15718,27,2021-09-25T02:06:34Z,582.1481481481482
path.chain,"Provides path_chain class and functions, which facilitates loading and saving 
             directory structure in YAML configuration files via 'config' package. 
             The file structure you created during exploration can be transformed 
             into legible section in the config file, and then easily loaded for further usage.",2020-09-23,Krzysztof Joachimiak,"https://github.com/krzjoa/path.chain,
https://krzjoa.github.io/path.chain/",TRUE,https://github.com/krzjoa/path.chain,6827,9,2021-11-05T15:05:22Z,758.5555555555555
pathfindR,"Enrichment analysis enables researchers to uncover mechanisms 
    underlying a phenotype. However, conventional methods for enrichment 
    analysis do not take into account protein-protein interaction information, 
    resulting in incomplete conclusions. pathfindR is a tool for enrichment 
    analysis utilizing active subnetworks. The main function identifies active 
    subnetworks in a protein-protein interaction network using a user-provided 
    list of genes and associated p values. It then performs enrichment analyses 
    on the identified subnetworks, identifying enriched terms (i.e. pathways or, 
    more broadly, gene sets) that possibly underlie the phenotype of interest.
    pathfindR also offers functionalities to cluster the enriched terms and 
    identify representative terms in each cluster, to score the enriched terms 
    per sample and to visualize analysis results. The enrichment, clustering and 
    other methods implemented in pathfindR are described in detail in 
    Ulgen E, Ozisik O, Sezerman OU. 2019. pathfindR: An R Package for 
    Comprehensive Identification of Enriched Pathways in Omics Data Through 
    Active Subnetworks. Front. Genet. <doi:10.3389/fgene.2019.00858>.",2021-11-15,Ege Ulgen,"https://egeulgen.github.io/pathfindR/,
https://github.com/egeulgen/pathfindR",TRUE,https://github.com/egeulgen/pathfindr,25966,119,2022-07-07T10:42:39Z,218.2016806722689
pathfindR.data,"This is a data-only package, containing data needed to run the CRAN 
    package 'pathfindR', a package for enrichment analysis utilizing active 
    subnetworks. This package contains protein-protein interaction network data, 
    data related to gene sets and example input/output data.",2021-08-21,Ege Ulgen,https://github.com/egeulgen/pathfindR.data,TRUE,https://github.com/egeulgen/pathfindr.data,16972,0,2021-08-21T07:44:51Z,NA
pathviewr,"Tools to import, clean, and visualize movement data,
    particularly from motion capture systems such as Optitrack's 
    'Motive', the Straw Lab's 'Flydra', or from other sources. We provide 
    functions to remove artifacts, standardize tunnel position and tunnel 
    axes, select a region of interest, isolate specific trajectories, fill
    gaps in trajectory data, and calculate 3D and per-axis velocity. For 
    experiments of visual guidance, we also provide functions that use 
    subject position to estimate perception of visual stimuli. ",2021-05-06,Vikram B. Baliga,"https://github.com/ropensci/pathviewr/,
https://docs.ropensci.org/pathviewr/",TRUE,https://github.com/ropensci/pathviewr,5507,5,2021-07-28T18:16:35Z,1101.4
patientProfilesVis,"Creation of patient profile visualizations for
  exploration, diagnostic or monitoring purposes during a clinical trial.
  These static visualizations display a patient-specific overview
  of the evolution during the trial time frame of 
  parameters of interest (as laboratory, ECG, vital signs),
  presence of adverse events, exposure to a treatment; 
  associated with metadata patient information, 
  as demography, concomitant medication.
  The visualizations can be tailored for specific domain(s) or endpoint(s) of interest.
  Visualizations are exported into patient profile report(s)
  or can be embedded in custom report(s).",2021-09-28,Laure Cougnaud,https://github.com/openanalytics/patientProfilesVis,TRUE,https://github.com/openanalytics/patientprofilesvis,4708,2,2022-02-17T08:24:25Z,2354
patrick,"This is an extension of the 'testthat' package that
    lets you add parameters to your unit tests. Parameterized unit tests
    are often easier to read and more reliable, since they follow the DNRY
    (do not repeat yourself) rule.",2021-10-11,Michael Quinn,https://github.com/google/patrick,TRUE,https://github.com/google/patrick,40933,87,2021-10-11T20:48:22Z,470.4942528735632
patternize,"Quantification of variation in organismal color patterns as
    obtained from image data. Patternize defines homology between pattern positions
    across images either through fixed landmarks or image registration. Pattern
    identification is performed by categorizing the distribution of colors using RGB
    thresholds or image segmentation.",2022-01-03,Steven Van Belleghem,https://github.com/StevenVB12/patternize,TRUE,https://github.com/stevenvb12/patternize,14899,20,2022-07-04T17:21:02Z,744.95
PAutilities,"A collection of utilities that are useful for a broad range of
    tasks that are common in physical activity research, including the
    following: creation of Bland-Altman plots, formatted descriptive
    statistics, metabolic calculations (e.g. basal metabolic rate predictions)
    and conversions, demographic calculations (age and age-for-body-mass-index
    percentile), bout analysis of moderate-to-vigorous intensity physical
    activity, and analysis of bout detection algorithm performance.",2020-05-17,Paul R. Hibbing,https://github.com/paulhibbing/PAutilities,TRUE,https://github.com/paulhibbing/pautilities,18683,1,2022-05-27T18:56:55Z,18683
pavo,"A cohesive framework for the spectral and spatial analysis of 
    colour described in Maia, Eliason, Bitton, Doucet & Shawkey (2013) 
    <doi:10.1111/2041-210X.12069> and Maia, Grsuon, Endler & White (2019)
    <doi:10.1111/2041-210X.13174>.",2021-09-21,Thomas White,"http://pavo.colrverse.com, https://github.com/rmaia/pavo/",TRUE,https://github.com/rmaia/pavo,30165,47,2022-06-22T14:40:43Z,641.8085106382979
paws,"Interface to Amazon Web Services <https://aws.amazon.com>,
    including storage, database, and compute services, such as 'Simple
    Storage Service' ('S3'), 'DynamoDB' 'NoSQL' database, and 'Lambda'
    functions-as-a-service.",2021-09-03,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,81606,209,2022-07-08T09:23:07Z,390.4593301435407
paws.analytics,"Interface to 'Amazon Web Services' 'analytics' services,
    including 'Elastic MapReduce' 'Hadoop' and 'Spark' big data service,
    'Elasticsearch' search engine, and more <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,70091,209,2022-07-08T09:23:07Z,335.3636363636364
paws.application.integration,"Interface to 'Amazon Web Services' application integration
    services, including 'Simple Queue Service' ('SQS') message queue,
    'Simple Notification Service' ('SNS') publish/subscribe messaging, and
    more <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,70140,209,2022-07-08T09:23:07Z,335.5980861244019
paws.compute,"Interface to 'Amazon Web Services' compute services,
    including 'Elastic Compute Cloud' ('EC2'), 'Lambda'
    functions-as-a-service, containers, batch processing, and more
    <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,76381,209,2022-07-08T09:23:07Z,365.4593301435407
paws.cost.management,"Interface to 'Amazon Web Services' cost management services,
    including cost and usage reports, budgets, pricing, and more
    <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,75677,209,2022-07-08T09:23:07Z,362.09090909090907
paws.customer.engagement,"Interface to 'Amazon Web Services' customer engagement
    services, including 'Simple Email Service', 'Connect' contact center
    service, and more <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,69912,209,2022-07-08T09:23:07Z,334.50717703349284
paws.database,"Interface to 'Amazon Web Services' database services,
    including 'Relational Database Service' ('RDS'), 'DynamoDB' 'NoSQL'
    database, and more <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,70310,209,2022-07-08T09:23:07Z,336.41148325358853
paws.developer.tools,"Interface to 'Amazon Web Services' developer tools services,
    including version control, continuous integration and deployment, and
    more <https://aws.amazon.com/products/developer-tools/>.",2021-08-24,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,24678,209,2022-07-08T09:23:07Z,118.07655502392345
paws.end.user.computing,"Interface to 'Amazon Web Services' end user computing
    services, including collaborative document editing, mobile intranet,
    and more <https://aws.amazon.com/>.",2021-08-24,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,24666,209,2022-07-08T09:23:07Z,118.01913875598086
paws.machine.learning,"Interface to 'Amazon Web Services' machine learning services,
    including 'SageMaker' managed machine learning service, natural
    language processing, speech recognition, translation, and more
    <https://aws.amazon.com/machine-learning/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,75949,209,2022-07-08T09:23:07Z,363.39234449760767
paws.management,"Interface to 'Amazon Web Services' management and governance
    services, including 'CloudWatch' application and infrastructure
    monitoring, 'Auto Scaling' for automatically scaling resources, and
    more <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,73827,209,2022-07-08T09:23:07Z,353.2392344497608
paws.networking,"Interface to 'Amazon Web Services' networking and content
    delivery services, including 'Route 53' Domain Name System service,
    'CloudFront' content delivery, load balancing, and more
    <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,70129,209,2022-07-08T09:23:07Z,335.54545454545456
paws.security.identity,"Interface to 'Amazon Web Services' security, identity, and
    compliance services, including the 'Identity & Access Management'
    ('IAM') service for managing access to services and resources, and
    more <https://aws.amazon.com/>.",2021-08-23,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,72060,209,2022-07-08T09:23:07Z,344.78468899521533
paws.storage,"Interface to 'Amazon Web Services' storage services,
    including 'Simple Storage Service' ('S3') and more
    <https://aws.amazon.com/>.",2021-08-22,David Kretch,https://github.com/paws-r/paws,TRUE,https://github.com/paws-r/paws,73910,209,2022-07-08T09:23:07Z,353.6363636363636
pbapply,"A lightweight package that adds
  progress bar to vectorized R functions
  ('*apply'). The implementation can easily be added
  to functions where showing the progress is
  useful (e.g. bootstrap). The type and style of the
  progress bar (with percentages or remaining time)
  can be set through options.
  Supports several parallel processing backends.",2021-09-16,Peter Solymos,https://github.com/psolymos/pbapply,TRUE,https://github.com/psolymos/pbapply,1911735,124,2022-04-24T22:35:34Z,15417.217741935483
pbdMPI,"An efficient interface to MPI by utilizing S4
        classes and methods with a focus on Single Program/Multiple Data
        ('SPMD')
        parallel programming style, which is intended for batch parallel
        execution.",2021-11-06,Wei-Chen Chen,https://pbdr.org/,TRUE,https://github.com/snoweye/pbdmpi,26209,2,2021-11-06T04:04:25Z,13104.5
pbdSLAP,"Utilizing scalable linear algebra packages mainly
        including 'BLACS', 'PBLAS', and 'ScaLAPACK' in double precision via
        'pbdMPI' based on 'ScaLAPACK' version 2.0.2.",2022-02-04,Wei-Chen Chen,https://pbdr.org/,TRUE,https://github.com/snoweye/pbdslap,19763,0,2022-02-04T00:21:03Z,NA
pbdZMQ,"'ZeroMQ' is a well-known library for high-performance
    asynchronous messaging in scalable, distributed applications.  This
    package provides high level R wrapper functions to easily utilize
    'ZeroMQ'. We mainly focus on interactive client/server programming
    frameworks. For convenience, a minimal 'ZeroMQ' library (4.2.2)
    is shipped with 'pbdZMQ', which can be used if no system installation
    of 'ZeroMQ' is available.  A few wrapper functions compatible with
    'rzmq' are also provided.",2022-02-05,Wei-Chen Chen,https://pbdr.org/,TRUE,https://github.com/snoweye/pbdzmq,427584,16,2022-02-05T00:31:27Z,26724
pbmcapply,"A light-weight package helps you track and visualize
  the progress of parallel version of vectorized R functions (mc*apply).
  Parallelization (mc.core > 1) works only on *nix (Linux, Unix such as macOS) system due to
  the lack of fork() functionality, which is essential for mc*apply, on Windows.",2022-04-28,Kevin Kuang,https://github.com/kvnkuang/pbmcapply,TRUE,https://github.com/kvnkuang/pbmcapply,157996,34,2022-04-28T13:50:00Z,4646.941176470588
pbo,"Following the method of Bailey et al., computes for a collection
    of candidate models the probability of backtest overfitting, the
    performance degradation and probability of loss, and the stochastic
    dominance.",2022-05-26,Matt Barry,https://github.com/mrbcuda/pbo,TRUE,https://github.com/mrbcuda/pbo,16318,37,2022-05-26T14:19:44Z,441.02702702702703
PBSmodelling,"Provides software to facilitate the design, testing, and operation
   of computer models. It focuses particularly on tools that make it easy to
   construct and edit a customized graphical user interface ('GUI'). Although our
   simplified 'GUI' language depends heavily on the R interface to the 'Tcl/Tk'
   package, a user does not need to know 'Tcl/Tk'. Examples illustrate models
   built with other R packages, including 'PBSmapping', 'PBSddesolve', and 'BRugs'. 
   A complete user's guide 'PBSmodelling-UG.pdf' shows how to use this package
   effectively.",2019-03-14,Rowan Haigh,https://github.com/pbs-software/pbs-modelling,TRUE,https://github.com/pbs-software/pbs-modelling,38560,2,2021-11-23T18:45:06Z,19280
PCADSC,"A suite of non-parametric, visual tools for assessing differences in data structures
    for two datasets that contain different observations of the same variables. These tools are all 
    based on Principal Component Analysis (PCA) and thus effectively address differences in the structures
    of the covariance matrices of the two datasets. The PCASDC tools consist of easy-to-use, 
    intuitive plots that each focus on different aspects of the PCA decompositions. The cumulative eigenvalue
    (CE) plot describes differences in the variance components (eigenvalues) of the deconstructed covariance matrices. The
    angle plot presents the information loss when moving from the PCA decomposition of one dataset to the 
    PCA decomposition of the other. The chroma plot describes the loading patterns of the two datasets, thereby
    presenting the relative weighting and importance of the variables from the original dataset. ",2017-04-19,Anne H. Petersen,https://github.com/annepetersen1/PCADSC,TRUE,https://github.com/annepetersen1/pcadsc,12881,1,2022-04-30T14:55:16Z,12881
PCAmatchR,"Matches cases to controls based on genotype principal components (PC). 
      In order to produce better results, matches are based on the weighted 
      distance of PCs where the weights are equal to the % variance explained 
      by that PC. A weighted Mahalanobis distance metric (Kidd et al. (1987)
      <DOI:10.1016/0031-3203(87)90066-5>) is used to determine matches. ",2022-03-02,Derek W. Brown,https://github.com/machiela-lab/PCAmatchR,TRUE,https://github.com/machiela-lab/pcamatchr,10692,7,2022-02-28T16:57:36Z,1527.4285714285713
pcaPP,"Provides functions for robust PCA by projection pursuit.
    The methods are described in Croux et al. (2006) <doi:10.2139/ssrn.968376>,
    Croux et al. (2013) <doi:10.1080/00401706.2012.727746>,
    Todorov and Filzmoser (2013) <doi:10.1007/978-3-642-33042-1_31>.",2022-07-08,Peter Filzmoser,https://github.com/valentint/pcaPP,TRUE,https://github.com/valentint/pcapp,1313488,0,2022-07-08T23:10:19Z,NA
pcFactorStan,"Provides convenience functions and pre-programmed
    Stan models related to the paired comparison factor model. Its purpose
    is to make fitting paired comparison data using Stan easy. This
    package is described in Pritikin (2020) <doi:10.1016/j.heliyon.2020.e04821>.",2021-09-25,Joshua N. Pritikin,https://github.com/jpritikin/pcFactorStan,TRUE,https://github.com/jpritikin/pcfactorstan,20938,2,2021-09-25T02:05:36Z,10469
PCLassoReg,"Two protein complex-based group regression models (PCLasso and PCLasso2) for risk protein complex identification. PCLasso is a prognostic model that identifies risk protein complexes associated with survival. PCLasso2 is a classification model that identifies risk protein complexes associated with classes. For more information, see Wang and Liu (2021) <doi:10.1093/bib/bbab212>. ",2021-10-26,Wei Liu,https://github.com/weiliu123/PCLassoReg,TRUE,https://github.com/weiliu123/pclassoreg,2552,1,2021-10-25T11:34:24Z,2552
PCMBase,"Phylogenetic comparative methods represent models of continuous trait 
  data associated with the tips of a phylogenetic tree. Examples of such models 
  are Gaussian continuous time branching stochastic processes such as Brownian 
  motion (BM) and Ornstein-Uhlenbeck (OU) processes, which regard the data at the 
  tips of the tree as an observed (final) state of a Markov process starting from 
  an initial state at the root and evolving along the branches of the tree. The 
  PCMBase R package provides a general framework for manipulating such models. 
  This framework consists of an application programming interface for specifying 
  data and model parameters, and efficient algorithms for simulating trait evolution 
  under a model and calculating the likelihood of model parameters for an assumed
  model and trait data. The package implements a growing collection of models, 
  which currently includes BM, OU, BM/OU with jumps, two-speed OU as well as mixed 
  Gaussian models, in which different types of the above models can be associated 
  with different branches of the tree. The PCMBase package is limited to 
  trait-simulation and likelihood calculation of (mixed) Gaussian phylogenetic 
  models. The PCMFit package provides functionality for inference of 
  these models to tree and trait data. The package web-site 
  <https://venelin.github.io/PCMBase/>
  provides access to the documentation and other resources. ",2021-06-07,Venelin Mitov,"https://venelin.github.io/PCMBase/, https://venelin.github.io",TRUE,https://github.com/venelin/pcmbase,14107,4,2021-07-22T17:19:21Z,3526.75
pcoxtime,Fits penalized models for both time-independent and time-dependent survival data. It fully implements elastic net and uses proximal gradient descent to solve the optimization problem. The package is an implementation of Steve Cygu and Benjamin M. Bolker. (2021) <arXiv:2102.02297>.,2022-05-13,Bicko Cygu,https://github.com/CYGUBICKO/pcoxtime-pkg,TRUE,https://github.com/cygubicko/pcoxtime-pkg,6454,3,2022-05-13T13:30:25Z,2151.3333333333335
PCRedux,"Extracts features from amplification curve data of quantitative 
    Polymerase Chain Reactions (qPCR) (Pabinger S. et al. (2014) 
    <doi:10.1016/j.bdq.2014.08.002>) for machine learning purposes. Helper 
    functions prepare the amplification curve data for processing as functional 
    data (e.g., Hausdorff distance) or enable the plotting of amplification 
    curve classes (negative, ambiguous, positive). The hookreg() and hookregNL() 
    functions (Burdukiewicz M. et al. (2018) <doi:10.1016/j.bdq.2018.08.001>) 
    can be used to predict amplification curves with an hook effect-like 
    curvature. The pcrfit_single() function can be used to extract features 
    from an amplification curve.",2022-05-11,Stefan Roediger,https://CRAN.R-project.org/package=PCRedux,TRUE,https://github.com/pcruniversum/pcredux,13314,7,2022-06-07T15:14:05Z,1902
pcsstools,"Defines functions to describe regression models using only
    pre-computed summary statistics (i.e. means, variances, and covariances)
    in place of individual participant data.
    Possible models include linear models for linear combinations, products, 
    and logical combinations of phenotypes.
    Implements methods presented in 
    Wolf et al. (2021) <doi:10.1101/2021.03.08.433979>
    Wolf et al. (2020) <doi:10.1142/9789811215636_0063> and 
    Gasdaska et al. (2019) <doi:10.1142/9789813279827_0036>.",2021-03-23,Jack Wolf,https://github.com/jackmwolf/pcsstools/,TRUE,https://github.com/jackmwolf/pcsstools,4340,4,2021-10-22T01:43:17Z,1085
pct,"Functions and example data to teach and
  increase the reproducibility of the methods and code underlying 
  the Propensity to Cycle Tool (PCT), a research project and web application 
  hosted at <https://www.pct.bike/>. 
  For an academic paper on the methods,
  see Lovelace et al (2017) <doi:10.5198/jtlu.2016.862>.",2021-11-02,Robin Lovelace,"https://itsleeds.github.io/pct/, https://github.com/ITSLeeds/pct",TRUE,https://github.com/itsleeds/pct,23959,15,2021-12-09T13:49:39Z,1597.2666666666667
pdfetch,"Download economic and financial time series from public sources, 
  including the St Louis Fed's FRED system, Yahoo Finance, the US Bureau of Labor Statistics, 
  the US Energy Information Administration, the World Bank, Eurostat, the European Central Bank,
  the Bank of England, the UK's Office of National Statistics, Deutsche Bundesbank, and INSEE.",2022-05-21,Abiel Reinhart,https://github.com/abielr/pdfetch,TRUE,https://github.com/abielr/pdfetch,51080,9,2022-05-21T13:08:46Z,5675.555555555556
pdfsearch,"Includes functions for keyword search of pdf files. There is
    also a wrapper that includes searching of all files within a single
    directory.",2019-01-09,Brandon LeBeau,https://github.com/lebebr01/pdfsearch,TRUE,https://github.com/lebebr01/pdfsearch,20263,34,2022-04-01T15:28:14Z,595.9705882352941
pdp,"A general framework for constructing partial dependence (i.e.,
        marginal effect) plots from various types machine learning models
        in R.",2022-06-07,Brandon M. Greenwell,"https://github.com/bgreenwell/pdp,
http://bgreenwell.github.io/pdp/",TRUE,https://github.com/bgreenwell/pdp,242563,78,2022-05-27T01:35:33Z,3109.7820512820513
PDtoolkit,"The goal of this package is to cover the most common steps in probability of default (PD) rating model development and validation. 
	     The main procedures available are those that refer to univariate, bivariate, multivariate analysis, calibration and validation. 
	     Along with accompanied 'monobin' and 'monobinShiny' packages, 'PDtoolkit' provides functions which are suitable for different 
	     data transformation and modeling tasks such as: 
	     imputations, monotonic binning of numeric risk factors, binning of categorical risk factors, weights of evidence (WoE) and 
	     information value (IV) calculations, WoE coding (replacement of risk factors modalities with WoE values), risk factor clustering, 
	     area under curve (AUC) calculation and others. Additionally, package provides set of validation functions for testing homogeneity, 
	     heterogeneity, discriminatory and predictive power of the model.",2022-06-06,Andrija Djurovic,https://github.com/andrija-djurovic/PDtoolkit,TRUE,https://github.com/andrija-djurovic/pdtoolkit,2027,7,2022-07-08T06:49:31Z,289.57142857142856
pdynmc,"Linear dynamic panel data modeling based on linear and
    nonlinear moment conditions as proposed by
    Holtz-Eakin, Newey, and Rosen (1988) <doi:10.2307/1913103>,
    Ahn and Schmidt (1995) <doi:10.1016/0304-4076(94)01641-C>,
    and Arellano and Bover (1995) <doi:10.1016/0304-4076(94)01642-D>.
    Estimation of the model parameters relies on the Generalized
    Method of Moments (GMM), numerical optimization (when nonlinear
    moment conditions are employed) and the computation of closed
    form solutions (when estimation is based on linear moment
    conditions). One-step, two-step and iterated estimation is
    available. For inference and specification
    testing, Windmeijer (2005) <doi:10.1016/j.jeconom.2004.02.005>
    and doubly corrected standard errors
    (Hwang, Kang, Lee, 2021 <doi:10.1016/j.jeconom.2020.09.010>)
    are available. Additionally, serial correlation tests, tests for
    overidentification, and Wald tests are provided. Functions for
    visualizing panel data structures and modeling results obtained
    from GMM estimation are also available. The plot methods include
    functions to plot unbalanced panel structure, coefficient ranges
    and coefficient paths across GMM iterations (the latter is
    implemented according to the plot shown in
    Hansen and Lee, 2021 <doi:10.3982/ECTA16274>).
    For a more detailed description of the functionality, please
    see Fritsch, Pua, Schnurbus (2021) <doi:10.32614/RJ-2021-035>.",2022-03-24,Markus Fritsch,https://github.com/markusfritsch/pdynmc,TRUE,https://github.com/markusfritsch/pdynmc,16032,2,2022-05-09T12:48:11Z,8016
peacesciencer,"These are useful tools and data sets for the study of quantitative 
    peace science. The goal for this package is to include tools and data sets
    for doing original research that mimics well what a user would have to previously
    get from a software package that may not be well-sourced or well-supported.
    Those software bundles were useful the extent to which they encourage replications 
    of long-standing analyses by starting the data-generating process from scratch. However, 
    a lot of the functionality can be done relatively quickly and more transparently
    in the R programming language.",2022-03-24,Steve Miller,https://github.com/svmiller/peacesciencer/,TRUE,https://github.com/svmiller/peacesciencer,9160,15,2022-05-03T13:25:35Z,610.6666666666666
peakRAM,"When working with big data sets, RAM conservation is critically
    important. However, it is not always enough to just monitor the
    size of the objects created. So-called ""copy-on-modify"" behavior,
    characteristic of R, means that some expressions or functions may
    require an unexpectedly large amount of RAM overhead. For example,
    replacing a single value in a matrix duplicates that matrix in the
    back-end, making this task require twice as much RAM as that used
    by the matrix itself. This package makes it easy to monitor the total
    and peak RAM used so that developers can quickly identify and
    eliminate RAM hungry code.",2017-01-16,Thomas Quinn,http://github.com/tpq/peakRAM,TRUE,https://github.com/tpq/peakram,37999,16,2021-08-27T04:55:16Z,2374.9375
PeakSegDisk,"Disk-based implementation of
 Functional Pruning Optimal Partitioning with up-down constraints
 <doi:10.18637/jss.v101.i10> for single-sample peak calling
 (independently for each sample and genomic problem),
 can handle huge data sets (10^7 or more).",2022-02-02,Toby Dylan Hocking,https://github.com/tdhock/PeakSegDisk,TRUE,https://github.com/tdhock/peaksegdisk,13575,2,2022-02-02T05:19:43Z,6787.5
PeakSegJoint,"Jointly segment several ChIP-seq samples to find the peaks 
 which are the same and different across samples. The fast approximate
 maximum Poisson likelihood algorithm is described in
 ""PeakSegJoint: fast supervised peak detection via joint segmentation
 of multiple count data samples""
 <arXiv:1506.01286> by TD Hocking and G Bourque.",2022-04-07,Toby Dylan Hocking,https://github.com/tdhock/PeakSegJoint,TRUE,https://github.com/tdhock/peaksegjoint,13430,5,2022-04-07T03:34:03Z,2686
pedbp,"Data and utilities for estimating pediatric blood pressure
    percentiles by sex, age, and optionally height (stature).
    Blood pressure percentiles for children under one year of age come from Gemelli
    et.al. (1990) <doi:10.1007/BF02171556>.  Estimates of blood pressure
    percentiles for children at least one year of age are informed by
    data from the National Heart, Lung, and Blood Institute (NHLBI) and the
    Centers for Disease Control and Prevention (CDC)
    <doi:10.1542/peds.2009-2107C> or from Lo et.al. (2013)
    <doi:10.1542/peds.2012-1292>.  The flowchart for selecting the informing
    data source comes from Martin et.al. (2022)
    <doi:10.1542/hpeds.2021-005998>.",2022-07-02,Peter DeWitt,https://github.com/dewittpe/pedbp/,TRUE,https://github.com/dewittpe/pedbp,97,1,2022-07-02T17:32:29Z,97
pedmod,"Provides functions to estimate mixed probit models using, for 
    instance, pedigree data like in <doi:10.1002/sim.1603>. The models are also 
    commonly called liability threshold models. The approximation is 
    based on direct log marginal likelihood approximations like the randomized 
    Quasi-Monte Carlo suggested by <doi:10.1198/106186002394> with a similar 
    procedure to approximate the derivatives. The minimax tilting method 
    suggested by <doi:10.1111/rssb.12162> is also supported. Graph-based methods 
    are also provided that can be used to simplify pedigrees.",2022-06-22,Benjamin Christoffersen,https://github.com/boennecd/pedmod,TRUE,https://github.com/boennecd/pedmod,3113,2,2022-06-22T09:46:42Z,1556.5
pedmut,"A collection of functions for modelling mutations in pedigrees with 
    marker data, as used e.g. in likelihood computations with microsatellite data.
    Implemented models include proportional and stepwise models, as well as random 
    models for experimental work, and custom models allowing the user to apply any 
    valid mutation matrix. Allele lumping is done following the lumpability criteria 
    of Kemeny and Snell (1976), ISBN:0387901922.",2021-10-22,Magnus Dehli Vigeland,https://github.com/magnusdv/pedmut,TRUE,https://github.com/magnusdv/pedmut,13516,1,2021-10-22T08:48:53Z,13516
pedometrics,"An R implementation of methods employed in the field of pedometrics, soil science
    discipline dedicated to studying the spatial, temporal, and spatio-temporal variation of soil
    using statistical and computational methods. The methods found here include the calibration of
    linear regression models using covariate selection strategies, computation of summary validation
    statistics for predictions, generation of summary plots, evaluation of the local quality of a
    geostatistical model of uncertainty, and so on. Other functions simply extend the
    functionalities of or facilitate the usage of functions from other packages that are commonly
    used for the analysis of soil data. Formerly available versions of suggested packages no longer
    available from CRAN can be obtained from the CRAN archive
    <https://cran.r-project.org/src/contrib/Archive/>.",2022-06-19,Alessandro Samuel-Rosa,https://github.com/Laboratorio-de-Pedometria/pedometrics-package,TRUE,https://github.com/laboratorio-de-pedometria/pedometrics-package,24609,5,2022-06-18T22:16:57Z,4921.8
pedprobr,"An implementation of the Elston-Stewart algorithm for
    calculating pedigree likelihoods given genetic marker data (Elston and
    Stewart (1971) <doi:10.1159/000152448>). The standard algorithm is
    extended to allow inbred founders. 'pedprobr' is part of the 'ped
    suite', a collection of packages for pedigree analysis in R. In
    particular, 'pedprobr' depends on 'pedtools' for pedigree
    manipulations and 'pedmut' for mutation modelling. For more
    information, see 'Pedigree Analysis in R' (Vigeland, 2021,
    ISBN:9780128244302).",2022-06-07,Magnus Dehli Vigeland,https://github.com/magnusdv/pedprobr,TRUE,https://github.com/magnusdv/pedprobr,19111,3,2022-06-07T08:04:00Z,6370.333333333333
pedquant,"
    Provides an interface to access public economic and financial data for 
    economic research and quantitative analysis. The data sources including 
    NBS, FRED, 163, Sina, Eastmoney and etc. ",2022-05-02,Shichen Xie,https://github.com/ShichenXie/pedquant,TRUE,https://github.com/shichenxie/pedquant,22177,42,2022-07-10T15:48:25Z,528.0238095238095
pedSimulate,"Simulate pedigree, genetic merits and phenotypes with random/non-random matings followed by random/non-random selection with different intensities and patterns in males and females. Genotypes can be simulated for a given pedigree, or an appended pedigree to an existing pedigree with genotypes.
   Bijma, P. & Rutten, M. (2002) <https://www.wur.nl/en/Research-Results/Chair-groups/Animal-Sciences/Animal-Breeding-and-Genomics-Group/Research/Software.htm>.",2022-03-22,Mohammad Ali Nilforooshan,https://github.com/nilforooshan/pedSimulate,TRUE,https://github.com/nilforooshan/pedsimulate,22392,1,2022-04-01T01:34:01Z,22392
pedsuite,"The 'ped suite' is a collection of packages for pedigree
    analysis, covering applications in forensic genetics, medical genetics
    and more. A detailed presentation of the 'ped suite' is given in the
    book 'Pedigree Analysis in R' (Vigeland, 2021, ISBN: 9780128244302).",2022-01-07,Magnus Dehli Vigeland,"https://magnusdv.github.io/pedsuite/,
https://github.com/magnusdv/pedsuite",TRUE,https://github.com/magnusdv/pedsuite,3935,3,2022-06-21T13:21:37Z,1311.6666666666667
pedtools,"A comprehensive collection of tools for creating,
    manipulating and visualising pedigrees and genetic marker data.
    Pedigrees can be read from text files or created on the fly with
    built-in functions. A range of utilities enable modifications like
    adding or removing individuals, breaking loops, and merging pedigrees.
    Pedigree plots are produced by wrapping the plotting functionality of
    the 'kinship2' package. A Shiny app for creating pedigrees, based on
    'pedtools', is available at <https://magnusdv.shinyapps.io/quickped>.
    'pedtools' is the hub of the 'ped suite', a collection of packages for
    pedigree analysis. A detailed presentation of the 'ped suite' is given
    in the book 'Pedigree Analysis in R' (Vigeland, 2021,
    ISBN:9780128244302).",2022-06-07,Magnus Dehli Vigeland,"https://github.com/magnusdv/pedtools,
https://magnusdv.github.io/pedsuite/",TRUE,https://github.com/magnusdv/pedtools,18414,14,2022-06-20T10:34:11Z,1315.2857142857142
pema,"Conduct penalized meta-analysis, see Van Lissa & Van Erp (2021).
    <doi:10.31234/osf.io/6phs5>. In meta-analysis, there are
    often between-study differences. These can be coded as moderator variables,
    and controlled for using meta-regression. However, if the number of
    moderators is large relative to the number of studies, such an analysis may
    be overfit. Penalized meta-regression is useful in these cases, because
    it shrinks the regression slopes of irrelevant moderators towards zero.",2022-04-25,Caspar J van Lissa,https://github.com/cjvanlissa/pema,TRUE,https://github.com/cjvanlissa/pema,4383,0,2022-04-30T14:30:08Z,NA
penfa,"Fits single- and multiple-group penalized factor analysis models 
    via a trust-region algorithm with integrated automatic multiple tuning 
    parameter selection (Geminiani et al., 2021 <doi:10.1007/s11336-021-09751-8>). 
    Available penalties include lasso, adaptive lasso, scad, mcp, and ridge. ",2021-07-17,Elena Geminiani,https://github.com/egeminiani/penfa,TRUE,https://github.com/egeminiani/penfa,3973,2,2021-07-20T11:46:25Z,1986.5
penppml,"A set of tools that enables efficient estimation of penalized 
    Poisson Pseudo Maximum Likelihood regressions, using lasso or ridge penalties, for models 
    that feature one or more sets of high-dimensional fixed effects. The methodology is based on 
    Breinlich, Corradi, Rocha, Ruta, Santos Silva, and Zylkin (2021) <http://hdl.handle.net/10986/35451> 
    and takes advantage of the method of alternating projections of Gaure (2013) 
    <doi:10.1016/j.csda.2013.03.024> for dealing with HDFE, as well as 
    the coordinate descent algorithm of Friedman, Hastie and Tibshirani (2010) 
    <doi:10.18637/jss.v033.i01> for fitting lasso regressions. The package is also able to carry out 
    cross-validation and to implement the plugin lasso of Belloni, Chernozhukov, Hansen and Kozbur (2016) 
    <doi:10.1080/07350015.2015.1102733>.",2022-01-03,Nicolas Apfel,https://github.com/tomzylkin/penppml,TRUE,https://github.com/tomzylkin/penppml,3466,6,2022-06-09T13:13:57Z,577.6666666666666
pense,"Robust penalized (adaptive) elastic net S and M estimators for
    linear regression. The methods are proposed in
    Cohen Freue, G. V., Kepplinger, D., Salibián-Barrera, M., and Smucler, E.
    (2019) <https://projecteuclid.org/euclid.aoas/1574910036>.
    The package implements the extensions and algorithms described in
    Kepplinger, D. (2020) <doi:10.14288/1.0392915>.",2021-07-07,David Kepplinger,"https://dakep.github.io/pense-rpkg/,
https://github.com/dakep/pense-rpkg",TRUE,https://github.com/dakep/pense-rpkg,23219,1,2022-05-16T21:07:40Z,23219
pepe,"Is designed to make easier printing summary statistics (for continues and factor level) tables in Latex, and plotting by factor. ",2022-05-13,Seyma Kalay,https://github.com/seymakalay/pepe,TRUE,https://github.com/seymakalay/pepe,388,0,2022-05-15T19:50:53Z,NA
peperr,"Designed for prediction error estimation
        through resampling techniques, possibly accelerated by parallel
        execution on a compute cluster. Newly developed model fitting
        routines can be easily incorporated. Methods used in the package are detailed in
        Porzelius Ch., Binder H. and Schumacher M. (2009) <doi:10.1093/bioinformatics/btp062>
        and were used, for instance, in
        Porzelius Ch., Schumacher M.and  Binder H. (2011) <doi:10.1007/s00180-011-0236-6>.",2022-03-03,Christine Porzelius,"https://github.com/fbertran/peperr/,
https://fbertran.github.io/peperr/",TRUE,https://github.com/fbertran/peperr,23744,1,2022-03-03T14:58:21Z,23744
performance,"Utilities for computing measures to assess model quality,
    which are not directly provided by R's 'base' or 'stats' packages.
    These include e.g. measures like r-squared, intraclass correlation
    coefficient (Nakagawa, Johnson & Schielzeth (2017)
    <doi:10.1098/rsif.2017.0213>), root mean squared error or functions to
    check models for overdispersion, singularity or zero-inflation and
    more. Functions apply to a large variety of regression models,
    including generalized linear models, mixed effects models and Bayesian
    models.",2022-06-20,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>,https://easystats.github.io/performance/,TRUE,https://github.com/easystats/performance,1054496,692,2022-07-06T09:04:29Z,1523.8381502890174
PerformanceAnalytics,"Collection of econometric functions for performance and risk 
    analysis. In addition to standard risk and performance metrics, this 
    package aims to aid practitioners and researchers in utilizing the latest
    research in analysis of non-normal return streams.  In general, it is most 
    tested on return (rather than price) data on a regular scale, but most 
    functions will work with irregular return data as well, and increasing
    numbers of functions will work with P&L or price data where possible.",2020-02-06,Brian G. Peterson,https://github.com/braverock/PerformanceAnalytics,TRUE,https://github.com/braverock/performanceanalytics,1243672,171,2022-06-11T18:54:56Z,7272.93567251462
periscope,"An enterprise-targeted scalable and UI-standardized 'shiny' framework 
    including a variety of developer convenience functions with the goal of both 
    streamlining robust application development while assisting with creating a 
    consistent user experience regardless of application or developer.",2022-01-03,Constance Brett,"https://github.com/cb4ds/periscope, http://periscopeapps.org:3838",TRUE,https://github.com/cb4ds/periscope,21706,15,2022-01-03T23:57:50Z,1447.0666666666666
permuco,"Functions to compute p-values based on permutation tests. Regression, ANOVA and ANCOVA, omnibus F-tests, marginal unilateral and bilateral t-tests are available. Several methods to handle nuisance variables are implemented (Kherad-Pajouh, S., & Renaud, O. (2010) <doi:10.1016/j.csda.2010.02.015> ; Kherad-Pajouh, S., & Renaud, O. (2014) <doi:10.1007/s00362-014-0617-3> ; Winkler, A. M., Ridgway, G. R., Webster, M. A., Smith, S. M., & Nichols, T. E. (2014) <doi:10.1016/j.neuroimage.2014.01.060>). An extension for the comparison of signals issued from experimental conditions (e.g. EEG/ERP signals) is provided. Several corrections for multiple testing are possible, including the cluster-mass statistic (Maris, E., & Oostenveld, R. (2007) <doi:10.1016/j.jneumeth.2007.03.024>) and the threshold-free cluster enhancement (Smith, S. M., & Nichols, T. E. (2009) <doi:10.1016/j.neuroimage.2008.03.061>). ",2022-06-30,Jaromil Frossard,https://github.com/jaromilfrossard/permuco,TRUE,https://github.com/jaromilfrossard/permuco,16050,7,2022-06-28T08:38:56Z,2292.8571428571427
permutations,Manipulates invertible functions from a finite set to itself.  Can transform from word form to cycle form and back.,2020-11-12,Robin K. S. Hankin,https://github.com/RobinHankin/permutations,TRUE,https://github.com/robinhankin/permutations,24330,3,2022-06-29T23:00:40Z,8110
permute,"A set of restricted permutation designs for freely exchangeable, line transects (time series), and spatial grid designs plus permutation of blocks (groups of samples) is provided. 'permute' also allows split-plot designs, in which the whole-plots or split-plots or both can be freely-exchangeable or one of the restricted designs. The 'permute' package is modelled after the permutation schemes of 'Canoco 3.1' (and later) by Cajo ter Braak.",2022-01-27,Gavin L. Simpson,https://github.com/gavinsimpson/permute,TRUE,https://github.com/gavinsimpson/permute,1297480,22,2022-01-27T11:12:27Z,58976.36363636364
permutes,"Helps you determine the analysis window to use when analyzing densely-sampled
    time-series data, such as EEG data, using permutation testing (Maris & Oostenveld, 2007)
    <doi:10.1016/j.jneumeth.2007.03.024>. These permutation tests can help identify the timepoints
    where significance of an effect begins and ends, and the results can be plotted in various
    types of heatmap for reporting. Mixed-effects models are supported using an implementation of
    the approach by Lee & Braun (2012) <doi:10.1111/j.1541-0420.2011.01675.x>.",2022-06-15,Cesko C. Voeten,NA,TRUE,https://github.com/cvoeten/permutes,19385,5,2022-06-14T15:42:43Z,3877
personalized,"Provides functions for fitting and validation of models for subgroup
    identification and personalized medicine / precision medicine under the general subgroup
    identification framework of Chen et al. (2017) <doi:10.1111/biom.12676>.
    This package is intended for use for both randomized controlled trials and
    observational studies and is described in detail in Huling and Yu (2021) 
    <doi:10.18637/jss.v098.i05>.",2022-06-27,Jared Huling,"https://jaredhuling.org/personalized/,
https://arxiv.org/abs/1809.07905",TRUE,https://github.com/jaredhuling/personalized,18043,24,2022-07-07T15:06:40Z,751.7916666666666
personalr,"Functions to setup a personal R package that
    attaches given libraries and exports personal helper functions.",2020-11-23,Sebastian Carl,https://github.com/mrcaseb/personalr,TRUE,https://github.com/mrcaseb/personalr,5823,7,2022-02-04T11:05:05Z,831.8571428571429
peRspective,"Interface to the 'Perspective' API, which can be found at the following URL: <https://github.com/conversationai/perspectiveapi#perspective-comment-analyzer-api>. 
    The 'Perspective' API uses machine learning models to score the perceived impact a comment might have on a conversation (i.e. TOXICITY, INFLAMMATORY, etc.).     
    'peRspective' provides access to the API and returns tidy data frames with results of the specified machine learning model(s).",2021-07-14,Fabio Votta,"https://favstats.github.io/peRspective/,
https://github.com/favstats/peRspective",TRUE,https://github.com/favstats/perspective,12411,41,2021-07-13T13:41:57Z,302.7073170731707
pestr,"Set of tools to automatize extraction of data on pests from 'EPPO
    Data Services' and 'EPPO Global Database' and to put them into tables with
    human readable format. Those function use 'EPPO database API', thus you 
    first need to register on <https://data.eppo.int> (free of charge).
    Additional helpers allow to download, check and connect to
    'SQLite EPPO database'.",2021-01-20,Michal Jan Czyz,https://github.com/mczyzj/pestr,TRUE,https://github.com/mczyzj/pestr,5351,0,2021-09-10T16:27:11Z,NA
pexm,Load the Just Another Gibbs Sampling (JAGS) module 'pexm'. The module provides the tools to work with the Piecewise Exponential (PE) distribution in a Bayesian model with the corresponding Markov Chain Monte Carlo algorithm (Gibbs Sampling) implemented via JAGS. Details about the module implementation can be found in Mayrink et al. (2021) <doi:10.18637/jss.v100.i08>.,2021-12-14,Vinicius Mayrink,https://github.com/vdinizm/pexm,TRUE,https://github.com/vdinizm/pexm,8176,3,2021-12-15T10:28:00Z,2725.3333333333335
pfica,Performs penalized independent component analysis for univariate functional data [<doi:10.3390/math9111243>].,2021-06-03,Marc Vidal,https://github.com/m-vidal/pfica,TRUE,https://github.com/m-vidal/pfica,7660,0,2021-12-02T20:56:57Z,NA
pgirmess,"Set of tools for reading, writing and transforming spatial and seasonal data, model selection and specific statistical tests for ecologists. It includes functions to interpolate regular positions of points between landmarks, to discretize polylines into regular point positions, link distant observations to points and convert a bounding box in a spatial object. It also provides miscellaneous functions for field ecologists such as spatial statistics and inference on diversity indexes, writing data.frame with Chinese characters.",2022-02-23,Patrick Giraudoux,"https://giraudoux.pagesperso-orange.fr,
https://github.com/pgiraudoux/pgirmess",TRUE,https://github.com/pgiraudoux/pgirmess,150525,2,2022-02-23T07:16:40Z,75262.5
PGRdup,"Provides functions to aid the identification of probable/possible
    duplicates in Plant Genetic Resources (PGR) collections using
    'passport databases' comprising of information records of each constituent
    sample. These include methods for cleaning the data, creation of a
    searchable Key Word in Context (KWIC) index of keywords associated with
    sample records and the identification of nearly identical records with
    similar information by fuzzy, phonetic and semantic matching of keywords.",2021-02-17,J. Aravind,"https://cran.r-project.org/package=PGRdup,
https://github.com/aravind-j/PGRdup,
https://doi.org/10.5281/zenodo.841963,
https://aravind-j.github.io/PGRdup/,
https://www.rdocumentation.org/packages/PGRdup",TRUE,https://github.com/aravind-j/pgrdup,18361,1,2022-07-06T04:13:04Z,18361
pguIMP,"Reproducible cleaning of bio-medical laboratory data using methods of visualization,error correction and transformation implemented as interactive R-notebooks.",2021-09-30,Sebastian Malkusch,https://github.com/SMLMS/pguIMP,TRUE,https://github.com/smlms/pguimp,4614,0,2021-09-30T11:30:15Z,NA
PH1XBAR,"The purpose of 'PH1XBAR' is to build a Phase I Shewhart control chart for the basic Shewhart, the variance components and the ARMA models in R for subgrouped and individual data. More details can be found: Yao and Chakraborti (2020) <doi: 10.1002/qre.2793>, and Yao and Chakraborti (2021) <doi: 10.1080/08982112.2021.1878220>.",2021-09-23,Yuhui Yao,https://github.com/bolus123/PH1XBAR,TRUE,https://github.com/bolus123/ph1xbar,3473,0,2022-05-06T15:26:07Z,NA
phacking,"Fits right-truncated meta-analysis (RTMA), a bias correction for
  the joint effects of p-hacking (i.e., manipulation of results within studies
  to obtain significant, positive estimates) and traditional publication bias
  (i.e., the selective publication of studies with significant, positive
  results) in meta-analyses [see Mathur MB (2022). ""Sensitivity analysis for
  p-hacking in meta-analyses."" <doi:10.31219/osf.io/ezjsx>.]. Unlike publication
  bias alone, p-hacking that favors significant, positive results (termed
  ""affirmative"") can distort the distribution of affirmative results. To
  bias-correct results from affirmative studies would require strong assumptions
  on the exact nature of p-hacking. In contrast, joint p-hacking and publication
  bias do not distort the distribution of published nonaffirmative results when
  there is stringent p-hacking (e.g., investigators who hack always eventually
  obtain an affirmative result) or when there is stringent publication bias
  (e.g., nonaffirmative results from hacked studies are never published). This
  means that any published nonaffirmative results are from unhacked studies.
  Under these assumptions, RTMA involves analyzing only the published
  nonaffirmative results to essentially impute the full underlying distribution
  of all results prior to selection due to p-hacking and/or publication bias.
  The package also provides diagnostic plots described in Mathur (2022).",2022-06-21,Mika Braginsky,https://github.com/mikabr/phacking,TRUE,https://github.com/mikabr/phacking,181,0,2022-06-17T20:16:54Z,NA
phangorn,"Allows for estimation of phylogenetic trees and networks
    using Maximum Likelihood, Maximum Parsimony, distance methods and
    Hadamard conjugation (Schliep 2011). Offers methods for tree comparison, 
    model selection and visualization of phylogenetic networks as described in
    Schliep et al. (2017).",2022-06-16,Klaus Schliep,"https://github.com/KlausVigo/phangorn,
http://klausvigo.github.io/phangorn/",TRUE,https://github.com/klausvigo/phangorn,447410,160,2022-07-08T14:18:09Z,2796.3125
pharmaRTF,"Enhanced RTF wrapper written in R for use with existing R tables
    packages such as 'Huxtable' or 'GT'. This package fills a gap where tables in
    certain packages can be written out to RTF, but cannot add certain metadata
    or features to the document that are required/expected in a report for a
    regulatory submission, such as multiple levels of titles and footnotes,
    making the document landscape, and controlling properties such as margins.",2021-09-28,Michael Stackhouse,NA,TRUE,https://github.com/atorus-research/pharmartf,12544,24,2021-09-27T17:38:37Z,522.6666666666666
pharmr,Interface to the 'Pharmpy' 'pharmacometrics' library. The 'Reticulate' package is used to interface Python from R.,2022-06-23,Rikard Nordgren,https://github.com/pharmpy/pharmr,TRUE,https://github.com/pharmpy/pharmr,2856,9,2022-06-22T11:31:19Z,317.3333333333333
PhaseTypeR,"General implementation of core function from phase-type
    theory. 'PhaseTypeR' can be used to model continuous and discrete
    phase-type distributions, both univariate and multivariate. The
    package includes functions for outputting the mean and (co)variance of
    phase-type distributions; their density, probability and quantile
    functions; functions for random draws; functions for
    reward-transformation; and functions for plotting the distributions as
    networks. For more information on these functions please refer to
    Bladt and Nielsen (2017, ISBN: 978-1-4939-8377-3) and Campillo Navarro
    (2019)
    <https://orbit.dtu.dk/en/publications/order-statistics-and-multivariate-discrete-phase-type-distributio>.",2022-02-10,Iker Rivas-González,"https://rivasiker.github.io/PhaseTypeR/,
https://github.com/rivasiker/PhaseTypeR",TRUE,https://github.com/rivasiker/phasetyper,2152,2,2022-05-31T08:53:00Z,1076
phecodemap,To build a shiny app for visualization of the hierarchy of PheCode Mapping with International Classification of Diseases (ICD). The same PheCode hierarchy is displayed in two ways: as a sunburst plot and as a tree.,2022-01-15,PARSE LTD,https://github.com/celehs/phecodemap,TRUE,https://github.com/celehs/phecodemap,1523,0,2021-11-29T02:57:54Z,NA
PHEindicatormethods,"Functions to calculate commonly used public health statistics and 
    their confidence intervals using methods approved for use in the production  
    of Public Health England indicators such as those presented via Fingertips 
    (<http://fingertips.phe.org.uk/>). It provides functions for the generation 
    of proportions, crude rates, means, directly standardised rates, indirectly 
    standardised rates, standardised mortality ratios, slope and relative index
    of inequality and life expectancy. 
    Statistical methods are referenced in the following publications. 
    Breslow NE, Day NE (1987) <doi:10.1002/sim.4780080614>.
    Dobson et al (1991) <doi:10.1002/sim.4780100317>. 
    Armitage P, Berry G (2002) <doi:10.1002/9780470773666>.
    Wilson EB. (1927) <doi:10.1080/01621459.1927.10502953>.
    Altman DG et al (2000, ISBN: 978-0-727-91375-3).
    Chiang CL. (1968, ISBN: 978-0-882-75200-6).
    Newell C. (1994, ISBN: 978-0-898-62451-9).
    Eayres DP, Williams ES (2004) <doi:10.1136/jech.2003.009654>.
    Silcocks PBS et al (2001) <doi:10.1136/jech.55.1.38>.
    Low and Low (2004) <doi:10.1093/pubmed/fdh175>.",2020-06-25,Anderson Georgina,NA,TRUE,https://github.com/publichealthengland/pheindicatormethods,19269,14,2022-01-06T15:55:25Z,1376.357142857143
phenofit,"
    The merits of 'TIMESAT' and 'phenopix' are adopted. Besides, a simple and 
    growing season dividing method and a practical snow elimination method 
    based on Whittaker were proposed. 7 curve fitting methods and 4 phenology 
    extraction methods were provided. Parameters boundary are considered for 
    every curve fitting methods according to their ecological meaning. 
    And 'optimx' is used to select best optimization method for different 
    curve fitting methods.
    Reference:
    Kong, D., (2020). R package: A state-of-the-art Vegetation Phenology extraction 
    package, phenofit version 0.3.1, <doi:10.5281/zenodo.5150204>;
    Kong, D., Zhang, Y., Wang, D., Chen, J., & Gu, X. (2020). Photoperiod Explains 
    the Asynchronization Between Vegetation Carbon Phenology and Vegetation Greenness 
    Phenology. Journal of Geophysical Research: Biogeosciences, 125(8), e2020JG005636. 
    <doi:10.1029/2020JG005636>;
    Kong, D., Zhang, Y., Gu, X., & Wang, D. (2019). A robust method for reconstructing 
    global MODIS EVI time series on the Google Earth Engine. 
    ISPRS Journal of Photogrammetry and Remote Sensing, 155, 13–24;
    Zhang, Q., Kong, D., Shi, P., Singh, V.P., Sun, P., 2018. Vegetation phenology 
    on the Qinghai-Tibetan Plateau and its response to climate change (1982–2013). 
    Agric. For. Meteorol. 248, 408–417. <doi:10.1016/j.agrformet.2017.10.026>.",2021-10-15,Dongdong Kong,https://github.com/eco-hydro/phenofit,TRUE,https://github.com/eco-hydro/phenofit,14194,50,2022-04-28T09:21:33Z,283.88
PhenotypeSimulator,"Simulation is a critical part of method development and assessment
    in quantitative genetics. 'PhenotypeSimulator' allows for the flexible 
    simulation of phenotypes under different models, including genetic variant 
    and  infinitesimal genetic effects (reflecting population structure) as well 
    as non-genetic covariate effects, observational noise and additional 
    correlation effects. The different phenotype components are combined into a 
    final phenotype while controlling for the proportion of variance explained 
    by each of the components. For each effect component, the number of 
    variables, their distribution and the design of their effect across traits 
    can be customised. For the simulation of the genetic effects, external 
    genotype data from a number of standard software ('plink', 'hapgen2'/
    'impute2', 'genome', 'bimbam', simple text files) can be imported. The final 
    simulated phenotypes and its components can be automatically saved into .rds 
    or .csv files. In addition, they can be saved in formats compatible with 
    commonly used genetic association software ('gemma', 'bimbam', 'plink', 
    'snptest', 'LiMMBo'). ",2021-07-16,Hannah Meyer,https://github.com/HannahVMeyer/PhenotypeSimulator,TRUE,https://github.com/hannahvmeyer/phenotypesimulator,16523,23,2021-07-16T14:46:35Z,718.3913043478261
phers,"Use phenotype risk scores based on linked clinical and genetic data
  to study Mendelian disease and rare genetic variants. See Bastarache et al.
  2018 <doi:10.1126/science.aal4043>.",2022-05-31,Jake Hughey,"https://phers.hugheylab.org, https://github.com/hugheylab/phers",TRUE,https://github.com/hugheylab/phers,589,0,2022-06-10T12:02:20Z,NA
philentropy,"Computes 46 optimized distance and similarity measures for comparing probability functions (Drost (2018) <doi:10.21105/joss.00765>). These comparisons between probability functions have their foundations in a broad range of scientific disciplines from mathematics to ecology. The aim of this package is to provide a core framework for clustering, classification, statistical inference, goodness-of-fit, non-parametric statistics, information theory, and machine learning tasks that are based on comparing univariate or multivariate probability functions.",2022-02-14,Hajk-Georg Drost,https://github.com/drostlab/philentropy,TRUE,https://github.com/drostlab/philentropy,124537,95,2022-03-03T13:53:59Z,1310.9157894736843
phonfieldwork,"There are a lot of different typical tasks that have to be solved during phonetic research and experiments. This includes creating a presentation that will contain all stimuli, renaming and concatenating multiple sound files recorded during a session, automatic annotation in 'Praat' TextGrids (this is one of the sound annotation standards provided by 'Praat' software, see Boersma & Weenink 2020 <https://www.fon.hum.uva.nl/praat/>), creating an html table with annotations and spectrograms, and converting multiple formats ('Praat' TextGrid, 'ELAN', 'EXMARaLDA', 'Audacity', subtitles '.srt', and 'FLEx' flextext). All of these tasks can be solved by a mixture of different tools (any programming language has programs for automatic renaming, and Praat contains scripts for concatenating and renaming files, etc.). 'phonfieldwork' provides a functionality that will make it easier to solve those tasks independently of any additional tools. You can also compare the functionality with other packages: 'rPraat' <https://CRAN.R-project.org/package=rPraat>, 'textgRid' <https://CRAN.R-project.org/package=textgRid>.",2021-03-02,George Moroz,"https://CRAN.R-project.org/package=phonfieldwork,
https://docs.ropensci.org/phonfieldwork/",TRUE,https://github.com/ropensci/phonfieldwork,14331,16,2022-05-09T03:31:07Z,895.6875
phonics,"Provides a collection of phonetic algorithms including
    Soundex, Metaphone, NYSIIS, Caverphone, and others.  The package is
    documented in <doi:10.18637/jss.v095.i08>.",2021-07-11,James Howard,https://jameshoward.us/phonics-in-r/,TRUE,https://github.com/k3jph/phonics-in-r,25840,25,2021-07-11T12:51:56Z,1033.6
photobiology,"Definitions of classes, methods, operators and functions for use 
    in photobiology and radiation meteorology and climatology. Calculation of
    effective (weighted) and not-weighted irradiances/doses, fluence rates,
    transmittance, reflectance, absorptance, absorbance and diverse ratios and 
    other derived quantities from spectral data. Local maxima and minima: peaks,
    valleys and spikes. Conversion between energy-and photon-based units. 
    Wavelength interpolation. Astronomical calculations related solar angles and 
    day length. Colours and vision. This package is part of the 'r4photobiology' 
    suite, Aphalo, P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.",2022-03-25,Pedro J. Aphalo,"https://docs.r4photobiology.info/photobiology/,
https://github.com/aphalo/photobiology",TRUE,https://github.com/aphalo/photobiology,37104,2,2022-07-10T16:35:30Z,18552
photobiologyInOut,"Functions for reading, and in some cases writing, foreign files 
    containing spectral data from spectrometers and their associated software, 
    output from daylight simulation models in common use, and some spectral 
    data repositories. As well as functions for exchange of spectral data with 
    other R packages. Part of the 'r4photobiology' suite, 
    Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.",2022-05-14,Pedro J. Aphalo,https://docs.r4photobiology.info/photobiologyInOut/,TRUE,https://github.com/aphalo/photobiologyinout,21640,0,2022-05-19T18:04:19Z,NA
photobiologyLamps,"Spectral emission data for some frequently used lamps including 
    bulbs and flashlights based on led emitting diodes (LEDs) but excluding
    LEDs available as electronic components. Original spectral irradiance data 
    for incandescent-, LED- and discharge lamps are included. They are 
    complemented by data on the effect of temperature on the emission by 
    fluorescent tubes. Part of the 'r4photobiology' suite, Aphalo P. J. (2015) 
    <doi:10.19232/uv4pb.2015.1.14>.",2022-03-11,Pedro J. Aphalo,"https://www.r4photobiology.info/,
https://github.com/aphalo/photobiologylamps",TRUE,https://github.com/aphalo/photobiologylamps,13258,0,2022-04-12T18:24:41Z,NA
photobiologyLEDs,"Spectral emission data for some frequently used light emitting
    diodes available as electronic components. Part of the 'r4photobiology' 
    suite, Aphalo P. J. (2015) <doi:10.19232/uv4pb.2015.1.14>.",2022-05-14,Pedro J. Aphalo,"https://docs.r4photobiology.info/photobiologyLEDs/,
https://github.com/aphalo/photobiologyLEDs",TRUE,https://github.com/aphalo/photobiologyleds,13178,1,2022-06-01T18:11:21Z,13178
PhotosynQ,"Connect R to the PhotosynQ platform (<https://photosynq.org>). It allows to login and logout,
    as well as receive project information and project data. Further it transforms the received JSON objects
    into a data frame, which can be used for the final data analysis.",2021-07-13,Sebastian Kuhlgert,https://github.com/Photosynq/PhotosynQ-R,TRUE,https://github.com/photosynq/photosynq-r,3718,4,2021-07-14T20:13:00Z,929.5
phreeqc,"A geochemical modeling program developed by the US Geological
    Survey that is designed to perform a wide variety of aqueous geochemical
    calculations, including speciation, batch-reaction, one-dimensional 
    reactive-transport, and inverse geochemical calculations.",2022-03-28,S.R. Charlton,https://www.usgs.gov/software/phreeqc-version-3,TRUE,https://github.com/usgs-coupled/iphreeqc,22450,0,2022-03-29T17:14:43Z,NA
phylin,"The spatial interpolation of genetic distances between
	     samples is based on a modified kriging method that
	     accepts a genetic distance matrix and generates a map of
	     probability of lineage presence. This package also offers
	     tools to generate a map of  potential contact zones
	     between groups with user-defined thresholds in the tree
	     to account for old and recent divergence. Additionally,
	     it has functions for IDW interpolation using genetic data
	     and midpoints.",2019-12-12,Pedro Tarroso,"https://www.r-project.org, https://github.com/ptarroso/phylin",TRUE,https://github.com/ptarroso/phylin,16830,3,2021-12-16T11:12:20Z,5610
PhylogeneticEM,"
    Implementation of the automatic shift detection method for
    Brownian Motion (BM) or Ornstein–Uhlenbeck (OU) models of trait evolution on
    phylogenies. Some tools to handle equivalent shifts configurations are also
    available. See Bastide et al. (2017) <doi:10.1111/rssb.12206> and
    Bastide et al. (2018) <doi:10.1093/sysbio/syy005>.",2021-09-16,Paul Bastide,https://github.com/pbastide/PhylogeneticEM,TRUE,https://github.com/pbastide/phylogeneticem,16136,14,2021-09-16T11:44:03Z,1152.5714285714287
phylolm,Provides functions for fitting phylogenetic linear models and phylogenetic generalized linear models. The computation uses an algorithm that is linear in the number of tips in the tree. The package also provides functions for simulating continuous or binary traits along the tree. Other tools include functions to test the adequacy of a population tree.,2020-06-22,Lam Si Tung Ho,https://github.com/lamho86/phylolm,TRUE,https://github.com/lamho86/phylolm,48348,22,2022-03-02T05:40:41Z,2197.6363636363635
phylopath,"A comprehensive and easy to use R implementation of confirmatory
    phylogenetic path analysis as described by Von Hardenberg and Gonzalez-Voyer
    (2012) <doi:10.1111/j.1558-5646.2012.01790.x>.",2021-10-04,Wouter van der Bijl,https://Ax3man.github.io/phylopath/,TRUE,https://github.com/ax3man/phylopath,17908,9,2021-10-04T18:50:19Z,1989.7777777777778
phyloregion,"Computational infrastructure for biogeography, community ecology,
    and biodiversity conservation (Daru et al. 2020) <doi:10.1111/2041-210X.13478>.
    It is based on the methods described in Daru et al. (2020) <doi:10.1038/s41467-020-15921-6>.
    The original conceptual work is described in Daru et al. (2017) <doi:10.1016/j.tree.2017.08.013>
    on patterns and processes of biogeographical regionalization. Additionally, the package
    contains fast and efficient functions to compute more standard conservation measures
    such as phylogenetic diversity, phylogenetic endemism, evolutionary distinctiveness
    and global endangerment, as well as compositional turnover (e.g., beta diversity).",2021-05-01,Barnabas H. Daru,"https://github.com/darunabas/phyloregion,
https://darunabas.github.io/phyloregion/index.html",TRUE,https://github.com/darunabas/phyloregion,11306,13,2022-06-14T18:14:07Z,869.6923076923077
phylosamp,"Implements novel tools that estimate the probability of true transmission between two cases given 
    phylogenetic linkage and the expected number of true transmission links in a sample. Methods described in
    Wohl, Giles, and Lessler (2021) <doi:10.1371/journal.pcbi.1009182>.",2021-11-22,Justin Lessler,https://github.com/HopkinsIDD/phylosamp,TRUE,https://github.com/hopkinsidd/phylosamp,1937,7,2021-11-20T22:06:41Z,276.7142857142857
phytools,"A wide range of functions for phylogenetic analysis - concentrated in phylogenetic comparative biology, but also including numerous methods for visualizing, manipulating, reading or writing, and even inferring phylogenetic trees. Included among the functions in phylogenetic comparative biology are various for ancestral state reconstruction, model-fitting, and simulation of phylogenies and data, for continuous, discrete, and multivariate characters. A broad range of plotting methods for phylogenies and comparative data include, but are not restricted to, methods for mapping trait evolution on trees, for projecting trees into phenotypic space or a geographic map, and for visualizing correlated speciation between trees. Finally, numerous functions are designed for reading, writing, analyzing, inferring, simulating, and manipulating phylogenetic trees and comparative data. For instance, there are functions for randomly or non-randomly attaching species or clades to a phylogeny, for computing consensus phylogenies from a set, for simulating trees and phylogenetic data under a range of models, and for a wide variety of other manipulations and analyses that phylogenetic biologists might find useful in their research.",2022-04-05,Liam J. Revell,https://github.com/liamrevell/phytools,TRUE,https://github.com/liamrevell/phytools,268567,144,2022-06-27T12:41:29Z,1865.048611111111
piar,"Most price indexes are made with a two-step procedure, where period-over-period elemental indexes are first calculated for a collection of elemental aggregates at each point in time, and then aggregated according to a price index aggregation structure. These indexes can then be chained together to form a time series that gives the evolution of prices with respect to a fixed base period. This package contains a collections of functions that revolve around this work flow, making it easy to build standard price indexes, and implement the methods described by Balk (2008, ISBN:978-1-107-40496-0), von der Lippe (2001, ISBN:3-8246-0638-0), and the CPI manual (2020, ISBN:978-1-51354-298-0) for bilateral price indexes.",2022-04-30,Steve Martin,https://github.com/marberts/piar,TRUE,https://github.com/marberts/piar,1533,1,2022-05-01T02:14:08Z,1533
picker,"Performant interactive scatterplot for ~ 1 million points. Zoom, pan,
    and pick points. Includes tooltips, labels, a grid overlay, legend, and
    coupled interactions across multiple plots.",2022-03-31,Alex Pickering,https://github.com/hms-dbmi/picker,TRUE,https://github.com/hms-dbmi/picker,853,2,2022-05-17T22:29:33Z,426.5
piecemaker,"Tokenizers break text into pieces that are more usable by machine 
    learning models. Many tokenizers share some preparation steps. This package
    provides those shared steps, along with a simple tokenizer.",2022-03-03,Jon Harmon,https://github.com/macmillancontentscience/piecemaker,TRUE,https://github.com/macmillancontentscience/piecemaker,4227,0,2022-03-03T14:01:23Z,NA
piecepackr,"Functions to make board game graphics with the 'ggplot2', 'grid', 'rayrender', 'rayvertex', and 'rgl' packages.  Specializes in game diagrams, animations, and ""Print & Play"" layouts for the 'piecepack' <https://www.ludism.org/ppwiki> but can make graphics for other board game systems.  Includes configurations for several public domain game systems such as checkers, (double-18) dominoes, go, 'piecepack', playing cards, etc.",2022-06-16,Trevor L Davis,"https://trevorldavis.com/piecepackr/ (blog),
https://trevorldavis.com/R/piecepackr/ (pkgdown),
https://groups.google.com/forum/#!forum/piecepackr (forum)",TRUE,https://github.com/piecepackr/piecepackr,17425,34,2022-06-17T18:23:10Z,512.5
piggyback,"Because larger (> 50 MB) data files cannot easily be committed to git,
  a different approach is required to manage data associated with an analysis in a 
  GitHub repository.  This package provides a simple work-around by allowing larger
  (up to 2 GB) data files to piggyback on a repository as assets attached to individual
  GitHub releases.  These files are not handled by git in any way, but instead are
  uploaded, downloaded, or edited directly by calls through the GitHub API. These
  data files can be versioned manually by creating different releases.  This approach
  works equally well with public or private repositories.  Data can be uploaded
  and downloaded programmatically from scripts. No authentication is required to
  download data from public repositories.",2022-05-19,Carl Boettiger,https://github.com/ropensci/piggyback,TRUE,https://github.com/ropensci/piggyback,26625,154,2022-07-07T15:54:23Z,172.8896103896104
pillar,"Provides 'pillar' and 'colonnade' generics designed
    for formatting columns of data using the full range of colours
    provided by modern terminals.",2022-02-01,Kirill Müller,"https://pillar.r-lib.org/, https://github.com/r-lib/pillar",TRUE,https://github.com/r-lib/pillar,39052107,145,2022-07-08T04:12:36Z,269324.87586206896
pinp,"A 'PNAS'-alike style for 'rmarkdown', derived from the
 'Proceedings of the National Academy of Sciences of the United States
 of America' ('PNAS', see <https://www.pnas.org>) 'LaTeX' style, and
 adapted for use with 'markdown' and 'pandoc'.",2020-10-01,Dirk Eddelbuettel and James Balamuta,http://dirk.eddelbuettel.com/code/pinp.html,TRUE,https://github.com/eddelbuettel/pinp,75898,142,2021-11-21T14:17:39Z,534.4929577464789
pins,"Publish data sets, models, and other R objects, making it
    easy to share them across projects and with your colleagues. You can
    pin objects to a variety of ""boards"", including local folders (to
    share on a networked drive or with 'DropBox'), 'RStudio' connect,
    Amazon S3, and more.",2021-12-15,Hadley Wickham,"https://pins.rstudio.com/, https://github.com/rstudio/pins",TRUE,https://github.com/rstudio/pins,85441,243,2022-06-30T20:34:00Z,351.6090534979424
PINstimation,"A comprehensive bundle of utilities for the estimation of probability of informed trading models: original PIN in Easley and O'Hara (1992) and Easley et al. (1996); Multilayer PIN (MPIN) in Ersan (2016); Adjusted PIN (AdjPIN) in Duarte and Young (2009); and volume-synchronized PIN (VPIN) in Easley et al. (2011, 2012). Implementations of various estimation methods suggested in the literature are included. Additional compelling features comprise posterior probabilities, an implementation of an expectation-maximization (EM) algorithm, and PIN decomposition into layers, and into bad/good components. Versatile data simulation tools, and trade classification algorithms are among the supplementary utilities. The package provides fast, compact, and precise utilities to tackle the sophisticated, error-prone, and time-consuming estimation procedure of informed trading, and this solely using the raw trade-level data. ",2022-05-27,Montasser Ghachem,"https://www.pinstimation.com,
https://github.com/monty-se/PINstimation",TRUE,https://github.com/monty-se/pinstimation,342,8,2022-06-22T17:18:44Z,42.75
pipebind,"Provides a simple function to bind a piped object to a placeholder
    symbol to enable complex function evaluation with the base R |> pipe.",2022-04-29,Brenton M. Wiernik  (<https://orcid.org/0000-0001-9560-6336>,https://github.com/bwiernik/pipebind/,TRUE,https://github.com/bwiernik/pipebind,813,36,2022-05-11T16:34:24Z,22.583333333333332
pipenostics,"Functions representing some useful empirical and data-driven 
    models of heat losses, corrosion diagnostics, reliability and predictive 
    maintenance of pipeline systems. The package is an option for digital 
    transformation of technical engineering departments of heat generating and 
    heat transferring companies. Methods are described in 
    Timashev et al. (2016) <doi:10.1007/978-3-319-25307-7>, 
    A.C.Reddy (2017) <doi:10.1016/j.matpr.2017.07.081>,
    Minenergo (2008) <https://docs.cntd.ru/document/902148459>,
    Minenergo (2005) <http://www.complexdoc.ru/ntdtext/547103>.",2021-03-02,Yuri Possokhov,https://omega1x.github.io/pipenostics/,TRUE,https://github.com/omega1x/pipenostics,3861,0,2022-03-04T05:52:36Z,NA
piRF,"Implements multiple state-of-the-art prediction interval methodologies for random forests. 
	These include: quantile regression intervals, out-of-bag intervals, bag-of-observations intervals, 
	one-step boosted random forest intervals, bias-corrected intervals, high-density intervals, and 
	split-conformal intervals. The implementations include a combination of novel adjustments to the 
	original random forest methodology and novel prediction interval methodologies. All of these 
	methodologies can be utilized using solely this package, rather than a collection of separate 
	packages. Currently, only regression trees are supported. Also capable of handling high dimensional data. 
	Roy, Marie-Helene and Larocque, Denis (2019) <doi:10.1177/0962280219829885>.
	Ghosal, Indrayudh and Hooker, Giles (2018) <arXiv:1803.08000>.
	Zhu, Lin and Lu, Jiaxin and Chen, Yihong (2019) <arXiv:1905.10101>.
	Zhang, Haozhe and Zimmerman, Joshua and Nettleton, Dan and Nordman, Daniel J. (2019) <doi:10.1080/00031305.2019.1585288>.
	Meinshausen, Nicolai (2006) <http://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdf>.
	Romano, Yaniv and Patterson, Evan and Candes, Emmanuel (2019) <arXiv:1905.03222>.
	Tung, Nguyen Thanh and Huang, Joshua Zhexue and Nguyen, Thuy Thi and Khan, Imran (2014) <doi:10.13140/2.1.2500.8002>.",2020-05-12,Chancellor Johnstone,http://github.com/chancejohnstone/piRF,TRUE,https://github.com/chancejohnstone/pirf,7123,7,2022-04-13T18:00:00Z,1017.5714285714286
pivmet,"Collection of pivotal algorithms 
             for: relabelling the MCMC chains in order to undo the label 
             switching problem in Bayesian mixture models,
             as proposed in Egidi, Pappadà, Pauli and Torelli (2018a)<doi:10.1007/s11222-017-9774-2>;
             initializing the centers of the classical k-means algorithm 
             in order to obtain a better clustering solution. For further details see
             Egidi, Pappadà, Pauli and Torelli (2018b)<ISBN:9788891910233>.",2021-04-30,Leonardo Egidi,https://github.com/leoegidi/pivmet,TRUE,https://github.com/leoegidi/pivmet,13252,5,2022-02-16T09:44:06Z,2650.4
piwikproR,Run Queries against the API of 'Piwik Pro' <https://developers.piwik.pro/en/latest/custom_reports/http_api/http_api.html>. The result is a tibble.,2021-10-11,Martin Stingl,https://github.com/dfv-ms/piwikproR,TRUE,https://github.com/dfv-ms/piwikpror,4406,0,2022-03-07T16:46:34Z,NA
pixarfilms,"Data about Disney Pixar films provided by Wikipedia. This
    package contains data about the films, the people involved, and their
    awards.",2021-07-27,Eric Leung,"https://github.com/erictleung/pixarfilms,
https://erictleung.com/pixarfilms/",TRUE,https://github.com/erictleung/pixarfilms,7879,12,2022-07-07T21:45:13Z,656.5833333333334
pkgbuild,"Provides functions used to build R packages. Locates compilers
  needed to build R packages on various platforms and ensures the PATH is
  configured appropriately so R can use them.",2021-12-20,Gábor Csárdi,https://github.com/r-lib/pkgbuild,TRUE,https://github.com/r-lib/pkgbuild,15229202,51,2022-05-21T04:14:05Z,298611.8039215686
pkgdepR,"Statically determine and visualize the function dependencies
    within and across packages. This may be useful for managing function 
    dependencies across a code base of multiple R packages.",2022-02-16,Ed Peyton,https://pkgdepR.org/,TRUE,https://github.com/edpeyton/pkgdepr,1421,1,2022-06-14T14:08:07Z,1421
pkgdown,"Generate an attractive and useful website from a source
    package.  'pkgdown' converts your documentation, vignettes, 'README',
    and more to 'HTML' making it easy to share information about your
    package online.",2022-06-23,Hadley Wickham,"https://pkgdown.r-lib.org, https://github.com/r-lib/pkgdown",TRUE,https://github.com/r-lib/pkgdown,18926405,627,2022-06-23T15:47:15Z,30185.653907496013
pkgKitten,"Provides a function kitten() which creates cute little 
 packages which pass R package checks. This sets it apart from 
 package.skeleton() which it calls, and which leaves imperfect files 
 behind. As this is not exactly helpful for beginners, kitten() offers 
 an alternative. Unit test support can be added via the 'tinytest'
 package (if present), and documentation-creation support can be
 added via 'roxygen2' (if present).",2021-07-20,Dirk Eddelbuettel,"https://github.com/eddelbuettel/pkgkitten,
https://dirk.eddelbuettel.com/code/pkgkitten.html",TRUE,https://github.com/eddelbuettel/pkgkitten,234474,31,2021-11-21T14:18:50Z,7563.677419354839
pkglite,"A tool, grammar, and standard to represent and exchange
    R package source code as text files. Converts one or more source
    packages to a text file and restores the package structures from the file.",2021-05-22,Nan Xiao,"https://merck.github.io/pkglite/, https://github.com/Merck/pkglite",TRUE,https://github.com/merck/pkglite,13726,18,2022-06-08T02:44:33Z,762.5555555555555
pkgload,"Simulates the process of installing a package and then
    attaching it. This is a key part of the 'devtools' package as it
    allows you to rapidly iterate while developing a package.",2022-06-27,Lionel Henry,"https://github.com/r-lib/pkgload, https://pkgload.r-lib.org",TRUE,https://github.com/r-lib/pkgload,17081421,50,2022-06-28T07:40:21Z,341628.42
pkgndep,"A new metric named 'dependency heaviness' is proposed that measures the number 
    of additional dependency packages that a parent package brings to its child package 
    and are unique to the dependency packages imported by all other parents.  
    The dependency heaviness analysis is visualized by a customized heatmap.",2022-06-09,Zuguang Gu,https://github.com/jokergoo/pkgndep,TRUE,https://github.com/jokergoo/pkgndep,10681,33,2022-06-09T12:13:17Z,323.6666666666667
pkgnet,"Tools from the domain of graph theory can be used to quantify the complexity
             and vulnerability to failure of a software package. That is the guiding philosophy
             of this package. 'pkgnet' provides tools to analyze the dependencies between functions
             in an R package and between its imported packages.  See the pkgnet website for vignettes 
             and other supplementary information.",2021-12-23,Brian Burns,"https://github.com/uptake/pkgnet, https://uptake.github.io/pkgnet/",TRUE,https://github.com/uptake/pkgnet,38309,124,2021-12-23T19:38:19Z,308.94354838709677
pkgsearch,"Search CRAN metadata about packages by keyword, popularity,
    recent activity, package name and more. Uses the 'R-hub' search server,
    see <https://r-pkg.org> and the CRAN metadata database, that
    contains information about CRAN packages. Note that this is _not_
    a CRAN project.",2022-02-16,Gábor Csárdi,"https://github.com/r-hub/pkgsearch,
https://r-hub.github.io/pkgsearch/",TRUE,https://github.com/r-hub/pkgsearch,222205,92,2022-06-17T10:55:26Z,2415.271739130435
pkgstats,"Static code analyses for R packages using the external code-tagging
    libraries ""ctags"" and ""gtags"". Static analyses enable packages to be
    analysed very quickly, generally a couple of seconds at most. The package
    also provides access to a database generating by applying the main function
    to the full CRAN archive, enabling the statistical properties of any package
    to be compared with all other CRAN packages.",2022-06-21,Mark Padgham,"https://docs.ropensci.org/pkgstats/,
https://github.com/ropensci-review-tools/pkgstats",TRUE,https://github.com/ropensci-review-tools/pkgstats,363,12,2022-07-01T13:07:03Z,30.25
PKNCA,"Compute standard Non-Compartmental Analysis (NCA) parameters for
    typical pharmacokinetic analyses and summarize them.",2021-10-29,Bill Denney,"https://billdenney.github.io/pknca/,
https://github.com/billdenney/pknca",TRUE,https://github.com/billdenney/pknca,33616,31,2022-06-22T21:05:45Z,1084.3870967741937
pksensi,"Applying the global sensitivity analysis workflow to investigate 
    the parameter uncertainty and sensitivity in physiologically based 
    kinetic (PK) models, especially the physiologically based 
    pharmacokinetic/toxicokinetic model with multivariate outputs. 
    The package also provides some functions to check the convergence 
    and sensitivity of model parameters. The workflow was first mentioned 
    in Hsieh et al., (2018) <doi:10.3389/fphar.2018.00588>, then further 
    refined (Hsieh et al., 2020 <doi:10.1016/j.softx.2020.100609>).                ",2021-07-04,Nan-Hung Hsieh,"https://github.com/nanhung/pksensi,
https://nanhung.github.io/pksensi/",TRUE,https://github.com/nanhung/pksensi,15767,4,2022-01-13T17:48:16Z,3941.75
PL94171,"Tools to process legacy format summary redistricting data files
    produced by the United States Census Bureau pursuant to P.L. 94-171. These
    files are generally available earlier but are difficult to work with as-is.",2022-05-10,Cory McCartan,"https://corymccartan.github.io/PL94171/,
https://github.com/CoryMcCartan/PL94171/",TRUE,https://github.com/corymccartan/pl94171,4794,5,2022-05-10T19:32:12Z,958.8
PlackettLuce,"Functions to prepare rankings data and fit the Plackett-Luce model
    jointly attributed to Plackett (1975) <doi:10.2307/2346567> and Luce
    (1959, ISBN:0486441369). The standard Plackett-Luce model is generalized
    to accommodate ties of any order in the ranking. Partial rankings, in which
    only a subset of items are ranked in each ranking, are also accommodated in
    the implementation. Disconnected/weakly connected networks implied by the
    rankings may be handled by adding pseudo-rankings with a hypothetical item.
    Optionally, a multivariate normal prior may be set on the log-worth
    parameters and ranker reliabilities may be incorporated as proposed by
    Raman and Joachims (2014) <doi:10.1145/2623330.2623654>. Maximum a
    posteriori estimation is used when priors are set. Methods are provided to
    estimate standard errors or quasi-standard errors for inference as well as
    to fit Plackett-Luce trees. See the package website or vignette for further
    details.",2021-08-16,Heather Turner,https://hturner.github.io/PlackettLuce/,TRUE,https://github.com/hturner/plackettluce,23673,14,2021-08-24T11:10:22Z,1690.9285714285713
plan,Supports the creation of 'burndown' charts and 'gantt' diagrams.,2022-04-06,Dan Kelley,https://github.com/dankelley/plan,TRUE,https://github.com/dankelley/plan,17310,30,2022-04-06T16:57:51Z,577
PlaneGeometry,"An extensive set of plane geometry routines. Provides R6 classes representing triangles, circles, circular arcs, ellipses, elliptical arcs and lines, and their plot methods. Also provides R6 classes representing transformations: rotations, reflections, homotheties, scalings, general affine transformations, inversions, Möbius transformations. ",2022-01-13,Stéphane Laurent,https://github.com/stla/PlaneGeometry,TRUE,https://github.com/stla/planegeometry,13974,8,2022-01-13T17:44:47Z,1746.75
PlanetNICFI,It includes functions to download and process the 'Planet NICFI' (Norway's International Climate and Forest Initiative) Satellite Imagery utilizing the Planet Mosaics API <https://developers.planet.com/docs/basemaps/reference/#tag/Basemaps-and-Mosaics>. 'GDAL' (library for raster and vector geospatial data formats) and 'aria2c' (paralleled download utility) must be installed and configured in the user's Operating System.,2022-02-06,Lampros Mouselimis,https://github.com/mlampros/PlanetNICFI,TRUE,https://github.com/mlampros/planetnicfi,5033,2,2022-02-07T07:52:53Z,2516.5
plater,"Tools for interacting with data from experiments done in microtiter
    plates. Easily read in plate-shaped data and convert it to tidy format, 
    combine plate-shaped data with tidy data, and view tidy data in plate shape.  ",2022-02-11,Sean Hughes,"https://docs.ropensci.org/plater/,
https://github.com/ropensci/plater",TRUE,https://github.com/ropensci/plater,18011,22,2022-02-11T19:24:48Z,818.6818181818181
platetools,"Collection of functions for working with multi-well microtitre
    plates, mainly 96, 384 and 1536 well plates.",2021-06-03,Scott Warchal,https://github.com/swarchal/platetools,TRUE,https://github.com/swarchal/platetools,18965,45,2021-08-02T15:06:00Z,421.44444444444446
platowork,"Data and analysis from an experiment with improving touch 
    typing speed, using the tDCS PlatoWork headset produced by PlatoScience.",2021-05-04,Lasse Hjorth Madsen,https://github.com/lassehjorthmadsen/platowork,TRUE,https://github.com/lassehjorthmadsen/platowork,4539,0,2022-03-14T21:30:33Z,NA
pleiotest,It performs a fast multi-trait genome-wide association analysis based on seemingly unrelated regressions. It tests for pleiotropic effects based on a series of Intersection-Union Wald tests. The package can handle large and unbalanced data and plot results.,2021-03-18,Fernando Aguate,https://github.com/FerAguate/pleiotest,TRUE,https://github.com/feraguate/pleiotest,4321,1,2021-10-08T16:45:28Z,4321
pliman,"Provides tools for image manipulation that will help you to
    quantify plant leaf area, disease severity, number of disease lesions,
    and obtain statistics of image objects such as grains, pods, pollen,
    leaves, and more. Tools to segment images and create binary images
    using the method of automatic threshold selection proposed by
    Otsu (1979) <doi:10.1109/tsmc.1979.4310076> are also provided.",2021-12-10,Tiago Olivoto,https://github.com/TiagoOlivoto/pliman,TRUE,https://github.com/tiagoolivoto/pliman,4862,16,2022-07-09T02:28:03Z,303.875
plinkQC,"Genotyping arrays enable the direct measurement of an individuals
    genotype at thousands of markers. 'plinkQC' facilitates genotype quality
    control for genetic association studies as described by Anderson and
    colleagues (2010) <doi:10.1038/nprot.2010.116>. It makes 'PLINK' basic
    statistics (e.g. missing genotyping rates per individual, allele frequencies
    per genetic marker) and relationship functions accessible from 'R' and
    generates a per-individual and per-marker quality control report.
    Individuals and markers that fail the quality control can subsequently be
    removed to generate a new, clean dataset. Removal of individuals based on
    relationship status is optimised to retain as many individuals as possible
    in the study.",2021-07-15,Hannah Meyer,https://meyer-lab-cshl.github.io/plinkQC/,TRUE,https://github.com/meyer-lab-cshl/plinkqc,18485,35,2021-12-04T15:09:13Z,528.1428571428571
plm,"A set of estimators for models and (robust) covariance matrices, and tests for panel data
             econometrics, including within/fixed effects, random effects, between, first-difference, 
             nested random effects as well as instrumental-variable (IV) and Hausman-Taylor-style models,
             panel generalized method of moments (GMM) and general FGLS models,
             mean groups (MG), demeaned MG, and common correlated effects (CCEMG) and pooled (CCEP) estimators
             with common factors, variable coefficients and limited dependent variables models.
             Test functions include model specification, serial correlation, cross-sectional dependence,
             panel unit root and panel Granger (non-)causality. Typical references are general econometrics 
             text books such as Baltagi (2021), Econometric Analysis of Panel Data, ISBN-13:978-3-030-53952-8, 
             Hsiao (2014), Analysis of Panel Data <doi:10.1017/CBO9781139839327>, and Croissant and Millo (2018), 
             Panel Data Econometrics with R, ISBN-13:978-1-118-94918-4.",2022-03-05,Yves Croissant,"https://cran.r-project.org/package=plm (CRAN releases),
https://github.com/ycroissant/plm (development repository)",TRUE,https://github.com/ycroissant/plm,1441881,25,2022-06-24T20:25:58Z,57675.24
PLNmodels,"The Poisson-lognormal model and variants (Chiquet, Mariadassou and Robin, 
    2020 <doi:10.1101/2020.10.07.329383>) can be used for 
    a variety of multivariate problems when count data are at play, including 
    principal component analysis for count data, discriminant analysis, model-based clustering and 
    network inference. Implements variational algorithms to fit such models accompanied with a set of 
    functions for visualization and diagnostic. ",2022-02-01,Julien Chiquet,https://pln-team.github.io/PLNmodels/,TRUE,https://github.com/pln-team/plnmodels,16350,41,2022-04-04T15:40:54Z,398.780487804878
plnr,"A system to plan analyses within the mental model
    where you have one (or more) datasets and want to run either A) the same 
    function multiple times with different arguments, or B) multiple functions. 
    This is appropriate when you have multiple strata (e.g. locations, age groups)
    that you want to apply the same function to, or you have multiple variables 
    (e.g. exposures) that you want to apply the same statistical method to, or
    when you are creating the output for a report and you need multiple different
    tables or graphs.",2022-06-09,Richard Aubrey White,"https://docs.sykdomspulsen.no/plnr/,
https://github.com/sykdomspulsen-org/plnr",TRUE,https://github.com/sykdomspulsen-org/plnr,401,1,2022-06-08T09:38:01Z,401
plot.matrix,Visualizes a matrix object plainly as heatmap. It provides S3 functions to plot simple matrices and loading matrices.,2022-03-16,Sigbert Klinke,https://github.com/sigbertklinke/plot.matrix (development version),TRUE,https://github.com/sigbertklinke/plot.matrix,59774,4,2022-03-16T10:30:52Z,14943.5
plot3logit,"An implementation of the ternary plot for interpreting regression
    coefficients of trinomial regression models, as proposed in Santi, Dickson
    and Espa (2019) <doi:10.1080/00031305.2018.1442368>. Ternary plots can be
    drawn using either 'ggtern' package (based on 'ggplot2') or 'Ternary'
    package (based on standard graphics).",2022-04-15,Flavio Santi,https://www.flaviosanti.it/software/plot3logit/,TRUE,https://github.com/f-santi/plot3logit,15172,2,2022-04-15T12:40:37Z,7586
plotBart,"Functions to assist in diagnostics and plotting during the causal inference modeling process. 
  Supplements the 'bartCause' package.",2022-05-27,Joseph Marlo,"https://priism-center.github.io/plotBart/,
https://github.com/priism-center/plotBart",TRUE,https://github.com/priism-center/plotbart,358,0,2022-06-13T23:46:59Z,NA
plotKML,"Writes spatial-class, spacetime-class, raster-class and similar spatial and spatiotemporal objects to KML following some basic cartographic rules.",2022-06-07,Tomislav Hengl,https://github.com/Envirometrix/plotKML,TRUE,https://github.com/envirometrix/plotkml,75649,24,2022-06-07T08:09:51Z,3152.0416666666665
plotly,Create interactive web graphics from 'ggplot2' graphs and/or a custom interface to the (MIT-licensed) JavaScript library 'plotly.js' inspired by the grammar of graphics.,2021-10-09,Carson Sievert,"https://plotly-r.com, https://github.com/plotly/plotly.R,
https://plotly.com/r/",TRUE,https://github.com/plotly/plotly.r,7359686,2214,2022-05-04T19:07:56Z,3324.1580849141824
plotmm,"The main function, plot_mm(), is used for plotting output from mixture models, 
    including both densities and overlaying mixture weight component curves from the fit models. In line with the
    tidyverse, the package also includes the plot_cut_point() function to visualize the cutpoint (mu) from the model
    over a histogram of the data density with several color options. Finally, the package includes the plot_mix_comps() 
    helper function, which is used for both added customization as well as in the plot_mm() function. 
    Supported model objects include: 'mixtools', 'EMCluster', and 'flexmix', with more from each forthcoming. 
    Supported mixture model specifications include mixtures of univariate Gaussians, multivariate Gaussians, Gammas, 
    logistic regressions, linear regressions, and Poisson regressions.",2020-07-10,Philip Waggoner,NA,TRUE,https://github.com/pdwaggoner/plotmm,8569,21,2022-04-29T14:27:39Z,408.04761904761904
plotROC,"Most ROC curve plots obscure the cutoff values and inhibit
    interpretation and comparison of multiple curves. This attempts to address
    those shortcomings by providing plotting and interactive tools. Functions
    are provided to generate an interactive ROC curve plot for web use, and
    print versions. A Shiny application implementing the functions is also
    included.",2022-05-26,Michael C. Sachs,https://sachsmc.github.io/plotROC/,TRUE,https://github.com/sachsmc/plotroc,172361,80,2022-05-27T09:34:16Z,2154.5125
PLreg,"Fitting power logit regression models for bounded
  continuous data, in which the density generator may be normal, Student-t, 
  power exponential, slash, hyperbolic, sinh-normal, or type II logistic. 
  Diagnostic tools associated with the fitted model, such as the residuals, 
  local influence measures, leverage measures, and goodness-of-fit statistics,
  are implemented. The estimation process follows the maximum likelihood approach
  and, currently, the package supports two types of estimators: the usual maximum 
  likelihood estimator and the penalized maximum likelihood estimator. More details
  about power logit regression models are described in 
  Queiroz and Ferrari (2022) <arXiv:2202.01697>.",2022-03-30,Felipe Queiroz,https://github.com/ffqueiroz/PLreg,TRUE,https://github.com/ffqueiroz/plreg,850,0,2022-05-27T18:33:19Z,NA
pls,"Multivariate regression methods
	Partial Least Squares Regression (PLSR), Principal Component
	Regression (PCR) and Canonical Powered Partial Least Squares (CPPLS).",2021-09-03,Kristian Hovde Liland,https://github.com/khliland/pls,TRUE,https://github.com/khliland/pls,1162047,27,2021-09-02T18:46:01Z,43038.77777777778
plsmod,"Bindings for additional regression models for use with the
    'parsnip' package, including ordinary and spare partial least squares
    models for regression and classification (Rohart et al (2017)
    <doi:10.1371/journal.pcbi.1005752>).",2022-03-09,Max Kuhn,"https://plsmod.tidymodels.org,
https://github.com/tidymodels/plsmod",TRUE,https://github.com/tidymodels/plsmod,11611,12,2022-04-06T18:47:15Z,967.5833333333334
plsRbeta,"Provides Partial least squares Regression for (weighted) beta regression models (Bertrand 2013,  <http://journal-sfds.fr/article/view/215>) and k-fold cross-validation of such models using various criteria. It allows for missing data in the explanatory variables. Bootstrap confidence intervals constructions are also available.",2022-05-02,Frederic Bertrand,"https://fbertran.github.io/plsRbeta/,
https://github.com/fbertran/plsRbeta/",TRUE,https://github.com/fbertran/plsrbeta,15001,2,2022-05-02T23:12:11Z,7500.5
plsRglm,Provides (weighted) Partial least squares Regression for generalized linear models and repeated k-fold cross-validation of such models using various criteria <arXiv:1810.01005>. It allows for missing data in the explanatory variables. Bootstrap confidence intervals constructions are also available.,2022-05-02,Frederic Bertrand,"https://fbertran.github.io/plsRglm/,
https://github.com/fbertran/plsRglm/",TRUE,https://github.com/fbertran/plsrglm,32106,12,2022-05-02T22:28:18Z,2675.5
plsVarSel,"Interfaces and methods for variable selection in Partial Least
    Squares. The methods include filter methods, wrapper methods and embedded
    methods. Both regression and classification is supported.",2022-01-04,Kristian Hovde Liland,https://github.com/khliland/plsVarSel/,TRUE,https://github.com/khliland/plsvarsel,32216,1,2021-12-28T10:10:55Z,32216
plu,"Converts English phrases to singular or plural form based on
    the length of an associated vector.  Contains helper functions to
    create natural language lists from vectors and to include the length
    of a vector in natural language.",2022-06-07,Alexander Rossell Hayes,"https://plu.rossellhayes.com, https://github.com/rossellhayes/plu",TRUE,https://github.com/rossellhayes/plu,17117,1,2022-06-07T17:56:04Z,17117
plumber,"Gives the ability to automatically generate and serve an HTTP API
    from R functions using the annotations in the R documentation around your
    functions.",2022-07-09,Barret Schloerke,"https://www.rplumber.io, https://github.com/rstudio/plumber",TRUE,https://github.com/rstudio/plumber,1176691,1271,2022-07-10T03:05:40Z,925.7993705743509
plumbertableau,"Build 'Plumber' APIs that can be used in 'Tableau' workbooks.
    Annotations in R comments allow APIs to conform to the 'Tableau Analytics
    Extension' specification, so that R code can be used to power 'Tableau'
    workbooks.",2021-08-06,James Blair,"https://rstudio.github.io/plumbertableau/,
https://github.com/rstudio/plumbertableau",TRUE,https://github.com/rstudio/plumbertableau,4568,18,2021-10-22T22:54:12Z,253.77777777777777
plyr,"A set of tools that solves a common set of problems: you need
    to break a big problem down into manageable pieces, operate on each
    piece and then put all the pieces back together.  For example, you
    might want to fit a model to each spatial location or time point in
    your study, summarise data by panels or collapse high-dimensional
    arrays to simpler summary statistics. The development of 'plyr' has
    been generously supported by 'Becton Dickinson'.",2022-03-24,Hadley Wickham,"http://had.co.nz/plyr, https://github.com/hadley/plyr",TRUE,https://github.com/hadley/plyr,15830628,490,2022-03-26T12:40:28Z,32307.404081632652
PMA,"Performs Penalized Multivariate Analysis: a penalized
        matrix decomposition, sparse principal components analysis,
        and sparse canonical correlation analysis, described in
        Witten, Tibshirani and Hastie (2009)
        <doi:10.1093/biostatistics/kxp008> and Witten and Tibshirani
        (2009) Extensions of sparse canonical correlation analysis,
        with applications to genomic data
        <doi:10.2202/1544-6115.1470>.",2020-02-03,Daniela Witten and Rob Tibshirani,https://github.com/bnaras/PMA,TRUE,https://github.com/bnaras/pma,35223,4,2022-02-06T23:44:06Z,8805.75
PMA2,"A modified version of PMA. The CCA() and CCA.permute() functions can also compute the
	component-wise standard deviations of estimated U and V through 
	permutations in addition to standardize them. Furthermore, it computes 
	the non-parametric p-values for each components. 
	Performs Penalized Multivariate Analysis: a penalized matrix decomposition, sparse principal 	
	components analysis, and sparse canonical correlation analysis, described in
        Ali Mahzarnia, Alexander Badea (2022), ""Joint Estimation of Vulnerable Brain Networks and Alzheimer’s Disease Risk Via Novel Extension of Sparse Canonical Correlation"" at bioRxiv.",2022-05-12,Ali Mahzarnia,https://github.com/Ali-Mahzarnia/PMA2,TRUE,https://github.com/ali-mahzarnia/pma2,503,0,2022-05-29T04:01:34Z,NA
pmd,"Paired mass distance (PMD) analysis proposed in Yu, Olkowicz and Pawliszyn (2018) <doi:10.1016/j.aca.2018.10.062> for gas/liquid chromatography–mass spectrometry (GC/LC-MS) based non-targeted analysis. PMD analysis including GlobalStd algorithm and structure/reaction directed analysis. GlobalStd algorithm could found independent peaks in m/z-retention time profiles based on retention time hierarchical cluster analysis and frequency analysis of paired mass distances within retention time groups. Structure directed analysis could be used to find potential relationship among those independent peaks in different retention time groups based on frequency of paired mass distances. Reactomics analysis could also be performed to build PMD network, assign sources and make biomarker reaction discovery. GUIs for PMD analysis is also included as 'shiny' applications.",2021-01-21,Miao YU,https://yufree.github.io/pmd/,TRUE,https://github.com/yufree/pmd,11207,6,2022-07-06T19:39:38Z,1867.8333333333333
pmetar,"Allows to download current and historical METAR weather reports
  extract and parse basic parameters and present main weather information. 
  Current reports are downloaded from Aviation Weather Center 
  <https://www.aviationweather.gov/metar> and historical reports from
  Iowa Environmental Mesonet web page of Iowa State University
  ASOS-AWOS-METAR <http://mesonet.agron.iastate.edu/AWOS/>.",2022-03-08,Pawel Cwiek,https://github.com/prcwiek/pmetar,TRUE,https://github.com/prcwiek/pmetar,8282,4,2022-05-06T18:21:32Z,2070.5
pmlbr,"Check available classification and regression data sets from the PMLB repository and download them.
    The PMLB repository (<https://github.com/EpistasisLab/pmlbr>) contains a curated collection of data sets for evaluating and comparing machine learning algorithms.
    These data sets cover a range of applications, and include binary/multi-class classification problems and 
    regression problems, as well as combinations of categorical, ordinal, and continuous features.
    There are currently over 150 datasets included in the PMLB repository.",2020-10-02,Trang Le,https://github.com/EpistasisLab/pmlbr,TRUE,https://github.com/epistasislab/pmlbr,6682,7,2021-09-13T20:51:45Z,954.5714285714286
pmml,"The Predictive Model Markup Language (PMML) is an XML-based language which provides a way for applications to define machine learning, statistical and data mining models and to share models between PMML compliant applications. More information about the PMML industry standard and the Data Mining Group can be found at <http://dmg.org/>. The generated PMML can be imported into any PMML consuming application, such as Zementis Predictive Analytics products. The package isofor (used for anomaly detection) can be installed with devtools::install_github(""gravesee/isofor"").",2022-03-04,Dmitriy Bolotov,"https://open-source.softwareag.com/r-pmml/,
https://github.com/SoftwareAG/r-pmml,
https://www.softwareag.com/corporate/products/az/zementis/default.html",TRUE,https://github.com/softwareag/r-pmml,140228,20,2022-03-08T01:06:09Z,7011.4
pmparser,"Provides a simple interface for extracting various elements from
  the publicly available PubMed XML files, incorporating PubMed's regular
  updates, and combining the data with the NIH Open Citation Collection. See
  Schoenbachler and Hughey (2021) <doi:10.7717/peerj.11071>.",2022-04-27,Jake Hughey,"https://pmparser.hugheylab.org,
https://github.com/hugheylab/pmparser",TRUE,https://github.com/hugheylab/pmparser,774,7,2022-05-23T15:09:36Z,110.57142857142857
PMwR,"Functions and examples for 'Portfolio
  Management with R': backtesting investment and
  trading strategies, computing profit/loss and
  returns, analysing trades, handling lists of
  transactions, reporting, and more.",2021-10-19,Enrico Schumann,"http://enricoschumann.net/PMwR/,
https://github.com/enricoschumann/PMwR,
https://gitlab.com/enricoschumann/PMwR",TRUE,https://github.com/enricoschumann/pmwr,15940,43,2022-06-23T06:39:12Z,370.69767441860466
pmxTools,"Pharmacometric tools for common data analytical tasks; closed-form solutions for calculating concentrations at given 
    times after dosing based on compartmental PK models (1-compartment, 2-compartment and 3-compartment, covering infusions, zero- 
    and first-order absorption, and lag times, after single doses and at steady state, per Bertrand & Mentre (2008) 
    <http://lixoft.com/wp-content/uploads/2016/03/PKPDlibrary.pdf>); parametric simulation from NONMEM-generated parameter estimates 
    and other output; and parsing, tabulating and plotting results generated by Perl-speaks-NONMEM (PsN).",2022-04-06,Justin Wilkins,https://github.com/kestrel99/pmxTools,TRUE,https://github.com/kestrel99/pmxtools,16546,15,2022-04-14T12:20:51Z,1103.0666666666666
PNADcIBGE,"Provides tools for downloading, reading and analyzing the PNADC,
	a household survey from Brazilian Institute of Geography and Statistics - IBGE.
	The data must be downloaded from the official website <https://www.ibge.gov.br/>. 
	Further analysis must be made using package 'survey'.",2021-11-30,Gabriel Assuncao,NA,TRUE,https://github.com/gabriel-assuncao/pnadcibge,38535,6,2021-11-30T13:20:10Z,6422.5
PNSIBGE,"Provides tools for downloading, reading and analyzing the PNS,
	a household survey from Brazilian Institute of Geography and Statistics - IBGE.
	The data must be downloaded from the official website <https://www.ibge.gov.br/>. 
	Further analysis must be made using package 'survey'.",2022-03-24,Gabriel Assuncao,NA,TRUE,https://github.com/gabriel-assuncao/pnsibge,9565,2,2022-03-24T16:30:02Z,4782.5
PNWColors,"PNW-Inspired Palettes for 'R' data visualizations. Palettes are variable 
	in length and checked for colorblind accessibility from hue, saturation, 
	and lightness value scaling using the 'Chroma.js  Color Palette Helper' 
	<https://gka.github.io/palettes/>.",2020-06-12,Jake Lawlor,https://github.com/jakelawlor/PNWColors,TRUE,https://github.com/jakelawlor/pnwcolors,9193,185,2022-03-10T17:37:24Z,49.69189189189189
poems,"The poems package provides a framework of interoperable R6 classes 
    (Chang, 2020, <https://CRAN.R-project.org/package=R6>) for building ensembles 
    of viable models via the pattern-oriented modeling (POM) approach (Grimm et al.,
    2005, <doi:10.1126/science.1116681>). The package includes classes for 
    encapsulating and generating model parameters, and managing the POM workflow. 
    The workflow includes: model setup; generating model parameters via Latin 
    hyper-cube sampling (Iman & Conover, 1980, <doi:10.1080/03610928008827996>); 
    running multiple sampled model simulations; collating summary results; and 
    validating and selecting an ensemble of models that best match known patterns. 
    By default, model validation and selection utilizes an approximate Bayesian 
    computation (ABC) approach (Beaumont et al., 2002, 
    <doi:10.1093/genetics/162.4.2025>), although alternative user-defined 
    functionality could be employed. The package includes a spatially explicit 
    demographic population model simulation engine, which incorporates default 
    functionality for density dependence, correlated environmental stochasticity, 
    stage-based transitions, and distance-based dispersal. The user may customize
    the simulator by defining functionality for translocations, harvesting, 
    mortality, and other processes, as well as defining the sequence order for the 
    simulator processes. The framework could also be adapted for use with other 
    model simulators by utilizing its extendable (inheritable) base classes.",2022-01-17,Sean Haythorne,https://github.com/GlobalEcologyLab/poems,TRUE,https://github.com/globalecologylab/poems,10032,7,2022-01-17T00:32:22Z,1433.142857142857
POFIBGE,"Provides tools for downloading, reading and analyzing the POF,
	a household survey from Brazilian Institute of Geography and Statistics - IBGE.
	The data must be downloaded from the official website <https://www.ibge.gov.br/>. 
	Further analysis must be made using package 'survey'.",2022-03-24,Gabriel Assuncao,NA,TRUE,https://github.com/gabriel-assuncao/pofibge,8796,5,2022-03-24T18:00:02Z,1759.2
pointblank,"Validate data in data frames, 'tibble' objects, 'Spark'
    'DataFrames', and database tables. Validation pipelines can be made using
    easily-readable, consecutive validation steps. Upon execution of the
    validation plan, several reporting options are available. User-defined
    thresholds for failure rates allow for the determination of appropriate
    reporting actions. Many other workflows are available including an
    information management workflow, where the aim is to record, collect, and
    generate useful information on data tables.",2022-01-23,Richard Iannone,"https://rich-iannone.github.io/pointblank/,
https://github.com/rich-iannone/pointblank",TRUE,https://github.com/rich-iannone/pointblank,182815,647,2022-07-10T01:09:16Z,282.5579598145286
PointedSDMs,"Integrated species distribution modeling is a rising field in quantitative ecology thanks to significant rises in the quantity of data available, increases in computational speed and the proven benefits of using such models. 
  Despite this, the general software to help ecologists construct such models in an easy-to-use framework is lacking. 
  We therefore introduce the R package 'PointedSDMs': which provides the tools to help ecologists set up integrated models and perform inference on them.
  There are also functions within the package to help run spatial cross-validation for model selection, as well as generic plotting and predicting functions.
  An introduction to these methods is discussed in Issac, Jarzyna, Keil, Dambly, Boersch-Supan, Browning, Freeman, Golding, Guillera-Arroita, Henrys, Jarvis, Lahoz-Monfort, Pagel, Pescott, Schmucki, Simmonds and O’Hara (2020) <doi:10.1016/j.tree.2019.08.006>.",2022-06-15,Philip Mostert,https://github.com/PhilipMostert/PointedSDMs,TRUE,https://github.com/philipmostert/pointedsdms,363,8,2022-06-15T13:58:06Z,45.375
poismf,"Creates a non-negative low-rank approximate factorization of a sparse counts matrix by maximizing Poisson
    likelihood with L1/L2 regularization (e.g. for implicit-feedback recommender systems or bag-of-words-based topic modeling)
    (Cortes, (2018) <arXiv:1811.01908>), which usually leads to very sparse user and item factors (over 90% zero-valued).
    Similar to hierarchical Poisson factorization (HPF), but follows an optimization-based approach with regularization
    instead of a hierarchical prior, and is fit through gradient-based methods instead of variational inference.",2022-02-25,David Cortes,https://github.com/david-cortes/poismf,TRUE,https://github.com/david-cortes/poismf,17209,37,2022-05-30T20:00:28Z,465.1081081081081
PoissonBinomial,"Efficient implementations of multiple exact and approximate methods as described in Hong (2013) <doi:10.1016/j.csda.2012.10.006>, Biscarri, Zhao & Brunner (2018) <doi:10.1016/j.csda.2018.01.007> and Zhang, Hong & Balakrishnan (2018) <doi:10.1080/00949655.2018.1440294> for computing the probability mass, cumulative distribution and quantile functions, as well as generating random numbers for both the ordinary and generalized Poisson binomial distribution.",2022-05-31,Florian Junge,https://github.com/DISOhda/PoissonBinomial,TRUE,https://github.com/disohda/poissonbinomial,23007,0,2022-05-31T09:48:38Z,NA
poissonreg,"Bindings for Poisson regression models for use with the
    'parsnip' package. Models include simple generalized linear models,
    Bayesian models, and zero-inflated Poisson models (Zeileis, Kleiber,
    and Jackman (2008) <doi:10.18637/jss.v027.i08>).",2022-06-15,Max Kuhn,"https://github.com/tidymodels/poissonreg,
https://poissonreg.tidymodels.org/",TRUE,https://github.com/tidymodels/poissonreg,31195,14,2022-06-15T12:39:21Z,2228.214285714286
poLCA,"Latent class analysis and latent class regression models 
    for polytomous outcome variables.  Also known as latent structure analysis.",2022-04-25,Drew Linzer,https://github.com/dlinzer/poLCA,TRUE,https://github.com/dlinzer/polca,167526,38,2022-04-05T16:13:08Z,4408.578947368421
PolicyPortfolios,"Tools for simplifying the creation and management of data structures
    suitable for dealing with policy portfolios, that is, two-dimensional spaces 
    of policy instruments and policy targets. The package also allows to generate measures of
    portfolio characteristics and facilitates their visualization.",2022-03-11,Xavier Fernández i Marín,"http://xavier-fim.net/packages/PolicyPortfolios/,
https://github.com/xfim/PolicyPortfolios",TRUE,https://github.com/xfim/policyportfolios,5183,0,2022-03-16T09:54:03Z,NA
policytree,"Learn optimal policies via doubly robust empirical
 welfare maximization over trees. Given doubly robust reward estimates, this package
 finds a rule-based treatment prescription policy, where the policy takes the form of
 a shallow decision tree that is globally (or close to) optimal.",2022-03-18,Erik Sverdrup,https://github.com/grf-labs/policytree,TRUE,https://github.com/grf-labs/policytree,18362,56,2022-07-08T17:40:36Z,327.89285714285717
polished,"Easily add modern authentication and user administration to your 'shiny' apps. 
  Customize user sign in and registration pages to match your brand.  Control who can
  access one or more of your 'shiny' apps. Also, deploy & host your apps with Polished Hosting.",2022-02-24,Andy Merlino,"https://github.com/tychobra/polished, https://polished.tech",TRUE,https://github.com/tychobra/polished,12167,198,2022-06-23T12:02:10Z,61.44949494949495
pollen,"Supports analysis of aerobiological data. 
    Available features include determination of pollen season limits, 
    replacement of outliers (Kasprzyk and Walanus (2014) <doi:10.1007/s10453-014-9332-8>),
    calculation of growing degree days (Baskerville and Emin (1969) <doi:10.2307/1933912>), 
    and determination of the base temperature for growing degree days
    (Yang et al. (1995) <doi:10.1016/0168-1923(94)02185-M).",2021-12-03,Jakub Nowosad,https://nowosad.github.io/pollen/,TRUE,https://github.com/nowosad/pollen,16626,3,2021-12-03T11:18:59Z,5542
polmineR,"Package for corpus analysis using the Corpus Workbench 
    ('CWB', <https://cwb.sourceforge.io>) as an efficient back end for indexing
    and querying large corpora. The package offers functionality to flexibly create
    subcorpora and to carry out basic statistical operations (count, co-occurrences
    etc.). The original full text of documents can be reconstructed and inspected at
    any time. Beyond that, the package is intended to serve as an interface to 
    packages implementing advanced statistical procedures. Respective data structures
    (document-term matrices, term-co-occurrence matrices etc.) can be created based 
    on the indexed corpora.",2022-05-05,Andreas Blaette,https://github.com/PolMine/polmineR,TRUE,https://github.com/polmine/polminer,22018,37,2022-05-05T20:50:35Z,595.081081081081
polyCub,"Numerical integration of continuously differentiable
    functions f(x,y) over simple closed polygonal domains.
    The following cubature methods are implemented:
    product Gauss cubature (Sommariva and Vianello, 2007,
    <doi:10.1007/s10543-007-0131-2>),
    the simple two-dimensional midpoint rule
    (wrapping 'spatstat.geom' functions),
    adaptive cubature for radially symmetric functions via line
    integrate() along the polygon boundary (Meyer and Held, 2014,
    <doi:10.1214/14-AOAS743>, Supplement B),
    and integration of the bivariate Gaussian density based on
    polygon triangulation.
    For simple integration along the axes, the 'cubature' package
    is more appropriate.",2021-01-27,Sebastian Meyer,https://github.com/bastistician/polyCub,TRUE,https://github.com/bastistician/polycub,33962,5,2022-03-08T21:43:17Z,6792.4
polyMatrix,"
  Implementation of class ""polyMatrix"" for storing a matrix of polynomials and implements 
  basic matrix operations; including a determinant and characteristic polynomial.
  It is based on the package 'polynom' and uses a lot of its methods to implement matrix operations.
  This package includes 3 methods of triangularization of polynomial matrices:
  Extended Euclidean algorithm which is most classical but numerically unstable;
  Sylvester algorithm based on LQ decomposition;
  Interpolation algorithm is based on LQ decomposition and Newton interpolation.
  Both methods are described in 
  D. Henrion & M. Sebek, Reliable numerical methods for polynomial matrix triangularization,
  IEEE Transactions on Automatic Control (Volume 44, Issue 3, Mar 1999, Pages 497-508) <doi:10.1109/9.751344>
  and in 
  Salah Labhalla, Henri Lombardi & Roger Marlin, 
  Algorithmes de calcule de la reduction de Hermite d'une matrice a coefficients polynomeaux,
  Theoretical Computer Science (Volume 161, Issue 1-2, July 1996, Pages 69-92) <doi:10.1016/0304-3975(95)00090-9>.",2021-07-18,Nikolai Ryzhkov,https://github.com/namezys/polymatrix,TRUE,https://github.com/namezys/polymatrix,13288,1,2021-07-11T21:42:44Z,13288
polypharmacy,"Analyse prescription drug deliveries to calculate several indicators of polypharmacy corresponding to the various definitions found in the literature.
  Bjerrum, L., Rosholm, J. U., Hallas, J., & Kragstrup, J. (1997) <doi:10.1007/s002280050329>.
  Chan, D.-C., Hao, Y.-T., & Wu, S.-C. (2009a) <doi:10.1002/pds.1712>.
  Fincke, B. G., Snyder, K., Cantillon, C., Gaehde, S., Standring, P., Fiore, L., ... Gagnon, D.R. (2005) <doi:10.1002/pds.966>.
  Hovstadius, B., Astrand, B., & Petersson, G. (2009) <doi:10.1186/1472-6904-9-11>.
  Hovstadius, B., Astrand, B., & Petersson, G. (2010) <doi:10.1002/pds.1921>.
  Kennerfalk, A., Ruigómez, A., Wallander, M.-A., Wilhelmsen, L., & Johansson, S. (2002) <doi:10.1345/aph.1A226>.
  Masnoon, N., Shakib, S., Kalisch-Ellett, L., & Caughey, G. E. (2017) <doi:10.1186/s12877-017-0621-2>.
  Narayan, S. W., & Nishtala, P. S. (2015) <doi:10.1007/s40801-015-0020-y>.
  Nishtala, P. S., & Salahudeen, M. S. (2015) <doi:10.1159/000368191>.
  Park, H. Y., Ryu, H. N., Shim, M. K., Sohn, H. S., & Kwon, J. W. (2016) <doi:10.5414/cp202484>.
  Veehof, L., Stewart, R., Haaijer-Ruskamp, F., & Jong, B. M. (2000) <doi:10.1093/fampra/17.3.261>.",2021-07-12,Guillaume Boucher,NA,TRUE,https://github.com/guiboucher/polypharmacy,3272,3,2021-09-16T20:10:27Z,1090.6666666666667
polypoly,"Tools for reshaping, plotting, and manipulating matrices of orthogonal polynomials.",2017-05-27,Tristan Mahr,https://github.com/tjmahr/polypoly,TRUE,https://github.com/tjmahr/polypoly,10574,14,2022-01-14T13:58:38Z,755.2857142857143
polyRAD,"Read depth data from genotyping-by-sequencing (GBS) or restriction 
  site-associated DNA sequencing (RAD-seq) are imported and used to make Bayesian
  probability estimates of genotypes in polyploids or diploids.  The genotype 
  probabilities, posterior mean genotypes, or most probable genotypes can then
  be exported for downstream analysis.  'polyRAD' is described by Clark et al.
  (2019) <doi:10.1534/g3.118.200913>.  A variant calling pipeline for highly
  duplicated genomes is also included and is described by Clark et al. (2020)
  <doi:10.1101/2020.01.11.902890>.",2022-02-15,Lindsay V. Clark,https://github.com/lvclark/polyRAD,TRUE,https://github.com/lvclark/polyrad,14433,16,2022-04-08T15:49:53Z,902.0625
polyreg,"Automate formation and evaluation of polynomial regression models. The motivation for this package is described in 'Polynomial Regression As an Alternative to Neural Nets' by Xi Cheng, Bohdan Khomtchouk, Norman Matloff, and Pete Mohanty (<arXiv:1806.06850>).",2022-03-31,Norm Matloff,https://github.com/matloff/polyreg,TRUE,https://github.com/matloff/polyreg,13955,176,2022-06-03T19:31:05Z,79.28977272727273
pomdp,"Provides the infrastructure to define and analyze the solutions of Partially Observable Markov Decision Process (POMDP) models. Interfaces for various exact and approximate solution algorithms are available including value iteration, point-based value iteration and SARSOP. Smallwood and Sondik (1973) <doi:10.1287/opre.21.5.1071>.",2022-05-19,Michael Hahsler,https://github.com/mhahsler/pomdp,TRUE,https://github.com/mhahsler/pomdp,18301,5,2022-06-26T22:49:07Z,3660.2
pomdpSolve,"Installs 'pomdp-solve', a program to solve Partially Observable Markov Decision Processes (POMDPs) using a variety of exact and approximate value iteration algorithms. Smallwood and Sondik (1973) <doi:10.1287/opre.21.5.1071>.",2022-02-08,Michael Hahsler,https://github.com/mhahsler/pomdp,TRUE,https://github.com/mhahsler/pomdp,3828,5,2022-06-26T22:49:07Z,765.6
pomodoro,"Runs generalized and multinominal logistic (GLM and MLM) models, as well as random forest (RF), Bagging (BAG), and Boosting (BOOST). This package prints out to predictive outcomes easy for the selected data and data splits.",2022-03-26,Seyma Kalay,"https://github.com/seymakalay/pomodoro,
https://seymakalay.github.io/pomodoro/",TRUE,https://github.com/seymakalay/pomodoro,1759,0,2022-05-15T19:48:40Z,NA
pomp,"Tools for data analysis with partially observed Markov process (POMP) models (also known as stochastic dynamical systems, hidden Markov models, and nonlinear, non-Gaussian, state-space models).  The package provides facilities for implementing POMP models, simulating them, and fitting them to time series data by a variety of frequentist and Bayesian methods.  It is also a versatile platform for implementation of inference methods for general POMP models.",2022-07-06,Aaron A. King,https://kingaa.github.io/pomp/,TRUE,https://github.com/kingaa/pomp,68294,89,2022-07-10T16:55:45Z,767.3483146067416
pool,"Enables the creation of object pools, which make it
    less computationally expensive to fetch a new object. Currently the
    only supported pooled objects are 'DBI' connections.",2021-01-14,Joe Cheng,https://github.com/rstudio/pool,TRUE,https://github.com/rstudio/pool,262473,194,2021-11-19T15:49:49Z,1352.9536082474226
PoolTestR,"An easy-to-use tool for working with presence/absence tests on 'pooled'
    or 'grouped' samples. The primary application is for estimating prevalence of 
    a marker in a population based on the results of tests on pooled specimens.
    This sampling method is often employed in surveillance of rare conditions in
    humans or animals (e.g. molecular xenomonitoring). The package was initially
    conceived as an R-based alternative to the molecular xenomonitoring software,
    'PoolScreen' <https://sites.uab.edu/statgenetics/software/>. However, it goes
    further, allowing for estimates of prevalence to be adjusted for hierarchical
    sampling frames, and perform flexible mixed-effect regression analyses
    (McLure et al. Environmental Modelling and Software.
    <DOI:10.1016/j.envsoft.2021.105158>). The package is currently in early stages,
    however more features are planned or in the works: e.g. adjustments for
    imperfect test specificity/sensitivity, functions for helping with optimal
    experimental design, and functions for spatial modelling.",2022-07-01,Angus McLure,https://github.com/AngusMcLure/PoolTestR,TRUE,https://github.com/angusmclure/pooltestr,5974,1,2022-07-01T07:02:44Z,5974
popbayes,"Infers the trends of one or several animal populations over time 
    from series of counts. It does so by accounting for count precision 
    (provided or inferred based on expert knowledge, e.g. guesstimates), 
    smoothing the population rate of increase over time, and accounting for the
    maximum demographic potential of species. Inference is carried out in a 
    Bayesian framework. This work is part of the FRB-CESAB working group
    AfroBioDrivers 
    <https://www.fondationbiodiversite.fr/en/the-frb-in-action/programs-and-projects/le-cesab/afrobiodrivers/>.",2022-03-04,Nicolas Casajus,"https://frbcesab.github.io/popbayes/,
https://github.com/frbcesab/popbayes",TRUE,https://github.com/frbcesab/popbayes,2205,0,2022-03-06T08:04:41Z,NA
PopED,"Optimal experimental designs for both population and individual
    studies based on nonlinear mixed-effect models. Often this is based on a
    computation of the Fisher Information Matrix. This package was developed
    for pharmacometric problems, and examples and predefined models are available
    for these types of systems. The methods are described in Nyberg et al. 
    (2012) <doi:10.1016/j.cmpb.2012.05.005>, and Foracchia et al. (2004) 
    <doi:10.1016/S0169-2607(03)00073-7>.",2021-05-21,Andrew C. Hooker,"https://andrewhooker.github.io/PopED/,
https://github.com/andrewhooker/PopED,",TRUE,https://github.com/andrewhooker/poped,22441,25,2022-03-28T18:21:52Z,897.64
popEpi,"Enables computation of epidemiological statistics, including those 
    where counts or mortality rates of the reference population are used. 
    Currently supported: excess hazard models (Dickman, Sloggett, Hills, and 
    Hakulinen (2012) <doi:10.1002/sim.1597>), rates, mean survival times, 
    relative/net survival (in particular the Ederer II (Ederer and Heise (1959))
    and Pohar Perme (Pohar Perme, Stare, and Esteve 
    (2012) <doi:10.1111/j.1541-0420.2011.01640.x>) estimators), 
    and standardized incidence and mortality ratios, 
    all of which can be easily adjusted for by covariates such as 
    age. Fast splitting and aggregation of 'Lexis' objects (from package 'Epi') 
    and other computations achieved using 'data.table'. ",2021-10-29,Joonas Miettinen,https://github.com/WetRobot/popEpi,TRUE,https://github.com/wetrobot/popepi,59272,4,2021-10-28T09:29:29Z,14818
PopGenReport,"Provides beginner friendly framework to analyse population genetic
    data. Based on 'adegenet' objects it uses 'knitr' to create comprehensive reports on spatial genetic data. 
    For detailed information how to use the package refer to the comprehensive
    tutorials or visit <http://www.popgenreport.org/>.",2022-05-27,Bernd Gruber,https://github.com/green-striped-gecko/PopGenReport,TRUE,https://github.com/green-striped-gecko/popgenreport,31852,6,2022-05-27T00:39:45Z,5308.666666666667
popkin,"Provides functions to estimate the kinship matrix of individuals from a large set of biallelic SNPs, and extract inbreeding coefficients and the generalized FST (Wright's fixation index).  Method described in Ochoa and Storey (2021) <doi:10.1371/journal.pgen.1009241>.",2022-01-27,Alejandro Ochoa,https://github.com/StoreyLab/popkin/,TRUE,https://github.com/storeylab/popkin,15179,18,2022-05-13T22:13:52Z,843.2777777777778
poppr,"Population genetic analyses for hierarchical analysis of partially
    clonal populations built upon the architecture of the 'adegenet' package. 
    Originally described in Kamvar, Tabima, and Grünwald (2014) 
    <doi:10.7717/peerj.281> with version 2.0 described in Kamvar, Brooks, and 
    Grünwald (2015) <doi:10.3389/fgene.2015.00208>.",2021-09-07,Zhian N. Kamvar,"https://grunwaldlab.github.io/poppr/,
https://github.com/grunwaldlab/poppr/,
https://grunwaldlab.github.io/Population_Genetics_in_R/",TRUE,https://github.com/grunwaldlab/poppr,121189,56,2021-09-07T14:46:33Z,2164.089285714286
popPyramid,Functions that facilitate the elaboration of population pyramids.  ,2021-12-15,Jorge L. C. Musaja,https://github.com/musajajorge/popPyramid,TRUE,https://github.com/musajajorge/poppyramid,1449,0,2021-12-25T18:22:55Z,NA
popsom,"Kohonen's self-organizing maps with a number of distinguishing features:
    (1) An efficient, single threaded, stochastic training algorithm inspired by ideas from tensor algebra.  Provides significant speedups over traditional single-threaded training algorithms. No special accelerator hardware required (see <doi:10.1007/978-3-030-01057-7_60>).
    (2) Automatic centroid detection and visualization using starbursts.
    (3) Two models of the data: (a) a self organizing map model, (b) a centroid based clustering model.
    (4) A number of easily accessible quality metrics for the self organizing map and the centroid based cluster model (see <doi:10.1007/978-3-319-28518-4_4>).",2021-12-20,Lutz Hamel,https://github.com/lutzhamel/popsom,TRUE,https://github.com/lutzhamel/popsom,19581,5,2021-12-20T22:25:36Z,3916.2
poptrend,"Functions to estimate and plot smooth or linear population trends, or population indices, 
    from animal or plant count survey data.",2016-12-13,Jonas Knape,https://github.com/jknape/poptrend,TRUE,https://github.com/jknape/poptrend,12858,7,2022-05-26T11:53:05Z,1836.857142857143
portalr,"Download and generate summaries for the rodent,
    plant, ant, and weather data from the Portal Project. Portal is a
    long-term (and ongoing) experimental monitoring site in the Chihuahua
    desert. The raw data files can be found at
    <https://github.com/weecology/portaldata>.",2021-12-03,Glenda M. Yenni,"https://weecology.github.io/portalr/,
https://github.com/weecology/portalr",TRUE,https://github.com/weecology/portalr,24903,10,2022-04-01T02:09:19Z,2490.3
portfolioBacktest,"Automated backtesting of multiple portfolios over multiple 
    datasets of stock prices in a rolling-window fashion. Intended for 
    researchers and practitioners to backtest a set of different portfolios, 
    as well as by a course instructor to assess the students in their portfolio 
    design in a fully automated and convenient manner, with results conveniently 
    formatted in tables and plots. Each portfolio design is easily defined as a
    function that takes as input a window of the stock prices and outputs the 
    portfolio weights. Multiple portfolios can be easily specified as a list 
    of functions or as files in a folder. Multiple datasets can be conveniently 
    extracted randomly from different markets, different time periods, and 
    different subsets of the stock universe. The results can be later assessed 
    and ranked with tables based on a number of performance criteria (e.g., 
    expected return, volatility, Sharpe ratio, drawdown, turnover rate, return 
    on investment, computational time, etc.), as well as plotted in a number of 
    ways with nice barplots and boxplots.",2022-04-22,Daniel P. Palomar,"https://CRAN.R-project.org/package=portfolioBacktest,
https://github.com/dppalomar/portfolioBacktest",TRUE,https://github.com/dppalomar/portfoliobacktest,23126,34,2022-04-22T02:21:00Z,680.1764705882352
portvine,"Following Sommer (2022) <https://mediatum.ub.tum.de/1658240>
    portfolio level risk estimates (e.g. Value at Risk, Expected
    Shortfall) are estimated by modeling each asset univariately by an
    ARMA-GARCH model and then their cross dependence via a Vine Copula
    model in a rolling window fashion. One can even condition on
    variables/time series at certain quantile levels to stress test the
    risk measure estimates.",2022-05-31,Emanuel Sommer,"https://github.com/EmanuelSommer/portvine,
https://emanuelsommer.github.io/portvine/",TRUE,https://github.com/emanuelsommer/portvine,307,3,2022-06-07T21:56:46Z,102.33333333333333
postcards,"A collection of R Markdown templates for creating simple and easy 
  to personalize single page websites.",2022-01-07,Sean Kross,https://github.com/seankross/postcards,TRUE,https://github.com/seankross/postcards,12826,469,2022-01-07T01:16:44Z,27.347547974413647
PostcodesioR,"Free UK geocoding using data from Office for National Statistics.
    It is using several functions to get information about post codes, outward
    codes, reverse geocoding, nearest post codes/outward codes, validation, or
    randomly generate a post code. API wrapper around <https://postcodes.io>.",2021-12-01,Eryk Walczak,https://docs.ropensci.org/PostcodesioR/,TRUE,https://github.com/ropensci/postcodesior,14966,35,2021-11-30T22:19:51Z,427.6
posterior,"Provides useful tools for both users and developers of packages 
  for fitting Bayesian models or working with output from Bayesian models. 
  The primary goals of the package are to: 
  (a) Efficiently convert between many different useful formats of
  draws (samples) from posterior or prior distributions.
  (b) Provide consistent methods for operations commonly performed on draws, 
  for example, subsetting, binding, or mutating draws.
  (c) Provide various summaries of draws in convenient formats.
  (d) Provide lightweight implementations of state of the art posterior 
  inference diagnostics. References: Vehtari et al. (2021) 
  <doi:10.1214/20-BA1221>.",2022-06-09,Paul-Christian Bürkner,"https://mc-stan.org/posterior/, https://discourse.mc-stan.org/",TRUE,https://github.com/stan-dev/posterior,241732,111,2022-06-09T12:10:37Z,2177.765765765766
postGGIR,"Generate all necessary R/Rmd/shell files for data processing after running 'GGIR' (v2.4.0) for accelerometer data. In part 1, all csv files in the GGIR output directory were read, transformed and then merged. In part 2, the GGIR output files were checked and summarized in one excel sheet. In part 3, the merged data was cleaned according to the number of valid hours on each night and the number of valid days for each subject. In part 4, the cleaned activity data was imputed by the average Euclidean norm minus one (ENMO) over all the valid days for each subject. Finally, a comprehensive report of data processing was created using Rmarkdown, and the report includes few exploratory plots and multiple commonly used features extracted from minute level actigraphy data. ",2022-01-06,Wei Guo,https://github.com/dora201888/postGGIR,TRUE,https://github.com/dora201888/postggir,6811,0,2022-06-02T15:55:34Z,NA
potential,"Provides functions to compute the potential model as defined by
    Stewart (1941) <doi:10.1126/science.93.2404.89>. Several options are available
    to customize the model, such as the possibility to fine-tune the distance
    friction functions or to use custom distance matrices. Some computations are
    parallelized to improve their efficiency.",2022-07-05,Timothée Giraud,https://github.com/riatelab/potential,TRUE,https://github.com/riatelab/potential,5303,22,2022-07-04T12:30:19Z,241.04545454545453
potools,"Translating messages in R packages is managed using the po top-level directory and the 'gettext' program. This package provides some helper functions for building this support in R packages, e.g. common validation & I/O tasks.",2021-07-12,Michael Chirico,https://github.com/MichaelChirico/potools,TRUE,https://github.com/michaelchirico/potools,8637,45,2022-04-26T14:20:23Z,191.93333333333334
powdR,"Full pattern summation of X-ray powder diffraction data as
  described in Chipera and Bish (2002) <doi:10.1107/S0021889802017405> and
  Butler and Hillier (2021) <doi:10.1016/j.cageo.2020.104662>.
  Derives quantitative estimates of crystalline and amorphous phase
  concentrations in complex mixtures.",2021-08-13,Benjamin Butler,https://github.com/benmbutler/powdR,TRUE,https://github.com/benmbutler/powdr,16365,7,2021-11-26T15:57:11Z,2337.8571428571427
Power2Stage,"Contains functions to obtain the operational characteristics of 
    bioequivalence studies in Two-Stage Designs (TSD) via simulations.",2021-11-20,Detlew Labes,https://github.com/Detlew/Power2Stage,TRUE,https://github.com/detlew/power2stage,18766,1,2022-07-03T12:34:53Z,18766
powerjoin,"Extensions of 'dplyr' and 'fuzzyjoin' join functions. Packed with
    features to preprocess the data, apply various data checks, and deal with
    conflicting columns.",2022-01-13,Antoine Fabri,https://github.com/moodymudskipper/powerjoin,TRUE,https://github.com/moodymudskipper/powerjoin,1508,67,2022-05-14T02:39:53Z,22.507462686567163
powerly,"An implementation of the sample size computation method for network
    models proposed by Constantin et al. (2021) <doi:10.31234/osf.io/j5v7u>.
    The implementation takes the form of a three-step recursive algorithm
    designed to find an optimal sample size given a model specification and a
    performance measure of interest. It starts with a Monte Carlo simulation
    step for computing the performance measure and a statistic at various sample
    sizes selected from an initial sample size range. It continues with a
    monotone curve-fitting step for interpolating the statistic across the entire
    sample size range. The final step employs stratified bootstrapping to quantify
    the uncertainty around the fitted curve.",2022-05-01,Mihai Constantin,https://powerly.dev,TRUE,https://github.com/mihaiconstantin/powerly,3605,6,2022-05-02T12:08:22Z,600.8333333333334
PowerTOST,"Contains functions to calculate power and sample size for
    various study designs used in bioequivalence studies. Use known.designs() to
    see the designs supported. Power and sample size can be obtained based on
    different methods, amongst them prominently the TOST procedure (two one-sided
    t-tests). See README and NEWS for further information.",2022-02-21,Detlew Labes,https://github.com/Detlew/PowerTOST,TRUE,https://github.com/detlew/powertost,40781,12,2022-04-25T17:18:45Z,3398.4166666666665
ppdiag,"A suite of diagnostic tools for univariate point processes.
    This includes tools for simulating and fitting both common and more
    complex temporal point processes. We also include functions to 
    visualise these point processes and collect existing diagnostic
    tools of Brown et al. (2002) <doi:10.1162/08997660252741149> and
    Wu et al. (2021) <doi:10.1002/9781119821588.ch7>,
    which can be used to assess the fit of a chosen point process
    model.",2021-08-12,Owen G. Ward,https://owenward.github.io/ppdiag/,TRUE,https://github.com/owenward/ppdiag,5208,2,2021-08-12T13:15:52Z,2604
PPforest,Implements projection pursuit forest algorithm for supervised classification.,2021-10-14,Natalia da Silva,https://github.com/natydasilva/PPforest,TRUE,https://github.com/natydasilva/ppforest,14345,15,2021-10-14T12:36:04Z,956.3333333333334
ppgmmga,Projection Pursuit (PP) algorithm for dimension reduction based on Gaussian Mixture Models (GMMs) for density estimation using Genetic Algorithms (GAs) to maximise an approximated negentropy index. For more details see Scrucca and Serafini (2019) <doi:10.1080/10618600.2019.1598871>.,2019-07-08,Alessio Serafini,https://github.com/luca-scr/ppgmmga,TRUE,https://github.com/luca-scr/ppgmmga,11346,2,2021-09-27T15:18:01Z,5673
ppmf,"Implements data processing described in <doi:10.1126/sciadv.abk3283> to align modern differentially private data with formatting of older US Census data releases. The primary goal is to read in Census Privacy Protected Microdata Files data in a reproducible way. This includes tools for aggregating to relevant levels of geography by creating geographic identifiers which match the US Census Bureau's numbering. Additionally, there are tools for grouping race numeric identifiers into categories, consistent with OMB (Office of Management and Budget) classifications. Functions exist for downloading and linking to existing sources of privacy protected microdata.",2021-12-15,Christopher T. Kenny,"https://github.com/christopherkenny/ppmf/,
https://www.christophertkenny.com/ppmf/",TRUE,https://github.com/christopherkenny/ppmf,1766,1,2021-12-13T16:06:11Z,1766
PPQplan,"Assessment for statistically-based PPQ sampling plan, including calculating the passing probability, optimizing the baseline and high performance cutoff points, visualizing the PPQ plan and power dynamically. The analytical idea is based on the simulation methods from the textbook Burdick, R. K., LeBlond, D. J., Pfahler, L. B., Quiroz, J., Sidor, L., Vukovinsky, K., & Zhang, L. (2017). Statistical Methods for CMC Applications. In Statistical Applications for Chemistry, Manufacturing and Controls (CMC) in the Pharmaceutical Industry (pp. 227-250). Springer, Cham.",2020-10-08,Yalin Zhu,"https://allenzhuaz.github.io/PPQplan/,
https://github.com/allenzhuaz/PPQplan",TRUE,https://github.com/allenzhuaz/ppqplan,12242,0,2021-11-02T01:05:46Z,NA
PPSFS,"
    This is an implementation of the partial profile score feature 
    selection (PPSFS) approach to generalized linear (interaction) models. 
    The PPSFS is highly scalable even for ultra-high-dimensional feature space. 
    See the paper by Xu, Luo and Chen (2021, <doi:10.4310/21-SII706>).",2022-03-21,Zengchao Xu,https://github.com/paradoxical-rhapsody/PPSFS,TRUE,https://github.com/paradoxical-rhapsody/ppsfs,835,1,2022-03-19T13:57:10Z,835
prais,"The Prais-Winsten estimator (Prais & Winsten, 1954) takes into account AR(1) serial correlation of the errors in a linear regression model. The procedure recursively estimates the coefficients and the error autocorrelation of the specified model until sufficient convergence of the AR(1) coefficient is attained.",2021-11-01,Franz X. Mohr,https://github.com/franzmohr/prais,TRUE,https://github.com/franzmohr/prais,28646,3,2021-11-05T21:33:15Z,9548.666666666666
praise,"Build friendly R packages that
    praise their users if they have done something
    good, or they just need it to feel better.",2015-08-11,Gabor Csardi,https://github.com/gaborcsardi/praise,TRUE,https://github.com/gaborcsardi/praise,12416324,137,2022-04-11T14:43:01Z,90630.10218978103
prcbench,"A testing workbench to evaluate tools that calculate precision-recall curves. 
    Saito and Rehmsmeier (2015) <doi:10.1371/journal.pone.0118432>.",2022-02-03,Takaya Saito,"https://evalclass.github.io/prcbench/,
https://github.com/evalclass/prcbench",TRUE,https://github.com/evalclass/prcbench,17309,4,2022-02-10T22:29:26Z,4327.25
pre,"Derives prediction rule ensembles (PREs). Largely follows the
    procedure for deriving PREs as described in Friedman & Popescu (2008; 
    <DOI:10.1214/07-AOAS148>), with adjustments and improvements. The 
    main function pre() derives prediction rule ensembles consisting of 
    rules and/or linear terms for continuous, binary, count, multinomial, 
    and multivariate continuous responses. Function gpe() derives 
    generalized prediction ensembles, consisting of rules, hinge and linear 
    functions of the predictor variables.",2022-06-10,Marjolein Fokkema,https://github.com/marjoleinF/pre,TRUE,https://github.com/marjoleinf/pre,51321,46,2022-06-18T17:09:37Z,1115.6739130434783
PRECAST,"An efficient data integration method is provided for multiple spatial transcriptomics data with non-cluster-relevant effects such as the complex batch effects. It unifies spatial factor analysis simultaneously with spatial clustering and embedding alignment, requiring only partially shared cell/domain clusters across datasets. More details can be referred to Wei Liu, et al. (2022) <doi:10.1101/2022.06.26.497672>.",2022-06-29,Wei Liu,https://github.com/feiyoung/PRECAST,TRUE,https://github.com/feiyoung/precast,244,1,2022-07-05T02:21:28Z,244
pRecipe,"An open-access tool/framework to download, validate, visualize, and analyze multi-source precipitation data across various spatio-temporal scales. Ultimately providing the hydrology science community with the tools for consistent and reproducible analysis regarding precipitation.",2022-04-22,Mijael Rodrigo Vargas Godoy,https://github.com/MiRoVaGo/pRecipe,TRUE,https://github.com/mirovago/precipe,4011,1,2022-04-22T09:02:57Z,4011
precisely,"Estimate sample size based on precision rather than power.
    'precisely' is a study planning tool to calculate sample size based on
    precision. Power calculations are focused on whether or not an
    estimate will be statistically significant; calculations of precision
    are based on the same principles as power calculation but turn the
    focus to the width of the confidence interval. 'precisely' is based on
    the work of 'Rothman and Greenland' (2018).",2021-10-10,Malcolm Barrett,https://github.com/malcolmbarrett/precisely,TRUE,https://github.com/malcolmbarrett/precisely,9010,90,2021-10-10T20:29:32Z,100.11111111111111
precommit,"Useful git hooks for R building on top of the multi-language
    framework 'pre-commit' for hook management. This package provides git
    hooks for common tasks like formatting files with 'styler' or spell
    checking as well as wrapper functions to access the 'pre-commit'
    executable.",2022-07-01,Lorenz Walthert,"https://lorenzwalthert.github.io/precommit/,
https://github.com/lorenzwalthert/precommit",TRUE,https://github.com/lorenzwalthert/precommit,13883,189,2022-07-02T10:16:13Z,73.45502645502646
precrec,"Accurate calculations and visualization of precision-recall and ROC (Receiver Operator Characteristics)
    curves. Saito and Rehmsmeier (2015) <doi:10.1371/journal.pone.0118432>.",2022-03-10,Takaya Saito,https://github.com/evalclass/precrec,TRUE,https://github.com/evalclass/precrec,56558,44,2022-03-10T12:03:44Z,1285.409090909091
predictMe,"Enables researchers to visualize the prediction performance of any algorithm on the individual level (or close to it), given that the predicted outcome is either binary or continuous. Visual results are instantly comprehensible.",2022-05-24,Marcel Miché,https://github.com/mmiche/predictMe,TRUE,https://github.com/mmiche/predictme,339,1,2022-05-21T06:10:30Z,339
predieval,"Methods for assessing the performance of a prediction model with respect to identifying patient-level treatment benefit. All methods are applicable for continuous and binary outcomes, and for any type of statistical or machine-learning prediction model as long as it uses baseline covariates to predict outcomes under treatment and control. ",2022-04-19,Orestis Efthimiou,https://github.com/esm-ispm-unibe-ch/predieval,TRUE,https://github.com/esm-ispm-unibe-ch/predieval,674,0,2022-04-19T09:18:33Z,NA
predtools,"Provides additional functions for evaluating predictive models, including plotting calibration curves and model-based Receiver Operating Characteristic (mROC) based on Sadatsafavi et al (2021) <arXiv:2003.00316>. ",2021-10-05,Mohsen Sadatsafavi,https://github.com/resplab/predtools,TRUE,https://github.com/resplab/predtools,3862,2,2022-07-08T21:18:37Z,1931
prefeR,"Allows users to derive multi-objective weights from pairwise comparisons, which
    research shows is more repeatable, transparent, and intuitive other techniques. These weights
    can be rank existing alternatives or to define a multi-objective utility function for optimization.",2022-04-24,John Lepird,"https://github.com/jlepird/prefeR,
https://jlepird.github.io/prefeR/",TRUE,https://github.com/jlepird/prefer,14486,1,2022-04-24T22:51:07Z,14486
preferably,"This is an accessible template for 'pkgdown'. It uses two
    bootstrap themes, Flatly and Darkly and utilizes the
    'prefers-color-scheme' CSS variable to automatically serve either of
    the two based on user’s operating system setting, or allowing them to
    manually toggle between them.",2021-12-02,Amir Masoud Abdol,https://preferably.amirmasoudabdol.name,TRUE,https://github.com/amirmasoudabdol/preferably,21862,54,2022-07-04T10:19:18Z,404.85185185185185
prereg,Provides a collection of templates to author preregistration documents for scientific studies in PDF format.,2022-01-20,Frederik Aust,https://github.com/crsh/prereg,TRUE,https://github.com/crsh/prereg,17945,44,2022-01-20T11:49:39Z,407.84090909090907
presenter,"Consists of custom wrapper functions using packages
    'openxlsx', 'flextable', and 'officer' to create highly formatted MS office friendly output of your data frames.
    These viewer friendly outputs are intended to match expectations of professional looking presentations
    in business and consulting scenarios. The functions are opinionated in the sense that they expect the input data
    frame to have certain properties in order to take advantage of the automated formatting.",2021-11-18,Harrison Tietze,https://github.com/Harrison4192/presenter,TRUE,https://github.com/harrison4192/presenter,3669,10,2022-04-25T16:59:13Z,366.9
presentes,"Compilation and digitalization of the official registry of victims of state terrorism in Argentina during the last
             military coup. The original data comes from RUVTE-ILID (2019) <https://www.argentina.gob.ar/sitiosdememoria/ruvte/informe> and <http://basededatos.parquedelamemoria.org.ar/registros/>. The title, presentes, comes from present in spanish.",2019-11-05,Diego Kozlowski,https://diegokoz.github.io/presentes/,TRUE,https://github.com/diegokoz/presentes,9915,6,2022-03-26T17:10:08Z,1652.5
presize,"Bland (2009) <doi:10.1136/bmj.b3985> recommended to
    base study sizes on the width of the confidence interval rather the power of 
    a statistical test. The goal of 'presize' is to provide functions for such 
    precision based sample size calculations. For a given sample size, the 
    functions will return the precision (width of the confidence interval), and 
    vice versa. ",2022-03-03,Alan G. Haynes,"https://github.com/CTU-Bern/presize,
https://ctu-bern.github.io/presize/",TRUE,https://github.com/ctu-bern/presize,8879,8,2022-03-02T15:07:25Z,1109.875
PressPurt,"This is a computational package designed to identify the most sensitive interactions within a network which must be estimated most accurately in order to produce qualitatively robust predictions to a press perturbation. This is accomplished by enumerating the number of sign switches (and their magnitude) in the net effects matrix when an edge experiences uncertainty. The package produces data and visualizations when uncertainty is associated to one or more edges in the network and according to a variety of distributions. The software requires the network to be described by a system of differential equations but only requires as input a numerical Jacobian matrix evaluated at an equilibrium point. This package is based on Koslicki, D., & Novak, M. (2017) <doi:10.1007/s00285-017-1163-0>.",2020-10-19,David Koslicki,https://github.com/dkoslicki/PressPurt,TRUE,https://github.com/dkoslicki/presspurt,6270,2,2021-11-09T20:17:10Z,3135
prettifyAddins,"Provides 'RStudio' addins to prettify 'HTML', 'CSS', 'SCSS', 'JavaScript', 'JSX', 'Markdown', 'C(++)', 'LaTeX', 'Python', 'Julia', 'XML', 'Java', 'JSON', 'Ruby', and to reindent 'C(++)', 'Fortran', 'Java', 'Julia', 'Python', 'SAS', 'Scala', 'Shell', 'SQL' and ""TypeScript"". Two kinds of addins are provided: 'Prettify' and 'Indent'. The 'Indent' addins only reindent the code, while the 'Prettify' addins also modify the code, e.g. trailing semi-colons are added to 'JavaScript' code when they are missing. ",2022-01-25,Stéphane Laurent,https://github.com/stla/prettifyAddins,TRUE,https://github.com/stla/prettifyaddins,9532,15,2022-07-08T08:55:12Z,635.4666666666667
prettymapr,"Automates the process of creating a scale bar and north arrow in
    any package that uses base graphics to plot in R. Bounding box tools help find
    and manipulate extents. Finally, there is a function to automate the process
    of setting margins, plotting the map, scale bar, and north arrow, and resetting
    graphic parameters upon completion.",2022-06-09,Dewey Dunnington,https://github.com/paleolimbot/prettymapr,TRUE,https://github.com/paleolimbot/prettymapr,176221,20,2022-06-09T11:32:42Z,8811.05
prevalence,"The prevalence package provides Frequentist and Bayesian methods for prevalence assessment studies. IMPORTANT: the truePrev functions in the prevalence package call on JAGS (Just Another Gibbs Sampler), which therefore has to be available on the user's system. JAGS can be downloaded from <https://mcmc-jags.sourceforge.io/>.",2022-06-03,Brecht Devleesschauwer,http://prevalence.cbra.be/,TRUE,https://github.com/brechtdv/prevalence,22386,2,2022-06-03T20:53:36Z,11193
prevR,"Spatial estimation of a prevalence surface
    or a relative risks surface, using data from a Demographic and Health
    Survey (DHS) or an analog survey, see Larmarange et al. (2011)
    <doi:10.4000/cybergeo.24606>.",2022-05-11,Joseph Larmarange,https://github.com/larmarange/prevR/,TRUE,https://github.com/larmarange/prevr,23339,4,2022-05-12T08:24:27Z,5834.75
prewas,"Standardize the pre-processing of genomic variants before 
    performing a bacterial genome-wide association study (bGWAS). 'prewas'
    creates a variant matrix (where each row is a variant, each column is a 
    sample, and the entries are presence - 1 - or absence - 0 - of the variant) 
    that can be used as input for bGWAS tools. When creating the binary variant
    matrix, 'prewas' can perform 3 pre-processing steps including: dealing with 
    multiallelic SNPs, (optional) dealing with SNPs in overlapping genes, and 
    choosing a reference allele. 'prewas' can output matrices for use with both 
    SNP-based bGWAS and gene-based bGWAS. This method is described in Saund et 
    al. (2020) <doi:10.1099/mgen.0.000368>. 'prewas' can also provide 
    gene matrices for variants with specific annotations from the 'SnpEff' 
    software (Cingolani et al. 2012).",2021-04-02,Katie Saund,https://github.com/Snitkin-Lab-Umich/prewas,TRUE,https://github.com/snitkin-lab-umich/prewas,8520,4,2021-12-15T16:33:36Z,2130
priceR,"Functions to aid in micro and macro economic analysis and handling of price and
    currency data. Includes extraction of relevant inflation and exchange rate data from World Bank
    API, data cleaning/parsing, and standardisation. Inflation adjustment
    calculations as found in Principles of Macroeconomics by Gregory Mankiw et al (2014). Current
    and historical end of day exchange rates for 171 currencies from the European Central Bank
    Statistical Data Warehouse (2020) <https://sdw.ecb.europa.eu/curConverter.do>.",2022-06-30,Steve Condylios,https://github.com/stevecondylios/priceR,TRUE,https://github.com/stevecondylios/pricer,22430,30,2022-06-29T10:59:11Z,747.6666666666666
pricesensitivitymeter,"An implementation of the van Westendorp Price
    Sensitivity Meter in R, which is a survey-based approach
	to analyze consumer price preferences and sensitivity
    (van Westendorp 1976, isbn:9789283100386).",2021-10-19,Max Alletsee,"https://max-alletsee.github.io/pricesensitivitymeter/,
https://github.com/max-alletsee/pricesensitivitymeter",TRUE,https://github.com/max-alletsee/pricesensitivitymeter,15189,12,2022-04-15T18:37:45Z,1265.75
prider,"Implementation of an oligonucleotide primer and probe design algorithm using a linearly scaling approximation of set coverage. A detailed description available at Smolander and Tamminen, 2021; <doi:10.1101/2021.09.06.459073>.",2022-03-11,Manu Tamminen,https://github.com/tamminenlab/prider,TRUE,https://github.com/tamminenlab/prider,2830,2,2022-05-23T08:07:36Z,1415
printr,"Extends the S3 generic function knit_print() in 'knitr'
    to automatically print some objects using an appropriate format such as
    Markdown or LaTeX. For example, data frames are automatically printed as
    tables, and the help() pages can also be rendered in 'knitr' documents.",2021-09-27,Yihui Xie,https://yihui.org/printr/,TRUE,https://github.com/yihui/printr,60869,120,2021-09-27T21:05:28Z,507.2416666666667
prinvars,"Provides methods for reducing the number of features within a data set. See Bauer JO (2021) <doi:10.1145/3475827.3475832> and Bauer JO, Drabant B (2021) <doi:10.1016/j.jmva.2021.104754> for more information on principal loading analysis.",2022-01-11,Ron Holzapfel,https://github.com/Ronho/prinvars,TRUE,https://github.com/ronho/prinvars,1504,2,2022-01-10T11:28:23Z,752
prioriactions,"This uses a mixed integer mathematical programming (MIP)
        approach for building and solving multi-action planning problems, 
        where the goal is to find an optimal combination of management actions that
        abate threats, in an efficient way while accounting for spatial aspects. 
        Thus, optimizing the connectivity and conservation effectiveness of 
        the prioritized units and of the deployed actions. The package is capable of 
        handling different commercial (gurobi) and non-commercial (symphony) MIP solvers. 
        Gurobi optimization solver can be installed using comprehensive instructions in 
        the gurobi installation vignette of the prioritizr package (available in 
        <https://prioritizr.net/articles/gurobi_installation_guide.html>). Methods used in the 
        package refers to Salgado-Rojas et al. (2020) <doi:10.1016/j.ecolmodel.2019.108901>,
        Beyer et al. (2016) <doi:10.1016/j.ecolmodel.2016.02.005>, Cattarino et al. (2015)
        <doi:10.1371/journal.pone.0128027> and Watts et al. (2009) <doi:10.1016/j.envsoft.2009.06.005>. 
        See the prioriactions website for more information, documentations and examples.",2022-02-09,Jose Salgado-Rojas,"https://prioriactions.github.io/prioriactions/,
https://github.com/prioriactions/prioriactions",TRUE,https://github.com/prioriactions/prioriactions,1991,5,2022-07-07T15:22:45Z,398.2
prioritizr,"
    Systematic conservation prioritization using mixed integer linear
    programming (MILP). It provides a flexible interface for building and
    solving conservation planning problems. Once built, conservation planning
    problems can be solved using a variety of commercial and open-source exact
    algorithm solvers. By using exact algorithm solvers, solutions can be
    generated that are guaranteed to be optimal (or within a pre-specified
    optimality gap). Furthermore, conservation problems can be constructed to
    optimize the spatial allocation of different management actions or zones,
    meaning that conservation practitioners can identify solutions that benefit
    multiple stakeholders. To solve large-scale or complex conservation
    planning problems, users should install the Gurobi optimization software
    (available from <https://www.gurobi.com/>) and the 'gurobi' R package (see
    Gurobi Installation Guide vignette for details). Additionally, the 'rcbc' R
    package (available at <https://github.com/dirkschumacher/rcbc>) can be used
    to generate solutions using the CBC optimization software
    (<https://projects.coin-or.org/Cbc>).",2021-10-29,Jeffrey O Hanson,"https://prioritizr.net, https://github.com/prioritizr/prioritizr",TRUE,https://github.com/prioritizr/prioritizr,33694,81,2022-07-07T10:31:35Z,415.9753086419753
prioritizrdata,"Conservation planning datasets for learning how to use the
    'prioritizr' package <https://CRAN.R-project.org/package=prioritizr>.",2020-08-05,Jeffrey O Hanson,"https://prioritizr.github.io/prioritizrdata/,
https://github.com/prioritizr/prioritizrdata",TRUE,https://github.com/prioritizr/prioritizrdata,19350,1,2021-10-18T03:16:24Z,19350
prism,"Allows users to access the Oregon State Prism climate data
    (<https://prism.nacse.org/>). Using the web service API data
    can easily downloaded in bulk and loaded into R for spatial analysis.
    Some user friendly visualizations are also provided.",2020-12-05,Hart Edmund,"https://docs.ropensci.org/prism/,
https://github.com/ropensci/prism",TRUE,https://github.com/ropensci/prism,20087,48,2022-05-18T14:29:50Z,418.4791666666667
prismadiagramR,"Creates 'PRISMA' <http://prisma-statement.org/> diagram from a minimal dataset of included and excluded studies and allows for more custom diagrams. 'PRISMA' diagrams are used to track the identification, screening, eligibility, and inclusion of studies in a systematic review. ",2020-05-04,Lionel Duarte,https://github.com/ltrainstg/prismadiagramR,TRUE,https://github.com/ltrainstg/prismadiagramr,7609,1,2021-09-07T17:31:58Z,7609
prismatic,"Manipulate and visualize colors in a intuitive,
    low-dependency and functional way.",2021-10-17,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/prismatic,TRUE,https://github.com/emilhvitfeldt/prismatic,219445,112,2021-10-17T04:22:41Z,1959.330357142857
probably,"Models can be improved by post-processing class probabilities, by: recalibration, conversion to hard probabilities, assessment of equivocal zones, and other activities. 'probably' contains tools for conducting these operations. ",2020-06-05,Davis Vaughan,"https://github.com/tidymodels/probably/,
https://probably.tidymodels.org",TRUE,https://github.com/tidymodels/probably,25852,72,2021-11-01T22:02:32Z,359.05555555555554
pROC,"Tools for visualizing, smoothing and comparing receiver operating characteristic (ROC curves). (Partial) area under the curve (AUC) can be compared with statistical tests based on U-statistics or bootstrap. Confidence intervals can be computed for (p)AUC or ROC curves.",2021-09-03,Xavier Robin,http://expasy.org/tools/pROC/,TRUE,https://github.com/xrobin/proc,4522077,103,2021-09-02T11:23:33Z,43903.66019417476
proceduralnames,"A small, dependency-free way to generate random names. Methods 
    provided include the adjective-surname approach of Docker containers 
    ('<https://github.com/moby/moby/blob/master/pkg/namesgenerator/names-generator.go'),
    and combinations of common English or Spanish words.",2021-10-12,Michael Mahoney,"https://mikemahoney218.github.io/proceduralnames/,
https://github.com/mikemahoney218/proceduralnames",TRUE,https://github.com/mikemahoney218/proceduralnames,13487,2,2021-10-12T18:10:47Z,6743.5
processanimateR,"Provides animated process maps based on the 'procesmapR' package.
  Cases stored in event logs created with with 'bupaR' S3 class eventlog() are
  rendered as tokens (SVG shapes) and animated according to their occurrence 
  times on top of the process map. For rendering SVG animations ('SMIL') and the
  'htmlwidget' package are used.",2021-10-11,Felix Mannhardt,https://github.com/bupaverse/processanimateR/,TRUE,https://github.com/bupaverse/processanimater,42819,55,2021-10-11T15:34:51Z,778.5272727272727
processmapR,"Visualize event logs using directed graphs, i.e. process maps. Part of the 'bupaR' framework.",2020-03-11,Gert Janssenswillen,"https://www.bupar.net, https://github.com/bupaverse/processmapr",TRUE,https://github.com/bupaverse/processmapr,76861,6,2021-10-19T14:52:09Z,12810.166666666666
procmaps,"Portable '/proc/self/maps' as a data frame.
    Determine which library or other region is mapped to a specific
    address of a process. --
    R packages can contain native code, compiled to shared libraries at build or
    installation time.
    When loaded, each shared library occupies a portion of the address space of
    the main process.
    When only a machine instruction pointer is available (e.g. from a backtrace
    during error inspection or profiling), the address space map determines
    which library this instruction pointer corresponds to.",2021-10-02,Kirill Müller,"https://r-prof.github.io/procmaps/,
https://github.com/r-prof/procmaps",TRUE,https://github.com/r-prof/procmaps,9472,2,2022-05-14T02:39:20Z,4736
proffer,"Like similar profiling tools,
  the 'proffer' package automatically detects
  sources of slowness in R code.
  The distinguishing feature of 'proffer' is its utilization of
  'pprof', which supplies interactive visualizations
  that are efficient and easy to interpret.
  Behind the scenes, the 'profile' package converts
  native Rprof() data to a protocol buffer
  that 'pprof' understands.
  For the documentation of 'proffer',
  visit <https://r-prof.github.io/proffer/>.
  To learn about the implementations and methodologies of
  'pprof', 'profile', and protocol buffers,
  visit <https://github.com/google/pprof>.
  <https://developers.google.com/protocol-buffers>,
  and <https://github.com/r-prof/profile>, respectively.",2021-07-26,William Michael Landau,"https://github.com/r-prof/proffer,
https://r-prof.github.io/proffer/",TRUE,https://github.com/r-prof/proffer,15594,69,2021-07-26T16:32:39Z,226
profile,"Defines a data structure for profiler data, and methods to read and
    write from the 'Rprof' and 'pprof' file formats.",2020-05-11,Kirill Müller,"https://github.com/r-prof/profile,
https://r-prof.github.io/profile",TRUE,https://github.com/r-prof/profile,15585,9,2022-05-14T02:33:59Z,1731.6666666666667
ProFit,Get data / Define model / ??? / Profit! 'ProFit' is a Bayesian galaxy fitting tool that uses a fast 'C++' image generation library and a flexible interface to a large number of likelihood samplers.,2019-11-11,Aaron Robotham,https://github.com/ICRAR/ProFit,TRUE,https://github.com/icrar/profit,14153,25,2022-05-26T07:04:49Z,566.12
profmem,"A simple and light-weight API for memory profiling of R expressions.  The profiling is built on top of R's built-in memory profiler ('utils::Rprofmem()'), which records every memory allocation done by R (also native code).",2020-12-13,Henrik Bengtsson,https://github.com/HenrikBengtsson/profmem,TRUE,https://github.com/henrikbengtsson/profmem,397703,32,2021-10-18T20:32:53Z,12428.21875
profoc,"Combine probabilistic forecasts using CRPS learning algorithms proposed in Berrisch, Ziel (2021) <arXiv:2102.00968> <doi:10.1016/j.jeconom.2021.11.008>. The package implements multiple online learning algorithms like Bernstein online aggregation; see Wintenberger (2014) <arXiv:1404.1356>. Quantile regression is also implemented for comparison purposes. Model parameters can be tuned automatically with respect to the loss of the forecast combination. Methods like predict(), update(), plot() and print() are available for convenience. This package utilizes the optim C++ library for numeric optimization <https://github.com/kthohr/optim>.",2022-04-21,Jonathan Berrisch,"https://profoc.berrisch.biz/, https://github.com/BerriJ/profoc",TRUE,https://github.com/berrij/profoc,6043,8,2022-04-21T16:19:12Z,755.375
progressr,"A minimal, unifying API for scripts and packages to report progress updates from anywhere including when using parallel processing.  The package is designed such that the developer can to focus on what progress should be reported on without having to worry about how to present it.  The end user has full control of how, where, and when to render these progress updates, e.g. in the terminal using utils::txtProgressBar() or progress::progress_bar(), in a graphical user interface using utils::winProgressBar(), tcltk::tkProgressBar() or shiny::withProgress(), via the speakers using beep::beepr(), or on a file system via the size of a file. Anyone can add additional, customized, progression handlers. The 'progressr' package uses R's condition framework for signaling progress updated. Because of this, progress can be reported from almost anywhere in R, e.g. from classical for and while loops, from map-reduce API:s like the lapply() family of functions, 'purrr', 'plyr', and 'foreach'. It will also work with parallel processing via the 'future' framework, e.g. future.apply::future_lapply(), furrr::future_map(), and 'foreach' with 'doFuture'. The package is compatible with Shiny applications.",2022-06-03,Henrik Bengtsson,"https://progressr.futureverse.org,
https://github.com/HenrikBengtsson/progressr",TRUE,https://github.com/henrikbengtsson/progressr,2088769,237,2022-06-19T03:02:24Z,8813.371308016878
PROJ,"Currently non-operational, a harmless wrapper to allow package 'reproj' to install and 
  function while relying on the 'proj4' package. ",2020-10-19,Michael D. Sumner,https://github.com/hypertidy/PROJ,TRUE,https://github.com/hypertidy/proj,72442,13,2021-07-27T02:21:30Z,5572.461538461538
ProjectionBasedClustering,"A clustering approach applicable to every projection method is proposed here. The two-dimensional scatter plot of any projection method can construct a topographic map which displays unapparent data structures by using distance and density information of the data. The generalized U*-matrix renders this visualization in the form of a topographic map, which can be used to automatically define the clusters of high-dimensional data. The whole system is based on Thrun and Ultsch, ""Using Projection based Clustering to Find Distance and Density based Clusters in High-Dimensional Data"" <DOI:10.1007/s00357-020-09373-2>. Selecting the correct projection method will result in a visualization in which mountains surround each cluster. The number of clusters can be determined by counting valleys on the topographic map. Most projection methods are wrappers for already available methods in R. By contrast, the neighbor retrieval visualizer (NeRV) is based on C++ source code of the 'dredviz' software package, and the Curvilinear Component Analysis (CCA) is translated from 'MATLAB' ('SOM Toolbox' 2.0) to R.",2022-05-26,Michael Thrun,https://www.deepbionics.org,TRUE,https://github.com/mthrun/projectionbasedclustering,21370,4,2022-05-31T15:26:55Z,5342.5
ProjectTemplate,"Provides functions to
    automatically build a directory structure for a new R
    project. Using this structure, 'ProjectTemplate'
    automates data loading, preprocessing, library
    importing and unit testing.",2021-07-31,Aleksandar Blagotic [ctb,http://projecttemplate.net,TRUE,https://github.com/kentonwhite/projecttemplate,44748,597,2021-10-29T18:13:33Z,74.95477386934674
projpred,"
    Performs projection predictive feature selection for generalized linear
    models and generalized linear and additive multilevel models (see Piironen,
    Paasiniemi and Vehtari, 2020, <doi:10.1214/20-EJS1711>; Catalina, Bürkner
    and Vehtari, 2020, <arXiv:2010.06994>). The package is compatible with the
    'rstanarm' and 'brms' packages, but other reference models can also be used.
    See the documentation as well as the package vignette for more information
    and examples.",2022-05-13,Frank Weber,"https://mc-stan.org/projpred/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/projpred,253504,100,2022-07-10T11:27:50Z,2535.04
promises,"Provides fundamental abstractions for doing asynchronous programming
    in R using promises. Asynchronous programming is useful for allowing a single
    R process to orchestrate multiple tasks in the background while also attending
    to something else. Semantics are similar to 'JavaScript' promises, but with a
    syntax that is idiomatic R.",2021-02-11,Joe Cheng,"https://rstudio.github.io/promises/,
https://github.com/rstudio/promises",TRUE,https://github.com/rstudio/promises,12198951,174,2022-01-21T20:15:00Z,70108.91379310345
prompt,"Set the 'R' prompt dynamically, from a function. The package
    contains some examples to include various useful dynamic information
    in the prompt: the status of the last command (success or failure);
    the amount of memory allocated by the current 'R' process; the name of
    the R package(s) loaded by 'pkgload' and/or 'devtools'; various 'git'
    information: the name of the active branch, whether it is dirty,
    if it needs pushes pulls. You can also create your own prompt if you
    don't like the predefined examples.",2021-03-12,Gábor Csárdi,https://github.com/gaborcsardi/prompt,TRUE,https://github.com/gaborcsardi/prompt,7433,207,2021-11-16T11:54:14Z,35.908212560386474
prompter,"In 'Shiny' apps, it is sometimes useful to store information
    on a particular item in a tooltip. 'Prompter' allows you to easily 
    create such tooltips, using 'Hint.css'.",2021-10-07,Etienne Bacher,https://github.com/etiennebacher/prompter,TRUE,https://github.com/etiennebacher/prompter,6707,24,2022-06-21T23:23:45Z,279.4583333333333
propr,"The bioinformatic evaluation of gene co-expression often begins with
    correlation-based analyses. However, correlation lacks validity when
    applied to relative data, including count data generated by next-generation
    sequencing. This package implements several metrics for proportionality, including
    phi [Lovell et al (2015) <DOI:10.1371/journal.pcbi.1004075>] and
    rho [Erb and Notredame (2016) <DOI:10.1007/s12064-015-0220-8>]. This package also
    implements several metrics for differential proportionality. Unlike correlation,
    these measures give the same result for both relative and absolute data.",2019-12-16,Thomas Quinn,http://github.com/tpq/propr,TRUE,https://github.com/tpq/propr,26755,48,2021-12-22T04:09:12Z,557.3958333333334
PROscorer,"An extensible repository of accurate, up-to-date functions to
    score commonly used patient-reported outcome (PRO), quality of life
    (QOL), and other psychometric and psychological measures.
    'PROscorer', together with the 'PROscorerTools' package, is a system
    to facilitate the incorporation of PRO measures into research studies
    and clinical settings in a scientifically rigorous and reproducible
    manner.  These packages and their vignettes are intended to help
    establish and promote ""best practices"" to improve the planning,
    scoring, and reporting of PRO-like measures in research.  The
    'PROscorer' ""Instrument Descriptions"" vignette contains descriptions
    of each instrument scored by 'PROscorer', complete with references.
    These instrument descriptions are suitable for inclusion in formal
    study protocol documents, grant proposals, and manuscript Method
    sections.  Each 'PROscorer' function is composed of helper functions
    from the 'PROscorerTools' package, and users are encouraged to
    contribute new functions to 'PROscorer'.  More scoring functions are
    currently in development and will be added in future updates.",2022-03-09,Ray Baser,https://github.com/raybaser/PROscorer,TRUE,https://github.com/raybaser/proscorer,13392,2,2022-04-15T21:10:17Z,6696
PROscorerTools,"Provides a reliable and flexible toolbox to score 
    patient-reported outcome (PRO), Quality of Life (QOL), and other 
    psychometric measures. The guiding philosophy is that scoring errors can 
    be eliminated by using a limited number of well-tested, well-behaved 
    functions to score PRO-like measures. The workhorse of the package is 
    the 'scoreScale' function, which can be used to score most single-scale 
    measures. It can reverse code items that need to be reversed before 
    scoring and pro-rate scores for missing item data. Currently, three 
    different types of scores can be output: summed item scores, mean item 
    scores, and scores scaled to range from 0 to 100. The 'PROscorerTools' 
    functions can be used to write new functions that score more complex 
    measures. In fact, 'PROscorerTools' functions are the building blocks of 
    the scoring functions in the 'PROscorer' package (which is a repository 
    of functions that score specific commonly-used instruments). Users are 
    encouraged to use 'PROscorerTools' to write scoring functions for their 
    favorite PRO-like instruments, and to submit these functions for 
    inclusion in 'PROscorer' (a tutorial vignette will be added soon). The 
    long-term vision for the 'PROscorerTools' and 'PROscorer' packages is to 
    provide an easy-to-use system to facilitate the incorporation of PRO 
    measures into research studies in a scientifically rigorous and 
    reproducible manner. These packages and their vignettes are intended to 
    help establish and promote ""best practices"" for scoring and describing 
    PRO-like measures in research. ",2022-03-07,Ray Baser,https://github.com/MSKCC-Epi-Bio/PROscorerTools,TRUE,https://github.com/mskcc-epi-bio/proscorertools,13729,1,2022-03-07T17:46:55Z,13729
PROsetta,"Perform scale linking to establish relationships between instruments
    that measure similar constructs according to the PROsetta Stone methodology, as in Choi, Schalet, Cook, & Cella (2014) <doi:10.1037/a0035768>.",2022-01-04,Seung W. Choi,"https://www.prosettastone.org/ (project description),
https://choi-phd.github.io/PROsetta/ (documentation)",TRUE,https://github.com/choi-phd/prosetta,9871,1,2022-01-15T22:08:40Z,9871
ProSGPV,"Implementation of penalized regression with second-generation p-values for variable
    selection. The algorithm can handle linear regression, GLM, and Cox regression. S3 methods print(), summary(), coef(), predict(), and plot() are available for the algorithm. Technical details
    can be found at Zuo et al. (2021) <doi:10.1080/00031305.2021.1946150>. ",2021-08-06,Yi Zuo,https://github.com/zuoyi93/ProSGPV,TRUE,https://github.com/zuoyi93/prosgpv,6236,3,2021-08-24T12:43:35Z,2078.6666666666665
prospectr,"Functions to preprocess spectroscopic data 
    and conduct (representative) sample selection/calibration sampling.",2022-04-03,Antoine Stevens,https://github.com/l-ramirez-lopez/prospectr,TRUE,https://github.com/l-ramirez-lopez/prospectr,35229,24,2022-04-03T20:33:00Z,1467.875
protolite,"Pure C++ implementations for reading and writing several common data 
    formats based on Google protocol-buffers. Currently supports 'rexp.proto' for 
    serialized R objects, 'geobuf.proto' for binary geojson, and 'mvt.proto' for 
    vector tiles. This package uses the auto-generated C++ code by protobuf-compiler, 
    hence the entire serialization is optimized at compile time. The 'RProtoBuf' 
    package on the other hand uses the protobuf runtime library to provide a general-
    purpose toolkit for reading and writing arbitrary protocol-buffer data in R.",2021-07-28,Jeroen Ooms,https://github.com/jeroen/protolite,TRUE,https://github.com/jeroen/protolite,340388,44,2021-09-17T10:20:24Z,7736.090909090909
protr,"Comprehensive toolkit for generating various numerical
    features of protein sequences described in Xiao et al. (2015)
    <DOI:10.1093/bioinformatics/btv042>. For full functionality,
    the software 'ncbi-blast+' is needed, see
    <https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download>
    for more information.",2019-05-18,Nan Xiao,"https://nanx.me/protr/, https://github.com/nanxstats/protr,
http://protr.org",TRUE,https://github.com/nanxstats/protr,40823,36,2021-12-19T04:24:29Z,1133.9722222222222
protti,"Useful functions and workflows for proteomics quality control and data analysis of both limited proteolysis-coupled mass spectrometry (LiP-MS) (Feng et. al. (2014) <doi:10.1038/nbt.2999>) and regular bottom-up proteomics experiments. Data generated with search tools such as 'Spectronaut', 'MaxQuant' and 'Proteome Discover' can be easily used due to flexibility of functions.",2022-07-01,Jan-Philipp Quast,"https://github.com/jpquast/protti,
https://jpquast.github.io/protti/",TRUE,https://github.com/jpquast/protti,5905,27,2022-07-01T07:34:09Z,218.7037037037037
protViz,"Helps with quality checks, visualizations 
    and analysis of mass spectrometry data, coming from proteomics 
    experiments. The package is developed, tested and used at the Functional 
    Genomics Center Zurich <https://fgcz.ch>. We use this package
    mainly for prototyping, teaching, and having fun with proteomics data.
    But it can also be used to do data analysis for small scale data sets.",2022-04-04,Christian Panse,https://github.com/cpanse/protViz/,TRUE,https://github.com/cpanse/protviz,26170,7,2022-05-25T09:19:03Z,3738.5714285714284
proverbs,"A simple package to grab a Bible proverb corresponding to the
    day of the month.",2022-02-01,Brad Lindblad,"https://github.com/bradlindblad/proverbs,
https://bradlindblad.github.io/proverbs/",TRUE,https://github.com/bradlindblad/proverbs,1241,3,2022-02-03T02:58:36Z,413.6666666666667
proxyC,"
    Computes proximity between rows or columns of large matrices efficiently in C++.
    Functions are optimised for large sparse matrices using the Armadillo and Intel TBB libraries.
    Among several built-in similarity/distance measures, computation of correlation,
    cosine similarity and Euclidean distance is particularly fast.",2021-12-10,Kohei Watanabe,https://github.com/koheiw/proxyC,TRUE,https://github.com/koheiw/proxyc,252767,21,2021-12-08T13:20:20Z,12036.52380952381
prozor,"Determine minimal protein set explaining
    peptide spectrum matches. Utility functions for creating fasta amino acid databases with decoys and contaminants.
    Peptide false discovery rate estimation for target decoy search results on psm, precursor, peptide and protein
    level. Computing dynamic swath window sizes based on MS1 or MS2 signal distributions.",2021-12-07,Witold Wolski,https://github.com/protviz/prozor,TRUE,https://github.com/protviz/prozor,14510,5,2022-05-02T11:54:39Z,2902
prrd,"Reverse depends for a given package are queued such that multiple
 workers can run the tests in parallel.",2021-09-22,Dirk Eddelbuettel,"https://github.com/eddelbuettel/prrd,
https://dirk.eddelbuettel.com/code/prrd.html",TRUE,https://github.com/eddelbuettel/prrd,14676,12,2022-01-07T14:44:03Z,1223
pryr,"Useful tools to pry back the covers of R and understand the
    language at a deeper level.",2021-07-26,Hadley Wickham,https://github.com/hadley/pryr,TRUE,https://github.com/hadley/pryr,1028596,195,2022-04-15T12:43:03Z,5274.851282051282
PSCBS,Segmentation of allele-specific DNA copy number data and detection of regions with abnormal copy number within each parental chromosome.  Both tumor-normal paired and tumor-only analyses are supported.,2021-10-23,Henrik Bengtsson,https://github.com/HenrikBengtsson/PSCBS,TRUE,https://github.com/henrikbengtsson/pscbs,38506,6,2021-10-23T08:02:17Z,6417.666666666667
pscore,"Provides a number of functions to
  simplify and automate the scoring, comparison, and evaluation of
  different ways of creating composites of data.  It is particularly
  aimed at facilitating the creation of physiological composites of
  metabolic syndrome symptom score (MetSSS) and allostatic load (AL).
  Provides a wrapper to calculate the MetSSS on new data using the
  Healthy Hearts formula. ",2022-05-13,Joshua F. Wiley,"https://score-project.org, https://github.com/JWiley/score-project",TRUE,https://github.com/jwiley/score-project,13251,1,2022-05-13T21:40:07Z,13251
psd,"Produces power spectral density estimates through iterative
    refinement of the optimal number of sine-tapers at each frequency. This
    optimization procedure is based on the method of Riedel and Sidorenko
    (1995), which minimizes the Mean Square Error (sum of variance and bias)
    at each frequency, but modified for computational stability. The same
    procedure can now be used to calculate the cross spectrum (multivariate
    analyses).",2022-01-31,Andrew J. Barbour,"https://github.com/abarbour/psd, Barbour and Parker (2014):
https://doi.org/10.1016/j.cageo.2013.09.015, Riedel and
Sidorenko (1995): https://doi.org/10.1109/78.365298",TRUE,https://github.com/abarbour/psd,26769,9,2022-01-31T21:05:54Z,2974.3333333333335
psData,"This R package includes functions for gathering commonly used and
    regularly maintained data set in political science. It also includes
    functions for combining components from these data sets into variables that
    have been suggested in the literature, but are not regularly maintained.",2016-09-03,Christopher Gandrud,http://cran.r-project.org/package=psData,TRUE,https://github.com/christophergandrud/psdata,17449,37,2021-11-14T06:41:10Z,471.5945945945946
pseudorank,"Efficient calculation of pseudo-ranks and (pseudo)-rank based test statistics. In case of equal sample sizes, pseudo-ranks and mid-ranks are equal. When used for inference mid-ranks may lead to paradoxical results. Pseudo-ranks are in general not affected by such a problem <doi:10.18637/jss.v095.c01>.",2020-10-02,Martin Happ,https://github.com/happma/pseudorank/,TRUE,https://github.com/happma/pseudorank,14454,1,2021-12-21T21:44:10Z,14454
psfmi,"
	Pooling, backward and forward selection of linear, logistic and Cox regression models in 
	multiply imputed datasets. Backward and forward selection can be done 
	from the pooled model using Rubin's Rules (RR), the D1, D2, D3, D4 and 
	the median p-values method. This is also possible for Mixed models. 
	The models can contain continuous, dichotomous, categorical and restricted 
	cubic spline predictors and interaction terms between	all these type of predictors. 
	The stability of the models	can be evaluated using bootstrapping and cluster 
	bootstrapping. The package further contains functions to pool the model performance 
	as ROC/AUC, R-squares, scaled Brier score, H&L test and calibration	plots for logistic 
	regression models. Internal validation can be	done with cross-validation or bootstrapping. 
	The adjusted intercept after shrinkage of pooled regression coefficients can be obtained. 
	Backward and forward selection as part of internal validation is possible. 
	A function to externally validate logistic prediction models in multiple imputed 
	datasets is available and a function to compare models. 
	Eekhout (2017) <doi:10.1186/s12874-017-0404-7>.
	Wiel (2009) <doi:10.1093/biostatistics/kxp011>.
	Marshall (2009) <doi:10.1186/1471-2288-9-57>.",2021-09-23,Martijn Heymans,https://mwheymans.github.io/psfmi/,TRUE,https://github.com/mwheymans/psfmi,16238,3,2022-07-06T14:34:56Z,5412.666666666667
psidR,"Makes it easy to build panel data in wide format from Panel Survey
    of Income Dynamics ('PSID') delivered raw data. Downloads data directly from
    the PSID server using the 'SAScii' package. 'psidR' takes care of merging
    data from each wave onto a cross-period index file, so that individuals can be
    followed over time. The user must specify which years they are interested in,
    and the 'PSID' variable names (e.g. ER21003) for each year (they differ in each
    year). The package offers helper functions to retrieve variable names from different
    waves. There are different panel data designs and sample subsetting criteria
    implemented (""SRC"", ""SEO"", ""immigrant"" and ""latino"" samples).",2021-05-07,Florian Oswald,https://github.com/floswald/psidR,TRUE,https://github.com/floswald/psidr,23242,45,2021-07-13T09:24:37Z,516.4888888888889
pspatreg,"Estimation and inference of spatial and spatio-temporal 
    semiparametric models including spatial or spatio-temporal non-parametric 
    trends, parametric and non-parametric covariates and, possibly, a spatial 
    lag for the dependent variable and temporal correlation in the noise.
    The spatio-temporal trend can be decomposed in ANOVA way including main and 
    interaction functional terms. Use of SAP algorithm to estimate the spatial 
    or spatio-temporal trend and non-parametric covariates. The methodology of 
    these models can be found in next references
    Basile, R. et al. (2014), <doi:10.1016/j.jedc.2014.06.011>;
    Rodriguez-Alvarez, M.X. et al. (2015) <doi:10.1007/s11222-014-9464-2> and,
    particularly referred to the focus of the package, Minguez, R., 
    Basile, R. and Durban, M. (2020) <doi:10.1007/s10260-019-00492-8>.",2022-07-04,Roman Minguez,https://github.com/rominsal/pspatreg,TRUE,https://github.com/rominsal/pspatreg,984,3,2022-07-04T16:17:48Z,328
psqn,"Provides quasi-Newton methods to minimize partially separable
    functions. The methods are largely described by  
    Nocedal and Wright (2006) <doi:10.1007/978-0-387-40065-5>.",2022-03-02,Benjamin Christoffersen,https://github.com/boennecd/psqn,TRUE,https://github.com/boennecd/psqn,9997,2,2022-04-11T10:28:44Z,4998.5
psrwe,"High-quality real-world data can be transformed into scientific
    real-world evidence (RWE) for regulatory and healthcare decision-making
    using proven analytical methods and techniques. For example, propensity
    score (PS) methodology can be applied to pre-select a subset of real-world
    data containing patients that are similar to those in the current clinical
    study in terms of covariates, and to stratify the selected patients together
    with those in the current study into more homogeneous strata. Then, methods
    such as the power prior approach or composite likelihood approach can be
    applied in each stratum to draw inference for the parameters of interest.
    This package provides functions that implement the PS-integrated RWE
    analysis methods proposed in Wang et al. (2019)
    <doi:10.1080/10543406.2019.1657133>, Wang et al. (2020)
    <doi:10.1080/10543406.2019.1684309> and Chen et al. (2020)
    <doi:10.1080/10543406.2020.1730877>.",2022-03-01,Chenguang Wang,https://github.com/olssol/psrwe,TRUE,https://github.com/olssol/psrwe,6386,1,2022-02-28T23:18:45Z,6386
PSSMCOOL,"Returns almost all features that has been extracted from Position Specific 
             Scoring Matrix (PSSM) so far, which is a matrix of L rows (L is protein length) 
             and 20 columns produced by 'PSI-BLAST' which is a program to produce
             PSSM Matrix from multiple sequence alignment of proteins
             see <https://www.ncbi.nlm.nih.gov/books/NBK2590/> for mor details. some 
             of these features are described in Zahiri, J., et al.(2013)
             <DOI:10.1016/j.ygeno.2013.05.006>,
             Saini, H., et al.(2016)
             <DOI:10.17706/jsw.11.8.756-767>,
             Ding, S., et al.(2014)
             <DOI:10.1016/j.biochi.2013.09.013>,
             Cheng, C.W., et al.(2008)
             <DOI:10.1186/1471-2105-9-S12-S6>,
             Juan, E.Y., et al.(2009)
             <DOI:10.1109/CISIS.2009.194>. ",2022-01-04,Alireza mohammadi,https://github.com/BioCool-Lab/PSSMCOOL,TRUE,https://github.com/biocool-lab/pssmcool,9889,2,2021-12-30T09:03:10Z,4944.5
PSweight,"Supports propensity score weighting analysis of observational studies and randomized trials. Enables the estimation and inference of average causal effects with binary and multiple treatments using overlap weights (ATO), inverse probability of treatment weights (ATE), average treatment effect among the treated weights (ATT), matching weights (ATM) and entropy weights (ATEN), with and without propensity score trimming. These weights are members of the family of balancing weights introduced in Li, Morgan and Zaslavsky (2018) <doi:10.1080/01621459.2016.1260466> and Li and Li (2019) <doi:10.1214/19-AOAS1282>.",2022-05-11,Tianhui Zhou,https://github.com/thuizhou/PSweight,TRUE,https://github.com/thuizhou/psweight,30727,13,2022-05-12T16:31:29Z,2363.6153846153848
psychmeta,"Tools for computing bare-bones and psychometric meta-analyses and for generating psychometric data for use in meta-analysis simulations. Supports bare-bones, individual-correction, and artifact-distribution methods for meta-analyzing correlations and d values. Includes tools for converting effect sizes, computing sporadic artifact corrections, reshaping meta-analytic databases, computing multivariate corrections for range variation, and more. Bugs can be reported to <https://github.com/psychmeta/psychmeta/issues> or <issues@psychmeta.com>.",2022-04-14,Jeffrey A. Dahlke,NA,TRUE,https://github.com/psychmeta/psychmeta,32212,42,2022-07-10T00:26:21Z,766.952380952381
psychonetrics,"Multi-group (dynamical) structural equation models in combination with confirmatory network models from cross-sectional, time-series and panel data <doi:10.31234/osf.io/8ha93>. Allows for confirmatory testing and fit as well as exploratory model search.",2021-10-25,Sacha Epskamp,http://psychonetrics.org/,TRUE,https://github.com/sachaepskamp/psychonetrics,26731,21,2022-06-01T05:52:23Z,1272.904761904762
psychrolib,"
    Implementation of 'PsychroLib'
    <https://github.com/psychrometrics/psychrolib> library which contains
    functions to enable the calculation properties of moist and dry air in both
    metric (SI) and imperial (IP) systems of units. References: Meyer, D. and
    Thevenard, D (2019) <doi:10.21105/joss.01137>.",2021-05-29,Hongyuan Jia,https://github.com/psychrometrics/psychrolib,TRUE,https://github.com/psychrometrics/psychrolib,13456,129,2021-12-12T19:45:08Z,104.31007751937985
psychtm,"Provides text mining methods for social science research. The
    package implements estimation, inference, summarization, and goodness-of-fit
    methods for topic models including Latent Dirichlet Allocation (LDA),
    supervised LDA, and supervised LDA with covariates using Bayesian Markov Chain
    Monte Carlo. A description of the key models and estimation methods is available
    in Wilcox, Jacobucci, Zhang, & Ammerman (2021). <doi:10.31234/osf.io/62tc3>.",2021-11-02,Kenneth Wilcox,https://github.com/ktw5691/psychtm/,TRUE,https://github.com/ktw5691/psychtm,2385,6,2021-11-02T18:49:00Z,397.5
pTITAN2,"Permute treatment labels for taxa and environmental gradients to
    generate an empirical distribution of change points.  This is an extension
    for the 'TITAN2' package <https://cran.r-project.org/package=TITAN2>.",2022-03-07,Peter DeWitt,https://github.com/USEPA/pTITAN2,TRUE,https://github.com/usepa/ptitan2,2370,0,2022-06-15T20:57:42Z,NA
ptspotter,"Utility functions produced specifically for (but not limited to) 
    working with 'ProjectTemplate' data pipelines. This package helps to quickly
    create and manage sequentially numbered scripts, quickly set up logging with
    'log4r' and functions to help debug and monitor procedures.",2021-05-03,Rich Leyshon,https://github.com/r-leyshon/ptspotter,TRUE,https://github.com/r-leyshon/ptspotter,4740,0,2022-05-02T08:33:25Z,NA
ptvapi,"Access the 'Public Transport Victoria' Timetable API 
    <https://www.ptv.vic.gov.au/footer/data-and-reporting/datasets/ptv-timetable-api/>,
    with results returned as familiar R data structures. Retrieve information on
    stops, routes, disruptions, departures, and more.",2021-05-02,David Neuzerling,https://github.com/mdneuzerling/ptvapi,TRUE,https://github.com/mdneuzerling/ptvapi,9152,14,2021-10-04T23:51:29Z,653.7142857142857
ptw,"Parametric Time Warping aligns patterns, i.e. it aims to
        put corresponding features at the same locations. The algorithm
        searches for an optimal polynomial describing the warping. It
        is possible to align one sample to a reference, several samples
        to the same reference, or several samples to several
        references. One can choose between calculating individual
        warpings, or one global warping for a set of samples and one
        reference. Two optimization criteria are implemented: RMS (Root
        Mean Square error) and WCC (Weighted Cross Correlation). Both
	warping of peak profiles and of peak lists are supported. A
	vignette for the latter is contained in the inst/doc directory
	of the source package - the vignette source can be found on
	the package github site.",2022-01-19,Ron Wehrens,https://github.com/rwehrens/ptw,TRUE,https://github.com/rwehrens/ptw,42214,6,2022-01-19T11:55:17Z,7035.666666666667
PTXQC,"Generates Proteomics (PTX) quality control (QC) reports for shotgun LC-MS data analyzed with the 
             MaxQuant software suite (from .txt files) or mzTab files (ideally from OpenMS 'QualityControl' tool).
             Reports are customizable (target thresholds, subsetting) and available in HTML or PDF format.
             Published in J. Proteome Res., Proteomics Quality Control: Quality Control Software for MaxQuant Results (2015)
             <doi:10.1021/acs.jproteome.5b00780>.",2022-03-22,Chris Bielow,https://github.com/cbielow/PTXQC,TRUE,https://github.com/cbielow/ptxqc,28075,31,2022-03-23T14:16:37Z,905.6451612903226
pubh,"A toolbox for making R functions and capabilities more
    accessible to students and professionals from Epidemiology and
    Public Health related disciplines. Includes a function to report 
    coefficients and confidence intervals from models using robust
    standard errors (when available), functions that expand 'ggplot2'
    plots and functions relevant for introductory papers in Epidemiology 
    or Public Health. Please note that use of the 
    provided data sets is for educational purposes only.",2022-04-04,Josie Athens,NA,TRUE,https://github.com/josie-athens/pubh,19448,4,2022-04-03T20:55:09Z,4862
pubmedR,A set of tools to extract bibliographic content from 'PubMed' database using 'NCBI' REST API <https://www.ncbi.nlm.nih.gov/home/develop/api/>.,2020-07-09,Massimo Aria,https://github.com/massimoaria/pubmedR,TRUE,https://github.com/massimoaria/pubmedr,92461,20,2022-02-14T09:14:06Z,4623.05
pullword,"R Interface to Pullword Service for natural language processing
    in Chinese. It enables users to extract valuable words from text by deep learning models. 
    For more details please visit the official site (in Chinese) <http://www.pullword.com/>.",2021-07-13,Tong He,NA,TRUE,https://github.com/hetong007/pullword,14471,20,2021-07-13T07:46:29Z,723.55
PUMP,"Estimates power, minimum detectable effect size (MDES) and sample size requirements. The context is multilevel randomized experiments with multiple outcomes. The estimation takes into account the use of multiple testing procedures. Development of this package was supported by a grant from the Institute of Education Sciences (R305D170030). For a full package description, including a detailed technical appendix, see <arXiv:2112.15273>.",2022-02-09,Luke Miratrix,https://github.com/MDRCNY/PUMP,TRUE,https://github.com/mdrcny/pump,1213,3,2022-06-23T14:10:55Z,404.3333333333333
puniform,"Provides meta-analysis methods that correct for
    publication bias and outcome reporting bias. Four methods and a visual tool 
    are currently included in the package. The p-uniform method as described in 
    van Assen, van Aert, and Wicherts (2015) <https:psycnet.apa.org/record/2014-48759-001> 
    can be used for estimating the average effect size, testing the null hypothesis 
    of no effect, and testing for publication bias using only the statistically 
    significant effect sizes of primary studies. The second method in the package 
    is the p-uniform* method as described in van Aert and van Assen (2019) 
    <doi:10.31222/osf.io/zqjr9>. This method is an extension of the p-uniform 
    method that allows for estimation of the average effect size and the 
    between-study variance in a meta-analysis, and uses both the statistically 
    significant and nonsignificant effect sizes. The third method in the package 
    is the hybrid method as described in van Aert and van Assen (2017) 
    <doi:10.3758/s13428-017-0967-6>. The hybrid method is a meta-analysis method 
    for combining an original study and replication and while taking into account 
    statistical significance of the  original study. The p-uniform and hybrid method 
    are based on the statistical theory that the distribution of p-values is 
    uniform conditional on the population effect size. The fourth method in the 
    package is the Snapshot Bayesian Hybrid Meta-Analysis Method as described in 
    van Aert and van Assen (2018) <doi:10.1371/journal.pone.0175302>. This method 
    computes posterior probabilities for four true effect sizes (no, small, medium, 
    and large) based on an original study and replication while taking into account 
    publication bias in the original study. The method can also be used for computing 
    the required sample size of the replication akin to power analysis in null 
    hypothesis significance testing. The meta-plot is a visual tool for meta-analysis 
    that provides information on the primary studies in the meta-analysis, the 
    results of the meta-analysis, and characteristics of the research on the effect 
    under study (van Assen et al., 2021). Helper functions to apply the 
    Correcting for Outcome Reporting Bias (CORB) method to correct for outcome 
    reporting bias in a meta-analysis (van Aert & Wicherts, 2021).",2022-03-21,Robbie C.M. van Aert,https://github.com/RobbievanAert/puniform,TRUE,https://github.com/robbievanaert/puniform,16109,3,2022-06-15T09:15:40Z,5369.666666666667
PupillometryR,"Provides a unified pipeline to clean, prepare, plot,
    and run basic analyses on pupillometry experiments.",2021-09-19,Samuel Forbes,NA,TRUE,https://github.com/samhforbes/pupillometryr,16759,38,2022-06-24T15:38:59Z,441.0263157894737
pureseqtmr,"Proteins reside in either the cell plasma or in the
    cell membrane. A membrane protein goes through the 
    membrane at least once. Given the amino acid sequence of a
    membrane protein, the tool
    'PureseqTM' (<https://github.com/PureseqTM/pureseqTM_package>,
    as described in ""Efficient And Accurate Prediction Of Transmembrane 
    Topology From Amino acid sequence only."", Wang, Qing, et al (2019), 
    <doi:10.1101/627307>),
    can predict the topology of a membrane protein. This package
    allows one to use 'PureseqTM' from R.",2020-07-30,Richèl J.C. Bilderbeek,https://github.com/richelbilderbeek/pureseqtmr,TRUE,https://github.com/richelbilderbeek/pureseqtmr,7688,0,2021-08-19T13:19:00Z,NA
purrr,"A complete and consistent functional programming
    toolkit for R.",2020-04-17,Lionel Henry,"http://purrr.tidyverse.org, https://github.com/tidyverse/purrr",TRUE,https://github.com/tidyverse/purrr,23629612,1046,2022-03-02T13:50:12Z,22590.45124282983
purrrlyr,"Some functions at the intersection of 'dplyr' and
    'purrr' that formerly lived in 'purrr'.",2022-03-29,Lionel Henry,https://github.com/hadley/purrrlyr,TRUE,https://github.com/hadley/purrrlyr,101822,103,2022-03-29T13:35:01Z,988.5631067961165
pushoverr,"Send push notifications to mobile devices or the desktop
    using 'Pushover' <https://pushover.net>. These notifications can
    display things such as results, job status, plots, or any other text
    or numeric data.",2021-11-16,Brian Connelly,"https://briandconnelly.github.io/pushoverr/,
https://github.com/briandconnelly/pushoverr",TRUE,https://github.com/briandconnelly/pushoverr,18490,59,2021-11-16T14:32:51Z,313.3898305084746
pvaluefunctions,"Contains functions to compute and plot confidence distributions, confidence densities, p-value functions and s-value (surprisal) functions for several commonly used estimates. Instead of just calculating one p-value and one confidence interval, p-value functions display p-values and confidence intervals for many levels thereby allowing to gauge the compatibility of several parameter values with the data. These methods are discussed by Infanger D, Schmidt-Trucksäss A. (2019) <doi:10.1002/sim.8293>; Poole C. (1987) <doi:10.2105/AJPH.77.2.195>; Schweder T, Hjort NL. (2002) <doi:10.1111/1467-9469.00285>; Bender R, Berg G, Zeeb H. (2005) <doi:10.1002/bimj.200410104> ; Singh K, Xie M, Strawderman WE. (2007) <doi:10.1214/074921707000000102>; Rothman KJ, Greenland S, Lash TL. (2008, ISBN:9781451190052); Amrhein V, Trafimow D, Greenland S. (2019) <doi:10.1080/00031305.2018.1543137>; Greenland S. (2019) <doi:10.1080/00031305.2018.1529625> and Rafi Z, Greenland S. (2020) <doi:10.1186/s12874-020-01105-9>.",2021-12-01,Denis Infanger,https://github.com/DInfanger/pvaluefunctions,TRUE,https://github.com/dinfanger/pvaluefunctions,16987,9,2021-11-30T20:48:10Z,1887.4444444444443
pvLRT,A suite of likelihood ratio test based methods to use in pharmacovigilance. Contains various testing and post-processing functions.,2022-02-25,Saptarshi Chakraborty,NA,TRUE,https://github.com/c7rishi/pvlrt,2043,0,2022-03-11T17:11:43Z,NA
PWFSLSmoke,"Utilities for working with air quality monitoring data
    with a focus on small particulates (PM2.5) generated by wildfire
    smoke. Functions are provided for downloading available data from
    the United States 'EPA' <https://www.epa.gov/outdoor-air-quality-data> and
    it's 'AirNow' air quality site <https://www.airnow.gov>.
    Additional sources of PM2.5 data made accessible by the package include:
    'AIRSIS' (aka ""Oceaneering"", not public)
    and 'WRCC' <https://wrcc.dri.edu/cgi-bin/smoke.pl>.
    Data compilations are hosted by the USFS 'AirFire' research team
    <https://www.airfire.org>.",2021-11-23,Jonathan Callahan,https://github.com/MazamaScience/PWFSLSmoke,TRUE,https://github.com/mazamascience/pwfslsmoke,21602,17,2022-07-06T23:18:05Z,1270.7058823529412
pxweb,"Generic interface for the PX-Web/PC-Axis API. The
    PX-Web/PC-Axis API is used by organizations such as Statistics Sweden
    and Statistics Finland to disseminate data. The R package can interact
    with all PX-Web/PC-Axis APIs to fetch information about the data
    hierarchy, extract metadata and extract and parse statistics to R
    data.frame format. PX-Web is a solution to disseminate PC-Axis data
    files in dynamic tables on the web.  Since 2013 PX-Web contains an API
    to disseminate PC-Axis files.",2022-07-01,Mans Magnusson,"https://github.com/rOpenGov/pxweb/,
https://ropengov.github.io/pxweb/,
https://github.com/rOpenGov/pxweb",TRUE,https://github.com/ropengov/pxweb,29017,60,2022-07-06T08:30:37Z,483.6166666666667
PxWebApiData,"Function to read PX-Web data into R via API. The example code reads data from the three national statistical institutes, Statistics Norway, Statistics Sweden and Statistics Finland.",2021-10-11,Øyvind Langsrud,https://github.com/statisticsnorway/PxWebApiData,TRUE,https://github.com/statisticsnorway/pxwebapidata,16001,2,2022-03-18T21:23:06Z,8000.5
pyinit,"Deterministic Pena-Yohai initial estimator for robust S estimators
    of regression. The procedure is described in detail in
    Pena, D., & Yohai, V. (1999) <doi:10.2307/2670164>.",2022-04-26,David Kepplinger,https://github.com/dakep/pyinit,TRUE,https://github.com/dakep/pyinit,42485,1,2022-04-26T14:43:25Z,42485
pylintR,Allow to run 'pylint' on Python files with a R command or a 'RStudio' addin. The report appears in the RStudio viewer pane as a formatted HTML file.,2021-10-12,Stéphane Laurent,https://github.com/stla/pylintR,TRUE,https://github.com/stla/pylintr,2788,0,2021-10-11T16:03:28Z,NA
pzfx,Read and write 'GraphPad Prism' '.pzfx' files in R.,2020-07-04,Yue Jiang,https://github.com/Yue-Jiang/pzfx,TRUE,https://github.com/yue-jiang/pzfx,52383,8,2021-09-27T04:19:41Z,6547.875
qacBase,"Functions for descriptive statistics,
  data management, and data visualization.",2022-02-09,Kabacoff Robert,https://github.com/rkabacoff/qacBase,TRUE,https://github.com/rkabacoff/qacbase,1931,1,2022-06-20T18:20:27Z,1931
qad,"A copula-based measure for quantifying asymmetry in dependence and associations. Documentation and theory about 'qad' is provided
    by the paper by Junker, Griessenberger & Trutschnig (2021, <doi:10.1016/j.csda.2020.107058>), and the paper by Trutschnig (2011, <doi:10.1016/j.jmaa.2011.06.013>).",2022-07-05,Thimo Kasper,https://github.com/griefl/qad,TRUE,https://github.com/griefl/qad,14370,0,2022-07-05T08:50:52Z,NA
qap,"Implements heuristics for the Quadratic Assignment Problem (QAP). Although, the QAP was introduced as a combinatorial optimization problem for the facility location problem in operations research, it also has many applications in data analysis. The problem is NP-hard and the package implements a simulated annealing heuristic.",2022-06-27,Michael Hahsler,https://github.com/mhahsler/qap,TRUE,https://github.com/mhahsler/qap,713745,2,2022-06-27T16:18:14Z,356872.5
QBMS,"Query the Breeding Management System(s) like BMS <https://bmspro.io>, 
    BreeBase <https://breedbase.org>, and GIGWA <https://southgreen.fr/content/gigwa> 
    (using 'BrAPI' <https://brapi.org> calls) to help breeders as targeted end-users 
    retrieve phenotypic and genotypic data directly into their analyzing pipelines.",2022-05-19,Khaled Al-Shamaa,https://github.com/icarda-git/QBMS,TRUE,https://github.com/icarda-git/qbms,3182,3,2022-06-29T08:03:57Z,1060.6666666666667
qbr,"Programmatically access the 'Quickbase' JSON API <https://developer.quickbase.com>. 
    You supply parameters for an API call, 'qbr' delivers an http request to the 
    API endpoint and returns its response. Outputs follow 'tidyverse' philosophy.",2022-06-30,John Erdmann,https://github.com/BHII-KSC/qbr,TRUE,https://github.com/bhii-ksc/qbr,432,0,2022-06-30T17:41:38Z,NA
QCAcluster,"Clustered set-relational data in Qualitative Comparative Analysis
    (QCA) can have a hierarchical structure, a panel structure or repeated cross
    sections. 'QCAcluster' allows QCA researchers to supplement the analysis
    of pooled the data with a disaggregated perspective focusing on selected 
    partitions of the data. The pooled data can be partitioned along the 
    dimensions of the clustered data (individual cross sections or time series) 
    to perform partition-specific truth table minimizations. Empirical 
    researchers can further calculate the weight that each partition has on the 
    parameters of the pooled solution and the diversity of the cases under 
    analysis within and across partitions 
    (see <https://ingorohlfing.github.io/QCAcluster/>).",2021-10-26,Ingo Rohlfing,https://github.com/ingorohlfing/QCAcluster,TRUE,https://github.com/ingorohlfing/qcacluster,2742,2,2021-10-26T09:05:53Z,1371
qcc,"Shewhart quality control charts for continuous, attribute and count data. Cusum and EWMA charts. Operating characteristic curves. Process capability analysis. Pareto chart and cause-and-effect chart. Multivariate control charts.",2017-07-11,Luca Scrucca,https://github.com/luca-scr/qcc,TRUE,https://github.com/luca-scr/qcc,357359,37,2022-04-06T07:59:10Z,9658.351351351352
qcr,"Univariate and multivariate SQC tools that completes and increases
    the SQC techniques available in R. Apart from integrating different R packages 
    devoted to SQC ('qcc','MSQC'), provides nonparametric tools that are highly 
    useful when Gaussian assumption is not met. 
    This package computes standard univariate control charts for individual measurements, 
    'X-bar', 'S', 'R', 'p', 'np', 'c', 'u', 'EWMA' and 'CUSUM'. In addition, it 
    includes functions to perform multivariate control charts such as 'Hotelling T2', 
    'MEWMA' and 'MCUSUM'. As representative feature, multivariate nonparametric 
    alternatives based on data depth are implemented in this package: 'r', 'Q' and 
    'S' control charts. In addition, Phase I and II control charts for functional 
    data are included. This package also allows the estimation of the most complete 
    set of capability indices from first to fourth generation, covering the nonparametric 
    alternatives, and performing the corresponding capability analysis graphical outputs,
    including the process capability plots. See Flores et al. (2021) <doi:10.32614/RJ-2021-034>.",2022-03-02,Miguel Flores,https://github.com/mflores72000/qcr,TRUE,https://github.com/mflores72000/qcr,17130,0,2022-07-07T20:31:06Z,NA
qdapRegex,"A collection of regular expression tools associated with
        the 'qdap' package that may be useful outside of the context of
        discourse analysis. Tools include
        removal/extraction/replacement of abbreviations, dates, dollar
        amounts, email addresses, hash tags, numbers, percentages,
        citations, person tags, phone numbers, times, and zip codes.",2022-05-02,Tyler Rinker,https://github.com/trinker/qdapRegex,TRUE,https://github.com/trinker/qdapregex,443273,42,2022-05-02T12:01:55Z,10554.119047619048
QFASA,"Accurate estimates of the diets of predators are required
    in many areas of ecology, but for many species current methods are
    imprecise, limited to the last meal, and often biased. The diversity
    of fatty acids and their patterns in organisms, coupled with the
    narrow limitations on their biosynthesis, properties of digestion in
    monogastric animals, and the prevalence of large storage reservoirs of
    lipid in many predators, led to the development of quantitative
    fatty acid signature analysis (QFASA) to study predator diets.",2021-07-20,Connie Stewart,https://CRAN.R-project.org/package=QFASA,TRUE,https://github.com/cstewartgh/qfasa,15358,0,2021-07-20T18:51:02Z,NA
QGameTheory,"General purpose toolbox for simulating quantum versions of game theoretic models (Flitney and Abbott 2002) <arXiv:quant-ph/0208069>. Quantum (Nielsen and Chuang 2010, ISBN:978-1-107-00217-3) versions of models that have been handled are: Penny Flip Game (David A. Meyer 1998) <arXiv:quant-ph/9804010>, Prisoner's Dilemma (J. Orlin Grabbe 2005) <arXiv:quant-ph/0506219>, Two Person Duel (Flitney and Abbott 2004) <arXiv:quant-ph/0305058>, Battle of the Sexes (Nawaz and Toor 2004) <arXiv:quant-ph/0110096>, Hawk and Dove Game (Nawaz and Toor 2010) <arXiv:quant-ph/0108075>, Newcomb's Paradox (Piotrowski and Sladkowski 2002) <arXiv:quant-ph/0202074> and Monty Hall Problem (Flitney and Abbott 2002) <arXiv:quant-ph/0109035>.",2020-06-12,Indranil Ghosh,https://github.com/indrag49/QGameTheory,TRUE,https://github.com/indrag49/qgametheory,6584,8,2021-09-24T11:53:18Z,823
qgcomp,"G-computation for a set of time-fixed exposures with
    quantile-based basis functions, possibly under linearity and
    homogeneity assumptions. This approach estimates a regression line
    corresponding to the expected change in the outcome (on the link
    basis) given a simultaneous increase in the quantile-based category
    for all exposures. Works with continuous, binary, and right-censored
    time-to-event outcomes.  Reference: Alexander P. Keil, Jessie P.
    Buckley, Katie M. OBrien, Kelly K. Ferguson, Shanshan Zhao, and
    Alexandra J. White (2019) A quantile-based g-computation approach to
    addressing the effects of exposure mixtures; <doi:10.1289/EHP5838>.",2022-01-24,Alexander Keil,https://github.com/alexpkeil1/qgcomp/,TRUE,https://github.com/alexpkeil1/qgcomp,21653,10,2022-01-24T14:17:26Z,2165.3
qgcompint,"G-computation for a set of time-fixed exposures
    with quantile-based basis functions, possibly under linearity and
    homogeneity assumptions. Effect measure modification in this method is a way
    to assess how the effect of the mixture varies by a binary, categorical or continuous variable.  
    Reference: Alexander P. Keil, Jessie P.
    Buckley, Katie M. OBrien, Kelly K. Ferguson, Shanshan Zhao, and
    Alexandra J. White (2019) A quantile-based g-computation approach to
    addressing the effects of exposure mixtures; <doi:10.1289/EHP5838>.",2022-03-22,Alexander Keil,https://github.com/alexpkeil1/qgcomp/,TRUE,https://github.com/alexpkeil1/qgcomp,3102,10,2022-01-24T14:17:26Z,310.2
qgg,"Provides an infrastructure for efficient processing of large-scale genetic and phenotypic data including core functions for: 1) fitting linear mixed models, 2) constructing marker-based genomic relationship matrices, 3) estimating genetic parameters (heritability and correlation), 4) performing genomic prediction and genetic risk profiling, and 5) single or multi-marker association analyses.
    Rohde et al. (2019) <doi:10.1101/503631>.",2022-06-27,Peter Soerensen,https://github.com/psoerensen/qgg,TRUE,https://github.com/psoerensen/qgg,13540,17,2022-06-29T13:50:56Z,796.4705882352941
qgraph,"Weighted network visualization and analysis, as well as Gaussian graphical model computation. See Epskamp et al. (2012) <doi:10.18637/jss.v048.i04>.",2022-03-04,Sacha Epskamp,NA,TRUE,https://github.com/sachaepskamp/qgraph,488806,60,2022-03-04T11:47:24Z,8146.766666666666
qicharts2,"Functions for making run charts, Shewhart control charts and
    Pareto charts for continuous quality improvement. Included control charts
    are: I, MR, Xbar, S, T, C, U, U', P, P', and G charts. Non-random variation
    in the form of minor to moderate persistent shifts in data over time is
    identified by the Anhoej rules for unusually long runs and unusually few
    crossing  [Anhoej, Olesen (2014) <doi:10.1371/journal.pone.0113825>].
    Non-random variation in the form of larger, possibly transient, shifts is
    identified by Shewhart's 3-sigma rule [Mohammed, Worthington, Woodall (2008)
    <doi:10.1136/qshc.2004.012047>].",2021-07-08,Jacob Anhoej,https://github.com/anhoej/qicharts2,TRUE,https://github.com/anhoej/qicharts2,40077,31,2022-05-29T06:57:10Z,1292.8064516129032
qlcal,"'QuantLib' bindings are provided for R using 'Rcpp' via an evolved version
 of the initial header-only 'Quantuccia' project offering an subset of 'QuantLib' (now
 maintained separately just for the calendaring subset). See the included file 'AUTHORS'
 for a full list of contributors to 'QuantLib' (and hence also 'Quantuccia').",2022-01-21,Dirk Eddelbuettel; the authors and contributors of QuantLib,"https://github.com/qlcal/qlcal-r,
https://dirk.eddelbuettel.com/code/rcpp.quantuccia.html",TRUE,https://github.com/qlcal/qlcal-r,1937,0,2022-03-01T01:56:22Z,NA
qmethod,"Analysis of Q methodology, used to identify distinct perspectives existing within a group.
  This methodology is used across social, health and environmental sciences to understand diversity of attitudes, discourses, or decision-making styles (for more information, see <https://qmethod.org/>).
  A single function runs the full analysis. Each step can be run separately using the corresponding functions: for automatic flagging of Q-sorts (manual flagging is optional), for statement scores, for distinguishing and consensus statements, and for general characteristics of the factors.
  The package allows to choose either principal components or centroid factor extraction, manual or automatic flagging, a number of mathematical methods for rotation (or none), and a number of correlation coefficients for the initial correlation matrix, among many other options.
  Additional functions are available to import and export data (from raw *.CSV, 'HTMLQ' and 'FlashQ' *.CSV, 'PQMethod' *.DAT and 'easy-htmlq' *.JSON files), to print and plot, to import raw data from individual *.CSV files, and to make printable cards.
  The package also offers functions to print Q cards and to generate Q distributions for study administration.
  See further details in the package documentation, and in the web pages below, which include a cookbook, guidelines for more advanced analysis (how to perform manual flagging or change the sign of factors), data management, and a beta graphical user interface for online and offline use.",2021-03-15,Aiora Zabala  (Main author,"https://github.com/aiorazabala/qmethod,
https://github.com/aiorazabala/qmethod/wiki",TRUE,https://github.com/aiorazabala/qmethod,20886,30,2022-06-28T09:56:41Z,696.2
qoi,"The new QOI file format offers a very simple but efficient image compression algorithm. This package provides an easy and simple way to read, write and display bitmap images stored in the QOI (Quite Ok Image) format. It can read and write both files and in-memory raw vectors.",2022-04-25,Johannes Friedrich,https://github.com/JohannesFriedrich/qoi4R,TRUE,https://github.com/johannesfriedrich/qoi4r,649,0,2022-04-25T20:51:13Z,NA
qPCRtools,"qPCR is a widely used method to detect the expression level of genes in 
  biological research. A crucial step in processing qPCR data is to calculate 
  the amplification efficiency of genes to determine which method should be used 
  to calculate expression level of genes. This Package can do it easily. 
  In addition to that, this package can calculate the expression level of genes 
  based on three methods.",2022-07-03,Xiang LI,https://github.com/lixiang117423/qPCRtools,TRUE,https://github.com/lixiang117423/qpcrtools,121,0,2022-07-02T17:22:58Z,NA
qpdf,"Content-preserving transformations transformations of PDF files such 
    as split, combine, and compress. This package interfaces directly to the 'qpdf' 
    C++ API and does not require any command line utilities. Note that 'qpdf' does
    not read actual content from PDF files: to extract text and data you need the
    'pdftools' package.",2022-05-29,Jeroen Ooms,"https://docs.ropensci.org/qpdf/ (website),
https://github.com/ropensci/qpdf (devel),
https://qpdf.sourceforge.io/ (upstream)",TRUE,https://github.com/ropensci/qpdf,725084,44,2022-05-29T08:27:09Z,16479.18181818182
qqconf,"Provides functionality for creating Quantile-Quantile (QQ) and Probability-Probability (PP) plots with simultaneous 
    testing bands to asses significance of sample deviation from a reference distribution.",2022-03-29,Eric Weine,https://github.com/eweine/qqconf,TRUE,https://github.com/eweine/qqconf,37186,0,2022-04-06T18:27:23Z,NA
qqplotr,Extensions of 'ggplot2' Q-Q plot functionalities.,2021-04-23,Adam Loy,https://github.com/aloy/qqplotr,TRUE,https://github.com/aloy/qqplotr,135924,42,2022-04-06T21:48:59Z,3236.285714285714
qra,"Functions are provided that implement the 
    use of the Fieller's formula methodology, for 
    calculating a confidence interval for a ratio of
    (commonly, correlated) means.  See Fieller (1954)
    <doi:10.1111/j.2517-6161.1954.tb00159.x>.  Here,
    the application of primary interest is to studies
    of insect mortality response to increasing doses
    of a fumigant, or, e.g., to time in coolstorage.
    The formula is used to calculate a confidence
    interval for the dose or time required to achieve
    a specified mortality proportion, commonly 0.5 
    or 0.99.  Vignettes demonstrate link functions
    that may be considered, checks on fitted models,
    and alternative choices of error family.  Note
    in particular the betabinomial error family.
    See also Maindonald, Waddell, and Petry (2001) 
    <doi:10.1016/S0925-5214(01)00082-5>.",2021-10-29,John Maindonald,https://github.com/jhmaindonald/qra,TRUE,https://github.com/jhmaindonald/qra,3506,0,2022-02-13T08:42:55Z,NA
qrcode,Create QRcode in R.,2021-10-13,Victor Teh,"https://thierryo.github.io/qrcode/,
https://github.com/ThierryO/qrcode,
https://doi.org/10.5281/zenodo.5040088",TRUE,https://github.com/thierryo/qrcode,121661,11,2021-10-13T14:39:38Z,11060.09090909091
qs,Provides functions for quickly writing and reading any R object to and from disk.  ,2022-02-22,Travers Ching,https://github.com/traversc/qs,TRUE,https://github.com/traversc/qs,182073,302,2022-03-26T21:31:27Z,602.8907284768212
qsimulatR,"A quantum computer simulator framework with up to 24 qubits. It allows to
    define general single qubit gates and general controlled single
    qubit gates. For convenience, it currently provides the
    most common gates (X, Y, Z, H, Z, S, T, Rx, Ry, Rz, CNOT, SWAP, Toffoli or
    CCNOT, Fredkin or CSWAP). 'qsimulatR' supports plotting of circuits and is able to
    export circuits to 'Qiskit' <https://qiskit.org/>, a python package
    which can be used to run on IBM's hardware <https://quantum-computing.ibm.com/>.",2020-12-09,Carsten Urbach,https://github.com/HISKP-LQCD/qsimulatR,TRUE,https://github.com/hiskp-lqcd/qsimulatr,5533,7,2022-03-20T22:21:52Z,790.4285714285714
qsplines,"Provides routines to create some quaternions splines:
    Barry-Goldman algorithm, De Casteljau algorithm, and Kochanek-Bartels
    algorithm. The implementations are based on the Python library
    'splines'. Quaternions splines allow to construct spherical curves. 
    References: Barry and Goldman <doi:10.1145/54852.378511>, 
    Kochanek and Bartels <doi:10.1145/800031.808575>.",2022-06-28,Stéphane Laurent,https://github.com/stla/qsplines,TRUE,https://github.com/stla/qsplines,154,0,2022-07-08T15:19:11Z,NA
qsub,"Run lapply() calls in parallel by submitting them to 
    'gridengine' clusters using the 'qsub' command.",2021-09-23,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,https://github.com/rcannood/qsub,TRUE,https://github.com/rcannood/qsub,15418,6,2021-09-23T09:28:39Z,2569.6666666666665
qtl,"Analysis of experimental crosses to identify genes
  (called quantitative trait loci, QTLs) contributing to variation in
  quantitative traits.
  Broman et al. (2003) <doi:10.1093/bioinformatics/btg112>.",2022-07-09,Karl W Broman <broman@wisc.edu> and Hao Wu,"https://rqtl.org, https://github.com/kbroman/qtl",TRUE,https://github.com/kbroman/qtl,111686,65,2022-07-09T11:15:25Z,1718.246153846154
qtl2,"Provides a set of tools to perform quantitative
    trait locus (QTL) analysis in experimental crosses. It is a
    reimplementation of the 'R/qtl' package to better handle
    high-dimensional data and complex cross designs.
    Broman et al. (2018) <doi:10.1534/genetics.118.301595>.",2021-10-17,Karl W Broman,"https://kbroman.org/qtl2/, https://github.com/rqtl/qtl2",TRUE,https://github.com/rqtl/qtl2,16071,27,2021-10-25T14:35:29Z,595.2222222222222
qtl2convert,"Functions to convert data structures among the 'qtl2', 'qtl', and 'DOQTL' packages for mapping quantitative trait loci (QTL).",2021-10-07,Karl W Broman,"https://kbroman.org/qtl2/, https://github.com/rqtl/qtl2convert",TRUE,https://github.com/rqtl/qtl2convert,9387,5,2021-10-07T12:09:47Z,1877.4
qtl2fst,"Uses the 'fst' package to store genotype probabilities on disk for the 'qtl2' package. These genotype probabilities are a central data object for mapping quantitative trait loci (QTL), but they can be quite large. The facilities in this package enable the genotype probabilities to be stored on disk, leading to reduced memory usage with only a modest increase in computation time.",2021-10-07,Karl W Broman,https://github.com/rqtl/qtl2fst,TRUE,https://github.com/rqtl/qtl2fst,8770,2,2021-10-07T12:44:59Z,4385
qtl2ggplot,"Functions to plot QTL (quantitative trait loci) analysis
    results and related diagnostics.
    Part of 'qtl2', an upgrade of the 'qtl'
    package to better handle high-dimensional data and complex cross
    designs.",2022-01-24,Brian S Yandell,"https://github.com/byandell/qtl2ggplot, https://kbroman.org/qtl2/",TRUE,https://github.com/byandell/qtl2ggplot,4903,5,2022-01-24T19:08:26Z,980.6
qtl2pattern,"Routines in 'qtl2' to study allele patterns in quantitative trait loci (QTL)
    mapping over a chromosome.
    Useful in crosses with more than two alleles to identify how sets of alleles,
    genetically different strands at the same locus, have different response levels.
    Plots show profiles over a chromosome.
    Can handle multiple traits together.
    See <https://github.com/byandell/qtl2pattern>.",2022-01-24,Brian S Yandell,https://github.com/byandell/qtl2pattern,TRUE,https://github.com/byandell/qtl2pattern,3279,1,2022-01-23T22:20:25Z,3279
qtl2pleio,"We implement an
    adaptation of Jiang & Zeng's (1995) <https://www.genetics.org/content/140/3/1111> likelihood ratio test for testing
    the null hypothesis of pleiotropy against the alternative hypothesis,
    two separate quantitative trait loci. The test differs from that in Jiang & Zeng (1995) <https://www.genetics.org/content/140/3/1111> 
    and that in Tian et al. (2016) <doi:10.1534/genetics.115.183624> in
    that our test accommodates multiparental populations.",2020-12-02,Frederick J Boehm,https://github.com/fboehm/qtl2pleio,TRUE,https://github.com/fboehm/qtl2pleio,12628,4,2021-07-13T20:20:18Z,3157
qtlbook,"Datasets for the book, A Guide to QTL Mapping with R/qtl.
    Broman and Sen (2009) <doi:10.1007/978-0-387-92125-9>.",2019-06-28,Karl W Broman,"http://rqtl.org/book, https://github.com/kbroman/qtlbook",TRUE,https://github.com/kbroman/qtlbook,15593,5,2021-10-29T21:40:47Z,3118.6
qtlcharts,"Web-based interactive charts (using D3.js) for the analysis of
    experimental crosses to identify genetic loci (quantitative trait
    loci, QTL) contributing to variation in quantitative traits.
    Broman (2015) <doi:10.1534/genetics.114.172742>.",2022-01-07,Karl W Broman,"https://kbroman.org/qtlcharts/,
https://github.com/kbroman/qtlcharts",TRUE,https://github.com/kbroman/qtlcharts,20590,82,2022-01-07T22:52:27Z,251.09756097560975
qtlpoly,"Performs random-effect multiple interval mapping (REMIM) in full-sib families of autopolyploid species based on restricted maximum likelihood (REML) estimation and score statistics, as described in Pereira et al. (2020) <doi:10.1534/genetics.120.303080>.",2022-01-12,Guilherme da Silva Pereira,https://gabrielgesteira.github.io/QTLpoly/,TRUE,https://github.com/gabrielgesteira/qtlpoly,2043,2,2022-06-22T15:33:19Z,1021.5
quadcleanR,"A tool that can be customized to aid in the clean up of ecological data 
    collected using quadrats and can crop quadrats to ensure comparability between
    quadrats collected under different methodologies.",2022-06-17,Dominique Maucieri,"https://github.com/DominiqueMaucieri/quadcleanR,
https://dominiquemaucieri.com/quadcleanR/",TRUE,https://github.com/dominiquemaucieri/quadcleanr,215,0,2022-06-17T16:36:01Z,NA
quadtree,"Provides functionality for working with raster-like quadtrees
    (also called “region quadtrees”), which allow for variable-sized
    cells. The package allows for flexibility in the quadtree creation
    process.  Several functions defining how to split and aggregate cells
    are provided, and custom functions can be written for both of these
    processes. In addition, quadtrees can be created using other quadtrees
    as “templates”, so that the new quadtree's structure is identical to
    the template quadtree. The package also includes functionality for
    modifying quadtrees, querying values, saving quadtrees to a file, and
    calculating least-cost paths using the quadtree as a resistance
    surface.",2022-02-01,Derek Friend,"https://github.com/dfriend21/quadtree/,
https://dfriend21.github.io/quadtree/",TRUE,https://github.com/dfriend21/quadtree,3191,8,2022-02-16T17:55:44Z,398.875
qualmap,"Provides a set of functions for taking qualitative GIS data, hand drawn on a map, and 
   converting it to a simple features object. These tools are focused on data that are drawn on a map
   that contains some type of polygon features. For each area identified on the map, the id numbers
   of these polygons can be entered as vectors and transformed using qualmap.",2022-05-31,Christopher Prener,https://chris-prener.github.io/qualmap/,TRUE,https://github.com/chris-prener/qualmap,14521,14,2022-05-31T01:19:59Z,1037.2142857142858
qualtRics,"Provides functions to access survey results directly into R
    using the 'Qualtrics' API. 'Qualtrics'
    <https://www.qualtrics.com/about/> is an online survey and data
    collection software platform. See <https://api.qualtrics.com/> for
    more information about the 'Qualtrics' API.  This package is
    community-maintained and is not officially supported by 'Qualtrics'.",2022-06-06,Julia Silge,"https://docs.ropensci.org/qualtRics/,
https://github.com/ropensci/qualtRics",TRUE,https://github.com/ropensci/qualtrics,184862,187,2022-06-29T03:22:31Z,988.5668449197861
Quandl,"Functions for interacting directly with the Quandl API to offer data in a number of formats usable in R, downloading a zip with all data from a Quandl database, and the ability to search. This R package uses the Quandl API. For more information go to <https://docs.quandl.com>. For more help on the package itself go to <https://www.quandl.com/tools/r>.",2021-08-11,Dave Dotson,https://github.com/quandl/quandl-r,TRUE,https://github.com/quandl/quandl-r,657620,124,2022-06-08T19:50:15Z,5303.387096774193
quantdr,"An implementation of dimension reduction techniques
    for conditional quantiles. Nonparametric estimation of 
    conditional quantiles is also available.  ",2022-05-09,Eliana Christou,https://github.com/elianachristou/quantdr,TRUE,https://github.com/elianachristou/quantdr,7335,2,2022-05-10T22:02:59Z,3667.5
quanteda,"A fast, flexible, and comprehensive framework for 
    quantitative text analysis in R.  Provides functionality for corpus management,
    creating and manipulating tokens and ngrams, exploring keywords in context, 
    forming and manipulating sparse matrices
    of documents by features and feature co-occurrences, analyzing keywords, computing feature similarities and
    distances, applying content dictionaries, applying supervised and unsupervised machine learning, 
    visually representing text and text analyses, and more. ",2022-03-01,Kenneth Benoit,https://quanteda.io,TRUE,https://github.com/quanteda/quanteda,609484,732,2022-06-09T11:01:45Z,832.6284153005464
quanteda.textmodels,"Scaling models and classifiers for sparse matrix objects representing 
    textual data in the form of a document-feature matrix.  Includes original 
    implementations of 'Laver', 'Benoit', and Garry's (2003) <doi:10.1017/S0003055403000698>,
    'Wordscores' model, Perry and 'Benoit's' (2017) <arXiv:1710.08963> class affinity scaling model, 
    and 'Slapin' and 'Proksch's' (2008) <doi:10.1111/j.1540-5907.2008.00338.x> 'wordfish'
    model, as well as methods for correspondence analysis, latent semantic analysis,
    and fast Naive Bayes and linear 'SVMs' specially designed for sparse textual data.",2021-04-06,Kenneth Benoit,https://github.com/quanteda/quanteda.textmodels,TRUE,https://github.com/quanteda/quanteda.textmodels,86330,35,2021-10-11T08:40:07Z,2466.5714285714284
quanteda.textplots,"Plotting functions for visualising textual data.  Extends 'quanteda' and 
   related packages with plot methods designed specifically for text data, textual statistics, 
   and models fit to textual data. Plot types include word clouds, lexical dispersion plots, 
   scaling plots, network visualisations, and word 'keyness' plots.",2022-03-23,Kenneth Benoit,NA,TRUE,https://github.com/quanteda/quanteda.textplots,63233,2,2022-03-23T10:23:02Z,31616.5
quanteda.textstats,"Textual statistics functions formerly in the 'quanteda' package.
    Textual statistics for characterizing and comparing textual data. Includes 
    functions for measuring term and document frequency, the co-occurrence of 
    words, similarity and distance between features and documents, feature entropy, 
    keyword occurrence, readability, and lexical diversity.  These functions 
    extend the 'quanteda' package and are specially designed for sparse textual data.",2021-11-24,Kenneth Benoit,https://quanteda.io,TRUE,https://github.com/quanteda/quanteda.textstats,77240,9,2022-03-23T12:28:14Z,8582.222222222223
quantities,"Integration of the 'units' and 'errors' packages for a complete
    quantity calculus system for R vectors, matrices and arrays, with automatic
    propagation, conversion, derivation and simplification of magnitudes and
    uncertainties. Documentation about 'units' and 'errors' is provided in the
    papers by Pebesma, Mailund & Hiebert (2016, <doi:10.32614/RJ-2016-061>) and
    by Ucar, Pebesma & Azcorra (2018, <doi:10.32614/RJ-2018-075>), included in
    those packages as vignettes; see 'citation(""quantities"")' for details.",2021-02-21,Iñaki Ucar,https://github.com/r-quantities/quantities,TRUE,https://github.com/r-quantities/quantities,14045,21,2022-01-05T16:06:46Z,668.8095238095239
quantmod,"Specify, build, trade, and analyse quantitative financial trading strategies.",2022-04-29,Joshua M. Ulrich,http://www.quantmod.com https://github.com/joshuaulrich/quantmod,TRUE,https://github.com/joshuaulrich/quantmod,8087904,659,2022-06-12T18:08:05Z,12272.99544764795
Quartet,"Calculates the number of four-taxon subtrees consistent with a pair
  of cladograms, calculating the symmetric quartet distance of Bandelt & Dress
  (1986), Reconstructing the shape of a tree from observed dissimilarity data,
  Advances in Applied Mathematics, 7, 309-343 <doi:10.1016/0196-8858(86)90038-2>, 
  and using the tqDist algorithm of Sand et al. (2014), tqDist: a library for
  computing the quartet and triplet distances between binary or general trees,
  Bioinformatics, 30, 2079–2080 <doi:10.1093/bioinformatics/btu157>
  for pairs of binary trees.",2022-07-08,Martin R. Smith,"https://ms609.github.io/Quartet/,
https://github.com/ms609/Quartet/",TRUE,https://github.com/ms609/quartet,17942,5,2022-07-08T10:40:09Z,3588.4
quarto,"Convert R Markdown documents and 'Jupyter' notebooks to a variety of
  output formats using 'Quarto'.",2022-07-06,JJ Allaire,https://github.com/quarto-dev/quarto-r,TRUE,https://github.com/quarto-dev/quarto-r,12408,56,2022-07-08T19:05:46Z,221.57142857142858
queryparser,Translate 'SQL' 'SELECT' statements into lists of 'R' expressions.,2021-01-17,Ian Cook,https://github.com/ianmcook/queryparser,TRUE,https://github.com/ianmcook/queryparser,17036,47,2021-08-07T18:01:55Z,362.468085106383
questionr,"Set of functions to make the processing and analysis of
    surveys easier : interactive shiny apps and addins for data recoding,
    contingency tables, dataset metadata handling, and several convenience
    functions.",2022-01-31,Julien Barnier,https://juba.github.io/questionr/,TRUE,https://github.com/juba/questionr,1444475,65,2022-02-11T16:56:35Z,22222.69230769231
queuecomputer,"Implementation of a computationally efficient method for
    simulating queues with arbitrary arrival and service times. 
    Please see Ebert, Wu, Mengersen & Ruggeri (2020, <doi:10.18637/jss.v095.i05>) 
    for further details. ",2021-04-09,Anthony Ebert,https://github.com/AnthonyEbert/queuecomputer,TRUE,https://github.com/anthonyebert/queuecomputer,17388,28,2022-03-29T12:58:05Z,621
quickcheck,"Property based testing, inspired by 
    the original 'QuickCheck'. This package builds on 
    the property based testing framework provided by 
    'hedgehog' and is designed to seamlessly integrate with 
    'testthat'.",2022-03-17,Andrew McNeil,"https://github.com/armcn/quickcheck,
https://armcn.github.io/quickcheck/",TRUE,https://github.com/armcn/quickcheck,1497,11,2022-03-17T15:30:20Z,136.0909090909091
quincunx,"Programmatic access to the 'PGS' Catalog.
    This package provides easy access to 'PGS' Catalog data by
    accessing the REST API <https://www.pgscatalog.org/rest/>.",2021-10-30,Ramiro Magno,https://github.com/maialab/quincunx,TRUE,https://github.com/maialab/quincunx,3310,7,2021-10-30T10:27:49Z,472.85714285714283
qwraps2,"A collection of (wrapper) functions the creator found useful
    for quickly placing data summaries and formatted regression results into
    '.Rnw' or '.Rmd' files. Functions for generating commonly used graphics,
    such as receiver operating curves or Bland-Altman plots, are also provided
    by 'qwraps2'.  'qwraps2' is a updated version of a package 'qwraps'. The
    original version 'qwraps' was never submitted to CRAN but can be found at
    <https://github.com/dewittpe/qwraps/>. The implementation and limited scope
    of the functions within 'qwraps2' <https://github.com/dewittpe/qwraps2/> is
    fundamentally different from 'qwraps'.",2021-03-07,Peter DeWitt,https://github.com/dewittpe/qwraps2/,TRUE,https://github.com/dewittpe/qwraps2,105981,32,2022-04-05T16:17:23Z,3311.90625
R.cache,"Memoization can be used to speed up repetitive and computational expensive function calls.  The first time a function that implements memoization is called the results are stored in a cache memory.  The next time the function is called with the same set of parameters, the results are momentarily retrieved from the cache avoiding repeating the calculations.  With this package, any R object can be cached in a key-value storage where the key can be an arbitrary set of R objects.  The cache memory is persistent (on the file system).",2021-04-30,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.cache,TRUE,https://github.com/henrikbengtsson/r.cache,1504316,35,2022-06-21T04:22:43Z,42980.45714285714
R.devices,"Functions for creating plots and image files in a unified way
    regardless of output format (EPS, PDF, PNG, SVG, TIFF, WMF, etc.). Default
    device options as well as scales and aspect ratios are controlled in a uniform
    way across all device types. Switching output format requires minimal changes
    in code. This package is ideal for large-scale batch processing, because it
    will never leave open graphics devices or incomplete image files behind, even on
    errors or user interrupts.",2022-06-21,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.devices,TRUE,https://github.com/henrikbengtsson/r.devices,155512,17,2022-06-21T14:47:59Z,9147.764705882353
R.matlab,"Methods readMat() and writeMat() for reading and writing MAT files.  For user with MATLAB v6 or newer installed (either locally or on a remote host), the package also provides methods for controlling MATLAB (trademark) via R and sending and retrieving data between R and MATLAB.",2018-09-27,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.matlab,TRUE,https://github.com/henrikbengtsson/r.matlab,212466,78,2022-01-05T17:44:35Z,2723.923076923077
R.methodsS3,"Methods that simplify the setup of S3 generic functions and S3 methods.  Major effort has been made in making definition of methods as simple as possible with a minimum of maintenance for package developers.  For example, generic functions are created automatically, if missing, and naming conflict are automatically solved, if possible.  The method setMethodS3() is a good start for those who in the future may want to migrate to S4.  This is a cross-platform package implemented in pure R that generates standard S3 methods.",2022-06-13,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.methodsS3,TRUE,https://github.com/henrikbengtsson/r.methodss3,3679818,0,2022-06-13T23:35:21Z,NA
R.oo,Methods and classes for object-oriented programming in R with or without references.  Large effort has been made on making definition of methods as simple as possible with a minimum of maintenance for package developers.  The package has been developed since 2001 and is now considered very stable.  This is a cross-platform package implemented in pure R that defines standard S3 classes without any tricks.,2022-06-12,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.oo,TRUE,https://github.com/henrikbengtsson/r.oo,3612881,19,2022-06-13T17:27:28Z,190151.63157894736
r.proxy,"The use of proxies is required in certain network environments. 
    Despite the power of system level software, it is still inconvenient to 
    switch proxy networks at random in R's console. This package is designed 
    to provide one-click switching between proxy and non-proxy states.",2021-11-17,Yonghe Xia,https://github.com/xiayh17/r.proxy,TRUE,https://github.com/xiayh17/r.proxy,2234,2,2021-11-18T10:43:42Z,1117
R.rsp,"The RSP markup language makes any text-based document come alive.  RSP provides a powerful markup for controlling the content and output of LaTeX, HTML, Markdown, AsciiDoc, Sweave and knitr documents (and more), e.g. 'Today's date is <%=Sys.Date()%>'.  Contrary to many other literate programming languages, with RSP it is straightforward to loop over mixtures of code and text sections, e.g. in month-by-month summaries.  RSP has also several preprocessing directives for incorporating static and dynamic contents of external files (local or online) among other things.  Functions rstring() and rcat() make it easy to process RSP strings, rsource() sources an RSP file as it was an R script, while rfile() compiles it (even online) into its final output format, e.g. rfile('report.tex.rsp') generates 'report.pdf' and rfile('report.md.rsp') generates 'report.html'.  RSP is ideal for self-contained scientific reports and R package vignettes.  It's easy to use - if you know how to write an R script, you'll be up and running within minutes.",2022-06-27,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.rsp,TRUE,https://github.com/henrikbengtsson/r.rsp,398388,27,2022-06-28T02:41:47Z,14755.111111111111
R.utils,Utility functions useful when programming and developing R packages.,2022-06-28,Henrik Bengtsson,"https://henrikbengtsson.github.io/R.utils/,
https://github.com/HenrikBengtsson/R.utils",TRUE,https://github.com/henrikbengtsson/r.utils,3808451,54,2022-06-28T03:21:09Z,70526.87037037036
R2BEAT,"Multivariate optimal allocation for different domains in one and two stages stratified sample design. R2BEAT extends the Neyman (1934) – Tschuprow (1923) allocation method to the case of several variables, adopting a generalization of the Bethel’s proposal (1989).R2BEAT develops this methodology but, moreover, it allows to determine the sample allocation in the multivariate and multi-domains case of estimates for two-stage stratified samples. It also allows to perform both Primary Stage Units and Secondary Stage Units selection. This package requires the availability of ReGenesees, that can be installed from <https://github.com/DiegoZardetto/ReGenesees>.",2021-12-02,Andrea Fasulo,https://barcaroli.github.io/R2BEAT/,TRUE,https://github.com/barcaroli/r2beat,16498,1,2022-05-12T14:14:09Z,16498
r2d3,"Suite of tools for using 'D3', a library for producing dynamic, interactive data
  visualizations. Supports translating objects into 'D3' friendly data structures, rendering
  'D3' scripts, publishing 'D3' visualizations, incorporating 'D3' in R Markdown, creating
  interactive 'D3' applications with Shiny, and distributing 'D3' based 'htmlwidgets' in R
  packages.",2022-02-28,Nick Strayer,"https://rstudio.github.io/r2d3/, https://github.com/rstudio/r2d3",TRUE,https://github.com/rstudio/r2d3,613171,493,2021-11-18T21:31:50Z,1243.7545638945232
r2dii.analysis,"These tools help you to assess if a corporate lending
    portfolio aligns with climate goals. They summarize key climate
    indicators attributed to the portfolio (e.g. production, emission
    factors), and calculate alignment targets based on climate scenarios.
    They implement in R the last step of the free software 'PACTA' (Paris
    Agreement Capital Transition Assessment;
    <https://2degrees-investing.org/>). Financial institutions use 'PACTA'
    to study how their capital allocation decisions align with climate
    change mitigation goals.",2022-05-05,Jackson Hoffart,"https://github.com/2DegreesInvesting/r2dii.analysis,
https://2degreesinvesting.github.io/r2dii.analysis/",TRUE,https://github.com/2degreesinvesting/r2dii.analysis,13779,9,2022-05-16T13:46:44Z,1531
r2dii.data,"These datasets support the implementation in R of the
    software 'PACTA' (Paris Agreement Capital Transition Assessment),
    which is a free tool that calculates the alignment between corporate
    lending portfolios and climate scenarios
    (<https://2degrees-investing.org/>). Financial institutions use
    'PACTA' to study how their capital allocation decisions align with
    climate change mitigation goals. Because both financial institutions
    and market data providers keep their data private, this package
    provides fake, public data to enable the development and use of
    'PACTA' in R.",2022-05-05,Jackson Hoffart,"https://2degreesinvesting.github.io/r2dii.data//,
https://github.com/2DegreesInvesting/r2dii.data,
https://2degreesinvesting.github.io/r2dii.data/",TRUE,https://github.com/2degreesinvesting/r2dii.data,22731,4,2022-05-06T14:52:59Z,5682.75
r2dii.match,"These tools implement in R a fundamental part of the software
    'PACTA' (Paris Agreement Capital Transition Assessment), which is a
    free tool that calculates the alignment between financial portfolios
    and climate scenarios (<https://2degrees-investing.org/>). Financial
    institutions use 'PACTA' to study how their capital allocation
    decisions align with climate change mitigation goals. This package
    matches data from corporate lending portfolios to asset level data
    from market-intelligence databases (e.g. power plant capacities,
    emission factors, etc.). This is the first step to assess if a
    financial portfolio aligns with climate goals.",2022-05-05,Jackson Hoffart,"https://2degreesinvesting.github.io/r2dii.match//,
https://github.com/2DegreesInvesting/r2dii.match,
https://2degreesinvesting.github.io/r2dii.match/",TRUE,https://github.com/2degreesinvesting/r2dii.match,18244,3,2022-05-09T11:58:35Z,6081.333333333333
r2dii.plot,"Create plots to visualize the alignment of a corporate
    lending financial portfolio to climate change scenarios based on
    climate indicators (production and emission intensities) across key
    climate relevant sectors of the 'PACTA' methodology (Paris Agreement
    Capital Transition Assessment; <https://2degrees-investing.org/>).
    Financial institutions use 'PACTA' to study how their capital
    allocation decisions align with climate change mitigation goals.",2022-05-05,Monika Furdyna,"https://github.com/2DegreesInvesting/r2dii.plot,
https://2degreesinvesting.github.io/r2dii.plot/",TRUE,https://github.com/2degreesinvesting/r2dii.plot,5260,4,2022-05-06T15:31:40Z,1315
R2HTML,"Includes HTML function and methods to write in an HTML
        file. Thus, making HTML reports is easy. Includes a function
        that allows redirection on the fly, which appears to be very
        useful for teaching purpose, as the student can keep a copy of
        the produced output to keep all that he did during the course.
        Package comes with a vignette describing how to write HTML
        reports for statistical analysis. Finally, a driver for 'Sweave'
        allows to parse HTML flat files containing R code and to
        automatically write the corresponding outputs (tables and
        graphs).",2022-05-23,Milan Bouchet-Valat,https://github.com/nalimilan/R2HTML,TRUE,https://github.com/nalimilan/r2html,381234,3,2022-05-23T09:21:27Z,127078
R2jags,"Providing wrapper functions to implement Bayesian analysis in JAGS.  Some major features include monitoring convergence of a MCMC model using Rubin and Gelman Rhat statistics, automatically running a MCMC model till it converges, and implementing parallel processing of a MCMC model for multiple chains.",2021-08-05,Yu-Sung Su,NA,TRUE,https://github.com/suyusung/r2jags,326242,6,2021-08-04T23:14:37Z,54373.666666666664
r2mlm,"Generates both total- and level-specific R-squared measures from
    Rights and Sterba’s (2019) <doi:10.1037/met0000184> framework of R-squared measures for multilevel
    models with random intercepts and/or slopes, which is based on a complete
    decomposition of variance. Additionally generates graphical 
    representations of these R-squared measures to allow visualizing and 
    interpreting all measures in the framework together as an integrated set.
    This framework subsumes 10 previously-developed R-squared measures for 
    multilevel models as special cases of 5 measures from the framework, and it
    also includes several newly-developed measures. Measures in the framework 
    can be used to compute R-squared differences when comparing multilevel 
    models (following procedures in Rights & Sterba (2020) <doi:10.1080/00273171.2019.1660605>).",2022-07-06,Mairead Shaw,https://github.com/mkshaw/r2mlm,TRUE,https://github.com/mkshaw/r2mlm,15223,20,2022-07-06T15:11:21Z,761.15
r2pmml,"R wrapper for the JPMML-R library <https://github.com/jpmml/jpmml-r>,
    which converts R models to Predictive Model Markup Language (PMML).",2021-03-19,Villu Ruusmann,https://github.com/jpmml/r2pmml,TRUE,https://github.com/jpmml/r2pmml,15142,70,2022-06-28T16:37:37Z,216.31428571428572
R2PPT,"Provides a simple set of wrappers to easily use 
         RDCOMClient for generating Microsoft PowerPoint presentations. Warning:this package is soon to be archived from CRAN. ",2022-04-26,Wayne Jones,https://github.com/waynegitshell/R2PPT/,TRUE,https://github.com/waynegitshell/r2ppt,12050,0,2022-04-26T14:00:55Z,NA
r2pptx,"Provides a friendly, object oriented API for creating PowerPoint
    slide decks in R.",2021-09-15,Matt Lehman,"https://mattle24.github.io/r2pptx/,
https://github.com/mattle24/r2pptx",TRUE,https://github.com/mattle24/r2pptx,3148,2,2021-12-03T21:14:02Z,1574
r2rtf,Create production-ready Rich Text Format (RTF) table and figure with flexible format.,2022-05-17,Yilong Zhang,"https://merck.github.io/r2rtf/, https://github.com/Merck/r2rtf",TRUE,https://github.com/merck/r2rtf,13221,43,2022-07-05T04:54:06Z,307.4651162790698
r2shortcode,"When creating a package, authors may sometimes struggle with coming up with easy and straightforward function names, and at the same time hoping that other packages do not already have the same function names. In trying to meet this goal, sometimes, function names are not descriptive enough and may confuse the potential users. The purpose of this package is to serve as a package function short form generator and also provide shorthand names for other functions. Having this package will entice authors to create long function names without the fear of users not wanting to use their packages because of the long names. In a way, everyone wins - the authors can use long descriptive function names, and the users can use this package to make short functions names while still using the package in question.",2020-06-25,Obinna Obianom,https://github.com/oobianom/r2shortcode,TRUE,https://github.com/oobianom/r2shortcode,6438,0,2021-09-28T02:56:10Z,NA
r2spss,"Create plots and LaTeX tables that look like SPSS output for use in teaching materials.  Rather than copying-and-pasting SPSS output into documents, R code that mocks up SPSS output can be integrated directly into dynamic LaTeX documents with tools such as knitr.  Functionality includes statistical techniques that are typically covered in introductory statistics classes: descriptive statistics, common hypothesis tests, ANOVA, and linear regression, as well as box plots, histograms, scatter plots, and line plots (including profile plots).",2022-05-25,Andreas Alfons,https://github.com/aalfons/r2spss,TRUE,https://github.com/aalfons/r2spss,2544,1,2022-06-03T08:46:54Z,2544
R2SWF,"Using the 'Ming' library
    <https://github.com/libming/libming> to create Flash animations.
    Users can either use the 'SWF' device swf() to generate 'SWF' file
    directly through plotting functions like plot() and lines(),
    or convert images of other formats ('SVG', 'PNG', 'JPEG') into 'SWF'.",2022-02-11,Yixuan Qiu,https://github.com/yixuan/R2SWF,TRUE,https://github.com/yixuan/r2swf,21876,2,2022-02-09T15:24:46Z,10938
r2symbols,"Direct insertion of symbols (e.g. currencies, letters, arrows, mathematical symbols and so on) into 'Rmarkdown' documents and 'Shiny' applications by incorporating 'HTML' hex codes.",2020-09-09,Obinna Obianom,https://github.com/oobianom/r2symbols,TRUE,https://github.com/oobianom/r2symbols,9836,2,2021-09-28T02:45:57Z,4918
r3dmol,"Create rich and fully interactive 3D visualizations of molecular data.
    Visualizations can be included in Shiny apps and R markdown documents, or viewed
    from the R console and 'RStudio' Viewer. 'r3dmol' includes an extensive API
    to manipulate the visualization after creation, and supports getting data out of
    the visualization into R. Based on the '3dmol.js' and the 'htmlwidgets' R package.",2021-03-14,Wei Su,https://github.com/swsoyee/r3dmol,TRUE,https://github.com/swsoyee/r3dmol,7458,58,2021-09-16T15:45:27Z,128.58620689655172
r3PG,"Provides a flexible and easy-to-use interface for the Physiological Processes Predicting Growth (3-PG) model written in Fortran. The r3PG serves as a flexible and easy-to-use interface for the 3-PGpjs (monospecific, evenaged and evergreen forests) described in Landsberg & Waring (1997) <doi:10.1016/S0378-1127(97)00026-1> and the 3-PGmix (deciduous, uneven-aged or mixed-species forests) described in Forrester & Tang (2016) <doi:10.1016/j.ecolmodel.2015.07.010>.",2022-05-19,Volodymyr Trotsiuk,https://github.com/trotsiuk/r3PG,TRUE,https://github.com/trotsiuk/r3pg,9678,18,2022-05-19T11:36:18Z,537.6666666666666
r4googleads,"Interface for the 'Google Ads API'. 'Google Ads' is an online
    advertising service that enables advertisers to display advertising to web
    users (see <https://developers.google.com/google-ads/> for more information).",2022-02-28,Johannes Burkhardt,https://github.com/banboo-data/r4googleads,TRUE,https://github.com/banboo-data/r4googleads,1231,3,2022-02-28T11:22:06Z,410.3333333333333
r4ss,"A collection of R functions for use with Stock Synthesis, a
    fisheries stock assessment modeling platform written in ADMB by Dr. Richard
    D. Methot at the NOAA Northwest Fisheries Science Center. The functions
    include tools for summarizing and plotting results, manipulating files,
    visualizing model parameterizations, and various other common stock
    assessment tasks.
    This version of '{r4ss}' is compatible with Stock Synthesis versions
    3.24 through 3.30 (specifically version 3.30.19.01, from April
    2022).",2022-05-26,Ian G. Taylor,https://github.com/r4ss/r4ss,TRUE,https://github.com/r4ss/r4ss,22895,29,2022-07-08T23:41:28Z,789.4827586206897
r5r,"Rapid realistic routing on multimodal transport networks (walk, 
             bike, public transport and car) using 'R5', the Rapid Realistic 
             Routing on Real-world and Reimagined networks engine 
             <https://github.com/conveyal/r5>. The package allows users to 
             generate detailed routing analysis or calculate travel time matrices
             using seamless parallel computing on top of the R5 Java machine.
             While R5 is developed by Conveyal, the package r5r is independently 
             developed by a team at the Institute for Applied Economic Research
             (Ipea) with contributions from collaborators. Apart from the 
             documentation in this package, users will find additional information
             on R5 documentation at <https://docs.conveyal.com/>. Although we try
             to keep new releases of r5r in synchrony with R5, the development of R5
             follows Conveyal's independent update process. Hence, users should
             confirm the R5 version implied by the Conveyal user manual (see
             <https://docs.conveyal.com/changelog>) corresponds with the R5 version
             that r5r depends on.",2022-07-05,Marcus Saraiva,https://github.com/ipeaGIT/r5r,TRUE,https://github.com/ipeagit/r5r,36290,98,2022-07-06T13:01:59Z,370.3061224489796
R6,"Creates classes with reference semantics, similar to R's built-in
    reference classes. Compared to reference classes, R6 classes are simpler
    and lighter-weight, and they are not built on S4 classes so they do not
    require the methods package. These classes allow public and private
    members, and they support inheritance, even when the classes are defined in
    different packages.",2021-08-19,Winston Chang,"https://r6.r-lib.org, https://github.com/r-lib/R6/",TRUE,https://github.com/r-lib/r6,23115615,360,2022-06-22T20:16:42Z,64210.041666666664
R62S3,"After defining an R6 class, R62S3 is used to automatically generate optional S3/S4 generics and methods for dispatch. Also allows piping for R6 objects.",2020-03-09,Raphael Sonabend,https://github.com/RaphaelS1/R62S3/,TRUE,https://github.com/raphaels1/r62s3,108498,29,2022-03-25T21:38:04Z,3741.310344827586
r6methods,"Generate boilerplate code for R6 classes. Given R6 class create getters 
    and/or setters for selected class fields or use RStudio addins to insert methods 
    straight into class definition.",2021-03-16,Jakub Sobolewski,https://github.com/jakubsob/r6methods,TRUE,https://github.com/jakubsob/r6methods,4529,8,2022-01-16T19:36:37Z,566.125
R6P,"Build robust and maintainable software with object-oriented design 
    patterns in R. Design patterns abstract and present in neat, well-defined 
    components and interfaces the experience of many software designers and 
    architects over many years of solving similar problems. These are solutions 
    that have withstood the test of time with respect to re-usability,
    flexibility, and maintainability. 'R6P' provides abstract base classes with 
    examples for a few known design patterns. The patterns were selected by 
    their applicability to analytic projects in R. Using these patterns in R 
    projects have proven effective in dealing with the complexity that 
    data-driven applications possess.",2021-08-03,Harel Lustiger,"https://tidylab.github.io/R6P/, https://github.com/tidylab/R6P",TRUE,https://github.com/tidylab/r6p,8189,5,2021-08-05T05:29:01Z,1637.8
raceland,"Implements a computational framework for a pattern-based, 
    zoneless analysis, and visualization of (ethno)racial topography 
    (Dmowska, Stepinski, and Nowosad (2020) <doi:10.1016/j.apgeog.2020.102239>).
    It is a reimagined
    approach for analyzing residential segregation and racial diversity based on 
    the concept of 'landscape’ used in the domain of landscape ecology.",2022-02-11,Jakub Nowosad,https://jakubnowosad.com/raceland/,TRUE,https://github.com/nowosad/raceland,15428,8,2022-02-11T09:26:08Z,1928.5
radarBoxplot,"Creates the radar-boxplot, a plot that was created by the 
    author during his Ph.D. in forest resources. 
    The radar-boxplot is a visualization feature suited for  
    multivariate classification/clustering. It provides an intuitive 
    deep understanding of the data.",2021-10-07,Caio Hamamura,"https://github.com/caiohamamura/radarBoxplot-R,
https://radarboxplot.r-forge.r-project.org/",TRUE,https://github.com/caiohamamura/radarboxplot-r,11287,4,2021-10-06T16:59:33Z,2821.75
radiant,"A platform-independent browser-based interface for business
    analytics in R, based on the shiny package. The application combines the
    functionality of 'radiant.data', 'radiant.design', 'radiant.basics',
    'radiant.model', and 'radiant.multivariate'.",2022-05-25,Vincent Nijs,https://github.com/radiant-rstats/radiant,TRUE,https://github.com/radiant-rstats/radiant,57421,369,2022-05-25T06:21:19Z,155.61246612466124
radiant.basics,"The Radiant Basics menu includes interfaces for probability 
    calculation, central limit theorem simulation, comparing means and proportions, 
    goodness-of-fit testing, cross-tabs, and correlation. The application extends 
    the functionality in 'radiant.data'.",2021-11-18,Vincent Nijs,"https://github.com/radiant-rstats/radiant.basics/,
https://radiant-rstats.github.io/radiant.basics/,
https://radiant-rstats.github.io/docs/",TRUE,https://github.com/radiant-rstats/radiant.basics,48301,8,2021-11-18T04:42:57Z,6037.625
radiant.data,"The Radiant Data menu includes interfaces for loading, saving,
    viewing, visualizing, summarizing, transforming, and combining data. It also
    contains functionality to generate reproducible reports of the analyses
    conducted in the application.",2022-05-25,Vincent Nijs,"https://github.com/radiant-rstats/radiant.data/,
https://radiant-rstats.github.io/radiant.data/,
https://radiant-rstats.github.io/docs/",TRUE,https://github.com/radiant-rstats/radiant.data,67255,48,2022-07-03T06:27:29Z,1401.1458333333333
radiant.design,"The Radiant Design menu includes interfaces for design of
    experiments, sampling, and sample size calculation. The application extends
    the functionality in 'radiant.data'.",2021-11-18,Vincent Nijs,"https://github.com/radiant-rstats/radiant.design/,
https://radiant-rstats.github.io/radiant.design/,
https://radiant-rstats.github.io/docs/",TRUE,https://github.com/radiant-rstats/radiant.design,44311,9,2021-11-18T04:40:42Z,4923.444444444444
radiant.model,"The Radiant Model menu includes interfaces for linear and logistic
    regression, naive Bayes, neural networks, classification and regression trees,
    model evaluation, collaborative filtering, decision analysis, and simulation. 
    The application extends the functionality in 'radiant.data'.",2022-05-25,Vincent Nijs,"https://github.com/radiant-rstats/radiant.model/,
https://radiant-rstats.github.io/radiant.model/,
https://radiant-rstats.github.io/docs/",TRUE,https://github.com/radiant-rstats/radiant.model,58366,18,2022-05-25T07:40:39Z,3242.5555555555557
radiant.multivariate,"The Radiant Multivariate menu includes interfaces for perceptual
    mapping, factor analysis, cluster analysis, and conjoint analysis. The
    application extends the functionality in 'radiant.data'.",2021-11-22,Vincent Nijs,"https://github.com/radiant-rstats/radiant.multivariate/,
https://radiant-rstats.github.io/radiant.multivariate/,
https://radiant-rstats.github.io/docs/",TRUE,https://github.com/radiant-rstats/radiant.multivariate,45351,6,2021-11-22T05:17:01Z,7558.5
radsafer,"Provides functions for radiation safety, also known as
    ""radiation protection"" and ""radiological control"". The science of 
    radiation protection is called ""health physics"" and its engineering 
    functions are called ""radiological engineering"". Functions in this 
    package cover many of the computations needed by radiation safety 
    professionals. Examples include: obtaining updated calibration and
    source check values for radiation monitors to account for radioactive 
    decay in a reference source, simulating instrument readings to better
    understand measurement uncertainty, correcting instrument readings 
    for geometry and ambient atmospheric conditions. Many of these 
    functions are described in Johnson and Kirby (2011, ISBN-13:  
    978-1609134198). Utilities are also included for developing inputs 
    and processing outputs with radiation transport codes, such as MCNP, 
    a general-purpose Monte Carlo N-Particle code that can be used for 
    neutron, photon, electron, or coupled neutron/photon/electron transport
    (Werner et. al. (2018) <doi:10.2172/1419730>).",2022-02-01,Mark Hogue,https://github.com/markhogue/radsafer,TRUE,https://github.com/markhogue/radsafer,16093,1,2022-02-01T19:03:52Z,16093
Radviz,"An implementation of the radviz projection in R. It enables the visualization of
    multidimensional data while maintaining the relation to the original dimensions.
    This package provides functions to create and plot radviz projections, and a number of summary
    plots that enable comparison and analysis. For reference see Ankerst *et al.* (1996) 
    (<https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.1811>) for original implementation, 
    see Di Caro *et al* (2012) (<https://link.springer.com/chapter/10.1007/978-3-642-13672-6_13>) 
    for the original method for dimensional anchor arrangements, see Demsar *et al.* (2007) 
    (<doi:10.1016/j.jbi.2007.03.010>) for the original Freeviz implementation.",2022-03-25,Yann Abraham,https://github.com/yannabraham/Radviz,TRUE,https://github.com/yannabraham/radviz,18706,9,2022-03-25T09:00:31Z,2078.4444444444443
RAdwords,"Aims at loading Google Adwords data into R. Adwords is an online
    advertising service that enables advertisers to display advertising copy to web
    users (see <https://developers.google.com/adwords/> for more information). 
    Therefore the package implements three main features. First, the package
    provides an authentication process for R with the Google Adwords API (see 
    <https://developers.google.com/adwords/api/> for more information) via OAUTH2.
    Second, the package offers an interface to apply the Adwords query language in
    R and query the Adwords API with ad-hoc reports. Third, the received data are
    transformed into suitable data formats for further data processing and data
    analysis.",2019-01-28,Johannes Burkhardt,"https://github.com/jburkhardt/RAdwords,
https://developers.google.com/adwords,
https://developers.google.com/adwords/api/",TRUE,https://github.com/jburkhardt/radwords,36276,99,2022-02-28T15:16:03Z,366.42424242424244
Rage,Functions for calculating life history metrics using matrix population models ('MPMs'). Described in Jones et al. (2021) <doi:10.1101/2021.04.26.441330>.,2021-10-15,Pol Capdevila,https://github.com/jonesor/Rage,TRUE,https://github.com/jonesor/rage,10809,5,2022-06-14T18:03:07Z,2161.8
ragg,"Anti-Grain Geometry (AGG) is a high-quality and high-performance
    2D drawing library. The 'ragg' package provides a set of graphic devices 
    based on AGG to use as alternative to the raster devices provided through
    the 'grDevices' package.",2022-02-21,Thomas Lin Pedersen,"https://ragg.r-lib.org, https://github.com/r-lib/ragg",TRUE,https://github.com/r-lib/ragg,21768685,157,2022-03-03T09:40:38Z,138654.04458598726
RagGrid,"Data objects in 'R' can be rendered as 'HTML' tables using the
    'JavaScript' library 'ag-grid' (typically via 'R Markdown' or 'Shiny'). The
    'ag-grid' library has been included in this 'R' package. The package name
    'RagGrid' is an abbreviation of 'R agGrid'.",2018-08-12,Srikkanth M,https://github.com/no-types/RagGrid/,TRUE,https://github.com/no-types/raggrid,11211,30,2022-02-06T03:23:50Z,373.7
rags2ridges,"Proper L2-penalized maximum likelihood estimators for precision 
  matrices and supporting functions to employ these estimators in a graphical 
  modeling setting. For details, see Peeters, Bilgrau, & van Wieringen (2022) 
  <doi:10.18637/jss.v102.i04> and associated publications.",2022-05-01,Carel F.W. Peeters,"https://cfwp.github.io/rags2ridges/,
https://github.com/CFWP/rags2ridges",TRUE,https://github.com/cfwp/rags2ridges,26366,6,2022-04-30T08:02:09Z,4394.333333333333
rai,"A modified implementation of stepwise regression that greedily searches 
    the space of interactions among features in order to build polynomial regression models.
    Furthermore, the hypothesis tests conducted are valid-post model selection
    due to the use of a revisiting procedure that implements an alpha-investing
    rule. As a result, the set of rejected sequential hypotheses is proven to 
    control the marginal false discover rate. When not searching for polynomials,
    the package provides a statistically valid algorithm
    to run and terminate stepwise regression. For more information, see 
    Johnson, Stine, and Foster (2019) <arXiv:1510.06322>.",2019-07-02,Kory D. Johnson,https://github.com/korydjohnson/rai,TRUE,https://github.com/korydjohnson/rai,10326,2,2022-04-15T13:52:39Z,5163
rainette,"An R implementation of the Reinert text clustering method. For more 
    details about the algorithm see the included vignettes or Reinert (1990) 
    <doi:10.1177/075910639002600103>.",2022-02-18,Julien Barnier,https://juba.github.io/rainette/,TRUE,https://github.com/juba/rainette,12727,46,2022-05-10T10:35:08Z,276.67391304347825
rainfarmr,"An implementation of the RainFARM (Rainfall Filtered Autoregressive Model) stochastic precipitation downscaling method (Rebora et al. (2006) <doi:10.1175/JHM517.1>). Adapted for climate downscaling according to D'Onofrio et al. (2018) <doi:10.1175/JHM-D-13-096.1> and for complex topography as in Terzago et al. (2018) <doi:10.5194/nhess-18-2825-2018>. The RainFARM method is based on the extrapolation to small scales of the Fourier spectrum of a large-scale precipitation field, using a fixed logarithmic slope and random phases at small scales, followed by a nonlinear transformation of the resulting linearly correlated stochastic field. RainFARM allows to generate ensembles of spatially downscaled precipitation fields which conserve precipitation at large scales and whose statistical properties are consistent with the small-scale statistics of observed precipitation, based only on knowledge of the large-scale precipitation field.",2019-04-09,Jost von Hardenberg,https://github.com/jhardenberg/rainfarmr,TRUE,https://github.com/jhardenberg/rainfarmr,17335,2,2022-03-19T00:15:01Z,8667.5
rairtable,"Efficient CRUD interface for the 'Airtable' API <https://airtable.com/api>, supporting batch requests and parallel encoding of large data sets.",2022-06-10,Matthew Rogers,https://matthewjrogers.github.io/rairtable/,TRUE,https://github.com/matthewjrogers/rairtable,244,3,2022-06-16T14:06:22Z,81.33333333333333
ralger,The goal of 'ralger' is to facilitate web scraping in R. ,2021-03-17,Mohamed El Fodil Ihaddaden,https://github.com/feddelegrand7/ralger,TRUE,https://github.com/feddelegrand7/ralger,20764,139,2022-06-18T19:16:19Z,149.38129496402877
rAmCharts4,"Creates JavaScript charts. The charts can be included in 'Shiny' apps and R markdown documents, or viewed from the R console and 'RStudio' viewer. Based on the JavaScript library 'amCharts 4' and the R packages 'htmlwidgets' and 'reactR'. Currently available types of chart are: vertical and horizontal bar chart, radial bar chart, stacked bar chart, vertical and horizontal Dumbbell chart, line chart, scatter chart, range area chart, gauge chart, boxplot chart, pie chart, and 100% stacked bar chart.",2021-10-10,Stéphane Laurent,https://github.com/stla/rAmCharts4,TRUE,https://github.com/stla/ramcharts4,10510,21,2021-10-10T15:48:00Z,500.4761904761905
RAMClustR,"A feature clustering algorithm for non-targeted mass spectrometric metabolomics data. This method is compatible with gas and liquid chromatography coupled mass spectrometry, including indiscriminant tandem mass spectrometry <DOI: 10.1021/ac501530d> data. ",2022-04-13,Helge Hecht,https://github.com/cbroeckl/RAMClustR,TRUE,https://github.com/cbroeckl/ramclustr,11345,9,2022-05-12T21:16:49Z,1260.5555555555557
ramcmc,"Function for adapting the shape of the random walk Metropolis proposal
    as specified by robust adaptive Metropolis algorithm by Vihola (2012) <doi:10.1007/s11222-011-9269-5>. 
    The package also includes fast functions for rank-one Cholesky update and downdate.
    These functions can be used directly from R or the corresponding C++ header files 
    can be easily linked to other R packages.",2021-10-06,Jouni Helske,NA,TRUE,https://github.com/helske/ramcmc,64982,4,2021-10-06T20:50:02Z,16245.5
rameritrade,"Use R to interface with the 'TD Ameritrade' API <https://developer.tdameritrade.com/>.
    Functions include authentication, trading, price requests, account information, and option 
    chains. A user will need a TD brokerage account and TD Ameritrade developer app. See README 
    for authentication process and examples.",2021-02-22,Anthony Balentine,https://exploringfinance.github.io/rameritrade/,TRUE,https://github.com/exploringfinance/rameritrade,7109,12,2021-10-20T01:56:40Z,592.4166666666666
RaMS,"R-based access to mass-spectrometry (MS) data. While many packages 
  exist to process MS data, many of these make it difficult to 
  access the underlying mass-to-charge ratio (m/z), intensity, and 
  retention time of the files 
  themselves. This package is designed to format MS data in a tidy fashion and 
  allows the user perform the plotting and analysis.",2021-03-22,William Kumler,https://github.com/wkumler/RaMS,TRUE,https://github.com/wkumler/rams,4679,9,2022-05-17T02:18:28Z,519.8888888888889
randomForestExplainer,"A set of tools to help explain which variables are most important in a random forests. Various variable importance measures are calculated and visualized in different settings in order to get an idea on how their importance changes depending on our criteria (Hemant Ishwaran and Udaya B. Kogalur and Eiran Z. Gorodeski and Andy J. Minn and Michael S. Lauer (2010) <doi:10.1198/jasa.2009.tm08622>, Leo Breiman (2001) <doi:10.1023/A:1010933404324>).",2020-07-11,Yue Jiang,https://github.com/ModelOriented/randomForestExplainer,TRUE,https://github.com/modeloriented/randomforestexplainer,42410,198,2021-09-27T04:44:22Z,214.1919191919192
RandomForestsGLS,"Fits non-linear regression models on dependant data with Generalised Least Square (GLS) based Random Forest (RF-GLS) detailed in Saha, Basu and Datta (2020) <arXiv:2007.15421>.",2022-04-28,Arkajyoti Saha,https://github.com/ArkajyotiSaha/RandomForestsGLS,TRUE,https://github.com/arkajyotisaha/randomforestsgls,10709,8,2022-02-24T01:16:07Z,1338.625
randomForestSRC,"Fast OpenMP parallel computing of Breiman's random forests for univariate, multivariate, unsupervised, survival, competing risks, class imbalanced classification and quantile regression. New Mahalanobis splitting for correlated outcomes.  Extreme random forests and randomized splitting.  Suite of imputation methods for missing data.  Fast random forests using subsampling. Confidence regions and standard errors for variable importance. New improved holdout importance. Case-specific importance.  Minimal depth variable importance. Visualize trees on your Safari or Google Chrome browser. Anonymous random forests for data privacy.",2022-07-06,Hemant Ishwaran,https://www.randomforestsrc.org/ https://ishwaran.org/,TRUE,https://github.com/kogalur/randomforestsrc,320264,86,2022-04-15T14:59:45Z,3724
randomizr,"Generates random assignments for common experimental designs and 
	    random samples for common sampling designs.",2022-01-27,Alexander Coppock,"https://declaredesign.org/r/randomizr/,
https://github.com/DeclareDesign/randomizr",TRUE,https://github.com/declaredesign/randomizr,106463,30,2022-03-02T06:36:26Z,3548.766666666667
randomNames,Function for generating random gender and ethnicity correct first and/or last names. Names are chosen proportionally based upon their probability of appearing in a large scale data base of real names.,2021-04-22,Damian W. Betebenner,"https://CenterForAssessment.github.io/randomNames,
https://github.com/CenterForAssessment/randomNames,
https://cran.r-project.org/package=randomNames",TRUE,https://github.com/centerforassessment/randomnames,58268,26,2022-05-25T14:55:31Z,2241.076923076923
Randomuseragent,"Based on data of real user-agent strings, we can set filtering conditions
    and randomly sample user-agent strings from the user-agent string pool.",2021-06-17,Fangzhou Xie,"https://github.com/fangzhou-xie/Randomuseragent,
https://fangzhou-xie.github.io/Randomuseragent/index.html",TRUE,https://github.com/fangzhou-xie/randomuseragent,3959,3,2021-11-19T20:07:42Z,1319.6666666666667
rangeBuilder,"Provides tools for filtering occurrence records, generating alpha-hull-derived range polygons and mapping species distributions. ",2022-06-21,Pascal Title,https://github.com/ptitle/rangeBuilder,TRUE,https://github.com/ptitle/rangebuilder,18317,4,2022-06-22T14:18:57Z,4579.25
rangemap,"A collection of tools to create species range maps based on 
    occurrence data, statistics, and spatial objects. Other tools in this 
    collection can be used to analyze the environmental characteristics of 
    the species ranges. Plotting options to represent results in various 
    manners are also available. Results obtained using these tools can be 
    used to explore the distribution of species and define areas of occupancy 
    and extent of occurrence of species. Other packages help to explore species 
    distributions using distinct methods, but options presented in this set of 
    tools (e.g., using trend surface analysis and concave hull polygons) are 
    exclusive. Description of methods, approaches, and comments for some of the 
    tools implemented here can be found in: 
    IUCN (2001) <https://portals.iucn.org/library/node/10315>,
    Peterson et al. (2011) <https://www.degruyter.com/princetonup/view/title/506966>, 
    and Graham and Hijmans (2006) <doi:10.1111/j.1466-8238.2006.00257.x>.",2021-09-03,Marlon E. Cobos,https://github.com/marlonecobos/rangemap,TRUE,https://github.com/marlonecobos/rangemap,6973,16,2022-04-14T17:51:43Z,435.8125
ranger,"A fast implementation of Random Forests, particularly suited for high
          dimensional data. Ensembles of classification, regression, survival and
          probability prediction trees are supported. Data from genome-wide association
          studies can be analyzed efficiently. In addition to data frames, datasets of
          class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') 
          can be directly analyzed.",2022-06-18,Marvin N. Wright,https://github.com/imbs-hl/ranger,TRUE,https://github.com/imbs-hl/ranger,2840050,683,2022-06-17T07:04:58Z,4158.199121522694
RankAggSIgFUR,"Polynomially bounded algorithms to aggregate complete rankings under Kemeny's axiomatic framework. 'RankAggSIgFUR' (pronounced as rank-agg-cipher) contains two heuristics algorithms: FUR and SIgFUR. For details, please see Badal and Das (2018) <doi:10.1016/j.cor.2018.06.007>.",2022-05-21,Rakhi Singh,https://github.com/prakashvs613/RankAggSIgFUR,TRUE,https://github.com/prakashvs613/rankaggsigfur,334,0,2022-05-27T04:31:56Z,NA
Rankcluster,"Implementation of a model-based clustering algorithm for
    ranking data (C. Biernacki, J. Jacques (2013) <doi:10.1016/j.csda.2012.08.008>). 
    Multivariate rankings as well as partial rankings are taken
    into account. This algorithm is based on an extension of the Insertion
    Sorting Rank (ISR) model for ranking data, which is a meaningful and
    effective model parametrized by a position parameter (the modal ranking,
    quoted by mu) and a dispersion parameter (quoted by pi). The heterogeneity
    of the rank population is modelled by a mixture of ISR, whereas conditional
    independence assumption is considered for multivariate rankings.",2021-01-27,Quentin Grimonprez,NA,TRUE,https://github.com/modal-inria/rankcluster,19615,0,2021-10-15T18:49:16Z,NA
RankingProject,"Functions to generate plots and tables for comparing independently-
    sampled populations. Companion package to ""A Primer on Visualizations
    for Comparing Populations, Including the Issue of Overlapping Confidence
    Intervals"" by Wright, Klein, and Wieczorek (2019)
    <DOI:10.1080/00031305.2017.1392359> and ""A Joint Confidence Region for an
    Overall Ranking of Populations"" by Klein, Wright, and Wieczorek (2020)
    <DOI:10.1111/rssc.12402>.",2022-01-28,Jerzy Wieczorek,https://github.com/civilstat/RankingProject,TRUE,https://github.com/civilstat/rankingproject,15031,4,2022-04-25T17:53:58Z,3757.75
rapbase,"Provide common functions and resources for registry specific
    R-packages at Rapporteket
    <https://rapporteket.github.io/rapporteket/articles/short_introduction.html>.
    This package is relevant for developers of packages/registries at
    Rapporteket.",2019-08-07,Are Edvardsen,http://github.com/Rapporteket/rapbase,TRUE,https://github.com/rapporteket/rapbase,10584,0,2022-06-03T12:23:18Z,NA
rapiclient,"Access services specified in OpenAPI (formerly Swagger) format.
  It is not a code generator. Client is generated dynamically as a list of R 
  functions.",2020-01-17,Darko Bergant,https://github.com/bergant/rapiclient,TRUE,https://github.com/bergant/rapiclient,20132,52,2022-05-14T00:31:37Z,387.15384615384613
RApiDatetime,"Access to the C-level R date and datetime code is provided for
 C-level API use by other packages via registration of native functions.
 Client packages simply include a single header 'RApiDatetime.h' provided
 by this package, and also 'import' it.  The R Core group is the original
 author of the code made available with slight modifications by this package. ",2021-08-14,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rapidatetime,
https://dirk.eddelbuettel.com/code/rapidatetime.html",TRUE,https://github.com/eddelbuettel/rapidatetime,30041,10,2021-11-27T23:04:04Z,3004.1
rapidoc,"A collection of 'HTML', 'JavaScript', 'CSS' and fonts
  assets that generate 'RapiDoc' documentation from an 'OpenAPI' Specification:
   <https://mrin9.github.io/RapiDoc/>.",2021-02-05,Bruno Tremblay,https://github.com/meztez/rapidoc,TRUE,https://github.com/meztez/rapidoc,6688,10,2021-11-10T14:23:23Z,668.8
rapportools,"Helper functions that act as wrappers to more advanced statistical
    methods with the advantage of having sane defaults for quick reporting.",2022-03-22,Aleksandar Blagotić,NA,TRUE,https://github.com/rapporter/rapportools,269531,7,2022-03-21T23:20:00Z,38504.42857142857
rapsimng,"The Agricultural Production Systems sIMulator ('APSIM') is a widely
    used to simulate the agricultural systems for multiple crops. This package 
    is designed to create, modify and run 'apsimx' files in the 'APSIM' Next 
    Generation <https://www.apsim.info/>.",2021-09-09,Bangyou Zheng,"https://rapsimng.bangyou.me/, https://github.com/byzheng/rapsimng",TRUE,https://github.com/byzheng/rapsimng,7277,5,2022-07-08T07:10:08Z,1455.4
rare,"Implementation of an alternating direction method of multipliers
    algorithm for fitting a linear model with tree-based lasso regularization, 
    which is proposed in Algorithm 1 of Yan and Bien (2018) <arXiv:1803.06675>. 
    The package allows efficient model fitting on the entire 2-dimensional 
    regularization path for large datasets. The complete set of functions 
    also makes the entire process of tuning regularization parameters and 
    visualizing results hassle-free.",2018-08-03,Xiaohan Yan,https://github.com/yanxht/rare,TRUE,https://github.com/yanxht/rare,10909,9,2022-01-24T23:55:21Z,1212.111111111111
rassta,"Algorithms for the spatial stratification of landscapes, sampling and modeling of 
    spatially-varying phenomena. These algorithms offer a simple framework for the stratification 
    of geographic space based on raster layers representing landscape factors and/or factor scales. 
    The stratification process follows a hierarchical approach, which is based on first level units 
    (i.e., classification units) and second-level units (i.e., stratification units). Nonparametric 
    techniques allow to measure the correspondence between the geographic space and the landscape 
    configuration represented by the units. These correspondence metrics are useful to define 
    sampling schemes and to model the spatial variability of environmental phenomena. The 
    theoretical background of the algorithms and code examples are presented in Fuentes, Dorantes,
    and Tipton (2021). <doi:10.31223/X50S57>.",2022-02-25,Bryan A. Fuentes,https://bafuentes.github.io/rassta/,TRUE,https://github.com/bafuentes/rassta,3402,14,2022-04-11T15:10:01Z,243
raster,"Reading, writing, manipulating, analyzing and modeling of spatial data. The package implements basic and high-level functions for raster data and for vector data operations such as intersections. See the manual and tutorials on <https://rspatial.org/> to get started.",2022-06-27,Robert J. Hijmans,https://rspatial.org/raster,TRUE,https://github.com/rspatial/raster,4758912,144,2022-06-25T15:34:39Z,33048
rasterbc,"R-based access to a large set of data variables relevant to forest ecology in British Columbia (BC), Canada. Layers
    are in raster format at 100m resolution in the BC Albers projection, hosted at the Federated Research Data Repository (FRDR)
    with <doi:10.20383/101.0283>. The collection includes: elevation; biogeoclimatic zone; wildfire; cutblocks; forest attributes from
    Hansen et al. (2013) <doi:10.1139/cjfr-2013-0401> and Beaudoin et al. (2017) <doi:10.1139/cjfr-2017-0184>; and rasterized
    Forest Insect and Disease Survey (FIDS) maps for a number of insect pest species, all covering the period 2001-2018.
    Users supply a polygon or point location in the province of BC, and 'rasterbc' will download the overlapping raster tiles
    hosted at FRDR, merging them as needed and returning the result in R as a 'SpatRaster' object. Metadata associated with these
    layers, and code for downloading them from their original sources can be found in the 'github' repository
    <https://github.com/deankoch/rasterbc_src>.",2022-01-18,Dean Koch,"https://github.com/deankoch/rasterbc,
https://github.com/deankoch/rasterbc_src",TRUE,https://github.com/deankoch/rasterbc,1613,5,2022-01-20T09:18:21Z,322.6
rasterdiv,"Providing functions to calculate indices of diversity on numerical matrices based on information theory. The rationale behind the package is described in Rocchini, Marcantonio and Ricotta (2017) <doi:10.1016/j.ecolind.2016.07.039> and Rocchini, Marcantonio,..., Ricotta (2021) <doi:10.1101/2021.01.23.427872>.",2022-03-29,Matteo Marcantonio,NA,TRUE,https://github.com/mattmar/rasterdiv,11707,11,2022-03-24T15:51:33Z,1064.2727272727273
rasterpdf,"The ability to plot raster graphics in PDF files can be useful
    when one needs multi-page documents, but the plots contain so many
    individual elements that (the usual) use of vector graphics results in
    inconveniently large file sizes. Internally, the package plots each
    individual page as a PNG, and then combines them in one PDF file.",2019-11-22,Ilari Scheinin,"https://ilarischeinin.github.io/rasterpdf,
https://github.com/ilarischeinin/rasterpdf",TRUE,https://github.com/ilarischeinin/rasterpdf,10867,3,2021-08-06T06:22:15Z,3622.3333333333335
rasterpic,"Create a spatial raster, as the ones provided by 'terra',
    from regular pictures.",2022-06-10,Diego Hernangómez,"https://dieghernan.github.io/rasterpic/,
https://github.com/dieghernan/rasterpic",TRUE,https://github.com/dieghernan/rasterpic,1847,9,2022-06-10T10:51:29Z,205.22222222222223
rasterVis,"Methods for enhanced visualization and interaction with raster data. It implements visualization methods for quantitative data and categorical data, both for univariate and multivariate rasters. It also provides methods to display spatiotemporal rasters, and vector fields. See the website for examples.",2022-01-23,Oscar Perpinan Lamigueiro,https://oscarperpinan.github.io/rastervis/,TRUE,https://github.com/oscarperpinan/rastervis,372172,72,2022-06-02T22:47:06Z,5169.055555555556
ratematrix,"The Evolutionary Rate Matrix is a variance-covariance matrix which describes both the rates of trait evolution and the evolutionary correlation among multiple traits. This package has functions to estimate these parameters using Bayesian MCMC. It is possible to test if the pattern of evolutionary correlations among traits has changed between predictive regimes painted along the branches of the phylogenetic tree. Regimes can be created a priori or estimated as part of the MCMC under a joint estimation approach. The package has functions to run MCMC chains, plot results, evaluate convergence, and summarize posterior distributions.",2022-06-03,Daniel Caetano,https://github.com/Caetanods/ratematrix,TRUE,https://github.com/caetanods/ratematrix,14284,7,2022-06-02T17:06:03Z,2040.5714285714287
rater,"Fit statistical models based on the Dawid-Skene model - Dawid
    and Skene (1979) <doi:10.2307/2346806> - to repeated categorical
    rating data.  Full Bayesian inference for these models is supported
    through the Stan modelling language. 'rater' also allows the user to
    extract and plot key parameters of these models.",2021-07-13,Jeffrey Pullin,"https://jeffreypullin.github.io/rater/,
https://github.com/jeffreypullin/rater",TRUE,https://github.com/jeffreypullin/rater,7550,16,2021-07-14T01:20:22Z,471.875
RAthena,"Designed to be compatible with the R package 'DBI' (Database Interface)
    when connecting to Amazon Web Service ('AWS') Athena <https://aws.amazon.com/athena/>.
    To do this 'Python' 'Boto3' Software Development Kit ('SDK')
    <https://boto3.amazonaws.com/v1/documentation/api/latest/index.html> is used as a driver.",2022-05-20,Dyfan Jones,https://github.com/DyfanJones/RAthena,TRUE,https://github.com/dyfanjones/rathena,79171,29,2022-05-19T16:29:45Z,2730.0344827586205
rationalfun,"Functions to manipulate rational functions, including basic
    arithmetic operators, derivatives, and integrals with EXPLICIT forms.",2022-03-05,Yixuan Qiu,https://github.com/yixuan/rationalfun,TRUE,https://github.com/yixuan/rationalfun,13262,1,2022-03-05T14:05:59Z,13262
rATTAINS,"An R interface to United States Environmental Protection Agency (EPA)  
    Assessment, Total Maximum Daily Load (TMDL) Tracking and Implementation System 
    ('ATTAINS') data. 'ATTAINS' is the EPA database used to track information 
    provided by states about water quality assessments conducted under federal 
    Clean Water Act requirements. ATTAINS information and API information is available at <https://www.epa.gov/waterdata/attains>.",2021-11-03,Michael Schramm,NA,TRUE,https://github.com/mps9506/rattains,3811,0,2022-05-18T15:34:43Z,NA
ravedash,"Dashboard system to display the analysis results produced by 'RAVE'
    (Magnotti J.F., Wang Z., Beauchamp M.S. (2020), R analysis 
    and visualizations of 'iEEG' <doi:10.1016/j.neuroimage.2020.117341>). 
    Provides infrastructure to integrate customized analysis pipelines into
    dashboard modules, including file structures, front-end widgets, and 
    event handlers.",2022-06-23,Zhengjia Wang,https://dipterix.org/ravedash/,TRUE,https://github.com/dipterix/ravedash,184,0,2022-07-02T00:38:12Z,NA
raveio,"Includes multiple cross-platform read/write interfaces for
    'RAVE' project. 'RAVE' stands for ""R analysis and visualization of human 
    intracranial electroencephalography data"". The whole project aims at 
    providing powerful free-source package that analyze brain recordings from 
    patients with electrodes placed on the cortical surface or inserted into 
    the brain. 'raveio' as part of this project provides tools to read/write 
    neurophysiology data from/to 'RAVE' file structure, as well as several 
    popular formats including  'EDF(+)', 'Matlab', 'BIDS-iEEG', and 'HDF5', 
    etc. Documentation and examples about 'RAVE' project are provided at 
    <https://openwetware.org/wiki/RAVE>, and the paper by John F. Magnotti, 
    Zhengjia Wang, Michael S. Beauchamp (2020) 
    <doi:10.1016/j.neuroimage.2020.117341>; see 'citation(""raveio"")' for 
    details.",2022-06-20,Zhengjia Wang,https://beauchamplab.github.io/raveio/,TRUE,https://github.com/beauchamplab/raveio,13038,4,2022-06-20T16:19:12Z,3259.5
RavenR,"Utilities for processing input and output files associated with the Raven Hydrological Modelling Framework. Includes various plotting functions, model diagnostics, reading output files into extensible time series format, and support for writing Raven input files. 
    The 'RavenR' package is also archived at Chlumsky et al. (2020) <doi:10.5281/zenodo.4248183>.
    The Raven Hydrologic Modelling Framework method can be referenced with Craig et al. (2020) <doi:10.1016/j.envsoft.2020.104728>.",2022-06-23,Robert Chlumsky,https://github.com/rchlumsk/RavenR,TRUE,https://github.com/rchlumsk/ravenr,6767,25,2022-06-11T16:47:32Z,270.68
ravetools,"Implemented fast and memory-efficient 'Notch'-filter, 
    'Welch-periodogram', and discrete wavelet transform algorithm for hours of 
    high-resolution signals; providing fundamental toolbox
    for 'iEEG' preprocess pipelines. 
    Documentation and examples about 'RAVE' project are provided at 
    <https://openwetware.org/wiki/RAVE>, and the paper by John F. Magnotti, 
    Zhengjia Wang, Michael S. Beauchamp (2020) 
    <doi:10.1016/j.neuroimage.2020.117341>; see 'citation(""ravetools"")' for 
    details.",2022-05-29,Zhengjia Wang,http://dipterix.org/ravetools/,TRUE,https://github.com/dipterix/ravetools,1582,1,2022-07-08T02:10:48Z,1582
rayimage,"Uses convolution-based techniques to generate simulated camera bokeh, depth of field, and other camera effects, using an image and an optional depth map. Accepts both filename inputs and in-memory array representations of images and matrices. Includes functions to perform 2D convolutions, reorient and resize images/matrices, add image overlays, generate camera vignette effects, and add titles to images. ",2021-06-27,Tyler Morgan-Wall,"https://www.rayimage.dev,
https://github.com/tylermorganwall/rayimage",TRUE,https://github.com/tylermorganwall/rayimage,67460,37,2022-04-17T02:33:51Z,1823.2432432432433
rayrender,"Render scenes using pathtracing. Build 3D scenes out of spheres, cubes, planes, disks, triangles, cones, curves, line segments, cylinders, ellipsoids, and 3D models in the 'Wavefront' OBJ file format or the PLY Polygon File Format. Supports several material types, textures, multicore rendering, and tone-mapping. Based on the ""Ray Tracing in One Weekend"" book series. Peter Shirley (2018) <https://raytracing.github.io>.",2021-11-23,Tyler Morgan-Wall,"https://www.rayrender.net,
https://github.com/tylermorganwall/rayrender",TRUE,https://github.com/tylermorganwall/rayrender,48096,479,2022-06-24T00:27:03Z,100.40918580375782
rayshader,"Uses a combination of raytracing and multiple hill shading methods to produce 2D and 3D data visualizations and maps. Includes water detection and layering functions, programmable color palette generation, several built-in textures for hill shading, 2D and 3D plotting options, a built-in path tracer, 'Wavefront' OBJ file export, and the ability to save 3D visualizations to a 3D printable format.",2021-04-28,Tyler Morgan-Wall,"https://github.com/tylermorganwall/rayshader,
https://www.rayshader.com/",TRUE,https://github.com/tylermorganwall/rayshader,79473,1569,2022-05-12T03:45:49Z,50.652007648183556
raytracing,"Rossby wave ray paths are traced from 
             a determined source, specified wavenumber, and direction
             of propagation. ""raytracing"" also works with a set of 
             experiments changing these parameters, making possible the
             identification of Rossby wave sources automatically. 
             The theory used here is based on classical studies, 
             such as Hoskins and Karoly (1981) <doi:10.1175/1520-0469(1981)038%3C1179:TSLROA%3E2.0.CO;2>,
             Karoly (1983) <doi:10.1016/0377-0265(83)90013-1>, 
             Hoskins and Ambrizzi (1993) <doi:10.1175/1520-0469(1993)050%3C1661:RWPOAR%3E2.0.CO;2>,
             and Yang and Hoskins (1996) <doi:10.1175/1520-0469(1996)053%3C2365:PORWON%3E2.0.CO;2>.",2022-06-06,Amanda Rehbein,https://github.com/salvatirehbein/raytracing/,TRUE,https://github.com/salvatirehbein/raytracing,6133,3,2022-06-03T18:41:20Z,2044.3333333333333
rayvertex,"Rasterize images using a 3D software renderer. 3D scenes are created either by importing external files, building scenes out of the included objects, or by constructing meshes manually. Supports point and directional lights, anti-aliased lines, shadow mapping, transparent objects, translucent objects, multiple materials types, reflection, refraction, environment maps, multicore rendering, bloom, tone-mapping, and screen-space ambient occlusion.",2021-10-10,Tyler Morgan-Wall,"https://www.rayvertex.com,
https://github.com/tylermorganwall/rayvertex",TRUE,https://github.com/tylermorganwall/rayvertex,11344,53,2022-02-02T06:06:16Z,214.03773584905662
rb3,"Download and parse public files released by B3 and convert them
    into useful formats and data structures common to data analysis
    practitioners.",2022-06-22,Wilson Freitas,"https://github.com/wilsonfreitas/rb3,
http://wilsonfreitas.github.io/rb3/",TRUE,https://github.com/wilsonfreitas/rb3,949,45,2022-06-26T13:01:48Z,21.08888888888889
RBaseX,"'BaseX' <https://basex.org> is a XML database engine and a compliant 'XQuery 3.1' processor with full support of 'W3C Update Facility'. This package is a full client-implementation of the client/server protocol for 'BaseX' and provides functionalities to create, manipulate and query on XML-data. ",2022-03-10,Ben Engbers,https://github.com/BenEngbers/RBaseX,TRUE,https://github.com/benengbers/rbasex,12715,8,2022-03-11T14:27:27Z,1589.375
rbcb,"The Brazilian Central Bank API delivers many datasets which regard economic
  activity, regional economy, international economy, public finances, credit
  indicators and many more. For more information please see <http://dadosabertos.bcb.gov.br/>.
  These datasets can be accessed through 'rbcb' functions and can be obtained in
  different data structures common to R ('tibble', 'data.frame', 'xts', ...).",2022-03-30,Wilson Freitas,https://github.com/wilsonfreitas/rbcb,TRUE,https://github.com/wilsonfreitas/rbcb,5772,67,2022-05-17T12:11:00Z,86.14925373134328
rbch,"Issues RPC-JSON calls to 'bitcoind', the daemon of Bitcoin Cash (BCH), to
    extract transaction data from the blockchain. BCH is a fork of Bitcoin that permits
    a greater number of transactions per second. A BCH daemon is available under an MIT
    license from the Bitcoin Unlimited website <https://www.bitcoinunlimited.info>.",2022-01-10,Rucknium,"https://github.com/Rucknium/rbch,
https://www.bitcoinunlimited.info",TRUE,https://github.com/rucknium/rbch,1510,3,2022-01-08T20:40:00Z,503.3333333333333
Rbeast,"Interpretation of time series data is affected by model choices. Different models can give different or even contradicting estimates of patterns, trends, and mechanisms for the same data--a limitation alleviated by the Bayesian estimator of abrupt change,seasonality, and trend (BEAST) of this package. BEAST seeks to improve time series decomposition by forgoing the ""single-best-model"" concept and embracing all competing models into the inference via a Bayesian model averaging scheme. It is a flexible tool to uncover abrupt changes (i.e., change-points), cyclic variations (e.g., seasonality), and nonlinear trends in time-series observations. BEAST not just tells when changes occur but also quantifies how likely the detected changes are true. It detects not just piecewise linear trends but also arbitrary nonlinear trends. BEAST is applicable to real-valued time series data of all kinds, be it for remote sensing, economics, climate sciences, ecology, and hydrology. Example applications include its use to identify regime shifts in ecological data, map forest disturbance and land degradation from satellite imagery, detect market trends in economic data, pinpoint anomaly and extreme events in climate data, and unravel system dynamics in biological data. Details on BEAST are reported in Zhao et al. (2019) <doi:10.1016/j.rse.2019.04.034>.",2022-05-18,Kaiguang Zhao,https://github.com/zhaokg/Rbeast,TRUE,https://github.com/zhaokg/rbeast,35713,39,2022-07-05T19:09:11Z,915.7179487179487
rbedrock,Implements an interface to Minecraft (Bedrock Edition) worlds. Supports the analysis and management of these worlds and game saves.,2022-03-10,Reed Cartwright,https://github.com/reedacartwright/rbedrock,TRUE,https://github.com/reedacartwright/rbedrock,6697,16,2022-06-09T21:32:15Z,418.5625
rbi,"Provides a complete interface to 'LibBi', a library for Bayesian inference (see <http://libbi.org> and <doi:10.18637/jss.v067.i10> for more information). This includes functions for manipulating 'LibBi' models, for reading and writing 'LibBi' input/output files, for converting 'LibBi' output to provide traces for use with the coda package, and for running 'LibBi' to conduct inference.",2021-11-08,Sebastian Funk,https://github.com/sbfnk/RBi,TRUE,https://github.com/sbfnk/rbi,16241,21,2022-02-08T11:31:12Z,773.3809523809524
rbi.helpers,"Contains a collection of helper functions to use with 'RBi', the R interface to 'LibBi', described in Murray et al. (2015) <doi:10.18637/jss.v067.i10>. It contains functions to adapt the proposal distribution and number of particles in particle Markov-Chain Monte Carlo, as well as calculating the Deviance Information Criterion (DIC) and converting between times in 'LibBi' results and R time/dates.",2020-06-18,Sebastian Funk,"http://libbi.org, https://github.com/sbfnk/RBi,
https://github.com/sbfnk/RBi.helpers",TRUE,https://github.com/sbfnk/rbi,8341,21,2022-02-08T11:31:12Z,397.1904761904762
rBiasCorrection,"Implementation of the algorithms (with minor modifications)
    to correct bias in quantitative DNA methylation analyses as described
    by Moskalev et al. (2011) <doi:10.1093/nar/gkr213>. Publication:
    Kapsner et al. (2021) <doi:10.1002/ijc.33681>.",2022-06-20,Lorenz A. Kapsner,https://github.com/kapsner/rBiasCorrection,TRUE,https://github.com/kapsner/rbiascorrection,20175,1,2022-06-21T08:28:44Z,20175
rbibutils,"Read and write 'Bibtex' files. Convert between bibliography
    formats, including 'Bibtex', 'Biblatex', 'PubMed', 'Endnote', and
    'Bibentry'.  Includes a port of the 'bibutils' utilities by Chris
    Putnam <https://sourceforge.net/projects/bibutils/>. Supports all
    bibliography formats and character encodings implemented in
    'bibutils'.",2022-04-11,Georgi N. Boshnakov  (R port,"https://geobosh.github.io/rbibutils/ (website),
https://github.com/GeoBosh/rbibutils (devel)",TRUE,https://github.com/geobosh/rbibutils,1534398,4,2022-04-11T08:31:32Z,383599.5
rbioacc,"The MOSAICbioacc application is a turnkey package providing bioaccumulation
    factors (BCF/BMF/BSAF) from a toxicokinetic (TK) model fitted to
    accumulation-depuration data. It is designed to fulfil the requirements
    of regulators when examining applications for market authorization of active
    substances. See Ratier et al. (2021) <doi:10.1101/2021.09.08.459421>.",2022-01-12,Aurélie Siberchicot,https://github.com/aursiber/rbioacc,TRUE,https://github.com/aursiber/rbioacc,2940,0,2022-01-07T06:44:30Z,NA
rbioapi,"Currently fully supports Enrichr, JASPAR, miEAA, PANTHER,
    Reactome, STRING, and UniProt! The goal of rbioapi is to provide a
    user-friendly and consistent interface to biological databases and
    services: In a way that insulates the user from technicalities of
    using web services API and creates a unified and easy-to-use interface
    to biological and medical web services. This an ongoing project; New
    databases and services will be added periodically. Feel free to
    suggest any databases or services you often use.",2022-04-05,Moosa Rezwani,"https://rbioapi.moosa-r.com, https://github.com/moosa-r/rbioapi",TRUE,https://github.com/moosa-r/rbioapi,5791,6,2022-06-11T08:03:14Z,965.1666666666666
rbiom,"
    A toolkit for working with Biological Observation Matrix ('BIOM') files.
    Features include reading/writing all 'BIOM' formats, rarefaction, alpha
    diversity, beta diversity (including 'UniFrac'), summarizing counts by 
    taxonomic level, and sample subsetting. Standalone functions for 
    reading, writing, and subsetting phylogenetic trees are also provided. 
    All CPU intensive operations are encoded in C with multi-thread support.",2021-11-05,Daniel P. Smith,https://cmmr.github.io/rbiom/index.html,TRUE,https://github.com/cmmr/rbiom,9450,6,2022-05-24T05:02:39Z,1575
rbison,"Interface to the 'USGS' 'BISON' (<https://bison.usgs.gov/>)
    API, a 'database' for species occurrence data. Data comes from
    species in the United States from participating data providers. You can get
    data via 'taxonomic' and location based queries. A simple function
    is provided to help visualize data.",2020-06-08,Scott Chamberlain,"https://github.com/ropensci/rbison (devel)
https://docs.ropensci.org/rbison (docs)",TRUE,https://github.com/ropensci/rbison,105696,10,2022-05-10T13:15:56Z,10569.6
RblDataLicense,"R interface to access prices and market data with the 
    'Bloomberg Data License' service from 
    <https://www.bloomberg.com/professional/product/data-license/>. 
    As a prerequisite, a valid Data License from 'Bloomberg' is needed 
    together with the corresponding SFTP credentials and whitelisting 
    of the IP from which accessing the service. 
    This software and its author are in no way affiliated, 
    endorsed, or approved by 'Bloomberg' or any of its affiliates.
    'Bloomberg' is a registered trademark.",2021-07-29,Emanuele Guidotti,https://rbldatalicense.guidotti.dev,TRUE,https://github.com/eguidotti/rbldatalicense,14320,11,2022-01-22T17:16:41Z,1301.8181818181818
Rblpapi,An R Interface to 'Bloomberg' is provided via the 'Blp API'.,2022-01-09,Whit Armstrong,"https://dirk.eddelbuettel.com/code/rblpapi.html,
https://github.com/Rblp/Rblpapi",TRUE,https://github.com/rblp/rblpapi,60492,142,2022-07-07T15:21:06Z,426
rblt,"An R-shiny application to plot datalogger time series at a microsecond precision as Acceleration, Temperature, 
  Pressure, Light intensity from CATS, AXY-TREK LUL and WACU bio-loggers. It is possible to link behavioral labels extracted
  from 'BORIS' software <http://www.boris.unito.it> or manually written in a csv file.
  CATS bio-logger are manufactured by <http://www.cats.is>, AXY-TREK are manufactured by <http://www.technosmart.eu> and 
  LUL and WACU are manufactured by <http://www.iphc.cnrs.fr/-MIBE-.html>.",2019-12-05,Sebastien Geiger,https://github.com/sg4r/rblt,TRUE,https://github.com/sg4r/rblt,11939,1,2022-02-21T09:21:06Z,11939
rbmi,Implements reference based multiple imputation allowing for the imputation of longitudinal datasets using predefined strategies.,2022-05-18,Craig Gower-Page,"https://insightsengineering.github.io/rbmi/,
https://github.com/insightsengineering/rbmi",TRUE,https://github.com/insightsengineering/rbmi,1866,4,2022-06-15T07:41:45Z,466.5
RBNZ,"Provides a convenient way of accessing data published by the Reserve Bank of New Zealand (RBNZ) on their website, <https://www.rbnz.govt.nz/statistics>. A range of financial and economic data is provided in spreadsheet format including exchange and interest rates, commercial lending statistics, Reserve Bank market operations, financial institution statistics, household financial data, New Zealand debt security information, and economic indicators. This package provides a method to download those spreadsheets and read them directly into R.",2020-07-27,Jasper Watson,NA,TRUE,https://github.com/rntq472/rbnz,10535,0,2021-08-27T13:48:07Z,NA
rbokeh,"A native R plotting library that provides a flexible declarative interface for creating interactive web-based graphics, backed by the Bokeh visualization library <https://bokeh.pydata.org/>.",2021-08-04,Ryan Hafen,https://hafen.github.io/rbokeh/ https://github.com/bokeh/rbokeh,TRUE,https://github.com/bokeh/rbokeh,68053,303,2021-08-02T23:12:23Z,224.59735973597358
Rborist,"Scalable implementation of classification and regression forests, as described by Breiman (2001), <DOI:10.1023/A:1010933404324>.",2019-10-31,Mark Seligman,"http://www.suiji.org/arborist, https://github.com/suiji/Arborist",TRUE,https://github.com/suiji/arborist,55689,76,2022-07-08T21:39:34Z,732.75
rbw,"Residual balancing is a robust method of constructing weights for
  marginal structural models, which can be used to estimate (a) the average treatment effect in 
  a cross-sectional observational study, (b) controlled direct/mediator effects in causal mediation
  analysis, and (c) the effects of time-varying treatments in panel data (Zhou and Wodtke 2020
  <doi:10.1017/pan.2020.2>). This package provides three functions, rbwPoint(), rbwMed(), and rbwPanel(),
  that produce residual balancing weights for estimating (a), (b), (c), respectively.",2022-03-01,Xiang Zhou,https://github.com/xiangzhou09/rbw,TRUE,https://github.com/xiangzhou09/rbw,10191,7,2022-03-01T15:27:27Z,1455.857142857143
rcaiman,"Its main strength is to classify hemispherical 
    photographs of the plant canopy with algorithms specially developed for 
    such a task and well documented in 
    Díaz and Lencinas (2015) <doi:10.1109/lgrs.2015.2425931> and 
    Díaz and Lencinas (2018) <doi:10.1139/cjfr-2018-0006>. It supports 
    non-circular hemispherical photography.",2022-01-21,Gastón Mauro Díaz,NA,TRUE,https://github.com/gastonmaurodiaz/rcaiman,1498,0,2022-07-05T17:20:18Z,NA
RCarb,"Translation of the 'MATLAB' program 'Carb' (Nathan and Mauz 2008 <DOI:10.1016/j.radmeas.2007.12.012>; Mauz and Hoffmann 2014) for dose rate modelling for carbonate-rich samples in the context of trapped charged dating (e.g., luminescence dating) applications. ",2022-02-20,Sebastian Kreutzer,https://r-lum.github.io/RCarb/,TRUE,https://github.com/r-lum/rcarb,19461,0,2022-05-09T09:17:20Z,NA
rcarbon,"Enables the calibration and analysis of radiocarbon dates, often but not exclusively for the purposes of archaeological research. It includes functions not only for basic calibration, uncalibration, and plotting of one or more dates, but also a statistical framework for building demographic and related longitudinal inferences from aggregate radiocarbon date lists, including: Monte-Carlo simulation test (Timpson et al 2014 <doi:10.1016/j.jas.2014.08.011>), random mark permutation test (Crema et al 2016 <doi:10.1371/journal.pone.0154809>) and spatial permutation tests (Crema, Bevan, and Shennan 2017 <doi:10.1016/j.jas.2017.09.007>).  ",2022-02-17,Andrew Bevan,https://github.com/ahb108/rcarbon/,TRUE,https://github.com/ahb108/rcarbon,23391,32,2022-07-05T12:42:46Z,730.96875
Rcatch22,"Calculate 22 summary statistics coded in C on time-series vectors to enable 
    pattern detection, classification, and regression applications in the 
    feature space as proposed by Lubba et al. (2019) <doi:10.1007/s10618-019-00647-x>.",2022-06-03,Trent Henderson,NA,TRUE,https://github.com/hendersontrent/rcatch22,6359,17,2022-06-14T10:46:36Z,374.05882352941177
rccola,"The handling of an API key (misnomer for password) for protected
    data can be difficult. This package provides secure convenience functions for 
    entering / handling API keys and pulling data directly into memory. By default
    it will load from REDCap instances, but other sources are injectable via
    inversion of control.",2022-01-20,Shawn Garbett,https://github.com/spgarbet/rccola,TRUE,https://github.com/spgarbet/rccola,1594,1,2022-01-18T14:42:42Z,1594
rcdd,"R interface to (some of) cddlib
    (<https://github.com/cddlib/cddlib>).
    Converts back and forth between two representations of a convex polytope:
    as solution of a set of linear equalities and inequalities and as
    convex hull of set of points and rays.
    Also does linear programming and redundant generator elimination
    (for example, convex hull in n dimensions).  All functions can use exact
    infinite-precision rational arithmetic.",2021-11-18,Charles J. Geyer,"https://www.stat.umn.edu/geyer/rcdd/,
https://github.com/cjgeyer/rcdd",TRUE,https://github.com/cjgeyer/rcdd,122062,1,2021-10-19T17:47:33Z,122062
RCDT,"Performs 2D Delaunay triangulation, constrained or unconstrained, with the help of the C++ library 'CDT'. A function to plot the triangulation is provided. The constrained Delaunay triangulation has applications in geographic information systems.",2022-04-06,Stéphane Laurent,https://github.com/stla/RCDT,TRUE,https://github.com/stla/rcdt,1158,2,2022-04-11T09:54:00Z,579
rcheology,Provides a dataset of functions in all base packages of R versions 1.0.1 onwards.,2022-06-28,David Hugh-Jones,https://github.com/hughjonesd/rcheology,TRUE,https://github.com/hughjonesd/rcheology,23930,32,2022-06-28T01:15:13Z,747.8125
RChest,"Provides algorithms to locate multiple
    distributional change-points in piecewise stationary time series. The
    algorithms are provably consistent, even in the presence of long-range
    dependencies. Knowledge of the number of change-points is not
    required. The code is written in Go and interfaced with R.",2021-02-13,Lukas Zierahn,https://github.com/azalk/GoChest,TRUE,https://github.com/azalk/gochest,5047,2,2021-10-31T11:48:59Z,2523.5
Rchoice,"An implementation of simulated maximum likelihood method for the estimation of Binary (Probit and Logit), Ordered (Probit and Logit) and Poisson models with random parameters for cross-sectional and longitudinal data as presented in Sarrias (2016) <doi:10.18637/jss.v074.i10>.",2022-04-20,Mauricio Sarrias,https://github.com/mauricio1986/Rchoice,TRUE,https://github.com/mauricio1986/rchoice,33754,0,2022-04-20T22:04:12Z,NA
RCircos,"A simple and flexible way to generate Circos 2D track plot images for genomic data visualization is implemented in this package. The types of plots include: heatmap, histogram, lines, scatterplot, tiles and plot items for further decorations include connector, link (lines and ribbons), and text (gene) label. All functions require only R graphics package that comes with R base installation.  ",2021-12-19,Hongen Zhang,https://github.com/hzhanghenry/RCircos,TRUE,https://github.com/hzhanghenry/rcircos,47590,1,2021-12-19T18:12:32Z,47590
rcites,A programmatic interface to the Species+ <https://speciesplus.net/> database via the Species+/CITES Checklist API <https://api.speciesplus.net/>.,2021-11-04,Kevin Cazelles,"https://docs.ropensci.org/rcites/,
https://github.com/ropensci/rcites",TRUE,https://github.com/ropensci/rcites,12342,11,2021-11-05T02:32:17Z,1122
RClickhouse,"'Yandex Clickhouse' (<https://clickhouse.com/>) is a high-performance relational column-store database to enable
    big data exploration and 'analytics' scaling to petabytes of data. Methods are
    provided that enable working with 'Yandex Clickhouse' databases via
    'DBI' methods and using 'dplyr'/'dbplyr' idioms.",2022-06-12,Christian Hotz-Behofsits,https://github.com/IMSMWU/RClickhouse,TRUE,https://github.com/imsmwu/rclickhouse,20447,75,2022-06-12T18:55:50Z,272.62666666666667
rclipboard,"Leverages the functionality of 'clipboard.js', a JavaScript library
    for HMTL5-based copy to clipboard from web pages (see <https://clipboardjs.com>
    for more information), and provides a reactive copy-to-clipboard UI button 
    component, called 'rclipButton', and a a reactive copy-to-clipboard UI link 
    component, called 'rclipLink', for 'shiny' R applications.",2022-02-02,Sebastien Bihorel,https://github.com/sbihorel/rclipboard/,TRUE,https://github.com/sbihorel/rclipboard,50189,34,2022-02-02T11:44:18Z,1476.1470588235295
RcmdrPlugin.NMBU,"An R Commander ""plug-in"" extending functionality of linear models
    and providing an interface to Partial Least Squares Regression and Linear and
    Quadratic Discriminant analysis. Several statistical summaries are extended,
    predictions are offered for additional types of analyses, and extra plots, tests
    and mixed models are available.",2022-01-04,Kristian Hovde Liland,https://github.com/khliland/RcmdrPlugin.NMBU/,TRUE,https://github.com/khliland/rcmdrplugin.nmbu,33441,0,2021-12-28T11:21:15Z,NA
rCNV,"Functions in this package will import filtered variant call format (VCF) files of SNPs data and generate data sets to detect copy number variants, visualize them and do downstream analyses with copy number variants(e.g. Environmental association analyses).",2022-04-06,Piyal Karunarathne,https://piyalkarum.github.io/rCNV/,TRUE,https://github.com/piyalkarum/rcnv,760,2,2022-07-07T13:57:31Z,380
rco,"Automatically apply different strategies to optimize R code. 
    'rco' functions take R code as input, and returns R code as output.",2021-04-17,Juan Cruz Rodriguez,https://jcrodriguez1989.github.io/rco/,TRUE,https://github.com/jcrodriguez1989/rco,9593,61,2021-07-14T12:28:16Z,157.2622950819672
Rcompadre,Utility functions for interacting with the 'COMPADRE' and 'COMADRE' databases of matrix population models. Described in Jones et al. (2021) <doi:10.1101/2021.04.26.441330>.,2021-10-15,Roberto Salguero-Gomez,https://github.com/jonesor/Rcompadre,TRUE,https://github.com/jonesor/rcompadre,7306,9,2021-10-15T19:41:33Z,811.7777777777778
rcompendium,"Makes easier the creation of R package or research compendium 
    (i.e. a predefined files/folders structure) so that users can focus on the 
    code/analysis instead of wasting time organizing files. A full 
    ready-to-work structure is set up with some additional features: version 
    control, remote repository creation, CI/CD configuration (check package 
    integrity under several OS, test code with 'testthat', and build and deploy 
    website using 'pkgdown'). This package heavily relies on the R packages 
    'devtools' and 'usethis' and follows recommendations made by Wickham H. 
    (2015) <ISBN:9781491910597> and Marwick B. et al. (2018) 
    <doi:10.7287/peerj.preprints.3192v2>.",2022-04-06,Nicolas Casajus,"https://github.com/FRBCesab/rcompendium,
https://frbcesab.github.io/rcompendium/",TRUE,https://github.com/frbcesab/rcompendium,6395,18,2022-04-07T09:14:47Z,355.27777777777777
rconfig,"Configuration management using files (JSON, YAML, separated text),
  JSON strings, and command line arguments. Command line arguments
  can be used to override configuration. Period-separated command line
  flags are parsed as hierarchical lists.",2022-06-22,Peter Solymos,https://github.com/analythium/rconfig,TRUE,https://github.com/analythium/rconfig,1442,9,2022-07-09T01:17:53Z,160.22222222222223
RConics,"Solve some conic related problems (intersection of conics with lines and conics, arc length of an ellipse, polar lines, etc.). ",2022-03-11,Emanuel Huber,https://github.com/emanuelhuber/RConics,TRUE,https://github.com/emanuelhuber/rconics,24660,0,2022-05-09T17:49:51Z,NA
Rcpp,"The 'Rcpp' package provides R functions as well as C++ classes which
 offer a seamless integration of R and C++. Many R data types and objects can be
 mapped back and forth to C++ equivalents which facilitates both writing of new
 code as well as easier integration of third-party libraries. Documentation
 about 'Rcpp' is provided by several vignettes included in this package, via the
 'Rcpp Gallery' site at <https://gallery.rcpp.org>, the paper by Eddelbuettel and
 Francois (2011, <doi:10.18637/jss.v040.i08>), the book by Eddelbuettel (2013,
 <doi:10.1007/978-1-4614-6868-4>) and the paper by Eddelbuettel and Balamuta (2018,
 <doi:10.1080/00031305.2017.1375990>); see 'citation(""Rcpp"")' for details.",2022-07-08,Dirk Eddelbuettel,"https://www.rcpp.org,
https://dirk.eddelbuettel.com/code/rcpp.html,
https://github.com/RcppCore/Rcpp",TRUE,https://github.com/rcppcore/rcpp,28799935,647,2022-07-10T14:55:09Z,44513.037094281295
RcppAlgos,"Provides optimized functions and flexible combinatorial iterators
    implemented in C++ for solving problems in combinatorics and
    computational mathematics. Utilizes the RMatrix class from 'RcppParallel'
    for thread safety. There are combination/permutation functions with
    constraint parameters that allow for generation of all results of a vector
    meeting specific criteria (e.g. generating integer partitions
    or finding all combinations such that the sum is between two bounds).
    Capable of generating specific combinations/permutations (e.g. retrieve
    only the nth lexicographical result) which sets up nicely for
    parallelization as well as random sampling. Gmp support permits exploration
    where the total number of results is large (e.g. comboSample(10000, 500,
    n = 4)). Additionally, there are several high performance number theoretic
    functions that are useful for problems common in computational mathematics.
    Some of these functions make use of the fast integer division library
    'libdivide'. The primeSieve function is based on the segmented sieve of
    Eratosthenes implementation by Kim Walisch. It is also efficient for large
    numbers by using the cache friendly improvements originally developed by
    Tomás Oliveira. Finally, there is a prime counting function that implements
    Legendre's formula based on the work of Kim Walisch.",2022-03-31,Joseph Wood,"https://github.com/jwood000/RcppAlgos, https://gmplib.org/,
https://github.com/kimwalisch/primesieve, http://libdivide.com,
https://github.com/kimwalisch/primecount,
http://ridiculousfish.com/,
http://sweet.ua.pt/tos/software/prime_sieve.html",TRUE,https://github.com/jwood000/rcppalgos,35662,33,2022-05-10T01:42:07Z,1080.6666666666667
RcppAnnoy,"'Annoy' is a small C++ library for Approximate Nearest Neighbors 
 written for efficient memory usage as well an ability to load from / save to
 disk. This package provides an R interface by relying on the 'Rcpp' package,
 exposing the same interface as the original Python wrapper to 'Annoy'. See
 <https://github.com/spotify/annoy> for more on 'Annoy'. 'Annoy' is released
 under Version 2.0 of the Apache License. Also included is a small Windows
 port of 'mmap' which is released under the MIT license.",2021-07-30,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppannoy,
https://dirk.eddelbuettel.com/code/rcpp.annoy.html",TRUE,https://github.com/eddelbuettel/rcppannoy,487476,59,2021-12-01T01:34:39Z,8262.305084745763
RcppAPT,"The 'APT Package Management System' provides Debian and
 Debian-derived Linux systems with a powerful system to resolve package
 dependencies. This package offers access directly from R.  This can
 only work on a system with a suitable 'libapt-pkg-dev' installation
 so functionality is curtailed if such a library is not found.",2022-05-25,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppapt,
https://dirk.eddelbuettel.com/code/rcpp.apt.html",TRUE,https://github.com/eddelbuettel/rcppapt,14067,8,2022-05-25T12:43:19Z,1758.375
RcppArmadillo,"'Armadillo' is a templated C++ linear algebra library (by Conrad
 Sanderson) that aims towards a good balance between speed and ease of
 use. Integer, floating point and complex numbers are supported, as
 well as a subset of trigonometric and statistics functions. Various
 matrix decompositions are provided through optional integration with
 LAPACK and ATLAS libraries.  The 'RcppArmadillo' package includes the
 header files from the templated 'Armadillo' library. Thus users do
 not need to install 'Armadillo' itself in order to use
 'RcppArmadillo'. From release 7.800.0 on, 'Armadillo' is licensed
 under Apache License 2; previous releases were under licensed as MPL
 2.0 from version 3.800.0 onwards and LGPL-3 prior to that;
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to Armadillo) is licensed
 under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.
 Armadillo requires a C++11 compiler.",2022-06-15,Dirk Eddelbuettel,"https://github.com/RcppCore/RcppArmadillo,
https://dirk.eddelbuettel.com/code/rcpp.armadillo.html",TRUE,https://github.com/rcppcore/rcpparmadillo,17164633,147,2022-07-04T16:52:26Z,116766.21088435374
RcppBDT,"Access to Boost Date_Time functionality for dates,
 durations (both for days and date time objects), time zones, and 
 posix time ('ptime') is provided by using 'Rcpp modules'. The 
 posix time implementation can support high-resolution of up to 
 nano-second  precision by using 96 bits (instead of R's 64)
 to present a 'ptime' object (but this needs recompilation with
 a #define set).",2022-03-29,Dirk Eddelbuettel and Romain Francois,"https://github.com/eddelbuettel/rcppbdt,
https://dirk.eddelbuettel.com/code/rcpp.bdt.html",TRUE,https://github.com/eddelbuettel/rcppbdt,47386,17,2022-03-29T18:45:10Z,2787.4117647058824
RcppCCTZ,"'Rcpp' Access to the 'CCTZ' timezone library is provided. 'CCTZ' is
 a C++ library for translating between absolute and civil times using the rules
 of a time zone. The 'CCTZ' source code, released under the Apache 2.0 License,
 is included in this package. See <https://github.com/google/cctz> for more
 details.",2021-12-15,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppcctz,
https://dirk.eddelbuettel.com/code/rcpp.cctz.html",TRUE,https://github.com/eddelbuettel/rcppcctz,273923,20,2021-12-15T01:20:04Z,13696.15
RcppCGAL,"Creates a header only package to link to the CGAL 
  (Computational Geometry Algorithms Library)
  header files in Rcpp. There are a variety of potential uses for 
  the software such as Hilbert sorting, KDtree nearest neighbors, 
  and convex hull algorithms. There is only one R function in this 
  package, which returns the current version of the CGAL library 
  included. For more information about how to use the header files, 
  see the CGAL documentation at <https://www.cgal.org>. Currently
  includes the CGAL 5.4 stable release.",2022-03-21,Eric Dunipace,NA,TRUE,https://github.com/ericdunipace/rcppcgal,2709,6,2022-06-23T02:52:26Z,451.5
RcppClassic,"The 'RcppClassic' package provides a deprecated C++ library which
 facilitates the integration of R and C++. New projects should use the new 'Rcpp'
 'API' in the 'Rcpp' package.",2019-12-09,Dirk Eddelbuettel and Romain Francois,NA,TRUE,https://github.com/eddelbuettel/rcppclassic,44251,1,2021-12-08T21:52:36Z,44251
RcppCNPy,"The 'cnpy' library written by Carl Rogers provides read and write
 facilities for files created with (or for) the 'NumPy' extension for 'Python'.
 Vectors and matrices of numeric types can be read or written to and from
 files as well as compressed files. Support for integer files is available if
 the package has been built with -std=c++11 which should be the default on
 all platforms since the release of R 3.3.0.",2022-03-25,Dirk Eddelbuettel and Wush Wu,"https://github.com/eddelbuettel/rcppcnpy,
https://dirk.eddelbuettel.com/code/rcpp.cnpy.html",TRUE,https://github.com/eddelbuettel/rcppcnpy,25058,23,2022-03-24T14:01:07Z,1089.4782608695652
RcppColors,"Provides 'C++' header files to deal with color conversion
    from some color spaces to hexadecimal with 'Rcpp', and exports some
    color mapping functions for usage in R. Also exports functions to
    convert colors from the 'HSLuv' color space for usage in R. 'HSLuv' is
    a human-friendly alternative to HSL.",2022-07-01,Stéphane Laurent,https://github.com/stla/RcppColors,TRUE,https://github.com/stla/rcppcolors,122,2,2022-06-30T07:40:01Z,61
RcppCWB,"'Rcpp' Bindings for the C code of the 'Corpus Workbench' ('CWB'), an indexing and query 
  engine to efficiently analyze large corpora (<https://cwb.sourceforge.io>). 'RcppCWB' is licensed
  under the GNU GPL-3, in line with the GPL-3 license of the 'CWB' (<https://www.r-project.org/Licenses/GPL-3>).
  The 'CWB' relies on 'pcre' (BSD license, see <http://www.pcre.org/licence.txt>)
  and 'GLib' (LGPL license, see <https://www.gnu.org/licenses/lgpl-3.0.en.html>).
  See the file LICENSE.note for further information. The package includes modified code of the
  'rcqp' package (GPL-2, see <https://cran.r-project.org/package=rcqp>). The original work of the authors
  of the 'rcqp' package is acknowledged with great respect, and they are listed as authors of this
  package. To achieve cross-platform portability (including Windows), using 'Rcpp' for wrapper code
  is the approach used by 'RcppCWB'.",2022-05-19,Andreas Blaette,https://github.com/PolMine/RcppCWB,TRUE,https://github.com/polmine/rcppcwb,21513,1,2022-05-18T22:06:28Z,21513
RcppDate,"A header-only C++ library is provided with support
 for dates, time zones, ISO weeks, Julian dates, and Islamic dates.
 'date' offers extensive date and time functionality for the C++11,
 C++14 and C++17 standards and was written by Howard Hinnant and released 
 under the MIT license. A slightly modified version has been accepted
 (along with 'tz.h') as part of C++20. This package regroups all
 header files from the upstream repository by Howard Hinnant so that
 other R packages can use them in their C++ code. At present, few of
 the types have explicit 'Rcpp' wrappers though these may be added as
 needed. ",2021-05-19,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppdate,
https://dirk.eddelbuettel.com/code/rcpp.date.html",TRUE,https://github.com/eddelbuettel/rcppdate,164183,11,2021-12-09T03:50:16Z,14925.727272727272
RcppDynProg,Dynamic Programming implemented in 'Rcpp'.  Includes example partition and out of sample fitting applications.  Also supplies additional custom coders for the 'vtreat' package.,2020-12-15,John Mount,"https://github.com/WinVector/RcppDynProg/,
https://winvector.github.io/RcppDynProg/",TRUE,https://github.com/winvector/rcppdynprog,14318,13,2022-01-26T17:13:26Z,1101.3846153846155
RcppEigen,"R and 'Eigen' integration using 'Rcpp'.
 'Eigen' is a C++ template library for linear algebra: matrices, vectors,
 numerical solvers and related algorithms.  It supports dense and sparse
 matrices on integer, floating point and complex numbers, decompositions of
 such matrices, and solutions of linear systems. Its performance on many
 algorithms is comparable with some of the best implementations based on
 'Lapack' and level-3 'BLAS'. The 'RcppEigen' package includes the header
 files from the 'Eigen' C++ template library (currently version 3.3.4). Thus
 users do not need to install 'Eigen' itself in order to use 'RcppEigen'.
 Since version 3.1.1, 'Eigen' is licensed under the Mozilla Public License
 (version 2); earlier version were licensed under the GNU LGPL version 3 or
 later. 'RcppEigen' (the 'Rcpp' bindings/bridge to 'Eigen') is licensed under
 the GNU GPL version 2 or later, as is the rest of 'Rcpp'.",2022-04-08,Douglas Bates,"https://github.com/RcppCore/RcppEigen,
https://dirk.eddelbuettel.com/code/rcpp.eigen.html",TRUE,https://github.com/rcppcore/rcppeigen,12309113,80,2022-04-08T16:12:31Z,153863.9125
RcppEnsmallen,"'Ensmallen' is a templated C++ mathematical optimization library 
 (by the 'MLPACK' team) that provides a simple set of abstractions for writing an
 objective function to optimize. Provided within are various standard and
 cutting-edge optimizers that include full-batch gradient descent techniques, 
 small-batch techniques, gradient-free optimizers, and constrained optimization.
 The 'RcppEnsmallen' package includes the header files from the 'Ensmallen' library
 and pairs the appropriate header files from 'armadillo' through the 
 'RcppArmadillo' package. Therefore, users do not need to install 'Ensmallen' nor
 'Armadillo' to use 'RcppEnsmallen'. Note that 'Ensmallen' is licensed under 
 3-Clause BSD, 'Armadillo' starting from 7.800.0 is licensed under Apache License 2,
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to 'Armadillo') is licensed under 
 the GNU GPL version 2 or later. Thus, 'RcppEnsmallen' is also licensed under
 similar terms. Note that 'Ensmallen' requires a compiler that supports 
 'C++11' and 'Armadillo' 9.800 or later.",2022-04-11,James Joseph Balamuta,"https://github.com/coatless-rpkg/rcppensmallen,
https://github.com/mlpack/ensmallen, http://ensmallen.org/",TRUE,https://github.com/coatless-rpkg/rcppensmallen,29092,28,2022-04-11T16:31:18Z,1039
RcppExamples,"Examples for Seamless R and C++ integration
 The 'Rcpp' package contains a C++ library that facilitates the integration of
 R and C++ in various ways. This package provides some usage examples.
 Note that the documentation in this package currently does not cover all the
 features in the package. The site <http://gallery.rcpp.org> regroups a large
 number of examples for 'Rcpp'.",2019-08-24,Dirk Eddelbuettel and Romain Francois,http://dirk.eddelbuettel.com/code/rcpp.examples.html,TRUE,https://github.com/eddelbuettel/rcppexamples,16427,40,2021-12-10T22:00:38Z,410.675
RcppFarmHash,"The Google 'FarmHash' family of hash functions is used by
 the Google 'BigQuery' data warehouse via the 'FARM_FINGERPRINT'
 function. This package permits to calculate these hash digest
 fingerprints directly from R, and uses the included 'FarmHash'
 files written by G. Pike and copyrighted by Google, Inc.",2021-08-02,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppfarmhash/,
https://dirk.eddelbuettel.com/code/rcpp.farmhash.html",TRUE,https://github.com/eddelbuettel/rcppfarmhash,3745,1,2021-12-10T22:36:52Z,3745
RcppFastFloat,"Converting ascii text into (floating-point) numeric values is a
 very common problem. The 'fast_float' header-only C++ library by Daniel Lemire
 does it very well and very fast at up to or over to 1 gigabyte per second as
 described in more detail in <arXiv:2101.11408>. 'fast_float' is licensed under
 the Apache 2.0 license and provided here for use by other R packages via a simple
 'LinkingTo:' statement.",2021-08-21,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppfastfloat/,
https://dirk.eddelbuettel.com/code/rcpp.fastfloat.html",TRUE,https://github.com/eddelbuettel/rcppfastfloat,6293,18,2021-08-21T13:15:01Z,349.6111111111111
RcppGetconf,"The 'getconf' command-line tool provided by 'libc' allows
 querying of a large number of system variables. This package provides
 similar functionality.",2018-11-16,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.getconf.html,TRUE,https://github.com/eddelbuettel/rcppgetconf,9259,1,2021-12-17T23:46:29Z,9259
RcppGreedySetCover,A fast implementation of the greedy algorithm for the set cover problem using 'Rcpp'.,2018-01-24,Matthias Kaeding,http://github.com/matthiaskaeding/RcppGreedySetCover,TRUE,https://github.com/matthiaskaeding/rcppgreedysetcover,10700,3,2022-04-21T16:37:10Z,3566.6666666666665
RcppGSL,"'Rcpp' integration for 'GNU GSL' vectors and matrices
 The 'GNU Scientific Library' (or 'GSL') is a collection of numerical routines for
 scientific computing. It is particularly useful for C and C++ programs as it
 provides a standard C interface to a wide range of mathematical routines. There
 are over 1000 functions in total with an extensive test suite. The 'RcppGSL'
 package provides an easy-to-use interface between 'GSL' data structures and
 R using concepts from 'Rcpp' which is itself a package that eases the
 interfaces between R and C++. This package also serves as a prime example of
 how to build a package that uses 'Rcpp' to connect to another third-party
 library. The 'autoconf' script, 'inline' plugin and example package can all
 be used as a stanza to  write a similar package against another library.",2022-03-12,Dirk Eddelbuettel and Romain Francois,"https://github.com/eddelbuettel/rcppgsl,
https://dirk.eddelbuettel.com/code/rcpp.gsl.html",TRUE,https://github.com/eddelbuettel/rcppgsl,517406,29,2022-03-12T15:30:05Z,17841.58620689655
RcppHNSW,"'Hnswlib' is a C++ library for Approximate Nearest Neighbors. This 
 package provides a minimal R interface by relying on the 'Rcpp' package. See 
 <https://github.com/nmslib/hnswlib> for more on 'hnswlib'. 'hnswlib' is 
 released under Version 2.0 of the Apache License.",2020-09-06,James Melville,https://github.com/jlmelville/rcpphnsw,TRUE,https://github.com/jlmelville/rcpphnsw,172831,28,2022-07-05T05:41:07Z,6172.535714285715
RcppHungarian,"Header library and R functions to solve minimum cost bipartite matching problem 
 using Huhn-Munkres algorithm (Hungarian algorithm; <https://en.wikipedia.org/wiki/Hungarian_algorithm>;
 Kuhn (1955) <doi:10.1002/nav.3800020109>). 
 This is a repackaging of code written by Cong Ma in the GitHub repo <https://github.com/mcximing/hungarian-algorithm-cpp>.",2022-01-26,Justin Silverman,https://github.com/jsilve24/RcppHungarian,TRUE,https://github.com/jsilve24/rcpphungarian,12389,1,2022-01-26T16:37:32Z,12389
RcppML,"Fast machine learning algorithms including matrix factorization 
    and divisive clustering for large sparse and dense matrices.",2021-09-21,Zachary DeBruine,https://github.com/zdebruine/RcppML,TRUE,https://github.com/zdebruine/rcppml,10911,37,2022-06-24T13:09:01Z,294.8918918918919
RcppMsgPack,"'MsgPack' header files are provided for use by R packages, along 
 with the ability to access, create and alter 'MsgPack' objects directly from R.
 'MsgPack' is an efficient binary serialization format. It lets you exchange
 data among multiple languages like 'JSON' but it is faster and smaller.
 Small integers are encoded into a single byte, and typical short strings
 require only one extra byte in addition to the strings themselves. This
 package provides headers from the 'msgpack-c' implementation for C and
 C++(11) for use by R, particularly 'Rcpp'. The included 'msgpack-c' headers
 are licensed under the Boost Software License (Version 1.0); the code added
 by this package as well the R integration are licensed under the GPL (>= 2).
 See the files 'COPYRIGHTS' and 'AUTHORS' for a full list of  copyright holders
 and contributors to 'msgpack-c'.  ",2018-11-18,Travers Ching and Dirk Eddelbuettel; the authors and contributors of MsgPack,NA,TRUE,https://github.com/eddelbuettel/rcppmsgpack,15842,17,2021-12-19T01:50:51Z,931.8823529411765
RcppParallel,"High level functions for parallel programming with 'Rcpp'.
    For example, the 'parallelFor()' function can be used to convert the work of
    a standard serial ""for"" loop into a parallel one and the 'parallelReduce()'
    function can be used for accumulating aggregate or other values.",2022-01-05,Kevin Ushey,"https://rcppcore.github.io/RcppParallel/,
https://github.com/RcppCore/RcppParallel",TRUE,https://github.com/rcppcore/rcppparallel,4023509,152,2022-04-29T19:52:52Z,26470.45394736842
RcppQuantuccia,"'QuantLib' bindings are provided for R using 'Rcpp' via an updated
 variant of the header-only 'Quantuccia' project (put together initially by Peter
 Caspers) offering an essential subset of 'QuantLib' (and now maintained separately
 for the calendaring subset). See the included file 'AUTHORS' for a full list of
 contributors to both 'QuantLib' and 'Quantuccia'.",2021-10-30,Dirk Eddelbuettel; the authors and contributors of QuantLib,"https://github.com/eddelbuettel/rcppquantuccia,
https://dirk.eddelbuettel.com/code/rcpp.quantuccia.html",TRUE,https://github.com/eddelbuettel/rcppquantuccia,18187,10,2021-12-19T01:54:05Z,1818.7
RcppRedis,"Connection to the 'Redis' key/value store using the
 C-language client library 'hiredis' (included as a fallback) with
 'MsgPack' encoding provided via 'RcppMsgPack' headers. It now also
 includes the pub/sub functions from the 'rredis' package.",2022-04-09,Dirk Eddelbuettel and Bryan W. Lewis,"https://github.com/eddelbuettel/rcppredis,
https://dirk.eddelbuettel.com/code/rcpp.redis.html",TRUE,https://github.com/eddelbuettel/rcppredis,20366,46,2022-04-14T12:13:49Z,442.7391304347826
RcppSimdJson,"The 'JSON' format is ubiquitous for data interchange, and the
 'simdjson' library written by Daniel Lemire (and many contributors) provides 
 a high-performance parser for these files which by relying on parallel 'SIMD'
 instruction manages to parse these files as faster than disk speed. See the
 <arXiv:1902.08318> paper for more details about 'simdjson'.  This package 
 parses 'JSON' from string, file, or remote URLs under a variety of settings.",2022-02-18,Dirk Eddelbuettel,https://github.com/eddelbuettel/rcppsimdjson/,TRUE,https://github.com/eddelbuettel/rcppsimdjson,63683,99,2022-02-19T00:23:29Z,643.2626262626262
RcppSMC,"R access to the Sequential Monte Carlo Template Classes
 by Johansen <doi:10.18637/jss.v030.i06> is provided. At present, four
 additional examples have been added, and the first example from the JSS
 paper has been extended. Further integration and extensions are planned.",2021-12-18,Dirk Eddelbuettel,"https://github.com/rcppsmc/rcppsmc,
https://dirk.eddelbuettel.com/code/rcpp.smc.html",TRUE,https://github.com/rcppsmc/rcppsmc,19048,23,2022-06-14T16:21:45Z,828.1739130434783
RcppSpdlog,"The mature and widely-used C++ logging library 'spdlog' by Gabi Melman provides
 many desirable features. This package bundles these header files for easy use by R packages
 via a simple 'LinkingTo:' inclusion.",2022-04-04,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rcppspdlog,
https://dirk.eddelbuettel.com/code/rcpp.spdlog.html",TRUE,https://github.com/eddelbuettel/rcppspdlog,19604,10,2022-04-04T23:10:39Z,1960.4
RcppStreams,"The 'Streamulus' (template, header-only) library by
 Irit Katriel (at <https://github.com/iritkatriel/streamulus>)
 provides a very powerful yet convenient framework for stream
 processing. This package connects 'Streamulus' to R by providing 
 both the header files and all examples.",2019-02-25,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.streams.html,TRUE,https://github.com/eddelbuettel/rcppstreams,13740,15,2021-12-19T23:56:00Z,916
RcppThread,"Provides a C++11-style thread class and thread pool that can safely
    be interrupted from R. See Nagler (2021) <doi:10.18637/jss.v097.c01>.",2022-03-17,Thomas Nagler,https://github.com/tnagler/RcppThread,TRUE,https://github.com/tnagler/rcppthread,176260,43,2022-03-16T18:24:01Z,4099.069767441861
RcppTOML,"The configuration format defined by 'TOML' (which expands to
 ""Tom's Obvious Markup Language"") specifies an excellent format
 (described at <https://toml.io/en/>) suitable for both human editing
 as well as the common uses of a machine-readable format. This package
 uses 'Rcpp' to connect the 'cpptoml' parser written by Chase Geigle
 (in C++11) to R.",2020-12-02,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.toml.html,TRUE,https://github.com/eddelbuettel/rcpptoml,1507176,23,2021-12-19T23:56:57Z,65529.391304347824
RcppXPtrUtils,"Provides the means to compile user-supplied C++ functions with
  'Rcpp' and retrieve an 'XPtr' that can be passed to other C++ components.",2022-05-24,Iñaki Ucar,https://github.com/Enchufa2/RcppXPtrUtils,TRUE,https://github.com/enchufa2/rcppxptrutils,20012,17,2022-05-22T12:25:31Z,1177.1764705882354
rcrossref,"Client for various 'CrossRef' 'APIs', including 'metadata' search
    with their old and newer search 'APIs', get 'citations' in various formats
    (including 'bibtex', 'citeproc-json', 'rdf-xml', etc.), convert 'DOIs'
    to 'PMIDs', and 'vice versa', get citations for 'DOIs', and get links to
    full text of articles when available.",2020-10-02,Scott Chamberlain,"https://docs.ropensci.org/rcrossref/,
https://github.com/ropensci/rcrossref",TRUE,https://github.com/ropensci/rcrossref,43297,148,2021-08-19T07:03:04Z,292.5472972972973
RCzechia,Administrative regions and other spatial objects of the Czech Republic.,2022-05-14,Jindra Lacko,https://github.com/jlacko/RCzechia,TRUE,https://github.com/jlacko/rczechia,26431,18,2022-06-03T15:33:42Z,1468.388888888889
Rd2roxygen,"Functions to convert Rd to 'roxygen' documentation. It can parse an
    Rd file to a list, create the 'roxygen' documentation and update the original
    R script (e.g. the one containing the definition of the function)
    accordingly. This package also provides utilities that can help developers
    build packages using 'roxygen' more easily. The 'formatR' package can be used
    to reformat the R code in the examples sections so that the code will be
    more readable.",2022-03-02,Yihui Xie,https://github.com/yihui/Rd2roxygen,TRUE,https://github.com/yihui/rd2roxygen,49694,23,2022-03-02T22:10:34Z,2160.608695652174
rdacca.hp,"This function conducts variation partitioning and hierarchical partitioning to calculate the unique, shared (referred as to ""common"") and individual contributions of each predictor (or matrix) towards explained variation (R-square and adjusted R-square) on canonical analysis (RDA,CCA and db-RDA), applying the algorithm of Lai J.,Zou Y., Zhang J.,Peres-Neto P.(2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution,13: 782-788 <DOI:10.1111/2041-210X.13800>. ",2022-04-05,Jiangshan Lai,https://github.com/laijiangshan/rdacca.hp,TRUE,https://github.com/laijiangshan/rdacca.hp,13700,12,2022-04-05T14:07:33Z,1141.6666666666667
rDataPipeline,"R implementation of the 'FAIR Data Pipeline API'. The 'FAIR Data 
    Pipeline' is intended to enable tracking of provenance of FAIR (findable, 
    accessible and interoperable) data used in epidemiological modelling.",2021-11-17,Sonia Mitchell,"https://www.fairdatapipeline.org/rDataPipeline/,
https://github.com/FAIRDataPipeline/rDataPipeline",TRUE,https://github.com/fairdatapipeline/rdatapipeline,2038,4,2022-01-31T01:15:10Z,509.5
rdataretriever,"Provides an R interface to the Data Retriever
    <https://retriever.readthedocs.io/en/latest/> via the Data Retriever's
    command line interface. The Data Retriever automates the
    tasks of finding, downloading, and cleaning public datasets,
    and then stores them in a local database.",2022-05-18,Henry Senyondo,"https://docs.ropensci.org/rdataretriever/ (website),
https://github.com/ropensci/rdataretriever/",TRUE,https://github.com/ropensci/rdataretriever,15247,40,2022-05-14T03:54:23Z,381.175
rddtools,"Set of functions for Regression Discontinuity Design ('RDD'), for
    data visualisation, estimation and testing.",2022-01-10,Matthieu Stigler,https://qua.st/rddtools/,TRUE,https://github.com/bquast/rddtools,20459,11,2022-06-20T06:50:25Z,1859.909090909091
rdflib,"The Resource Description Framework, or 'RDF' is a widely used
             data representation model that forms the cornerstone of the 
             Semantic Web. 'RDF' represents data as a graph rather than 
             the familiar data table or rectangle of relational databases.
             The 'rdflib' package provides a friendly and concise user interface
             for performing common tasks on 'RDF' data, such as reading, writing
             and converting between the various serializations of 'RDF' data,
             including 'rdfxml', 'turtle', 'nquads', 'ntriples', and 'json-ld';
             creating new 'RDF' graphs, and performing graph queries using 'SPARQL'.
             This package wraps the low level 'redland' R package which
             provides direct bindings to the 'redland' C library.  Additionally,
             the package supports the newer and more developer friendly
             'JSON-LD' format through the 'jsonld' package. The package
             interface takes inspiration from the Python 'rdflib' library.",2022-02-09,Carl Boettiger,https://github.com/ropensci/rdflib,TRUE,https://github.com/ropensci/rdflib,24911,42,2022-05-27T19:41:50Z,593.1190476190476
rdhs,"Provides a client for (1) querying the DHS API for survey indicators
  and metadata (<https://api.dhsprogram.com/#/index.html>), (2) identifying surveys
  and datasets for analysis, (3) downloading survey datasets from the DHS website,
  (4) loading datasets and associate metadata into R, and (5) extracting variables
  and combining datasets for pooled analysis.",2021-07-19,OJ Watson,https://docs.ropensci.org/rdhs/,TRUE,https://github.com/ropensci/rdhs,18408,26,2022-05-09T23:02:31Z,708
RDieHarder,"The 'RDieHarder' package provides an R interface to 
 the 'DieHarder' suite of random number generators and tests that 
 was developed by Robert G. Brown and David Bauer, extending 
 earlier work by George Marsaglia and others. The 'DieHarder'
 library code is included.",2021-12-14,Dirk Eddelbuettel,https://github.com/eddelbuettel/rdieharder,TRUE,https://github.com/eddelbuettel/rdieharder,16512,6,2021-12-23T23:54:27Z,2752
Rdimtools,"We provide linear and nonlinear dimension reduction techniques.
	Intrinsic dimension estimation methods for exploratory analysis are also provided.
	For more details on the package, see the paper by You (2020) <arXiv:2005.11107>.",2022-02-04,Kisung You,https://kisungyou.com/Rdimtools/,TRUE,https://github.com/kisungyou/rdimtools,45198,36,2022-07-06T16:15:50Z,1255.5
rdiversity,"Provides a framework for the measurement and partitioning of
    the (similarity-sensitive) biodiversity of a metacommunity and its
    constituent subcommunities. Richard Reeve, et al. (2016) 
    <arXiv:1404.6520v3>.",2022-05-06,Sonia Mitchell,https://github.com/boydorr/rdiversity,TRUE,https://github.com/boydorr/rdiversity,15181,4,2022-05-05T23:27:20Z,3795.25
RDML,"Imports real-time thermo cycler (qPCR) data from Real-time PCR
    Data Markup Language (RDML) and transforms to the appropriate formats of
    the 'qpcR' and 'chipPCR' packages. Contains a dendrogram visualization 
    for the structure of RDML object and GUI for RDML editing.",2019-06-25,Konstantin A. Blagodatskikh,https://github.com/kablag/RDML,TRUE,https://github.com/kablag/rdml,17105,19,2022-06-30T13:44:41Z,900.2631578947369
rdnb,"A wrapper for the 'Deutsche Nationalbibliothek (German National
    Library) API', available at <https://www.dnb.de/EN/Home/home_node.html>. 
    The German National Library is the German central archival library, 
    collecting, archiving, bibliographically classifying all German and 
    German-language publications, foreign publications about Germany, 
    translations of German works, and the works of German-speaking emigrants 
    published abroad between 1933 and 1945.",2022-05-12,Christian Graul,https://github.com/chgrl/rdnb,TRUE,https://github.com/chgrl/rdnb,14787,1,2022-05-12T19:55:51Z,14787
RDP,"Pretty fast implementation of the Ramer-Douglas-Peucker algorithm for reducing the number of points on a 2D curve.
    Urs Ramer (1972), ""An iterative procedure for the polygonal approximation of plane curves"" <doi:10.1016/S0146-664X(72)80017-0>.
    David H. Douglas and Thomas K. Peucker (1973), ""Algorithms for the Reduction of the Number of Points Required to Represent a Digitized Line or its Caricature"" <doi:10.3138/FM57-6770-U75U-7727>.",2022-03-17,Robert Dahl Jacobsen,https://github.com/robertdj/RDP,TRUE,https://github.com/robertdj/rdp,4749,3,2022-03-24T09:01:47Z,1583
Rdpack,"Functions for manipulation of R documentation objects,
    including functions reprompt() and ereprompt() for updating 'Rd'
    documentation for functions, methods and classes; 'Rd' macros for
    citations and import of references from 'bibtex' files for use in
    'Rd' files and 'roxygen2' comments; 'Rd' macros for evaluating and
    inserting snippets of 'R' code and the results of its evaluation or
    creating graphics on the fly; and many functions for manipulation of
    references and Rd files.",2022-06-07,Georgi N. Boshnakov,"https://geobosh.github.io/Rdpack/ (doc),
https://github.com/GeoBosh/Rdpack (devel)",TRUE,https://github.com/geobosh/rdpack,1987536,18,2022-06-16T13:11:05Z,110418.66666666667
rdrop2,"Provides full programmatic access to the 'Dropbox' file hosting platform <https://dropbox.com>, including support for all standard file operations.",2020-08-05,Karthik Ram,NA,TRUE,https://github.com/karthik/rdrop2,90163,235,2022-06-03T15:47:16Z,383.6723404255319
rdryad,"Interface to the Dryad ""Solr"" API, their ""OAI-PMH"" service, and
    fetch datasets. Dryad (<https://datadryad.org/>) is a curated host of
    data underlying scientific publications.",2020-06-25,Karthik Ram,"https://docs.ropensci.org/rdryad,
https://github.com/ropensci/rdryad",TRUE,https://github.com/ropensci/rdryad,17629,24,2022-06-08T08:45:29Z,734.5416666666666
rdwd,"Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see 
             <https://www.dwd.de/EN/climate_environment/cdc/cdc_node_en.html> for more information).
             Choose observational time series from meteorological stations with 'selectDWD()'.
             Find raster data from radar and interpolation according to <https://bookdown.org/brry/rdwd/raster-data.html>.
             Download (multiple) data sets with progress bars and no re-downloads through 'dataDWD()'.
             Read both tabular observational data and binary gridded datasets with 'readDWD()'.",2022-05-30,Berry Boessenkool,https://github.com/brry/rdwd,TRUE,https://github.com/brry/rdwd,33317,48,2022-06-03T08:06:51Z,694.1041666666666
re2,"Pattern matching, extraction, replacement and other string
  processing operations using Google's RE2 <https://github.com/google/re2>
  regular-expression engine. Consistent interface (similar to 'stringr').
  RE2 uses finite-automata based techniques, and offers a
  fast and safe alternative to backtracking regular-expression engines
  like those used in 'stringr', 'stringi' and other PCRE implementations.",2022-03-29,Girish Palya,https://github.com/girishji/re2,TRUE,https://github.com/girishji/re2,5238,22,2022-03-29T08:32:39Z,238.0909090909091
reactable,"Interactive data tables for R, based on the 'React Table'
    JavaScript library. Provides an HTML widget that can be used in 'R Markdown'
    documents and 'Shiny' applications, or viewed from an R console.",2022-05-26,Greg Lin,"https://glin.github.io/reactable/,
https://github.com/glin/reactable",TRUE,https://github.com/glin/reactable,303364,482,2022-06-26T22:34:47Z,629.3858921161826
reactablefmtr,"Provides various features to streamline and enhance the styling of interactive 
    reactable tables with easy-to-use and highly-customizable functions and themes. 
    Apply conditional formatting to cells with data bars, color scales, color tiles,
    and icon sets. Utilize custom table themes inspired by popular websites such 
    and bootstrap themes. Apply sparkline line & bar charts 
    (note this feature requires the 'dataui' package which can be downloaded from
    <https://github.com/timelyportfolio/dataui>).
    Increase the portability and reproducibility of reactable tables by embedding images 
    from the web directly into cells. Save the final table output as a static image or 
    interactive file.",2022-03-16,Kyle Cuilla,"https://kcuilla.github.io/reactablefmtr/,
https://github.com/kcuilla/reactablefmtr",TRUE,https://github.com/kcuilla/reactablefmtr,13459,154,2022-06-20T17:40:59Z,87.3961038961039
reactlog,"Building interactive web applications with R is incredibly easy
  with 'shiny'. Behind the scenes, 'shiny' builds a reactive graph that can
  quickly become intertwined and difficult to debug. 'reactlog'
  (Schloerke 2019) <doi:10.5281/zenodo.2591517> provides a visual insight into
  that black box of 'shiny' reactivity by constructing a directed dependency
  graph of the application's reactive state at any time point in a reactive
  recording.",2020-09-12,Barret Schloerke,"https://rstudio.github.io/reactlog/,
https://github.com/rstudio/reactlog,
https://community.rstudio.com/tags/reactlog",TRUE,https://github.com/rstudio/reactlog,129241,105,2021-11-19T16:16:53Z,1230.8666666666666
readabs,"Downloads, imports, and tidies time series data from the 
    Australian Bureau of Statistics <https://www.abs.gov.au/>.",2022-04-15,Matt Cowgill,https://github.com/mattcowgill/readabs,TRUE,https://github.com/mattcowgill/readabs,31211,74,2022-07-08T06:17:49Z,421.77027027027026
readJDX,"Import data written in the JCAMP-DX format. This is an instrument-independent format used in the field of spectroscopy. Examples include IR, NMR, and Raman spectroscopy. See the vignette for background and supported formats.  The official JCAMP-DX site is <http://www.jcamp-dx.org/>.",2021-09-20,Bryan A. Hanson,https://github.com/bryanhanson/readJDX,TRUE,https://github.com/bryanhanson/readjdx,25408,5,2021-09-21T15:52:54Z,5081.6
readr,"The goal of 'readr' is to provide a fast and friendly way to
    read rectangular data (like 'csv', 'tsv', and 'fwf').  It is designed
    to flexibly parse many types of data found in the wild, while still
    cleanly failing when data unexpectedly changes.",2022-01-30,Jennifer Bryan,"https://readr.tidyverse.org, https://github.com/tidyverse/readr",TRUE,https://github.com/tidyverse/readr,18991298,914,2022-03-18T06:23:54Z,20778.225382932167
readrba,"Download up-to-date data from the Reserve Bank of Australia 
    in a tidy data frame. Package includes functions to download current and 
    historical statistical tables 
    (<https://www.rba.gov.au/statistics/tables/>) and forecasts 
    (<https://www.rba.gov.au/publications/smp/forecasts-archive.html>). Data
    includes a broad range of Australian macroeconomic and financial time
    series.",2022-06-17,Matt Cowgill,https://mattcowgill.github.io/readrba/index.html,TRUE,https://github.com/mattcowgill/readrba,7123,20,2022-07-01T06:10:08Z,356.15
readsdr,"The goal of 'readsdr' is to bridge the design capabilities from
    specialised System Dynamics software with the powerful numerical tools 
    offered by 'R' libraries. The package accomplishes this goal by parsing 
    'XMILE' files ('Vensim' and 'Stella') models into 'R' objects to construct 
    networks (graph theory); 'ODE' functions for 'Stan'; and inputs to simulate
    via 'deSolve' as described in Duggan (2016) <doi:10.1007/978-3-319-34043-2>.",2021-01-08,Jair Andrade,NA,TRUE,https://github.com/jandraor/readsdr,8235,10,2022-03-11T02:06:47Z,823.5
readsparse,"Read and write labelled sparse matrices in text format as used by
    software such as 'SVMLight', 'LibSVM', 'ThunderSVM', 'LibFM', 'xLearn', 'XGBoost', 'LightGBM',
    and others. Supports labelled data for regression, classification (binary, multi-class, multi-label),
    and ranking (with 'qid' field), and can handle header metadata and comments in files.",2021-10-14,David Cortes,https://github.com/david-cortes/readsparse,TRUE,https://github.com/david-cortes/readsparse,6189,5,2022-05-30T19:48:28Z,1237.8
readstata13,Function to read and write the 'Stata' file format.,2021-05-25,Sebastian Jeworutzki,https://github.com/sjewo/readstata13,TRUE,https://github.com/sjewo/readstata13,739088,39,2022-05-01T11:29:30Z,18950.97435897436
readtext,"Functions for importing and handling text files and formatted text
    files with additional meta-data, such including '.csv', '.tab', '.json', '.xml',
    '.html', '.pdf', '.doc', '.docx', '.rtf', '.xls', '.xlsx', and others.",2021-07-14,Kenneth Benoit,https://github.com/quanteda/readtext,TRUE,https://github.com/quanteda/readtext,171777,102,2021-07-13T16:53:18Z,1684.0882352941176
readwritesqlite,"Reads and writes data frames to 'SQLite'
    databases while preserving time zones (for POSIXct columns),
    projections (for 'sfc' columns), units (for 'units' columns), levels
    (for factors and ordered factors) and classes for logical, Date and
    'hms' columns.  It also logs changes to tables and provides more
    informative error messages.",2020-07-13,Joe Thorley,https://github.com/poissonconsulting/readwritesqlite,TRUE,https://github.com/poissonconsulting/readwritesqlite,16316,38,2021-11-10T01:43:58Z,429.36842105263156
readxl,"Import excel files into R. Supports '.xls' via the embedded
    'libxls' C library <https://github.com/libxls/libxls> and '.xlsx' via
    the embedded 'RapidXML' C++ library <http://rapidxml.sourceforge.net>.
    Works on Windows, Mac and Linux without external dependencies.",2022-03-28,Hadley Wickham,"https://readxl.tidyverse.org, https://github.com/tidyverse/readxl",TRUE,https://github.com/tidyverse/readxl,15601466,648,2022-03-31T23:15:26Z,24076.336419753086
realtest,"
    A framework for unit testing for realistic minimalists,
    where we distinguish between expected, acceptable, current, fallback,
    ideal, or regressive behaviour. It can also be used for monitoring
    third-party software projects for changes.",2021-06-17,Marek Gagolewski,https://realtest.gagolewski.com,TRUE,https://github.com/gagolews/realtest,4835,7,2022-02-09T00:58:01Z,690.7142857142857
rearrr,"Arrange data by a set of methods. Use rearrangers to reorder
    data points and mutators to change their values. From basic utilities,
    to centering the greatest value, to swirling in 3-dimensional space,
    'rearrr' enables creativity when plotting and experimenting with data.",2021-09-26,Ludvig Renbo Olsen,https://github.com/ludvigolsen/rearrr,TRUE,https://github.com/ludvigolsen/rearrr,40191,13,2021-09-26T15:55:52Z,3091.6153846153848
rebird,"A programmatic client for the eBird database 
    (<https://ebird.org/home>), including functions for searching for bird 
    observations by geographic location (latitude, longitude), eBird 
    hotspots, location identifiers, by notable sightings, by region, and by 
    taxonomic name.",2021-09-20,Sebastian Pardo,"https://docs.ropensci.org/rebird/,
https://github.com/ropensci/rebird",TRUE,https://github.com/ropensci/rebird,105521,61,2021-09-19T17:27:20Z,1729.8524590163934
RECA,"Relevant Component Analysis (RCA) tries to find a linear
    transformation of the feature space such that the effect of irrelevant
    variability is reduced in the transformed space.",2019-05-17,Nan Xiao,"https://nanx.me/RECA/, https://github.com/nanxstats/RECA",TRUE,https://github.com/nanxstats/reca,14172,7,2021-12-20T22:19:44Z,2024.5714285714287
recipes,"A recipe prepares your data for modeling. We provide an
    extensible framework for pipeable sequences of feature engineering
    steps provides preprocessing tools to be applied to data. Statistical
    parameters for the steps can be estimated from an initial data set and
    then applied to other data sets. The resulting processed output can
    then be used as inputs for statistical or machine learning models.",2022-07-07,Max Kuhn,"https://github.com/tidymodels/recipes,
https://recipes.tidymodels.org/",TRUE,https://github.com/tidymodels/recipes,5463208,457,2022-07-06T22:07:35Z,11954.503282275711
reclin2,"Functions to assist in performing probabilistic record linkage and
    deduplication: generating pairs, comparing records, em-algorithm for
    estimating m- and u-probabilities
    (I. Fellegi & A. Sunter (1969) <doi:10.1080/01621459.1969.10501049>, 
    T.N. Herzog, F.J. Scheuren, & W.E. Winkler (2007), 
    ""Data Quality and Record Linkage Techniques"", ISBN:978-0-387-69502-0),
    forcing one-to-one matching. Can also be
    used for pre- and post-processing for machine learning methods for record
    linkage. Focus is on memory, CPU performance and flexibility. ",2022-01-07,Jan van der Laan,https://github.com/djvanderlaan/reclin2,TRUE,https://github.com/djvanderlaan/reclin2,1523,7,2022-03-08T20:46:12Z,217.57142857142858
recluster,"The analysis of different aspects of biodiversity requires specific algorithms. 
	For example, in regionalisation analyses, the high frequency of ties and zero values in 
	dissimilarity matrices produced by Beta-diversity turnover produces hierarchical 
	cluster dendrograms whose topology and bootstrap supports are affected by the order of 
	rows in the original matrix. Moreover, visualisation of biogeographical regionalisation 
	can be facilitated by a combination of hierarchical clustering and multi-dimensional 
	scaling. The recluster package provides robust techniques to visualise and analyse 
	pattern of biodiversity and to improve occurrence data for cryptic taxa. 
	Other functions 	related to recluster (e.g. the biodecrypt family) are currently 
	available in GitHub at <https://github.com/leondap/recluster>.",2020-07-26,Leonardo Dapporto,https://github.com/leondap/recluster,TRUE,https://github.com/leondap/recluster,20819,0,2022-01-17T11:47:47Z,NA
recmap,"Provides an interface and a C++ implementation of the RecMap MP2
  construction heuristic (Panse C. (2018) <doi:10.18637/jss.v086.c01>).
  This algorithm draws maps according to a given statistical value
  (e.g., election results, population or epidemiological data).
  The basic idea of the RecMap algorithm is that each map region
  (e.g., different countries) is represented by a rectangle.
  The area of each rectangle represents the statistical value given
  as input (maintain zero cartographic error). Documentation about the usage
  of the recmap algorithm is provided by a vignette included in this package.",2021-09-23,Christian Panse,NA,TRUE,https://github.com/cpanse/recmap,22230,18,2022-05-25T11:01:58Z,1235
Recocrop,"The ecocrop model estimates environmental suitability for plants using a limiting factor approach for plant growth following Hackett (1991) <doi:10.1007/BF00045728>. The implementation in this package is fast and flexible: it allows for the use of any (environmental) predictor variable. Predictors can be either static (for example, soil pH) or dynamic (for example, monthly precipitation).",2021-05-04,Robert J. Hijmans,https://github.com/cropmodels/Recocrop/,TRUE,https://github.com/cropmodels/recocrop,4569,6,2022-04-05T18:53:04Z,761.5
recodeflow,"Contains functions to interface with variables and variable details sheets, including recoding variables and converting them to PMML.",2021-06-09,Rostyslav Vyuha,https://github.com/Big-Life-Lab/recodeflow,TRUE,https://github.com/big-life-lab/recodeflow,4188,4,2022-03-28T15:53:58Z,1047
recogito,"Annotate text with entities and the relations between them. Annotate areas of interest in images with your labels. 
    Providing 'htmlwidgets' bindings to the 'recogito' <https://github.com/recogito/recogito-js> and 'annotorious' <https://github.com/recogito/annotorious> libraries.",2021-06-17,Jan Wijffels,https://github.com/DIGI-VUB/recogito,TRUE,https://github.com/digi-vub/recogito,4020,5,2022-06-29T20:35:01Z,804
recometrics,"Calculates evaluation metrics for implicit-feedback recommender systems
  that are based on low-rank matrix factorization models, given the fitted model
  matrices and data, thus allowing to compare models from a variety of libraries.
  Metrics include P@K (precision-at-k, for top-K recommendations), R@K (recall at k),
  AP@K (average precision at k), NDCG@K (normalized discounted cumulative gain at k),
  Hit@K (from which the 'Hit Rate' is calculated), RR@K (reciprocal rank at k, from
  which the 'MRR' or 'mean reciprocal rank' is calculated), ROC-AUC (area under the
  receiver-operating characteristic curve), and PR-AUC (area under the
  precision-recall curve).
  These are calculated on a per-user basis according to the ranking of items induced
  by the model, using efficient multi-threaded routines. Also provides functions
  for creating train-test splits for model fitting and evaluation.",2022-01-20,David Cortes,https://github.com/david-cortes/recometrics,TRUE,https://github.com/david-cortes/recometrics,4663,16,2022-05-30T19:46:08Z,291.4375
recommenderlab,"Provides a research infrastructure to develop and evaluate
    collaborative filtering recommender algorithms. This includes a sparse 
    representation for user-item matrices, many popular algorithms, top-N recommendations,
    and cross-validation. Hahsler (2022) <doi:10.48550/arXiv.2205.12371>.",2022-06-17,Michael Hahsler,https://github.com/mhahsler/recommenderlab,TRUE,https://github.com/mhahsler/recommenderlab,162792,198,2022-06-27T00:31:36Z,822.1818181818181
recommenderlabBX,Provides the Book-Crossing Dataset for the package recommenderlab.,2022-05-31,Michael Hahsler,https://github.com/mhahsler/recommenderlabBX,TRUE,https://github.com/mhahsler/recommenderlabbx,13376,0,2022-06-20T17:13:55Z,NA
recommenderlabJester,Provides the Jester Dataset for package recommenderlab.,2022-05-31,Michael Hahsler,https://github.com/mhahsler/recommenderlabJester,TRUE,https://github.com/mhahsler/recommenderlabjester,13562,0,2022-06-20T17:14:11Z,NA
reconstructr,"Functions to reconstruct sessions from web log or other user trace data
             and calculate various metrics around them, producing tabular,
             output that is compatible with 'dplyr' or 'data.table' centered processes.",2022-02-18,Os Keyes,https://github.com/Ironholds/reconstructr,TRUE,https://github.com/ironholds/reconstructr,521426,28,2022-02-12T21:08:08Z,18622.35714285714
RecordTest,"Statistical tools based on the probabilistic properties of the 
    record occurrence in a sequence of independent and identically distributed 
    continuous random variables. In particular, tools to prepare a time series 
    as well as distribution-free trend and change-point tests and graphical 
    tools to study the record occurrence.",2021-08-08,Jorge Castillo-Mateo,https://github.com/JorgeCastilloMateo/RecordTest,TRUE,https://github.com/jorgecastillomateo/recordtest,12875,0,2021-11-06T23:44:38Z,NA
recosystem,"R wrapper of the 'libmf' library
    <https://www.csie.ntu.edu.tw/~cjlin/libmf/> for recommender
    system using matrix factorization. It is typically used to
    approximate an incomplete matrix using the product of two
    matrices in a latent space. Other common names for this task
    include ""collaborative filtering"", ""matrix completion"",
    ""matrix recovery"", etc. High performance multi-core parallel
    computing is supported in this package.",2021-09-19,Yixuan Qiu,https://github.com/yixuan/recosystem,TRUE,https://github.com/yixuan/recosystem,116582,78,2021-09-19T12:16:15Z,1494.6410256410256
reda,"Contains implementations of recurrent event data analysis routines
    including (1) survival and recurrent event data simulation from
    stochastic process point of view by the thinning method
    proposed by Lewis and Shedler (1979) <doi:10.1002/nav.3800260304>
    and the inversion method introduced in Cinlar (1975, ISBN:978-0486497976),
    (2) the mean cumulative function (MCF) estimation by the
    Nelson-Aalen estimator of the cumulative hazard rate function,
    (3) two-sample recurrent event responses comparison with the pseudo-score
    tests proposed by Lawless and Nadeau (1995) <doi:10.2307/1269617>,
    (4) gamma frailty model with spline rate function following
    Fu, et al. (2016) <doi:10.1080/10543406.2014.992524>.",2022-07-08,Wenjie Wang,"https://wwenjie.org/reda, https://github.com/wenjie2wang/reda",TRUE,https://github.com/wenjie2wang/reda,22976,9,2022-07-08T15:19:29Z,2552.8888888888887
ReDaMoR,"The aim of this package is to manipulate relational
   data models in R.
   It provides functions to create, modify and export data models
   in json format.
   It also allows importing models created
   with 'MySQL Workbench' (<https://www.mysql.com/products/workbench/>).
   These functions are accessible through a graphical user
   interface made with 'shiny'.
   Constraints such as types, keys, uniqueness and mandatory fields are
   automatically checked and corrected when editing a model.
   Finally, real data can be confronted to a model to check their compatibility.",2022-04-13,Patrice Godard,https://github.com/patzaw/ReDaMoR,TRUE,https://github.com/patzaw/redamor,10219,12,2022-06-27T15:13:44Z,851.5833333333334
REDCapR,"Encapsulates functions to streamline calls from R to the REDCap
    API.  REDCap (Research Electronic Data CAPture) is a web application for
    building and managing online surveys and databases developed at Vanderbilt
    University.  The Application Programming Interface (API) offers an avenue
    to access and modify data programmatically, improving the capacity for
    literate and reproducible programming.",2021-07-22,Will Beasley,"https://ouhscbbmc.github.io/REDCapR/,
https://github.com/OuhscBbmc/REDCapR,
https://www.ouhsc.edu/bbmc/, https://project-redcap.org",TRUE,https://github.com/ouhscbbmc/redcapr,34198,82,2022-02-24T16:13:41Z,417.0487804878049
REddyProc,"Standard and extensible Eddy-Covariance data post-processing 
  (Wutzler et al. (2018) <doi:10.5194/bg-15-5015-2018>)
  includes  
  uStar-filtering, gap-filling, and flux-partitioning.
  The Eddy-Covariance (EC)  micrometeorological technique quantifies continuous 
  exchange fluxes of gases, energy, and momentum between an ecosystem and the atmosphere.
  It is important for understanding ecosystem dynamics and upscaling exchange fluxes.
  (Aubinet et al. (2012) <doi:10.1007/978-94-007-2351-1>).
  This package inputs pre-processed (half-)hourly data and supports further processing. 
  First, a quality-check and filtering is performed based on the relationship between 
  measured flux and friction
  velocity (uStar) to discard biased data 
  (Papale et al. (2006) <doi:10.5194/bg-3-571-2006>).
  Second, gaps in the data are filled based on information from environmental conditions
  (Reichstein et al. (2005) <doi:10.1111/j.1365-2486.2005.001002.x>).
  Third, the net flux of carbon dioxide is partitioned
  into its gross fluxes in and out of the ecosystem by night-time 
  based and day-time based approaches
  (Lasslop et al. (2010) <doi:10.1111/j.1365-2486.2009.02041.x>).",2022-03-09,Thomas Wutzler,"https://www.bgc-jena.mpg.de/bgi/index.php/Services/REddyProcWeb,
https://github.com/bgctw/REddyProc",TRUE,https://github.com/bgctw/reddyproc,25572,36,2022-06-27T14:56:15Z,710.3333333333334
redist,"Enables researchers to sample redistricting plans from a pre-specified
    target distribution using Sequential Monte Carlo and Markov Chain Monte Carlo
    algorithms.  The package allows for the implementation of various constraints in
    the redistricting process such as geographic compactness and population parity
    requirements. Tools for analysis such as computation of various summary statistics
    and plotting functionality are also included. The package implements methods
    described in Fifield, Higgins, Imai and Tarr (2020) <doi:10.1080/10618600.2020.1739532>,
    Fifield, Imai, Kawahara, and Kenny (2020) <doi:10.1080/2330443X.2020.1791773>,
    and McCartan and Imai (2020) <arXiv:2008.06131>.",2022-06-16,Christopher T. Kenny,"https://alarm-redist.github.io/redist/,
https://github.com/alarm-redist/redist",TRUE,https://github.com/alarm-redist/redist,19853,47,2022-06-22T20:46:02Z,422.40425531914894
redistmetrics,"Reliable and flexible tools for scoring redistricting plans using 
  common measures and metrics. These functions provide key direct access to 
  tools useful for non-simulation analyses of redistricting plans, such as for 
  measuring compactness or partisan fairness. Tools are designed to work with 
  the 'redist' package seamlessly.",2022-04-11,Christopher T. Kenny,"https://alarm-redist.github.io/redistmetrics/,
https::/github.com/alarm-redist/redistmetrics/",TRUE,https://github.com/alarm-redist/redistmetrics,2331,5,2022-04-27T02:06:33Z,466.2
redoc,"A collection of 'HTML', 'JavaScript', 'CSS' and fonts
  assets that generate 'Redoc' documentation from an 'OpenAPI' Specification:
   <https://redoc.ly/redoc/>.",2021-02-05,Bruno Tremblay,https://github.com/meztez/redoc,TRUE,https://github.com/meztez/redoc,6254,8,2021-11-10T05:15:19Z,781.75
redux,"A 'hiredis' wrapper that includes support for
    transactions, pipelining, blocking subscription, serialisation of
    all keys and values, 'Redis' error handling with R errors.
    Includes an automatically generated 'R6' interface to the full
    'hiredis' API.  Generated functions are faithful to the
    'hiredis' documentation while attempting to match R's argument
    semantics.  Serialisation must be explicitly done by the user, but
    both binary and text-mode serialisation is supported.",2022-01-12,Rich FitzJohn,https://github.com/richfitz/redux,TRUE,https://github.com/richfitz/redux,46549,74,2022-01-13T15:59:15Z,629.0405405405405
refinr,"These functions take a character vector as input, identify and 
  cluster similar values, and then merge clusters together so their values 
  become identical. The functions are an implementation of the key collision 
  and ngram fingerprint algorithms from the open source tool Open Refine 
  <https://openrefine.org/>. More info on key collision and ngram fingerprint 
  can be found here <https://docs.openrefine.org/next/technical-reference/clustering-in-depth/>.",2022-04-24,Chris Muir,https://github.com/ChrisMuir/refinr,TRUE,https://github.com/chrismuir/refinr,15602,97,2022-04-23T22:43:38Z,160.84536082474227
RefManageR,"Provides tools for importing and working with bibliographic
    references. It greatly enhances the 'bibentry' class by providing a class
    'BibEntry' which stores 'BibTeX' and 'BibLaTeX' references, supports 'UTF-8'
    encoding, and can be easily searched by any field, by date ranges, and by
    various formats for name lists (author by last names, translator by full names,
    etc.). Entries can be updated, combined, sorted, printed in a number of styles,
    and exported. 'BibTeX' and 'BibLaTeX' '.bib' files can be read into 'R' and
    converted to 'BibEntry' objects. Interfaces to 'NCBI Entrez', 'CrossRef', and
    'Zotero' are provided for importing references and references can be created
    from locally stored 'PDF' files using 'Poppler'. Includes functions for citing
    and generating a bibliography with hyperlinks for documents prepared with
    'RMarkdown' or 'RHTML'.",2020-11-13,Mathew W. McLean,https://github.com/ropensci/RefManageR/,TRUE,https://github.com/ropensci/refmanager,155030,105,2021-12-15T08:16:49Z,1476.4761904761904
refreshr,"Connects dataframes/tables with a remote data source. Raw data downloaded
  from the data source can be further processed and transformed using data preparation 
  code that is also baked into the dataframe/table. Refreshable dataframes can 
  be shared easily (e.g. as R data files). Their users do not need to care about
  the inner workings of the data update mechanisms.",2022-03-01,Joachim Zuckarelli,https://github.com/jsugarelli/refreshr/,TRUE,https://github.com/jsugarelli/refreshr,745,1,2022-02-25T16:52:49Z,745
regfilter,"Traditional noise filtering methods aim at removing noisy samples from a classification dataset. This package adapts classic and recent filtering techniques to be used in regression problems. To do this, it uses the approach proposed in Martin (2021) [<doi:10.1109/ACCESS.2021.3123151>]. Thus, the goal of the implemented noise filters is to eliminate samples with noise in regression datasets.",2022-03-10,Juan Martin,https://github.com/juanmartinsantos/regfilter,TRUE,https://github.com/juanmartinsantos/regfilter,1076,0,2022-06-29T11:41:16Z,NA
reghelper,"A set of functions used to automate commonly used methods in
    regression analysis. This includes plotting interactions, and calculating
    simple slopes, standardized coefficients, regions of significance
    (Johnson & Neyman, 1936; cf. Spiller et al., 2012), etc. See the reghelper
    documentation for more information, documentation, and examples.",2022-04-24,Jeffrey Hughes,https://github.com/jeff-hughes/reghelper,TRUE,https://github.com/jeff-hughes/reghelper,46548,4,2022-04-23T16:48:24Z,11637
regional,"Calculates intra-regional and inter-regional similarities based on user-provided
    spatial vector objects (regions) and spatial raster objects (cells with values).
    Implemented metrics include inhomogeneity, isolation 
    (Haralick and Shapiro (1985) <doi:10.1016/S0734-189X(85)90153-7>, 
    Jasiewicz et al. (2018) <doi:10.1016/j.cageo.2018.06.003>), 
    and distinction (Nowosad (2021) <doi:10.1080/13658816.2021.1893324>).",2022-03-14,Jakub Nowosad,NA,TRUE,https://github.com/nowosad/regional,1349,6,2022-07-05T13:57:37Z,224.83333333333334
regioncode,"A fast tool to conquer the difficulties to convert various region names and administration division codes of Chinese regions. The current version enables seamlessly converting Chinese regions' formal names, common-used names, and codes between each other at the city level from 1986 to 2019.",2021-08-02,Yue Hu,NA,TRUE,https://github.com/sammo3182/regioncode,5428,7,2021-08-05T11:49:51Z,775.4285714285714
regions,"Validating sub-national statistical typologies, re-coding across 
    standard typologies of sub-national statistics, and making valid aggregate
    level imputation, re-aggregation, re-weighting and projection down to 
    lower hierarchical levels to create meaningful data panels and time series.",2021-06-21,Daniel Antal,https://regions.dataobservatory.eu/,TRUE,https://github.com/ropengov/regions,17049,5,2021-10-28T09:58:03Z,3409.8
regmedint,"This is an extension of the regression-based causal mediation analysis first proposed by Valeri and VanderWeele (2013) <doi:10.1037/a0031034> and Valeri and VanderWeele (2015) <doi:10.1097/EDE.0000000000000253>). It supports including effect measure modification by covariates(treatment-covariate and mediator-covariate product terms in mediator and outcome regression models). It also accommodates the original 'SAS' macro and 'PROC CAUSALMED' procedure in 'SAS' when there is no effect measure modification. Linear and logistic models are supported for the mediator model. Linear, logistic, loglinear, Poisson, negative binomial, Cox, and accelerated failure time (exponential and Weibull) models are supported for the outcome model.",2022-04-06,Kazuki Yoshida,https://kaz-yos.github.io/regmedint/,TRUE,https://github.com/kaz-yos/regmedint,11210,15,2022-04-06T17:02:41Z,747.3333333333334
regnet,"Network-based regularization has achieved success in variable selection for 
    high-dimensional biological data due to its ability to incorporate correlations among 
    genomic features. This package provides procedures of network-based variable selection 
    for generalized linear models (Ren et al. (2017) <doi:10.1186/s12863-017-0495-5> and 
    Ren et al. (2019) <doi:10.1002/gepi.22194>). Two recent additions are the robust network 
    regularization for the survival response and the network regularization for continuous 
    response. Functions for other regularization methods will be included in the forthcoming 
    upgraded versions. ",2019-06-08,Jie Ren,https://github.com/jrhub/regnet,TRUE,https://github.com/jrhub/regnet,13525,4,2022-03-29T21:43:50Z,3381.25
rego,"Machine learning algorithm for predicting and imputing time series. It can automatically set all the parameters needed, thus in the minimal configuration it only requires the target variable and the dependent variables if present. It can address large problems with hundreds or thousands of dependent variables and problems in which the number of dependent variables is greater than the number of observations. Moreover it can be used not only for time series but also for any other real valued target variable. The algorithm implemented includes a Bayesian stochastic search methodology for model selection and a robust estimation based on bootstrapping. 'rego' is fast because all the code is C++.",2022-05-26,Davide Altomare,https://channelattribution.io/docs/rego,TRUE,https://github.com/davidealtomare/rego,2624,14,2022-05-26T15:26:15Z,187.42857142857142
regport,"Provides R6 classes, methods and utilities to construct,
    analyze, summarize, and visualize regression models.",2022-05-10,Shixiang Wang,"https://github.com/ShixiangWang/regport,
https://shixiangwang.github.io/regport/",TRUE,https://github.com/shixiangwang/regport,956,4,2022-05-12T04:49:32Z,239
regress,"Functions to fit Gaussian linear model by maximising the
        residual log likelihood where the covariance structure can be
        written as a linear combination of known matrices.  Can be used
        for multivariate models and random effects models.  Easy
        straight forward manner to specify random effects models,
        including random interactions. Code now optimised to use
        Sherman Morrison Woodbury identities for matrix inversion in
        random effects models. We've added the ability to fit models
        using any kernel as well as a function to return the mean and
        covariance of random effects conditional on the data (best
        linear unbiased predictors, BLUPs).
        Clifford and McCullagh (2006)
        <https://www.r-project.org/doc/Rnews/Rnews_2006-2.pdf>.",2020-06-18,David Clifford,https://github.com/kbroman/regress,TRUE,https://github.com/kbroman/regress,24942,3,2021-10-29T21:41:50Z,8314
regrrr,"Compiling regression results into a publishable format, conducting post-hoc hypothesis testing, and plotting moderating effects (the effect of X on Y becomes stronger/weaker as Z increases).",2021-08-13,Rui K. Yang,NA,TRUE,https://github.com/rkzyang/regrrr,12831,1,2021-08-13T14:00:30Z,12831
RegSDC,"Implementation of the methods described in the paper with the above title: Langsrud, Ø. (2019) <doi:10.1007/s11222-018-9848-9>. The package can be used to generate synthetic or hybrid continuous microdata, and the relationship to the original data can be controlled in several ways. A function for replacing suppressed tabular cell frequencies with decimal numbers is included.",2021-05-14,Øyvind Langsrud,https://github.com/olangsrud/RegSDC,TRUE,https://github.com/olangsrud/regsdc,12766,0,2021-09-17T08:29:18Z,NA
regtools,"Tools for linear, nonlinear and nonparametric regression
             and classification.  Novel graphical methods for assessment 
             of parametric models using nonparametric methods. One 
             vs. All and All vs. All multiclass classification, optional
             class probabilities adjustment.  Nonparametric regression 
             (k-NN) for general dimension, local-linear option.  Nonlinear 
             regression with Eickert-White method for dealing with 
             heteroscedasticity.  Utilities for converting time series
             to rectangular form.  Utilities for conversion between
             factors and indicator variables.  Some code related to
             ""Statistical Regression and Classification: from Linear
             Models to Machine Learning"", N. Matloff, 2017, CRC,
             ISBN 9781498710916.",2022-03-30,Norm Matloff,https://github.com/matloff/regtools,TRUE,https://github.com/matloff/regtools,18590,118,2022-05-16T20:28:03Z,157.54237288135593
reinstallr,Search R files for not installed packages and run install.packages.,2021-11-27,Calli Gross,https://github.com/calligross/reinstallr/,TRUE,https://github.com/calligross/reinstallr,15655,47,2021-11-27T08:13:29Z,333.0851063829787
reliabilitydiag,"Checking the reliability of predictions via the CORP approach,
    which generates provably statistically 'C'onsistent, 'O'ptimally binned, and
    'R'eproducible reliability diagrams using the 'P'ool-adjacent-violators
    algorithm. See Dimitriadis, Gneiting, Jordan (2021) <doi:10.1073/pnas.2016191118>.",2022-06-29,Alexander I. Jordan,https://github.com/aijordan/reliabilitydiag/,TRUE,https://github.com/aijordan/reliabilitydiag,9923,5,2022-06-29T11:02:32Z,1984.6
remap,"Automatically creates separate regression models for different spatial 
    regions. The prediction surface is smoothed using a regional border smoothing 
    method. If regional models are continuous, the resulting prediction surface is 
    continuous across the spatial dimensions, even at region borders. Methodology 
    is described in Wagstaff (2021) <https://digitalcommons.usu.edu/etd/8065/>.",2021-04-16,Jadon Wagstaff,https://github.com/jadonwagstaff/remap,TRUE,https://github.com/jadonwagstaff/remap,8015,1,2021-11-17T20:15:54Z,8015
remiod,"Reference-based multiple imputation of ordinal and binary responses under Bayesian
          framework, as described in Wang and Liu (2022) <arXiv:2203.02771>. Methods for 
          missing-not-at-random include Jump-to-Reference (J2R), Copy Reference (CR), and Delta 
          Adjustment which can generate tipping point analysis.",2022-03-14,Tony Wang,https://github.com/xsswang/remiod,TRUE,https://github.com/xsswang/remiod,719,0,2022-05-18T01:14:23Z,NA
rEMM,"Implements TRACDS (Temporal Relationships 
    between Clusters for Data Streams), a generalization of 
    Extensible Markov Model (EMM). TRACDS adds a temporal or order model
    to data stream clustering by superimposing a dynamically adapting
    Markov Chain. Also provides an implementation of EMM (TRACDS on top of tNN 
    data stream clustering). Development of this 
    package was supported in part by NSF IIS-0948893 and R21HG005912 from 
    the National Human Genome Research Institute. Hahsler and Dunham (2010) <doi:10.18637/jss.v035.i05>.",2022-06-25,Michael Hahsler,https://github.com/mhahsler/rEMM,TRUE,https://github.com/mhahsler/remm,17159,1,2022-06-26T22:38:58Z,17159
remoter,"A set of utilities for client/server computing with R, controlling
    a remote R session (the server) from a local one (the client).  Simply set
    up a server (see package vignette for more details) and connect to it from
    your local R session ('RStudio', terminal, etc).  The client/server
    framework is a custom 'REPL' and runs entirely in your R session without the
    need for installing a custom environment on your system.  Network
    communication is handled by the 'ZeroMQ' library by way of the 'pbdZMQ'
    package.",2018-01-05,Drew Schmidt,https://github.com/RBigData/remoter,TRUE,https://github.com/rbigdata/remoter,17762,73,2021-11-15T23:47:25Z,243.31506849315068
REndo,"Fits linear models with endogenous regressor using latent instrumental variable approaches. 
    The methods included in the package are Lewbel's (1997) <doi:10.2307/2171884> higher moments approach as well as 
    Lewbel's (2012) <doi:10.1080/07350015.2012.643126> heteroscedasticity approach, Park and Gupta's (2012) <doi:10.1287/mksc.1120.0718> joint estimation method 
    that uses Gaussian copula and Kim and Frees's (2007) <doi:10.1007/s11336-007-9008-1> multilevel generalized
    method of moment approach that deals with endogeneity in a multilevel setting.
    These are statistical techniques to address the endogeneity problem where no external instrumental variables are needed.
    Note that with version 2.0.0 sweeping changes were introduced which greatly improve functionality and usability but break backwards compatibility.",2022-05-18,Raluca Gui,https://github.com/mmeierer/REndo,TRUE,https://github.com/mmeierer/rendo,26505,8,2022-07-10T13:16:38Z,3313.125
renv,"A dependency management toolkit for R. Using 'renv', you can create
    and manage project-local R libraries, save the state of these libraries to
    a 'lockfile', and later restore your library as required. Together, these
    tools can help make your projects more isolated, portable, and reproducible.",2022-05-26,Kevin Ushey,https://rstudio.github.io/renv/,TRUE,https://github.com/rstudio/renv,3671690,746,2022-07-09T03:09:15Z,4921.836461126006
repairData,"The complete data set of open repair data, full compliant with the Open Repair Data Standards (ORDS).
      It combines the datasets contributed by partner organizations of the Open Repair Alliance (ORA). Last updated: 2021-02-22. 
      The package also contains via quests enriched datasets on batteries,
      printer, mobiles, and tablets.",2021-10-21,Peter Baumgartner,https://github.com/petzi53/repairData,TRUE,https://github.com/petzi53/repairdata,3283,0,2021-10-22T21:13:16Z,NA
repana,"Set of utilities to facilitate the reproduction of analysis in R.
 It allow to make_structure(), clean_structure(), and run and log programs in a
 predefined order to allow secondary files, analysis and reports be constructed in
 an ordered form.",2021-09-20,John J. Aponte,https://github.com/johnaponte/repana,TRUE,https://github.com/johnaponte/repana,4684,2,2021-09-20T10:16:36Z,2342
repeated,"Various functions to fit models for non-normal repeated
    measurements, such as Binary Random Effects Models with Two Levels of Nesting,
    Bivariate Beta-binomial Regression Models, Marginal Bivariate Binomial Regression Models,
    Cormack capture-recapture models, Continuous-time Hidden Markov Chain Models, 
    Discrete-time Hidden Markov Chain Models,
    Changepoint Location Models using a Continuous-time Two-state Hidden Markov Chain,
    generalized nonlinear autoregression models, multivariate Gaussian copula models,
    generalized non-linear mixed models with one random effect,  
    generalized non-linear mixed models using h-likelihood for one random effect, 
    Repeated Measurements Models for Counts with Frailty or Serial Dependence,
    Repeated Measurements Models for Continuous Variables with Frailty or Serial Dependence,
    Ordinal Random Effects Models with Dropouts, marginal homogeneity models for square
    contingency tables, correlated negative binomial models with Kalman update.
    References include Lindsey's text books, 
    JK Lindsey (2001) <isbn-10:0198508123> and JK Lindsey (1999) <isbn-10:0198505590>.",2022-03-01,Bruce Swihart,https://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/repeated,19575,0,2022-03-01T14:10:37Z,NA
RepertoiR,"Visualization platform for T cell receptor repertoire
    analysis output results. It includes comparison of sequence frequency
    among samples, network of similar sequences and convergent
    recombination source between species. Currently repertoire analysis is
    in early stage of development and requires new approaches for
    repertoire data examination and assessment as we intend to develop.
    No publication is available yet (will be available in the near
    future), Efroni (2021) <https:>.",2021-10-25,Ido Hasson,https://github.com/systemsbiomed/RepertoiR,TRUE,https://github.com/systemsbiomed/repertoir,2562,0,2021-10-25T08:08:38Z,NA
replicateBE,"Performs comparative bioavailability calculations for Average
    Bioequivalence with Expanding Limits (ABEL). Implemented are 'Method A' /
    'Method B' and the detection of outliers. If the design allows, assessment
    of the empiric Type I Error and iteratively adjusting alpha to control the
    consumer risk. Average Bioequivalence - optionally with a tighter (narrow
    therapeutic index drugs) or wider acceptance range (South Africa: Cmax) -
    is implemented as well.",2022-05-02,Helmut Schütz,https://github.com/Helmut01/replicateBE,TRUE,https://github.com/helmut01/replicatebe,18602,6,2022-05-04T22:08:43Z,3100.3333333333335
ReplicationSuccess,"Provides utilities for the design and analysis of replication studies.
    Features both traditional methods based on statistical significance and
    more recent methods such as the sceptical p-value; Held L. (2020) <doi:10.1111/rssa.12493>.
    Also provides related methods including the harmonic mean chi-squared test; Held, L. (2020), <doi:10.1111/rssc.12410>,
    and intrinsic credibility; Held, L. (2019) <doi:10.1098/rsos.181534>.
    Contains datasets from four large-scale replication projects.",2022-01-26,Leonhard Held,https://SamCH93.github.io/ReplicationSuccess/,TRUE,https://github.com/samch93/replicationsuccess,4620,1,2022-01-26T09:36:15Z,4620
report,"The aim of the 'report' package is to bridge the gap between 
    R’s output and the formatted results contained in your manuscript. 
    This package converts statistical models and data frames into textual 
    reports suited for publication, ensuring standardization and quality 
    in results reporting.",2022-02-22,Dominique Makowski  (<https://orcid.org/0000-0001-5375-9967>,https://easystats.github.io/report/,TRUE,https://github.com/easystats/report,39169,542,2022-07-08T02:41:39Z,72.26752767527675
reporter,"Contains functions to create regulatory-style statistical reports.
    Originally designed to create tables, listings, and figures for the 
    pharmaceutical, biotechnology, and medical device industries, these
    reports are generalized enough that they could be used in any industry.
    Generates text, rich-text, PDF, HTML, and Microsoft Word file formats.  
    The package specializes 
    in printing wide and long tables with automatic page wrapping and splitting.  
    Reports can be produced with a minimum of function calls, and without 
    relying on other table packages.  The package supports titles, footnotes, 
    page header, page footers, spanning headers, page by variables, 
    and automatic page numbering.",2022-06-20,David Bosak,https://reporter.r-sassy.org,TRUE,https://github.com/dbosak01/reporter,10310,10,2022-07-07T19:25:34Z,1031
repoRter.nih,"Methods to easily build requests in the non-standard JSON
    schema required by the National Institute of Health (NIH)'s 'RePORTER
    Project API' <https://api.reporter.nih.gov/#/Search/post_v2_projects_search>.
    Also retrieve and process result sets as either a ragged or flattened 'tibble'.",2022-05-17,Michael Barr,https://github.com/bikeactuary/repoRter.nih,TRUE,https://github.com/bikeactuary/reporter.nih,987,2,2022-05-17T18:35:17Z,493.5
reportfactory,"Provides an infrastructure for handling multiple R Markdown
  reports, including automated curation and time-stamping of outputs,
  parameterisation and provision of helper functions to manage dependencies.",2021-08-09,Tim Taylor,https://github.com/reconverse/reportfactory,TRUE,https://github.com/reconverse/reportfactory,15178,72,2021-08-09T12:10:02Z,210.80555555555554
repr,"String and binary representations of objects for several formats /
    mime types.",2022-01-04,Philipp Angerer,https://github.com/IRkernel/repr/,TRUE,https://github.com/irkernel/repr,2337280,49,2022-01-04T14:54:32Z,47699.5918367347
reproducible,"Collection of high-level, machine- and OS-independent tools
    for making deeply reproducible and reusable content in R.
    The two workhorse functions are Cache and prepInputs; 
    these allow for: nested caching, robust to environments, and objects with
    environments (like functions); and data retrieval and processing 
    in continuous workflow environments. In all cases,
    efforts are made to make the first and subsequent calls of functions have 
    the same result, but vastly faster at subsequent times by way of checksums
    and digesting. Several features are still under active development, including
    cloud storage of cached objects, allowing for sharing between users. Several
    advanced options are available, see ?reproducibleOptions.",2021-09-26,Eliot J B McIntire,"https://reproducible.predictiveecology.org,
https://github.com/PredictiveEcology/reproducible",TRUE,https://github.com/predictiveecology/reproducible,40731,34,2021-09-26T16:04:18Z,1197.9705882352941
repurrrsive,"Recursive lists in the form of R objects, 'JSON',
    and 'XML', for use in teaching and examples. Examples include color
    palettes, Game of Thrones characters, 'GitHub' users and repositories,
    music collections, and entities from the Star Wars universe. Data from
    the 'gapminder' package is also included, as a simple data frame and
    in nested and split forms.",2019-07-15,Jennifer Bryan,https://github.com/jennybc/repurrrsive,TRUE,https://github.com/jennybc/repurrrsive,235491,127,2022-06-08T16:17:52Z,1854.259842519685
Require,"A single key function, 'Require' that wraps 'install.packages',
    'remotes::install_github', 'versions::install.versions', and 'base::require'
    that allows for reproducible workflows. As with other functions in a
    reproducible workflow, this package emphasizes functions that return the 
    same result whether it is the first or subsequent times running the function.
    Maturing.",2021-05-31,Eliot J B McIntire,"https://Require.predictiveecology.org,
https://github.com/PredictiveEcology/Require",TRUE,https://github.com/predictiveecology/require,39873,10,2022-04-13T18:10:23Z,3987.3
requiRements,"Helper function to install packages for R using an external
    'requirements.txt' or a string containing diverse packages from
    several resources like Github or CRAN.",2021-06-18,Jonathan M. Mang,https://github.com/joundso/requirements,TRUE,https://github.com/joundso/requirements,2587,3,2021-11-12T21:27:04Z,862.3333333333334
rerddap,"General purpose R client for 'ERDDAP' servers. Includes
    functions to search for 'datasets', get summary information on
    'datasets', and fetch 'datasets', in either 'csv' or 'netCDF' format.
    'ERDDAP' information: 
    <https://upwell.pfeg.noaa.gov/erddap/information.html>.",2021-11-19,Roy Mendelssohn,"https://docs.ropensci.org/rerddap/,
https://github.com/ropensci/rerddap",TRUE,https://github.com/ropensci/rerddap,28485,33,2022-01-07T20:10:28Z,863.1818181818181
rerddapXtracto,"Contains three functions that access
    environmental data from any 'ERDDAP' data web service. The rxtracto() function extracts
    data along a trajectory for a given ""radius"" around the point. The
    rxtracto_3D() function extracts data in a box. The rxtractogon() function
    extracts data in a polygon. All of those three function use the 'rerddap' package
    to extract the data, and should work with any 'ERDDAP' server.
    There are also two functions, plotBBox() and plotTrack() that use the 'plotdap'
    package to simplify the creation of maps of the data.",2021-09-26,Roy Mendelssohn,https://github.com/rmendels/rerddapXtracto,TRUE,https://github.com/rmendels/rerddapxtracto,19938,11,2021-09-27T00:28:08Z,1812.5454545454545
reReg,"A comprehensive collection of practical and easy-to-use tools for regression analysis of recurrent events, with or without the presence of a (possibly) informative terminal event. The modeling framework is based on a joint frailty scale-change model, that includes models described in Wang et al. (2001) <doi:10.1198/016214501753209031>, Huang and Wang (2004) <doi:10.1198/016214504000001033>, Xu et al. (2017) <doi:10.1080/01621459.2016.1173557>, and Xu et al. (2019) <doi:10.5705/SS.202018.0224> as special cases. The implemented estimating procedure does not require any parametric assumption on the frailty distribution. The package also allows the users to specify different model forms for both the recurrent event process and the terminal event. ",2022-06-15,Sy Han (Steven) Chiou,https://github.com/stc04003/reReg,TRUE,https://github.com/stc04003/rereg,20897,9,2022-07-05T00:44:27Z,2321.8888888888887
resemble,"
    Functions for dissimilarity analysis and memory-based learning 
    (MBL, a.k.a local modeling) in complex spectral data sets. 
    Most of these functions are based on the methods presented in 
    Ramirez-Lopez et al. (2013) <doi:10.1016/j.geoderma.2012.12.014>.",2022-01-17,Leonardo Ramirez-Lopez,http://l-ramirez-lopez.github.io/resemble/,TRUE,https://github.com/l-ramirez-lopez/resemble,15648,12,2022-03-19T23:42:04Z,1304
resevol,"Simulates individual-based models of agricultural pest management
    and the evolution of pesticide resistance. Management occurs on a spatially
    explicit landscape that is divided into an arbitrary number of farms that
    can grow one of up to 10 crops and apply one of up to 10 pesticides. Pest
    genomes are modelled in a way that allows for any number of pest traits with
    an arbitrary covariance structure that is constructed using an evolutionary
    algorithm in the mine_gmatrix() function. Simulations are then run using the
    run_farm_sim() function. This package thereby allows for highly mechanistic
    social-ecological models of the evolution of pesticide resistance under
    different types of crop rotation and pesticide application regimes.",2022-01-06,A. Bradley Duthie,https://bradduthie.github.io/resevol/,TRUE,https://github.com/bradduthie/resevol,2278,1,2022-01-06T19:36:33Z,2278
ResistorArray,Electrical properties of resistor networks using matrix methods.,2019-01-29,Robin K. S. Hankin,https://github.com/RobinHankin/ResistorArray.git,TRUE,https://github.com/robinhankin/resistorarray,22891,0,2021-09-18T22:25:41Z,NA
resourcer,"A resource represents some data or a computation unit. It is 
    described by a URL and credentials. This package proposes a Resource model
    with ""resolver"" and ""client"" classes to facilitate the access and the usage of the 
    resources.",2022-03-11,Yannick Marcon,NA,TRUE,https://github.com/obiba/resourcer,17945,2,2022-05-23T11:46:54Z,8972.5
respR,"Provides a structural, reproducible workflow for the
    processing and analysis of respirometry data. It contains analytical
    functions and utilities for working with oxygen time-series to determine
    respiration or oxygen production rates, and to make it easier to report and
    share analyses. ",2022-03-23,Nicholas Carey,"https://github.com/januarharianto/respr,
https://doi.org/10.5281/zenodo.2548601,
https://januarharianto.github.io/respR/",TRUE,https://github.com/januarharianto/respr,1819,8,2022-03-24T08:06:38Z,227.375
restatapi,"Eurostat is the statistical office of the European Union and provides high quality statistics for Europe.
             Large set of the data is disseminated through the Eurostat database (<https://ec.europa.eu/eurostat/data/database>). 
             The tools are using the REST API with the Statistical Data and Metadata eXchange (SDMX) Web Services 
             (<https://ec.europa.eu/eurostat/web/sdmx-web-services/about-this-service>) to search and download data from 
             the Eurostat database using the SDMX standard. ",2022-05-31,Mátyás Mészáros,https://github.com/eurostat/restatapi,TRUE,https://github.com/eurostat/restatapi,20900,14,2022-05-31T23:11:50Z,1492.857142857143
restoptr,"
  Flexible framework for ecological restoration planning. It aims to identify priority areas for restoration efforts using optimization algorithms (based on Justeau-Allaire et al. 2021 <doi:10.1111/1365-2664.13803>). Priority areas can be identified by maximizing landscape indices, such as the effective mesh size (Jaeger 2000 <doi:10.1023/A:1008129329289>), or the integral index of connectivity (Pascual-Hortal & Saura 2006 <doi:10.1007/s10980-006-0013-z>). Additionally, constraints can be used to ensure that priority areas exhibit particular characteristics (e.g., ensure that particular places are not selected for restoration, ensure that priority areas form a single contiguous network). Furthermore, multiple near-optimal solutions can be generated to explore multiple options in restoration planning. The package leverages the 'Choco-solver' software to perform optimization using constraint programming (CP) techniques (<https://choco-solver.org/>).",2022-06-17,Dimitri Justeau-Allaire,https://dimitri-justeau.github.io/restoptr/,TRUE,https://github.com/dimitri-justeau/restoptr,353,2,2022-06-25T15:31:56Z,176.5
RestRserve,"
  Allows to easily create high-performance full featured HTTP APIs from R
  functions. Provides high-level classes such as 'Request', 'Response',
  'Application', 'Middleware' in order to streamline server side
  application development. Out of the box allows to serve requests using
  'Rserve' package, but flexible enough to integrate with other HTTP servers
  such as 'httpuv'.",2022-06-09,Dmitry Selivanov,"https://restrserve.org, https://github.com/rexyai/RestRserve",TRUE,https://github.com/rexyai/restrserve,32330,247,2022-06-09T10:20:02Z,130.8906882591093
resumer,"Using a CSV, LaTeX and R to easily build attractive resumes.",2021-02-12,Jared Lander,https://github.com/jaredlander/resumer,TRUE,https://github.com/jaredlander/resumer,15335,66,2022-03-18T01:50:48Z,232.34848484848484
rethnicity,"Implementation of the race/ethnicity prediction method, described 
    in ""rethnicity: An R package for predicting ethnicity from names"" 
    by Fangzhou Xie (2022) <doi:10.1016/j.softx.2021.100965> and 
    ""Rethnicity: Predicting Ethnicity from Names"" by Fangzhou Xie (2021) <arXiv:2109.09228>.",2022-05-31,Fangzhou Xie,https://github.com/fangzhou-xie/rethnicity,TRUE,https://github.com/fangzhou-xie/rethnicity,3869,3,2022-05-31T14:59:37Z,1289.6666666666667
reticulate,"Interface to 'Python' modules, classes, and functions. When calling
    into 'Python', R data types are automatically converted to their equivalent 'Python'
    types. When values are returned from 'Python' to R they are converted back to R
    types. Compatible with all versions of 'Python' >= 2.7.",2022-05-11,Tomasz Kalinowski [ctb,"https://rstudio.github.io/reticulate/,
https://github.com/rstudio/reticulate",TRUE,https://github.com/rstudio/reticulate,5882806,1437,2022-06-29T15:00:01Z,4093.810716771051
retistruct,"Reconstructs retinae by morphing a flat surface with cuts (a
    dissected flat-mount retina) onto a curvilinear surface (the standard retinal
    shape). It can estimate the position of a point on the intact adult retina
    to within 8 degrees of arc (3.6% of nasotemporal axis). The coordinates in
    reconstructed retinae can be transformed to visuotopic coordinates.",2020-04-04,David C. Sterratt,http://davidcsterratt.github.io/retistruct/,TRUE,https://github.com/davidcsterratt/retistruct,16533,5,2022-01-11T23:06:06Z,3306.6
retroharmonize,"Assist in reproducible retrospective (ex-post) harmonization
    of data, particularly individual level survey data, by providing tools
    for organizing metadata, standardizing the coding of variables, and
    variable names and value labels, including missing values, and
    documenting the data transformations, with the help of comprehensive
    s3 classes.",2021-11-02,Daniel Antal,"https://retroharmonize.dataobservatory.eu/,
https://ropengov.github.io/retroharmonize/,
https://github.com/rOpenGov/retroharmonize",TRUE,https://github.com/ropengov/retroharmonize,7873,6,2022-07-03T13:40:00Z,1312.1666666666667
retrosheet,"A collection of tools to import and structure the (currently) single-season
    event, game-log, roster, and schedule data available from <https://www.retrosheet.org>.
    In particular, the event (a.k.a. play-by-play) files can be especially difficult to parse.
    This package does the parsing on those files, returning the requested data in the most
    practical R structure to use for sabermetric or other analyses.",2021-09-16,Colin Douglas,https://github.com/colindouglas/retrosheet,TRUE,https://github.com/colindouglas/retrosheet,15597,1,2021-09-16T01:59:26Z,15597
retry,Provide simple mechanism to repeatedly evaluate an expression until either it succeeds or timeout exceeded. It is useful in situations that random failures could happen.,2020-04-23,Randy Lai,https://github.com/randy3k/retry,TRUE,https://github.com/randy3k/retry,60688,14,2021-11-09T17:21:58Z,4334.857142857143
reval,"Simplified scenario testing and sensitivity analysis,
    redesigned to use packages 'future' and 'furrr'. Provides
    functions for generating function argument sets using
    one-factor-at-a-time (OFAT) and (sampled) permutations.",2022-06-29,Michael C Koohafkan,https://github.com/mkoohafkan/reval,TRUE,https://github.com/mkoohafkan/reval,13833,1,2022-06-29T06:15:22Z,13833
revdbayes,"Provides functions for the Bayesian analysis of extreme value
    models.  The 'rust' package <https://cran.r-project.org/package=rust> is
    used to simulate a random sample from the required posterior distribution.
    The functionality of 'revdbayes' is similar to the 'evdbayes' package
    <https://cran.r-project.org/package=evdbayes>, which uses Markov Chain
    Monte Carlo ('MCMC') methods for posterior simulation.  In addition, there
    are functions for making inferences about the extremal index, using 
    the models for threshold inter-exceedance times of Suveges and Davison 
    (2010) <doi:10.1214/09-AOAS292> and Holesovsky and Fusek (2020) 
    <doi:10.1007/s10687-020-00374-3>. Also provided are d,p,q,r functions for 
    the Generalised Extreme Value ('GEV') and Generalised Pareto ('GP') 
    distributions that deal appropriately with cases where the shape parameter 
    is very close to zero.",2022-05-09,Paul J. Northrop,"https://paulnorthrop.github.io/revdbayes/,
https://github.com/paulnorthrop/revdbayes",TRUE,https://github.com/paulnorthrop/revdbayes,68035,5,2022-05-15T20:09:30Z,13607
revealjs,"R Markdown format for 'reveal.js' presentations, a framework 
  for easily creating beautiful presentations using HTML.",2017-03-13,Hakim El Hattab,https://github.com/rstudio/revealjs,TRUE,https://github.com/rstudio/revealjs,42024,300,2022-04-06T16:51:01Z,140.08
reveneraR,"Facilitates making a connection to the 
  'Revenera' API and executing various queries. You can use it to
  get event data and metadata. The 'Revenera' documentation 
  is available at 
  <https://docs.revenera.com/ui560/report/>. This package is not 
  supported by 'Flexera' (owner of the software). ",2022-02-03,Chris Umphlett,https://github.com/chrisumphlett/reveneraR,TRUE,https://github.com/chrisumphlett/revenerar,4459,0,2022-02-03T20:30:46Z,NA
ReviewR,"A portable Shiny tool to explore patient-level electronic health record data 
    and perform chart review in a single integrated framework. This tool supports 
    browsing clinical data in many different formats including multiple versions 
    of the 'OMOP' common data model as well as the 'MIMIC-III' data model. In 
    addition, chart review information is captured and stored securely via the 
    Shiny interface in a 'REDCap' (Research Electronic Data Capture) project 
    using the 'REDCap' API. See the 'ReviewR' website for additional information, 
    documentation, and examples.",2022-05-18,Laura Wiley,"https://reviewr.thewileylab.org/,
https://github.com/thewileylab/ReviewR/",TRUE,https://github.com/thewileylab/reviewr,5490,18,2022-05-18T17:06:40Z,305
revss,"Implements the estimation techniques described in Rousseeuw &
    Verboven (2002) <doi:10.1016/S0167-9473(02)00078-6> for the location and
    scale of very small samples.",2022-04-04,Avraham Adler,https://github.com/aadler/revss,TRUE,https://github.com/aadler/revss,8893,2,2022-04-04T05:02:25Z,4446.5
revulyticsR,"Facilitates making a connection to the 
  'Revulytics' API and executing various queries. You can use it to
  get event data and metadata. The Revulytics documentation 
  is available at <https://docs.revenera.com/ui560/report/>. This
  package is not supported by 'Flexera' (owner of the software). ",2020-12-04,Chris Umphlett,https://github.com/chrisumphlett/revulyticsR,TRUE,https://github.com/chrisumphlett/revulyticsr,8293,0,2022-02-03T20:30:46Z,NA
rex,"A friendly interface for the construction of regular
    expressions.",2021-11-26,Kevin Ushey,https://github.com/kevinushey/rex,TRUE,https://github.com/kevinushey/rex,5653119,306,2022-01-11T17:51:43Z,18474.245098039217
rextendr,"Provides functions to compile and load Rust code from R, similar
    to how 'Rcpp' or 'cpp11' allow easy interfacing with C++ code. Also provides
    helper functions to create R packages that use Rust code. Under the hood,
    the Rust crate 'extendr' is used to do all the heavy lifting.",2021-06-15,Claus O. Wilke,https://extendr.github.io/rextendr/,TRUE,https://github.com/extendr/rextendr,3872,99,2022-06-13T17:08:12Z,39.111111111111114
rfacebookstat,"Load data by campaigns, ads, ad sets and insights, ad account and business manager 
    from Facebook Marketing API into R. For more details see official documents by Facebook 
    Marketing API <https://developers.facebook.com/docs/marketing-apis/>.",2022-06-09,Alexey Seleznev,"https://selesnow.github.io/rfacebookstat/,
https://www.youtube.com/playlist?list=PLD2LDq8edf4pItOb-vZTG5AXZK2niJ8_R",TRUE,https://github.com/selesnow/rfacebookstat,21707,24,2022-06-06T09:51:03Z,904.4583333333334
rfacts,"The 'rfacts' package is an R interface to the
  Fixed and Adaptive Clinical Trial Simulator ('FACTS')
  on Unix-like systems. It programmatically invokes 'FACTS' to run clinical
  trial simulations, and it aggregates simulation output data
  into tidy data frames. These capabilities provide end-to-end
  automation for large-scale simulation pipelines, and
  they enhance computational reproducibility.
  For more information on 'FACTS' itself,
  please visit <https://www.berryconsultants.com/software/>.",2022-01-04,William Michael Landau,"https://elilillyco.github.io/rfacts/,
https://github.com/EliLillyCo/rfacts",TRUE,https://github.com/elilillyco/rfacts,12353,3,2022-01-04T22:06:50Z,4117.666666666667
Rfast,"A collection of fast (utility) functions for data analysis. Column- and row- wise means, medians, variances, minimums, maximums, many t, F and G-square tests, many regressions (normal, logistic, Poisson), are some of the many fast functions. References: a) Tsagris M., Papadakis M. (2018). Taking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1 <doi:10.7287/peerj.preprints.26605v1>. b) Tsagris M. and Papadakis M. (2018). Forward regression in R: from the extreme slow to the extreme fast. Journal of Data Science, 16(4): 771--780. <doi:10.6339/JDS.201810_16(4).00006>. ",2022-02-16,Manos Papadakis,https://github.com/RfastOfficial/Rfast,TRUE,https://github.com/rfastofficial/rfast,319556,83,2022-06-22T11:00:25Z,3850.0722891566265
Rfast2,"A collection of fast statistical and utility functions for data analysis. Functions for regression, maximum likelihood, column-wise statistics and many more have been included. C++ has been utilized to speed up the functions.",2022-03-23,Manos Papadakis,https://github.com/RfastOfficial/Rfast2,TRUE,https://github.com/rfastofficial/rfast2,61674,23,2022-06-20T18:40:06Z,2681.478260869565
RFCCA,"Random Forest with Canonical Correlation Analysis (RFCCA) is a 
  random forest method for estimating the canonical correlations between two 
  sets of variables depending on the subject-related covariates. The trees are 
  built with a splitting rule specifically designed to partition the data to 
  maximize the canonical correlation heterogeneity between child nodes. The 
  method is described in Alakus et al. (2021) <doi:10.1093/bioinformatics/btab158>. RFCCA uses 
  'randomForestSRC' package (Ishwaran and Kogalur, 2020) by freezing at the 
  version 2.9.3. The custom splitting rule feature is utilised to apply the 
  proposed splitting rule.",2022-04-13,Cansu Alakus,https://github.com/calakus/RFCCA,TRUE,https://github.com/calakus/rfcca,7556,1,2022-04-08T20:59:54Z,7556
rFIA,"The goal of 'rFIA' is to increase the accessibility and use of the United States Forest Services (USFS) Forest Inventory and Analysis (FIA) Database by providing a user-friendly, open source toolkit to easily query and analyze FIA Data. Designed to accommodate a wide range of potential user objectives, 'rFIA' simplifies the estimation of forest variables from the FIA Database and allows all R users (experts and newcomers alike) to unlock the flexibility inherent to the Enhanced FIA design. Specifically, 'rFIA' improves accessibility to the spatial-temporal estimation capacity of the FIA Database by producing space-time indexed summaries of forest variables within user-defined population boundaries. Direct integration with other popular R packages (e.g., 'dplyr', 'tidyr', and 'sf') facilitates efficient space-time query and data summary, and supports common data representations and API design. The package implements design-based estimation procedures outlined by Bechtold & Patterson (2005) <doi:10.2737/SRS-GTR-80>, and has been validated against estimates and sampling errors produced by FIA 'EVALIDator'. Current development is focused on the implementation of spatially-enabled model-assisted estimators to improve population, change, and ratio estimates.",2021-12-15,Hunter Stanke,https://github.com/hunter-stanke/rFIA,TRUE,https://github.com/hunter-stanke/rfia,18612,34,2022-05-12T03:57:38Z,547.4117647058823
rfigshare,An R interface to 'figshare'.,2022-05-09,Carl Boettiger,https://github.com/ropensci-archive/rfigshare,TRUE,https://github.com/ropensci-archive/rfigshare,25942,44,2022-05-10T13:14:58Z,589.5909090909091
rfishbase,"A programmatic interface to 'FishBase', re-written
    based on an accompanying 'RESTful' API. Access tables describing over 30,000
    species of fish, their biology, ecology, morphology, and more. This package also
    supports experimental access to 'SeaLifeBase' data, which contains
    nearly 200,000 species records for all types of aquatic life not covered by
    'FishBase.'",2021-12-14,Carl Boettiger,"https://docs.ropensci.org/rfishbase/,
https://github.com/ropensci/rfishbase",TRUE,https://github.com/ropensci/rfishbase,34666,82,2021-12-13T23:54:58Z,422.7560975609756
RFishBC,"Helps fisheries scientists collect measurements from calcified
    structures and back-calculate estimated lengths at previous ages using
    standard procedures and models. This is intended to replace much of the
    functionality provided by the now out-dated 'fishBC' software
    (<https://fisheries.org/bookstore/all-titles/software/70317/>).",2022-02-13,Derek Ogle,https://derekogle.com/RFishBC/,TRUE,https://github.com/droglenc/rfishbc,13085,12,2022-02-27T02:28:08Z,1090.4166666666667
rfishdraw,"Automatic generation of fish drawings based on JavaScript library <https://github.com/LingDong-/fishdraw>, including JavaScript code for dynamic generation of fish drawings.",2021-09-08,Liuyong Ding,https://github.com/Otoliths/rfishdraw,TRUE,https://github.com/otoliths/rfishdraw,3233,5,2021-09-10T14:38:46Z,646.6
rflashtext,"Implementation of the FlashText algorithm, by Singh (2017) <arXiv:1711.00046>. It can be used to find and replace words in a given text with only one pass over the document.",2022-06-30,Abraham Jaimes,https://github.com/AbrJA/rflashtext,TRUE,https://github.com/abrja/rflashtext,114,6,2022-06-30T16:05:06Z,19
rflsgen,"Interface to the 'flsgen' neutral landscape generator <https://github.com/dimitri-justeau/flsgen>. It allows to
  - Generate fractal terrain;
  - Generate landscape structures satisfying user targets over landscape indices;
  - Generate landscape raster from landscape structures.",2022-02-23,Dimitri Justeau-Allaire,https://dimitri-justeau.github.io/rflsgen/,TRUE,https://github.com/dimitri-justeau/rflsgen,2302,5,2022-06-25T15:30:35Z,460.4
rfm,"Tools for RFM (recency, frequency and monetary value) analysis. 
    Generate RFM score from both transaction and customer level data. Visualize the
    relationship between recency, frequency and monetary value using heatmap, 
    histograms, bar charts and scatter plots. Includes a 'shiny' app for 
    interactive segmentation. References:
    i. Blattberg R.C., Kim BD., Neslin S.A (2008) <doi:10.1007/978-0-387-72579-6_12>.",2020-07-21,Aravind Hebbali,"https://github.com/rsquaredacademy/rfm,
https://rfm.rsquaredacademy.com/",TRUE,https://github.com/rsquaredacademy/rfm,260786,45,2022-04-01T10:04:16Z,5795.2444444444445
rfoaas,R access to the 'FOAAS' (F... Off As A Service) web service is provided.,2020-01-09,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rfoaas.html,TRUE,https://github.com/eddelbuettel/rfoaas,16629,28,2021-12-23T23:55:37Z,593.8928571428571
rfordummies,"Contains all the code examples in the book ""R for Dummies"" (2nd
    edition) by Andrie de Vries and Joris Meys. You can view the table of 
    contents as well as the sample code for each chapter.",2022-02-25,Andrie de Vries,"https://rfordummies.com,
https://rfordummies.github.io/rfordummies/",TRUE,https://github.com/rfordummies/rfordummies,16171,4,2022-02-25T18:38:39Z,4042.75
rForest,Set of tools designed for forest inventory analysis.,2021-10-04,Carlos Alberto Silva,https://github.com/carlos-alberto-silva/rForest,TRUE,https://github.com/carlos-alberto-silva/rforest,3254,8,2021-10-02T04:18:56Z,406.75
Rforestry,"Provides fast implementations of Honest Random Forests, 
    Gradient Boosting, and Linear Random Forests, with an emphasis on inference 
    and interpretability. Additionally contains methods for variable 
    importance, out-of-bag prediction, regression monotonicity, and
    several methods for missing data imputation. Soren R. Kunzel, 
    Theo F. Saarinen, Edward W. Liu, Jasjeet S. Sekhon (2019) <arXiv:1906.06463>.",2022-03-09,Theo Saarinen,https://github.com/forestry-labs/Rforestry,TRUE,https://github.com/forestry-labs/rforestry,7474,15,2022-03-31T22:18:26Z,498.26666666666665
rfPermute,"Estimate significance of importance metrics
    for a Random Forest model by permuting the response
    variable. Produces null distribution of importance
    metrics for each predictor variable and p-value of
    observed. Provides summary and visualization functions for 'randomForest' 
    results.",2022-03-10,Eric Archer,https://github.com/EricArcher/rfPermute,TRUE,https://github.com/ericarcher/rfpermute,29837,20,2022-04-18T17:51:32Z,1491.85
RFpredInterval,"Implements various prediction interval methods with random forests and boosted forests.
    The package has two main functions: pibf() produces prediction intervals with boosted forests
    (PIBF) as described in Alakus et al. (2021) <arXiv:2106.08217> and rfpi() builds 15 distinct
    variations of prediction intervals with random forests (RFPI) proposed by Roy and Larocque (2020)
    <doi:10.1177/0962280219829885>.",2022-05-25,Cansu Alakus,https://github.com/calakus/RFpredInterval,TRUE,https://github.com/calakus/rfpredinterval,4892,5,2022-05-25T13:56:40Z,978.4
Rfssa,"Methods and tools for implementing univariate and multivariate functional singular spectrum analysis for functional time series whose variables might be observed over different dimensional domains. The univariate fssa algorithm is described in Haghbin H., Najibi, S.M., Mahmoudvand R., Trinka J., Maadooliat M. (2021) and the multivariate fssa over different dimensional domains technique may be found in Trinka J., Haghbin H., and Maadooliat M. (Accepted). In addition, one may perform forecasting of univariate and multivariate fts whose variables are observed over one-dimensional domains as described in the dissertation of Trinka J. (2021) and the manuscript of Trinka J., Haghbin H., Maadooliat M. (2020) where the manuscript is to be submitted to a journal for publication. ",2022-01-10,Hossein Haghbin,https://github.com/haghbinh/Rfssa,TRUE,https://github.com/haghbinh/rfssa,12693,5,2022-05-25T22:09:53Z,2538.6
rfUtilities,"Utilities for Random Forest model selection, class balance
    correction, significance test, cross validation and partial dependency
    plots.",2019-10-03,Jeffrey S. Evans,https://github.com/jeffreyevans/rfUtilities,TRUE,https://github.com/jeffreyevans/rfutilities,53407,10,2022-02-09T19:17:44Z,5340.7
rgabriel,"Analyze multi-level one-way
        experimental designs where there are unequal sample
        sizes and population variance homogeneity can not be assumed.
        To conduct the Gabriel test <doi:10.2307/2286265>, create two vectors: one for your 
        observations and one for the factor level of each observation. 
        The function, rgabriel, conduct the test and save the output as
        a vector to input into the gabriel.plot function, which produces 
        a confidence interval plot for Multiple Comparison.",2022-05-09,Miao YU,"https://github.com/yufree/rgabriel,
http://yufree.github.io/rgabriel/",TRUE,https://github.com/yufree/rgabriel,17097,1,2022-05-09T17:42:25Z,17097
RGAN,"An easy way to get started with Generative Adversarial Nets (GAN) in R. The GAN algorithm was initially 
    described by Goodfellow et al. 2014 <https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf>. A GAN can be used to learn the joint distribution of complex data by 
    comparison. A GAN consists of two neural networks a Generator and a Discriminator, where the two
    neural networks play an adversarial minimax game.
    Built-in GAN models make the training of GANs in R possible in one line and make it easy to 
    experiment with different design choices (e.g. different network architectures, value functions, optimizers).
    The built-in GAN models work with tabular data (e.g. to produce synthetic data) and image data. 
    Methods to post-process the output of GAN models to enhance the quality of samples are available.",2022-03-29,Marcel Neunhoeffer,https://github.com/mneunhoe/RGAN,TRUE,https://github.com/mneunhoe/rgan,889,8,2022-03-28T21:26:07Z,111.125
rgbif,"A programmatic interface to the Web Service methods
    provided by the Global Biodiversity Information Facility (GBIF;
    <https://www.gbif.org/developer/summary>). GBIF is a database
    of species occurrence records from sources all over the globe.
    rgbif includes functions for searching for taxonomic names,
    retrieving information on data providers, getting species occurrence
    records, getting counts of occurrence records, and using the GBIF
    tile map service to make rasters summarizing huge amounts of data.",2022-04-11,Dan Mcglinn [ctb,"https://github.com/ropensci/rgbif (devel),
https://docs.ropensci.org/rgbif/ (documentation)",TRUE,https://github.com/ropensci/rgbif,197104,122,2022-06-28T07:04:36Z,1615.6065573770493
rgdax,"Allow access to both public and private end points to Coinbase Pro (erstwhile GDAX) 
    cryptocurrency exchange. For authenticated flow, users must have valid api, secret and passphrase to be able to connect.",2021-08-03,Dheeraj Agarwal,https://github.com/DheerajAgarwal/rgdax/,TRUE,https://github.com/dheerajagarwal/rgdax,17268,35,2021-12-14T10:47:44Z,493.37142857142857
rgee,"Earth Engine <https://earthengine.google.com/> client library for R. All
  of the 'Earth Engine' API classes, modules, and functions are made available. Additional
  functions implemented include importing (exporting) of Earth Engine spatial objects, 
  extraction of time series, interactive map display, assets management interface, 
  and metadata display. See <https://r-spatial.github.io/rgee/> for further details.",2022-03-16,Cesar Aybar,"https://github.com/r-spatial/rgee/,
https://r-spatial.github.io/rgee/,
https://github.com/google/earthengine-api/",TRUE,https://github.com/r-spatial/rgee,27898,448,2022-07-02T03:13:34Z,62.27232142857143
RGENERATE,"A method 'generate()' is implemented in this package for the random
    generation of vector time series according to models obtained by 'RMAWGEN',
    'vars' or other packages.  This package was created to generalize the
    algorithms of the 'RMAWGEN' package for the analysis and generation of any
    environmental vector time series.",2022-01-14,Emanuele Cordano,https://github.com/ecor/RGENERATE,TRUE,https://github.com/ecor/rgenerate,17597,1,2022-05-06T21:31:19Z,17597
RGENERATEPREC,"The method 'generate()' is extended for spatial multi-site
    stochastic generation of daily precipitation. It generates precipitation
    occurrence in several sites using logit regression (Generalized Linear
    Models) and the approach by D.S. Wilks (1998) <doi:10.1016/S0022-1694(98)00186-3> . ",2022-01-20,Emanuele Cordano,https://github.com/ecor/RGENERATEPREC,TRUE,https://github.com/ecor/rgenerateprec,14890,2,2022-05-06T21:20:09Z,7445
rgenoud,A genetic algorithm plus derivative optimizer.,2022-04-20,Jasjeet Singh Sekhon,https://github.com/JasjeetSekhon/rgenoud,TRUE,https://github.com/jasjeetsekhon/rgenoud,257938,4,2022-04-19T16:46:45Z,64484.5
rgeoda,"Provides spatial data analysis functionalities including Exploratory Spatial Data Analysis, 
    Spatial Cluster Detection and Clustering Analysis, Regionalization, etc. based on the C++ source code 
    of 'GeoDa', which is an open-source software tool that serves as an introduction to spatial data analysis.
    The 'GeoDa' software and its documentation are available at <https://geodacenter.github.io>.",2022-04-11,Xun Li,"https://github.com/geodacenter/rgeoda/,
https://geodacenter.github.io/rgeoda/",TRUE,https://github.com/geodacenter/rgeoda,25625,53,2022-04-10T06:44:39Z,483.49056603773585
rgeolocate,"Connectors to online and offline sources for taking IP addresses
    and geolocating them to country, city, timezone and other geographic ranges. For
    individual connectors, see the package index.",2021-12-20,Os Keyes,NA,TRUE,https://github.com/ironholds/rgeolocate,39041,67,2021-12-18T21:21:40Z,582.7014925373135
rgexf,"Create, read and write 'GEXF' (Graph Exchange 'XML' Format) graph
    files (used in 'Gephi' and others). Using the 'XML' package, it allows the user to
    easily build/read graph files including attributes, 'GEXF' visual attributes (such
    as color, size, and position), network dynamics (for both edges and nodes) and
    edge weighting. Users can build/handle graphs element-by-element or massively
    through data-frames, visualize the graph on a web browser through 'gexf-js' (a
    'javascript' library) and interact with the 'igraph' package.",2021-08-12,George Vega Yon,https://gvegayon.github.io/rgexf/,TRUE,https://github.com/gvegayon/rgexf,88992,20,2021-10-20T19:50:23Z,4449.6
rGhanaCensus,"Datasets from the 2021 Ghana Population and Housing Census Results. Users can access results as 'tidyverse' and 'sf'-Ready Data Frames.    The data in this package is scraped from pdf reports released by the Ghana Statistical Service website <https://census2021.statsghana.gov.gh/> . The package currently only contains datasets from the literacy and education reports. Namely, school attendance data for respondents aged 3 years and above.",2022-01-13,Ama Owusu-Darko,https://github.com/ktemadarko/rGhanaCensus,TRUE,https://github.com/ktemadarko/rghanacensus,1445,0,2022-03-01T16:38:27Z,NA
rgl,"Provides medium to high level functions for 3D interactive graphics, including
    functions modelled on base graphics (plot3d(), etc.) as well as functions for
    constructing representations of geometric objects (cube3d(), etc.).  Output
    may be on screen using OpenGL, or to various standard 3D file formats including
    WebGL, PLY, OBJ, STL as well as 2D image formats, including PNG, Postscript, SVG, PGF.",2022-07-08,Duncan Murdoch,"https://github.com/dmurdoch/rgl, https://dmurdoch.github.io/rgl/",TRUE,https://github.com/dmurdoch/rgl,17130130,58,2022-07-07T23:41:28Z,295347.0689655172
rgl2gltf,"The 'glTF' file format is used to describe 3D models.  This package 
 provides read and write functions to work with it.",2022-06-20,Duncan Murdoch,https://github.com/dmurdoch/rgl2gltf,TRUE,https://github.com/dmurdoch/rgl2gltf,193,7,2022-06-17T11:45:40Z,27.571428571428573
rglobi,"A programmatic interface to the web service methods
    provided by Global Biotic Interactions (GloBI)
    (<https://www.globalbioticinteractions.org/>). GloBI provides 
    access to spatial-temporal species interaction records from 
    sources all over the world. rglobi provides methods to search 
    species interactions by location, interaction type, and 
    taxonomic name. In addition, it supports Cypher, a graph query
    language, to allow for executing custom queries on the GloBI 
    aggregate species interaction data set.",2021-10-18,Jorrit Poelen,"https://docs.ropensci.org/rglobi/,
https://github.com/ropensci/rglobi",TRUE,https://github.com/ropensci/rglobi,20271,12,2021-10-18T21:24:05Z,1689.25
rgoogleads,"Interface for loading data from 'Google Ads API', 
    see <https://developers.google.com/google-ads/api/docs/start>. 
    Package provide function for authorization and loading reports.",2022-05-31,Alexey Seleznev,"https://selesnow.github.io/rgoogleads/,
https://selesnow.github.io/rgoogleads/docs/,
https://github.com/selesnow/rgoogleads",TRUE,https://github.com/selesnow/rgoogleads,6338,9,2022-05-31T18:40:05Z,704.2222222222222
rgraph6,"Encode network data as strings of printable ASCII characters. Implemented 
    functions include encoding and decoding adjacency matrices, edgelists, igraph, and
    network objects to/from formats 'graph6', 'sparse6', and 'digraph6'. The formats and
    methods are described in McKay, B.D. and Piperno, A (2014)
    <doi:10.1016/j.jsc.2013.09.003>.",2022-03-09,Michal Bojanowski  (<https://orcid.org/0000-0001-7503-852X>,https://mbojan.github.io/rgraph6/,TRUE,https://github.com/mbojan/rgraph6,1301,6,2022-02-24T22:14:20Z,216.83333333333334
rgrass7,"Interpreted interface between 'GRASS' geographical 
    information system and R, based on starting R from within the 'GRASS' 'GIS'
    environment, or running free-standing R in a temporary 'GRASS' location;
    the package provides facilities for using all 'GRASS' commands from the 
    R command line. This package may not be used for 'GRASS' 6, for which
    'spgrass6' should be used.",2022-05-02,Roger Bivand,"https://grass.osgeo.org/, https://github.com/rsbivand/rgrass,
https://rsbivand.github.io/rgrass/",TRUE,https://github.com/rsbivand/rgrass,47079,17,2022-05-02T08:20:01Z,2769.3529411764707
rgtmx,"This is a library to access the current API of the web speed test service 'GTmetrix'.
    It provides a convenient wrapper to start tests, get reports, and access all kinds of meta data. 
    For more information about using the API please visit <https://gtmetrix.com/api/docs/2.0/>.",2021-11-11,Roman A. Abashin,https://github.com/RomanAbashin/rgtmx,TRUE,https://github.com/romanabashin/rgtmx,2160,1,2022-04-23T10:40:34Z,2160
rgugik,"Automatic open data acquisition from resources of Polish Head Office
    of Geodesy and Cartography ('Główny Urząd Geodezji i Kartografii')
    (<https://www.gov.pl/web/gugik>).
    Available datasets include various types of numeric, raster and vector data,
    such as orthophotomaps, digital elevation models (digital terrain models,
    digital surface model, point clouds), state register of borders, spatial
    databases, geometries of cadastral parcels, 3D models of buildings, and more.
    It is also possible to geocode addresses or objects using the geocodePL_get()
    function.",2022-01-17,Krzysztof Dyba,"https://kadyb.github.io/rgugik/, https://github.com/kadyb/rgugik",TRUE,https://github.com/kadyb/rgugik,9838,29,2022-06-27T10:24:55Z,339.2413793103448
rhandsontable,"An R interface to the 'Handsontable' JavaScript library, which is a
    minimalist Excel-like data grid editor.  See <https://handsontable.com/> for details.",2021-05-27,Jonathan Owen,http://jrowen.github.io/rhandsontable/,TRUE,https://github.com/jrowen/rhandsontable,296619,349,2021-12-10T05:01:57Z,849.9111747851003
rhino,A framework that supports creating and extending enterprise Shiny applications using best practices.,2022-04-19,Kamil Zyla,"https://appsilon.github.io/rhino/,
https://github.com/Appsilon/rhino",TRUE,https://github.com/appsilon/rhino,1967,71,2022-07-08T13:14:34Z,27.704225352112676
rhosa,"Higher-order spectra or polyspectra of time series, such as bispectrum and bicoherence, have been investigated in abundant literature and applied to problems of signal detection in a wide range of fields. This package aims to provide a simple API to estimate and analyze them. The current implementation is based on Brillinger and Irizarry (1998) <doi:10.1016/S0165-1684(97)00217-X> for estimating bispectrum or bicoherence, Lii and Helland (1981) <doi:10.1145/355958.355961> for cross-bispectrum, and Kim and Powers (1979) <doi:10.1109/TPS.1979.4317207> for cross-bicoherence.",2022-01-21,Takeshi Abe,https://tabe.github.io/rhosa/,TRUE,https://github.com/tabe/rhosa,10654,0,2022-02-04T07:20:48Z,NA
RHRT,Methods to scan RR interval data for Premature Ventricular Complexes (PVCs) and parameterise and plot the resulting Heart Rate Turbulence (HRT). The methodology of HRT analysis is based on the original publication by Schmidt et al. <doi:10.1016/S0140-6736(98)08428-1> and extended with suggestions from <doi:10.1088/1361-6579/ab98b3>.,2021-06-29,Valeria Blesius,NA,TRUE,https://github.com/vblesius/rhrt,4148,3,2021-10-14T09:59:40Z,1382.6666666666667
rhub,"Run 'R CMD check' on any of the 'R-hub' (<https://builder.r-hub.io/>)
    architectures, from the command line. The current architectures include
    'Windows', 'macOS', 'Solaris' and various 'Linux' distributions.",2019-04-08,Gábor Csárdi,"https://github.com/r-hub/rhub, https://r-hub.github.io/rhub/",TRUE,https://github.com/r-hub/rhub,498421,324,2021-12-05T09:43:28Z,1538.3364197530864
ribd,"Recursive algorithms for computing various relatedness
    coefficients, including pairwise kinship, kappa and identity
    coefficients. Both autosomal and X-linked coefficients are computed.
    Founders are allowed to be inbred, enabling construction of any given
    kappa coefficients (Vigeland (2020) <doi:10.1007/s00285-020-01505-x>).
    In addition to the standard pairwise coefficients, 'ribd' also
    computes a range of lesser-known coefficients, including generalised
    kinship coefficients (Karigl (1981)
    <doi:10.1111/j.1469-1809.1981.tb00341.x>; Weeks and Lange (1988)
    <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1715269>), two-locus
    coefficients (Thompson (1988) <doi:10.1093/imammb/5.4.261>) and
    multi-person coefficients. This package is part of the 'ped suite', a
    collection of packages for pedigree analysis in R. Several methods of
    'ribd' are featured in the online app 'QuickPed' available at
    <https://magnusdv.shinyapps.io/quickped>.",2022-04-16,Magnus Dehli Vigeland,"https://github.com/magnusdv/ribd,
https://magnusdv.github.io/pedsuite/",TRUE,https://github.com/magnusdv/ribd,15296,2,2022-06-06T07:38:34Z,7648
ricu,"Focused on (but not exclusive to) data sets hosted on PhysioNet
    (<https://physionet.org>), 'ricu' provides utilities for download, setup
    and access of intensive care unit (ICU) data sets. In addition to
    functions for running arbitrary queries against available data sets, a
    system for defining clinical concepts and encoding their representations
    in tabular ICU data is presented.",2022-04-26,Nicolas Bennett,"https://github.com/eth-mds/ricu, https://physionet.org",TRUE,https://github.com/eth-mds/ricu,7706,4,2022-04-26T06:03:28Z,1926.5
ridge,"Linear and logistic ridge regression functions. Additionally includes special functions for 
            genome-wide single-nucleotide polymorphism (SNP) data. More details can be found in
            <doi: 10.1002/gepi.21750> and <doi: 10.1186/1471-2105-12-372>.",2022-04-11,Steffen Moritz,https://github.com/SteffenMoritz/ridge,TRUE,https://github.com/steffenmoritz/ridge,93089,17,2022-04-11T10:15:30Z,5475.823529411765
riem,"Allows to get weather data from Automated Surface Observing
    System (ASOS) stations (airports) in the whole world thanks to the
    Iowa Environment Mesonet website.",2022-02-08,Maëlle Salmon,"https://docs.ropensci.org/riem/, https://github.com/ropensci/riem",TRUE,https://github.com/ropensci/riem,18295,38,2022-02-08T13:38:33Z,481.44736842105266
Riemann,"We provide a variety of algorithms for manifold-valued data, including Fréchet summaries, hypothesis testing, clustering, visualization, and other learning tasks. See Bhattacharya and Bhattacharya (2012) <doi:10.1017/CBO9781139094764> for general exposition to statistics on manifolds.",2022-02-28,Kisung You,https://kisungyou.com/Riemann/,TRUE,https://github.com/kisungyou/riemann,8496,6,2022-03-15T17:18:56Z,1416
RiemBase,"We provide a number of algorithms to estimate fundamental statistics including Fréchet mean and geometric median for manifold-valued data. Also, C++ header files are contained that implement elementary operations on manifolds such as Sphere, Grassmann, and others. See Bhattacharya and Bhattacharya (2012) <doi:10.1017/CBO9781139094764> if you are interested in statistics on manifolds, and Absil et al (2007, ISBN:9780691132983) on computational aspects of optimization on matrix manifolds.",2021-08-21,Kisung You,https://github.com/kisungyou/RiemBase,TRUE,https://github.com/kisungyou/riembase,13340,2,2021-08-21T04:20:08Z,6670
rigr,"A set of tools to streamline data analysis. Learning both R and introductory statistics at the same time can be challenging, and so we created 'rigr' to facilitate common data analysis tasks and enable learners to focus on statistical concepts. We provide easy-to-use interfaces for descriptive statistics, one- and two-sample inference, and regression analyses. 'rigr' output includes key information while omitting unnecessary details that can be confusing to beginners. Heteroscedasticity-robust (""sandwich"") standard errors are returned by default, and multiple partial F-tests and tests for contrasts are easy to specify. A single regression function can fit both linear and generalized linear models, allowing students to more easily make connections between different classes of models.",2022-06-08,Amy D Willis,NA,TRUE,https://github.com/statdivlab/rigr,4566,4,2021-12-09T17:51:03Z,1141.5
Rilostat,"Tools to download data from the ilostat database
    <https://ilostat.ilo.org> together with search and
    manipulation utilities.",2021-07-29,David Bescond,https://ilostat.github.io/Rilostat/,TRUE,https://github.com/ilostat/rilostat,22308,20,2021-07-29T11:25:10Z,1115.4
rim,"Provides an interface to the powerful and fairly complete computer algebra system maxima.
    It can be used to start and control 'Maxima' from within R by entering 'Maxima' commands. 
    It facilitates outputting results from 'Maxima' in 'LaTeX' and 'MathML'. 2D and 3D plots can be displayed directly. This package also registers a 'knitr'-engine 
    enabling 'Maxima' code chunks to be written in 'RMarkdown' documents.",2022-05-06,Eric Stemmler,https://rcst.github.io/rim/,TRUE,https://github.com/rcst/rim,6553,5,2022-05-06T09:30:24Z,1310.6
RInside,"C++ classes to embed R in C++ (and C) applications
 A C++ class providing the R interpreter is offered by this package
 making it easier to have ""R inside"" your C++ application. As R itself
 is embedded into your application, a shared library build of R is
 required. This works on Linux, OS X and even on Windows provided you
 use the same tools used to build R itself. Numerous examples are
 provided in the nine subdirectories of the examples/ directory of
 the installed package: standard, 'mpi' (for parallel computing), 'qt'
 (showing how to embed 'RInside' inside a Qt GUI application), 'wt'
 (showing how to build a ""web-application"" using the Wt toolkit),
 'armadillo' (for 'RInside' use with 'RcppArmadillo'), 'eigen' (for
 'RInside' use with 'RcppEigen'), and 'c_interface' for a basic C
 interface and 'Ruby' illustration.  The examples use 'GNUmakefile(s)'
 with GNU extensions, so a GNU make is required (and will use the
 'GNUmakefile' automatically). 'Doxygen'-generated documentation of
 the C++ classes is available at the 'RInside' website as well.",2022-04-01,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rinside/,
http://dirk.eddelbuettel.com/code/rinside.html",TRUE,https://github.com/eddelbuettel/rinside,37624,124,2022-04-01T19:48:54Z,303.4193548387097
rintrojs,"A wrapper for the 'Intro.js' library (For more info: <https://introjs.com/>). 
  This package makes it easy to include step-by-step introductions, and clickable hints in a 'Shiny' 
  application. It supports both static introductions in the UI, and programmatic introductions from 
  the server-side. ",2021-06-06,Carl Ganz,https://github.com/carlganz/rintrojs,TRUE,https://github.com/carlganz/rintrojs,105573,110,2021-09-13T18:39:37Z,959.7545454545455
rio,"Streamlined data import and export by making assumptions that
    the user is probably willing to make: 'import()' and 'export()' determine
    the data structure from the file extension, reasonable defaults are used for
    data import and export (e.g., 'stringsAsFactors=FALSE'), web-based import is
    natively supported (including from SSL/HTTPS), compressed files can be read
    directly without explicit decompression, and fast import packages are used where
    appropriate. An additional convenience function, 'convert()', provides a simple
    method for converting between file types.",2021-11-22,Thomas J. Leeper,https://github.com/leeper/rio,TRUE,https://github.com/leeper/rio,6188505,524,2021-11-07T20:46:14Z,11810.124045801527
riot,"An input-output interface for reading in and writing out common 
    VTK formats that store tractography data. This data comes in the form of 3D 
    polygons with possibly attributes at each point. These are obtained via 
    tracking algorithms from diffusion MRI and are a non-invasive way of 
    studying brain structural connectivity.",2022-05-10,Aymeric Stamm,https://github.com/astamm/riot,TRUE,https://github.com/astamm/riot,573,1,2022-06-23T16:26:06Z,573
ripserr,"Ports the Ripser <arXiv:1908.02518> and Cubical Ripser
        <arXiv:2005.12692> persistent homology calculation engines from
        C++. Can be used as a rapid calculation tool in topological
        data analysis pipelines.",2020-10-20,Raoul Wadhwa,https://rrrlw.github.io/ripserr/,TRUE,https://github.com/rrrlw/ripserr,6709,4,2022-07-09T18:48:49Z,1677.25
riskclustr,"A collection of functions related to the study of etiologic heterogeneity both across disease subtypes and across individual disease markers. The included functions allow one to quantify the extent of etiologic heterogeneity in the context of a case-control study, and provide p-values to test for etiologic heterogeneity across individual risk factors. Begg CB, Zabor EC, Bernstein JL, Bernstein L, Press MF, Seshan VE (2013) <doi:10.1002/sim.5902>.",2022-03-23,Emily C. Zabor,"http://www.emilyzabor.com/riskclustr/,
https://github.com/zabore/riskclustr",TRUE,https://github.com/zabore/riskclustr,11184,1,2022-03-22T18:14:36Z,11184
riskmetric,"Facilities for assessing R packages against a number of metrics to 
    help quantify their robustness.",2022-01-28,Eli Miller,"https://pharmar.github.io/riskmetric/,
https://github.com/pharmaR/riskmetric",TRUE,https://github.com/pharmar/riskmetric,3620,114,2022-03-02T17:37:54Z,31.75438596491228
riskParityPortfolio,"Fast design of risk parity portfolios for financial investment.
    The goal of the risk parity portfolio formulation is to equalize or distribute
    the risk contributions of the different assets, which is missing if we simply
    consider the overall volatility of the portfolio as in the mean-variance
    Markowitz portfolio. In addition to the vanilla formulation, where the risk
    contributions are perfectly equalized subject to no shortselling and budget
    constraints, many other formulations are considered that allow for box
    constraints and shortselling, as well as the inclusion of additional
    objectives like the expected return and overall variance. See vignette for
    a detailed documentation and comparison, with several illustrative examples.
    The package is based on the papers:
    Y. Feng, and D. P. Palomar (2015). SCRIP: Successive Convex Optimization Methods
    for Risk Parity Portfolio Design. IEEE Trans. on Signal Processing, vol. 63,
    no. 19, pp. 5285-5300. <doi:10.1109/TSP.2015.2452219>.
    F. Spinu (2013), An Algorithm for Computing Risk Parity Weights.
    <doi:10.2139/ssrn.2297383>.
    T. Griveau-Billion, J. Richard, and T. Roncalli (2013). A fast algorithm for computing
    High-dimensional risk parity portfolios. <arXiv:1311.4057>.",2021-06-01,Daniel P. Palomar,"https://CRAN.R-project.org/package=riskParityPortfolio,
https://github.com/dppalomar/riskParityPortfolio,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2015.2452219",TRUE,https://github.com/dppalomar/riskparityportfolio,26699,85,2022-02-10T14:56:22Z,314.1058823529412
riskRegression,"Implementation of the following methods for event history analysis.
    Risk regression models for survival endpoints also in the presence of competing
    risks are fitted using binomial regression based on a time sequence of binary
    event status variables. A formula interface for the Fine-Gray regression model
    and an interface for the combination of cause-specific Cox regression models.
    A toolbox for assessing and comparing performance of risk predictions (risk
    markers and risk prediction models). Prediction performance is measured by the
    Brier score and the area under the ROC curve for binary possibly time-dependent
    outcome. Inverse probability of censoring weighting and pseudo values are used
    to deal with right censored data. Lists of risk markers and lists of risk models
    are assessed simultaneously. Cross-validation repeatedly splits the data, trains
    the risk prediction models on one part of each split and then summarizes and
    compares the performance across splits.",2022-03-23,Thomas Alexander Gerds,https://github.com/tagteam/riskRegression,TRUE,https://github.com/tagteam/riskregression,204454,29,2022-07-07T15:33:46Z,7050.137931034483
riskyr,"Risk-related information (like the prevalence of conditions, the sensitivity and specificity of diagnostic tests, or the effectiveness of interventions or treatments) can be expressed in terms of frequencies or probabilities. By providing a toolbox of corresponding metrics and representations, 'riskyr' computes, translates, and visualizes risk-related information in a variety of ways. Adopting multiple complementary perspectives provides insights into the interplay between key parameters and renders teaching and training programs on risk literacy more transparent. ",2021-03-23,Hansjoerg Neth,"https://CRAN.R-project.org/package=riskyr,
https://github.com/hneth/riskyr/",TRUE,https://github.com/hneth/riskyr,12302,12,2022-06-01T07:19:43Z,1025.1666666666667
riverdist,"Reads river network shape files and computes network distances.
    Also included are a variety of computation and graphical tools designed 
    for fisheries telemetry research, such as minimum home range, kernel density 
    estimation, and clustering analysis using empirical k-functions with 
    a bootstrap envelope.  Tools are also provided for editing the river 
    networks, meaning there is no reliance on external software.",2022-01-04,Matt Tyers,https://cran.r-project.org/package=riverdist,TRUE,https://github.com/mbtyers/riverdist,19440,14,2022-01-04T13:55:34Z,1388.5714285714287
rJava,"Low-level interface to Java VM very much like .C/.Call and friends. Allows creation of objects, calling methods and accessing fields.",2021-12-10,Simon Urbanek,http://www.rforge.net/rJava/,TRUE,https://github.com/s-u/rjava,7848564,213,2022-04-29T01:17:39Z,36847.718309859156
RJDemetra,"Interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>), the seasonal adjustment software officially
    recommended to the members of the European Statistical System (ESS) and the European System of Central Banks.
    It offers full access to all options and outputs of 'JDemetra+', including the two leading seasonal adjustment methods
    TRAMO/SEATS+ and X-12ARIMA/X-13ARIMA-SEATS.",2022-03-23,Alain Quartier-la-Tente,https://github.com/jdemetra/rjdemetra,TRUE,https://github.com/jdemetra/rjdemetra,29863,37,2022-03-24T18:57:59Z,807.1081081081081
rjdmarkdown,"Functions to have nice 'rmarkdown' outputs of the 
  seasonal and trading day adjustment models made with 'RJDemetra'.",2020-10-01,Alain Quartier-la-Tente,https://github.com/AQLT/rjdmarkdown,TRUE,https://github.com/aqlt/rjdmarkdown,8639,4,2021-10-09T13:50:25Z,2159.75
rjdqa,"Add-in to the 'RJDemetra' package on seasonal adjustments.
    It allows to produce quality assessments outputs (dashboards, quality report matrix, etc.).",2020-08-06,Alain Quartier-la-Tente,https://github.com/AQLT/rjdqa,TRUE,https://github.com/aqlt/rjdqa,11816,1,2021-10-09T13:46:27Z,11816
rjson,Converts R object into JSON objects and vice-versa.,2022-01-09,Alex Couture-Beil,https://github.com/alexcb/rjson,TRUE,https://github.com/alexcb/rjson,6431927,16,2022-01-08T19:35:15Z,401995.4375
rjstat,"Handle 'JSON-stat' format (<https://json-stat.org>) in R.
    Not all features are supported, especially the extensive metadata
    features of 'JSON-stat'.",2022-03-17,Aaron Schumacher,https://github.com/ajschumacher/rjstat,TRUE,https://github.com/ajschumacher/rjstat,21585,29,2022-03-17T18:49:03Z,744.3103448275862
rjwsacruncher,"'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>) is the seasonal adjustment software officially recommended
  to the members of the European Statistical System and the European System of Central Banks. Seasonal adjustment models performed
  with 'JDemetra+' can be stored into workspaces. 'JWSACruncher' (<https://github.com/jdemetra/jwsacruncher/releases>) is a console tool that 
  re-estimates all the multi-processing defined in a workspace and to export the result. 'rjwsacruncher' allows to launch easily the 'JWSACruncher'.",2021-09-11,Alain Quartier-la-Tente,https://github.com/AQLT/rjwsacruncher,TRUE,https://github.com/aqlt/rjwsacruncher,11661,3,2021-09-11T08:50:07Z,3887
rkeops,"The 'KeOps' library lets you compute generic reductions of very 
    large arrays whose entries are given by a mathematical formula with CPU and 
    GPU computing support. It combines a tiled reduction scheme with an 
    automatic differentiation engine. It is perfectly suited to the efficient 
    computation of Kernel dot products and the associated gradients, even when 
    the full kernel matrix does not fit into the GPU memory.",2021-02-17,Benjamin Charlier,"https://www.kernel-operations.io/,
https://github.com/getkeops/keops/",TRUE,https://github.com/getkeops/keops,80921,723,2022-07-07T22:20:31Z,111.92392807745505
rKolada,"Methods for downloading and processing data and metadata from 'Kolada', the official Swedish regions and municipalities database <https://kolada.se/>.",2022-03-10,Love Hansson,"https://lchansson.github.io/rKolada/,
https://github.com/lchansson/rKolada",TRUE,https://github.com/lchansson/rkolada,6656,2,2022-03-16T09:53:44Z,3328
RKorAPClient,"A client package that makes the 'KorAP' web service API accessible from R.
  The corpus analysis platform 'KorAP' has been developed as a scientific tool to make
  potentially large, stratified and multiply annotated corpora, such as the 'German Reference Corpus DeReKo'
  or the 'Corpus of the Contemporary Romanian Language CoRoLa', accessible for linguists to let them verify
  hypotheses and to find interesting patterns in real language use.
  The 'RKorAPClient' package provides access to 'KorAP' and the corpora behind it for user-created R code,
  as a programmatic alternative to the 'KorAP' web user-interface.
  You can learn more about 'KorAP' and use it directly on 'DeReKo' at <https://korap.ids-mannheim.de/>.",2022-03-01,Marc Kupietz,"https://github.com/KorAP/RKorAPClient/,
https://korap.ids-mannheim.de/,
https://www.ids-mannheim.de/digspra/kl/projekte/korap",TRUE,https://github.com/korap/rkorapclient,13095,5,2022-06-30T14:23:01Z,2619
rlang,"A toolbox for working with base types, core R features
  like the condition system, and core 'Tidyverse' features like tidy
  evaluation.",2022-06-27,Lionel Henry,"https://rlang.r-lib.org, https://github.com/r-lib/rlang",TRUE,https://github.com/r-lib/rlang,58052222,393,2022-07-08T06:15:03Z,147715.57760814248
rlas,Read and write 'las' and 'laz' binary file formats. The LAS file format is a public file format for the interchange of 3-dimensional point cloud data between data users. The LAS specifications are approved by the American Society for Photogrammetry and Remote Sensing <https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities>. The LAZ file format is an open and lossless compression scheme for binary LAS format versions 1.0 to 1.4 <https://laszip.org/>.,2022-05-26,Jean-Romain Roussel,https://github.com/r-lidar/rlas,TRUE,https://github.com/r-lidar/rlas,71513,25,2022-05-26T14:24:53Z,2860.52
rlemon,"Allows easy access to the LEMON Graph Library set of algorithms, written in C++.
             See the LEMON project page at <https://lemon.cs.elte.hu/trac/lemon>.
             Current LEMON version is 1.3.1.",2022-04-15,Josh Errickson,https://errickson.net/rlemon/,TRUE,https://github.com/josherrickson/rlemon,27883,7,2022-05-27T18:54:49Z,3983.285714285714
Rlgt,"An implementation of a number of Global Trend models for time series forecasting 
    that are Bayesian generalizations and extensions of some Exponential Smoothing models. 
    The main differences/additions include 1) nonlinear global trend, 2) Student-t error 
    distribution, and 3) a function for the error size, so heteroscedasticity. The methods 
    are particularly useful for short time series. When tested on the well-known M3 dataset,
    they are able to outperform all classical time series algorithms. The models are fitted 
    with MCMC using the 'rstan' package.",2022-05-17,Christoph Bergmeir,https://github.com/cbergmeir/Rlgt,TRUE,https://github.com/cbergmeir/rlgt,14529,17,2022-06-20T04:40:33Z,854.6470588235294
Rlibeemd,"An R interface for libeemd (Luukko, Helske, Räsänen, 2016) <doi:10.1007/s00180-015-0603-9>, 
    a C library of highly efficient parallelizable functions  for performing the ensemble empirical mode decomposition (EEMD), 
    its complete variant (CEEMDAN), the regular empirical mode decomposition (EMD), and bivariate EMD (BEMD). 
    Due to the possible portability issues CRAN version no longer supports OpenMP, you can install OpenMP-supported version 
    from GitHub: <https://github.com/helske/Rlibeemd/>.",2021-10-07,Jouni Helske  (R interface,NA,TRUE,https://github.com/helske/rlibeemd,37985,28,2021-10-06T22:10:45Z,1356.607142857143
rLiDAR,"Set of tools for reading, processing and visualizing small set of
    LiDAR (Light Detection and Ranging) data for forest inventory applications.
    More details were published in Silva et al. (2016) <doi:10.1080/07038992.2016.1196582>.",2021-10-05,Carlos Alberto Silva,https://github.com/carlos-alberto-silva/rLiDAR,TRUE,https://github.com/carlos-alberto-silva/rlidar,16332,6,2021-10-04T19:38:20Z,2722
rliger,"Uses an extension of nonnegative matrix factorization to identify shared and dataset-specific factors. See Welch J, Kozareva V, et al (2019) <doi:10.1016/j.cell.2019.05.006>, and Liu J, Gao C, Sodicoff J, et al (2020) <doi:10.1038/s41596-020-0391-8> for more details.",2021-04-19,Joshua Welch,https://github.com/welch-lab/liger,TRUE,https://github.com/welch-lab/liger,11372,264,2022-04-29T13:29:46Z,43.07575757575758
rlist,"Provides a set of functions for data manipulation with
    list objects, including mapping, filtering, grouping, sorting,
    updating, searching, and other useful functions. Most functions
    are designed to be pipeline friendly so that data processing with
    lists can be chained.",2021-09-03,Kun Ren,"https://renkun-ken.github.io/rlist/,
https://github.com/renkun-ken/rlist,
https://renkun-ken.github.io/rlist-tutorial/",TRUE,https://github.com/renkun-ken/rlist,3946269,172,2022-06-12T14:48:10Z,22943.424418604653
rlog,"A very lightweight package that writes out log messages in an opinionated way.
  Simpler and lighter than other logging packages, 'rlog' provides a compact feature set that
  focuses on getting the job done in a Unix-like way.",2021-02-24,Mark Sellors,https://github.com/sellorm/rlog,TRUE,https://github.com/sellorm/rlog,6202,14,2021-09-30T17:45:04Z,443
RLRsim,"Rapid, simulation-based exact (restricted) likelihood ratio tests
    for testing the presence of variance components/nonparametric terms for
    models fit with nlme::lme(),lme4::lmer(), lmeTest::lmer(), gamm4::gamm4(),
    mgcv::gamm() and SemiPar::spm().",2022-03-16,Fabian Scheipl,https://github.com/fabian-s/RLRsim,TRUE,https://github.com/fabian-s/rlrsim,156305,10,2022-03-15T16:23:33Z,15630.5
RLumCarlo,"A collection of functions to simulate luminescence production in 
    dosimetric materials using Monte Carlo methods. Implemented are models for 
    delocalised transitions (e.g., Chen and McKeever (1997) <doi:10.1142/2781>), 
    localised transitions (e.g., Pagonis et al. (2019) <doi:10.1016/j.jlumin.2018.11.024>) 
    and tunnelling transitions (Jain et al. (2012) <doi:10.1088/0953-8984/24/38/385402> 
    and Pagonis et al. (2019) <doi:10.1016/j.jlumin.2018.11.024>). 
    Supported stimulation methods are thermal luminescence (TL), 
    continuous-wave optically stimulated luminescence (CW-OSL), 
    linearly-modulated optically stimulated luminescence (LM-OSL), 
    linearly-modulated infrared stimulated luminescence (LM-IRSL),
    and isothermal luminescence (ITL or ISO-TL).",2022-02-21,Johannes Friedrich,https://CRAN.R-project.org/package=RLumCarlo,TRUE,https://github.com/r-lum/rlumcarlo,8651,1,2022-02-21T10:15:08Z,8651
RLumModel,A collection of functions to simulate luminescence signals in quartz and Al2O3 based on published models.,2022-02-22,Johannes Friedrich,https://CRAN.R-project.org/package=RLumModel,TRUE,https://github.com/r-lum/rlummodel,17411,3,2022-02-20T21:39:08Z,5803.666666666667
RLumShiny,"A collection of 'shiny' applications for the R package
    'Luminescence'. These mainly, but not exclusively, include applications for
    plotting chronometric data from e.g. luminescence or radiocarbon dating. It
    further provides access to bootstraps tooltip and popover functionality and
    contains the 'jscolor.js' library with a custom 'shiny' output binding.",2022-01-31,Christoph Burow,https://tzerk.github.io/RLumShiny/,TRUE,https://github.com/tzerk/rlumshiny,22360,7,2022-01-29T14:52:49Z,3194.285714285714
rly,R implementation of the common parsing tools 'lex' and 'yacc'.,2022-05-08,Marek Jagielski,https://github.com/systemincloud/rly,TRUE,https://github.com/systemincloud/rly,22295,34,2022-05-08T12:42:26Z,655.7352941176471
rmangal,An interface to the 'Mangal' database - a collection of ecological networks. This package includes functions to work with the 'Mangal RESTful API' methods (<https://mangal-interactions.github.io/mangal-api/>).,2022-05-16,Steve Vissault,"https://docs.ropensci.org/rmangal/, https://mangal.io,
https://github.com/ropensci/rmangal",TRUE,https://github.com/ropensci/rmangal,7483,11,2022-05-16T01:00:35Z,680.2727272727273
rmapshaper,"Edit and simplify 'geojson', 'Spatial', and 'sf'
    objects.  This is wrapper around the 'mapshaper' 'JavaScript' library
    by Matthew Bloch <https://github.com/mbloch/mapshaper/> to perform
    topologically-aware polygon simplification, as well as other
    operations such as clipping, erasing, dissolving, and converting
    'multi-part' to 'single-part' geometries.  It relies on the
    'geojsonio' package for working with 'geojson' objects, the 'sf'
    package for working with 'sf' objects, and the 'sp' and 'rgdal'
    packages for working with 'Spatial' objects.",2022-05-10,Andy Teucher,https://github.com/ateucher/rmapshaper,TRUE,https://github.com/ateucher/rmapshaper,217586,160,2022-05-11T00:07:38Z,1359.9125
RMariaDB,"Implements a DBI-compliant interface to MariaDB
    (<https://mariadb.org/>) and MySQL (<https://www.mysql.com/>)
    databases.",2022-06-19,Kirill Müller,"https://rmariadb.r-dbi.org, https://github.com/r-dbi/RMariaDB,
https://downloads.mariadb.org/connector-c/",TRUE,https://github.com/r-dbi/rmariadb,1541073,106,2022-06-19T04:57:06Z,14538.424528301886
rmarkdown,Convert R Markdown documents into a variety of formats.,2022-04-25,Yihui Xie,"https://github.com/rstudio/rmarkdown,
https://pkgs.rstudio.com/rmarkdown/",TRUE,https://github.com/rstudio/rmarkdown,23338424,2472,2022-06-22T16:12:37Z,9441.11003236246
rmatio,"Read and write 'Matlab' MAT files from R. The 'rmatio'
    package supports reading MAT version 4, MAT version 5 and MAT
    compressed version 5. The 'rmatio' package can write version 5 MAT
    files and version 5 files with variable compression.",2021-10-27,Stefan Widgren,https://github.com/stewid/rmatio,TRUE,https://github.com/stewid/rmatio,102456,9,2021-10-27T16:18:10Z,11384
RMAWGEN,"S3 and S4 functions are implemented for spatial multi-site
    stochastic generation of daily time series of temperature and
    precipitation. These tools make use of Vector AutoRegressive models (VARs).
    The weather generator model is then saved as an object and is calibrated by
    daily instrumental ""Gaussianized"" time series through the 'vars' package
    tools. Once obtained this model, it can it can be used for weather
    generations and be adapted to work with several climatic monthly time
    series.",2019-12-12,Emanuele Cordano,"https://github.com/ecor/RMAWGEN,
https://docs.google.com/file/d/0B66otCUk3Bv6V3RPbm1mUG4zVHc/edit,
http://presentations.copernicus.org/EGU2012-14026_presentation.pdf,
http://presentations.copernicus.org/EGU2012-5404_presentation.pdf",TRUE,https://github.com/ecor/rmawgen,27365,1,2021-08-18T07:22:32Z,27365
rmBayes,"A Bayesian credible interval is interpreted with respect to posterior probability, 
    and this interpretation is far more intuitive than that of a frequentist confidence interval. 
    However, standard highest-density intervals can be wide due to between-subjects variability and tends 
    to hide within-subjects effects, rendering its relationship with the Bayes factor less clear 
    in within-subjects (repeated-measures) designs. 
    This urgent issue can be addressed by using within-subjects intervals in within-subjects designs.",2021-09-15,Zhengxiao Wei,https://github.com/zhengxiaoUVic/rmBayes,TRUE,https://github.com/zhengxiaouvic/rmbayes,2640,0,2022-01-19T22:23:06Z,NA
rmdcev,"Estimates and simulates Kuhn-Tucker demand models with individual heterogeneity. The package implements the multiple-discrete continuous extreme value (MDCEV) model and the Kuhn-Tucker specification common in the environmental economics literature on recreation demand. Latent class and random parameters specifications can be implemented and the models are fit using maximum likelihood estimation or Bayesian estimation. All models are implemented in Stan, which is a C++ package for performing full Bayesian inference (see Stan Development Team, 2019) <https://mc-stan.org/>. The package also implements demand forecasting (Pinjari and Bhat (2011) <https://repositories.lib.utexas.edu/handle/2152/23880>) and welfare calculation (Lloyd-Smith (2018) <doi:10.1016/j.jocm.2017.12.002>) for policy simulation.",2020-09-30,Patrick Lloyd-Smith,https://github.com/plloydsmith/rmdcev,TRUE,https://github.com/plloydsmith/rmdcev,13104,8,2021-09-24T14:28:02Z,1638
rmdformats,"HTML formats and templates for 'rmarkdown' documents, with some extra
    features such as automatic table of contents, lightboxed figures, dynamic
    crosstab helper.",2022-05-17,Julien Barnier,https://github.com/juba/rmdformats,TRUE,https://github.com/juba/rmdformats,148677,646,2022-06-28T12:08:36Z,230.1501547987616
rMEA,"A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Kleinbub, J. R., & Ramseyer, F. T. (2020). rMEA: An R package to assess nonverbal synchronization in motion energy analysis time-series. Psychotherapy research, 1-14. <doi:10.1080/10503307.2020.1844334>.",2022-02-17,Johann R. Kleinbub,https://github.com/kleinbub/rMEA https://psync.ch,TRUE,https://github.com/kleinbub/rmea,20021,8,2022-02-17T17:18:11Z,2502.625
rmgarch,"Feasible multivariate GARCH models including DCC, GO-GARCH and Copula-GARCH.",2022-02-05,Alexios Galanos,"http://www.unstarched.net, https://github.com/alexiosg/rmgarch",TRUE,https://github.com/alexiosg/rmgarch,564830,2,2022-03-05T23:37:39Z,282415
rMIDAS,"A tool for multiply imputing missing data using 'MIDAS', a deep learning method based on denoising autoencoder neural networks. This algorithm offers significant accuracy and efficiency advantages over other multiple imputation strategies, particularly when applied to large datasets with complex features. Alongside interfacing with 'Python' to run the core algorithm, this package contains functions for processing data before and after model training, running imputation model diagnostics, generating multiple completed datasets, and estimating regression models on these datasets.",2022-06-20,Thomas Robinson,https://github.com/MIDASverse/rMIDAS,TRUE,https://github.com/midasverse/rmidas,8099,20,2022-06-25T09:57:47Z,404.95
rminizinc,"Constraint optimization, or constraint programming, is the name given to identifying
  feasible solutions out of a very large set of candidates, where the problem can be modeled in terms 
  of arbitrary constraints. 'MiniZinc' is a free and open-source constraint modeling language. 
  Constraint satisfaction and discrete optimization problems can be formulated in a high-level 
  modeling language. Models are compiled into an intermediate representation that is understood by a
  wide range of solvers. 'MiniZinc' itself provides several solvers, for instance 'GeCode'. R users 
  can use the package to solve constraint programming problems without using 'MiniZinc' directly, 
  modify existing 'MiniZinc' models and also create their own models.",2021-10-15,Akshit Achara,https://github.com/acharaakshit/RMiniZinc,TRUE,https://github.com/acharaakshit/rminizinc,8314,10,2021-10-17T23:20:43Z,831.4
rmio,"Provides header files of 'mio', a cross-platform C++11 header-only 
    library for memory mapped file IO <https://github.com/mandreyel/mio>.",2022-02-17,Florian Privé,https://github.com/privefl/rmio,TRUE,https://github.com/privefl/rmio,68820,4,2022-02-16T18:46:41Z,17205
Rmixmod,"Interface of 'MIXMOD' software for supervised, unsupervised and
    semi-supervised classification with mixture modelling.",2021-11-24,Quentin Grimonprez,NA,TRUE,https://github.com/mixmod/mixmod,55398,0,2022-07-04T13:36:16Z,NA
RMixtComp,"Mixture Composer <https://github.com/modal-inria/MixtComp> is a project to build mixture models with
    heterogeneous data sets and partially missing data management. 
    It includes 8 models for real, categorical, counting, functional and ranking data.",2021-03-29,Vincent Kubicki,https://github.com/modal-inria/MixtComp,TRUE,https://github.com/modal-inria/mixtcomp,13638,8,2022-01-14T12:42:20Z,1704.75
RMixtCompIO,"Mixture Composer <https://github.com/modal-inria/MixtComp> is a project to build mixture models with
    heterogeneous data sets and partially missing data management.
    It includes models for real, categorical, counting, functional and ranking data.
    This package contains the minimal R interface of the C++ 'MixtComp' library.",2022-01-17,Quentin Grimonprez,https://github.com/modal-inria/MixtComp,TRUE,https://github.com/modal-inria/mixtcomp,13937,8,2022-01-14T12:42:20Z,1742.125
RMixtCompUtilities,"Mixture Composer <https://github.com/modal-inria/MixtComp> is a project to build mixture models with
    heterogeneous data sets and partially missing data management. This package contains graphical, getter and some utility 
    functions to facilitate the analysis of 'MixtComp' output.",2020-11-13,Vincent Kubicki,"https://github.com/modal-inria/MixtComp,
https://massiccc.lille.inria.fr/",TRUE,https://github.com/modal-inria/mixtcomp,13687,8,2022-01-14T12:42:20Z,1710.875
RMOA,"Connect R with MOA (Massive Online Analysis -
    <https://moa.cms.waikato.ac.nz>) to build classification models and
    regression models on streaming data or out-of-RAM data.
    Also streaming recommendation models are made available.",2021-09-27,Jan Wijffels,"http://www.bnosac.be, https://github.com/jwijffels/RMOA,
https://moa.cms.waikato.ac.nz/",TRUE,https://github.com/jwijffels/rmoa,14224,34,2021-09-23T22:01:40Z,418.3529411764706
RMOAjars,"External jars required for package RMOA. RMOA is a framework to
    build data stream models on top of MOA (Massive Online Analysis -
    <http://moa.cms.waikato.ac.nz>). The jar files are put in this R package, the modelling logic can be found in the RMOA package.",2018-09-22,See file AUTHORS,"http://moa.cms.waikato.ac.nz/, https://github.com/jwijffels/RMOA",TRUE,https://github.com/jwijffels/rmoa,15476,34,2021-09-23T22:01:40Z,455.1764705882353
rmoo,"A multiobjective optimization package based on K. Deb's 
    algorithm and inspired in 'GA' package by Luca Scrucca (2017) <DOI:10.32614/RJ-2017-008>. 
    The 'rmoo' package is a framework for multi- and many-objective optimization, 
    allowing to work with representation of real numbers, permutations and 
    binaries, offering a high range of configurations.",2021-09-07,Francisco Benitez,https://github.com/Evolutionary-Optimization-Laboratory/rmoo/,TRUE,https://github.com/evolutionary-optimization-laboratory/rmoo,7946,18,2021-12-12T22:32:56Z,441.44444444444446
rms,"Regression modeling, testing, estimation, validation,
	graphics, prediction, and typesetting by storing enhanced model design
	attributes in the fit.  'rms' is a collection of functions that
	assist with and streamline modeling.  It also contains functions for
	binary and ordinal logistic regression models, ordinal models for
  continuous Y with a variety of distribution families, and the Buckley-James
	multiple regression model for right-censored responses, and implements
	penalized maximum likelihood estimation for logistic and ordinary
	linear models.  'rms' works with almost any regression model, but it
	was especially written to work with binary or ordinal regression
	models, Cox regression, accelerated failure time models,
	ordinary linear models,	the Buckley-James model, generalized least
	squares for serially or spatially correlated observations, generalized
	linear models, and quantile regression.",2022-04-22,Frank E Harrell Jr,"https://hbiostat.org/R/rms/, https://github.com/harrelfe/rms",TRUE,https://github.com/harrelfe/rms,1038170,130,2022-06-06T17:17:47Z,7985.923076923077
RMTstat,"
    Functions for working with the Tracy-Widom laws and other distributions 
    related to the eigenvalues of large Wishart matrices.
    The tables for computing the Tracy-Widom densities and distribution
    functions were computed by functions were computed by Momar Dieng's MATLAB package ""RMLab"". This package is part of a collaboration between Iain Johnstone, Zongming Ma, Patrick Perry, and Morteza Shahram.",2022-04-12,Iain M. Johnstone,https://github.com/evanbiederstedt/RMTstat,TRUE,https://github.com/evanbiederstedt/rmtstat,35773,5,2022-04-12T20:40:39Z,7154.6
rmumps,"Some basic features of 'MUMPS' (Multifrontal Massively Parallel
         sparse direct Solver) are wrapped in a class whose methods can be used
         for sequentially solving a sparse linear system (symmetric or not)
         with one or many right hand sides (dense or sparse).
         There is a possibility to do separately symbolic analysis,
         LU (or LDL^t) factorization and system solving.
         Third part ordering libraries are included and can be used: 'PORD', 'METIS', 'SCOTCH'.
         'MUMPS' method was first described in Amestoy et al. (2001) <doi:10.1137/S0895479899358194>
         and Amestoy et al. (2006) <doi:10.1016/j.parco.2005.07.004>.",2022-03-25,Serguei Sokol,"http://mumps.enseeiht.fr/, https://github.com/sgsokol/rmumps/",TRUE,https://github.com/sgsokol/rmumps,23245,9,2021-08-11T10:37:23Z,2582.777777777778
rmutil,"A toolkit of functions for nonlinear regression and repeated
    measurements not to be used by itself but called by other Lindsey packages such
    as 'gnlm', 'stable', 'growth', 'repeated', and 'event' 
    (available at <https://www.commanster.eu/rcode.html>).",2022-03-01,Bruce Swihart,https://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/rmutil,376577,1,2022-03-01T14:14:11Z,376577
rMVP,"A memory-efficient, visualize-enhanced, parallel-accelerated Genome-Wide Association Study (GWAS) tool. It can
    (1) effectively process large data, 
    (2) rapidly evaluate population structure, 
    (3) efficiently estimate variance components several algorithms, 
    (4) implement parallel-accelerated association tests of markers three methods, 
    (5) globally efficient design on GWAS process computing, 
    (6) enhance visualization of related information. 
    'rMVP' contains three models GLM (Alkes Price (2006) <DOI:10.1038/ng1847>), MLM (Jianming Yu (2006) <DOI:10.1038/ng1702>) 
    and FarmCPU (Xiaolei Liu (2016) <doi:10.1371/journal.pgen.1005767>); variance components estimation methods EMMAX 
    (Hyunmin Kang (2008) <DOI:10.1534/genetics.107.080101>;), FaSTLMM (method: Christoph Lippert (2011) <DOI:10.1038/nmeth.1681>, 
    R implementation from 'GAPIT2': You Tang and Xiaolei Liu (2016) <DOI:10.1371/journal.pone.0107684> and 
    'SUPER': Qishan Wang and Feng Tian (2014) <DOI:10.1371/journal.pone.0107684>), and HE regression 
    (Xiang Zhou (2017) <DOI:10.1214/17-AOAS1052>).",2021-04-18,Xiaolei Liu,https://github.com/xiaolei-lab/rMVP,TRUE,https://github.com/xiaolei-lab/rmvp,17768,175,2022-07-05T11:11:39Z,101.53142857142858
rmweather,"An integrated set of tools to allow data users to conduct 
    meteorological normalisation on air quality data. This meteorological 
    normalisation technique uses predictive random forest models to remove 
    variation of pollutant concentrations so trends and interventions can be 
    explored in a robust way. For examples, see Grange et al. (2018) 
    <doi:10.5194/acp-18-6223-2018> and Grange and Carslaw (2019) 
    <doi:10.1016/j.scitotenv.2018.10.344>.",2020-06-15,Stuart K. Grange,https://github.com/skgrange/rmweather,TRUE,https://github.com/skgrange/rmweather,13939,31,2022-06-21T15:34:45Z,449.64516129032256
RMySQL,"Legacy 'DBI' interface to 'MySQL' / 'MariaDB' based on old code
    ported from S-PLUS. A modern 'MySQL' client based on 'Rcpp' is available 
    from the 'RMariaDB' package.",2021-12-14,Jeroen Ooms,https://downloads.mariadb.org/connector-c/ (upstream),TRUE,https://github.com/r-dbi/rmysql,3914308,196,2021-12-15T10:53:13Z,19970.95918367347
rnaturalearth,Facilitates mapping by making natural earth map data from <http://www.naturalearthdata.com/> more easily available to R users.,2017-03-21,Andy South,https://github.com/ropenscilabs/rnaturalearth,TRUE,https://github.com/ropenscilabs/rnaturalearth,316531,150,2021-10-11T20:38:53Z,2110.2066666666665
rncl,"An interface to the Nexus Class Library which allows parsing
    of NEXUS, Newick and other phylogenetic tree file formats. It provides
    elements of the file that can be used to build phylogenetic objects
    such as ape's 'phylo' or phylobase's 'phylo4(d)'. This functionality
    is demonstrated with 'read_newick_phylo()' and 'read_nexus_phylo()'.",2022-03-18,Francois Michonneau,https://github.com/fmichonneau/rncl,TRUE,https://github.com/fmichonneau/rncl,211346,8,2022-03-22T16:48:33Z,26418.25
RNeXML,"Provides access to phyloinformatic data in 'NeXML' format.  The
    package should add new functionality to R such as the possibility to
    manipulate 'NeXML' objects in more various and refined way and compatibility
    with 'ape' objects.",2022-05-13,Carl Boettiger,"https://docs.ropensci.org/RNeXML/,
https://github.com/ropensci/RNeXML",TRUE,https://github.com/ropensci/rnexml,131172,12,2022-05-11T21:00:33Z,10931
rngtools,"Provides a set of functions for working with
    Random Number Generators (RNGs). In particular, a generic
    S4 framework is defined for getting/setting the current RNG, or RNG data
    that are embedded into objects for reproducibility.
    Notably, convenient default methods greatly facilitate the way current
    RNG settings can be changed.",2021-09-20,Renaud Gaujoux,https://renozao.github.io/rngtools/,TRUE,https://github.com/renozao/rngtools,769449,6,2021-09-24T06:52:08Z,128241.5
RNHANES,"Tools for downloading and analyzing CDC NHANES data, with a focus
    on analytical laboratory data.",2016-11-29,Herb Susmann,http://github.com/silentspringinstitute/RNHANES,TRUE,https://github.com/silentspringinstitute/rnhanes,20603,29,2021-09-30T15:23:08Z,710.448275862069
RNifti,"Provides very fast read and write access to images stored in the
    NIfTI-1, NIfTI-2 and ANALYZE-7.5 formats, with seamless synchronisation
    of in-memory image objects between compiled C and interpreted R code. Also
    provides a simple image viewer, and a C/C++ API that can be used by other
    packages. Not to be confused with 'RNiftyReg', which performs image
    registration and applies spatial transformations.",2022-07-01,Jon Clayden,https://github.com/jonclayden/RNifti,TRUE,https://github.com/jonclayden/rnifti,84112,33,2022-07-01T14:06:27Z,2548.848484848485
rnmamod,"A comprehensive suite of functions to perform and visualise 
    pairwise and network meta-analysis with aggregate binary or continuous
    missing participant outcome data. The package covers core Bayesian one-stage
    models implemented in a systematic review with multiple interventions, 
    including fixed-effect and random-effects network meta-analysis, 
    meta-regression, evaluation of the consistency assumption via the 
    node-splitting approach and the unrelated mean effects model, and 
    sensitivity analysis. Missing participant outcome data are addressed in all 
    models of the package. The package also offers a rich, user-friendly 
    visualisation toolkit that aids in appraising and interpreting the results 
    thoroughly and preparing the manuscript for journal submission. 
    The visualisation tools comprise the network plot, forest plots, panel of 
    diagnostic plots, heatmaps on the extent of missing participant outcome data
    in the network, league heatmaps on estimation and prediction, rankograms, 
    Bland-Altman plot, leverage plot, deviance scatterplot, heatmap of 
    robustness, and barplot of Kullback-Leibler divergence. The package also 
    allows the user to export the results to an Excel file at the working 
    directory.",2022-04-06,Loukia Spineli,https://github.com/LoukiaSpin/rnmamod,TRUE,https://github.com/loukiaspin/rnmamod,1855,2,2022-07-05T21:12:36Z,927.5
Rnmr1D,Perform the complete processing of a set of proton nuclear magnetic resonance spectra from the free induction decay (raw data) and based on a processing sequence (macro-command file). An additional file specifies all the spectra to be considered by associating their sample code as well as the levels of experimental factors to which they belong. More detail can be found in Jacob et al. (2017) <doi:10.1007/s11306-017-1178-y>.,2021-11-10,Daniel Jacob,https://github.com/INRA/Rnmr1D,TRUE,https://github.com/inra/rnmr1d,11249,7,2022-06-05T07:28:03Z,1607
rnn,"Implementation of a Recurrent Neural Network architectures in native R, including Long Short-Term Memory (Hochreiter and Schmidhuber, <doi:10.1162/neco.1997.9.8.1735>), Gated Recurrent Unit (Chung et al., <arXiv:1412.3555>) and vanilla RNN.",2022-06-19,Bastiaan Quast,"https://qua.st/rnn/, https://github.com/bquast/rnn",TRUE,https://github.com/bquast/rnn,29147,70,2022-07-01T09:06:43Z,416.3857142857143
rnoaa,"Client for many 'NOAA' data sources including the 'NCDC' climate
    'API' at <https://www.ncdc.noaa.gov/cdo-web/webservices/v2>, with functions for
    each of the 'API' 'endpoints': data, data categories, data sets, data types,
    locations, location categories, and stations. In addition, we have an interface
    for 'NOAA' sea ice data, the 'NOAA' severe weather inventory, 'NOAA' Historical
    Observing 'Metadata' Repository ('HOMR') data, 'NOAA' storm data via 'IBTrACS',
    tornado data via the 'NOAA' storm prediction center, and more.",2021-12-01,Scott Chamberlain,"https://docs.ropensci.org/rnoaa/ (docs),
https://github.com/ropensci/rnoaa (devel)",TRUE,https://github.com/ropensci/rnoaa,67997,309,2022-05-25T16:50:19Z,220.05501618122977
rnpn,"Programmatic interface to the
    Web Service methods provided by the National 'Phenology' Network
    (<https://usanpn.org/>), which includes data on various life history
    events that occur at specific times.",2022-04-20,Alyssa Rosemartin,https://github.com/usa-npn/rnpn/ (devel),TRUE,https://github.com/usa-npn/rnpn,15726,13,2022-04-20T22:08:37Z,1209.6923076923076
Rnumerai,"Routines to interact with the Numerai Machine Learning Tournament
  API <https://numer.ai>. The functionality includes the ability to automatically download the
  current tournament data, submit predictions, and to get information for your
  user. General 'GraphQL' queries can also be executed.",2021-10-08,Eric Hare,https://github.com/Omni-Analytics-Group/Rnumerai,TRUE,https://github.com/omni-analytics-group/rnumerai,18855,32,2021-10-08T18:58:40Z,589.21875
Rnvd3,"Creates JavaScript charts with the 'nvd3' library. So far only the multibar chart, the horizontal multibar chart, the line chart and the line chart with focus are available.",2021-09-02,Stéphane Laurent,https://github.com/stla/Rnvd3,TRUE,https://github.com/stla/rnvd3,3133,1,2021-09-01T12:37:33Z,3133
roadoi,"This web client interfaces Unpaywall <https://unpaywall.org/products/api>, formerly
    oaDOI, a service finding free full-texts of academic papers by linking DOIs with 
    open access journals and repositories. It provides unified access to various data sources 
    for open access full-text links including Crossref and the Directory of Open Access 
    Journals (DOAJ). API usage is free and no registration is required.",2022-03-04,Najko Jahn,"https://docs.ropensci.org/roadoi/,
https://github.com/ropensci/roadoi/",TRUE,https://github.com/ropensci/roadoi,19395,61,2022-02-28T14:26:45Z,317.95081967213116
roads,"Project road network development based on an existing road 
    network, target locations to be connected by roads and a cost surface. Road 
    projection methods include minimum spanning tree with least cost path 
    (Kruskal’s algorithm (1956) <doi:10.2307/2033241>), least cost path 
    (Dijkstra's algorithm (1959) <doi:10.1007/BF01386390>) or snapping. 
    These road network projection methods are ideal for use with land cover
    change projection models.",2022-06-22,Josie Hughes,"https://github.com/LandSciTech/roads,
https://landscitech.github.io/roads/",TRUE,https://github.com/landscitech/roads,214,1,2022-06-17T20:42:53Z,214
roahd,"A collection of methods for the robust analysis of univariate and
    multivariate functional data, possibly in high-dimensional cases, and hence
    with attention to computational efficiency and simplicity of use. See the R 
    Journal publication of Ieva et al. (2019) <doi:10.32614/RJ-2019-032> for an 
    in-depth presentation of the 'roahd' package. See Aleman-Gomez et al. (2021) 
    <arXiv:2103.08874> for details about the concept of depthgram.",2021-11-04,Nicholas Tarabelloni,"https://astamm.github.io/roahd/, https://github.com/astamm/roahd",TRUE,https://github.com/astamm/roahd,13580,1,2022-02-08T09:42:46Z,13580
robber,"Implementation of a variety of methods to compute
    the robustness of ecological interaction networks with binary interactions 
    as described in <arXiv:1910.10512>. In particular, using the Stochastic 
    Block Model and its bipartite counterpart, the Latent Block Model to put a 
    parametric model on the network, allows the comparison of the robustness of 
    networks differing in species richness and number of interactions. It also
    deals with networks that are partially sampled and/or with missing values. ",2021-09-20,Saint-Clair Chabert-Liddell,https://github.com/Chabert-Liddell/robber,TRUE,https://github.com/chabert-liddell/robber,3090,0,2021-09-18T22:18:49Z,NA
robin,"Assesses the robustness of the community structure of a network found by one or more community detection algorithm to give indications about their reliability. It detects if the community structure found by a set of algorithms is statistically significant and compares the different selected detection algorithms on the same network. robin helps to choose among different community detection algorithms the one that better fits the network of interest. Reference in Policastro V., Righelli D., Carissimo A., Cutillo L., De Feis I. (2021) <https://journal.r-project.org/archive/2021/RJ-2021-040/index.html>.",2022-05-16,Valeria Policastro,https://github.com/ValeriaPolicastro/robin,TRUE,https://github.com/valeriapolicastro/robin,9836,7,2022-04-21T10:18:44Z,1405.142857142857
RobinHood,"Execute API calls to the RobinHood <https://robinhood.com> investing platform. Functionality includes accessing account data and current holdings, retrieving investment statistics and quotes, placing and canceling orders, getting market trading hours, searching investments by popular tag, and interacting with watch lists.",2022-04-22,Joseph Blubaugh,https://github.com/JestonBlu/RobinHood,TRUE,https://github.com/jestonblu/robinhood,17130,39,2022-05-16T20:02:25Z,439.2307692307692
robis,Client for the Ocean Biodiversity Information System (<https://obis.org>).,2021-10-13,Pieter Provoost,https://github.com/iobis/robis,TRUE,https://github.com/iobis/robis,21278,23,2022-02-14T13:47:12Z,925.1304347826087
RoBMA,"A framework for estimating ensembles of meta-analytic models
    (assuming either presence or absence of the effect, heterogeneity, and
    publication bias). The RoBMA framework uses Bayesian model-averaging to 
    combine the competing meta-analytic models into a model ensemble, weights 
    the posterior parameter distributions based on posterior model probabilities 
    and uses Bayes factors to test for the presence or absence of the
    individual components (e.g., effect vs. no effect; Bartoš et al., 2021, 
    <doi:10.31234/osf.io/kvsp7>; Maier, Bartoš & Wagenmakers, in press, 
    <doi:10.31234/osf.io/u4cns>). Users can define a wide range of non-informative 
    or informative prior distributions for the effect size, heterogeneity, 
    and publication bias components (including selection models and PET-PEESE). 
    The package provides convenient functions for summary, visualizations, and 
    fit diagnostics.",2022-04-20,František Bartoš,https://fbartos.github.io/RoBMA/,TRUE,https://github.com/fbartos/robma,13839,3,2022-07-07T12:58:03Z,4613
robmed,Perform mediation analysis via a (fast and robust) bootstrap test.,2022-05-23,Andreas Alfons,https://github.com/aalfons/robmed,TRUE,https://github.com/aalfons/robmed,19488,2,2022-05-23T19:15:39Z,9744
robnptests,"Implementations of several robust nonparametric two-sample tests
    for location or scale differences. The test statistics are based on robust
    location and scale estimators, e.g. the sample median or the Hodges-Lehmann estimators
    as described in Fried & Dehling (2011) <doi:10.1007/s10260-011-0164-1>.
    The p-values can be computed via the permutation principle, the randomization principle, or by using
    the asymptotic distributions of the test statistics under the null hypothesis, which ensures
    (approximate) distribution independence of the test decision. To test for a difference in
    scale, we apply the tests for location difference to transformed observations; see Fried (2012) <doi:10.1016/j.csda.2011.02.012>.
    Random noise on a small range can be added to the original observations in order to
    hold the significance level on data from discrete distributions.
    The location tests assume homoscedasticity and the scale tests require the
    location parameters to be zero.",2021-11-08,Sermad Abbas,https://github.com/s-abbas/robnptests,TRUE,https://github.com/s-abbas/robnptests,1742,1,2021-11-07T14:03:16Z,1742
RoBSA,"A framework for estimating ensembles of parametric survival models
    with different parametric families. The RoBSA framework uses Bayesian 
    model-averaging to combine the competing parametric survival models into 
    a model ensemble, weights the posterior parameter distributions based on 
    posterior model probabilities and uses Bayes factors to test for the 
    presence or absence of the individual predictors or preference for a 
    parametric family (Bartoš, Aust & Haaf, 2021, <doi:10.48550/arXiv.2112.08311>).
    The user can define a wide range of informative priors for all parameters 
    of interest. The package provides convenient functions for summary, visualizations, 
    fit diagnostics, and prior distribution calibration.",2022-05-27,František Bartoš,https://fbartos.github.io/RoBSA/,TRUE,https://github.com/fbartos/robsa,315,3,2022-06-15T21:50:59Z,105
robservable,"Allows loading and displaying an Observable notebook (online JavaScript  
    notebooks powered by <https://observablehq.com>) as an HTML Widget in an R 
    session, 'shiny' application or 'rmarkdown' document.",2022-06-28,Julien Barnier,https://juba.github.io/robservable/,TRUE,https://github.com/juba/robservable,8230,138,2022-07-10T09:42:01Z,59.63768115942029
robsurvey,"Robust (outlier-resistant) estimators of finite population
    characteristics like of means, totals, ratios, regression, etc. Available
    methods are M- and GM-estimators of regression, weight reduction,
    trimming, and winsorization. The package extends the 'survey'
    <https://CRAN.R-project.org/package=survey> package.",2022-06-10,Tobias Schoch,https://github.com/tobiasschoch/robsurvey,TRUE,https://github.com/tobiasschoch/robsurvey,11498,1,2022-06-30T09:17:16Z,11498
robust,"Methods for robust statistics, a state of the art in the early
  2000s, notably for robust regression and robust multivariate analysis.",2022-07-08,Jiahui Wang,https://github.com/valentint/robust,TRUE,https://github.com/valentint/robust,262680,0,2022-07-08T21:21:42Z,NA
robust2sls,"An implementation of easy tools for outlier robust inference in
    two-stage least squares (2SLS) models. The user specifies a reference 
    distribution against which observations are classified as outliers or not. 
    After removing the outliers, adjusted standard errors are automatically 
    provided. Furthermore, several statistical tests for the false outlier 
    detection rate can be calculated. The outlier removing algorithm can be 
    iterated a fixed number of times or until the procedure converges. The 
    algorithms and robust inference are described in more detail in Jiao (2019) 
    <https://drive.google.com/file/d/1qPxDJnLlzLqdk94X9wwVASptf1MPpI2w/view>.",2022-02-14,Jonas Kurle,https://github.com/jkurle/robust2sls,TRUE,https://github.com/jkurle/robust2sls,1860,0,2022-05-31T18:28:15Z,NA
robustarima,"Functions for fitting a linear regression model with ARIMA
  errors using a filtered tau-estimate.",2021-04-30,Stephen Kaluzny,https://github.com/spkaluzny/robustarima,TRUE,https://github.com/spkaluzny/robustarima,21962,0,2022-02-27T02:22:01Z,NA
robustHD,"Robust methods for high-dimensional data, in particular linear
    model selection techniques based on least angle regression and sparse
    regression.",2021-11-23,Andreas Alfons,https://github.com/aalfons/robustHD,TRUE,https://github.com/aalfons/robusthd,157119,4,2021-11-23T09:07:24Z,39279.75
robustlmm,"A method to fit linear mixed effects models robustly.
    Robustness is achieved by modification of the scoring equations
    combined with the Design Adaptive Scale approach.",2022-03-23,Manuel Koller,https://github.com/kollerma/robustlmm,TRUE,https://github.com/kollerma/robustlmm,101601,21,2022-03-22T21:04:53Z,4838.142857142857
robvis,"Helps users in quickly visualizing risk-of-bias 
    assessments performed as part of a systematic review. It allows users to 
    create weighted bar-plots of the distribution of risk-of-bias judgments 
    within each bias domain, in addition to traffic-light plots of the 
    specific domain-level judgments for each study. The resulting figures are 
    of publication quality and are formatted according the risk-of-bias 
    assessment tool use to perform the assessments. Currently, the supported 
    tools are ROB2.0 (for randomized controlled trials; Sterne et al (2019)  
    <doi:10.1136/bmj.l4898>), ROBINS-I (for non-randomised studies of 
    interventions; Sterne et al (2016) <doi:10.1136/bmj.i4919>), and QUADAS-2 
    (for diagnostic accuracy studies; Whiting et al (2011) 
    <doi:10.7326/0003-4819-155-8-201110180-00009>).",2019-11-22,Luke McGuinness,https://github.com/mcguinlu/robvis,TRUE,https://github.com/mcguinlu/robvis,19700,39,2022-06-21T14:09:05Z,505.12820512820514
Robyn,"Semi-Automated Marketing Mix Modeling (MMM) aiming to reduce human bias by means of ridge regression and evolutionary algorithms, enables actionable decision making providing a budget allocation and diminishing returns curves and allows ground-truth calibration to account for causation.",2022-05-06,Bernardo Lares,"https://github.com/facebookexperimental/Robyn,
https://facebookexperimental.github.io/Robyn/",TRUE,https://github.com/facebookexperimental/robyn,2725,536,2022-07-10T13:22:21Z,5.083955223880597
ROCFTP.MMS,"The algorithm provided in this package generates perfect sample for unimodal or multimodal posteriors. Read Once Coupling From The Past, with Metropolis-Multishift is used to generate a perfect sample for a given posterior density based on the two extreme starting paths, minimum and maximum of the most interest range of the posterior. It uses the monotone random operation of multishift coupler which allows to sandwich all of the state space in one point. It means both Markov Chains starting from the maximum and minimum will be coalesced. The generated sample is independent from the starting points. It is useful for mixture distributions too. The output of this function is a real value as an exact draw from the posterior distribution.",2022-02-18,Majid Nabipoor,https://github.com/nabipoor/ROCFTP.MMS,TRUE,https://github.com/nabipoor/rocftp.mms,1059,0,2022-02-17T04:48:12Z,NA
rocker,"'R6' class interface for handling relational database connections using 'DBI' package as backend.
  The class allows handling of connections to e.g. PostgreSQL, MariaDB and SQLite.
  The purpose is having an intuitive object allowing straightforward handling of SQL databases.",2022-01-04,Nikolaus Pawlowski,https://github.com/nikolaus77/rocker,TRUE,https://github.com/nikolaus77/rocker,2529,3,2022-01-31T21:32:56Z,843
roclang,"Efficient diffusing of content across function documentations. Sections, parameters or dot parameters are extracted from function documentations and turned into valid Rd character strings, which are ready to diffuse into the 'roxygen' comments of another function by inserting inline code. ",2022-05-15,Xiurui Zhu,https://github.com/zhuxr11/roclang,TRUE,https://github.com/zhuxr11/roclang,3657,1,2022-05-14T07:41:12Z,3657
rocnp,"A set of tools for working with Romanian personal numeric codes. 
    The core is a validation function which applies several verification
    criteria to assess the validity of numeric codes. This is accompanied by 
    functionality for extracting the different components of a personal numeric
    code. A personal numeric code is issued to all Romanian residents either at 
    birth or when they obtain a residence permit.",2021-11-05,Dragoș Moldovan-Grünfeld,https://github.com/dragosmg/rocnp,TRUE,https://github.com/dragosmg/rocnp,2285,0,2021-11-05T20:01:44Z,NA
Rodam,"'ODAM' (Open Data for Access and Mining) is a framework that implements a simple way to make research data broadly accessible and fully available for reuse, including by a script language such as R. The main purpose is to make a data set accessible online with a minimal effort from the data provider, and to allow any scientists or bioinformaticians to be able to explore the data set and then extract a subpart or the totality of the data according to their needs. The Rodam package has only one class, 'odamws', that provides methods to allow you to retrieve online data using 'ODAM' Web Services. This obviously requires that data are implemented according the 'ODAM' approach , namely that the data subsets were deposited in the suitable data repository in the form of TSV files associated with  their metadata also described  in TSV files. See <https://inrae.github.io/ODAM/>.",2022-03-01,Daniel Jacob,https://github.com/inrae/ODAM,TRUE,https://github.com/inrae/odam,15133,7,2022-05-25T15:38:43Z,2161.8571428571427
rodeo,"Provides an R6 class and several utility methods to
    facilitate the implementation of models based on ordinary
    differential equations. The heart of the package is a code generator
    that creates compiled 'Fortran' (or 'R') code which can be passed to
    a numerical solver. There is direct support for solvers contained
    in packages 'deSolve' and 'rootSolve'.",2021-03-27,David Kneis,https://github.com/dkneis/rodeo,TRUE,https://github.com/dkneis/rodeo,24255,6,2022-01-31T16:49:14Z,4042.5
rofanova,"Implements the robust functional analysis of variance (RoFANOVA), described in Centofanti et al. (2021) <arXiv:2112.10643>. 
    It allows testing mean differences among groups of  functional data by being robust against the presence of outliers.",2022-01-21,Fabio Centofanti,https://github.com/unina-sfere/rofanova,TRUE,https://github.com/unina-sfere/rofanova,1450,0,2022-01-21T10:45:06Z,NA
Rogue,"Rogue (""wildcard"") taxa are leaves with uncertain phylogenetic
  position.
  Their position may vary from tree to tree under inference methods that yield a
  tree set (e.g. bootstrapping, Bayesian tree searches, maximum parsimony).
  The presence of rogue taxa in a tree set can potentially remove all
  information from a consensus tree. The information content of a consensus
  tree - a function of its resolution and branch support values - can often be
  increased by removing rogue taxa. 
  'Rogue' provides an explicitly information-theoretic approach to rogue
  detection (Smith 2022) <doi:10.1093/sysbio/syab099>,
  and an interface to 'RogueNaRok' (Aberer et al. 2013)
  <doi:10.1093/sysbio/sys078>.",2022-01-13,Martin R. Smith,"https://github.com/ms609/Rogue/,
https://github.com/aberer/RogueNaRok/,
https://github.com/ms609/RogueNaRok/",TRUE,https://github.com/ms609/rogue,6151,2,2022-07-01T13:35:53Z,3075.5
roistats,"Easily applying same t-tests/basic data description across several sub-groups, with the output as a nice arranged data.frame. Multiple comparison and the significance symbols are also provided.",2021-03-10,Yufei Zhao,https://github.com/Irisfee/roistats,TRUE,https://github.com/irisfee/roistats,4726,1,2021-08-21T20:03:50Z,4726
roll,Fast and efficient computation of rolling and expanding statistics for time-series data.,2020-07-13,Jason Foster,https://github.com/jjf234/roll,TRUE,https://github.com/jjf234/roll,137338,98,2022-07-10T10:30:05Z,1401.408163265306
rollinglda,"A rolling version of the Latent Dirichlet Allocation, see Rieger et al. (2021) <https://www.statistik.tu-dortmund.de/fileadmin/user_upload/Lehrstuehle/IWuS/Forschung/rollinglda.pdf>. By a sequential approach, it enables the construction of LDA-based time series of topics that are consistent with previous states of LDA models. After an initial modeling, updates can be computed efficiently, allowing for real-time monitoring and detection of events or structural breaks.",2021-10-28,Jonas Rieger,https://github.com/JonasRieger/rollinglda,TRUE,https://github.com/jonasrieger/rollinglda,2877,7,2022-02-03T10:04:40Z,411
rollRegres,"Methods for fast rolling and expanding linear regression models. That is, series of linear regression models estimated on either an expanding window of data or a moving window of data. The methods use rank-one updates and downdates of the upper triangular matrix from a QR decomposition (see Dongarra, Moler, Bunch, and Stewart (1979) <doi:10.1137/1.9781611971811>).",2022-05-04,Benjamin Christoffersen,https://github.com/boennecd/rollRegres,TRUE,https://github.com/boennecd/rollregres,23123,16,2022-05-05T07:42:47Z,1445.1875
rolog,"This R package embeds 'SWI'-'Prolog', <https://www.swi-prolog.org/>, so that R can send deterministic and non-deterministic queries to 'prolog' ('consult', 'query'/'submit', 'once', 'findall').",2022-05-14,Matthias Gondan,https://github.com/mgondan/rolog,TRUE,https://github.com/mgondan/rolog,494,3,2022-06-16T14:09:51Z,164.66666666666666
ROOPSD,"Statistical distribution in OOP (Object Oriented Programming) way.
             This package proposes a R6 class interface to classic statistical
             distribution, and new distributions can be easily added with the
             class AbstractDist. A useful point is the generic fit() method for
             each class, which uses a maximum likelihood estimation to find the
             parameters of a dataset, see, e.g. Hastie, T. and al (2009)
             <isbn:978-0-387-84857-0>. Furthermore, the rv_histogram class
             gives a non-parametric fit, with the same accessors that for the
             classic distribution. Finally, three random generators useful to
             build synthetic data are given: a multivariate normal generator, an
             orthogonal matrix generator, and a symmetric positive definite
             matrix generator, see Mezzadri, F. (2007)
             <arXiv:math-ph/0609050>.",2020-08-26,Yoann Robin,https://github.com/yrobink/ROOPSD,TRUE,https://github.com/yrobink/roopsd,17166,1,2022-05-06T05:58:30Z,17166
ROpenCVLite,"Installs 'OpenCV' for use by other packages. 'OpenCV' <https://opencv.org/> 
    is library of programming functions mainly aimed at real-time computer 
    vision. This 'Lite' version contains the stable base version of 'OpenCV' and 
    does not contain any of its externally contributed modules.",2022-05-18,Simon Garnier,"https://swarm-lab.github.io/ROpenCVLite/,
https://github.com/swarm-lab/ROpenCVLite",TRUE,https://github.com/swarm-lab/ropencvlite,19573,48,2022-05-19T14:23:50Z,407.7708333333333
roperators,"Provides string arithmetic, reassignment operators, logical operators
  that handle missing values, and extra logical operators such as floating point
  equality and all or nothing. The intent is to allow R users to write code that
  is easier to read, write, and maintain while providing a friendlier experience
  to new R users from other language backgrounds (such as 'Python') who are used
  to concepts such as x += 1 and 'foo' + 'bar'.
  Includes operators for not in, easy floating point comparisons, === equivalent, and SQL-like 
  like operations (), etc. 
  We also added in some extra helper functions, such as OS checks, pasting
  in Oxford comma format, and functions to get the first, last, nth, or most common 
  element of a vector or word in a string. ",2022-02-10,Ben Wiseman,"https://benwiseman.github.io/roperators/,
https://github.com/BenWiseman/roperators",TRUE,https://github.com/benwiseman/roperators,20139,3,2022-04-08T17:09:53Z,6713
Ropj,"Read the data from Origin(R) project files ('*.opj')
	<https://www.originlab.com/doc/User-Guide/Origin-File-Types>.
	No write support is planned.",2022-03-14,Ivan Krylov,https://github.com/aitap/Ropj,TRUE,https://github.com/aitap/ropj,12784,0,2022-05-14T18:46:52Z,NA
roptim,"Perform general purpose optimization in R using C++. A unified 
    wrapper interface is provided to call C functions of the five optimization 
    algorithms ('Nelder-Mead', 'BFGS', 'CG', 'L-BFGS-B' and 'SANN') underlying 
    optim().",2020-06-29,Yi Pan,https://github.com/ypan1988/roptim/,TRUE,https://github.com/ypan1988/roptim,21066,11,2022-05-04T13:59:09Z,1915.090909090909
rosm,"Download and plot Open Street Map <https://www.openstreetmap.org/>,
    Bing Maps <https://www.bing.com/maps> and other tiled map sources. Use to create 
    basemaps quickly and add hillshade to vector-based maps.",2022-06-09,Dewey Dunnington,https://github.com/paleolimbot/rosm,TRUE,https://github.com/paleolimbot/rosm,169446,17,2022-06-09T15:51:05Z,9967.411764705883
rotasym,"Implementation of the tests for rotational symmetry on the
    hypersphere proposed in García-Portugués, Paindaveine and Verdebout (2020)
    <doi:10.1080/01621459.2019.1665527>. The package also implements the
    proposed distributions on the hypersphere, based on the tangent-normal
    decomposition, and allows for the replication of the data application
    considered in the paper.",2021-10-18,Eduardo García-Portugués,https://github.com/egarpor/rotasym,TRUE,https://github.com/egarpor/rotasym,17691,1,2021-10-18T14:28:43Z,17691
rotations,"Tools for working with rotational data, including
    simulation from the most commonly used distributions on SO(3),
    methods for different Bayes, mean and median type estimators for
    the central orientation of a sample, confidence/credible
    regions for the central orientation based on those estimators and
    a novel visualization technique for rotation data.  Most recently,
    functions to identify potentially discordant (outlying) values
    have been added.  References: Bingham, Melissa A. and Nordman, Dan J. and Vardeman, Steve B. (2009),
    Bingham, Melissa A and Vardeman, Stephen B and Nordman, Daniel J (2009),
    Bingham, Melissa A and Nordman, Daniel J and Vardeman, Stephen B (2010),
    Leon, C.A. and Masse, J.C. and Rivest, L.P. (2006),
    Hartley, R and Aftab, K and Trumpf, J. (2011),
    Stanfill, Bryan and Genschel, Ulrike and Hofmann, Heike (2013),
    Maonton, Jonathan (2004), 
    Mardia, KV and Jupp, PE (2000, ISBN:9780471953333), 
    Rancourt, D. and Rivest, L.P. and Asselin, J. (2000),
    Chang, Ted and Rivest, Louis-Paul (2001), 
    Fisher, Nicholas I. (1996, ISBN:0521568900).",2022-06-24,Bryan Stanfill,https://github.com/stanfill/rotationsC,TRUE,https://github.com/stanfill/rotationsc,15383,0,2022-06-24T21:27:24Z,NA
rotl,"An interface to the 'Open Tree of Life' API to retrieve
    phylogenetic trees, information about studies used to assemble the
    synthetic tree, and utilities to match taxonomic names to 'Open Tree
    identifiers'. The 'Open Tree of Life' aims at assembling a
    comprehensive phylogenetic tree for all named species.",2021-12-08,Francois Michonneau,"https://docs.ropensci.org/rotl/, https://github.com/ropensci/rotl",TRUE,https://github.com/ropensci/rotl,141459,30,2022-05-02T15:57:58Z,4715.3
rotor,"Conditionally rotate or back-up files based on
    their size or the date of the last backup; inspired by the 'Linux'
    utility 'logrotate'.",2020-12-13,Stefan Fleck,https://s-fleck.github.io/rotor/,TRUE,https://github.com/s-fleck/rotor,25437,9,2021-08-16T08:32:11Z,2826.3333333333335
roxut,"Much as 'roxygen2' allows one to document functions in the same file as the function itself, 'roxut'  allows one to write the unit tests in the same file as the function.  Once processed, the unit tests are moved to the appropriate directory.  Currently supports 'testthat' and 'tinytest' frameworks. The 'roxygen2' package provides much of the infrastructure.",2021-08-22,Bryan A. Hanson,https://github.com/bryanhanson/roxut,TRUE,https://github.com/bryanhanson/roxut,22958,4,2021-08-25T16:49:55Z,5739.5
roxygen2,"Generate your Rd documentation, 'NAMESPACE' file, and
    collation field using specially formatted comments. Writing
    documentation in-line with code makes it easier to keep your
    documentation up-to-date as your requirements change. 'Roxygen2' is
    inspired by the 'Doxygen' system for C++.",2022-05-13,Hadley Wickham,"https://roxygen2.r-lib.org/, https://github.com/r-lib/roxygen2",TRUE,https://github.com/r-lib/roxygen2,7525817,500,2022-07-10T05:35:58Z,15051.634
roxygen2md,"Converts elements of 'roxygen' documentation to
    'markdown'.",2019-06-17,Kirill Müller,"https://roxygen2md.r-lib.org, https://github.com/r-lib/roxygen2md",TRUE,https://github.com/r-lib/roxygen2md,12887,67,2022-05-14T02:34:26Z,192.34328358208955
roxytest,"Various tests as 'roxygen2' roclets: e.g. 'testthat' and 'tinytest' tests. 
  Also other static analysis tools as checking parameter documentation consistency and others.",2020-06-03,Mikkel Meyer Andersen,NA,TRUE,https://github.com/mikldk/roxytest,11622,87,2022-06-08T18:02:26Z,133.58620689655172
rPACI,"Analysis of corneal data obtained from a Placido disk corneal topographer with calculation of irregularity indices. This package performs analyses of corneal data obtained from a Placido disk corneal topographer, with the calculation of the Placido irregularity indices and the posterior analysis. The package is intended to be easy to use by a practitioner, providing a simple interface and yielding easily interpretable results. A corneal topographer is an ophthalmic clinical device that obtains measurements in the cornea (the anterior part of the eye). A Placido disk corneal topographer makes use of the Placido disk [Rowsey et al. (1981)]<doi:10.1001/archopht.1981.03930011093022>, which produce a circular pattern of measurement nodes. The raw information measured by such a topographer is used by practitioners to analyze curvatures, to study optical aberrations, or to diagnose specific conditions of the eye (e.g. keratoconus, an important corneal disease). The rPACI package allows the calculation of the corneal irregularity indices described in [Castro-Luna et al. (2020)]<doi:10.1016%2Fj.clae.2019.12.006>, [Ramos-Lopez et al. (2013)]<doi:10.1097%2FOPX.0b013e3182843f2a>, and [Ramos-Lopez et al. (2011)]<doi:10.1097/opx.0b013e3182279ff8>. It provides a simple interface to read corneal topography data files as exported by a typical Placido disk topographer, to compute the irregularity indices mentioned before, and to display summary plots that are easy to interpret for a clinician.",2021-11-04,Darío Ramos-López,"https://cran.r-project.org/package=rPACI,
https://github.com/dariorlual/rPACI/",TRUE,https://github.com/dariorlual/rpaci,13223,1,2021-11-03T18:50:51Z,13223
Rpadrino,"'PADRINO' houses textual representations of
    Integral Projection Models which can be converted from their 
    table format into full kernels to reproduce or extend an 
    already published analysis. 'Rpadrino' is an R interface to this database. For
    more information on Integral Projection Models, see Easterling et al. (2000) 
  <doi:10.1890/0012-9658(2000)081[0694:SSSAAN]2.0.CO;2>, Merow et al. (2013) 
  <doi:10.1111/2041-210X.12146>, Rees et al. (2014) <doi:10.1111/1365-2656.12178>,
  and Metcalf et al. (2015) <doi:10.1111/2041-210X.12405>. See Levin et al. (2021)
  for more information on 'ipmr', the engine that powers model reconstruction
  <doi:10.1111/2041-210X.13683>.",2022-04-29,Sam Levin,"https://github.com/padrinoDB/Rpadrino,
https://padrinoDB.github.io/Rpadrino/",TRUE,https://github.com/padrinodb/rpadrino,2412,2,2022-05-02T17:40:38Z,1206
rpart,"Recursive partitioning for classification, 
  regression and survival trees.  An implementation of most of the 
  functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.",2022-01-24,Beth Atkinson,"https://github.com/bethatkinson/rpart,
https://cran.r-project.org/package=rpart",TRUE,https://github.com/bethatkinson/rpart,1767914,26,2022-01-24T19:15:56Z,67996.69230769231
rpdo,"Monthly Pacific Decadal Oscillation (PDO) index
    values from January 1900 to September 2018. 
    Superseded by 'rsoi' package which includes the historical and 
    most recent monthly PDO index values together with related climate indices.",2020-07-09,Joe Thorley,https://github.com/poissonconsulting/rpdo,TRUE,https://github.com/poissonconsulting/rpdo,17728,1,2022-06-17T21:09:33Z,17728
rpf,"The purpose of this package is to factor out logic
    and math common to Item Factor Analysis fitting, diagnostics, and
    analysis. It is envisioned as core support code suitable for more
    specialized IRT packages to build upon. Complete access to optimized C
    functions are made available with R_RegisterCCallable().
    This software is described in Pritikin & Falk (2020) <doi:10.1177/0146621620929431>.",2021-10-20,Joshua Pritikin,https://github.com/jpritikin/rpf,TRUE,https://github.com/jpritikin/rpf,515105,0,2021-09-28T21:07:48Z,NA
rphylopic,"Work with 'Phylopic' web service (<http://phylopic.org/api/>) 
    to get 'silhouette' images of 'organisms', search names, and more.
    Includes functions for adding 'silhouettes' to both base plots and
    ggplot2 plots.",2020-06-04,Scott Chamberlain,https://github.com/sckott/rphylopic,TRUE,https://github.com/sckott/rphylopic,13560,77,2022-03-01T17:44:57Z,176.1038961038961
rpicosat,"Bindings for the 'PicoSAT' solver to solve Boolean satisfiability problems (SAT).
             The boolean satisfiability problem asks the question if a given boolean formula can be TRUE; 
             i.e. does there exist an assignment of TRUE/FALSE for each variable such that the whole formula is TRUE?
             The package bundles 'PicoSAT' solver release 965 <http://www.fmv.jku.at/picosat/>.",2017-11-15,Dirk Schumacher,https://github.com/dirkschumacher/rpicosat,TRUE,https://github.com/dirkschumacher/rpicosat,10388,6,2022-01-22T11:34:20Z,1731.3333333333333
rplos,"A programmatic interface to the 'SOLR' based
    search API (<http://api.plos.org/>) provided by the Public
    Library of Science journals to search their articles.
    Functions are included for searching for articles, retrieving
    articles, making plots, doing 'faceted' searches,
    'highlight' searches, and viewing results of 'highlighted'
    searches in a browser.",2021-02-23,Scott Chamberlain,https://docs.ropensci.org/rplos/ https://github.com/ropensci/rplos,TRUE,https://github.com/ropensci/rplos,30075,301,2021-12-17T12:30:27Z,99.91694352159469
rpmodel,"Implements the P-model 
  (Stocker et al., 2020 <doi:10.5194/gmd-13-1545-2020>),
  predicting acclimated parameters of the enzyme kinetics of C3 photosynthesis,
  assimilation, and dark respiration rates as a function of the environment
  (temperature, CO2, vapour pressure deficit, light, atmospheric pressure).",2021-06-09,Benjamin Stocker,https://github.com/stineb/rpmodel,TRUE,https://github.com/stineb/rpmodel,12406,19,2022-04-07T13:16:30Z,652.9473684210526
Rpolyhedra,A polyhedra database scraped from various sources as R6 objects and 'rgl' visualizing capabilities.,2022-06-26,Alejandro Baranek,"https://docs.ropensci.org/Rpolyhedra/,
https://github.com/ropensci/Rpolyhedra",TRUE,https://github.com/ropensci/rpolyhedra,12376,9,2022-06-26T01:24:03Z,1375.111111111111
RPostgres,"Fully DBI-compliant Rcpp-backed interface to
    PostgreSQL <https://www.postgresql.org/>, an open-source relational
    database.",2022-05-02,Kirill Müller,"https://rpostgres.r-dbi.org, https://github.com/r-dbi/RPostgres",TRUE,https://github.com/r-dbi/rpostgres,968725,289,2022-05-14T02:42:16Z,3351.989619377163
RPostgreSQL,"Database interface and 'PostgreSQL' driver for 'R'.
 This package provides a Database Interface 'DBI' compliant 
 driver for 'R' to access 'PostgreSQL' database systems.  
 In order to build and install this package from source, 'PostgreSQL' 
 itself must be present your system to provide 'PostgreSQL' functionality 
 via its libraries and header files. These files are provided as
 'postgresql-devel' package under some Linux distributions.
 On 'macOS' and 'Microsoft Windows' system the attached 'libpq' library source will be used.",2021-10-22,Joe Conway,"https://github.com/tomoakin/RPostgreSQL,
https://cran.r-project.org/package=DBI,
https://www.postgresql.org",TRUE,https://github.com/tomoakin/rpostgresql,2847798,59,2021-11-29T01:22:57Z,48267.76271186441
RPPASPACE,"Provides tools for the analysis of reverse-phase protein arrays (RPPAs), which are also known as ""tissue lysate arrays"" or simply ""lysate arrays"". The package's primary purpose is to input a set of quantification files representing dilution series of samples and control points taken from scanned RPPA slides and determine a relative log concentration value for each valid dilution series present in each slide and provide graphical visualization of the input and output data and their relationships. Other optional features include generation of quality control scores for judging the quality of the input data, spatial adjustment of sample points based on controls added to the slides, and various types of normalization of calculated values across a set of slides. The package was derived from a previous package named SuperCurve. For a detailed description of data inputs and outputs, usage  information, and a list of related papers describing methods used in the package please review the vignette ""Guide_to_RPPASPACE"". Hu (2007) <doi:10.1093/bioinformatics/btm283>.",2021-10-20,James M. Melott,https://github.com/MD-Anderson-Bioinformatics/rppaspace,TRUE,https://github.com/md-anderson-bioinformatics/rppaspace,10350,2,2021-08-26T21:32:04Z,5175
rPraat,"Read, write and manipulate 'Praat' TextGrid, PitchTier, Pitch, IntensityTier, Formant, Sound, and Collection files <https://www.fon.hum.uva.nl/praat/>.",2021-02-27,Tomas Boril,https://github.com/bbTomas/rPraat/,TRUE,https://github.com/bbtomas/rpraat,16307,19,2021-12-09T18:42:48Z,858.2631578947369
RPresto,"Implements a 'DBI' compliant interface to Presto. Presto is
    an open source distributed SQL query engine for running interactive
    analytic queries against data sources of all sizes ranging from
    gigabytes to petabytes: <https://prestodb.io/>.",2021-09-04,Onur Ismail Filiz,https://github.com/prestodb/RPresto,TRUE,https://github.com/prestodb/rpresto,69323,123,2022-02-14T05:49:05Z,563.6016260162602
rprojroot,"Robust, reliable and flexible paths to files below
    a project root. The 'root' of a project is defined as a directory that
    matches a certain criterion, e.g., it contains a certain regular file.",2022-04-02,Kirill Müller,"https://rprojroot.r-lib.org/, https://github.com/r-lib/rprojroot",TRUE,https://github.com/r-lib/rprojroot,15845038,142,2022-05-14T02:38:36Z,111584.77464788733
rprojtree,Use JSON templates to create folders and files structure for data science projects. Includes customized templates and accepts your own as JSON files.,2022-03-01,Miguel Conde,https://github.com/miguel-conde/rprojtree,TRUE,https://github.com/miguel-conde/rprojtree,1015,0,2022-03-01T17:53:34Z,NA
RProtoBuf,"Protocol Buffers are a way of encoding structured data in an
 efficient yet extensible format. Google uses Protocol Buffers for almost all
 of its internal 'RPC' protocols and file formats.  Additional documentation
 is available in two included vignettes one of which corresponds to our 'JSS'
 paper (2016, <doi:10.18637/jss.v071.i02>. A sufficiently recent version of
 'Protocol Buffers' library is required; currently version 3.3.0 from 2017
 is the stated minimum.",2022-05-06,Romain Francois,"https://github.com/eddelbuettel/rprotobuf,
https://dirk.eddelbuettel.com/code/rprotobuf.html",TRUE,https://github.com/eddelbuettel/rprotobuf,49367,62,2022-05-06T14:53:31Z,796.241935483871
RPublica,Client for accessing data journalism APIs from ProPublica <http://www.propublica.org/>.,2015-12-22,Thomas J. Leeper,https://github.com/rOpenGov/RPublica,TRUE,https://github.com/ropengov/rpublica,13626,21,2021-10-26T18:05:04Z,648.8571428571429
rpymat,"Aims to create a single isolated 'Miniconda' 
    and 'Python' environment for reproducible pipeline scripts. 
    The package provides utilities to run system command within the 'conda'
    environment, making it easy to install, launch, manage, and stop 
    'Jupyter-lab'.",2022-02-19,Zhengjia Wang [cph,https://github.com/dipterix/rpymat,TRUE,https://github.com/dipterix/rpymat,2255,0,2022-02-19T17:06:36Z,NA
rqdatatable,"Implements the 'rquery' piped Codd-style query algebra using 'data.table'.  This allows
   for a high-speed in memory implementation of Codd-style data manipulation tools.",2022-01-22,John Mount,"https://github.com/WinVector/rqdatatable/,
https://winvector.github.io/rqdatatable/",TRUE,https://github.com/winvector/rqdatatable,58351,36,2022-01-22T16:56:46Z,1620.861111111111
RQuantLib,"The 'RQuantLib' package makes parts of 'QuantLib' accessible from R
 The 'QuantLib' project aims to provide a comprehensive software framework
 for quantitative finance. The goal is to provide a standard open source library
 for quantitative analysis, modeling, trading, and risk management of financial
 assets.",2022-05-05,Dirk Eddelbuettel,"https://github.com/eddelbuettel/rquantlib,
https://dirk.eddelbuettel.com/code/rquantlib.html",TRUE,https://github.com/eddelbuettel/rquantlib,73146,101,2022-05-05T13:08:32Z,724.2178217821782
rquery,"A piped query generator based on Edgar F. Codd's relational
    algebra, and on production experience using 'SQL' and 'dplyr' at big data
    scale.  The design represents an attempt to make 'SQL' more teachable by
    denoting composition by a sequential pipeline notation instead of nested
    queries or functions.   The implementation delivers reliable high 
    performance data processing on large data systems such as 'Spark',
    databases, and 'data.table'. Package features include: data processing trees
    or pipelines as observable objects (able to report both columns
    produced and columns used), optimized 'SQL' generation as an explicit
    user visible table modeling step, plus explicit query reasoning and checking.",2022-02-28,John Mount,"https://github.com/WinVector/rquery/,
https://winvector.github.io/rquery/",TRUE,https://github.com/winvector/rquery,134562,107,2022-03-02T01:14:43Z,1257.588785046729
rrapply,"The minimal 'rrapply'-package contains a single function rrapply(), providing an extended implementation of 'R'-base rapply() by allowing to recursively apply a function to elements of a nested list based on a general condition function and including the possibility to prune or aggregate nested list elements from the result. In addition, special arguments can be supplied to access the name, location, parents and siblings in the nested list of the element under evaluation. The rrapply() function builds upon rapply()'s native 'C' implementation and requires no other package dependencies.",2022-03-07,Joris Chau,"https://jorischau.github.io/rrapply/,
https://github.com/JorisChau/rrapply",TRUE,https://github.com/jorischau/rrapply,19021,23,2022-03-07T10:11:24Z,827
Rraven,A tool to exchange data between R and 'Raven' sound analysis software (Cornell Lab of Ornithology). Functions work on data formats compatible with the R package 'warbleR'.,2021-04-21,Marcelo Araya-Salas,https://github.com/maRce10/Rraven,TRUE,https://github.com/marce10/rraven,17132,5,2022-07-02T22:37:48Z,3426.4
rrcov,"Robust Location and Scatter Estimation and Robust
        Multivariate Analysis with High Breakdown Point:
        principal component analysis (Filzmoser and Todorov (2013), <doi:10.1016/j.ins.2012.10.017>),
        linear and quadratic discriminant analysis (Todorov and Pires (2007)),
        multivariate tests (Todorov and Filzmoser (2010) <doi:10.1016/j.csda.2009.08.015>),
        outlier detection (Todorov et al. (2010) <doi:10.1007/s11634-010-0075-2>).
        See also Todorov and Filzmoser (2009) <ISBN-13:978-3838108148>,
        Todorov and Filzmoser (2010) <doi:10.18637/jss.v032.i03> and
        Boudt et al. (2019) <doi:10.1007/s11222-019-09869-x>.",2022-04-26,Valentin Todorov,https://github.com/valentint/rrcov,TRUE,https://github.com/valentint/rrcov,744267,1,2022-02-06T18:32:42Z,744267
rrcov3way,"Provides methods for multiway data analysis by means of Parafac
    and Tucker 3 models. Robust versions (Engelen and Hubert (2011) <doi:10.1016/j.aca.2011.04.043>) and versions
    for compositional data are also provided (Gallo (2015) <doi:10.1080/03610926.2013.798664>, Di Palma et al. (2018) <doi:10.1080/02664763.2017.1381669>.",2022-02-10,Valentin Todorov,https://github.com/valentint/rrcov3way,TRUE,https://github.com/valentint/rrcov3way,15136,0,2022-02-11T10:00:43Z,NA
rrd,"Makes it easy to import the data from a 'RRD' database 
   (<https://oss.oetiker.ch/rrdtool/>) directly into R data structures. The 
   resulting objects are 'tibble' objects or a list of 'tibble' objects, making
   it easy to manipulate the data.  The package uses 'librrd' to import the 
   numerical data in a 'RRD' database directly into R data structures without 
   using intermediate formats.",2022-03-07,Andrie de Vries,"https://github.com/andrie/rrd/, https://andrie.github.io/rrd/",TRUE,https://github.com/andrie/rrd,3551,7,2022-03-07T16:34:13Z,507.2857142857143
rrecsys,"Processes standard recommendation datasets (e.g., a user-item rating matrix) as input and generates rating predictions and lists of recommended items. Standard algorithm implementations which are included in this package are the following: Global/Item/User-Average baselines, Weighted Slope One, Item-Based KNN, User-Based KNN, FunkSVD, BPR and weighted ALS. They can be assessed according to the standard offline evaluation methodology (Shani, et al. (2011) <doi:10.1007/978-0-387-85820-3_8>) for recommender systems using measures such as MAE, RMSE, Precision, Recall, F1, AUC, NDCG, RankScore and coverage measures. The package (Coba, et al.(2017) <doi: 10.1007/978-3-319-60042-0_36>) is intended for rapid prototyping of recommendation algorithms and education purposes. ",2019-06-09,Ludovik Çoba,https://rrecsys.inf.unibz.it/,TRUE,https://github.com/ludovikcoba/rrecsys,18552,21,2022-05-15T09:45:21Z,883.4285714285714
rrefine,"'OpenRefine' (formerly 'Google Refine') is a popular, open source data cleaning software. This package enables users to programmatically trigger data transfer between R and 'OpenRefine'. Available functionality includes project import, export and deletion.",2021-11-14,VP Nagraj,https://github.com/vpnagraj/rrefine,TRUE,https://github.com/vpnagraj/rrefine,17178,18,2021-11-14T14:25:29Z,954.3333333333334
rRofex,"Execute API calls to the 'Matba Rofex' <https://apihub.primary.com.ar> trading platform. Functionality includes accessing account data and current holdings, retrieving investment quotes, placing and canceling orders, and getting reference data for instruments.",2021-08-02,Augusto Hassel,"https://matbarofex.github.io/rRofex/,
https://github.com/matbarofex/rRofex/",TRUE,https://github.com/matbarofex/rrofex,16998,21,2021-12-24T01:56:30Z,809.4285714285714
RRPP,"Linear model calculations are made for many random versions of data.  
    Using residual randomization in a permutation procedure, sums of squares are 
    calculated over many permutations to generate empirical probability distributions 
    for evaluating model effects.  This packaged is described by 
    Collyer & Adams (2018).  Additionally, coefficients, statistics, fitted values, and residuals generated over many 
    permutations can be used for various procedures including pairwise tests, prediction, classification, and
    model comparison.  This package should provide most tools one could need for the analysis of
    high-dimensional data, especially in ecology and evolutionary biology, but certainly other fields, as well.",2022-06-21,Michael Collyer,https://github.com/mlcollyer/RRPP,TRUE,https://github.com/mlcollyer/rrpp,60977,3,2022-06-21T16:19:42Z,20325.666666666668
rsae,"Empirical best linear unbiased prediction (EBLUP) and
    robust prediction of the area-level means under the basic unit-level
    model. The model can be fitted by maximum likelihood or a (robust)
    M-estimator. Mean square prediction error is computed by a parametric
    bootstrap.",2022-05-24,Tobias Schoch,https://github.com/tobiasschoch/rsae,TRUE,https://github.com/tobiasschoch/rsae,51369,1,2022-05-24T07:57:31Z,51369
rSAFE,Provides a model agnostic tool for white-box model trained on features extracted from a black-box model. For more information see: Gosiewska et al. (2020) <doi:10.1016/j.dss.2021.113556>.,2022-02-08,Alicja Gosiewska,https://github.com/ModelOriented/rSAFE,TRUE,https://github.com/modeloriented/rsafe,4833,23,2022-02-09T15:31:42Z,210.1304347826087
Rsagacmd,"Provides an R scripting interface to the open-source 'SAGA-GIS' 
    (System for Automated Geoscientific Analyses Geographical Information
    System) software. 'Rsagacmd' dynamically generates R functions for every
    'SAGA-GIS' geoprocessing tool based on the user's currently installed
    'SAGA-GIS' version. These functions are contained within an S3 object
    and are accessed as a named list of libraries and tools. This structure
    facilitates an easier scripting experience by organizing the large number
    of 'SAGA-GIS' geoprocessing tools (>700) by their respective library.
    Interactive scripting can fully take advantage of code autocompletion tools
    (e.g. in 'Rstudio'), allowing for each tools syntax to be quickly
    recognized. Furthermore, the most common types of spatial data (via the
    'raster', 'terra', 'sp', and 'sf' packages) along with non-spatial data are
    automatically passed from R to the 'SAGA-GIS' command line tool for
    geoprocessing operations, and the results are loaded as the appropriate R
    object. Outputs from individual 'SAGA-GIS' tools can also be chained using
    pipes from the 'magrittr' and 'dplyr' packages to combine complex
    geoprocessing operations together in a single statement. 'SAGA-GIS' is
    available under a GPLv2 / LGPLv2 licence from
    <https://sourceforge.net/projects/saga-gis/> including Windows x86/x64
    binaries. SAGA-GIS is also included in Debian/Ubuntu default software
    repositories and is available for macOS using homebrew (<https://brew.sh/>)
    from the osgeo/osgeo4mac (<https://github.com/OSGeo/homebrew-osgeo4mac>)
    formula tap, as well as being bundled within the 'QGIS' application bundle
    for macOS. Rsagacmd has currently been tested on 'SAGA-GIS' versions
    from 2.3.1 to 8.0.1 on Windows, Linux and macOS.",2022-04-04,Steven Pawley,https://stevenpawley.github.io/Rsagacmd/,TRUE,https://github.com/stevenpawley/rsagacmd,15842,25,2022-04-04T16:47:31Z,633.68
rsample,"Classes and functions to create and summarize different types
    of resampling objects (e.g. bootstrap, cross-validation).",2022-06-24,Julia Silge,"https://rsample.tidymodels.org,
https://github.com/tidymodels/rsample",TRUE,https://github.com/tidymodels/rsample,1899693,285,2022-07-07T17:56:26Z,6665.58947368421
rsat,"Downloading, customizing, and processing time series of satellite images for a region of interest. 'rsat' functions allow a unified access to multispectral images from Landsat, MODIS and Sentinel repositories. 'rsat' also offers capabilities for customizing satellite images, such as tile mosaicking, image cropping and new variables computation. Finally, 'rsat' covers the processing, including cloud masking, compositing and gap-filling/smoothing time series of images (Militino et al., 2018 <doi:10.3390/rs10030398> and Militino et al., 2019 <doi:10.1109/TGRS.2019.2904193>).",2022-03-02,Unai Pérez - Goya,https://github.com/ropensci/rsat,TRUE,https://github.com/ropensci/rsat,1642,35,2022-06-23T14:25:09Z,46.91428571428571
rscala,"'Scala' <http://www.scala-lang.org/> is embedded in 'R' and callbacks from 'Scala' to 'R' are available. Support is provided to write 'R' packages that access 'Scala'. After installation, please run 'rscala::scalaConfig()'.  The vignette provides an update of the original paper <doi:10.18637/jss.v092.i04>.",2020-04-05,David B. Dahl,https://github.com/dbdahl/rscala,TRUE,https://github.com/dbdahl/rscala,32847,98,2022-02-02T18:06:49Z,335.1734693877551
RSCAT,"As an advanced approach to computerized adaptive testing (CAT), 
  shadow testing (van der Linden(2005) <doi:10.1007/0-387-29054-0>) dynamically 
  assembles entire shadow tests as a part of 
  selecting items throughout the testing process.
  Selecting items from shadow tests guarantees the compliance of all content 
  constraints defined by the blueprint. 'RSCAT' is an R package for the 
  shadow-test approach to CAT. The objective of 
  'RSCAT' is twofold: 1) Enhancing the effectiveness of shadow-test CAT simulation;
  2) Contributing to the academic and scientific community for CAT research.
  RSCAT is currently designed for dichotomous items based on the three-parameter logistic (3PL) model.",2021-10-12,Bingnan Jiang,NA,TRUE,https://github.com/act-org/rscat,12927,4,2021-10-15T17:26:06Z,3231.75
rscc,"Evaluates R source codes by variable and/or functions names. Similar source codes should deliver similarity coefficients near one. Since neither the frequency nor the order of the used names is considered, a manual inspection of the R source code is required to check for similarity. Possible use cases include detection of code clones for improving
    software quality and of plagiarism amongst students' assignments.",2022-01-20,Sigbert Klinke,https://github.com/sigbertklinke/rscc (development version),TRUE,https://github.com/sigbertklinke/rscc,7900,0,2022-01-20T11:34:03Z,NA
rsconnect,"Programmatic deployment interface for 'RPubs', 'shinyapps.io', and
    'RStudio Connect'. Supported content types include R Markdown documents,
    Shiny applications, Plumber APIs, plots, and static web content.",2022-05-31,Aron Atkins,https://github.com/rstudio/rsconnect,TRUE,https://github.com/rstudio/rsconnect,32255164,97,2022-06-29T20:27:12Z,332527.4639175258
rscopus,"Uses Elsevier 'Scopus' API
    <https://dev.elsevier.com/sc_apis.html> to download 
    information about authors and their citations.",2019-09-17,John Muschelli,"https://dev.elsevier.com/sc_apis.html,
https://github.com/muschellij2/rscopus",TRUE,https://github.com/muschellij2/rscopus,100143,61,2021-12-18T00:37:22Z,1641.688524590164
rscorecard,"A method to download Department of Education College
     Scorecard data using the public API
     <https://collegescorecard.ed.gov/data/documentation/>. It is based on
     the 'dplyr' model of piped commands to select and filter data in a
     single chained function call.  An API key from the U.S. Department of
     Education is required.",2022-07-05,Benjamin Skinner,https://github.com/btskinner/rscorecard,TRUE,https://github.com/btskinner/rscorecard,25628,23,2022-07-05T20:34:32Z,1114.2608695652175
rsdmx,"Set of classes and methods to read data and metadata documents
  exchanged through the Statistical Data and Metadata Exchange (SDMX) framework,
  currently focusing on the SDMX XML standard format (SDMX-ML).",2021-02-06,Emmanuel Blondel,"https://github.com/opensdmx/rsdmx, https://sdmx.org",TRUE,https://github.com/opensdmx/rsdmx,81788,89,2022-05-17T22:16:19Z,918.9662921348314
rSEA,"SEA performs simultaneous feature-set testing for (gen)omics data. It tests the unified null hypothesis controls the family-wise error rate for all possible pathways. The unified null hypothesis is defined as: ""The proportion of true features in the set is less than or equal to the threshold c"", where c is selected by the user. Family-wise error rate control is provided through use of closed testing with Simes test. For more information on closed testing with Simes see Goeman et al. (2019) <doi:10.1093/biomet/asz041> and for more information about the properties and performance of SEA procedure see Ebrahimpoor et al. (2019) <doi:10.1093/bib/bbz074>.",2020-03-23,Mitra Ebrahimpoor,https://github.com/mitra-ep/rSEA,TRUE,https://github.com/mitra-ep/rsea,11971,0,2021-10-17T19:59:20Z,NA
RSelenium,"Provides a set of R bindings for the 'Selenium 2.0 WebDriver'
    (see <https://selenium.dev/documentation/en/>
    for more information) using the 'JsonWireProtocol' (see
    <https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol> for more
    information). 'Selenium 2.0 WebDriver' allows driving a web browser
    natively as a user would either locally or on a remote machine using
    the Selenium server it marks a leap forward in terms of web browser
    automation. Selenium automates web browsers (commonly referred to as
    browsers). Using RSelenium you can automate browsers locally or
    remotely.",2020-02-03,John Harrison,http://docs.ropensci.org/RSelenium,TRUE,https://github.com/ropensci/rselenium,161943,305,2022-02-24T19:39:24Z,530.9606557377049
rsimsum,"Summarise results from simulation studies and compute Monte Carlo
  standard errors of commonly used summary statistics. This package is modelled 
  on the 'simsum' user-written command in 'Stata' (White I.R., 2010 
  <https://www.stata-journal.com/article.html?article=st0200>), further extending
  it with additional functionality.",2022-03-22,Alessandro Gasparini,https://ellessenne.github.io/rsimsum/,TRUE,https://github.com/ellessenne/rsimsum,20431,19,2022-03-22T12:35:51Z,1075.3157894736842
rsinaica,"Easy-to-use functions for downloading air quality data from the 
    Mexican National Air Quality Information System (SINAICA).  Allows you to 
    query pollution and meteorological parameters from more than a hundred
    monitoring stations located throughout Mexico. See <https://sinaica.inecc.gob.mx> 
    for more information.",2019-02-04,Diego Valle-Jones,"https://hoyodesmog.diegovalle.net/rsinaica/,
https://github.com/diegovalle/rsinaica",TRUE,https://github.com/diegovalle/rsinaica,11543,6,2022-03-20T01:42:34Z,1923.8333333333333
rskey,"Create custom keyboard shortcuts to examine code selected in the 'Rstudio' editor.
             F3 can for example yield 'str(selection)' and F7 open the source
             code of CRAN and base package functions on 'github'.",2020-06-05,Berry Boessenkool,NA,TRUE,https://github.com/brry/rskey,10704,4,2022-02-15T10:10:22Z,2676
rslurm,"Functions that simplify submitting R scripts to a 'Slurm' 
    workload manager, in part by automating the division of embarrassingly
    parallel calculations across cluster nodes.",2021-11-15,Quentin Read,https://sesync-ci.github.io/rslurm/,TRUE,https://github.com/sesync-ci/rslurm,20617,41,2021-11-16T14:52:21Z,502.8536585365854
rsmatrix,"A small package for calculating the matrices in Shiller (1991, <doi:10.1016/S1051-1377(05)80028-2>) that serve as the foundation for many repeat-sales price indexes.",2022-03-15,Steve Martin,https://github.com/marberts/rsmatrix,TRUE,https://github.com/marberts/rsmatrix,8015,0,2022-03-15T16:47:22Z,NA
RSNNS,"The Stuttgart Neural Network Simulator (SNNS) is a library
    containing many standard implementations of neural networks. This
    package wraps the SNNS functionality to make it available from
    within R. Using the 'RSNNS' low-level interface, all of the
    algorithmic functionality and flexibility of SNNS can be accessed.
    Furthermore, the package contains a convenient high-level
    interface, so that the most common neural network topologies and
    learning algorithms integrate seamlessly into R.",2021-08-13,Christoph Bergmeir,https://github.com/cbergmeir/RSNNS,TRUE,https://github.com/cbergmeir/rsnns,165711,22,2021-08-09T02:30:15Z,7532.318181818182
rsnps,"A programmatic interface to various 'SNP' 'datasets'
    on the web: 'OpenSNP' (<https://opensnp.org>), and 'NBCIs' 'dbSNP' database
    (<https://www.ncbi.nlm.nih.gov/projects/SNP/>). Functions
    are included for searching for 'NCBI'. For 'OpenSNP', functions are included 
    for getting 'SNPs', and data for 'genotypes', 'phenotypes', annotations, 
    and bulk downloads of data by user.",2022-01-28,Julia Gustavsen,"https://docs.ropensci.org/rsnps/,
https://github.com/ropensci/rsnps/",TRUE,https://github.com/ropensci/rsnps,20553,44,2022-06-24T12:28:56Z,467.1136363636364
RSocrata,"Provides easier interaction with
    'Socrata' open data portals <https://dev.socrata.com>.
    Users can provide a 'Socrata' data set resource URL,
    or a 'Socrata' Open Data API (SoDA) web query,
    or a 'Socrata' ""human-friendly"" URL,
    returns an R data frame. Converts dates to 'POSIX'
    format and manages throttling by 'Socrata'.
    Users can upload data to 'Socrata' portals directly
    from R.",2021-09-14,Hugh Devlin,https://github.com/Chicago/RSocrata,TRUE,https://github.com/chicago/rsocrata,43345,209,2021-09-16T19:52:31Z,207.39234449760767
rsoi,"Downloads Southern Oscillation Index, Oceanic Nino
    Index, North Pacific Gyre Oscillation data, North Atlantic Oscillation
    and Arctic Oscillation. Data sources are described in the help files for each function.",2022-03-25,Sam Albers,"https://github.com/boshek/rsoi/, https://boshek.github.io/rsoi/",TRUE,https://github.com/boshek/rsoi,19514,14,2022-03-25T16:31:42Z,1393.857142857143
rspa,"Minimally adjust the values of numerical records in a data.frame, such
    that each record satisfies a predefined set of equality and/or inequality
    constraints. The constraints can be defined using the 'validate' package. 
    The core algorithms have recently been moved to the 'lintools' package,
    refer to 'lintools' for a more basic interface and access to a version
    of the algorithm that works with sparse matrices.",2022-06-16,Mark van der Loo,https://github.com/markvanderloo/rspa,TRUE,https://github.com/markvanderloo/rspa,17909,3,2022-06-15T08:03:26Z,5969.666666666667
rsparse,"Implements many algorithms for statistical learning on 
  sparse matrices - matrix factorizations, matrix completion, 
  elastic net regressions, factorization machines. 
  Also 'rsparse' enhances 'Matrix' package by providing methods for 
  multithreaded <sparse, dense> matrix products and native slicing of 
  the sparse matrices in Compressed Sparse Row (CSR) format.
  List of the algorithms for regression problems:
  1) Elastic Net regression via Follow The Proximally-Regularized Leader (FTRL) 
  Stochastic Gradient Descent (SGD), as per McMahan et al(, <doi:10.1145/2487575.2488200>)
  2) Factorization Machines via SGD, as per Rendle (2010, <doi:10.1109/ICDM.2010.127>)
  List of algorithms for matrix factorization and matrix completion:
  1) Weighted Regularized Matrix Factorization (WRMF) via Alternating Least 
  Squares (ALS) - paper by Hu, Koren, Volinsky (2008, <doi:10.1109/ICDM.2008.22>)
  2) Maximum-Margin Matrix Factorization via ALS, paper by Rennie, Srebro 
  (2005, <doi:10.1145/1102351.1102441>)
  3) Fast Truncated Singular Value Decomposition (SVD), Soft-Thresholded SVD, 
  Soft-Impute matrix completion via ALS - paper by Hastie, Mazumder 
  et al. (2014, <arXiv:1410.2596>)
  4) Linear-Flow matrix factorization, from 'Practical linear models for 
  large-scale one-class collaborative filtering' by Sedhain, Bui, Kawale et al 
  (2016, ISBN:978-1-57735-770-4)
  5) GlobalVectors (GloVe) matrix factorization via SGD, paper by Pennington, 
  Socher, Manning (2014, <https://aclanthology.org/D14-1162/>)
  Package is reasonably fast and memory efficient - it allows to work with large
  datasets - millions of rows and millions of columns. This is particularly useful 
  for practitioners working on recommender systems.",2021-11-30,Dmitriy Selivanov,https://github.com/rexyai/rsparse,TRUE,https://github.com/rexyai/rsparse,235202,161,2022-05-16T12:16:25Z,1460.8819875776398
rSPDE,"Functions that compute rational approximations of fractional elliptic stochastic partial differential equations. The package also contains functions for common statistical usage of these approximations. The main reference for the methods is Bolin and Kirchner (2020) <doi:10.1080/10618600.2019.1665537>, which can be generated by the citation function in R.",2022-01-14,David Bolin,https://davidbolin.github.io/rSPDE/,TRUE,https://github.com/davidbolin/rspde,12865,6,2022-07-10T16:42:07Z,2144.1666666666665
RSpectra,"R interface to the 'Spectra' library
    <https://spectralib.org/> for large-scale eigenvalue and SVD
    problems. It is typically used to compute a few
    eigenvalues/vectors of an n by n matrix, e.g., the k largest eigenvalues,
    which is usually more efficient than eigen() if k << n. This package
    provides the 'eigs()' function that does the similar job as in 'Matlab',
    'Octave', 'Python SciPy' and 'Julia'. It also provides the 'svds()' function
    to calculate the largest k singular values and corresponding
    singular vectors of a real matrix. The matrix to be computed on can be
    dense, sparse, or in the form of an operator defined by the user.",2022-04-24,Yixuan Qiu,https://github.com/yixuan/RSpectra,TRUE,https://github.com/yixuan/rspectra,957207,66,2022-04-24T15:33:29Z,14503.136363636364
rsprite2,"The SPRITE algorithm creates possible distributions of discrete responses
    based on reported sample parameters, such as mean, standard deviation and range 
    (Heathers et al., 2018, <doi:10.7287/peerj.preprints.26968v1>). This package implements it, 
    drawing heavily on the code for Nick Brown's 'rSPRITE' Shiny app <http://shiny.ieis.tue.nl/sprite/>. 
    In addition, it supports the modeling of distributions based on multi-item (Likert-type) 
    scales and the use of restrictions on the frequency of particular responses.",2021-09-22,Lukas Wallrich,https://lukaswallrich.github.io/rsprite2/,TRUE,https://github.com/lukaswallrich/rsprite2,2980,0,2022-05-22T10:45:08Z,NA
RSQL,"Allows the user to generate and execute select, insert, update and delete 'SQL' queries the underlying database without having to explicitly write 'SQL' code. ",2022-05-21,Alejandro Baranek,https://github.com/rOpenStats/RSQL,TRUE,https://github.com/ropenstats/rsql,15888,6,2022-05-20T23:45:35Z,2648
RSQLite,"Embeds the SQLite database engine in R and
    provides an interface compliant with the DBI package. The source for
    the SQLite engine and for various extensions in a recent version is
    included. System libraries will never be consulted because
    this package relies on static linking for the plugins it includes;
    this also ensures a consistent experience across all installations.",2022-05-07,Kirill Müller,"https://rsqlite.r-dbi.org, https://github.com/r-dbi/RSQLite",TRUE,https://github.com/r-dbi/rsqlite,3943593,283,2022-06-26T19:52:32Z,13934.957597173145
rsqliteadmin,"A comprehensive tool written in R Shiny to explore, manage and update SQLite Databases.",2021-07-04,Vijay Barve,https://github.com/rsqliteadmin/rsqliteadmin,TRUE,https://github.com/rsqliteadmin/rsqliteadmin,5048,2,2022-06-16T09:32:47Z,2524
Rssa,"Methods and tools for Singular Spectrum Analysis including decomposition,
             forecasting and gap-filling for univariate and multivariate time series.
             General description of the methods with many examples can be found in the book
             Golyandina (2018, <doi:10.1007/978-3-662-57380-8>).
             See 'citation(""Rssa"")' for details.",2021-10-05,Anton Korobeynikov,https://github.com/asl/rssa,TRUE,https://github.com/asl/rssa,33985,49,2021-10-05T12:33:43Z,693.5714285714286
RSSL,"A collection of implementations of semi-supervised classifiers
    and methods to evaluate their performance. The package includes implementations
    of, among others, Implicitly Constrained Learning, Moment Constrained Learning,
    the Transductive SVM, Manifold regularization, Maximum Contrastive Pessimistic
    Likelihood estimation, S4VM and WellSVM.",2022-01-17,Jesse Krijthe,https://github.com/jkrijthe/RSSL,TRUE,https://github.com/jkrijthe/rssl,131445,51,2022-01-17T14:21:14Z,2577.3529411764707
rstac,"Provides functions to access, search and download spacetime earth
    observation data via SpatioTemporal Asset Catalog (STAC). This package 
    supports the version 1.0.0 of the STAC specification
    (<https://github.com/radiantearth/stac-spec>). 
    For further details see Simoes et al. (2021) <doi:10.1109/IGARSS47720.2021.9553518>.",2021-10-31,Brazil Data Cube Team,https://github.com/brazil-data-cube/rstac,TRUE,https://github.com/brazil-data-cube/rstac,9307,42,2021-11-04T03:41:07Z,221.5952380952381
rstackdeque,"Provides fast, persistent (side-effect-free) stack, queue and
    deque (double-ended-queue) data structures. While deques include a superset
    of functionality provided by queues, in these implementations queues are
    more efficient in some specialized situations. See the documentation for
    rstack, rdeque, and rpqueue for details.",2015-04-13,Shawn T. ONeil,https://github.com/oneilsh/rstackdeque,TRUE,https://github.com/oneilsh/rstackdeque,19501,28,2022-05-09T17:18:27Z,696.4642857142857
rstan,"User-facing R functions are provided to parse, compile, test,
    estimate, and analyze Stan models by accessing the header-only Stan library
    provided by the 'StanHeaders' package. The Stan project develops a probabilistic
    programming language that implements full Bayesian statistical inference
    via Markov Chain Monte Carlo, rough Bayesian inference via 'variational'
    approximation, and (optionally penalized) maximum likelihood estimation via
    optimization. In all three cases, automatic differentiation is used to quickly
    and accurately evaluate gradients without burdening the user with the need to
    derive the partial derivatives.",2022-04-11,Ben Goodrich,"https://mc-stan.org/rstan/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/rstan,2880277,869,2021-11-09T21:19:20Z,3314.4729574223247
rstanarm,"Estimates previously compiled regression models using the 'rstan'
    package, which provides the R interface to the Stan C++ library for Bayesian
    estimation. Users specify models via the customary R syntax with a formula and
    data.frame plus some additional arguments for priors.",2022-04-09,Simon Wood [cph,"https://mc-stan.org/rstanarm/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/rstanarm,545554,322,2022-04-14T20:03:07Z,1694.2670807453417
rstanemax,"Perform sigmoidal Emax model fit using 'Stan' in a formula notation, without writing 'Stan' model code.",2020-11-24,Kenta Yoshida,https://github.com/yoshidk6/rstanemax,TRUE,https://github.com/yoshidk6/rstanemax,13725,2,2021-09-29T02:17:13Z,6862.5
rstantools,"Provides various tools for developers of R packages interfacing
    with 'Stan' <https://mc-stan.org>, including functions to set up the required 
    package structure, S3 generics and default methods to unify function naming 
    across 'Stan'-based R packages, and vignettes with recommendations for 
    developers.",2022-04-08,Jonah Gabry,"https://mc-stan.org/rstantools/, https://discourse.mc-stan.org/",TRUE,https://github.com/stan-dev/rstantools,1042349,34,2022-04-11T18:58:59Z,30657.323529411766
rstoat,"A wrapper for the 'Spatiotemporal Observation Annotation Tool' ('STOAT', <https://www.mol.org/stoat>) which allows users to run annotation jobs and retrieve results in the R environment.",2021-11-10,John Wilshire,https://www.mol.org/stoat,TRUE,https://github.com/mapoflife/rstoat,5410,0,2021-11-09T23:24:14Z,NA
RStoolbox,"Toolbox for remote sensing image processing and analysis such as
    calculating spectral indices, principal component transformation, unsupervised
    and supervised classification or fractional cover analyses.",2022-03-07,Benjamin Leutner,"https://bleutner.github.io/RStoolbox/,
https://github.com/bleutner/RStoolbox",TRUE,https://github.com/bleutner/rstoolbox,78072,207,2022-04-01T19:54:52Z,377.15942028985506
RstoxData,"Set of tools to read and manipulate various data formats for fisheries. Mainly
  catered towards scientific trawl survey sampling ('biotic') data, acoustic
  trawl data, and commercial fishing catch ('landings') data. Among the
  supported data formats are the data products from the Norwegian Institute
  Marine Research ('IMR') and the International Council for the Exploration of
  the Sea (ICES).",2021-07-17,Ibrahim Umar,https://github.com/StoXProject/RstoxData,TRUE,https://github.com/stoxproject/rstoxdata,8680,0,2022-06-23T12:02:34Z,NA
rStrava,Functions to access data from the 'Strava v3 API' <https://developers.strava.com/>.,2021-10-27,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/rstrava,3060,128,2021-12-01T21:09:06Z,23.90625
rstudio.prefs,"As of 'RStudio' v1.3, the preferences in the Global Options
    dialog (and a number of other preferences that aren’t) are now saved
    in simple, plain-text JSON files. This package provides an interface
    for working with these 'RStudio' JSON preference files to easily make
    modifications without using the point-and-click option menus. This is
    particularly helpful when working on teams to ensure a unified
    experience across machines and utilizing settings for best practices.",2021-11-15,Daniel D. Sjoberg,"https://github.com/ddsjoberg/rstudio.prefs,
https://www.danieldsjoberg.com/rstudio.prefs/index.html",TRUE,https://github.com/ddsjoberg/rstudio.prefs,7459,23,2021-11-15T12:56:20Z,324.30434782608694
rstudioapi,"Access the RStudio API (if available) and provide informative error
    messages when it's not.",2020-11-12,Kevin Ushey,https://github.com/rstudio/rstudioapi,TRUE,https://github.com/rstudio/rstudioapi,20549799,149,2022-04-06T18:58:16Z,137918.11409395974
rsvddpd,"Computing singular value decomposition with robustness is a challenging task. 
    This package provides an implementation of computing robust SVD using density power 
    divergence (<arXiv:2109.10680>). It combines the idea of robustness and efficiency in estimation
    based on a tuning parameter. It also provides utility functions to simulate various
    scenarios to compare performances of different algorithms.",2021-10-27,Subhrajyoty Roy,https://github.com/subroy13/rsvddpd,TRUE,https://github.com/subroy13/rsvddpd,2536,2,2022-03-12T11:04:00Z,1268
rsvg,"Renders vector-based svg images into high-quality custom-size
    bitmap arrays using 'librsvg2'. The resulting bitmap can be written to
    e.g. png, jpeg or webp format. In addition, the package can convert
    images directly to various formats such as pdf or postscript.",2022-04-20,Jeroen Ooms,"https://docs.ropensci.org/rsvg/, https://github.com/ropensci/rsvg",TRUE,https://github.com/ropensci/rsvg,600143,89,2022-04-16T09:34:50Z,6743.179775280899
rsyncrosim,"'SyncroSim' is a generalized framework for managing scenario-based 
    datasets (<https://syncrosim.com/>). 'rsyncrosim' provides an interface to 
    'SyncroSim'. Simulation models can be added to 'SyncroSim' in order to 
    transform these datasets, taking advantage of general features such as 
    defining scenarios of model inputs, running Monte Carlo simulations, and 
    summarizing model outputs. 'rsyncrosim' requires 'SyncroSim' 2.3.5 or higher 
    (API documentation: <https://docs.syncrosim.com/>).",2021-10-27,Colin Daniel,<https://syncrosim.github.io/rsyncrosim/>,TRUE,https://github.com/syncrosim/rsyncrosim,9169,5,2022-07-09T17:49:20Z,1833.8
rtables,"Reporting tables often have structure that goes beyond simple rectangular
  data. The 'rtables' package provides a framework for declaring complex multi-level tabulations
  and then applying them to data. This framework models both tabulation and the resulting
  tables as hierarchical, tree-like objects which support sibling sub-tables, arbitrary splitting
  or grouping of data in row and column dimensions, cells containing multiple values,
  and the concept of contextual summary computations. A convenient pipe-able interface is provided
  for declaring table layouts and the corresponding computations, and then applying them to data.",2022-05-21,Gabriel Becker,"https://github.com/roche/rtables, https://roche.github.io/rtables/",TRUE,https://github.com/roche/rtables,9665,147,2022-06-22T18:36:06Z,65.74829931972789
RtD3,"Create interactive visualisations of Rt estimates using 'D3.js' 
  (Gibbs et al. (2020) <doi:10.5281/zenodo.4011842>). Developed primarily targeting Rt estimates 
  generated by the 'EpiNow2' package, 'RtD3' aims to make simple, beautiful 
  visualisations that help researchers explore their results and share them with others.",2020-11-06,Hamish Gibbs,"https:/epiforecasts.io/RtD3, https://github.com/epiforecasts/RtD3",TRUE,https://github.com/epiforecasts/rtd3,6081,5,2022-05-25T12:36:06Z,1216.2
rtdists,"Provides response time distributions (density/PDF,
       distribution function/CDF, quantile function, and random
       generation): (a) Ratcliff diffusion model (Ratcliff &
       McKoon, 2008, <doi:10.1162/neco.2008.12-06-420>) based on C
       code by Andreas and Jochen Voss and (b) linear ballistic
       accumulator (LBA; Brown & Heathcote, 2008,
       <doi:10.1016/j.cogpsych.2007.12.002>) with different
       distributions underlying the drift rate.",2022-01-07,Henrik Singmann,https://github.com/rtdists/rtdists/,TRUE,https://github.com/rtdists/rtdists,123486,38,2022-01-04T09:00:15Z,3249.6315789473683
rtern,"A small language extension for succinct conditional assignment using `?` and `:`, emulating the conditional ternary operator syntax using in C, Java, JavaScript and other languages.",2022-01-24,Gethin Davies,https://github.com/grddavies/rtern,TRUE,https://github.com/grddavies/rtern,4890,4,2022-01-26T18:40:25Z,1222.5
rTG,"Methods for comparing different regression algorithms for 
    describing the temporal dynamics of secondary tree growth (xylem and 
    phloem). Users can compare the accuracy of the most common fitting methods 
    usually used to analyse xylem and phloem data, i.e., Gompertz function and 
    General Additive Models (GAMs); and an algorithm newly introduced to the 
    field, i.e., Bayesian Regularised Neural Networks (brnn). The core function
    of the package is XPSgrowth(), while the results can be interpreted using 
    implemented generic S3 methods, such as plot() and summary().",2022-05-12,Jernej Jevsenak,https://github.com/jernejjevsenak/rTG,TRUE,https://github.com/jernejjevsenak/rtg,4081,0,2022-05-12T15:55:03Z,NA
rtgstat,"Allow function for using 'TGStat Stat API' and
    'TGStat Search API', for more details see <https://api.tgstat.ru/docs/ru/start/intro.html>.
    'TGStat' provide telegram channel analytics data.",2022-05-02,Alexey Seleznev,https://selesnow.github.io/rtgstat/,TRUE,https://github.com/selesnow/rtgstat,2258,6,2022-05-03T07:24:24Z,376.3333333333333
rticles,"A suite of custom R Markdown formats and templates for
    authoring journal articles and conference submissions.",2022-03-04,Yihui Xie,https://github.com/rstudio/rticles,TRUE,https://github.com/rstudio/rticles,313108,1182,2022-06-22T10:27:17Z,264.89678510998306
rtiddlywiki,"'TiddlyWiki' is a unique non-linear notebook for capturing, organising and sharing complex information. 'rtiddlywiki' is a R interface of 'TiddlyWiki' <https://tiddlywiki.com> to create new tiddler from Rmarkdown file, and then put into a local 'TiddlyWiki' node.js server if it is available.",2022-07-05,Bangyou Zheng,"https://rtiddlywiki.bangyou.me/,
https://github.com/byzheng/rtiddlywiki",TRUE,https://github.com/byzheng/rtiddlywiki,64,1,2022-07-05T03:29:33Z,64
rtide,"Calculates tide heights based on tide station harmonics.  It
    includes the harmonics data for 637 US stations.  The harmonics data
    was converted from
    <https://github.com/poissonconsulting/rtide/blob/master/data-raw/harmonics-dwf-20151227-free.tar.bz2>,
    NOAA web site data processed by David Flater for 'XTide'.  The code to
    calculate tide heights from the harmonics is based on 'XTide'.",2021-05-29,Joe Thorley,https://github.com/poissonconsulting/rtide,TRUE,https://github.com/poissonconsulting/rtide,16783,14,2022-05-19T02:01:21Z,1198.7857142857142
RTL,"A toolkit for Commodities 'analytics', risk management and
    trading professionals. Includes functions for API calls to
    'Morningstar Commodities' and 'Genscape'.",2022-06-17,Philippe Cote,https://github.com/risktoollib/RTL,TRUE,https://github.com/risktoollib/rtl,14007,14,2022-06-23T17:10:26Z,1000.5
rTLS,"A set of tools to process and calculate 
             metrics on point clouds derived from terrestrial LiDAR 
             (Light Detection and Ranging; TLS). Its creation is based on key 
             aspects of the TLS application in forestry and ecology. 
             Currently, the main routines are based on filtering, neighboring 
             features of points, voxelization, canopy structure, 
             and the creation of artificial stands. It is written using 
             data.table and C++ language and in most of the functions it is 
             possible to use parallel processing to speed-up the routines.",2021-12-10,J. Antonio Guzmán Q.,https://github.com/Antguz/rTLS,TRUE,https://github.com/antguz/rtls,2548,13,2021-12-10T17:38:52Z,196
rtodoist,"Allows you to interact with the API of the ""Todoist"" platform.
    'Todoist' <https://todoist.com/> provides an online task manager service for teams.",2020-05-14,Cervan Girard,https://github.com/ThinkR-open/rtodoist,TRUE,https://github.com/thinkr-open/rtodoist,7311,10,2022-02-21T10:40:42Z,731.1
rTorch,"'R' implementation and interface of the Machine Learning platform 
    'PyTorch' <https://pytorch.org/> developed in 'Python'. It requires a 'conda'
    environment with 'torch' and 'torchvision' Python packages to provide 
    'PyTorch' functions, methods and classes. The key object in 'PyTorch' is the 
    tensor which is in essence a multidimensional array. These tensors are fairly 
    flexible in performing calculations in CPUs as well as 'GPUs' to accelerate 
    tensor operations.",2020-10-12,Alfonso R. Reyes,https://github.com/f0nzie/rTorch,TRUE,https://github.com/f0nzie/rtorch,13894,1,2021-10-23T09:44:19Z,13894
RTransferEntropy,Measuring information flow between time series with Shannon and Rényi transfer entropy. See also Dimpfl and Peter (2013) <doi:10.1515/snde-2012-0044> and Dimpfl and Peter (2014) <doi:10.1016/j.intfin.2014.03.004> for theory and applications to financial time series. Additional references can be found in the theory part of the vignette.,2021-04-02,David Zimmermann,https://github.com/BZPaper/RTransferEntropy,TRUE,https://github.com/bzpaper/rtransferentropy,18861,17,2022-04-28T17:42:10Z,1109.4705882352941
rtrend,"The traditional linear regression trend, Modified Mann-Kendall (MK)
    non-parameter trend and bootstrap trend are included in this package. Linear 
    regression trend is rewritten by '.lm.fit'. MK trend is rewritten by 'Rcpp'.
    Finally, those functions are about 10 times faster than previous version 
    in R.
    Reference:
    Hamed, K. H., & Rao, A. R. (1998). A modified Mann-Kendall trend test for 
    autocorrelated data. Journal of hydrology, 204(1-4), 182-196. 
    <doi:10.1016/S0022-1694(97)00125-X>.",2022-04-03,Dongdong Kong,https://github.com/rpkgs/rtrend,TRUE,https://github.com/rpkgs/rtrend,5710,4,2022-04-07T16:15:27Z,1427.5
Rtropical,"Process phylogenetic trees with tropical support vector machine and principal component analysis defined with tropical geometry. Details about tropical support vector machine are available in : Tang, X., Wang, H. & Yoshida, R. (2020) <arXiv:2003.00677>. Details about tropical principle component analysis are available in : Page, R., Yoshida, R. & Zhang L. (2020) <doi:10.1093/bioinformatics/btaa564> and Yoshida, R., Zhang, L. & Zhang, X. (2019) <doi:10.1007/s11538-018-0493-4>.",2021-11-09,Houjie Wang,https://github.com/HoujieWang/Rtropical,TRUE,https://github.com/houjiewang/rtropical,2082,0,2022-05-14T04:08:58Z,NA
rtry,"Designed to support the application of plant trait data providing easy applicable functions
    for the basic steps of data preprocessing, e.g. data import, data exploration, selection of columns
    and rows, excluding trait data according to different attributes, geocoding, long- to wide-table
    transformation, and data export. 'rtry' was initially developed as part of the TRY R project to
    preprocess trait data received via the TRY database.",2022-01-17,Olee Hoi Ying Lam,"https://github.com/MPI-BGC-Functional-Biogeography/rtry,
https://www.try-db.org/TryWeb/Home.php",TRUE,https://github.com/mpi-bgc-functional-biogeography/rtry,1307,8,2022-01-17T13:40:12Z,163.375
Rtsne,"An R wrapper around the fast T-distributed Stochastic
    Neighbor Embedding implementation by Van der Maaten  (see <https://github.com/lvdmaaten/bhtsne/> for more information on the original implementation).",2022-04-17,Jesse Krijthe,https://github.com/jkrijthe/Rtsne,TRUE,https://github.com/jkrijthe/rtsne,941505,244,2022-04-15T09:39:15Z,3858.627049180328
Rttf2pt1,"Contains the program 'ttf2pt1', for use with the
    'extrafont' package. This product includes software developed by the 'TTF2PT1'
    Project and its contributors.",2022-02-07,Winston Chang,https://github.com/wch/Rttf2pt1,TRUE,https://github.com/wch/rttf2pt1,1378261,13,2022-02-05T15:30:37Z,106020.07692307692
rtweet,"An implementation of calls designed to collect and organize Twitter data via Twitter's REST and stream Application Program Interfaces (API), which can be found at the following URL: <https://developer.twitter.com/en/docs>.
 This package has been peer-reviewed by rOpenSci (v. 0.6.9).",2020-01-08,Michael W. Kearney,https://CRAN.R-project.org/package=rtweet,TRUE,https://github.com/ropensci/rtweet,688561,720,2022-07-05T06:14:57Z,956.3347222222222
rugarch,"ARFIMA, in-mean, external regressors and various GARCH flavors, with methods for fit, forecast, simulation, inference and plotting.",2022-04-19,Alexios Galanos,"http://www.unstarched.net, https://github.com/alexiosg/rugarch",TRUE,https://github.com/alexiosg/rugarch,764488,4,2022-04-19T15:39:42Z,191122
rules,"Bindings for additional models for use with the 'parsnip'
    package.  Models include prediction rule ensembles (Friedman and
    Popescu, 2008) <doi:10.1214/07-AOAS148>, C5.0 rules (Quinlan, 1992
    ISBN: 1558602380), and Cubist (Kuhn and Johnson, 2013)
    <doi:10.1007/978-1-4614-6849-3>.",2022-06-23,Emil Hvitfeldt,"https://github.com/tidymodels/rules, https://rules.tidymodels.org/",TRUE,https://github.com/tidymodels/rules,21721,34,2022-06-23T22:39:09Z,638.8529411764706
rUM,"This holds some r markdown templates and a template to create a
    research project in RStudio.",2021-11-22,Raymond Balise,"https://raymondbalise.github.io/rUM/,
https://github.com/RaymondBalise/rUM",TRUE,https://github.com/raymondbalise/rum,3925,2,2022-03-06T13:58:16Z,1962.5
runcharter,"Plots multiple run charts, finds successive signals of 
    improvement, and revises medians when each signal occurs. Finds runs
    above, below, or on both sides of the median, and returns a plot and
    a data.table summarising original medians and any revisions, for all
    groups within the supplied data.",2021-11-09,John MacKintosh,https://github.com/johnmackintosh/runcharter,TRUE,https://github.com/johnmackintosh/runcharter,1853,31,2021-11-10T19:40:00Z,59.774193548387096
runjags,"User-friendly interface utilities for MCMC models via
    Just Another Gibbs Sampler (JAGS), facilitating the use of parallel
    (or distributed) processors for multiple chains, automated control
    of convergence and sample length diagnostics, and evaluation of the
    performance of a model using drop-k validation or against simulated
    data. Template model specifications can be generated using a standard
    lme4-style formula interface to assist users less familiar with the
    BUGS syntax.  A JAGS extension module provides additional distributions
    including the Pareto family of distributions, the DuMouchel prior and
    the half-Cauchy prior.",2022-04-15,Matthew Denwood,https://github.com/ku-awdc/runjags,TRUE,https://github.com/ku-awdc/runjags,138167,3,2022-06-03T19:57:10Z,46055.666666666664
runner,"Lightweight library for rolling windows operations. Package enables
  full control over the window length, window lag and a time indices. With a runner 
  one can apply any R function on a rolling windows. The package eases work with 
  equally and unequally spaced time series.",2021-10-03,Dawid Kałędkowski,NA,TRUE,https://github.com/gogonzo/runner,55041,40,2022-03-17T09:49:00Z,1376.025
runonce,"Package 'runonce' helps automating the saving of long-running code
    to help running the same code multiple times. If you run some long-running 
    code once, it saves the result in a file on disk. Then, if the result 
    already exists, i.e. if the code has already been run and its output has 
    already been saved, it just reads the result from the stored file instead 
    of running the code again. ",2021-10-02,Florian Privé,https://github.com/privefl/runonce,TRUE,https://github.com/privefl/runonce,8746,3,2021-10-02T07:54:15Z,2915.3333333333335
runstats,"Provides methods for fast computation of running sample 
    statistics for time series. These include: (1) mean, (2) 
    standard deviation, and (3) variance over a fixed-length window 
    of time-series, (4) correlation, (5) covariance, and (6) 
    Euclidean distance (L2 norm) between short-time pattern and 
    time-series. Implemented methods utilize Convolution Theorem to 
    compute convolutions via Fast Fourier Transform (FFT).",2019-11-14,Marta Karas,https://github.com/martakarass/runstats,TRUE,https://github.com/martakarass/runstats,14396,2,2022-04-01T02:43:57Z,7198
rust,"Uses the generalized ratio-of-uniforms (RU) method to simulate
    from univariate and (low-dimensional) multivariate continuous distributions.
    The user specifies the log-density, up to an additive constant. The RU
    algorithm is applied after relocation of mode of the density to zero, and
    the user can choose a tuning parameter r. For details see Wakefield, Gelfand
    and Smith (1991) <DOI:10.1007/BF01889987>, Efficient generation of random
    variates via the ratio-of-uniforms method, Statistics and Computing (1991)
    1, 129-133.  A Box-Cox variable transformation can be used to make the input
    density suitable for the RU method and to improve efficiency.  In the
    multivariate case rotation of axes can also be used to improve efficiency.
    From version 1.2.0 the 'Rcpp' package 
    <https://cran.r-project.org/package=Rcpp> can be used to improve efficiency.",2021-10-31,Paul J. Northrop,"https://paulnorthrop.github.io/rust/,
https://github.com/paulnorthrop/rust",TRUE,https://github.com/paulnorthrop/rust,38467,0,2022-07-09T20:54:15Z,NA
rv,"Implements a simulation-based random variable class and a suite of
  methods for extracting parts of random vectors, calculating extremes of random
  vectors, and generating random vectors under a variety of distributions 
  following Kerman and Gelman (2007) <doi:10.1007/s11222-007-9020-4>. ",2022-02-12,Jouni Kerman,https://github.com/jsta/rv,TRUE,https://github.com/jsta/rv,15917,2,2022-02-12T03:14:36Z,7958.5
RVA,Automate downstream visualization & pathway analysis in RNAseq analysis. 'RVA' is a collection of functions that efficiently visualize RNAseq differential expression analysis result from summary statistics tables. It also utilize the Fisher's exact test to evaluate gene set or pathway enrichment in a convenient and efficient manner.,2021-11-01,Xingpeng Li,https://github.com/THERMOSTATS/RVA,TRUE,https://github.com/thermostats/rva,4946,6,2021-10-29T16:02:06Z,824.3333333333334
Rvcg,"Operations on triangular meshes based on 'VCGLIB'. This package
    integrates nicely with the R-package 'rgl' to render the meshes processed by
    'Rvcg'. The Visualization and Computer Graphics Library (VCG for short) is
    an open source portable C++ templated library for manipulation, processing
    and displaying with OpenGL of triangle and tetrahedral meshes. The library,
    composed by more than 100k lines of code, is released under the GPL license,
    and it is the base of most of the software tools of the Visual Computing Lab of
    the Italian National Research Council Institute ISTI <http://vcg.isti.cnr.it>,
    like 'metro' and 'MeshLab'. The 'VCGLIB' source is pulled from trunk
    <https://github.com/cnr-isti-vclab/vcglib> and patched to work with options
    determined by the configure script as well as to work with the header files
    included by 'RcppEigen'.",2022-03-18,Stefan Schlager,"https://github.com/zarquon42b/Rvcg,
https://github.com/cnr-isti-vclab/vcglib",TRUE,https://github.com/zarquon42b/rvcg,50713,22,2022-05-18T10:29:45Z,2305.1363636363635
rvcheck,"Check latest release version of R and R package (both in 'CRAN', 'Bioconductor' or 'Github').",2021-10-22,Guangchuang Yu,https://github.com/GuangchuangYu/rvcheck,TRUE,https://github.com/guangchuangyu/rvcheck,432170,21,2021-10-22T02:07:37Z,20579.52380952381
rvest,"Wrappers around the 'xml2' and 'httr' packages to
    make it easy to download, then manipulate, HTML and XML.",2021-10-16,Hadley Wickham,"https://rvest.tidyverse.org/, https://github.com/tidyverse/rvest",TRUE,https://github.com/tidyverse/rvest,17262498,1345,2022-03-01T14:53:28Z,12834.571003717472
rvinecopulib,"Provides an interface to 'vinecopulib', a C++ library for vine 
 copula modeling. The 'rvinecopulib' package implements the core features of the
 popular 'VineCopula' package, in particular inference algorithms for both vine 
 copula and bivariate copula models. Advantages over 'VineCopula' are a sleeker 
 and more modern API, improved performances, especially in high dimensions, 
 nonparametric and multi-parameter families, and the ability to model discrete 
 variables. The 'rvinecopulib' package includes 'vinecopulib' as header-only 
 C++ library (currently version 0.6.1). Thus users do not need to install 
 'vinecopulib' itself in order to use 'rvinecopulib'. Since their initial 
 releases, 'vinecopulib' is licensed under the MIT License, and 'rvinecopulib' 
 is licensed under the GNU GPL version 3.",2022-03-18,Thomas Nagler,NA,TRUE,https://github.com/vinecopulib/rvinecopulib,25886,21,2022-03-19T10:34:21Z,1232.6666666666667
rvkstat,"Load data from vk.com api about your communiti users and views,
    ads performance, post on user wall and etc.	For more information 
    see API Documentation <https://vk.com/dev/first_guide>.",2021-10-18,Alexey Seleznev,https://selesnow.github.io/rvkstat/,TRUE,https://github.com/selesnow/rvkstat,14064,13,2021-10-16T16:58:58Z,1081.8461538461538
RVowpalWabbit,"The 'Vowpal Wabbit' project is a fast out-of-core learning
 system sponsored by Microsoft Research (having started at Yahoo! Research)
 and written by John Langford along with a number of contributors. This R
 package does not include the distributed computing implementation of the
 cluster/ directory of the upstream sources. Use of the software as a network
 service is also not directly supported as the aim is a simpler direct call
 from R for validation and comparison. Note that this package contains an
 embedded older version of 'Vowpal Wabbit'. The package 'rvw' at the GitHub
 repo <https://github.com/rvw-org/rvw-legacy> can provide an alternative using 
 an external 'Vowpal Wabbit' library installation.",2021-10-18,Dirk Eddelbuettel,"https://vowpalwabbit.org/,
https://github.com/eddelbuettel/rvowpalwabbit",TRUE,https://github.com/eddelbuettel/rvowpalwabbit,7306,22,2022-01-02T03:54:26Z,332.09090909090907
rwalkr,"Provides API to Melbourne pedestrian and weather data
    <https://data.melbourne.vic.gov.au> in tidy data form.",2021-08-16,Earo Wang,https://pkg.earo.me/rwalkr/,TRUE,https://github.com/earowang/rwalkr,19995,10,2021-08-17T09:45:59Z,1999.5
rwhatsapp,"A straightforward, easy-to-use and robust parsing package which aims to
    digest history files from the popular messenger service 'WhatsApp' in all locales
    and from all devices.",2022-01-05,Johannes Gruber,https://github.com/JBGruber/rwhatsapp,TRUE,https://github.com/jbgruber/rwhatsapp,21648,81,2022-05-04T07:55:14Z,267.25925925925924
rwicc,"Provides functions to simulate and analyze data for a regression model with an interval censored covariate, as described in Morrison et al. (2021) <doi:10.1111/biom.13472>.",2022-03-09,Douglas Morrison,"https://d-morrison.github.io/rwicc/,
https://github.com/d-morrison/rwicc",TRUE,https://github.com/d-morrison/rwicc,974,1,2022-06-30T19:54:18Z,974
rWind,Tools for download and manage surface wind and sea currents data from the Global Forecasting System <https://www.ncei.noaa.gov/products/weather-climate-models/global-forecast> and to compute connectivity between locations.,2021-10-19,Javier Fernández-López,http://allthiswasfield.blogspot.com.es/,TRUE,https://github.com/jabiologo/rwind,20223,19,2022-01-24T14:56:45Z,1064.3684210526317
RWmisc,"Contains convenience functions for working with spatial data across
    multiple UTM zones, raster-vector operations common in the analysis of 
    conflict data, and converting degrees, minutes, and seconds latitude and
    longitude coordinates to decimal degrees.",2022-02-14,Rob Williams,https://github.com/jayrobwilliams/RWmisc,TRUE,https://github.com/jayrobwilliams/rwmisc,6138,0,2022-02-14T18:07:00Z,NA
Rwofost,"An implementation of the WOFOST (""World Food Studies"") crop growth model. WOFOST is a dynamic simulation model that uses daily weather data, and crop, soil and management parameters to simulate crop growth and development. See De Wit et al. (2019) <doi:10.1016/j.agsy.2018.06.018> for a recent review of the history and use of the model.",2021-10-01,Robert J. Hijmans,https://CRAN.R-project.org/package=Rwofost,TRUE,https://github.com/cropmodels/rwofost,11786,17,2022-06-08T12:07:40Z,693.2941176470588
Rwtss,"Allows remote access to satellite image time 
    series provided by the web time series service (WTSS) available 
    at servers such as <https://brazildatacube.dpi.inpe.br/wtss/>. 
    The functions include listing the data sets available in WTSS servers, 
    describing the contents of a data set, and retrieving a time series 
    based on spatial location and temporal filters.",2022-04-25,Gilberto Queiroz,https://github.com/e-sensing/Rwtss/,TRUE,https://github.com/e-sensing/rwtss,6886,10,2022-04-22T19:37:15Z,688.6
RxODE,"Facilities for running simulations from ordinary
    differential equation ('ODE') models, such as pharmacometrics and other
    compartmental models.  A compilation manager translates the ODE model
    into C, compiles it, and dynamically loads the object code into R for
    improved computational efficiency.  An event table object facilitates
    the specification of complex dosing regimens (optional) and sampling
    schedules.  NB: The use of this package requires both C and
    Fortran compilers, for details on their use with R please see
    Section 6.3, Appendix A, and Appendix D in the ""R Administration and
    Installation"" manual. Also the code is mostly released under GPL.  The
    'VODE' and 'LSODA' are in the public domain.  The information is available
    in the inst/COPYRIGHTS. ",2022-03-23,Wenping Wang,"https://nlmixrdevelopment.github.io/RxODE/,
https://github.com/nlmixrdevelopment/RxODE/",TRUE,https://github.com/nlmixrdevelopment/rxode,37401,52,2022-04-04T23:28:42Z,719.25
rxode2,"Facilities for running simulations from ordinary
    differential equation ('ODE') models, such as pharmacometrics and other
    compartmental models.  A compilation manager translates the ODE model
    into C, compiles it, and dynamically loads the object code into R for
    improved computational efficiency.  An event table object facilitates
    the specification of complex dosing regimens (optional) and sampling
    schedules.  NB: The use of this package requires both C and
    Fortran compilers, for details on their use with R please see
    Section 6.3, Appendix A, and Appendix D in the ""R Administration and
    Installation"" manual. Also the code is mostly released under GPL.  The
    'VODE' and 'LSODA' are in the public domain.  The information is available
    in the inst/COPYRIGHTS. ",2022-05-17,Matthew L. Fidler,"https://nlmixr2.github.io/rxode2/,
https://github.com/nlmixr2/rxode2/",TRUE,https://github.com/nlmixr2/rxode2,1495,5,2022-07-09T15:45:27Z,299
rxylib,"Provides access to the 'xylib' C library for to import xy 
  data from powder diffraction, spectroscopy and other experimental methods.",2022-02-20,Sebastian Kreutzer,https://github.com/R-Lum/rxylib,TRUE,https://github.com/r-lum/rxylib,17741,8,2022-05-10T10:11:10Z,2217.625
rym,"Allows work with 'Management API' for load counters, segments, filters,
	user permissions and goals list from Yandex Metrica, 'Reporting API' allows you to get 
	information about the statistics of site visits and other data without
	using the web interface, 'Logs API' allows to receive non-aggregated data and 
	'Compatible with Google Analytics Core Reporting API v3' allows 
	receive information about site traffic and other data using field names 
	from Google Analytics Core API.	For more information see official 
	documents <https://yandex.ru/dev/metrika/doc/api2/concept/about-docpage>.",2021-09-03,Alexey Seleznev,https://selesnow.github.io/rym/,TRUE,https://github.com/selesnow/rym,15854,10,2021-09-03T07:02:12Z,1585.4
rytstat,"Provide function for get data from 'YouTube Data API' 
    <https://developers.google.com/youtube/v3/docs/>, 'YouTube Analytics API' 
    <https://developers.google.com/youtube/analytics/reference/> and 
    'YouTube Reporting API' <https://developers.google.com/youtube/reporting/v1/reports>.",2022-06-30,Alexey Seleznev,https://selesnow.github.io/rytstat/docs/,TRUE,https://github.com/selesnow/rytstat,2839,1,2022-07-06T08:05:29Z,2839
s2,"Provides R bindings for Google's s2 library for geometric calculations on
    the sphere. High-performance constructors and exporters provide high compatibility
    with existing spatial packages, transformers construct new geometries from existing
    geometries, predicates provide a means to select geometries based on spatial 
    relationships, and accessors extract information about geometries.",2021-09-28,Dewey Dunnington,"https://r-spatial.github.io/s2/, https://github.com/r-spatial/s2,
https://s2geometry.io/",TRUE,https://github.com/r-spatial/s2,1605456,51,2022-07-08T11:11:23Z,31479.529411764706
s2net,"Implements the generalized semi-supervised elastic-net. This method extends the supervised elastic-net problem, and thus it is a practical solution to the problem of feature selection in semi-supervised contexts. Its mathematical formulation is presented from a general perspective, covering a wide range of models.  We focus on linear and logistic responses, but the implementation could be easily extended to other losses in generalized linear models. We develop a flexible and fast implementation, written in 'C++' using 'RcppArmadillo' and integrated into R via 'Rcpp' modules. See Culp, M. 2013 <doi:10.1080/10618600.2012.657139> for references on the Joint Trained Elastic-Net.",2022-06-30,Juan C. Laria,https://github.com/jlaria/s2net,TRUE,https://github.com/jlaria/s2net,10573,3,2022-06-30T19:07:35Z,3524.3333333333335
s3.resourcer,"Resources are files in tidy or R data format stored in a S3 compatible system, such as 
  Amazon Web Services S3 or Minio object stores. Resources can also be Parquet files, accessed through
  an Apache Spark service.",2022-05-12,Yannick Marcon,NA,TRUE,https://github.com/obiba/s3.resourcer,432,0,2022-05-20T09:16:23Z,NA
sabre,"Calculates a degree of spatial association between regionalizations 
    or categorical maps using the information-theoretical V-measure 
    (Nowosad and Stepinski (2018) <doi:10.1080/13658816.2018.1511794>). It also
    offers an R implementation of the MapCurve method 
    (Hargrove et al. (2006) <doi:10.1007/s10109-006-0025-x>).",2021-06-03,Jakub Nowosad,https://nowosad.github.io/sabre/,TRUE,https://github.com/nowosad/sabre,14050,34,2022-06-25T20:05:17Z,413.2352941176471
sae.prop,"Implements Additive Logistic Transformation (alr) for Small Area Estimation under Fay Herriot Model. Small Area Estimation is used to borrow strength from auxiliary variables to improve the effectiveness of a domain sample size. This package uses Empirical Best Linear Unbiased Prediction (EBLUP) estimator. The Additive Logistic Transformation (alr) are based on transformation by Aitchison J (1986). The covariance matrix for multivariate application is base on covariance matrix used by Esteban M, Lombardía M, López-Vizcaíno E, Morales D, and Pérez A <doi:10.1007/s11749-019-00688-w>. The non-sampled models are modified area-level models based on models proposed by Anisa R, Kurnia A, and Indahwati I <doi:10.9790/5728-10121519>, with univariate model using model-3, and multivariate model using model-1. The MSE are estimated using Parametric Bootstrap approach. For non-sampled cases, MSE are estimated using modified approach proposed by Haris F and Ubaidillah A <doi:10.4108/eai.2-8-2019.2290339>.",2022-06-16,M. Rijalus Sholihin,https://github.com/mrijalussholihin/sae.prop,TRUE,https://github.com/mrijalussholihin/sae.prop,219,0,2022-06-15T09:15:08Z,NA
saeHB,"Provides several functions for area level of small area estimation using hierarchical Bayesian (HB) method with several univariate distributions for variable of interest. The dataset that used in every function is generated accordingly in the Example. The 'rjags' package is employed to obtain parameter estimates. Model-based estimators involves the HB estimators which include the mean and the variation of mean. For the reference, see Rao and Molina (2015) <doi:10.1002/9781118735855>.",2022-04-08,Zaza Yuda Perwira,https://github.com/zazaperwira/saeHB,TRUE,https://github.com/zazaperwira/saehb,2995,0,2021-11-04T01:14:00Z,NA
saeHB.gpois,"We designed this package to provide function for area level of Small Area Estimation using Hierarchical Bayesian (HB) method under Generalized Poisson Distribution. This package provides model using Univariate Generalized Poisson Distribution for variable of interest. Some datasets simulated by a data generation are also provided. The 'rjags' package is employed to obtain parameter estimates. Model-based estimators involves the HB estimators which include the mean and the variation of mean. For the reference, see Rao and Molina (2015) <doi:10.1002/9781118735855>, Wang (2021) <doi:10.1016/j.ecoinf.2021.101301> and Ntzoufras (2009) <doi:10.1002/9780470434567>.",2022-06-08,Joice Evangelista Lase,https://github.com/joiceevangelista/saeHB.gpois,TRUE,https://github.com/joiceevangelista/saehb.gpois,844,0,2022-06-08T05:25:17Z,NA
saeHB.hnb,"We design this package to provide a function for area level of small area estimation using Hierarchical Bayesian (HB) method under Hurdle Negative Binomial Distribution. This package provides model using Univariate Hurdle Negative Binomial Distribution for variable of interest. This package also provides a dataset produced by a data generation. The 'rjags' package is employed to obtain parameter estimates. Model-based estimators involves the Hierarchical Bayes estimators which include the mean and the variation of mean. For references, see Hilbe (2011) <doi:10.1017/CBO9780511973420> and Rao (2015) <doi:10.1002/9781118735855>.",2022-07-01,Raka Ikmana,https://github.com/rakaikmana/saeHB.hnb,TRUE,https://github.com/rakaikmana/saehb.hnb,909,0,2022-06-22T07:10:39Z,NA
saeHB.panel,"We designed this package to provide several functions for area level of small area estimation using hierarchical Bayesian (HB) method. This package provides model using panel data for variable interest.This package also provides a dataset produced by a data generation. The 'rjags' package is employed to obtain parameter estimates. Model-based estimators involves the HB estimators which include the mean and the variation of mean. For the reference, see Rao and Molina (2015).",2022-05-10,Velia Tri Marliana,https://github.com/Veliatrimarliana/saeHB.panel,TRUE,https://github.com/veliatrimarliana/saehb.panel,875,0,2022-03-02T03:32:05Z,NA
saeHB.spatial,Provides several functions and datasets for area level of Small Area Estimation under Spatial SAR Model using Hierarchical Bayesian (HB) Method.,2022-03-02,Arina Mana Sikana,https://github.com/arinams/saeHB.spatial,TRUE,https://github.com/arinams/saehb.spatial,728,0,2022-03-01T17:52:57Z,NA
saeHB.twofold,"We designed this package to provides several functions for area and subarea level of small area estimation under Twofold Subarea Level Model using hierarchical Bayesian (HB) method with Univariate Normal distribution for variables of interest. Some dataset simulated by a data generation are also provided. The 'rjags' package is employed to obtain parameter estimates using Gibbs Sampling algorithm. Model-based estimators involves the HB estimators which include the mean, the variation of mean, and the quantile. For the reference, see Rao and Molina (2015) <doi:10.1002/9781118735855>, Torabi and Rao (2014) <doi:10.1016/j.jmva.2014.02.001>, Leyla Mohadjer et al.(2007) <http://www.asasrms.org/Proceedings/y2007/Files/JSM2007-000559.pdf>, and Erciulescu et al.(2019) <doi:10.1111/rssa.12390>.",2022-05-09,Reyhan Saadi,https://github.com/reymath99/saeHB.twofold,TRUE,https://github.com/reymath99/saehb.twofold,930,1,2022-04-11T05:21:13Z,930
saeHB.zinb,"We designed this package to provide a function for area level of small area estimation using Hierarchical Bayesian (HB) method under Zero Inflated Negative Binomial Distribution. This package provides model using Univariate Zero Inflated Negative Binomial Distribution for variable of interest. This package also provides a dataset produced by a data generation. The 'rjags' package is employed to obtain parameter estimates. Model-based estimators involves the HB estimators which include the mean and the variation of mean, and the quantile. For the reference, see Rao,J.N.K & Molina (2015) <doi:10.1002/9781118735855>.",2022-06-16,Hayun,https://github.com/hayunbuto/saeHB.zinb,TRUE,https://github.com/hayunbuto/saehb.zinb,879,0,2022-06-16T01:49:13Z,NA
saeRobust,"Methods to fit robust alternatives to commonly used models used in
    Small Area Estimation. The methods here used are based on best linear
    unbiased predictions and linear mixed models. At this time available models
    include area level models incorporating spatial and temporal correlation in
    the random effects.",2022-06-13,Sebastian Warnholz,NA,TRUE,https://github.com/wahani/saerobust,15674,1,2022-06-10T12:19:02Z,15674
saeSim,"Tools for the simulation of data in the context of small area
    estimation. Combine all steps of your simulation - from data generation
    over drawing samples to model fitting - in one object. This enables easy
    modification and combination of different scenarios. You can store your
    results in a folder or start the simulation in parallel.",2022-02-07,Sebastian Warnholz,https://wahani.github.io/saeSim/,TRUE,https://github.com/wahani/saesim,15837,2,2022-02-07T16:16:33Z,7918.5
saeTrafo,"The aim of this package is to offer new methodology for unit-level 
    small area models under transformations and limited population auxiliary 
    information. In addition to this new methodology, the widely used nested 
    error regression model without transformations (see ""An Error-Components 
    Model for Prediction of County Crop Areas Using Survey and Satellite Data"" 
    by Battese, Harter and Fuller (1988) <doi:10.1080/01621459.1988.10478561>) 
    and its well-known uncertainty estimate (see ""The estimation of the mean 
    squared error of small-area estimators"" by Prasad and Rao (1990) 
    <doi:10.1080/01621459.1995.10476570>) are provided. In this package, the 
    log transformation and the data-driven log-shift transformation are 
    provided. If a transformation is selected, an appropriate method is chosen 
    depending on the respective input of the population data: Individual 
    population data (see ""Empirical best prediction under a nested error model 
    with log transformation"" by Molina and Martín (2018) 
    <doi:10.1214/17-aos1608>) but also aggregated population data (see 
    ""Estimating regional income indicators under transformations and access to 
    limited population auxiliary information"" by Würz, Schmid and Tzavidis 
    <unpublished>) can be entered. Especially under limited data access, new 
    methodologies are provided in 'saeTrafo'. Several options are available to 
    assess the used model and to judge, present and export its results. For a 
    detailed description of the package and the methods used see the 
    corresponding vignette.",2022-06-23,Nora Würz [aut],https://github.com/NoraWuerz/saeTrafo,TRUE,https://github.com/norawuerz/saetrafo,180,0,2022-06-17T13:37:45Z,NA
safedata,"The SAFE Project (<https://www.safeproject.net/>) is a large 
	scale ecological experiment in Malaysian Borneo that explores the impact 
	of habitat fragmentation and conversion on ecosystem function and services. 
	Data collected at the SAFE Project is made available under a common format 
	through the Zenodo data repository and this package makes it easy to 
	discover and load that data into R.",2022-04-25,David Orme,https://imperialcollegelondon.github.io/safedata/index.html,TRUE,https://github.com/imperialcollegelondon/safedata,9146,2,2022-04-25T14:26:20Z,4573
safetyCharts,"Contains chart code for monitoring clinical trial safety. Charts can be used as standalone output, but are also designed for use with the 'safetyGraphics' package, which makes it easy to load data and customize the charts using an interactive web-based interface created with Shiny.",2022-03-22,Jeremy Wildfire,https://github.com/SafetyGraphics/safetyCharts,TRUE,https://github.com/safetygraphics/safetycharts,3608,2,2022-04-19T15:58:52Z,1804
safetyGraphics,A framework for evaluation of clinical trial safety. Users can interactively explore their data using the included 'Shiny' application. ,2022-04-08,Jeremy Wildfire,https://github.com/SafetyGraphics/safetyGraphics,TRUE,https://github.com/safetygraphics/safetygraphics,13492,61,2022-06-15T11:32:48Z,221.18032786885246
sageR,"Datasets and functions for the book ""Statistiques pour l’économie et la gestion"", ""Théorie et applications en entreprise"", F. Bertrand, Ch. Derquenne, G. Dufrénot, F. Jawadi and M. Maumy, C. Borsenberger editor, (2021, ISBN:9782807319448, De Boeck Supérieur, Louvain-la-Neuve). 
    The first chapter of the book is dedicated to an introduction to statistics and their world. 
    The second chapter deals with univariate exploratory statistics and graphics. 
    The third chapter deals with bivariate and multivariate exploratory statistics and graphics. 
    The fourth chapter is dedicated to data exploration with Principal Component Analysis. 
    The fifth chapter is dedicated to data exploration with Correspondance Analysis.
    The sixth chapter is dedicated to data exploration with Multiple Correspondance Analysis. 
    The seventh chapter is dedicated to data exploration with automatic clustering. 
    The eighth chapter is dedicated to an introduction to probability theory and classical probability distributions.
    The ninth chapter is dedicated to an estimation theory, one-sample and two-sample tests.
    The tenth chapter is dedicated to an Gaussian linear model.
    The eleventh chapter is dedicated to an introduction to time series.
    The twelfth chapter is dedicated to an introduction to probit and logit models.
    Various example datasets are shipped with the package as well as some new functions.",2021-07-20,Frederic Bertrand,"https://fbertran.github.io/homepage/,
https://fbertran.github.io/sageR/,
https://github.com/fbertran/sageR/",TRUE,https://github.com/fbertran/sager,3761,1,2021-08-07T16:13:36Z,3761
salesforcer,"Functions connecting to the 'Salesforce' Platform APIs (REST, SOAP, 
    Bulk 1.0, Bulk 2.0, Metadata, Reports and Dashboards) 
    <https://trailhead.salesforce.com/en/content/learn/modules/api_basics/api_basics_overview>. 
    ""API"" is an acronym for ""application programming interface"". Most all calls 
    from these APIs are supported as they use CSV, XML or JSON data that can be 
    parsed into R data structures. For more details please see the 'Salesforce' 
    API documentation and this package's website 
    <https://stevenmmortimer.github.io/salesforcer/> for more information, 
    documentation, and examples.",2022-03-01,Steven M. Mortimer,https://github.com/StevenMMortimer/salesforcer,TRUE,https://github.com/stevenmmortimer/salesforcer,64248,64,2022-03-02T15:52:59Z,1003.875
samc,"Implements functions for working with absorbing Markov chains. The
    implementation is based on the framework described in ""Toward a unified
    framework for connectivity that disentangles movement and mortality in space
    and time"" by Fletcher et al. (2019) <doi:10.1111/ele.13333>, which applies
    them to spatial ecology. This framework incorporates both resistance and 
    absorption with spatial absorbing Markov chains (SAMC) to provide several
    short-term and long-term predictions for metrics related to connectivity in 
    landscapes. Despite the ecological context of the framework, this package
    can be used in any application of absorbing Markov chains.",2022-06-11,Andrew Marx,https://andrewmarx.github.io/samc/,TRUE,https://github.com/andrewmarx/samc,15275,5,2022-06-06T17:12:25Z,3055
sampleVADIR,Affords researchers the ability to draw stratified samples from the U.S. Department of Veteran's Affairs/Department of Defense Identity Repository (VADIR) database according to a variety of population characteristics. The VADIR database contains information for all veterans who were separated from the military after 1980. The central utility of the present package is to integrate data cleaning and formatting for the VADIR database with the stratification methods described by Mahto (2019) <https://CRAN.R-project.org/package=splitstackshape>. Data from VADIR are not provided as part of this package.,2021-10-27,Trevor Swanson,https://github.com/tswanson222/sampleVADIR,TRUE,https://github.com/tswanson222/samplevadir,2462,0,2021-10-28T00:52:29Z,NA
SamplingStrata,"In the field of stratified sampling design, this package offers an approach for the determination of the best stratification of a sampling frame, the one that ensures the minimum sample cost under the condition to satisfy precision constraints in a multivariate and multidomain case. This approach is based on the use of the genetic algorithm: each solution (i.e. a particular partition in strata of the sampling frame) is considered as an individual in a population; the fitness of all individuals is evaluated applying the Bethel-Chromy algorithm to calculate the sampling size satisfying precision constraints on the target estimates. Functions in the package allows to: (a) analyse the obtained results of the optimisation step; (b) assign the new strata labels to the sampling frame; (c) select a sample from the new frame accordingly to the best allocation. Functions for the execution of the genetic algorithm are a modified version of the functions in the 'genalg' package. M.Ballin, G.Barcaroli (2020) <arXiv:2004.09366> ""R package SamplingStrata: new developments and extension to Spatial Sampling"".  ",2022-01-07,Giulio Barcaroli,"https://barcaroli.github.io/SamplingStrata/,
https://github.com/barcaroli/SamplingStrata/",TRUE,https://github.com/barcaroli/samplingstrata,22887,9,2022-04-22T10:00:38Z,2543
SAMtool,"Simulation tools for closed-loop simulation are provided for the 'MSEtool' operating model to inform data-rich fisheries. 
  'SAMtool' provides a conditioning model, assessment models of varying complexity with standardized reporting, 
  model-based management procedures, and diagnostic tools for evaluating assessments inside closed-loop simulation.",2022-06-07,Quang Huynh,"https://openmse.com, https://github.com/Blue-Matter/SAMtool",TRUE,https://github.com/blue-matter/samtool,9953,2,2022-06-07T21:19:48Z,4976.5
sandbox,"A flexible framework for definition and application of time/depth-
    based rules for sets of parameters for single grains that can be used to 
    create artificial sediment profiles. Such profiles can be used for virtual 
    sample preparation and synthetic, for instance, luminescence measurements.",2022-02-25,Michael Dietze,NA,TRUE,https://github.com/coffeemuggler/sandbox,1745,1,2022-02-25T07:45:11Z,1745
sanityTracker,"During the preparation of data set(s) one usually performs
    some sanity checks. The idea is that irrespective of where the
    checks are performed, they are centralized by this package in order
    to list all at once with examples if a check failed.",2020-04-22,Marsel Scheer,https://github.com/MarselScheer/sanityTracker,TRUE,https://github.com/marselscheer/sanitytracker,7172,0,2021-09-07T18:31:01Z,NA
santaR,"A graphical and automated pipeline for the analysis 
		of short time-series in R ('santaR'). This approach is designed to accommodate asynchronous 
		time sampling (i.e. different time points for different individuals), 
		inter-individual variability, noisy measurements and large numbers of variables. 
		Based on a smoothing splines functional model, 'santaR' is able to detect variables
		highlighting significantly different temporal trajectories between study groups.
		Designed initially for metabolic phenotyping, 'santaR' is also suited for other Systems Biology 
		disciplines. Command line and graphical analysis (via a 'shiny' application) enable fast and
		parallel automated analysis and reporting, intuitive visualisation and comprehensive plotting
		options for non-specialist users.",2022-05-23,Arnaud Wolfer,https://github.com/adwolfer/santaR,TRUE,https://github.com/adwolfer/santar,11178,10,2022-05-26T14:38:11Z,1117.8
santoku,"A tool for cutting data into intervals. Allows singleton intervals.
  Always includes the whole range of data by default. Flexible labelling. 
  Convenience functions for cutting by quantiles etc. Handles dates, times, units
  and other vectors.",2022-06-08,David Hugh-Jones,"https://github.com/hughjonesd/santoku,
https://hughjonesd.github.io/santoku/",TRUE,https://github.com/hughjonesd/santoku,18229,131,2022-06-15T11:03:59Z,139.15267175572518
saotd,"This analytic is an in initial foray into sentiment analysis.  
    This analytic will allow a user to access the Twitter API (once they create 
    their own developer account), ingest tweets of their interest, clean / tidy 
    data, perform topic modeling if interested, compute sentiment scores 
    utilizing the Bing Lexicon, and output visualizations.",2021-10-13,Evan Munson,https://github.com/evan-l-munson/saotd,TRUE,https://github.com/evan-l-munson/saotd,7358,9,2021-10-12T14:05:31Z,817.5555555555555
sapfluxnetr,"Access, modify, aggregate and plot data from the 'Sapfluxnet' project
  (<http://sapfluxnet.creaf.cat>), the first global database of sap flow measurements.",2021-11-19,Victor Granda,https://github.com/sapfluxnet/sapfluxnetr,TRUE,https://github.com/sapfluxnet/sapfluxnetr,13939,18,2022-04-20T14:43:41Z,774.3888888888889
saqgetr,"A collection of tools to access prepared air quality monitoring
    data files from web servers with ease and speed. Air quality data are 
    sourced from open and publicly accessible repositories and can be found in 
    these locations: 
    <https://www.eea.europa.eu/data-and-maps/data/airbase-the-european-air-quality-database-8> 
    and <https://discomap.eea.europa.eu/map/fme/AirQualityExport.htm>. The web 
    server space has been provided by Ricardo Energy & Environment.",2021-01-12,Stuart K. Grange,https://github.com/skgrange/saqgetr,TRUE,https://github.com/skgrange/saqgetr,13747,9,2022-06-22T11:09:53Z,1527.4444444444443
sarima,"Functions, classes and methods for time series modelling with ARIMA
    and related models. The aim of the package is to provide consistent
    interface for the user. For example, a single function autocorrelations()
    computes various kinds of theoretical and sample autocorrelations. This is
    work in progress, see the documentation and vignettes for the current
    functionality.  Function sarima() fits extended multiplicative seasonal
    ARIMA models with trends, exogenous variables and arbitrary roots on the
    unit circle, which can be fixed or estimated.",2022-02-24,Georgi N. Boshnakov,"https://github.com/GeoBosh/sarima (devel)
https://geobosh.github.io/sarima/ (doc)",TRUE,https://github.com/geobosh/sarima,45881,2,2022-03-26T08:49:23Z,22940.5
sars,"Implements the basic elements of the multi-model
    inference paradigm for up to twenty species-area relationship models (SAR), using simple
    R list-objects and functions, as in Triantis et al. 2012 <DOI:10.1111/j.1365-2699.2011.02652.x>.
    The package is scalable and users can easily create their own model and data objects. Additional
    SAR related functions are provided.",2021-08-05,Thomas J. Matthews,"https://github.com/txm676/sars, https://txm676.github.io/sars/",TRUE,https://github.com/txm676/sars,18041,6,2021-08-05T09:23:02Z,3006.8333333333335
sarsop,"A toolkit for Partially Observed Markov Decision Processes (POMDP). Provides
    bindings to C++ libraries implementing the algorithm SARSOP (Successive Approximations
    of the Reachable Space under Optimal Policies) and described in Kurniawati et al (2008),
    <doi:10.15607/RSS.2008.IV.009>.  This package also provides a high-level interface
    for generating, solving and simulating POMDP problems and their solutions.",2021-08-05,Carl Boettiger,https://github.com/boettiger-lab/sarsop,TRUE,https://github.com/boettiger-lab/sarsop,9515,6,2021-08-04T20:36:23Z,1585.8333333333333
SAScii,"Using any importation code designed for 'SAS' users to read ASCII files into 'sas7bdat' files, this package parses through the INPUT block of a '.sas' syntax file to design the parameters needed for a 'read.fwf()' function call.  This allows the user to specify the location of the ASCII (often a '.dat') file and the location of the 'SAS' syntax file, and then load the data frame directly into R in just one step.",2022-04-27,Anthony Joseph Damico,https://github.com/ajdamico/SAScii,TRUE,https://github.com/ajdamico/sascii,28747,19,2022-04-27T14:47:38Z,1513
sasMap,"A static code analysis tool for 'SAS' scripts. It is designed to load, count, extract, remove, and summarise components of 'SAS' code.",2017-08-18,Nic Crane,https://github.com/MangoTheCat/sasMap,TRUE,https://github.com/mangothecat/sasmap,12564,6,2021-08-31T14:16:52Z,2094
sass,"An 'SCSS' compiler, powered by the 'LibSass' library. With this,
    R developers can use variables, inheritance, and functions to generate
    dynamic style sheets. The package uses the 'Sass CSS' extension language,
    which is stable, powerful, and CSS compatible.",2022-03-23,Richard Iannone,"https://rstudio.github.io/sass/, https://github.com/rstudio/sass",TRUE,https://github.com/rstudio/sass,7363866,97,2022-04-14T19:40:10Z,75916.14432989691
sassy,"A meta-package that aims to make 'R' easier for 'SAS®' programmers.
    This set of packages brings many familiar concepts to 'R', including
    data libraries, data dictionaries, formats 
    and format catalogs, a data step, and a traceable log.  The 'flagship'
    package is a reporting package that can output in text, rich text, 'PDF' and 
    'HTML' file formats.",2022-01-19,David J. Bosak,https://r-sassy.org,TRUE,https://github.com/dbosak01/sassy,6087,3,2022-07-05T23:34:15Z,2029
satin,"With 'satin' functions, visualisation, data extraction and further analysis like producing climatologies from several images, and anomalies of satellite derived ocean data can be easily done.  Reading functions can import a user defined geographical extent of data stored in netCDF files.  Currently supported ocean data sources include NASA's Oceancolor web page <https://oceancolor.gsfc.nasa.gov/>, sensors VIIRS-SNPP; MODIS-Terra; MODIS-Aqua; and SeaWiFS.  Available variables from this source includes chlorophyll concentration, sea surface temperature (SST), and several others.  Data sources specific for SST that can be imported too includes Pathfinder AVHRR <https://www.ncei.noaa.gov/products/avhrr-pathfinder-sst> and GHRSST <https://www.ghrsst.org/>.  In addition, ocean productivity data produced by Oregon State University <http://sites.science.oregonstate.edu/ocean.productivity/> can also be handled previous conversion from HDF4 to HDF5 format.  Many other ocean variables can be processed by importing netCDF data files from two European Union's Copernicus Marine Service databases <https://marine.copernicus.eu/>, namely Global Ocean Physical Reanalysis and Global Ocean Biogeochemistry Hindcast.",2020-10-07,Héctor Villalobos and Eduardo González-Rodríguez,https://github.com/hvillalo/satin,TRUE,https://github.com/hvillalo/satin,6829,3,2022-06-01T19:06:26Z,2276.3333333333335
SAVER,"An implementation of a regularized regression prediction and 
    empirical Bayes method to recover the true gene expression profile in 
    noisy and sparse single-cell RNA-seq data. See Huang M, et al (2018) 
    <doi:10.1038/s41592-018-0033-z> for more details.",2019-11-13,Mo Huang,https://github.com/mohuangx/SAVER,TRUE,https://github.com/mohuangx/saver,14978,90,2022-06-13T01:37:13Z,166.42222222222222
sbfc,"An MCMC algorithm for simultaneous feature selection and classification, 
    and visualization of the selected features and feature interactions. 
    An implementation of SBFC by Krakovna, Du and Liu (2015), <arXiv:1506.02371>.",2022-01-15,Viktoriya Krakovna,https://github.com/vkrakovna/sbfc,TRUE,https://github.com/vkrakovna/sbfc,14108,16,2022-01-15T16:40:21Z,881.75
sbm,"A collection of tools and functions to adjust a variety of stochastic blockmodels (SBM). 
  Supports at the moment Simple, Bipartite, 'Multipartite' and Multiplex SBM (undirected or directed with Bernoulli,
  Poisson or Gaussian emission laws on the edges, and possibly covariate for Simple and Bipartite SBM).
  See Léger (2016) <arxiv:1602.07587>, 'Barbillon et al.' (2020) <doi:10.1111/rssa.12193> and 
  'Bar-Hen et al.' (2020) <arxiv:1807.10138>.",2021-06-09,Julien Chiquet,https://grosssbm.github.io/sbm/,TRUE,https://github.com/grosssbm/sbm,11677,10,2021-10-04T15:11:26Z,1167.7
sboost,"Creates classifier for binary outcomes using Adaptive Boosting 
    (AdaBoost) algorithm on decision stumps with a fast C++ implementation. 
    For a description of AdaBoost, see Freund and Schapire (1997) 
    <doi:10.1006/jcss.1997.1504>. This type of classifier is nonlinear, but
    easy to interpret and visualize. Feature vectors may be a combination of
    continuous (numeric) and categorical (string, factor) elements. Methods 
    for classifier assessment, predictions, and cross-validation also included.",2022-05-26,Jadon Wagstaff,https://github.com/jadonwagstaff/sboost,TRUE,https://github.com/jadonwagstaff/sboost,11759,2,2022-05-12T15:41:09Z,5879.5
sbtools,"Tools for interacting with U.S. Geological Survey ScienceBase
    <https://www.sciencebase.gov> interfaces. ScienceBase is a data cataloging and
    collaborative data management platform. Functions included for querying
    ScienceBase, and creating and fetching datasets.",2022-05-26,David Blodgett,https://github.com/USGS-R/sbtools,TRUE,https://github.com/usgs-r/sbtools,22695,17,2022-06-30T17:53:30Z,1335
scales,"Graphical scales map data to aesthetics, and provide methods
    for automatically determining breaks and labels for axes and legends.",2022-04-13,Hadley Wickham,"https://scales.r-lib.org, https://github.com/r-lib/scales",TRUE,https://github.com/r-lib/scales,20249408,325,2022-04-14T14:23:09Z,62305.87076923077
scan,"A collection of procedures for analysing, visualising, 
  and managing single-case data. These include piecewise linear regression 
  models, multilevel models, overlap indices (PND, PEM, PAND, PET, tauU, 
  baseline corrected tau, CDC), and randomization tests. Data preparation functions 
  support outlier detection, handling missing values, scaling, truncating, 
  rank transformation, and smoothing. An exporting function helps to generate 
  html and latex tables in a publication friendly style. More details can be 
  found at <https://jazznbass.github.io/scan-Book/>.",2022-04-03,Juergen Wilbert,"https://github.com/jazznbass/scan/,
https://jazznbass.github.io/scan-Book/",TRUE,https://github.com/jazznbass/scan,18756,2,2022-06-22T09:06:15Z,9378
scapesClassification,"Series of algorithms to translate  users' mental models of seascapes, 
  landscapes and, more generally, of geographic features into computer representations 
  (classifications). Spaces and geographic objects are classified with user-defined 
  rules taking into account spatial data as well as spatial relationships among 
  different classes and objects.",2022-03-16,Gerald H. Taranto,"https://github.com/ghTaranto/scapesClassification,
https://ghtaranto.github.io/scapesClassification/",TRUE,https://github.com/ghtaranto/scapesclassification,880,0,2022-03-28T18:58:20Z,NA
scatr,"Allows you to make clean, good-looking scatter plots with the option to 
    easily add marginal density or box plots on the axes. It is also available as a module for 'jamovi'
    (see <https://www.jamovi.org> for more information). 'Scatr' is based on the 
    'cowplot' package by Claus O. Wilke and the 'ggplot2' package by Hadley Wickham.",2017-12-05,Ravi Selker,https://github.com/raviselker/scatr,TRUE,https://github.com/raviselker/scatr,13631,2,2022-02-10T21:25:53Z,6815.5
scatterD3,"Creates 'D3' 'JavaScript' scatterplots from 'R' with interactive
    features : panning, zooming, tooltips, etc.",2021-10-06,Julien Barnier,https://juba.github.io/scatterD3/,TRUE,https://github.com/juba/scatterd3,53030,149,2021-10-06T09:41:29Z,355.90604026845637
scattermore,"C-based conversion of large scatterplot data to rasters. Speeds up
             plotting of data with millions of points.",2022-02-14,Mirek Kratochvil,https://github.com/exaexa/scattermore,TRUE,https://github.com/exaexa/scattermore,255945,175,2022-04-20T09:27:21Z,1462.5428571428572
scCATCH,"An automatic cluster-based annotation pipeline based on evidence-based score by matching the marker genes with known cell markers in tissue-specific cell taxonomy reference database for single-cell RNA-seq data. See Shao X, et al (2020) <doi:10.1016/j.isci.2020.100882> for more details.",2022-05-14,Xin Shao,https://github.com/ZJUFanLab/scCATCH,TRUE,https://github.com/zjufanlab/sccatch,3476,135,2022-05-14T07:00:20Z,25.748148148148147
sccore,"Core utilities for single-cell RNA-seq data analysis. Contained within are utility functions for working with differential expression (DE) matrices and count matrices, a collection of functions for manipulating and plotting data via 'ggplot2', and functions to work with cell graphs and cell embeddings. Graph-based methods include embedding kNN cell graphs into a UMAP <doi:10.21105/joss.00861>, collapsing vertices of each cluster in the graph, and propagating graph labels.",2021-12-12,Evan Biederstedt,https://github.com/kharchenkolab/sccore,TRUE,https://github.com/kharchenkolab/sccore,18603,8,2021-12-12T04:51:48Z,2325.375
scDHA,"Provides a fast and accurate pipeline for single-cell analyses. 
    The 'scDHA' software package can perform clustering, dimension reduction and visualization, classification, and time-trajectory inference on single-cell data (Tran et.al. (2021) <DOI:10.1038/s41467-021-21312-2>).",2021-09-15,Duc Tran,https://github.com/duct317/scDHA,TRUE,https://github.com/duct317/scdha,4645,25,2022-06-30T18:49:13Z,185.8
scdhlm,"Provides a set of tools for estimating hierarchical linear
    models and effect sizes based on data from single-case designs. 
    Functions are provided for calculating standardized mean difference effect sizes that 
    are directly comparable to standardized mean differences estimated from between-subjects randomized experiments,
    as described in Hedges, Pustejovsky, and Shadish (2012) <DOI:10.1002/jrsm.1052>; 
    Hedges, Pustejovsky, and Shadish (2013) <DOI:10.1002/jrsm.1086>; and 
    Pustejovsky, Hedges, and Shadish (2014) <DOI:10.3102/1076998614547577>. 
    Includes an interactive web interface.",2022-07-07,James Pustejovsky,https://jepusto.github.io/scdhlm/,TRUE,https://github.com/jepusto/scdhlm,29378,2,2022-07-08T19:48:34Z,14689
SCEM,"We introduce improved methods for statistically assessing birth seasonality and intra-annual variation. The first method we propose is a new idea that uses a nonparametric clustering procedure to group individuals with similar time series data and estimate birth seasonality based on the clusters. One can use the function SCEM() to implement this method. The second method estimates input parameters for use with a previously-developed parametric approach (Tornero et al., 2013). The relevant code for this approach is makeFits_OLS(), while makeFits_initial() is the code to implement the same method but with given initial conditions for two parameters. The latter can be used to show the disadvantage of the existing approach. One can use the function makeFits() to generate parametric birth seasonality estimates using either initialization. Detailed description can be found here: Chazin Hannah, Soudeep Deb, Joshua Falk, and Arun Srinivasan. (2019) ""New Statistical Approaches to Intra-Individual Isotopic Analysis and Modeling Birth Seasonality in Studies of Herd Animals."" <doi:10.1111/arcm.12432>.",2021-09-02,Kyung Serk Cho,https://github.com/kserkcho/SCEM,TRUE,https://github.com/kserkcho/scem,3577,0,2021-08-28T14:59:16Z,NA
scholar,"Provides functions to extract citation data from Google
    Scholar.  Convenience functions are also provided for comparing
    multiple scholars and predicting future h-index values.",2022-06-23,Guangchuang Yu,https://github.com/YuLab-SMU/scholar,TRUE,https://github.com/yulab-smu/scholar,41541,12,2022-06-25T02:24:27Z,3461.75
schrute,"The complete scripts from the American version of
    the Office television show in tibble format. Use this package to
    analyze and have fun with text from the best series of all time.",2020-06-30,Brad Lindblad,https://github.com/bradlindblad/schrute,TRUE,https://github.com/bradlindblad/schrute,17159,16,2022-02-06T03:11:02Z,1072.4375
schtools,"A collection of useful functions and example code created and
    used by the Schloss Lab for reproducible microbiome research. Perform
    common tasks like read files created by mothur <https://mothur.org/>,
    tidy up your microbiome data, and format R Markdown documents for
    publication.  See the website <http://www.schlosslab.org/schtools/>
    for more information, documentation, and examples.",2022-05-11,Kelly Sovacool,"http://www.schlosslab.org/schtools/,
https://github.com/SchlossLab/schtools",TRUE,https://github.com/schlosslab/schtools,2278,23,2022-07-08T19:57:47Z,99.04347826086956
SCIBER,Remove batch effects by projecting query batches into the reference batch space.,2022-07-06,Dailin Gan,https://github.com/RavenGan/SCIBER,TRUE,https://github.com/ravengan/sciber,613,1,2022-07-06T15:42:52Z,613
scico,"Colour choice in information visualisation is important in order to
    avoid being mislead by inherent bias in the used colour palette. The 'scico'
    package provides access to the perceptually uniform and colour-blindness 
    friendly palettes developed by Fabio Crameri and released under the 
    ""Scientific Colour-Maps"" moniker. The package contains 24 different palettes 
    and includes both diverging and sequential types.",2021-12-08,Thomas Lin Pedersen,https://github.com/thomasp85/scico,TRUE,https://github.com/thomasp85/scico,124057,309,2021-12-08T09:26:41Z,401.4789644012945
scImmuneGraph,"Statistics and visualization of the distribution, diversity and composition of clonotypes, the abundance and length distribution of CDR3, the respective abundance distribution of V and J genes, and the abundance of V-J gene pairs are the basic requirements for single-cell immune group analysis. 'scImmuneGraph' is designed to process data from 10x Genomics Chromium Immune Profiling for T cell receptor (TCR) and immunoglobulin (Ig) enrichment workflows.",2021-12-10,Fenfei Zhao,https://github.com/zff-excellent/scImmuneGraph,TRUE,https://github.com/zff-excellent/scimmunegraph,1518,0,2021-12-16T02:14:06Z,NA
scINSIGHT,"We develop a novel matrix factorization tool named 'scINSIGHT' to jointly analyze multiple single-cell gene expression samples from biologically heterogeneous sources, such as different disease phases, treatment groups, or developmental stages. Given multiple gene expression samples from different biological conditions, 'scINSIGHT' simultaneously identifies common and condition-specific gene modules and quantify their expression levels in each sample in a lower-dimensional space. With the factorized results, the inferred expression levels and memberships of common gene modules can be used to cluster cells and detect cell identities, and the condition-specific gene modules can help compare functional differences in transcriptomes from distinct conditions. Please also see Qian K, Fu SW, Li HW, Li WV (2022) <doi:10.1186/s13059-022-02649-3>.",2022-05-29,Kun Qian,"https://github.com/Vivianstats/scINSIGHT,
https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02649-3",TRUE,https://github.com/vivianstats/scinsight,5537,13,2022-05-29T06:35:19Z,425.9230769230769
sciRmdTheme,A set of 'Rmarkdown' themes for creating scientific and professional documents. Simple interface with features to ease navigation across the page and sub-pages.,2022-06-30,Obinna Obianom,https://github.com/oobianom/sciRmdTheme,TRUE,https://github.com/oobianom/scirmdtheme,119,0,2022-07-06T16:06:18Z,NA
scISR,"Provides an imputation pipeline for single-cell RNA sequencing data. 
  The 'scISR' method uses a hypothesis-testing technique to identify zero-valued entries that are most likely affected by dropout events and estimates the dropout values using a subspace regression model (Tran et.al. (2022) <DOI:10.1038/s41598-022-06500-4>).",2022-06-30,Duc Tran,https://github.com/duct317/scISR,TRUE,https://github.com/duct317/scisr,113,2,2022-06-30T18:47:05Z,56.5
scOntoMatch,"Unequal granularity of cell type annotation makes it difficult to compare scRNA-seq datasets at scale. Leveraging the ontology system for defining cell type hierarchy, 'scOntoMatch' aims to align cell type annotations to make them comparable across studies. The alignment involves two core steps: first is to trim the cell type tree within each dataset so each cell type does not have descendants, and then map cell type labels cross-studies by direct matching and mapping descendants to ancestors. Various functions for plotting cell type trees and manipulating ontology terms are also provided. In the Single Cell Expression Atlas hosted at EBI, a compendium of datasets with curated ontology labels are great inputs to this package.",2022-06-27,Yuyao Song,https://github.com/YY-SONG0718/scOntoMatch,TRUE,https://github.com/yy-song0718/scontomatch,164,2,2022-06-09T16:03:08Z,82
scopr,"Handling of behavioural data from the Ethoscope platform 
    (Geissmann, Garcia Rodriguez, Beckwith, French, Jamasb and Gilestro (2017) <DOI:10.1371/journal.pbio.2003026>).
    Ethoscopes (<http://gilestrolab.github.io/ethoscope/>) are an open source/open hardware framework made of 
    interconnected raspberry pis (<https://www.raspberrypi.org>) designed to quantify the behaviour of multiple 
    small animals in a distributed and real-time fashion. The default tracking algorithm records primary variables
    such as xy coordinates, dimensions and speed.
    This package is part of the rethomics framework <http://rethomics.github.io/>.",2019-02-15,Quentin Geissmann,https://github.com/rethomics/scopr,TRUE,https://github.com/rethomics/scopr,11626,3,2022-02-03T12:42:44Z,3875.3333333333335
scorecard,"
  The `scorecard` package makes the development of credit risk scorecard 
  easier and efficient by providing functions for some common tasks, 
  such as data partition, variable selection, woe binning, scorecard scaling,
  performance evaluation and report generation. These functions can also used
  in the development of machine learning models.
    The references including: 
  1. Refaat, M. (2011, ISBN: 9781447511199). Credit Risk Scorecard: 
  Development and Implementation Using SAS. 
  2. Siddiqi, N. (2006, ISBN: 9780471754510). Credit risk scorecards. 
  Developing and Implementing Intelligent Credit Scoring.",2022-07-09,Shichen Xie,"https://github.com/ShichenXie/scorecard,
http://shichen.name/scorecard/",TRUE,https://github.com/shichenxie/scorecard,260060,137,2022-07-09T07:10:19Z,1898.2481751824816
scoringRules,"Dictionary-like reference for computing scoring rules in a wide
    range of situations. Covers both parametric forecast distributions (such as
    mixtures of Gaussians) and distributions generated via simulation.",2020-10-05,Alexander Jordan,https://github.com/FK83/scoringRules,TRUE,https://github.com/fk83/scoringrules,68193,38,2022-01-15T22:10:01Z,1794.5526315789473
scoringutils,"
    Provides a collection of metrics and proper scoring rules 
    (Tilmann Gneiting & Adrian E Raftery (2007) 
    <doi:10.1198/016214506000001437>, Jordan, A., Krüger, F., & Lerch, S. (2019)
    <doi:10.18637/jss.v090.i12>) within a consistent framework for 
    evaluation, comparison and visualisation of forecasts. 
    In addition to proper scoring rules, functions are provided to assess 
    bias, sharpness and calibration 
    (Sebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe, Rosalind
    M. Eggo, W. John Edmunds (2019) <doi:10.1371/journal.pcbi.1006785>) of 
    forecasts. 
    Several types of predictions (e.g. binary, discrete, continuous) which may 
    come in different formats (e.g. forecasts represented by predictive samples 
    or by quantiles of the predictive distribution) can be evaluated. 
    Scoring metrics can be used either through a convenient data.frame format, 
    or can be applied as individual functions in a vector / matrix format. 
    All functionality has been implemented with a focus on performance and is 
    robustly tested. ",2022-05-13,Nikos Bosse,"https://epiforecasts.io/scoringutils/,
https://github.com/epiforecasts/scoringutils",TRUE,https://github.com/epiforecasts/scoringutils,14864,20,2022-07-09T22:19:18Z,743.2
scrappy,"A group of functions to scrape data from different websites, for 
    academic purposes.",2021-01-09,Roberto Villegas-Diaz,"https://github.com/villegar/scrappy/,
https://villegar.github.io/scrappy/",TRUE,https://github.com/villegar/scrappy,5289,3,2021-08-10T21:04:49Z,1763
SCRIP,"We provide a comprehensive scheme that is capable of simulating Single Cell RNA Sequencing data for various parameters of Biological Coefficient of Variation,
    busting kinetics, differential expression (DE), cell or sample groups, cell trajectory, batch effect and other experimental designs.
    'SCRIP' proposed and compared two frameworks with Gamma-Poisson and Beta-Gamma-Poisson models for simulating Single Cell RNA Sequencing data.
	Other reference is available in Zappia et al. (2017) <https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1305-0>.",2021-11-19,Fei Qin,https://github.com/thecailab/SCRIP,TRUE,https://github.com/thecailab/scrip,1301,1,2021-11-22T20:51:48Z,1301
scrm,"A coalescent simulator that allows the rapid simulation of
    biological sequences under neutral models of evolution. Different to other
    coalescent based simulations, it has an optional approximation parameter that
    allows for high accuracy while maintaining a linear run time cost for long
    sequences. It is optimized for simulating massive data sets as produced by Next-
    Generation Sequencing technologies for up to several thousand sequences.",2022-02-14,Dirk Metzler,https://github.com/scrm/scrm-r,TRUE,https://github.com/scrm/scrm-r,15552,7,2022-02-14T11:36:50Z,2221.714285714286
scrobbler,"'Last.fm'<https://www.last.fm> is a music platform focussed on building a 
    detailed profile of a users listening habits. It does this by 'scrobbling' (recording) 
    every track you listen to on other platforms ('spotify', 'youtube', 'soundcloud' etc)
    and transferring them to your 'Last.fm' database. This allows 'Last.fm' to act as a 
    complete record of your entire listening history. 'scrobbler' provides helper functions
    to download and analyse your listening history in R.",2021-08-15,Conor Neilson,https://github.com/condwanaland/scrobbler,TRUE,https://github.com/condwanaland/scrobbler,13105,2,2021-08-29T04:04:58Z,6552.5
scrypt,"Functions for working with the scrypt key derivation functions
    originally described by Colin Percival
    <https://www.tarsnap.com/scrypt/scrypt.pdf> and in Percival and Josefsson
    (2016) <doi:10.17487/RFC7914>. Scrypt is a password-based key derivation
    function created by Colin Percival. The algorithm was specifically designed
    to make it costly to perform large-scale custom hardware attacks by
    requiring large amounts of memory.",2022-04-19,Bob Jansen [ctb,https://github.com/rstudio/rscrypt,TRUE,https://github.com/rstudio/rscrypt,40694,32,2022-04-19T14:01:46Z,1271.6875
scryr,"A simple, light, and robust interface between R and
    the 'Scryfall' card data API <https://scryfall.com/docs/api>.",2022-01-28,Caio Lente,"https://curso-r.github.io/scryr/, https://github.com/curso-r/scryr",TRUE,https://github.com/curso-r/scryr,1469,14,2022-01-28T20:34:46Z,104.92857142857143
scs,"Solves convex cone programs via operator splitting. Can solve:
    linear programs ('LPs'), second-order cone programs ('SOCPs'), semidefinite programs
    ('SDPs'), exponential cone programs ('ECPs'), and power cone programs ('PCPs'), or
    problems with any combination of those cones. 'SCS' uses 'AMD' (a set of routines for permuting sparse matrices prior to factorization) and 'LDL' (a sparse 'LDL' factorization and solve package) from 'SuiteSparse' (<https://people.engr.tamu.edu/davis/suitesparse.html>).",2021-11-07,Florian Schwendinger,https://github.com/FlorianSchwendinger/scs,TRUE,https://github.com/florianschwendinger/scs,77083,5,2021-11-07T20:17:02Z,15416.6
scTenifoldKnk,"A workflow based on 'scTenifoldNet' to perform in-silico knockout experiments using single-cell RNA sequencing (scRNA-seq) data from wild-type (WT) control samples as input.  First, the package constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the gene’s outdegree edges to zero. Then, it compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the gene’s function in the analyzed cells.",2021-01-22,Daniel Osorio,https://github.com/cailab-tamu/scTenifoldKnk,TRUE,https://github.com/cailab-tamu/sctenifoldknk,6026,22,2022-01-22T00:22:56Z,273.90909090909093
scTenifoldNet,"A workflow based on machine learning methods to construct and compare single-cell gene regulatory networks (scGRN) using single-cell RNA-seq (scRNA-seq) data collected from different conditions. Uses principal component regression, tensor decomposition, and manifold alignment, to accurately identify even subtly shifted gene expression programs. See <doi:10.1016/j.patter.2020.100139> for more details.",2021-10-29,Daniel Osorio,https://github.com/cailab-tamu/scTenifoldNet,TRUE,https://github.com/cailab-tamu/sctenifoldnet,15638,14,2022-05-09T15:19:17Z,1117
SCtools,"Extensions to the synthetic controls analyses 
    performed by the package 'Synth' as detailed in Abadie, Diamond, and Hainmueller (2011) <doi: 10.18637/jss.v042.i13>. Includes generating 
    and plotting placebos, post/pre-MSPE (Mean Squared Prediction Error) significance tests and plots, 
    and calculating average treatment effects for multiple treated units. 
    This package represents an implementation of those methods 
    suggested in 
    Abadie, Diamond,and Hainmueller (2010) <doi:10.1198/jasa.2009.ap08746> for
    use in Synthetic Control Analysis.",2022-06-09,Bruno Castanho Silva,NA,TRUE,https://github.com/bcastanho/sctools,15571,9,2022-06-02T09:58:12Z,1730.111111111111
sctransform,"A normalization method for single-cell UMI count data using a 
  variance stabilizing transformation. The transformation is based on a 
  negative binomial regression model with regularized parameters. As part of the
  same regression framework, this package also provides functions for
  batch correction, and data correction. See Hafemeister and Satija (2019)
  <doi:10.1186/s13059-019-1874-1>, and Choudhary and Satija (2021) <doi:10.1101/2021.07.07.451498>
  for more details.",2022-01-13,Christoph Hafemeister,https://github.com/satijalab/sctransform,TRUE,https://github.com/satijalab/sctransform,411203,143,2022-03-23T16:30:26Z,2875.5454545454545
sdcHierarchies,"Provides functionality to generate, (interactively) modify (by adding, removing and renaming nodes) and convert nested hierarchies between different formats.
  These tree like structures can be used to define for example complex hierarchical tables used for statistical disclosure control.",2022-04-22,Bernhard Meindl,https://github.com/bernhard-da/sdcHierarchies,TRUE,https://github.com/bernhard-da/sdchierarchies,18145,0,2022-04-22T06:05:35Z,NA
sdcLog,"Tools for researchers to explicitly show that their results
    comply to rules for statistical disclosure control imposed by research
    data centers. These tools help in checking descriptive statistics and
    models and in calculating extreme values that are not individual data.
    Also included is a simple function to create log files. The methods
    used here are described in the ""Guidelines for the checking of output
    based on microdata research"" by Bond, Brandt, and de Wolf (2015)
    <https://ec.europa.eu/eurostat/cros/system/files/dwb_standalone-document_output-checking-guidelines.pdf>.",2022-03-19,Matthias Gomolka,https://github.com/matthiasgomolka/sdcLog,TRUE,https://github.com/matthiasgomolka/sdclog,7366,3,2022-04-01T10:53:41Z,2455.3333333333335
sdcMicro,"Data from statistical agencies and other institutions are mostly
    confidential. This package (see also Templ, Kowarik and Meindl (2017) <doi:10.18637/jss.v067.i04>) can be used for the generation of anonymized
    (micro)data, i.e. for the creation of public- and scientific-use files.
    The theoretical basis for the methods implemented can be found in Templ (2017) <doi:10.1007/978-3-319-50272-4>.
    Various risk estimation and anonymisation methods are included. Note that the package
    includes a graphical user interface (Meindl and Templ, 2019 <doi:10.3390/a12090191>) that allows to use various methods of this
    package.",2021-07-26,Matthias Templ,https://github.com/sdcTools/sdcMicro,TRUE,https://github.com/sdctools/sdcmicro,102442,54,2022-07-05T10:31:26Z,1897.0740740740741
sdcSpatial,"Privacy protected raster maps 
  can be created from spatial point data. Protection
  methods include smoothing of dichotomous variables by de Jonge and de Wolf (2016) 
  <doi:10.1007/978-3-319-45381-1_9>, continuous variables by de Wolf and 
  de Jonge (2018) <doi:10.1007/978-3-319-99771-1_23>, suppressing 
  revealing values and a generalization of the quad tree method by 
  Suñé, Rovira, Ibáñez and Farré (2017) <doi:10.2901/EUROSTAT.C2017.001>.",2022-03-24,Edwin de Jonge,https://github.com/edwindj/sdcSpatial,TRUE,https://github.com/edwindj/sdcspatial,11790,5,2022-03-24T12:54:15Z,2358
sdcTable,"Methods for statistical disclosure control in
    tabular data such as primary and secondary cell suppression as described for example
    in Hundepol et al. (2012) <doi:10.1002/9781118348239> are covered in this package.",2021-12-03,Bernhard Meindl,https://github.com/sdcTools/sdcTable,TRUE,https://github.com/sdctools/sdctable,31559,4,2021-12-03T09:44:03Z,7889.75
sdetorus,"Implementation of statistical methods for the estimation of
    toroidal diffusions. Several diffusive models are provided, most of them
    belonging to the Langevin family of diffusions on the torus. Specifically,
    the wrapped normal and von Mises processes are included, which can be seen
    as toroidal analogues of the Ornstein-Uhlenbeck diffusion. A collection of
    methods for approximate maximum likelihood estimation, organized in four
    blocks, is given: (i) based on the exact transition probability density,
    obtained as the numerical solution to the Fokker-Plank equation; (ii) based
    on wrapped pseudo-likelihoods; (iii) based on specific analytic
    approximations by wrapped processes; (iv) based on maximum likelihood of
    the stationary densities. The package allows the reproducibility of the
    results in García-Portugués et al. (2019) <doi:10.1007/s11222-017-9790-2>.",2021-08-19,Eduardo García-Portugués,https://github.com/egarpor/sdetorus,TRUE,https://github.com/egarpor/sdetorus,7856,3,2021-08-26T00:58:25Z,2618.6666666666665
SDLfilter,"Functions to filter GPS/Argos locations, as well as assessing the sample size for the analysis of animal distributions. The filters remove temporal and spatial duplicates, fixes located at a given height from estimated high tide line, and locations with high error as described in Shimada et al. (2012) <doi:10.3354/meps09747> and Shimada et al. (2016) <doi:10.1007/s00227-015-2771-0>. Sample size for the analysis of animal distributions can be assessed by the conventional area-based approach or the alternative probability-based approach as described in Shimada et al. (2021) <doi:10.1111/2041-210X.13506>. ",2022-05-24,Takahiro Shimada,https://github.com/TakahiroShimada/SDLfilter,TRUE,https://github.com/takahiroshimada/sdlfilter,17101,3,2022-05-30T07:30:25Z,5700.333333333333
sdmpredictors,"Terrestrial and marine predictors for species distribution modelling
    from multiple sources, including WorldClim <https://www.worldclim.org/>,,
    ENVIREM <https://envirem.github.io/>, Bio-ORACLE <https://bio-oracle.org/>
    and MARSPEC <http://www.marspec.org/>.",2022-02-24,Salvador Fernandez,http://lifewatch.github.io/sdmpredictors/,TRUE,https://github.com/lifewatch/sdmpredictors,30893,22,2022-02-23T14:34:04Z,1404.2272727272727
SDMtune,"User-friendly framework that enables the training and the
    evaluation of species distribution models (SDMs). The package implements
    functions for data driven variable selection and model tuning and includes
    numerous utilities to display the results. All the functions used to select
    variables or to tune model hyperparameters have an interactive real-time
    chart displayed in the 'RStudio' viewer pane during their execution.",2021-07-17,Sergio Vignali,"https://consbiol-unibern.github.io/SDMtune/,
https://github.com/ConsBiol-unibern/SDMtune",TRUE,https://github.com/consbiol-unibern/sdmtune,18726,12,2021-12-03T08:31:18Z,1560.5
SEAGLE,"
    The explosion of biobank data offers immediate opportunities for 
    gene-environment (GxE) interaction studies of complex diseases because of the 
    large sample sizes and rich collection in genetic and non-genetic information. 
    However, the extremely large sample size also introduces new computational 
    challenges in GxE assessment, especially for set-based GxE variance component (VC) 
    tests, a widely used strategy to boost overall GxE signals and to evaluate the 
    joint GxE effect of multiple variants from a biologically meaningful unit 
    (e.g., gene). 
    We present 'SEAGLE', a Scalable Exact AlGorithm for Large-scale Set-based 
    GxE tests, to permit GxE VC test scalable to biobank data. 'SEAGLE' employs modern 
    matrix computations to achieve the same “exact” results as the original GxE VC 
    tests, and does not impose additional assumptions nor relies on approximations. 
    'SEAGLE' can easily accommodate sample sizes in the order of 10^5, is implementable 
    on standard laptops, and does not require specialized equipment. 
    The accompanying manuscript for this package can be found at Chi, Ipsen, Hsiao, 
    Lin, Wang, Lee, Lu, and Tzeng. (2021+) <arXiv:2105.03228>.",2021-11-05,Jocelyn Chi,https://github.com/jocelynchi/SEAGLE,TRUE,https://github.com/jocelynchi/seagle,4226,0,2021-11-05T21:29:54Z,NA
searchConsoleR,"Provides an interface with the Google Search Console,
    formally called Google Webmaster Tools.",2019-09-06,Mark Edmondson,http://code.markedmondson.me/searchConsoleR/,TRUE,https://github.com/markedmondson1234/searchconsoler,28900,106,2022-06-21T13:39:58Z,272.64150943396226
searcher,"Provides a search interface to look up terms
    on 'Google', 'Bing', 'DuckDuckGo', 'Startpage', 'Ecosia', 'rseek',
    'Twitter', 'StackOverflow', 'RStudio Community', 'GitHub', and 'BitBucket'.
    Upon searching, a browser window will open with the aforementioned search
    results.",2021-07-24,James Balamuta,https://github.com/r-assist/searcher,TRUE,https://github.com/r-assist/searcher,17889,66,2021-07-24T19:14:53Z,271.04545454545456
seas,"Capable of deriving seasonal statistics, such as ""normals"", and
  analysis of seasonal data, such as departures. This package also has
  graphics capabilities for representing seasonal data, including boxplots for
  seasonal parameters, and bars for summed normals. There are many specific
  functions related to climatology, including precipitation normals,
  temperature normals, cumulative precipitation departures and precipitation
  interarrivals. However, this package is designed to represent any
  time-varying parameter with a discernible seasonal signal, such as found
  in hydrology and ecology.",2022-05-02,Mike Toews,https://github.com/mwtoews/seas,TRUE,https://github.com/mwtoews/seas,28609,8,2022-05-01T09:48:16Z,3576.125
seasonal,"Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment
    software by the US Census Bureau. It offers full access to almost all
    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model
    search, outlier detection and support for user defined holiday variables,
    such as Chinese New Year or Indian Diwali. A graphical user interface can be
    used through the 'seasonalview' package. Uses the X-13-binaries from the
    'x13binary' package.",2022-04-18,Christoph Sax,http://www.seasonal.website,TRUE,https://github.com/christophsax/seasonal,368903,109,2022-04-19T14:44:35Z,3384.4311926605506
seasonalclumped,"Compiles a set of functions and dummy data that simplify reconstructions of seasonal temperature
	 variability in the geological past from stable isotope and clumped isotope records in sub–annually resolved
	 carbonate archives (e.g. mollusk shells, corals and speleothems). For more information, see
	 de Winter et al., 2020 (Climate of the Past Discussions, <doi:10.5194/cp-2020-118>).",2021-01-14,Niels de Winter,https://github.com/nielsjdewinter/seasonalclumped,TRUE,https://github.com/nielsjdewinter/seasonalclumped,5171,1,2022-03-10T07:51:54Z,5171
secr,"Functions to estimate the density and size of a spatially distributed animal population sampled with an array of passive detectors, such as traps, or by searching polygons or transects. Models incorporating distance-dependent detection are fitted by maximizing the likelihood. Tools are included for data manipulation and model selection.",2022-05-31,Murray Efford,"https://github.com/MurrayEfford/secr/,
https://www.otago.ac.nz/density/",TRUE,https://github.com/murrayefford/secr,59998,0,2022-07-01T10:36:43Z,NA
secuTrialR,"Seamless and standardized interaction with data
    exported from the clinical data management system (CDMS)
    'secuTrial'<https://www.secutrial.com>.
    The primary data export the package works with is a standard non-rectangular export.",2021-03-11,Alan G. Haynes,https://github.com/SwissClinicalTrialOrganisation/secuTrialR,TRUE,https://github.com/swissclinicaltrialorganisation/secutrialr,9334,7,2022-05-09T06:37:11Z,1333.4285714285713
sedproxy,"Proxy forward modelling for sediment archived climate proxies such 
  as Mg/Ca, d18O or Alkenones. The user provides a hypothesised ""true"" past climate, 
  such as output from a climate model, and details of the sedimentation rate and 
  sampling scheme of a sediment core. Sedproxy returns simulated proxy records. 
  Implements the methods described in Dolman and Laepple (2018) 
  <doi:10.5194/cp-14-1851-2018>.",2022-03-31,Andrew Dolman,"https://earthsystemdiagnostics.github.io/sedproxy/,
https://github.com/EarthSystemDiagnostics/sedproxy",TRUE,https://github.com/earthsystemdiagnostics/sedproxy,807,6,2022-03-30T15:47:10Z,134.5
see,"Provides plotting utilities supporting easystats-packages
    (<https://github.com/easystats/easystats>) and some extra themes,
    geoms, and scales for 'ggplot2'. Color scales are based on
    <https://materialui.co/colors>.",2022-06-20,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>,https://easystats.github.io/see/,TRUE,https://github.com/easystats/see,210069,642,2022-06-25T07:57:16Z,327.2102803738318
seecolor,"Output colors used in literal vectors, palettes and plot objects (ggplot).",2020-12-07,Shangchen Song,https://github.com/lovestat/seecolor,TRUE,https://github.com/lovestat/seecolor,6241,1,2021-11-25T03:57:15Z,6241
seededlda,"Implements the seeded-LDA model (Lu, Ott, Cardie & Tsou 2010) <doi:10.1109/ICDMW.2011.125> using the quanteda package and the GibbsLDA++ library for semisupervised topic modeling. 
    Seeded-LDA allows users to pre-define topics with keywords to perform theory-driven analysis of textual data in social sciences and humanities (Watanabe & Zhou 2020) <doi:10.1177/0894439320907027>.",2022-03-28,Kohei Watanabe,https://github.com/koheiw/seededlda,TRUE,https://github.com/koheiw/seededlda,21927,41,2022-04-11T00:53:42Z,534.8048780487804
seeds,"Algorithms to calculate the hidden inputs of systems of differential equations. 
  These hidden inputs can be interpreted as a control that tries to minimize the
  discrepancies between a given model and taken measurements. The idea is 
  also called the Dynamic Elastic Net, as proposed in the paper ""Learning (from) the errors of a systems biology model"" 
  (Engelhardt, Froelich, Kschischo 2016) <doi:10.1038/srep20772>.
  To use the experimental SBML import function, the 'rsbml' package is required. For installation I refer to the official 'rsbml' page: <https://bioconductor.org/packages/release/bioc/html/rsbml.html>.",2020-07-14,Tobias Newmiwaka,https://github.com/Newmi1988/seeds,TRUE,https://github.com/newmi1988/seeds,11415,0,2021-07-30T10:53:35Z,NA
seer,A novel meta-learning framework for forecast model selection using time series features. Many applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. We propose a classification framework which selects forecast models based on features calculated from the time series. We call this framework FFORMS (Feature-based FORecast Model Selection). FFORMS builds a mapping that relates the features of time series to the best forecast model using a random forest. 'seer' package is the implementation of the FFORMS algorithm. For more details see our paper at <https://www.monash.edu/business/econometrics-and-business-statistics/research/publications/ebs/wp06-2018.pdf>.,2021-12-08,Thiyanga Talagala,https://thiyangt.github.io/seer/,TRUE,https://github.com/thiyangt/seer,15471,74,2021-12-08T02:20:09Z,209.06756756756758
segclust2d,"Provides two methods for segmentation and joint segmentation/clustering of
    bivariate time-series. Originally intended for ecological segmentation
    (home-range and behavioural modes) but easily applied on other series,
    the package also provides tools for analysing outputs from R packages 'moveHMM' and 'marcher'.
    The segmentation method is a bivariate extension of  Lavielle's method available in 'adehabitatLT' 
    (Lavielle, 1999 <doi:10.1016/S0304-4149(99)00023-X> and 2005 <doi:10.1016/j.sigpro.2005.01.012>).
    This method rely on dynamic programming for efficient segmentation.
    The segmentation/clustering method alternates steps of dynamic programming with an Expectation-Maximization algorithm.
    This is an extension of Picard et al (2007) <doi:10.1111/j.1541-0420.2006.00729.x> method 
    (formerly available in 'cghseg' package) to the bivariate case.
    The method is fully described in Patin et al (2018) <doi:10.1101/444794>.",2021-10-11,Remi Patin,https://github.com/rpatin/segclust2d,TRUE,https://github.com/rpatin/segclust2d,13205,5,2021-10-11T07:51:17Z,2641
segRDA,"Tools for modeling non-continuous linear responses of ecological communities to environmental data. The package is straightforward through three steps: (1) data ordering (function OrdData()), (2) split-moving-window analysis (function SMW()) and (3) piecewise redundancy analysis (function pwRDA()). Relevant references include Cornelius and Reynolds (1991) <doi:10.2307/1941559> and Legendre and Legendre (2012, ISBN: 9780444538697).",2019-07-31,Danilo C Vieira,https://github.com/DaniloCVieira/segRDA,TRUE,https://github.com/danilocvieira/segrda,10322,2,2021-09-29T19:07:45Z,5161
segregation,"Computes segregation indices, including the Index of Dissimilarity,
    as well as the information-theoretic indices developed by
    Theil (1971) <isbn:978-0471858454>, namely
    the Mutual Information Index (M) and Theil's Information Index (H).
    The M, further described by Mora and Ruiz-Castillo (2011) <doi:10.1111/j.1467-9531.2011.01237.x>
    and Frankel and Volij (2011) <doi:10.1016/j.jet.2010.10.008>,
    is a measure of segregation that is highly decomposable. The package provides
    tools to decompose the index by units and groups (local segregation),
    and by within and between terms. The package also provides a method to decompose
    differences in segregation as described by Elbers (2021) <doi:10.1177/0049124121986204>.
    The package includes standard error estimation by bootstrapping, which also corrects for
    small sample bias.",2021-09-02,Benjamin Elbers,https://elbersb.github.io/segregation/,TRUE,https://github.com/elbersb/segregation,14050,29,2022-06-29T16:47:03Z,484.48275862068965
segregatr,"An implementation of the full-likelihood Bayes factor (FLB) 
    for evaluating segregation evidence in clinical medical genetics. The method 
    was introduced by Thompson et al. (2003) <doi:10.1086/378100>, and further 
    popularised by Bayrak-Toydemir et al. (2008) <doi:10.1016/j.yexmp.2008.03.006>.
    This implementation allows custom penetrance values and liability classes, and 
    includes specialised pedigree visualisations.",2021-04-15,Magnus Dehli Vigeland,https://github.com/magnusdv/segregatr,TRUE,https://github.com/magnusdv/segregatr,4466,2,2022-01-12T08:20:43Z,2233
sehrnett,"A very nice interface to Princeton's 'WordNet' without 'rJava' dependency. 'WordNet' data is not included. Princeton University makes 'WordNet' available to research and commercial users free of charge provided the terms of their license (<https://wordnet.princeton.edu/license-and-commercial-use>) are followed, and proper reference is made to the project using an appropriate citation (<https://wordnet.princeton.edu/citing-wordnet>).",2022-01-17,Chung-hong Chan,https://github.com/chainsawriot/sehrnett,TRUE,https://github.com/chainsawriot/sehrnett,1575,2,2022-01-17T15:20:15Z,787.5
SEIRfansy,"Extended Susceptible-Exposed-Infected-Recovery Model for 
    handling high false negative rate and symptom based administration of 
    diagnostic tests. <doi:10.1101/2020.09.24.20200238>.",2021-09-27,Michael Kleinsasser,https://github.com/umich-biostatistics/SEIRfansy,TRUE,https://github.com/umich-biostatistics/seirfansy,6668,2,2021-09-22T14:19:15Z,3334
SelectBoost,"An implementation of the selectboost algorithm (Bertrand et al. 2020, 'Bioinformatics', <doi:10.1093/bioinformatics/btaa855>), which is a general algorithm that improves the precision of any existing variable selection method. This algorithm is based on highly intensive simulations and takes into account the correlation structure of the data. It can either produce a confidence index for variable selection or it can be used in an experimental design planning perspective.",2021-03-20,Frederic Bertrand,"https://github.com/fbertran/SelectBoost,
http://www-irma.u-strasbg.fr/~fbertran/",TRUE,https://github.com/fbertran/selectboost,12396,6,2021-07-15T00:06:21Z,2066
selection.index,"The aim of most plant breeding programmes is simultaneous improvement of several characters. An objective method involving simultaneous selection for several attributes then becomes necessary. It has been recognised that most rapid improvements in the economic value is expected from selection applied simultaneously to all the characters which determine the economic value of a plant, and appropriate assigned weights to each character according to their economic importance, heritability and correlations between characters. So the selection for economic value is a complex matter. If the component characters are combined together into an index in such a way that when selection is applied to the index, as if index is the character to be improved, most rapid improvement of economic value is expected. Such an index was first proposed by Smith (1937 <doi:10.1111/j.1469-1809.1936.tb02143.x>) based on the Fisher's (1936 <doi:10.1111/j.1469-1809.1936.tb02137.x>) ""discriminant function"" Dabholkar (1999 <https://books.google.co.in/books?id=mlFtumAXQ0oC&lpg=PA4&ots=Xgxp1qLuxS&dq=elements%20of%20biometrical%20genetics&lr&pg=PP1#v=onepage&q&f=false>). In this package selection index is calculated based on the Smith (1937) selection index method.",2022-06-13,Zankrut Goyani,https://github.com/zankrut20/selection.index,TRUE,https://github.com/zankrut20/selection.index,5867,0,2022-06-13T18:55:18Z,NA
selectr,"Translates a CSS3 selector into an equivalent XPath
  expression. This allows us to use CSS selectors when working with
  the XML package as it can only evaluate XPath expressions. Also
  provided are convenience functions useful for using CSS selectors on
  XML nodes. This package is a port of the Python package 'cssselect'
  (<https://cssselect.readthedocs.io/>).",2019-11-20,Simon Potter,https://sjp.co.nz/projects/selectr,TRUE,https://github.com/sjp/selectr,12952403,51,2022-03-22T04:41:27Z,253968.6862745098
semantic.dashboard,It offers functions for creating dashboard with Fomantic UI. ,2021-11-09,Developers Appsilon,NA,TRUE,https://github.com/appsilon/semantic.dashboard,26618,209,2022-05-06T12:03:41Z,127.35885167464114
semEff,"Automatically calculate direct, indirect, and total effects for 
    piecewise structural equation models, comprising lists of fitted models 
    representing structured equations (Lefcheck 2016 <doi:10/f8s8rb>). 
    Confidence intervals are provided via bootstrapping.",2021-10-12,Mark Murphy,"https://murphymv.github.io/semEff/,
https://github.com/murphymv/semEff",TRUE,https://github.com/murphymv/semeff,45301,7,2021-10-18T15:07:14Z,6471.571428571428
semgram,"A framework for extracting semantic motifs around entities in textual data. It implements an entity-centered semantic grammar that distinguishes six classes of motifs: actions of an entity, treatments of an entity, agents acting upon an entity, patients acted upon by an entity, characterizations of an entity, and possessions of an entity. Motifs are identified by applying a set of extraction rules to a parsed text object that includes part-of-speech tags and dependency annotations - such as those generated by 'spacyr'. For further reference, see: Stuhler (2022) <doi: 10.1177/00491241221099551>.",2022-05-31,Oscar Stuhler,https://github.com/omstuhler/semgram,TRUE,https://github.com/omstuhler/semgram,289,5,2022-06-22T13:42:40Z,57.8
SEMgraph,"Estimate networks and causal relationships in complex systems through
  Structural Equation Modeling. This package also includes functions to import,
  weight, manipulate, and fit biological network models within the
  Structural Equation Modeling framework described in
  Palluzzi and Grassi (2021) <arXiv:2103.08332>.",2022-07-05,Barbara Tarantino,https://github.com/fernandoPalluzzi/SEMgraph,TRUE,https://github.com/fernandopalluzzi/semgraph,4441,9,2022-06-24T16:02:09Z,493.44444444444446
SEMID,"Provides routines to check identifiability or non-identifiability
    of linear structural equation models as described in Drton, Foygel, and
    Sullivant (2011) <doi:10.1214/10-AOS859>, Foygel, Draisma, and Drton (2012) 
    <doi:10.1214/12-AOS1012>, and other works. The routines are based on the graphical 
    representation of structural equation models.",2022-01-13,Nils Sturma,https://github.com/Lucaweihs/SEMID,TRUE,https://github.com/lucaweihs/semid,14998,3,2022-01-13T09:45:46Z,4999.333333333333
SemNeT,"Implements several functions for the analysis of semantic networks including different network estimation algorithms, partial node bootstrapping (Kenett, Anaki, & Faust, 2014 <doi:10.3389/fnhum.2014.00407>), random walk simulation (Kenett & Austerweil, 2016 <http://alab.psych.wisc.edu/papers/files/Kenett16CreativityRW.pdf>), and a function to compute global network measures. Significance tests and plotting features are also implemented. ",2021-09-04,Alexander P. Christensen,https://github.com/AlexChristensen/SemNeT,TRUE,https://github.com/alexchristensen/semnet,20750,12,2022-06-20T16:54:48Z,1729.1666666666667
SemNetCleaner,"Implements several functions that automates the cleaning and spell-checking of text data. Also converges, finalizes, removes plurals and continuous strings, and puts text data in binary format for semantic network analysis. Uses the 'SemNetDictionaries' package to make the cleaning process more accurate, efficient, and reproducible.",2021-09-16,Alexander P. Christensen,https://github.com/AlexChristensen/SemNetCleaner,TRUE,https://github.com/alexchristensen/semnetcleaner,19413,6,2022-06-22T18:42:55Z,3235.5
SemNetDictionaries,Implements dictionaries that can be used in the 'SemNetCleaner' package. Also includes several functions aimed at facilitating the text cleaning analysis in the 'SemNetCleaner' package. This package is designed to integrate and update word lists and dictionaries based on each user's individual needs by allowing users to store and save their own dictionaries. Dictionaries can be added to the 'SemNetDictionaries' package by submitting user-defined dictionaries to <https://github.com/AlexChristensen/SemNetDictionaries>.,2022-01-17,Alexander P. Christensen,https://github.com/AlexChristensen/SemNetDictionaries,TRUE,https://github.com/alexchristensen/semnetdictionaries,17639,2,2022-02-11T15:03:29Z,8819.5
semPlot,Path diagrams and visual analysis of various SEM packages' output.,2022-03-08,Sacha Epskamp,https://github.com/SachaEpskamp/semPlot,TRUE,https://github.com/sachaepskamp/semplot,348027,58,2022-06-08T10:11:06Z,6000.4655172413795
semPower,"Provides a-priori, post-hoc, and compromise power-analyses
    for structural equation models (SEM). Moshagen & Erdfelder (2016)
    <doi:10.1080/10705511.2014.950896>.",2021-11-01,Morten Moshagen,https://github.com/moshagen/semPower,TRUE,https://github.com/moshagen/sempower,14999,1,2021-11-23T18:30:00Z,14999
semptools,"Most function focus on specific ways to customize a graph. 
             They use a 'qgraph' output  as the first argument, and return a
             modified 'qgraph' object. This allows the functions to be chained
             by a pipe operator.",2021-10-11,Shu Fai Cheung,https://sfcheung.github.io/semptools/,TRUE,https://github.com/sfcheung/semptools,3790,2,2022-04-10T10:49:02Z,1895
sen2r,"Functions to download Sentinel-2 optical images
 and perform preliminary processing operations.
 'sen2r' provides the instruments required to easily perform
 (and eventually automate) the steps necessary to build a complete
 Sentinel-2 processing chain.
 A Graphical User Interface to facilitate data processing is also provided.
 For additional documentation refer to the following article: 
 Ranghetti et al. (2020) <doi:10.1016/j.cageo.2020.104473>.",2022-04-12,Luigi Ranghetti,https://sen2r.ranghetti.info,TRUE,https://github.com/ranghetti/sen2r,34632,146,2022-06-14T09:38:12Z,237.2054794520548
sendgridr,"Send email using 'Sendgrid' <https://sendgrid.com/> 
            mail API(v3) <https://docs.sendgrid.com/api-reference/how-to-use-the-sendgrid-v3-api/authentication>.",2021-12-19,Chanyub Park,https://github.com/mrchypark/sendgridr,TRUE,https://github.com/mrchypark/sendgridr,6508,19,2022-06-29T02:47:22Z,342.5263157894737
sensemakr,"Implements a suite of sensitivity analysis tools 
  that extends the traditional omitted variable bias framework and makes it easier 
  to understand the impact of omitted variables in regression models, as discussed in Cinelli, C. and Hazlett, C. (2020), ""Making Sense of Sensitivity: Extending Omitted Variable Bias."" Journal of the Royal Statistical Society, Series B (Statistical Methodology) <doi:10.1111/rssb.12348>.",2021-10-08,Carlos Cinelli,https://github.com/carloscinelli/sensemakr,TRUE,https://github.com/carloscinelli/sensemakr,15907,64,2021-12-31T22:20:39Z,248.546875
sensobol,"It allows to rapidly compute, bootstrap and plot up to fourth-order Sobol'-based sensitivity indices using several state-of-the-art first and total-order estimators. Sobol' indices can be computed either for models that yield a scalar as a model output or for systems of differential equations. The package also provides a suit of benchmark tests functions and several options to obtain publication-ready figures of the model output uncertainty and sensitivity-related analysis. An overview of the package can be found in Puy et al. (2022) <doi:10.18637/jss.v102.i05>. ",2022-04-26,Arnald Puy,https://github.com/arnaldpuy/sensobol,TRUE,https://github.com/arnaldpuy/sensobol,16660,7,2022-04-26T10:05:57Z,2380
sentencepiece,"Unsupervised text tokenizer allowing to perform byte pair encoding and unigram modelling. 
    Wraps the 'sentencepiece' library <https://github.com/google/sentencepiece> which provides a language independent tokenizer to split text in words and smaller subword units. 
    The techniques are explained in the paper ""SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"" by Taku Kudo and John Richardson (2018) <doi:10.18653/v1/D18-2012>.
    Provides as well straightforward access to pretrained byte pair encoding models and subword embeddings trained on Wikipedia using 'word2vec', 
    as described in ""BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages"" by Benjamin Heinzerling and Michael Strube (2018) <http://www.lrec-conf.org/proceedings/lrec2018/pdf/1049.pdf>.",2021-12-21,Jan Wijffels,https://github.com/bnosac/sentencepiece,TRUE,https://github.com/bnosac/sentencepiece,8330,20,2021-12-21T12:12:38Z,416.5
sentiment.ai,"Sentiment Analysis via deep learning and gradient boosting models with a lot of the underlying hassle taken care of to make the process as simple as possible. 
  In addition to out-performing traditional, lexicon-based sentiment analysis (see <https://benwiseman.github.io/sentiment.ai/#Benchmarks>),
  it also allows the user to create embedding vectors for text which can be used in other analyses.
  GPU acceleration is supported on Windows and Linux.",2022-03-19,Ben Wiseman,"https://benwiseman.github.io/sentiment.ai/,
https://github.com/BenWiseman/sentiment.ai",TRUE,https://github.com/benwiseman/sentiment.ai,2798,26,2022-03-30T15:17:36Z,107.61538461538461
sentimentr,"Calculate text polarity sentiment at the sentence level and
         optionally aggregate by rows or grouping variable(s).",2021-10-12,Tyler Rinker,https://github.com/trinker/sentimentr,TRUE,https://github.com/trinker/sentimentr,206201,386,2021-10-13T13:27:36Z,534.199481865285
sentometrics,"Optimized prediction based on textual sentiment, accounting for the intrinsic challenge that sentiment can be computed and pooled across texts and time in various ways. See Ardia et al. (2021) <doi:10.18637/jss.v099.i02>.",2021-08-18,Samuel Borms,https://sentometrics-research.com/sentometrics/,TRUE,https://github.com/sentometricsresearch/sentometrics,19185,77,2021-08-18T09:15:38Z,249.15584415584416
sentopics,"A framework that joins topic modeling and sentiment analysis of
  textual data. The package implements a fast Gibbs sampling estimation of
  Latent Dirichlet Allocation (Griffiths and Steyvers (2004)
  <doi:10.1073/pnas.0307752101>) and Joint Sentiment/Topic Model (Lin, He,
  Everson and Ruger (2012) <doi:10.1109/TKDE.2011.48>). It offers a variety of
  helpers and visualizations to analyze the result of topic modeling. The
  framework also allows enriching topic models with dates and externally
  computed sentiment measures. A flexible aggregation scheme enables the
  creation of time series of sentiment or topical proportions from the enriched
  topic models. Moreover, a novel method jointly aggregates topic proportions
  and sentiment measures to derive time series of topical sentiment.",2022-05-18,Olivier Delmarcelle,https://github.com/odelmarcelle/sentopics,TRUE,https://github.com/odelmarcelle/sentopics,1327,5,2022-05-18T13:54:13Z,265.4
sentryR,"Unofficial client for 'Sentry' <https://sentry.io>,
  a self-hosted or cloud-based error-monitoring service. It will inform about
  errors in real-time, and includes integration with the 'Plumber' package.",2020-03-19,Joao Santiago,https://github.com/ozean12/sentryR,TRUE,https://github.com/ozean12/sentryr,10929,32,2021-10-22T14:35:12Z,341.53125
seplyr,"The 'seplyr' (standard evaluation plying) package supplies improved
    standard evaluation adapter methods for important common 'dplyr' data manipulation tasks.
    In addition the 'seplyr' package supplies several new ""key operations
    bound together"" methods.  These include 'group_summarize()' (which
    combines grouping, arranging and calculation in an atomic unit),
    'add_group_summaries()' (which joins grouped summaries into a 'data.frame'
    in a well documented manner), 'add_group_indices()' (which adds
    per-group identifiers to a 'data.frame' without depending on row-order),
    'partition_mutate_qt()' (which optimizes mutate sequences), and 'if_else_device()'
    (which simulates per-row if-else blocks in expression sequences).",2021-09-02,John Mount,"https://github.com/WinVector/seplyr/,
https://winvector.github.io/seplyr/",TRUE,https://github.com/winvector/seplyr,36557,49,2021-09-01T16:27:26Z,746.0612244897959
SeqExpMatch,"Generates the following sequential two-arm experimental designs:
    (1) completely randomized (Bernoulli)
    (2) balanced completely randomized
    (3) Efron's (1971) Biased Coin
    (4) Atkinson's (1982) Covariate-Adjusted Biased Coin
    (5) Kapelner and Krieger's (2014) Covariate-Adjusted Matching on the Fly
    (6) Kapelner and Krieger's (2021) CARA Matching on the Fly with Differential Covariate Weights (Naive)
    (7) Kapelner and Krieger's (2021) CARA Matching on the Fly with Differential Covariate Weights (Stepwise)
    and also provides the following types of inference:
    (1) estimation (with both Z-style estimators and OLS estimators), 
    (2) frequentist testing (via asymptotic distribution results and via employing the nonparametric randomization test) and
    (3) frequentist confidence intervals (only under the superpopulation sampling assumption currently). Details can be found
    in our publication: Kapelner and Krieger ""A Matching Procedure for Sequential Experiments that Iteratively Learns which 
    Covariates Improve Power"" (2020) <arXiv:2010.05980>.",2021-06-01,Adam Kapelner,https://github.com/kapelner/matching_on_the_fly_designs_R_package_and_paper_repr,TRUE,https://github.com/kapelner/matching_on_the_fly_designs_r_package_and_paper_repr,3367,0,2022-04-24T17:37:48Z,NA
seqgendiff,"Generates/modifies RNA-seq data for use in simulations. We provide
    a suite of functions that will add a known amount of signal to a real 
    RNA-seq dataset. The advantage of using this approach over simulating under
    a theoretical distribution is that common/annoying aspects of the data
    are more preserved, giving a more realistic evaluation of your method. 
    The main functions are select_counts(), thin_diff(), thin_lib(), 
    thin_gene(), thin_2group(), thin_all(), and effective_cor(). See
    Gerard (2020) <doi:10.1186/s12859-020-3450-9> for details on the
    implemented methods.",2022-02-19,David Gerard,https://github.com/dcgerard/seqgendiff,TRUE,https://github.com/dcgerard/seqgendiff,13774,4,2022-02-19T15:45:36Z,3443.5
seqHMM,"Designed for fitting hidden (latent) Markov models and mixture
    hidden Markov models for social sequence data and other categorical time series.
    Also some more restricted versions of these type of models are available: Markov
    models, mixture Markov models, and latent class models. The package supports
    models for one or multiple subjects with one or multiple parallel sequences
    (channels). External covariates can be added to explain cluster membership in
    mixture models. The package provides functions for evaluating and comparing
    models, as well as functions for visualizing of multichannel sequence data and
    hidden Markov models. Models are estimated using maximum likelihood via the EM
    algorithm and/or direct numerical maximization with analytical gradients. All
    main algorithms are written in C++ with support for parallel computation. 
    Documentation is available via several vignettes in this page, and the  
    paper by Helske and Helske (2019, <doi:10.18637/jss.v088.i03>).",2022-05-25,Jouni Helske,NA,TRUE,https://github.com/helske/seqhmm,24783,71,2022-06-13T10:14:20Z,349.056338028169
seqminer,"Integrate sequencing data (Variant call format, e.g. VCF or BCF) or meta-analysis results in R. This package can help you (1) read VCF/BCF/BGEN files by chromosomal ranges (e.g. 1:100-200); (2) read RareMETAL summary statistics files; (3) read tables from a tabix-indexed files; (4) annotate VCF/BCF files; (5) create customized workflow based on Makefile.",2022-02-07,Xiaowei Zhan,http://zhanxw.github.io/seqminer/,TRUE,https://github.com/zhanxw/seqminer,145933,27,2022-02-05T16:53:38Z,5404.925925925926
seriation,"Infrastructure for ordering objects with an implementation of several
    seriation/sequencing/ordination techniques to reorder matrices, dissimilarity
    matrices, and dendrograms. Also provides (optimally) reordered heatmaps,
    color images and clustering visualizations like dissimilarity plots, and
    visual assessment of cluster tendency plots (VAT and iVAT). Hahsler et al (2008) <doi:10.18637/jss.v025.i03>.",2022-03-28,Michael Hahsler,https://github.com/mhahsler/seriation,TRUE,https://github.com/mhahsler/seriation,891832,57,2022-07-03T21:54:44Z,15646.17543859649
serp,"A regularization method for the cumulative link
    models.  The smooth-effect-on-response penalty (SERP) provides
    flexible modelling of the ordinal model by enabling the smooth
    transition from the general cumulative link model to a coarser form of
    the same model. In other words, as the tuning parameter goes from zero
    to infinity, the subject-specific effects associated with each
    variable in the model tend to a unique global effect. The parameter
    estimates of the general cumulative model are mostly unidentifiable or
    at least only identifiable within a range of the entire parameter
    space. Thus, by maximizing a penalized rather than the usual
    non-penalized log-likelihood, this and other numerical problems common
    with the general model are to a large extent eliminated. Fitting is
    via a modified Newton's method. Several standard model performance and
    descriptive methods are also available. For more details on the penalty
    implemented here, see, Ugba (2021) <doi:10.21105/joss.03705> and 
    Ugba et al. (2021) <doi:10.3390/stats4030037>.",2022-02-16,Ejike R. Ugba,https://github.com/ejikeugba/serp,TRUE,https://github.com/ejikeugba/serp,6432,1,2022-04-12T08:00:36Z,6432
servr,"Start an HTTP server in R to serve static files, or dynamic
    documents that can be converted to HTML files (e.g., R Markdown) under a
    given directory.",2021-11-16,Yihui Xie,https://github.com/yihui/servr,TRUE,https://github.com/yihui/servr,740614,246,2021-11-16T19:38:22Z,3010.6260162601625
SEset,"Tools to compute and analyze the set of statistically-equivalent (Gaussian, linear) path models which generate the input precision or (partial) correlation matrix. 
             This procedure is useful for understanding how statistical network models such as the Gaussian Graphical Model (GGM) perform as causal discovery tools. 
             The statistical-equivalence set of a given GGM expresses the uncertainty we have about the sign, size and direction of directed relationships based on the weights matrix of the GGM alone. 
             The derivation of the equivalence set and its use for understanding GGMs as causal discovery tools is described by Ryan, O., Bringmann, L.F., & Schuurman, N.K. (2022) <doi: 10.31234/osf.io/ryg69>.",2022-03-17,Oisín Ryan,NA,TRUE,https://github.com/ryanoisin/seset,894,1,2022-06-17T10:24:13Z,894
set,"More easy to get intersection, union or complementary set and 
    combinations.",2021-02-26,Zhi Jin,https://github.com/yikeshu0611/set,TRUE,https://github.com/yikeshu0611/set,23964,0,2022-04-01T13:39:39Z,NA
set6,"An object-oriented package for mathematical sets, upgrading the current gold-standard {sets}. Many forms of mathematical sets are implemented, including (countably finite) sets, tuples, intervals (countably infinite or uncountable), and fuzzy variants. Wrappers extend functionality by allowing symbolic representations of complex operations on sets, including unions, (cartesian) products, exponentiation, and differences (asymmetric and symmetric).",2021-10-18,Raphael Sonabend,"https://xoopR.github.io/set6/, https://github.com/xoopR/set6",TRUE,https://github.com/xoopr/set6,128458,13,2022-03-25T21:42:49Z,9881.384615384615
Seurat,"A toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. 'Seurat' aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See Satija R, Farrell J, Gennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, Stuart T, Butler A, et al (2019) <doi:10.1016/j.cell.2019.05.031>, and Hao, Hao, et al (2020) <doi:10.1101/2020.10.12.335331> for more details.",2022-05-02,Christoph Hafemeister [ctb,"https://satijalab.org/seurat, https://github.com/satijalab/seurat",TRUE,https://github.com/satijalab/seurat,815413,1496,2022-05-02T14:03:38Z,545.062165775401
SeuratObject,"Defines S4 classes for single-cell genomic data and associated
  information, such as dimensionality reduction embeddings, nearest-neighbor
  graphs, and spatially-resolved coordinates. Provides data access methods and
  R-native hooks to ensure the Seurat object is familiar to other R users. See
  Satija R, Farrell J, Gennert D, et al (2015) <doi:10.1038/nbt.3192>,
  Macosko E, Basu A, Satija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>,
  and Stuart T, Butler A, et al (2019) <doi:10.1016/j.cell.2019.05.031> for
  more details.",2022-05-01,Rahul Satija,"https://mojaveazure.github.io/seurat-object/,
https://github.com/mojaveazure/seurat-object",TRUE,https://github.com/mojaveazure/seurat-object,319712,4,2022-05-18T14:40:18Z,79928
sever,Customise 'Shiny' disconnected screens as well as sanitize error messages to make them clearer and friendlier to the user.,2021-07-14,John Coene,https://sever.john-coene.com/,TRUE,https://github.com/johncoene/sever,12799,72,2022-04-19T19:49:24Z,177.76388888888889
sf,"Support for simple features, a standardized way to
    encode spatial vector data. Binds to 'GDAL' for reading and writing
    data, to 'GEOS' for geometrical operations, and to 'PROJ' for
    projection conversions and datum transformations. Uses by default the 's2'
    package for spherical geometry operations on ellipsoidal (long/lat) coordinates.",2022-03-07,Edzer Pebesma,"https://r-spatial.github.io/sf/, https://github.com/r-spatial/sf/",TRUE,https://github.com/r-spatial/sf,32408205,1032,2022-07-09T13:10:14Z,31403.299418604653
sfarrow,"Support for reading/writing simple feature ('sf') spatial objects from/to 'Parquet' files. 'Parquet' files are an open-source, column-oriented data storage format from Apache (<https://parquet.apache.org/>), now popular across programming languages. This implementation converts simple feature list geometries into well-known binary format for use by 'arrow', and coordinate reference system information is maintained in a standard metadata format.",2021-10-27,Chris Jochem,"https://github.com/wcjochem/sfarrow,
https://wcjochem.github.io/sfarrow/",TRUE,https://github.com/wcjochem/sfarrow,4225,49,2021-10-28T10:22:57Z,86.22448979591837
sfcr,"Routines to write, simulate, and validate stock-flow consistent (SFC) models. The accounting structure of SFC models are described in Godley and Lavoie (2007, ISBN:978-1-137-08599-3). The algorithms implemented to solve the models (Gauss-Seidel and Broyden) are described in Kinsella and O'Shea (2010) <doi:10.2139/ssrn.1729205> and Peressini and Sullivan (1988, ISBN:0-387-96614-5).",2021-10-11,Joao Macalos,https://github.com/joaomacalos/sfcr,TRUE,https://github.com/joaomacalos/sfcr,7204,13,2021-12-25T10:28:28Z,554.1538461538462
sfdep,An interface to 'spdep' to integrate with 'sf' objects and the 'tidyverse'.,2022-04-20,Josiah Parry,"https://sfdep.josiahparry.com,
https://github.com/josiahparry/sfdep",TRUE,https://github.com/josiahparry/sfdep,764,42,2022-07-10T13:41:02Z,18.19047619047619
sfheaders,"Converts between R and Simple Feature 'sf' objects, without depending
  on the Simple Feature library. Conversion functions are available at both the R level, 
  and through 'Rcpp'.",2020-12-01,David Cooley,https://dcooley.github.io/sfheaders/,TRUE,https://github.com/dcooley/sfheaders,597160,63,2021-09-04T03:05:14Z,9478.730158730159
sfnetworks,"Provides a tidy approach to spatial network
    analysis, in the form of classes and functions that enable a seamless
    interaction between the network analysis package 'tidygraph' and the
    spatial analysis package 'sf'.",2022-02-16,Lucas van der Meer,"https://luukvdmeer.github.io/sfnetworks/,
https://github.com/luukvdmeer/sfnetworks",TRUE,https://github.com/luukvdmeer/sfnetworks,10911,268,2022-02-16T15:04:53Z,40.71268656716418
sfsmisc,"Useful utilities ['goodies'] from Seminar fuer Statistik ETH Zurich,
   some of which were ported from S-plus in the 1990s.
 For graphics, have pretty (Log-scale) axes, an enhanced Tukey-Anscombe
   plot, combining histogram and boxplot, 2d-residual plots, a 'tachoPlot()',
   pretty arrows, etc.
 For robustness, have a robust F test and robust range().
 For system support, notably on Linux, provides 'Sys.*()' functions with
   more access to system and CPU information.
 Finally, miscellaneous utilities such as simple efficient prime numbers,
   integer codes, Duplicated(), toLatex.numeric() and is.whole().",2022-04-02,Martin Maechler,https://github.com/mmaechler/sfsmisc,TRUE,https://github.com/mmaechler/sfsmisc,569834,10,2022-05-31T13:41:49Z,56983.4
sGBJ,"Implements an extension of the Generalized Berk-Jones (GBJ) statistic for
    survival data, sGBJ. It computes the sGBJ statistic and its p-value for testing 
    the association between a gene set and a time-to-event outcome with possible 
    adjustment on additional covariates. Detailed method is available at Villain L, Ferte T, 
    Thiebaut R and Hejblum BP (2021) <doi:10.1101/2021.09.07.459329>.",2021-09-15,Laura Villain,https://github.com/lauravillain/sGBJ,TRUE,https://github.com/lauravillain/sgbj,2900,1,2021-09-15T08:58:09Z,2900
sgo,"Methods focused in performing the OSGB36/ETRS89 transformation 
  (Great Britain and the Isle of Man only) by using the Ordnance Survey's 
  OSTN15/OSGM15 transformation model. Calculation of distances and areas from 
  sets of points defined in any of the supported Coordinated Systems is also
  available.",2021-12-11,Carlos Lozano Ruiz,https://github.com/clozanoruiz/sgo,TRUE,https://github.com/clozanoruiz/sgo,2710,1,2022-04-02T13:01:35Z,2710
SGP,"An analytic framework for the calculation of norm- and criterion-referenced academic growth estimates using large scale, longitudinal education assessment data as developed in Betebenner (2009) <doi:10.1111/j.1745-3992.2009.00161.x>.",2022-05-27,Damian W. Betebenner,"https://sgp.io, https://github.com/CenterForAssessment/SGP,
https://CRAN.R-project.org/package=SGP",TRUE,https://github.com/centerforassessment/sgp,58723,19,2022-07-08T21:16:52Z,3090.684210526316
SGPdata,Data sets utilized by the 'SGP' package as exemplars for users to conduct their own student growth percentiles (SGP) analyses.,2022-05-27,Damian W. Betebenner,"https://CenterForAssessment.github.io/SGPdata/,
https://github.com/CenterForAssessment/SGPdata/,
https://cran.r-project.org/package=SGPdata",TRUE,https://github.com/centerforassessment/sgpdata,36344,2,2022-05-25T15:01:27Z,18172
sgsR,"Structurally guided sampling (SGS) approaches for airborne laser scanning (ALS; LIDAR). Primary functions provide means 
    to generate data-driven stratifications & methods for allocating samples. Intermediate functions for calculating and extracting important information 
    about input covariates and samples are also included. Processing outcomes are intended to help forest and environmental management
    practitioners better optimize field sample placement as well as assess and augment existing sample networks in the context of data
    distributions and conditions. ALS data is the primary intended use case, however any rasterized remote sensing data can be used, 
    enabling data-driven stratifications and sampling approaches.",2022-06-24,Tristan RH Goodbody,"https://github.com/tgoodbody/sgsR,
https://tgoodbody.github.io/sgsR/",TRUE,https://github.com/tgoodbody/sgsr,190,17,2022-06-28T22:49:19Z,11.176470588235293
shadowr,"Shadow Document Object Model is a web standard that offers component style and markup encapsulation. 
  It is a critically important piece of the Web Components story as it ensures that a component will work in any environment even if other CSS or JavaScript is at play on the page.
  Custom HTML tags can't be directly identified with selenium tools, because Selenium doesn't provide any way to deal with shadow elements. 
  Using this plugin you can handle any custom HTML tags.",2022-05-25,Ricardo Landolt,https://github.com/ricilandolt/shadowr,TRUE,https://github.com/ricilandolt/shadowr,633,2,2022-05-25T06:45:37Z,316.5
shadowtext,"Implement shadowtextGrob() for 'grid' and geom_shadowtext() layer for 'ggplot2'.
             These functions create/draw text grob with background shadow.",2022-04-22,Guangchuang Yu,https://github.com/GuangchuangYu/shadowtext/,TRUE,https://github.com/guangchuangyu/shadowtext,234633,31,2022-04-24T03:10:18Z,7568.806451612903
SHAPforxgboost,"Aid in visual data investigations
 using SHAP (SHapley Additive exPlanation) visualization plots for 'XGBoost' and 'LightGBM'. 
 It provides summary plot, dependence plot, interaction plot, and force plot and relies on
 the SHAP implementation provided by 'XGBoost' and 'LightGBM'.
 Please refer to 'slundberg/shap' for the original implementation of SHAP in 'Python'. ",2021-03-28,Yang Liu,https://github.com/liuyanguu/SHAPforxgboost,TRUE,https://github.com/liuyanguu/shapforxgboost,41882,68,2022-05-18T02:29:14Z,615.9117647058823
shapr,"Complex machine learning models are often hard to interpret. However, in 
  many situations it is crucial to understand and explain why a model made a specific 
  prediction. Shapley values is the only method for such prediction explanation framework 
  with a solid theoretical foundation. Previously known methods for estimating the Shapley 
  values do, however, assume feature independence. This package implements the method 
  described in Aas, Jullum and Løland (2019) <arXiv:1903.10464>, which accounts for any feature 
  dependence, and thereby produces more accurate estimates of the true Shapley values.",2021-01-28,Nikolai Sellereite,"https://norskregnesentral.github.io/shapr/,
https://github.com/NorskRegnesentral/shapr",TRUE,https://github.com/norskregnesentral/shapr,24729,95,2022-04-28T06:24:16Z,260.30526315789473
shapviz,"Visualizations for SHAP (SHapley Additive exPlanations), such
    as waterfall plots, force plots, various types of importance plots,
    and dependence plots.  These plots act on a 'shapviz' object created
    from a matrix of SHAP values and a corresponding feature dataset.
    Wrappers for the R packages 'xgboost', 'lightgbm', 'fastshap',
    'shapr', 'h2o', and 'treeshap' are added for convenience.  By
    separating visualization and computation, it is possible to display
    factor variables in graphs, even if the SHAP values are calculated by
    a model that requires numerical features. The plots are inspired by
    those provided by the 'shap' package in Python, but there is no
    dependency on it.",2022-07-07,Michael Mayer,https://github.com/mayer79/shapviz,TRUE,https://github.com/mayer79/shapviz,360,13,2022-07-08T07:27:18Z,27.692307692307693
shar,"
  Analyse species-habitat associations in R. Therefore, information about the location 
  of the species (as a point pattern) is needed together with environmental conditions 
  (as a categorical raster). To test for significance habitat associations, one of 
  the two components is randomized. Methods are mainly based on Plotkin et al. (2000) 
  <doi:10.1006/jtbi.2000.2158> and Harms et al. (2001) <doi:10.1111/j.1365-2745.2001.00615.x>.",2022-03-08,Maximillian H.K. Hesselbarth,https://r-spatialecology.github.io/shar/,TRUE,https://github.com/r-spatialecology/shar,15342,10,2022-06-23T12:14:36Z,1534.2
sharp,"Implementation of stability selection for graphical modelling and variable selection in regression and dimensionality reduction. These models use on resampling approaches to estimate selection probabilities (N Meinshausen, P Bühlmann (2010) <doi:10.1111/j.1467-9868.2010.00740.x>). Calibration of the hyper-parameters is done via maximisation of a stability score measuring the likelihood of informative (non-uniform) selection (B Bodinier, S Filippi, TH Nost, J Chiquet, M Chadeau-Hyam (2021) <arXiv:2106.02521>). This package also includes tools to simulate multivariate Normal data with different (partial) correlation structures.",2022-06-17,Barbara Bodinier,https://github.com/barbarabodinier/sharp,TRUE,https://github.com/barbarabodinier/sharp,219,2,2022-07-08T11:46:47Z,109.5
SharpeR,"A collection of tools for analyzing significance of assets,
    funds, and trading strategies, based on the Sharpe ratio and overfit 
    of the same. Provides density, distribution, quantile and random generation 
    of the Sharpe ratio distribution based on normal returns, as well
    as the optimal Sharpe ratio over multiple assets. Computes confidence intervals
    on the Sharpe and provides a test of equality of Sharpe ratios based on 
    the Delta method. The statistical foundations of the Sharpe can be found in
    the author's Short Sharpe Course  <doi:10.2139/ssrn.3036276>.",2021-08-18,Steven E. Pav,https://github.com/shabbychef/SharpeR,TRUE,https://github.com/shabbychef/sharper,22177,17,2021-08-18T17:50:04Z,1304.5294117647059
sharpshootR,"Miscellaneous soil data management, summary, visualization, and conversion utilities to support soil survey.",2022-01-04,Dylan Beaudette,https://github.com/ncss-tech/sharpshootR,TRUE,https://github.com/ncss-tech/sharpshootr,24203,10,2022-07-06T22:55:31Z,2420.3
SheetReader,"Uses C++ via the 'Rcpp' package to parse modern Excel files ('.xlsx').
    Memory usage is kept minimal by decompressing only parts of the file at a time,
    while employing multiple threads to achieve significant runtime reduction.
    Uses <https://github.com/richgel999/miniz>, <https://github.com/ebiggers/libdeflate>,
    and <https://github.com/lemire/fast_double_parser>.",2022-04-08,Felix Henze,https://github.com/fhenz/SheetReader-r,TRUE,https://github.com/fhenz/sheetreader-r,996,32,2022-04-07T18:54:10Z,31.125
SHELF,"Implements various methods for eliciting a probability distribution
    for a single parameter from an expert or a group of experts. The expert
    provides a small number of probability judgements, corresponding
    to points on his or her cumulative distribution function. A range of parametric
    distributions can then be fitted and displayed, with feedback provided in the
    form of fitted probabilities and percentiles. For multiple experts, a weighted
    linear pool can be calculated. Also includes functions for eliciting beliefs
    about population distributions, eliciting multivariate distributions using a
    Gaussian copula, eliciting a Dirichlet distribution, and eliciting distributions 
    for variance parameters in a random effects meta-analysis model. R Shiny apps  
    for most of the methods are included. ",2021-06-18,Jeremy Oakley,https://github.com/OakleyJ/SHELF,TRUE,https://github.com/oakleyj/shelf,19090,7,2022-04-22T08:16:00Z,2727.1428571428573
ShellChron,"Takes as input a stable oxygen isotope (d18O) profile measured in growth direction (D)
	through a shell + uncertainties in both variables (d18O_err & D_err). It then models the seasonality
	in the d18O record by fitting a combination of a growth and temperature sine wave to year-length chunks of
	the data (see Judd et al., (2018) <doi:10.1016/j.palaeo.2017.09.034>). This modeling is carried out along a sliding window through the data and yields estimates of
	the day of the year (Julian Day) and local growth rate for each data point. Uncertainties in both modeling
	routine and the data itself are propagated and pooled to obtain a confidence envelope around the age of
	each data point in the shell. The end result is a shell chronology consisting of estimated ages of shell
	formation relative to the annual cycle with their uncertainties. All formulae in the package serve this
	purpose, but the user can customize the model (e.g. number of days in a year and the mineralogy of the
	shell carbonate) through input parameters.",2021-07-05,Niels de Winter,https://github.com/nielsjdewinter/ShellChron,TRUE,https://github.com/nielsjdewinter/shellchron,6616,3,2022-06-02T12:44:22Z,2205.3333333333335
ShiftShareSE,"Provides confidence intervals in least-squares regressions when the
  variable of interest has a shift-share structure, and in instrumental
  variables regressions when the instrument has a shift-share structure. The
  confidence intervals implement the AKM and AKM0 methods developed in Adão,
  Kolesár, and Morales (2019) <doi:10.1093/qje/qjz025>.",2022-04-24,Michal Kolesár,https://github.com/kolesarm/ShiftShareSE,TRUE,https://github.com/kolesarm/shiftsharese,10733,13,2022-04-24T14:11:31Z,825.6153846153846
shiny,"Makes it incredibly easy to build interactive web
    applications with R. Automatic ""reactive"" binding between inputs and
    outputs and extensive prebuilt widgets make it possible to build
    beautiful, responsive, and powerful applications with minimal effort.",2021-10-02,Winston Chang,https://shiny.rstudio.com/,TRUE,https://github.com/rstudio/shiny,10286794,4721,2022-07-06T01:03:22Z,2178.9438678246133
shiny.i18n,"It provides easy internationalization of Shiny
    applications. It can be used as standalone translation package
    to translate reports, interactive visualizations or
    graphical elements as well.",2020-10-02,Dominik Krzemiński,https://github.com/Appsilon/shiny.i18n,TRUE,https://github.com/appsilon/shiny.i18n,27566,127,2021-10-31T16:41:46Z,217.0551181102362
shiny.info,Displays simple diagnostic information of the 'shiny' project in the user interface of the app.,2020-03-23,Jakub Nowicki,NA,TRUE,https://github.com/appsilon/shiny.info,8979,46,2022-04-21T13:09:28Z,195.19565217391303
shiny.pwa,"Adds Progressive Web App support for Shiny apps, including
  desktop and mobile installations.",2021-06-19,Pedro Silva,https://github.com/pedrocoutinhosilva/shiny.pwa,TRUE,https://github.com/pedrocoutinhosilva/shiny.pwa,7951,33,2021-09-05T19:56:17Z,240.93939393939394
shiny.semantic,"Creating a great user interface for your Shiny apps
    can be a hassle, especially if you want to work purely in R
    and don't want to use, for instance HTML templates. This
    package adds support for a powerful UI library Fomantic UI -
    <https://fomantic-ui.com/> (before Semantic). It also supports
    universal UI input binding that works with various DOM elements.",2021-11-07,Developers Appsilon,NA,TRUE,https://github.com/appsilon/shiny.semantic,36722,432,2022-06-23T12:12:02Z,85.00462962962963
shinyAce,"Ace editor bindings to enable a rich text editing environment
    within Shiny.",2022-05-06,Vincent Nijs,NA,TRUE,https://github.com/trestletech/shinyace,262577,193,2022-05-06T04:47:00Z,1360.5025906735752
shinyauthr,"Add in-app user authentication to 'shiny', 
    allowing you to secure publicly hosted apps and 
    build dynamic user interfaces from user information.",2021-07-20,Paul Campbell,https://github.com/paulc91/shinyauthr,TRUE,https://github.com/paulc91/shinyauthr,13335,357,2022-05-12T21:32:57Z,37.35294117647059
shinybrms,"A graphical user interface (GUI) for fitting Bayesian regression
    models using the package 'brms' which in turn relies on 'Stan'
    (<https://mc-stan.org/>). The 'shinybrms' GUI is a 'shiny' app.",2022-04-26,Frank Weber,https://fweber144.github.io/shinybrms/,TRUE,https://github.com/fweber144/shinybrms,14355,6,2022-04-26T19:07:12Z,2392.5
shinybusy,"Add indicators (spinner, progress bar, gif) in your 'shiny'
  applications to show the user that the server is busy. And other tools to let
  your users know something is happening (send notifications, reports, ...).",2022-05-10,Victor Perrier,https://github.com/dreamRs/shinybusy,TRUE,https://github.com/dreamrs/shinybusy,105439,118,2022-05-10T15:13:54Z,893.5508474576271
shinyChakraUI,"Makes the 'React' library 'Chakra UI' usable in 'Shiny' apps. 'Chakra UI' components include alert dialogs, drawers (sliding panels), menus, modals, popovers, sliders, and more. ",2022-01-05,Stéphane Laurent,https://github.com/stla/shinyChakraUI,TRUE,https://github.com/stla/shinychakraui,4092,20,2022-01-05T14:02:01Z,204.6
shinycssloaders,"When a 'Shiny' output (such as a plot, table, map, etc.) is recalculating, it remains 
    visible but gets greyed out. Using 'shinycssloaders', you can add a loading animation (""spinner"")
    to outputs instead. By wrapping a 'Shiny' output in 'withSpinner()', a spinner will automatically
    appear while the output is recalculating. See the demo online at
    <https://daattali.com/shiny/shinycssloaders-demo/>.",2020-07-28,Andras Sali,https://github.com/daattali/shinycssloaders,TRUE,https://github.com/daattali/shinycssloaders,548746,313,2021-10-10T19:55:37Z,1753.182108626198
shinydashboard,"Create dashboards with 'Shiny'. This package provides
    a theme on top of 'Shiny', making it easy to create attractive dashboards.",2021-09-30,Winston Chang,http://rstudio.github.io/shinydashboard/,TRUE,https://github.com/rstudio/shinydashboard,1709325,779,2021-11-30T16:30:05Z,2194.2554557124517
shinydashboardPlus,"Extend 'shinydashboard' with 'AdminLTE2' components. 
             'AdminLTE2' is a free 'Bootstrap 3' dashboard template available
             at <https://adminlte.io>. Customize boxes, add timelines and a lot more. ",2021-09-15,David Granjon,"https://github.com/RinteRface/shinydashboardPlus,
https://rinterface.com/shiny/shinydashboardPlus/",TRUE,https://github.com/rinterface/shinydashboardplus,253912,389,2022-01-12T11:00:57Z,652.7300771208227
shinyFeedback,Easily display user feedback in Shiny apps.,2021-09-23,Andy Merlino,https://github.com/merlinoa/shinyFeedback,TRUE,https://github.com/merlinoa/shinyfeedback,65657,168,2022-04-05T21:19:08Z,390.8154761904762
shinyFiles,"Provides functionality for client-side navigation of
    the server side file system in shiny apps. In case the app is running
    locally this gives the user direct access to the file system without the
    need to ""download"" files to a temporary location. Both file and folder
    selection as well as file saving is available.",2022-05-24,Thomas Lin Pedersen,https://github.com/thomasp85/shinyFiles,TRUE,https://github.com/thomasp85/shinyfiles,308718,165,2022-05-24T19:10:27Z,1871.0181818181818
shinyglide,"Insert Glide JavaScript component into Shiny applications for
    carousel or assistant-like user interfaces.",2021-06-11,Julien Barnier,"https://juba.github.io/shinyglide/,
https://github.com/juba/shinyglide",TRUE,https://github.com/juba/shinyglide,14563,72,2022-03-07T10:31:16Z,202.26388888888889
shinyGovstyle,"Collection of 'shiny' application styling that are the based on 
  the GOV.UK Design System.  See 
  <https://design-system.service.gov.uk/components/> for details.",2022-02-22,Ross Wyatt,https://github.com/moj-analytical-services/shinyGovstyle,TRUE,https://github.com/moj-analytical-services/shinygovstyle,3817,28,2022-02-22T10:36:38Z,136.32142857142858
ShinyItemAnalysis,"Package including functions and interactive shiny application
    for the psychometric analysis of educational tests, psychological
    assessments, health-related and other types of multi-item
    measurements, or ratings from multiple raters.",2022-04-15,Patricia Martinkova,"http://www.ShinyItemAnalysis.org,
https://CRAN.R-project.org/package=ShinyItemAnalysis",TRUE,https://github.com/patriciamar/shinyitemanalysis,32062,29,2022-04-19T21:50:59Z,1105.5862068965516
shinyjqui,"An extension to shiny that brings interactions and animation effects from
    'jQuery UI' library.",2022-02-03,Yang Tang,"https://github.com/yang-tang/shinyjqui,
https://yang-tang.github.io/shinyjqui/",TRUE,https://github.com/yang-tang/shinyjqui,188497,250,2022-02-04T03:35:21Z,753.988
shinyjs,"Perform common useful JavaScript operations in Shiny apps that will
    greatly improve your apps without having to know any JavaScript. Examples
    include: hiding an element, disabling an input, resetting an input back to
    its original value, delaying code execution by a few seconds, and many more
    useful functions for both the end user and the developer. 'shinyjs' can also
    be used to easily call your own custom JavaScript functions from R.",2021-12-23,Dean Attali,https://deanattali.com/shinyjs/,TRUE,https://github.com/daattali/shinyjs,2332717,635,2022-05-26T08:01:47Z,3673.5700787401574
shinyloadtest,"Assesses the number of concurrent users 'shiny'
  applications are capable of supporting, and for directing application changes
  in order to support a higher number of users. Provides facilities for recording
  'shiny' application sessions, playing recorded sessions against a target
  server at load, and analyzing the resulting metrics.",2021-02-11,Barret Schloerke,"https://rstudio.github.io/shinyloadtest/,
https://github.com/rstudio/shinyloadtest",TRUE,https://github.com/rstudio/shinyloadtest,16372,99,2021-12-22T18:21:29Z,165.37373737373738
shinylogs,"Track and record the use of applications and the user's interactions with 'Shiny' inputs.
  Allows to trace the inputs with which the user interacts, the outputs generated, 
  as well as the errors displayed in the interface.",2022-04-18,Victor Perrier,https://github.com/dreamRs/shinylogs,TRUE,https://github.com/dreamrs/shinylogs,20967,82,2022-04-18T16:02:24Z,255.6951219512195
shinyLP,"Provides functions that wrap HTML Bootstrap
    components code to enable the design and layout of informative landing home
    pages for Shiny applications. This can lead to a better user experience for
    the users and writing less HTML for the developer.",2018-04-25,Jasmine Dumas,https://github.com/jasdumas/shinyLP,TRUE,https://github.com/jasdumas/shinylp,30645,101,2022-06-02T00:37:04Z,303.41584158415844
shinymanager,"Simple and secure authentification mechanism for single 'Shiny' applications.
    Credentials are stored in an encrypted 'SQLite' database. Source code of main application
    is protected until authentication is successful.",2021-06-16,Benoit Thieurmel,https://github.com/datastorm-open/shinymanager,TRUE,https://github.com/datastorm-open/shinymanager,51454,312,2022-02-23T13:46:58Z,164.91666666666666
shinyMergely,"A 'Shiny' app allowing to compare and merge two files, with syntax highlighting for several coding languages.",2022-01-24,Stéphane Laurent,https://github.com/stla/shinyMergely,TRUE,https://github.com/stla/shinymergely,6962,5,2022-01-24T10:32:53Z,1392.4
shinymeta,"Provides tools for capturing logic in a Shiny app and exposing it as code that can be run outside of Shiny (e.g., from an R console). It also provides tools for bundling both the code and results to the end user.",2021-11-17,Carson Sievert,"https://rstudio.github.io/shinymeta/,
https://github.com/rstudio/shinymeta",TRUE,https://github.com/rstudio/shinymeta,6966,202,2021-11-19T16:17:13Z,34.48514851485149
shinyMobile,"Develop outstanding 'shiny' apps for 'iOS', 'Android', desktop as well as beautiful 'shiny' gadgets.
    'shinyMobile' is built on top of the latest 'Framework7' template <https://framework7.io>.
    Discover 14 new input widgets (sliders, vertical sliders, stepper, 
    grouped action buttons, toggles, picker, smart select, ...), 2 themes (light and dark), 
    12 new widgets (expandable cards, badges, chips, timelines, gauges, progress bars, ...) 
    combined with the power of server-side notifications such as alerts, modals, toasts,
    action sheets, sheets (and more) as well as 3 layouts (single, tabs and split).",2021-09-16,David Granjon,"https://github.com/RinteRface/shinyMobile,
https://rinterface.github.io/shinyMobile/",TRUE,https://github.com/rinterface/shinymobile,21817,315,2021-09-15T21:46:10Z,69.26031746031747
shinymodels,"Launch a 'shiny' application for 'tidymodels' results. For
    classification or regression models, the app can be used to determine
    if there is lack of fit or poorly predicted points.",2021-11-17,Max Kuhn,"https://shinymodels.tidymodels.org,
https://github.com/tidymodels/shinymodels",TRUE,https://github.com/tidymodels/shinymodels,2442,37,2022-05-17T13:51:02Z,66
shinyNORRRM,The computer program is an efficient igneous norm algorithm and rock classification system written in R but run as shiny app.,2022-06-23,Reneé González-Guzmán,https://github.com/TheRFrog/shinyNORRRM,TRUE,https://github.com/therfrog/shinynorrrm,89,1,2022-06-24T00:28:26Z,89
shinyobjects,"Troubleshooting reactive data in 'shiny' can be difficult. These functions will convert reactive data frames into functions and load all assigned objects into your local environment. If you create a dummy input object, as the function will suggest, you will be able to test your server and ui functions interactively.",2020-07-29,Jake Riley,NA,TRUE,https://github.com/rjake/shinyobjects,9696,18,2022-06-03T20:41:17Z,538.6666666666666
shinypanels,"Create 'Shiny Apps' with collapsible vertical panels. 
    This package provides a new visual arrangement for elements on top of 'Shiny'. 
    Use the expand and collapse capabilities to leverage web applications with
    many elements to focus the user attention on the panel of interest.",2020-01-26,Juan Pablo Marin Diaz,http://github.com/datasketch/shinypanels,TRUE,https://github.com/datasketch/shinypanels,10920,65,2021-10-14T18:35:20Z,168
shinySelect,"Provides a select control widget for 'Shiny'. It is easily customizable, and one can easily use HTML in the items and KaTeX to type mathematics.",2021-11-17,Stéphane Laurent,https://github.com/stla/shinySelect,TRUE,https://github.com/stla/shinyselect,1987,4,2021-11-16T09:59:05Z,496.75
shinystan,"A graphical user interface for interactive Markov chain Monte
    Carlo (MCMC) diagnostics and plots and tables helpful for analyzing a
    posterior sample. The interface is powered by the 'Shiny' web
    application framework from 'RStudio' and works with the output of MCMC 
    programs written in any programming language (and has extended 
    functionality for 'Stan' models fit using the 'rstan' and 'rstanarm' 
    packages).",2022-03-03,Jonah Gabry,"https://mc-stan.org/shinystan/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/shinystan,1025926,180,2022-03-02T19:39:29Z,5699.5888888888885
shinytest,"For automated testing of Shiny applications, using
    a headless browser, driven through 'WebDriver'.",2021-09-13,Winston Chang,https://github.com/rstudio/shinytest,TRUE,https://github.com/rstudio/shinytest,359050,224,2021-11-19T15:20:26Z,1602.9017857142858
shinytest2,Automated unit testing of Shiny applications through a headless 'Chromium' browser.,2022-04-27,Barret Schloerke,https://github.com/rstudio/shinytest2,TRUE,https://github.com/rstudio/shinytest2,1982,60,2022-06-15T17:41:37Z,33.03333333333333
shinyToastify,"This is a wrapper of the 'React' library 'React-Toastify'. It allows to show some notifications (toasts) in 'Shiny' applications. There are options for the style, the position, the transition effect, and more.",2021-07-31,Stéphane Laurent,https://github.com/stla/shinyToastify,TRUE,https://github.com/stla/shinytoastify,3952,9,2021-07-31T10:41:33Z,439.1111111111111
shinyTree,"Exposes bindings to jsTree -- a JavaScript library
    that supports interactive trees -- to enable a rich, editable trees in
    Shiny.",2019-05-27,Mike Schaffer,NA,TRUE,https://github.com/trestletech/shinytree,75658,127,2021-10-12T13:36:46Z,595.7322834645669
shinyvalidate,"Improves the user experience of Shiny apps by helping to
    provide feedback when required inputs are missing, or input values
    are not valid.",2022-04-21,Richard Iannone,"https://rstudio.github.io/shinyvalidate/,
https://github.com/rstudio/shinyvalidate",TRUE,https://github.com/rstudio/shinyvalidate,16268,87,2022-04-22T14:03:10Z,186.98850574712642
shinyWidgets,"Collection of custom input controls and user interface components for 'Shiny' applications. 
  Give your applications a unique and colorful style !",2022-05-11,Victor Perrier,"https://github.com/dreamRs/shinyWidgets,
https://dreamrs.github.io/shinyWidgets/",TRUE,https://github.com/dreamrs/shinywidgets,1382658,670,2022-07-05T07:24:47Z,2063.668656716418
shorts,"Create short sprint (<6sec) profiles using the split times or the radar gun data.
    Mono-exponential equation is used to estimate maximal sprinting speed (MSS), relative acceleration (TAU),
    and other parameters such us maximal acceleration (MAC) and maximal relative power (PMAX). These parameters 
    can be used to predict kinematic and kinetics variables and to compare individuals. The modeling method utilized
    in this package is based on the works of Chelly SM, Denis C. (2001) <doi: 10.1097/00005768-200102000-00024>,
    Clark KP, Rieger RH, Bruno RF, Stearne DJ. (2017) <doi: 10.1519/JSC.0000000000002081>, 
    Furusawa K, Hill AV, Parkinson JL (1927) <doi: 10.1098/rspb.1927.0035>, 
    Greene PR. (1986) <doi: 10.1016/0025-5564(86)90063-5>, and 
    Samozino P. (2018) <doi: 10.1007/978-3-319-05633-3_11>.",2022-07-07,Mladen Jovanović,https://mladenjovanovic.github.io/shorts/,TRUE,https://github.com/mladenjovanovic/shorts,18046,10,2022-07-07T08:33:55Z,1804.6
showtext,"Making it easy to use various types of fonts ('TrueType',
    'OpenType', Type 1, web fonts, etc.) in R graphs, and supporting most output
    formats of R graphics including PNG, PDF and SVG. Text glyphs will be converted
    into polygons or raster images, hence after the plot has been created, it no
    longer relies on the font files. No external software such as 'Ghostscript' is
    needed to use this package.",2022-02-09,"Yixuan Qiu and authors/contributors of the
    included software. See file AUTHORS for details.",https://github.com/yixuan/showtext,TRUE,https://github.com/yixuan/showtext,951966,420,2022-02-09T15:33:23Z,2266.5857142857144
SHT,"We provide a collection of statistical hypothesis testing procedures ranging from classical to modern methods for non-trivial settings such as high-dimensional scenario. For the general treatment of statistical hypothesis testing, see the book by Lehmann and Romano (2005) <doi:10.1007/0-387-27605-X>.",2022-06-06,Kisung You,https://kisungyou.com/SHT/,TRUE,https://github.com/kisungyou/sht,15550,5,2022-06-04T19:45:25Z,3110
siconfir,"Access tax and accounting data of Brazilian states 
    and municipalities provided by the Brazilian Public Sector 
    Accounting and Tax Information System.",2021-04-20,Pedro Castro,https://github.com/pedrocastroo/siconfir,TRUE,https://github.com/pedrocastroo/siconfir,4191,6,2022-01-27T16:52:25Z,698.5
siconvr,"Fetch data on targeted public investments from Plataforma +Brasil (SICONV) <http://plataformamaisbrasil.gov.br/>, 
    the responsible system for requests, execution, and monitoring of federal discretionary transfers in Brazil.",2021-05-18,Fernando Meireles,"https://github.com/meirelesff/siconvr,
https://fmeireles.com/siconvr/",TRUE,https://github.com/meirelesff/siconvr,3733,8,2021-09-05T20:42:17Z,466.625
sidrar,"Allows the user to connect with IBGE's (Instituto Brasileiro de 
    Geografia e Estatistica, see <https://www.ibge.gov.br/> for more information)
    SIDRA API in a flexible way. SIDRA is the acronym to ""Sistema IBGE de 
    Recuperacao Automatica"" and is the system where IBGE turns available 
    aggregate data from their researches.",2022-06-03,Renato Prado Siqueira,https://github.com/rpradosiqueira/sidrar/,TRUE,https://github.com/rpradosiqueira/sidrar,53978,45,2022-06-03T20:30:45Z,1199.5111111111112
sievePH,"Implements semiparametric estimation and testing procedures for a continuous, possibly multivariate, mark-specific hazard ratio (treatment/placebo) of an event of interest in a randomized treatment efficacy trial with a time-to-event endpoint, as described in Juraska M and Gilbert PB (2013), Mark-specific hazard ratio model with multivariate continuous marks: an application to vaccine efficacy. Biometrics 69(2):328 337 <doi:10.1111/biom.12016>, and in Juraska M and Gilbert PB (2015), Mark-specific hazard ratio model with missing multivariate marks. Lifetime Data Analysis 22(4): 606-25 <doi:10.1007/s10985-015-9353-9>. The former considers continuous multivariate marks fully observed in all subjects who experience the event of interest, whereas the latter extends the previous work to allow multivariate marks that are subject to missingness-at-random. For models with missing marks, two estimators are implemented based on (i) inverse probability weighting (IPW) of complete cases, and (ii) augmentation of the IPW estimating functions by leveraging correlations between the mark and auxiliary data to 'impute' the expected profile score vectors for subjects with missing marks. The augmented IPW estimator is doubly robust and recommended for use with incomplete mark data. The methods make two key assumptions: (i) the time-to-event is assumed to be conditionally independent of the mark given treatment, and (ii) the weight function in the semiparametric density ratio/biased sampling model is assumed to be exponential. Diagnostic testing procedures for evaluating validity of both assumptions are implemented. Summary and plotting functions are provided for estimation and inferential results.",2019-12-06,Michal Juraska,https://github.com/mjuraska/sievePH,TRUE,https://github.com/mjuraska/sieveph,10844,0,2022-05-03T22:07:03Z,NA
SightabilityModel,"Uses logistic regression to model the probability of detection as a function of covariates. 
             This model is then used with observational survey data to estimate population size, while
             accounting for uncertain detection.  See Steinhorst and Samuel (1989).",2022-06-01,Schwarz Carl James,https://github.com/jfieberg/SightabilityModel,TRUE,https://github.com/jfieberg/sightabilitymodel,18517,1,2022-06-01T22:22:41Z,18517
sigminer,"Genomic alterations including single nucleotide substitution,
    copy number alteration, etc. are the major force for cancer
    initialization and development. Due to the specificity of molecular
    lesions caused by genomic alterations, we can generate characteristic
    alteration spectra, called 'signature' (Wang, Shixiang, et al. (2021)
    <DOI:10.1371/journal.pgen.1009557> & Alexandrov, Ludmil B., et al.
    (2020) <DOI:10.1038/s41586-020-1943-3> & Steele Christopher D., et al.
    (2022) <DOI:10.1038/s41586-022-04738-6>).  This package helps users to
    extract, analyze and visualize signatures from genomic alteration
    records, thus providing new insight into cancer study.",2022-06-30,Shixiang Wang,https://github.com/ShixiangWang/sigminer,TRUE,https://github.com/shixiangwang/sigminer,17603,100,2022-06-30T10:01:45Z,176.03
Signac,"A framework for the analysis and exploration of single-cell chromatin data.
    The 'Signac' package contains functions for quantifying single-cell chromatin data,
    computing per-cell quality control metrics, dimension reduction
    and normalization, visualization, and DNA sequence motif analysis.
    Reference: Stuart et al. (2021) <doi:10.1038/s41592-021-01282-5>.",2022-06-01,Tim Stuart,"https://github.com/timoast/signac, https://satijalab.org/signac",TRUE,https://github.com/timoast/signac,120144,175,2022-06-01T13:27:50Z,686.5371428571428
SignacX,An implementation of neural networks trained with flow-sorted gene expression data to classify cellular phenotypes in single cell RNA-sequencing data. See Chamberlain M et al. (2021) <doi:10.1101/2021.02.01.429207> for more details.,2021-11-18,Mathew Chamberlain,https://github.com/mathewchamberlain/SignacX,TRUE,https://github.com/mathewchamberlain/signacx,6924,18,2021-07-22T20:19:06Z,384.6666666666667
signnet,"Methods for the analysis of signed networks. This includes several measures for structural balance as introduced by Cartwright and Harary (1956) <doi:10.1037/h0046049>, blockmodeling algorithms from Doreian (2008) <doi:10.1016/j.socnet.2008.03.005>, various centrality indices, and projections of signed two-mode networks introduced by Schoch (2020) <doi:10.1080/0022250X.2019.1711376>.",2022-02-13,David Schoch,https://github.com/schochastics/signnet,TRUE,https://github.com/schochastics/signnet,15540,20,2022-02-12T14:47:18Z,777
sigora,"
     Pathway Analysis is statistically linking observations on 
     the molecular level to biological processes or pathways on 
     the systems(i.e., organism, organ, tissue, cell) level.  
     Traditionally, pathway analysis methods regard pathways 
     as collections of single genes and treat all genes in a pathway
     as equally informative. However, this can lead to identifying
     spurious pathways as statistically significant since components
     are often shared amongst pathways. SIGORA seeks to avoid this
     pitfall by focusing on genes or gene pairs that are (as a combination)
     specific to a single pathway.
     In relying on such pathway gene-pair signatures (Pathway-GPS),
     SIGORA inherently uses the status of other genes in the
     experimental context to identify the most relevant pathways.
     The current version allows for pathway analysis of human
     and mouse datasets. In addition, it contains pre-computed
     Pathway-GPS data for pathways in the KEGG and  Reactome
     pathway repositories and mechanisms for extracting GPS
     for user-supplied repositories.",2021-11-30,Witold Wolski,https://github.com/wolski/sigora,TRUE,https://github.com/wolski/sigora,12258,0,2021-11-29T12:42:31Z,NA
SIHR,"Inference procedures in the high-dimensional setting for (1) linear functionals and quadratic functionals in linear regression ('Cai et al.' (2019) <arXiv:1904.12891>, 'Guo et al.' (2019) <arXiv:1909.01503>), (2) linear functional in logistic regression ('Guo et al.' <arXiv:2012.07133>), (3) individual treatment effects in linear and logistic regression, (4) single regression coefficient in binary outcome regression.",2021-10-07,Prabrisha Rakshit,https://github.com/prabrishar1/SIHR,TRUE,https://github.com/prabrishar1/sihr,4383,0,2022-07-05T00:38:28Z,NA
silicate,"Generate common data forms for complex data suitable for conversions and
 transmission by decomposition as paths or primitives. Paths are sequentially-linked records, 
 primitives are basic atomic elements and both can model many forms and be grouped into hierarchical 
 structures.  The universal models 'SC0' (structural) and 'SC' (labelled, relational) are composed of 
 edges and can represent any hierarchical form. Specialist models 'PATH', 'ARC' and 'TRI' provide the 
 most common intermediate forms used for converting from one form to another. The methods are
 inspired by the simplicial complex <https://en.wikipedia.org/wiki/Simplicial_complex> and 
 provide intermediate forms that relate spatial data structures to this mathematical construct. ",2020-11-13,Michael D. Sumner,https://github.com/hypertidy/silicate,TRUE,https://github.com/hypertidy/silicate,20372,46,2022-03-23T10:19:04Z,442.8695652173913
simcross,"Simulate and plot general experimental crosses. The focus is on simulating genotypes with an aim towards flexibility rather than speed. Meiosis is simulated following the Stahl model, in which chiasma locations are the superposition of two processes: a proportion p coming from a process exhibiting no interference, and the remainder coming from a process following the chi-square model.",2020-09-24,Karl W Broman,"https://kbroman.org/simcross/, https://github.com/kbroman/simcross",TRUE,https://github.com/kbroman/simcross,6540,6,2021-07-31T14:05:57Z,1090
SimDesign,"Provides tools to safely and efficiently organize and execute 
    Monte Carlo simulation experiments in R.
    The package controls the structure and back-end of Monte Carlo simulation experiments
    by utilizing a generate-analyse-summarise workflow. The workflow safeguards against 
    common simulation coding issues, such as automatically re-simulating non-convergent results, 
    prevents inadvertently overwriting simulation files, catches error and warning messages
    during execution, and implicitly supports parallel processing.
    For a pedagogical introduction to the package see
    Sigal and Chalmers (2016) <doi:10.1080/10691898.2016.1246953>. For a more in-depth overview of 
    the package and its design philosophy see Chalmers and Adkins (2020) <doi:10.20982/tqmp.16.4.p248>.",2021-12-08,Phil Chalmers,"https://github.com/philchalmers/SimDesign,
https://github.com/philchalmers/SimDesign/wiki",TRUE,https://github.com/philchalmers/simdesign,78374,45,2022-06-20T14:59:49Z,1741.6444444444444
simer,"Data simulator including genotype, phenotype, pedigree, 
    selection and reproduction in R. It simulates most of reproduction process
    of animals or plants and provides data for GS (Genomic Selection),
    GWAS (Genome-Wide Association Study), and Breeding.
    For ADI model, please see Kao C and Zeng Z (2002) <doi:10.1093/genetics/160.3.1243>.
    For build.cov, please see B. D. Ripley (1987) <ISBN:9780470009604>.",2022-05-12,Xiaolei Liu,https://github.com/xiaolei-lab/SIMER,TRUE,https://github.com/xiaolei-lab/simer,312,14,2022-07-10T04:10:53Z,22.285714285714285
simfam,"The focus is on simulating and modeling families with founders drawn from a structured population (for example, with different ancestries or other potentially non-family relatedness), in contrast to traditional pedigree analysis that treats all founders as equally unrelated.  Main function simulates a random pedigree for many generations, avoiding close relatives, pairing closest individuals according to a 1D geography and their randomly-drawn sex, and with variable children sizes to result in a target population size per generation.  Auxiliary functions calculate kinship matrices, admixture matrices, and draw random genotypes across arbitrary pedigree structures starting from the corresponding founder values.  The code is built around the plink FAM table format for pedigrees.  Partially described in Yao and Ochoa (2019) <doi:10.1101/858399>.",2021-10-05,Alejandro Ochoa,https://github.com/OchoaLab/simfam,TRUE,https://github.com/ochoalab/simfam,3229,1,2022-06-28T18:33:11Z,3229
simfinapi,"Through simfinapi, you can intuitively access the 'SimFin'
    Web-API (<https://simfin.com/>) to make 'SimFin' data easily available
    in R. To obtain an 'SimFin' API key (and thus to use this package),
    you need to register at <https://simfin.com/login>.",2021-09-11,Matthias Gomolka,https://github.com/matthiasgomolka/simfinapi,TRUE,https://github.com/matthiasgomolka/simfinapi,8749,11,2021-10-12T19:47:17Z,795.3636363636364
simglm,"Simulates regression models,
    including both simple regression and generalized linear mixed
    models with up to three level of nesting. Power simulations that are
    flexible allowing the specification of missing data, unbalanced designs,
    and different random error distributions are built into the package.",2022-02-07,Brandon LeBeau,https://github.com/lebebr01/simglm,TRUE,https://github.com/lebebr01/simglm,18555,41,2022-02-07T04:20:42Z,452.5609756097561
simhelpers,"Calculates performance criteria measures and associated Monte Carlo standard errors for simulation results. Includes functions to help run simulation studies. Our derivation and explanation of formulas and our general simulation workflow is closely aligned with the approach described by Morris, White, and Crowther (2019) <DOI:10.1002/sim.8086>. ",2022-05-03,Megha Joshi,https://meghapsimatrix.github.io/simhelpers/index.html,TRUE,https://github.com/meghapsimatrix/simhelpers,9370,9,2022-07-07T17:06:03Z,1041.111111111111
SimInf,"Provides an efficient and very flexible framework to
    conduct data-driven epidemiological modeling in realistic large
    scale disease spread simulations. The framework integrates
    infection dynamics in subpopulations as continuous-time Markov
    chains using the Gillespie stochastic simulation algorithm and
    incorporates available data such as births, deaths and movements
    as scheduled events at predefined time-points. Using C code for
    the numerical solvers and 'OpenMP' (if available) to divide work
    over multiple processors ensures high performance when simulating
    a sample outcome. One of our design goals was to make the package
    extendable and enable usage of the numerical solvers from other R
    extension packages in order to facilitate complex epidemiological
    research. The package contains template models and can be extended
    with user-defined models. For more details see the paper by
    Widgren, Bauer, Eriksson and Engblom (2019)
    <doi:10.18637/jss.v091.i12>. The package also provides
    functionality to fit models to time series data using the
    Approximate Bayesian Computation Sequential Monte Carlo
    ('ABC-SMC') algorithm of Toni and others (2009)
    <doi:10.1098/rsif.2008.0172>.",2022-06-08,Stefan Widgren,https://github.com/stewid/SimInf,TRUE,https://github.com/stewid/siminf,25195,21,2022-07-08T21:31:20Z,1199.7619047619048
simlandr,"A toolbox for constructing potential landscapes for dynamical systems using Monte Carlo simulation. 
    The method is based on the potential landscape definition by Wang et al. (2008) <doi:10.1073/pnas.0800579105> 
    (also see Zhou & Li, 2016 <doi:10.1063/1.4943096> for further mathematical discussions) and can be used for 
    a large variety of models.",2022-03-16,Jingmeng Cui,"https://sciurus365.github.io/simlandr/,
https://github.com/Sciurus365/simlandr",TRUE,https://github.com/sciurus365/simlandr,3699,3,2022-03-17T15:51:25Z,1233
simmer,"A process-oriented and trajectory-based Discrete-Event Simulation
    (DES) package for R. It is designed as a generic yet powerful framework. The
    architecture encloses a robust and fast simulation core written in 'C++' with
    automatic monitoring capabilities. It provides a rich and flexible R API that
    revolves around the concept of trajectory, a common path in the simulation
    model for entities of the same type. Documentation about 'simmer' is provided
    by several vignettes included in this package, via the paper by Ucar, Smeets
    & Azcorra (2019, <doi:10.18637/jss.v090.i02>), and the paper by Ucar,
    Hernández, Serrano & Azcorra (2018, <doi:10.1109/MCOM.2018.1700960>);
    see 'citation(""simmer"")' for details.",2022-06-25,Iñaki Ucar,"https://r-simmer.org, https://github.com/r-simmer/simmer",TRUE,https://github.com/r-simmer/simmer,45769,196,2022-06-25T21:20:46Z,233.51530612244898
simmer.bricks,Provides wrappers for common activity patterns in 'simmer' trajectories.,2019-01-09,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer.bricks",TRUE,https://github.com/r-simmer/simmer.bricks,12451,5,2022-06-01T12:56:19Z,2490.2
simmer.plot,A set of plotting methods for 'simmer' trajectories and simulations.,2022-02-07,Iñaki Ucar,"https://r-simmer.org, https://github.com/r-simmer/simmer.plot",TRUE,https://github.com/r-simmer/simmer.plot,29172,10,2022-02-07T22:09:44Z,2917.2
simmr,"Fits Stable Isotope Mixing Models (SIMMs) and is meant as a longer term replacement to the previous widely-used package SIAR. SIMMs are used to infer dietary proportions of organisms consuming various food sources from observations on the stable isotope values taken from the organisms' tissue samples. However SIMMs can also be used in other scenarios, such as in sediment mixing or the composition of fatty acids. The main functions are simmr_load and simmr_mcmc. The two vignettes contain a quick start and a full listing of all the features. The methods used are detailed in the papers Parnell et al 2010 <doi:10.1371/journal.pone.0009672>, and Parnell et al 2013 <doi:10.1002/env.2221>.",2021-02-27,Andrew Parnell,"https://github.com/andrewcparnell/simmr,
https://andrewcparnell.github.io/simmr/",TRUE,https://github.com/andrewcparnell/simmr,24883,16,2022-02-15T12:43:40Z,1555.1875
simodels,"Develop spatial interaction models (SIMs).  SIMs predict the
    amount of interaction, for example number of trips per day, between
    geographic entities representing trip origins and destinations.
    Contains functions for creating origin-destination datasets
    from geographic input datasets and calculating movement between
    origin-destination pairs with constrained, production-constrained,
    and attraction-constrained models (Wilson 1979) <doi:10.1068/a030001>.",2022-06-15,Robin Lovelace,"https://github.com/robinlovelace/simodels,
https://robinlovelace.github.io/simodels/",TRUE,https://github.com/robinlovelace/simodels,239,9,2022-06-15T10:39:02Z,26.555555555555557
simPH,"Simulates and plots quantities of interest (relative
    hazards, first differences, and hazard ratios) for linear coefficients,
    multiplicative interactions, polynomials, penalised splines, and
    non-proportional hazards, as well as stratified survival curves from Cox
    Proportional Hazard models. It also simulates and plots marginal effects
    for multiplicative interactions. Methods described in Gandrud (2015)
    <doi:10.18637/jss.v065.i03>.",2021-01-10,Christopher Gandrud,https://CRAN.R-project.org/package=simPH,TRUE,https://github.com/christophergandrud/simph,25144,14,2021-10-14T04:51:59Z,1796
simphony,"A tool for simulating rhythmic data: transcriptome data using
  Gaussian or negative binomial distributions, and behavioral activity data
  using Bernoulli or Poisson distributions. See Singer et al. (2019)
  <doi:10.7717/peerj.6985>.",2022-02-09,Jake Hughey,"https://simphony.hugheylab.org,
https://github.com/hugheylab/simphony",TRUE,https://github.com/hugheylab/simphony,1165,2,2022-05-18T16:35:17Z,582.5
simplecolors,"A curated set of colors that are called using
    a standardized syntax: saturation + hue + lightness. For example, 
    ""brightblue4"" and ""mutedred2"". Functions exists to return individual colors 
    by name or to build palettes across or within hues. Most functions allow you 
    to visualize the palettes in addition to returning the desired hex codes.",2020-10-27,Jake Riley,https://github.com/rjake/simplecolors,TRUE,https://github.com/rjake/simplecolors,11643,11,2022-06-30T02:13:15Z,1058.4545454545455
simplePHENOTYPES,"The number of studies involving correlated traits and the availability of tools to handle this type of data has increased considerably in the last decade. With such a demand, we need tools for testing hypotheses related to single and multi-trait (correlated) phenotypes based on many genetic settings. Thus, we implemented various options for simulation of pleiotropy and Linkage Disequilibrium under additive, dominance and epistatic models. The simulation currently takes a marker data set as an input and then uses it for simulating multiple traits as described in Fernandes and Lipka (2020) <doi:10.1186/s12859-020-03804-y>.",2021-01-20,Samuel Fernandes,https://github.com/samuelbfernandes/simplePHENOTYPES,TRUE,https://github.com/samuelbfernandes/simplephenotypes,11802,5,2022-01-13T17:41:22Z,2360.4
simplermarkdown,"Runs R-code present in a pandoc markdown file and 
  includes the resulting output in the resulting markdown file. This
  file can then be converted into any of the output formats 
  supported by pandoc. The package can also be used as an engine
  for writing package vignettes. ",2022-01-03,Jan van der Laan,https://github.com/djvanderlaan/simplermarkdown,TRUE,https://github.com/djvanderlaan/simplermarkdown,14986,12,2022-05-02T07:34:10Z,1248.8333333333333
simplevis,"Wrapper functions around the amazing 'ggplot2' and 'leaflet' 
    packages that aims to simplify beautiful 'ggplot2' and 'leaflet'  
    visualisation. Precursor package to the 'ggblanket' package. ",2022-06-07,David Hodge,"https://StatisticsNZ.github.io/simplevis/,
https://github.com/StatisticsNZ/simplevis/",TRUE,https://github.com/statisticsnz/simplevis,25072,79,2022-06-07T09:06:56Z,317.36708860759495
simplextree,"Provides an interface to a Simplex Tree data structure, which is 
  a data structure aimed at enabling efficient manipulation of simplicial complexes 
  of any dimension. The Simplex Tree data structure was originally introduced by 
  Jean-Daniel Boissonnat and Clément Maria (2014) <doi:10.1007/s00453-014-9887-3>. ",2020-09-12,Matt Piekenbrock,https://github.com/peekxc/simplextree,TRUE,https://github.com/peekxc/simplextree,7265,11,2022-05-23T14:30:06Z,660.4545454545455
simPop,"Tools and methods to simulate populations for surveys based
    on auxiliary data. The tools include model-based methods, calibration and
    combinatorial optimization algorithms, see Templ, Kowarik and Meindl (2017) <doi:10.18637/jss.v079.i10>) and
    Templ (2017) <doi:10.1007/978-3-319-50272-4>. The package was developed with support of
    the International Household Survey Network, DFID Trust Fund TF011722 and funds
    from the World bank.",2020-11-14,Matthias Templ,https://github.com/statistikat/simPop,TRUE,https://github.com/statistikat/simpop,19773,19,2022-06-20T13:45:38Z,1040.6842105263158
simpr,"A general, 'tidyverse'-friendly framework 
  for simulation studies, design analysis, and power analysis. 
  Specify data generation, define varying parameters, generate data, 
  fit models, and tidy model results in a single pipeline, without 
  needing loops or custom functions.",2022-02-13,Ethan Brown,"https://statisfactions.github.io/simpr/,
https://github.com/statisfactions/simpr/",TRUE,https://github.com/statisfactions/simpr,1577,16,2022-02-08T20:11:54Z,98.5625
simputation,"Easy to use interfaces to a number of imputation methods
        that fit in the not-a-pipe operator of the 'magrittr' package.",2022-06-16,Mark van der Loo,https://github.com/markvanderloo/simputation,TRUE,https://github.com/markvanderloo/simputation,78355,72,2022-06-16T13:33:18Z,1088.263888888889
simr,"Calculate power for generalised linear mixed models, using
    simulation. Designed to work with models fit using the 'lme4' package.
    Described in Green and MacLeod, 2016 <doi:10.1111/2041-210X.12504>.",2022-03-08,Peter Green,https://github.com/pitakakariki/simr,TRUE,https://github.com/pitakakariki/simr,43931,52,2022-03-08T09:09:50Z,844.8269230769231
simrel,"Researchers have been using simulated data from a multivariate linear model to compare and evaluate different methods, ideas and models. Additionally, teachers and educators have been using a simulation tool to demonstrate and teach various statistical and machine learning concepts.
    This package helps users to simulate linear model data with a wide range of properties by tuning few parameters such as relevant latent components. In addition, a shiny app as an 'RStudio' gadget gives users a simple interface for using the simulation function. See more on: Sæbø, S., Almøy, T., Helland, I.S. (2015) <doi:10.1016/j.chemolab.2015.05.012> and Rimal, R., Almøy, T., Sæbø, S. (2018) <doi:10.1016/j.chemolab.2018.02.009>.",2021-09-17,Raju Rimal,https://simulatr.github.io/simrel/,TRUE,https://github.com/simulatr/simrel,12799,2,2021-09-18T08:54:04Z,6399.5
simstandard,Creates simulated data from structural equation models with standardized loading. Data generation methods are described in Schneider (2013) <doi:10.1177/0734282913478046>.,2021-05-07,W. Joel Schneider,https://github.com/wjschne/simstandard,TRUE,https://github.com/wjschne/simstandard,14946,5,2022-03-28T08:13:01Z,2989.2
simstudy,"Simulates data sets in order to explore modeling
    techniques or better understand data generating processes. The user
    specifies a set of relationships between covariates, and generates
    data based on these specifications. The final data sets can represent
    data from randomized control trials, repeated measure (longitudinal)
    designs, and cluster randomized trials. Missingness can be generated
    using various mechanisms (MCAR, MAR, NMAR).",2022-07-08,Keith Goldfeld,"https://github.com/kgoldfeld/simstudy,
https://kgoldfeld.github.io/simstudy/,
https://kgoldfeld.github.io/simstudy/dev/",TRUE,https://github.com/kgoldfeld/simstudy,37163,52,2022-07-08T14:13:30Z,714.6730769230769
SimSurvey,"Simulate age-structured populations that vary in space and time and 
    explore the efficacy of a range of built-in or user-defined sampling 
    protocols to reproduce the population parameters of the known population. 
    (See Regular et al. (2020) <doi:10.1371/journal.pone.0232822> for more
    details).",2022-04-06,Paul Regular,https://paulregular.github.io/SimSurvey/,TRUE,https://github.com/paulregular/simsurvey,8202,10,2022-04-27T20:09:54Z,820.2
SimSurvNMarker,"Provides functions to simulate from joint survival and marker 
    models. The user can specific all basis functions of time, random or 
    deterministic covariates, random or deterministic left-truncation and 
    right-censoring times, and model parameters.",2022-03-30,Benjamin Christoffersen,https://github.com/boennecd/SimSurvNMarker,TRUE,https://github.com/boennecd/simsurvnmarker,7495,1,2022-03-30T10:45:19Z,7495
simTool,"Tool for statistical simulations that have two components. 
    One component generates the data and the other one
    analyzes the data. The main aims of the package are the reduction
    of the administrative source code (mainly loops and management code for the
    results) and a simple applicability of the package that allows the user to
    quickly learn how to work with it. Parallel computing is
    also supported. Finally, convenient functions are provided to summarize the
    simulation results.",2020-09-22,Marsel Scheer,https://github.com/MarselScheer/simTool,TRUE,https://github.com/marselscheer/simtool,16466,6,2021-09-06T18:45:26Z,2744.3333333333335
simtrait,"Simulate complex traits given a SNP genotype matrix and model parameters (the desired heritability, number of causal loci, and either the true ancestral allele frequencies used to generate the genotypes or the mean kinship for a real dataset).  Emphasis on avoiding common biases due to the use of estimated allele frequencies.  The code selects random loci to be causal, constructs coefficients for these loci and random independent non-genetic effects.  Traits can follow three models: random coefficients, fixed effect sizes, and infinitesimal (multivariate normal).  GWAS method benchmarking functions are also provided.  Partially described in Yao and Ochoa (2019) <doi:10.1101/858399>.",2021-08-16,Alejandro Ochoa,https://github.com/OchoaLab/simtrait,TRUE,https://github.com/ochoalab/simtrait,3181,3,2021-08-12T14:50:57Z,1060.3333333333333
simts,"A system contains easy-to-use tools as a support for time series analysis courses. In particular, it incorporates a technique called Generalized Method of Wavelet Moments (GMWM) as well as its robust implementation for fast and robust parameter estimation of time series models which is described, for example, in Guerrier et al. (2013) <doi: 10.1080/01621459.2013.799920>. More details can also be found in the paper linked to via the URL below.",2022-01-03,Stéphane Guerrier,"https://github.com/SMAC-Group/simts,
https://arxiv.org/pdf/1607.04543.pdf",TRUE,https://github.com/smac-group/simts,15122,10,2022-07-03T21:32:57Z,1512.2
simulariatools,"A set of tools developed at Simularia for Simularia, to help
    preprocessing and post-processing of meteorological and air quality data.",2021-11-29,Giuseppe Carlino,https://github.com/Simularia/simulariatools,TRUE,https://github.com/simularia/simulariatools,1946,2,2021-11-30T12:22:42Z,973
sinew,"Manage package documentation and namespaces from the command line. 
             Programmatically attach namespaces in R and Rmd script, populates 
             'Roxygen2' skeletons with information scraped from within functions and 
             populate the Imports field of the DESCRIPTION file.",2022-03-31,Jonathan Sidi,https://github.com/yonicd/sinew,TRUE,https://github.com/yonicd/sinew,20747,154,2022-03-27T11:27:09Z,134.7207792207792
singcar,"When comparing single cases to control populations and no parameters are known researchers and clinicians must estimate these with a control sample. This is often done when testing a case's abnormality on some variable or testing abnormality of the discrepancy between two variables. Appropriate frequentist and Bayesian methods for doing this are here implemented, including tests allowing for the inclusion of covariates. These have been developed first and foremost by John Crawford and Paul Garthwaite, e.g. in Crawford and Howell (1998) <doi:10.1076/clin.12.4.482.7241>, Crawford and Garthwaite (2005) <doi:10.1037/0894-4105.19.3.318>, Crawford and Garthwaite (2007) <doi:10.1080/02643290701290146> and Crawford, Garthwaite and Ryan (2011) <doi:10.1016/j.cortex.2011.02.017>. The package is also equipped with power calculators for each method. ",2021-03-01,Jonathan Rittmo,https://github.com/jorittmo/singcar,TRUE,https://github.com/jorittmo/singcar,7355,2,2021-12-30T12:34:27Z,3677.5
SingleCaseES,"
  Provides R functions for calculating basic effect size indices for 
  single-case designs, including several non-overlap measures and parametric 
  effect size measures, and for estimating the gradual effects model developed 
  by Swan and Pustejovsky (2018) <DOI:10.1080/00273171.2018.1466681>. 
  Standard errors and confidence intervals (based on the assumption that the outcome 
  measurements are mutually independent) are provided for the subset of effect sizes 
  indices with known sampling distributions.",2022-07-06,James E. Pustejovsky,https://jepusto.github.io/SingleCaseES/,TRUE,https://github.com/jepusto/singlecasees,23444,6,2022-07-07T03:08:48Z,3907.3333333333335
SIPDIBGE,"Provides access to packages developed for downloading, reading and analyzing microdata 
  from household surveys conducted by Brazilian Institute of Geography and Statistics - IBGE.
	More information can be obtained from the official website <https://www.ibge.gov.br/>.",2021-11-30,Gabriel Assuncao,NA,TRUE,https://github.com/gabriel-assuncao/sipdibge,8044,2,2021-11-30T13:20:07Z,4022
siplab,"A platform for computing competition indices and experimenting
    with spatially explicit individual-based vegetation models.",2022-03-07,Oscar Garcia,https://github.com/ogarciav/siplab/,TRUE,https://github.com/ogarciav/siplab,19997,2,2022-03-09T00:02:47Z,9998.5
sirt,"
    Supplementary functions for item response models aiming
    to complement existing R packages. The functionality includes among others
    multidimensional compensatory and noncompensatory IRT models
    (Reckase, 2009, <doi:10.1007/978-0-387-89976-3>), 
    MCMC for hierarchical IRT models and testlet models
    (Fox, 2010, <doi:10.1007/978-1-4419-0742-4>), 
    NOHARM (McDonald, 1982, <doi:10.1177/014662168200600402>), 
    Rasch copula model (Braeken, 2011, <doi:10.1007/s11336-010-9190-4>;
    Schroeders, Robitzsch & Schipolowski, 2014, <doi:10.1111/jedm.12054>),
    faceted and hierarchical rater models (DeCarlo, Kim & Johnson, 2011,
    <doi:10.1111/j.1745-3984.2011.00143.x>),
    ordinal IRT model (ISOP; Scheiblechner, 1995, <doi:10.1007/BF02301417>), 
    DETECT statistic (Stout, Habing, Douglas & Kim, 1996, 
    <doi:10.1177/014662169602000403>), local structural equation modeling 
    (LSEM; Hildebrandt, Luedtke, Robitzsch, Sommer & Wilhelm, 2016,
    <doi:10.1080/00273171.2016.1142856>).",2022-05-17,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/sirt,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/sirt,106856,19,2022-05-17T09:54:26Z,5624
sitar,"Functions for fitting and plotting SITAR (Super
    Imposition by Translation And Rotation) growth curve models. SITAR is
    a shape-invariant model with a regression B-spline mean curve and
    subject-specific random effects on both the measurement and age
    scales.  The model was first described by Lindstrom (1995)
    <doi:10.1002/sim.4780141807> and developed as the SITAR method by Cole
    et al (2010) <doi:10.1093/ije/dyq115>.",2021-04-22,Tim Cole,https://github.com/statist7/sitar,TRUE,https://github.com/statist7/sitar,24986,8,2022-07-07T15:08:59Z,3123.25
siteymlgen,"The goal of 'siteymlgen' is to make it easy to organise
  the building of your 'R Markdown' website.
  The init() function placed within the first code chunk of the index.Rmd
  file of an 'R' project directory will initiate the generation of an automatically
  written _site.yml file. 'siteymlgen' recommends a specific naming
  convention for your 'R Markdown' files. This naming will ensure that
  your navbar layout is ordered according to a hierarchy.",2020-05-08,Adam Cribbs,https://github.com/Acribbs/siteymlgen,TRUE,https://github.com/acribbs/siteymlgen,6969,2,2021-08-18T11:53:31Z,3484.5
sitmo,"Provided within are two high quality and fast PPRNGs that may be
    used in an 'OpenMP' parallel environment. In addition, there is a generator
    for one dimensional low-discrepancy sequence. The objective of this library
    to consolidate the distribution of the 'sitmo' (C++98 & C++11), 'threefry' and
    'vandercorput' (C++11-only) engines on CRAN by enabling others to link to the
    header files inside of 'sitmo' instead of including a copy of each engine
    within their individual package. Lastly, the package contains example
    implementations using the 'sitmo' package and three accompanying vignette that
    provide additional information.",2021-10-13,James Balamuta,"https://github.com/coatless/sitmo,
http://thecoatlessprofessor.com/projects/sitmo/,
https://github.com/stdfin/random/",TRUE,https://github.com/coatless/sitmo,467505,6,2021-10-13T17:31:34Z,77917.5
sits,"An end-to-end toolkit for land use and land cover classification
    using big Earth observation data, based on machine learning methods 
    applied to satellite image data cubes, as described in Simoes et al (2021) <doi:10.3390/rs13132428>.
    Builds regular data cubes from collections in AWS, Microsoft Planetary Computer, 
    Brazil Data Cube, and Digital Earth Africa using the STAC protocol <https://stacspec.org/>
    and the 'gdalcubes' R package <doi:10.3390/data4030092>.
    Supports visualization methods for images and time series and 
    smoothing filters for dealing with noisy time series.
    Includes functions for quality assessment of training samples using self-organized maps 
    as presented by Santos et al (2021) <doi:10.1016/j.isprsjprs.2021.04.014>. 
    Provides machine learning methods including support vector machines, 
    random forests, extreme gradient boosting, multi-layer perceptrons,
    temporal convolutional neural networks <doi:10.3390/rs11050523>, 
    residual networks <arxiv:1809.04356>, and temporal attention encoders
    <arXiv:2007.00586>.
    Performs efficient classification of big Earth observation data cubes and includes 
    functions for post-classification smoothing based on Bayesian inference, and 
    methods for uncertainty assessment. Enables best
    practices for estimating area and assessing accuracy of land change as 
    recommended by Olofsson et al(2014) <doi:10.1016/j.rse.2014.02.015>.
    Minimum recommended requirements: 16 GB RAM and 4 CPU dual-core.",2022-07-07,Gilberto Camara,"https://github.com/e-sensing/sits/,
https://e-sensing.github.io/sitsbook/",TRUE,https://github.com/e-sensing/sits,738,278,2022-07-06T22:28:44Z,2.6546762589928057
sivs,"An iterative feature selection method (manuscript submitted) that
    internally utilizes various Machine Learning methods that have embedded
    feature reduction in order to shrink down the feature space into a small
    and yet robust set.",2021-07-20,Mehrad Mahmoudian,"https://github.com/mmahmoudian/sivs,
https://doi.org/10.1093/bioinformatics/btab501",TRUE,https://github.com/mmahmoudian/sivs,7549,3,2021-10-10T08:44:14Z,2516.3333333333335
SiZer,"Calculates and plots the SiZer map for scatterplot data.  A 
  SiZer map is a way of examining when the p-th derivative of a 
  scatterplot-smoother is significantly negative, possibly zero or 
  significantly positive across a range of smoothing bandwidths.",2022-07-09,Derek Sonderegger,https://github.com/dereksonderegger/SiZer,TRUE,https://github.com/dereksonderegger/sizer,18917,0,2022-07-09T18:04:52Z,NA
sjlabelled,"Collection of functions dealing with labelled data, like reading and 
    writing data between R and other statistical software packages like 'SPSS',
    'SAS' or 'Stata', and working with labelled data. This includes easy ways 
    to get, set or change value and variable label attributes, to convert 
    labelled vectors into factors or numeric (and vice versa), or to deal with 
    multiple declared missing values.",2022-04-10,Daniel Lüdecke,https://strengejacke.github.io/sjlabelled/,TRUE,https://github.com/strengejacke/sjlabelled,1113684,68,2022-05-01T15:31:47Z,16377.70588235294
sjmisc,"Collection of miscellaneous utility functions, supporting data 
    transformation tasks like recoding, dichotomizing or grouping variables, 
    setting and replacing missing values. The data transformation functions 
    also support labelled data, and all integrate seamlessly into a 
    'tidyverse'-workflow.",2021-12-03,Daniel Lüdecke,https://strengejacke.github.io/sjmisc/,TRUE,https://github.com/strengejacke/sjmisc,932871,150,2022-05-01T16:22:04Z,6219.14
sjPlot,"Collection of plotting and table output functions for data
    visualization. Results of various statistical analyses (that are commonly used
    in social sciences) can be visualized using this package, including simple and
    cross tabulated frequencies, histograms, box plots, (generalized) linear models,
    mixed effects models, principal component analysis and correlation matrices, 
    cluster analyses, scatter plots, stacked scales, effects plots of regression 
    models (including interaction terms) and much more. This package supports
    labelled data.",2021-11-26,Daniel Lüdecke,https://strengejacke.github.io/sjPlot/,TRUE,https://github.com/strengejacke/sjplot,662145,536,2022-06-28T10:31:42Z,1235.3451492537313
sjSDM,"A scalable method to estimate joint Species Distribution Models (jSDMs) for big community datasets based on a Monte Carlo approximation of the joint likelihood.  The numerical approximation is based on 'PyTorch' and 'reticulate', and can be run on CPUs and GPUs alike. The method is described in Pichler & Hartig (2021) <doi:10.1111/2041-210X.13687>. The package contains various extensions, including support for different response families, ability to account for spatial autocorrelation, and deep neural networks instead of the linear predictor in jSDMs.",2022-06-23,Maximilian Pichler,https://theoreticalecology.github.io/s-jSDM/,TRUE,https://github.com/theoreticalecology/s-jsdm,2055,41,2022-06-23T06:04:05Z,50.1219512195122
sjstats,"Collection of convenient functions for common statistical computations,
             which are not directly provided by R's base or stats packages.
             This package aims at providing, first, shortcuts for statistical measures, 
             which otherwise could only be calculated with additional effort 
             (like Cramer's V, Phi, or effect size statistics like Eta or Omega squared), 
             or for which currently no functions available. Second, another focus 
             lies on weighted variants of common statistical measures and tests 
             like weighted standard error, mean, t-test, correlation, and more.",2021-01-09,Daniel Lüdecke,https://strengejacke.github.io/sjstats/,TRUE,https://github.com/strengejacke/sjstats,629818,174,2021-10-21T14:28:32Z,3619.6436781609195
sjtable2df,"A small set of helper functions to convert 'sjPlot'
    HTML-tables to R data.frame objects / knitr::kable-tables.",2022-06-22,Lorenz A. Kapsner,https://github.com/kapsner/sjtable2df,TRUE,https://github.com/kapsner/sjtable2df,206,2,2022-06-29T05:32:09Z,103
skater,"Utilities for single nucleotide polymorphism (SNP) based kinship analysis
    testing and evaluation. The 'skater' package contains functions for importing, parsing, 
    and analyzing pedigree data, performing relationship degree inference, benchmarking 
    relationship degree classification, and summarizing identity by descent (IBD) segment data.
    Package functions and methods are described in Turner et al. (2021) ""skater: An R package 
    for SNP-based Kinship Analysis, Testing, and Evaluation"" <doi:10.1101/2021.07.21.453083>.",2022-02-01,Stephen Turner,https://github.com/signaturescience/skater,TRUE,https://github.com/signaturescience/skater,2064,6,2022-02-01T14:24:24Z,344
skedastic,"Implements numerous methods for detecting heteroskedasticity 
    (sometimes called heteroscedasticity) in the classical linear regression 
    model. These include a test based on Anscombe (1961) 
    <https://projecteuclid.org/euclid.bsmsp/1200512155>, Ramsey's (1969) 
    BAMSET Test <doi:10.1111/j.2517-6161.1969.tb00796.x>, the tests of Bickel 
    (1978) <doi:10.1214/aos/1176344124>, Breusch and Pagan (1979)  
    <doi:10.2307/1911963> with and without the modification 
    proposed by Koenker (1981) <doi:10.1016/0304-4076(81)90062-2>, Carapeto and 
    Holt (2003) <doi:10.1080/0266476022000018475>, Cook and Weisberg (1983) 
    <doi:10.1093/biomet/70.1.1> (including their graphical methods), Diblasi 
    and Bowman (1997) <doi:10.1016/S0167-7152(96)00115-0>, Dufour, Khalaf, 
    Bernard, and Genest (2004) <doi:10.1016/j.jeconom.2003.10.024>, Evans and 
    King (1985) <doi:10.1016/0304-4076(85)90085-5> and Evans and King (1988) 
    <doi:10.1016/0304-4076(88)90006-1>, Glejser (1969) 
    <doi:10.1080/01621459.1969.10500976> as formulated by 
    Mittelhammer, Judge and Miller (2000, ISBN: 0-521-62394-4), Godfrey and 
    Orme (1999) <doi:10.1080/07474939908800438>, Goldfeld and Quandt 
    (1965) <doi:10.1080/01621459.1965.10480811>, Harrison and McCabe (1979) 
    <doi:10.1080/01621459.1979.10482544>, Harvey (1976) <doi:10.2307/1913974>, 
    Honda (1989) <doi:10.1111/j.2517-6161.1989.tb01749.x>, Horn (1981) 
    <doi:10.1080/03610928108828074>, Li and Yao (2019) 
    <doi:10.1016/j.ecosta.2018.01.001> with and without the modification of 
    Bai, Pan, and Yin (2016) <doi:10.1007/s11749-017-0575-x>, Rackauskas and 
    Zuokas (2007) <doi:10.1007/s10986-007-0018-6>, Simonoff and Tsai (1994) 
    <doi:10.2307/2986026> with and without the modification of Ferrari, 
    Cysneiros, and Cribari-Neto (2004) <doi:10.1016/S0378-3758(03)00210-6>, 
    Szroeter (1978) <doi:10.2307/1913831>, Verbyla (1993) 
    <doi:10.1111/j.2517-6161.1993.tb01918.x>, White (1980) 
    <doi:10.2307/1912934>, Wilcox and Keselman (2006) 
    <doi:10.1080/10629360500107923>, Yuce (2008) 
    <https://dergipark.org.tr/en/pub/iuekois/issue/8989/112070>, and Zhou, 
    Song, and Thompson (2015) <doi:10.1002/cjs.11252>. Besides these 
    heteroskedasticity tests, there are supporting functions that compute the 
    BLUS residuals of Theil (1965) <doi:10.1080/01621459.1965.10480851>, the 
    conditional two-sided p-values of Kulinskaya (2008) <arXiv:0810.2124v1>, 
    and probabilities for the nonparametric trend statistic of Lehmann (1975, 
    ISBN: 0-816-24996-1). Homoskedasticity refers to the assumption of 
    constant variance that is imposed on the model errors (disturbances); 
    heteroskedasticity is the violation of this assumption.",2022-02-22,Thomas Farrar,https://github.com/tjfarrar/skedastic,TRUE,https://github.com/tjfarrar/skedastic,35910,5,2022-02-21T13:29:08Z,7182
sketch,"Creates static / animated / interactive visualisations embeddable
    in R Markdown documents. It implements an R-to-JavaScript transpiler and
    enables users to write JavaScript applications using the syntax of R.",2021-10-06,Chun Fung Kwok,NA,TRUE,https://github.com/kcf-jackson/sketch,6967,90,2021-10-07T13:03:22Z,77.41111111111111
sketching,"Construct sketches of data via random subspace embeddings. 
  For more details, see the following papers.
  Lee, S. and Ng, S. (2022). ""Least Squares Estimation Using Sketched Data with Heteroskedastic Errors,"" <arXiv:2007.07781>, accepted for presentation at the Thirty-ninth International Conference on Machine Learning (ICML 2022).
  Lee, S. and Ng, S. (2020). ""An Econometric Perspective on Algorithmic Subsampling,"" Annual Review of Economics, 12(1): 45–80.",2022-06-08,Sokbae Lee,https://github.com/sokbae/sketching/,TRUE,https://github.com/sokbae/sketching,233,1,2022-06-13T10:41:01Z,233
sketchy,"Provides functions to create and manage research compendiums for data analysis. Research compendiums are a standard and intuitive folder structure for organizing the digital materials of a research project, which can significantly improve reproducibility. The package offers several compendium structure options that fit different research project as well as the ability of duplicating the folder structure of existing projects or implementing custom structures. It also simplifies the use of version control.",2022-02-09,Marcelo Araya-Salas,https://github.com/maRce10/sketchy,TRUE,https://github.com/marce10/sketchy,1134,0,2022-07-07T20:57:06Z,NA
skewlmm,"It fits scale mixture of skew-normal linear mixed models using an expectation–maximization (EM) type algorithm, including some possibilities for modeling the within-subject dependence. Details can be found in Schumacher, Lachos and Matos (2021) <doi:10.1002/sim.8870>.",2021-09-18,Fernanda L. Schumacher,https://github.com/fernandalschumacher/skewlmm,TRUE,https://github.com/fernandalschumacher/skewlmm,13366,1,2021-09-20T02:54:40Z,13366
skimr,"A simple to use summary function that can be used with pipes
    and displays nicely in the console. The default summary statistics may
    be modified by the user as can the default formatting.  Support for
    data frames and vectors is included, and users can implement their own
    skim methods for specific object types as described in a vignette.
    Default summaries include support for inline spark graphs.
    Instructions for managing these on specific operating systems are
    given in the ""Using skimr"" vignette and the README.",2022-04-15,Elin Waring,"https://docs.ropensci.org/skimr/ (website),
https://github.com/ropensci/skimr/",TRUE,https://github.com/ropensci/skimr,1052943,1022,2022-05-13T20:21:48Z,1030.2769080234834
sknifedatar,"Extension of the 'modeltime' ecosystem. In
    addition. Allows fitting of multiple models over multiple time series.
    It also provides a bridge for using the 'workflowsets' package with
    'modeltime'. It includes some functionalities for spatial data and
    visualization.",2021-06-01,Rafael Zambrano,https://github.com/rafzamb/sknifedatar,TRUE,https://github.com/rafzamb/sknifedatar,4740,27,2021-07-18T16:35:20Z,175.55555555555554
skpr,"Generates and evaluates D, I, A, Alias, E, T, and G optimal designs. Supports generation and evaluation of blocked and split/split-split/.../N-split plot designs. Includes parametric and Monte Carlo power evaluation functions, and supports calculating power for censored responses. Provides a framework to evaluate power using functions provided in other packages or written by the user. Includes a Shiny graphical user interface that displays the underlying code used to create and evaluate the design to improve ease-of-use and make analyses more reproducible. For details, see Morgan-Wall et al. (2021) <doi:10.18637/jss.v099.i01>.",2022-04-08,Tyler Morgan-Wall,https://github.com/tylermorganwall/skpr,TRUE,https://github.com/tylermorganwall/skpr,46871,84,2022-07-08T20:49:25Z,557.9880952380952
skynet,"A flexible tool that allows generating bespoke
    air transport statistics for urban studies based on publicly available
    data from the Bureau of Transport Statistics (BTS) in the United States
    <https://www.transtats.bts.gov/databases.asp?Z1qr_VQ=E&Z1qr_Qr5p=N8vn6v10&f7owrp6_VQF=D>.",2022-06-17,Filipe Teixeira,https://github.com/ropensci/skynet,TRUE,https://github.com/ropensci/skynet,14702,9,2022-06-17T11:17:49Z,1633.5555555555557
slackr,"'Slack' <https://slack.com/> provides a service for teams to
    collaborate by sharing messages, images, links, files and more.
    Functions are provided that make it possible to interact with the
    'Slack' platform 'API'. When you need to share information or data
    from R, rather than resort to copy/ paste in e-mails or other services
    like 'Skype' <https://www.skype.com/en/>, you can use this package to
    send well-formatted output from multiple R objects and expressions to
    all teammates at the same time with little effort. You can also send
    images from the current graphics device, R objects, and upload files.",2021-09-20,Bob Rudis,"https://github.com/mrkaye97/slackr,
https://mrkaye97.github.io/slackr/",TRUE,https://github.com/mrkaye97/slackr,138717,289,2022-03-04T22:10:36Z,479.9896193771626
slasso,Implements the smooth LASSO estimator for the function-on-function linear regression model described in Centofanti et al. (2020) <arXiv:2007.00529>.,2021-10-15,Fabio Centofanti,https://github.com/unina-sfere/slasso,TRUE,https://github.com/unina-sfere/slasso,2675,1,2021-10-15T16:58:33Z,2675
sld,"The skew logistic distribution is a quantile-defined generalisation
 of the logistic distribution (van Staden and King 2015).  Provides random 
 numbers, quantiles, probabilities, densities and density quantiles for the distribution.
 It provides Quantile-Quantile plots and method of L-Moments estimation 
 (including asymptotic standard errors) for the distribution.",2022-06-28,Robert King,https://github.com/newystats/SLD/,TRUE,https://github.com/newystats/sld,21726,0,2022-06-28T12:40:19Z,NA
sleepr,"Use behavioural variables to score activity and infer sleep from bouts of immobility. 
    It is primarily designed to score sleep in fruit flies from Drosophila Activity Monitor (TriKinetics) and Ethoscope data.
    It implements sleep scoring using the ""five-minute rule"" (Hendricks et al. (2000) <DOI:10.1016/S0896-6273(00)80877-6>),
    activity classification for Ethoscopes (Geissmann et al. (2017) <DOI:10.1371/journal.pbio.2003026>) 
    and a new algorithm to detect when animals are dead.",2018-10-30,Quentin Geissmann,https://github.com/rethomics/sleepr,TRUE,https://github.com/rethomics/sleepr,11636,5,2021-10-22T16:11:37Z,2327.2
sleepwalk,"A tool to interactively explore the
  embeddings created by dimension reduction methods such as 
  Principal Components Analysis (PCA), Multidimensional Scaling (MDS), 
  T-distributed Stochastic Neighbour Embedding (t-SNE),
  Uniform Manifold Approximation and Projection (UMAP) or any other.",2021-09-16,Svetlana Ovchinnikova,https://anders-biostat.github.io/sleepwalk/,TRUE,https://github.com/anders-biostat/sleepwalk,15098,89,2022-07-06T09:48:51Z,169.64044943820224
slider,"Provides type-stable rolling window functions over any R data
    type. Cumulative and expanding windows are also supported. For more
    advanced usage, an index can be used as a secondary vector that
    defines how sliding windows are to be created.",2021-07-01,Davis Vaughan,https://github.com/DavisVaughan/slider,TRUE,https://github.com/davisvaughan/slider,1854126,228,2022-03-01T20:47:35Z,8132.131578947368
SLOPE,"Efficient implementations for Sorted L-One Penalized Estimation
    (SLOPE): generalized linear models regularized with the sorted L1-norm
    (Bogdan et al. (2015) <doi:10/gfgwzt>). Supported models include ordinary
    least-squares regression, binomial regression, multinomial regression, and
    Poisson regression. Both dense and sparse  predictor matrices are supported.
    In addition, the package features predictor screening rules that enable fast
    and efficient solutions to high-dimensional problems.",2022-06-09,Johan Larsson,"https://jolars.github.io/SLOPE/, https://github.com/jolars/SLOPE",TRUE,https://github.com/jolars/slope,30003,15,2022-06-10T07:08:02Z,2000.2
slouch,"An implementation of a phylogenetic comparative method. It can fit univariate among-species Ornstein-Uhlenbeck models of phenotypic trait evolution, where the trait evolves towards a primary optimum. The optimum can be modelled as a single parameter, as multiple discrete regimes on the phylogenetic tree, and/or with continuous covariates. See also Hansen (1997) <doi:10.2307/2411186>, Butler & King (2004) <doi:10.1086/426002>, Hansen et al. (2008) <doi:10.1111/j.1558-5646.2008.00412.x>.",2020-02-21,Bjørn Tore Kopperud,http://github.com/kopperud/slouch,TRUE,https://github.com/kopperud/slouch,12042,1,2021-08-17T13:07:06Z,12042
slurmR,"'Slurm', Simple Linux Utility for Resource Management
          <https://slurm.schedmd.com/>, is a popular 'Linux' based software used to 
          schedule jobs in 'HPC' (High Performance Computing) clusters. This R package
          provides a specialized lightweight wrapper of 'Slurm' with a syntax similar to
          that found in the 'parallel' R package. The package also includes a method for
          creating socket cluster objects spanning multiple nodes that can be used with
          the 'parallel' package.",2022-06-22,George Vega Yon,"https://github.com/USCbiostats/slurmR, https://slurm.schedmd.com/",TRUE,https://github.com/uscbiostats/slurmr,18199,43,2022-06-21T20:51:43Z,423.2325581395349
smaa,"Implementation of the Stochastic Multi-Criteria Acceptability Analysis (SMAA) family of Multiple Criteria Decision Analysis (MCDA) methods. Tervonen, T. and Figueira,  J. R. (2008) <doi:10.1002/mcda.407>.",2022-05-30,Gert van Valkenhoef,https://github.com/gertvv/rsmaa,TRUE,https://github.com/gertvv/rsmaa,17958,7,2022-05-27T17:54:47Z,2565.4285714285716
SmallCountRounding,"A statistical disclosure control tool to protect frequency tables in cases where small values are sensitive. The function PLSrounding() performs small count rounding of necessary inner cells so that all small frequencies of cross-classifications to be published (publishable cells) are rounded. This is equivalent to changing micro data since frequencies of unique combinations are changed. Thus, additivity and consistency are guaranteed. The methodology is described in Langsrud and Heldal (2018) <https://www.researchgate.net/publication/327768398_An_Algorithm_for_Small_Count_Rounding_of_Tabular_Data>.",2021-09-29,Øyvind Langsrud,https://github.com/statisticsnorway/SmallCountRounding,TRUE,https://github.com/statisticsnorway/smallcountrounding,15215,2,2021-09-29T12:02:15Z,7607.5
smam,"Animal movement models including moving-resting process
    with embedded Brownian motion according to
    Yan et al. (2014) <doi:10.1007/s10144-013-0428-8>,
    Pozdnyakov et al. (2017) <doi:10.1007/s11009-017-9547-6>,
    Brownian motion with measurement error according to
    Pozdnyakov et al. (2014) <doi:10.1890/13-0532.1>,
    and moving-resting-handling process with embedded Brownian motion,
    Pozdnyakov et al. (2018) <arXiv:1806.00849>.",2021-07-11,Chaoran Hu,https://github.com/ChaoranHu/smam,TRUE,https://github.com/chaoranhu/smam,18746,2,2021-12-16T20:34:14Z,9373
smapr,"
    Facilitates programmatic access to NASA Soil Moisture Active
    Passive (SMAP) data with R. It includes functions to search for, acquire,
    and extract SMAP data.",2019-04-22,Maxwell Joseph,https://github.com/ropensci/smapr,TRUE,https://github.com/ropensci/smapr,16222,65,2022-01-26T15:50:03Z,249.56923076923076
smcfcs,"Implements multiple imputation of missing covariates by
    Substantive Model Compatible Fully Conditional Specification.
    This is a modification of the popular FCS/chained equations
    multiple imputation approach, and allows imputation of missing
    covariate values from models which are compatible with the user
    specified substantive model.",2022-06-22,Jonathan Bartlett,https://github.com/jwb133/smcfcs,TRUE,https://github.com/jwb133/smcfcs,63192,7,2022-06-22T09:19:00Z,9027.42857142857
smerc,"Implements statistical methods for analyzing the counts of areal data,
    with a focus on the detection of spatial clusters and clustering.  The package
    has a heavy emphasis on spatial scan methods, which were first introduced
    by Kulldorff and Nagarwalla (1995) <doi:10.1002/sim.4780140809> and
    Kulldorff (1997) <doi:10.1080/03610929708831995>.",2022-01-31,Joshua French,NA,TRUE,https://github.com/jfrench/smerc,24620,3,2022-01-28T18:32:54Z,8206.666666666666
smile,"Provides functions to estimate, predict and interpolate areal
        data. For estimation and prediction we assume areal data is an average
        of an underlying continuous spatial process as in Moraga et
        al. (2017) <doi:10.1016/j.spasta.2017.04.006>, Johnson et al. (2020)
        <doi:10.1186/s12942-020-00200-w>, and Wilson and Wakefield (2020)
        <doi:10.1093/biostatistics/kxy041>. The interpolation methodology is
        (mostly) based on Goodchild and Lam (1980, ISSN:01652273).",2022-04-29,Lucas da Cunha Godoy,"https://lcgodoy.me/smile/, https://github.com/lcgodoy/smile/",TRUE,https://github.com/lcgodoy/smile,562,3,2022-07-04T19:03:50Z,187.33333333333334
SMMT,"In Switzerland, the landscape of municipalities is changing rapidly
  mainly due to mergers. The Swiss Municipal Data Merger Tool 
  automatically detects these mutations and maps municipalities over time, i.e. municipalities of an old state
  to municipalities of a new state. This functionality is helpful when working 
  with datasets that are based on different spatial references. The package's idea and use 
  case is discussed in the following article: <https://onlinelibrary.wiley.com/doi/full/10.1111/spsr.12487>.",2022-04-03,Valentin Knechtl,https://github.com/ValValetl/SMMT,TRUE,https://github.com/valvaletl/smmt,8914,3,2022-04-05T08:30:55Z,2971.3333333333335
smoof,"Provides generators for a high number of both single- and multi-
    objective test functions which are frequently used for the benchmarking of
    (numerical) optimization algorithms. Moreover, it offers a set of convenient
    functions to generate, plot and work with objective functions.",2020-02-18,Jakob Bossek,https://github.com/jakobbossek/smoof,TRUE,https://github.com/jakobbossek/smoof,164890,31,2022-06-02T13:16:56Z,5319.032258064516
smooth,"Functions implementing Single Source of Error state space models for purposes of time series analysis and forecasting.
             The package includes ADAM (Svetunkov, 2021, <https://openforecast.org/adam/>),
             Exponential Smoothing (Hyndman et al., 2008, <doi: 10.1007/978-3-540-71918-2>),
             SARIMA (Svetunkov & Boylan, 2019 <doi: 10.1080/00207543.2019.1600764>),
             Complex Exponential Smoothing (Svetunkov & Kourentzes, 2018, <doi: 10.13140/RG.2.2.24986.29123>),
             Simple Moving Average (Svetunkov & Petropoulos, 2018 <doi: 10.1080/00207543.2017.1380326>)
             and several simulation functions. It also allows dealing with intermittent demand based on the
             iETS framework (Svetunkov & Boylan, 2019, <doi: 10.13140/RG.2.2.35897.06242>).",2022-03-30,"Ivan Svetunkov  (Lecturer at Centre for Marketing Analytics
    and Forecasting",https://github.com/config-i1/smooth,TRUE,https://github.com/config-i1/smooth,499077,77,2022-07-07T15:26:34Z,6481.519480519481
smoothHR,"Provides flexible hazard ratio curves allowing non-linear
  relationships between continuous predictors and survival.
  To better understand the effects that each continuous covariate
  has on the outcome, results are ex pressed in terms of hazard
  ratio curves, taking a specific covariate value as reference.
  Confidence bands for these curves are also derived.",2021-10-07,Artur Araujo,https://github.com/arturstat/smoothHR,TRUE,https://github.com/arturstat/smoothhr,19304,0,2022-04-15T19:55:18Z,NA
smoothic,"Implementation of the SIC epsilon-telescope method, either
    using single or multi-parameter regression. This package contains the data
    analyses from O'Neill and Burke (2021). ""Variable Selection Using a Smooth
    Information Criterion for Multi-Parameter Regression Models"". <arXiv:2110.02643>.",2021-10-27,Meadhbh ONeill,https://github.com/meadhbh-oneill/smoothic,TRUE,https://github.com/meadhbh-oneill/smoothic,3110,0,2022-06-27T13:27:31Z,NA
smovie,"Provides movies to help students to understand statistical 
  concepts.  The 'rpanel' package  <https://cran.r-project.org/package=rpanel> 
  is used to create interactive plots that move to illustrate key statistical 
  ideas and methods.  There are movies to: visualise probability distributions
  (including user-supplied ones); illustrate sampling distributions of the
  sample mean (central limit theorem), the median, the sample maximum 
  (extremal types theorem) and (the Fisher transformation of the) 
  product moment correlation coefficient; examine the influence of an 
  individual observation in simple linear regression; illustrate key concepts 
  in statistical hypothesis testing. Also provided are dpqr functions for the 
  distribution of the Fisher transformation of the correlation coefficient 
  under sampling from a bivariate normal distribution.",2021-10-31,Paul J. Northrop,"https://paulnorthrop.github.io/smovie/,
https://github.com/paulnorthrop/smovie/",TRUE,https://github.com/paulnorthrop/smovie,11981,0,2022-04-11T21:52:30Z,NA
SMR,"Computes the studentized midrange distribution (pdf, cdf and quantile) and generates random numbers.",2022-05-08,Ben Deivide,"https://bendeivide.github.io/SMR/,
https://github.com/bendeivide/SMR",TRUE,https://github.com/bendeivide/smr,20367,0,2022-05-17T20:09:28Z,NA
snahelper,"'RStudio' addin which provides a GUI to visualize and analyse networks. 
    After finishing a session, the code to produce the plot is inserted in the current script.
    Alternatively, the function SNAhelperGadget() can be used directly from the console.
    Additional addins include the Netreader() for reading network files, Netbuilder() to create
    small networks via point and click, and the Componentlayouter() to layout networks with many components manually.",2021-12-17,David Schoch,https://github.com/schochastics/snahelper,TRUE,https://github.com/schochastics/snahelper,16053,75,2021-12-17T13:36:01Z,214.04
snotelr,"Programmatic interface to the 'SNOTEL' snow data
  (<https://www.wcc.nrcs.usda.gov/snow/>). Provides easy downloads of snow 
  data into your R work space or a local directory. Additional post-processing 
  routines to extract snow season indexes are provided.",2020-05-08,Koen Hufkens,https://github.com/khufkens/snotelr,TRUE,https://github.com/khufkens/snotelr,8442,7,2021-11-21T09:21:56Z,1206
SNPassoc,"Functions to perform most of the common analysis in genome association studies are implemented. These analyses include descriptive statistics and exploratory analysis of missing values, calculation of Hardy-Weinberg equilibrium, analysis of association based on generalized linear models (either for quantitative or binary traits), and analysis of multiple SNPs (haplotype and epistasis analysis). Permutation test and related tests (sum statistic and truncated product) are also implemented. Max-statistic and genetic risk-allele score exact distributions are also possible to be estimated. The methods are described in Gonzalez JR et al., 2007 <doi: 10.1093/bioinformatics/btm025>.",2021-12-03,Juan R Gonzalez,https://github.com/isglobal-brge/SNPassoc,TRUE,https://github.com/isglobal-brge/snpassoc,54634,4,2021-11-30T11:01:09Z,13658.5
snpEnrichment,Implements classes and methods for large scale SNP enrichment analysis (e.g. SNPs associated with genes expression in a GWAS signal).,2015-10-01,Mickael Canouil,https://github.com/mcanouil/snpEnrichment,TRUE,https://github.com/mcanouil/snpenrichment,14947,2,2021-09-16T17:52:44Z,7473.5
snpsettest,"The goal of 'snpsettest' is to provide simple tools that perform
             set-based association tests (e.g., gene-based association tests)
             using GWAS (genome-wide association study) summary statistics. A
             set-based association test in this package is based on the
             statistical model described in VEGAS (versatile gene-based
             association study), which combines the effects of a set of SNPs
             accounting for linkage disequilibrium between markers. This package
             uses a different approach from the original VEGAS implementation to
             compute set-level p values more efficiently, as described in
             <https://github.com/HimesGroup/snpsettest/wiki/Statistical-test-in-snpsettest>.",2022-01-18,Jaehyun Joo,https://github.com/HimesGroup/snpsettest,TRUE,https://github.com/himesgroup/snpsettest,4841,2,2022-01-20T01:40:18Z,2420.5
SOAs,"Creates stratum orthogonal arrays (also known as strong orthogonal arrays). These are arrays with more levels per column than the typical orthogonal array, and whose low order projections behave like orthogonal arrays, when collapsing levels to coarser strata. Details are described in Groemping (2022) ""A unifying implementation of stratum (aka strong) orthogonal arrays"" <http://www1.bht-berlin.de/FB_II/reports/Report-2022-002.pdf>.",2022-06-06,Ulrike Groemping,https://github.com/bertcarnell/SOAs,TRUE,https://github.com/bertcarnell/soas,1663,0,2022-06-04T09:13:40Z,NA
soc.ca,"Specific and class specific multiple correspondence analysis on
    survey-like data. Soc.ca is optimized to the needs of the social scientist and
    presents easily interpretable results in near publication ready quality.",2021-09-02,"Anton Grau Larsen and Jacob Lunding with contributions from Christoph Ellersgaard and
    Stefan Andrade",https://github.com/Rsoc/soc.ca,TRUE,https://github.com/rsoc/soc.ca,18614,12,2022-06-17T07:47:21Z,1551.1666666666667
socialrisk,"Social risks are increasingly becoming a critical component of health
    care research. One of the most common ways to identify social needs is by using
    ICD-10-CM ""Z-codes."" This package identifies social risks using varying taxonomies
    of ICD-10-CM Z-codes from administrative health care data. The conceptual
    taxonomies come from:
    Centers for Medicare and Medicaid Services (2021) <https://www.cms.gov/files/document/zcodes-infographic.pdf>,
    Reidhead (2018) <https://www.mhanet.com/mhaimages/Policy_Briefs/PolicyBrief_SDOH.pdf>,
    A Arons, S DeSilvey, C Fichtenberg, L Gottlieb (2018) <https://sirenetwork.ucsf.edu/tools-resources/resources/compendium-medical-terminology-codes-social-risk-factors>.",2022-03-11,Wyatt Bensken,https://github.com/WYATTBENSKEN/multimorbidity,TRUE,https://github.com/wyattbensken/multimorbidity,951,1,2022-03-23T17:02:37Z,951
sociome,"Accesses raw data via API and calculates social
    determinants of health measures for user-specified locations in the
    US, returning them in tidyverse- and sf-compatible data frames.",2021-10-21,Nik Krieger,NA,TRUE,https://github.com/nikkrieger/sociome,15703,15,2021-10-20T20:18:32Z,1046.8666666666666
sodium,"Bindings to 'libsodium' <https://doc.libsodium.org/>: a modern, 
    easy-to-use software library for encryption, decryption, signatures, password
    hashing and more. Sodium uses curve25519, a state-of-the-art Diffie-Hellman 
    function by Daniel Bernstein, which has become very popular after it was 
    discovered that the NSA had backdoored Dual EC DRBG.",2022-06-11,Jeroen Ooms,https://docs.ropensci.org/sodium/ https://github.com/r-lib/sodium,TRUE,https://github.com/r-lib/sodium,1024692,60,2022-06-16T11:53:47Z,17078.2
soilDB,A collection of functions for reading data from USDA-NCSS soil databases.,2022-06-27,Andrew Brown,"http://ncss-tech.github.io/soilDB/,
http://ncss-tech.github.io/AQP/",TRUE,https://github.com/ncss-tech/soildb,38164,55,2022-07-08T16:40:09Z,693.8909090909091
SoilTaxonomy,"Taxonomic dictionaries, formative element lists, and functions related to the maintenance, development and application of U.S. Soil Taxonomy. 
   Data and functionality are based on official U.S. Department of Agriculture sources including the latest edition of the Keys to Soil Taxonomy. Descriptions and metadata are obtained from the National Soil Information System or Soil Survey Geographic databases. Other sources are referenced in the data documentation. 
   Provides tools for understanding and interacting with concepts in the U.S. Soil Taxonomic System. Most of the current utilities are for working with taxonomic concepts at the ""higher"" taxonomic levels: Order, Suborder, Great Group, and Subgroup.",2021-08-05,Andrew Brown,https://github.com/ncss-tech/SoilTaxonomy,TRUE,https://github.com/ncss-tech/soiltaxonomy,6226,5,2022-07-08T23:23:33Z,1245.2
soiltestcorr,"A compilation of functions designed to assist users on the correlation analysis of crop yield and soil test values. Functions to estimate crop response patterns to soil nutrient availability and critical soil test values using various approaches such as: 1) the modified arcsine-log calibration curve (Correndo et al. (2017) <doi:10.1071/CP16444>); 2) the graphical Cate-Nelson quadrants analysis (Cate & Nelson (1965)), 3) the statistical Cate-Nelson quadrants analysis (Cate & Nelson (1971) <doi:10.2136/sssaj1971.03615995003500040048x>), 4) the linear-plateau regression (Anderson & Nelson (1975) <doi:10.2307/2529422>), 5) the quadratic-plateau regression (Bullock & Bullock (1994) <doi:10.2134/agronj1994.00021962008600010033x>), and 6) the Mitscherlich-type exponential regression (Melsted & Peck (1977) <doi:10.2134/asaspecpub29.c1>). The package development stemmed from ongoing work with the Fertilizer Recommendation Support Tool (FRST) and Feed the Future Innovation Lab for Collaborative Research on Sustainable Intensification (SIIL) projects. ",2022-06-12,Adrian A. Correndo,https://adriancorrendo.github.io/soiltestcorr/,TRUE,https://github.com/adriancorrendo/soiltestcorr,577,5,2022-06-13T00:34:57Z,115.4
solaR,Calculation methods of solar radiation and performance of photovoltaic systems from daily and intradaily irradiation data sources.,2021-10-19,Oscar Perpiñán Lamigueiro,https://oscarperpinan.github.io/solar/,TRUE,https://github.com/oscarperpinan/solar,49888,32,2021-10-18T22:50:16Z,1559
solartime,"Provide utilities to work with solar time, 
  i.e. where noon is exactly when sun culminates.
  Provides functions for computing sun position and times of sunrise and sunset.",2021-04-22,Thomas Wutzler,https://github.com/bgctw/solartime,TRUE,https://github.com/bgctw/solartime,19053,7,2021-09-02T09:40:14Z,2721.8571428571427
solitude,"Isolation forest is anomaly detection method introduced by the paper Isolation based Anomaly Detection (Liu, Ting and Zhou <doi:10.1145/2133360.2133363>).",2021-07-29,Komala Sheshachala Srikanth,https://github.com/talegari/solitude,TRUE,https://github.com/talegari/solitude,56000,22,2021-07-29T19:12:18Z,2545.4545454545455
solvebio,"R language bindings for SolveBio's API.
    SolveBio is a biomedical knowledge hub that enables life science
    organizations to collect and harmonize the complex, disparate
    ""multi-omic"" data essential for today's R&D and BI needs.
    For more information, visit <https://www.solvebio.com>.",2022-05-17,David Caplan,https://github.com/solvebio/solvebio-r,TRUE,https://github.com/solvebio/solvebio-r,22976,3,2022-05-17T15:00:39Z,7658.666666666667
soma,"An R implementation of the Self-Organising Migrating Algorithm, a general-purpose, stochastic optimisation algorithm. The approach is similar to that of genetic algorithms, although it is based on the idea of a series of ``migrations'' by a fixed set of individuals, rather than the development of successive generations. It can be applied to any cost-minimisation problem with a bounded parameter space, and is robust to local minima.",2022-05-02,Jon Clayden,https://github.com/jonclayden/soma/,TRUE,https://github.com/jonclayden/soma,53077,7,2022-05-01T23:09:36Z,7582.428571428572
SOMbrero,"The stochastic (also called on-line) version of the Self-Organising
             Map (SOM) algorithm is provided. Different versions of the
             algorithm are implemented, for numeric and relational data and for
             contingency tables as described, respectively, in Kohonen (2001)
             <isbn:3-540-67921-9>, Olteanu & Villa-Vialaneix (2005)
             <doi:10.1016/j.neucom.2013.11.047> and Cottrell et al (2004)
             <doi:10.1016/j.neunet.2004.07.010>. The package also contains many
             plotting features (to help the user interpret the results), can 
             handle (and impute) missing values and is delivered with a 
             graphical user interface based on 'shiny'.",2022-01-03,Nathalie Vialaneix,NA,TRUE,https://github.com/tuxette/sombrero,20968,16,2022-01-03T20:42:51Z,1310.5
sortable,"Enables drag-and-drop behaviour in Shiny apps, by exposing the 
    functionality of the 'SortableJS' <https://sortablejs.github.io/Sortable/> 
    JavaScript library as an 'htmlwidget'. 
    You can use this in Shiny apps and widgets, 'learnr' tutorials as well as 
    R Markdown. In addition, provides a custom 'learnr' question type - 
    'question_rank()' - that allows ranking questions with drag-and-drop.",2021-12-13,Andrie de Vries,https://rstudio.github.io/sortable/,TRUE,https://github.com/rstudio/sortable,37295,112,2021-12-13T09:39:40Z,332.99107142857144
SortedEffects,"Implements the estimation and inference methods for sorted causal effects and 
    classification analysis as in Chernozhukov, Fernandez-Val and Luo (2018) <doi:10.3982/ECTA14415>.",2022-03-22,Shuowen Chen,https://github.com/shuowencs/SortedEffects,TRUE,https://github.com/shuowencs/sortedeffects,14261,2,2021-10-02T02:00:20Z,7130.5
sorvi,Misc support functions for rOpenGov and open data downloads.,2022-05-30,Leo Lahti,"https://github.com/ropengov/sorvi,
https://CRAN.R-project.org/package=sorvi,
https://ropengov.github.io/sorvi/",TRUE,https://github.com/ropengov/sorvi,17193,12,2022-05-31T12:05:25Z,1432.75
sotkanet,"Access statistical information on welfare and health in Finland 
    from the Sotkanet open data portal <https://sotkanet.fi/sotkanet/fi/index>.",2022-02-01,Leo Lahti,https://ropengov.github.io/sotkanet/,TRUE,https://github.com/ropengov/sotkanet,16106,5,2022-03-16T15:50:44Z,3221.2
soundClass,"Provides an all-in-one solution for automatic classification of 
    sound events using convolutional neural networks (CNN). The main purpose 
    is to provide a sound classification workflow, from annotating sound events
    in recordings to training and automating model usage in real-life
    situations. Using the package requires a pre-compiled collection of 
    recordings with sound events of interest and it can be employed for: 
    1) Annotation: create a database of annotated recordings, 
    2) Training: prepare train data from annotated recordings and fit CNN models, 
    3) Classification: automate the use of the fitted model for classifying 
    new recordings. By using automatic feature selection and a user-friendly GUI
    for managing data and training/deploying models, this package is intended 
    to be used by a broad audience as it does not require specific expertise in 
    statistics, programming or sound analysis. Please refer to the vignette for
    further information.
    Gibb, R., et al. (2019) <doi:10.1111/2041-210X.13101>
    Mac Aodha, O., et al. (2018) <doi:10.1371/journal.pcbi.1005995>
    Stowell, D., et al. (2019) <doi:10.1111/2041-210X.13103>
    LeCun, Y., et al. (2012) <doi:10.1007/978-3-642-35289-8_3>.",2022-05-29,Bruno Silva,NA,TRUE,https://github.com/bmsasilva/soundclass,1696,0,2022-06-21T11:14:16Z,NA
soundgen,"Performs parametric synthesis of sounds with harmonic and noise 
    components such as animal vocalizations or human voice. Also offers tools 
    for audio manipulation and acoustic analysis, including pitch tracking, 
    spectral analysis, audio segmentation, pitch and formant shifting, etc. 
    Includes four interactive web apps for synthesizing and annotating audio, 
    manually correcting pitch contours, and measuring formant frequencies. 
    Reference: Anikin (2019) <doi:10.3758/s13428-018-1095-7>.",2022-02-10,Andrey Anikin,http://cogsci.se/soundgen.html,TRUE,https://github.com/tatters/soundgen,27133,22,2022-06-17T08:42:56Z,1233.3181818181818
SoundShape,"Implement a promising, and yet little explored protocol for bioacoustical analysis, the eigensound method by MacLeod, Krieger and Jones (2013) <doi:10.4404/hystrix-24.1-6299>. Eigensound is a multidisciplinary method focused on the direct comparison between stereotyped sounds from different species. 'SoundShape', in turn, provide the tools required for anyone to go from sound waves to Principal Components Analysis, using tools extracted from traditional bioacoustics (i.e. 'tuneR' and 'seewave' packages), geometric morphometrics (i.e. 'geomorph' package) and multivariate analysis (e.g. 'stats' package). For more information, please see Rocha and Romano (2021) and check 'SoundShape' repository on GitHub for news and updates <https://github.com/p-rocha/SoundShape>.",2022-05-19,Pedro Rocha,https://github.com/p-rocha/SoundShape,TRUE,https://github.com/p-rocha/soundshape,13640,7,2022-04-04T22:48:40Z,1948.5714285714287
SoupX,"Quantify, profile and remove ambient mRNA contamination (the ""soup"") from droplet based single cell RNA-seq experiments.  Implements the method described in Young et al. (2018) <doi:10.1101/303727>.",2022-05-26,Matthew Daniel Young,https://github.com/constantAmateur/SoupX,TRUE,https://github.com/constantamateur/soupx,16822,142,2022-05-26T09:24:47Z,118.46478873239437
sovereign,"A set of tools for state-dependent 
  empirical analysis through both VAR- and local projection-based 
  state-dependent forecasts, impulse response functions, 
  historical decompositions, and forecast error variance decompositions.   ",2022-01-04,Tyler J. Pike,"https://github.com/tylerJPike/sovereign,
https://tylerjpike.github.io/sovereign/",TRUE,https://github.com/tylerjpike/sovereign,5684,2,2022-04-18T01:39:16Z,2842
SoyURT,"Data sets used by 'Krause et al. (2022)'  <doi:10.1101/2022.04.11.487885>. It comprises phenotypic records obtained from the USDA Northern Region Uniform Soybean Tests from 1989 to 2019 for maturity groups II and III. In addition, soil and weather variables are provided for the 591 observed environments (combination of locations and years).",2022-06-13,Matheus Dalsente Krause,https://github.com/mdkrause/soyurt,TRUE,https://github.com/mdkrause/soyurt,226,0,2022-06-10T14:41:46Z,NA
sp,"Classes and methods for spatial
  data; the classes document where the spatial location information
  resides, for 2D or 3D data. Utility functions are provided, e.g. for
  plotting data as maps, spatial selection, as well as methods for
  retrieving coordinates, for subsetting, print, summary, etc.",2022-06-05,Edzer Pebesma,https://github.com/edzer/sp/ https://edzer.github.io/sp/,TRUE,https://github.com/edzer/sp,12366838,108,2022-06-15T20:09:22Z,114507.75925925926
spaa,"Miscellaneous functions for analysing species association
        and niche overlap.",2016-06-09,Jinlong Zhang,https://github.com/helixcn/spaa,TRUE,https://github.com/helixcn/spaa,25885,10,2021-08-12T03:42:24Z,2588.5
spacefillr,"Generates random and quasi-random space-filling sequences. Supports the following sequences: 'Halton', 'Sobol', 'Owen'-scrambled 'Sobol',  'Owen'-scrambled 'Sobol' with errors distributed as blue noise, progressive jittered, progressive multi-jittered ('PMJ'), 'PMJ' with blue noise, 'PMJ02', and 'PMJ02' with blue noise. Includes a 'C++' 'API'. Methods derived from ""Constructing Sobol sequences with better two-dimensional projections"" (2012) <doi:10.1137/070709359> S. Joe and F. Y. Kuo, ""Progressive Multi-Jittered Sample Sequences"" (2018) <https://graphics.pixar.com/library/ProgressiveMultiJitteredSampling/paper.pdf> Christensen, P., Kensler, A. and Kilpatrick, C., and ""A Low-Discrepancy Sampler that Distributes Monte Carlo Errors as a Blue Noise in Screen Space"" (2019) E. Heitz, B. Laurent, O. Victor, C. David and I. Jean-Claude, <doi:10.1145/3306307.3328191>. ",2022-03-02,Tyler Morgan-Wall,https://github.com/tylermorganwall/spacefillr,TRUE,https://github.com/tylermorganwall/spacefillr,27622,4,2022-03-02T02:49:11Z,6905.5
spacejamr,"Social network analysis is becoming commonplace in many social 
    science disciplines, but access to useful network data, especially 
    among marginalized populations, still remains a formidable challenge. 
    This package mitigates that problem by providing tools to simulate spatial 
    Bernoulli networks as proposed in Carter T. Butts 
    (2002, ISBN:978-0-493-72676-2), ""Spatial models of large-scale interpersonal            
    networks."" Using this package, network analysts can simulate a spatial point 
    process or sequence with a given number of nodes inside a geographical 
    boundary and estimate the probability of a tie formation between all node 
    pairs. When simulating a network, an analyst can choose between five spatial
    interaction functions. The package also enables quick comparison of summary             
    statistics for simulated networks and provides simple to use plotting 
    methods for its classes that return plots which can be further refined with 
    the 'ggplot2' package.",2022-04-01,Darren Colby,https://github.com/dscolby/spacejamr,TRUE,https://github.com/dscolby/spacejamr,3212,1,2022-04-01T19:37:03Z,3212
spacetime,"Classes and methods for spatio-temporal data, including space-time regular lattices, sparse lattices, irregular data, and trajectories; utility functions for plotting data as map sequences (lattice or animation) or multiple time series; methods for spatial and temporal selection and subsetting, as well as for spatial/temporal/spatio-temporal matching or aggregation, retrieving coordinates, print, summary, etc.",2022-06-17,Edzer Pebesma,https://github.com/edzer/spacetime,TRUE,https://github.com/edzer/spacetime,556634,60,2022-06-15T10:11:40Z,9277.233333333334
spacyr,"An R wrapper to the 'Python' 'spaCy' 'NLP' library,
    from <http://spacy.io>.",2020-03-04,Kenneth Benoit,https://spacyr.quanteda.io,TRUE,https://github.com/quanteda/spacyr,115030,216,2022-01-21T11:02:54Z,532.5462962962963
SpaDES,"Metapackage for implementing a variety of event-based models, with
    a focus on spatially explicit models. These include raster-based,
    event-based, and agent-based models. The core simulation components
    (provided by 'SpaDES.core') are built upon a discrete event simulation (DES;
    see Matloff (2011) ch 7.8.3 <https://nostarch.com/artofr.htm>)
    framework that facilitates modularity, and easily enables the user to
    include additional functionality by running user-built simulation modules
    (see also 'SpaDES.tools'). Included are numerous tools to visualize rasters
    and other maps (via 'quickPlot'), and caching methods for reproducible
    simulations (via 'reproducible'). Tools for running simulation experiments are
    provided by 'SpaDES.experiment'. Additional functionality is provided by
    the 'SpaDES.addins' and 'SpaDES.shiny' packages.",2022-02-17,Alex M Chubaty,"https://spades.predictiveecology.org,
https://github.com/PredictiveEcology/SpaDES",TRUE,https://github.com/predictiveecology/spades,22596,44,2022-05-30T15:47:13Z,513.5454545454545
SpaDES.core,"Provides the core framework for a discrete event system (DES) to 
    implement a complete data-to-decisions, reproducible workflow.
    The core DES components facilitate modularity, and easily enable the user
    to include additional functionality by running user-built modules.
    Includes conditional scheduling, restart after interruption, packaging of
    reusable modules, tools for developing arbitrary automated workflows,
    automated interweaving of modules of different temporal resolution,
    and tools for visualizing and understanding the DES project.",2022-01-19,Alex M Chubaty,"https://spades-core.predictiveecology.org/,
https://github.com/PredictiveEcology/SpaDES.core",TRUE,https://github.com/predictiveecology/spades.core,31077,8,2022-01-19T15:39:46Z,3884.625
SpaDES.tools,"Provides GIS and map utilities, plus additional modeling tools for
    developing cellular automata, dynamic raster models, and agent based models
    in 'SpaDES'.
    Included are various methods for spatial spreading, spatial agents, GIS
    operations, random map generation, and others.
    See '?SpaDES.tools' for an categorized overview of these additional tools.",2022-02-03,Alex M Chubaty,"https://spades-tools.predictiveecology.org,
https://github.com/PredictiveEcology/SpaDES.tools",TRUE,https://github.com/predictiveecology/spades.tools,28707,3,2022-02-02T18:12:38Z,9569
spant,"Tools for reading, visualising and processing Magnetic Resonance
    Spectroscopy data. The package includes methods for spectral fitting: Wilson
    (2021) <DOI:10.1002/mrm.28385> and spectral alignment: Wilson (2018)
    <DOI:10.1002/mrm.27605>. ",2022-06-22,Martin Wilson,"https://martin3141.github.io/spant/,
https://github.com/martin3141/spant/",TRUE,https://github.com/martin3141/spant,29245,15,2022-06-22T08:53:14Z,1949.6666666666667
sparkbq,"A 'sparklyr' extension package providing an integration with Google 'BigQuery'.
  It supports direct import/export where records are directly streamed from/to 'BigQuery'.
  In addition, data may be imported/exported via intermediate data extracts on Google 'Cloud Storage'.",2019-12-18,Martin Studer,"http://www.mirai-solutions.com,
https://github.com/miraisolutions/sparkbq",TRUE,https://github.com/miraisolutions/sparkbq,15064,16,2022-01-25T10:34:03Z,941.5
sparklyr,"R interface to Apache Spark, a fast and general
    engine for big data processing, see <https://spark.apache.org/>. This
    package supports connecting to local and remote Apache Spark clusters,
    provides a 'dplyr' compatible back-end, and provides an interface to
    Spark's built-in machine learning algorithms.",2022-06-07,Edgar Ruiz,https://spark.rstudio.com/,TRUE,https://github.com/sparklyr/sparklyr,7361811,872,2022-07-08T20:50:31Z,8442.44380733945
sparklyr.flint,"This sparklyr extension makes 'Flint' time series
    library functionalities (<https://github.com/twosigma/flint>) easily
    accessible through R.",2022-01-11,Yitao Li,<https://github.com/r-spark/sparklyr.flint>,TRUE,https://github.com/r-spark/sparklyr.flint,14176,8,2022-01-11T18:31:30Z,1772
sparklyr.nested,A 'sparklyr' extension adding the capability to work easily with nested data.,2018-11-14,Matt Pollock,NA,TRUE,https://github.com/mitre/sparklyr.nested,267509,27,2022-05-19T10:22:21Z,9907.74074074074
sparkwarc,"Load WARC (Web ARChive) files into Apache Spark using 'sparklyr'. This
    allows to read files from the Common Crawl project <http://commoncrawl.org/>.",2022-01-11,Yitao Li,NA,TRUE,https://github.com/r-spark/sparkwarc,14295,13,2022-01-11T18:32:30Z,1099.6153846153845
sparr,"Provides functions to estimate kernel-smoothed spatial and spatio-temporal densities and relative risk functions, and perform subsequent inference. Methodological details can be found in the accompanying tutorial: Davies et al. (2018) <DOI:10.1002/sim.7577>.",2022-02-20,Tilman M. Davies,"https://tilmandavies.github.io/sparr/,
https://github.com/tilmandavies/sparr/",TRUE,https://github.com/tilmandavies/sparr,35600,3,2022-02-21T00:09:40Z,11866.666666666666
sparrpowR,"Calculate the statistical power to detect clusters using kernel-based 
        spatial relative risk functions that are estimated using the 'sparr' package.
        Details about the 'sparr' package methods can be found in the tutorial: Davies
        et al. (2018) <doi:10.1002/sim.7577>.  Details about kernel density estimation 
        can be found in J. F. Bithell (1990) <doi:10.1002/sim.4780090616>.  More 
        information about relative risk functions using kernel density estimation can 
        be found in J. F. Bithell (1991) <doi:10.1002/sim.4780101112>.",2022-02-05,Ian D. Buller,https://github.com/machiela-lab/sparrpowR,TRUE,https://github.com/machiela-lab/sparrpowr,9490,2,2022-02-04T15:36:44Z,4745
sparsegl,"Efficient implementation of sparse group lasso with optional bound 
  constraints on the coefficients. It supports the use of a sparse design matrix 
  as well as 
  returning coefficient estimates in a sparse matrix. Furthermore, it correctly
  calculates the degrees of freedom to allow for information criteria rather
  than cross-validation with very large data. Finally, the interface to 
  compiled code avoids unnecessary copies and allows for the use of
  long integers.",2022-03-07,Daniel J. McDonald,https://github.com/dajmcdon/sparsegl/,TRUE,https://github.com/dajmcdon/sparsegl,969,2,2022-04-27T17:29:39Z,484.5
sparseHessianFD,"Estimates Hessian of a scalar-valued function, and returns it
    in a sparse Matrix format. The sparsity pattern must be known in advance. The
    algorithm is especially efficient for hierarchical models with a large number of
    heterogeneous units.  See Braun, M. (2017) <doi:10.18637/jss.v082.i10>.",2021-09-24,Michael Braun,"https://braunm.github.io/sparseHessianFD/,
https://github.com/braunm/sparseHessianFD/",TRUE,https://github.com/braunm/sparsehessianfd,16320,0,2021-09-24T00:01:54Z,NA
sparseMVN,"Computes multivariate normal (MVN) densities, and
    samples from MVN distributions, when the covariance or
    precision matrix is sparse.",2021-10-25,Michael Braun,"https://braunm.github.io/sparseMVN/,
https://github.com/braunm/sparseMVN/",TRUE,https://github.com/braunm/sparsemvn,20329,2,2021-12-31T17:54:23Z,10164.5
sparsepp,"Provides interface to 'sparsepp' - fast, memory efficient hash map. 
    It is derived from Google's excellent 'sparsehash' implementation.
    We believe 'sparsepp' provides an unparalleled combination of performance and memory usage, 
    and will outperform your compiler's unordered_map on both counts. 
    Only Google's 'dense_hash_map' is consistently faster, at the cost of much greater 
    memory usage (especially when the final size of the map is not known in advance).",2018-09-22,Dmitriy Selivanov,"https://github.com/greg7mdp/sparsepp,
https://github.com/dselivanov/r-sparsepp",TRUE,https://github.com/greg7mdp/sparsepp,23261,1131,2021-07-21T20:56:47Z,20.566755083996462
SparseVFC,"The sparse vector field consensus 
		(SparseVFC) algorithm (Ma et al., 2013 <doi:10.1016/j.patcog.2013.05.017>) for robust vector 
		field learning. Largely translated from the Matlab functions in <https://github.com/jiayi-ma/VFC>.",2022-05-27,Jingmeng Cui,https://github.com/Sciurus365/SparseVFC,TRUE,https://github.com/sciurus365/sparsevfc,356,0,2022-05-26T17:18:01Z,NA
sparta,Fast Multiplication and Marginalization of Sparse Tables.,2022-04-12,Mads Lindskou,https://github.com/mlindsk/sparta,TRUE,https://github.com/mlindsk/sparta,10859,1,2022-04-11T18:52:18Z,10859
spatgeom,The implementation to perform the geometric spatial point analysis developed in Hernández & Solís (2022) <doi:10.1007/s00180-022-01244-1>. It estimates the geometric goodness-of-fit index for a set of variables against a response one based on the 'sf' package. The package has methods to print and plot the results.,2022-07-03,Maikol Solís,https://github.com/maikol-solis/spatgeom,TRUE,https://github.com/maikol-solis/spatgeom,114,0,2022-07-02T17:39:47Z,NA
spatialEco,"Utilities to support spatial data manipulation, query, sampling
    and modelling. Functions include models for species population density, download
    utilities for climate and global deforestation spatial products, spatial
    smoothing, multivariate separability, point process model for creating pseudo-
    absences and sub-sampling, polygon and point-distance landscape metrics,
    auto-logistic model, sampling models, cluster optimization, statistical
    exploratory tools and raster-based metrics.",2021-05-14,Jeffrey S. Evans,https://github.com/jeffreyevans/spatialEco,TRUE,https://github.com/jeffreyevans/spatialeco,74399,61,2022-04-13T22:57:21Z,1219.655737704918
SpatialEpi,Methods and data for cluster detection and disease mapping.,2021-11-15,Albert Y. Kim,https://github.com/rudeboybert/SpatialEpi,TRUE,https://github.com/rudeboybert/spatialepi,49946,21,2021-11-14T19:57:57Z,2378.3809523809523
SpatialKDE,"Calculate Kernel Density Estimation (KDE) for spatial data. 
  The algorithm is inspired by the tool 'Heatmap' from 'QGIS'. The method is described by:
  Hart, T., Zandbergen, P. (2014) <doi:10.1108/PIJPSM-04-2013-0039>, 
  Nelson, T. A., Boots, B. (2008) <doi:10.1111/j.0906-7590.2008.05548.x>,
  Chainey, S., Tompson, L., Uhlig, S.(2008) <doi:10.1057/palgrave.sj.8350066>.",2022-02-09,Jan Caha,"https://jancaha.github.io/SpatialKDE/index.html,
https://github.com/JanCaha/SpatialKDE",TRUE,https://github.com/jancaha/spatialkde,14785,6,2022-02-09T15:22:47Z,2464.1666666666665
spatialreg,"A collection of all the estimation functions for spatial cross-sectional models (on lattice/areal data using spatial weights matrices) contained up to now in 'spdep', 'sphet' and 'spse'. These model fitting functions include maximum likelihood methods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973, ISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially described by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The models are further described by 'Anselin' (1988) <doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and spatial general method of moment models initially proposed by 'Kelejian' and 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999) <doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC fitting methods proposed by 'LeSage' and 'Pace' (2009) <doi:10.1201/9781420064254> are implemented for the family of cross-sectional spatial regression models. Methods for fitting the log determinant term in maximum likelihood and MCMC fitting are compared by 'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting methods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both of these articles include extensive lists of references. 'spatialreg' >= 1.1-* corresponded to 'spdep' >= 1.1-1, in which the model fitting functions were deprecated and passed through to 'spatialreg', but masked those in 'spatialreg'. From versions 1.2-*, the functions have been made defunct in 'spdep'.",2022-04-18,Roger Bivand,"https://github.com/r-spatial/spatialreg/,
https://r-spatial.github.io/spatialreg/",TRUE,https://github.com/r-spatial/spatialreg,254877,30,2022-04-25T12:28:37Z,8495.9
spatialRF,"Automatic generation and selection of spatial predictors for spatial regression with Random Forest. Spatial predictors are surrogates of variables driving the spatial structure of a response variable. The package offers two methods to generate spatial predictors from a distance matrix among training cases: 1) Moran's Eigenvector Maps (MEMs; Dray, Legendre, and Peres-Neto 2006 <DOI:10.1016/j.ecolmodel.2006.02.015>): computed as the eigenvectors of a weighted matrix of distances; 2) RFsp (Hengl et al. <DOI:10.7717/peerj.5518>): columns of the distance matrix used as spatial predictors. Spatial predictors help minimize the spatial autocorrelation of the model residuals and facilitate an honest assessment of the importance scores of the non-spatial predictors. Additionally, functions to reduce multicollinearity, identify relevant variable interactions, tune random forest hyperparameters, assess model transferability via spatial cross-validation, and explore model results via partial dependence curves and interaction surfaces are included in the package. The modelling functions are built around the highly efficient 'ranger' package (Wright and Ziegler 2017 <DOI:10.18637/jss.v077.i01>).  ",2021-09-23,Blas M. Benito,https://blasbenito.github.io/spatialRF/,TRUE,https://github.com/blasbenito/spatialrf,3676,73,2021-11-08T09:45:08Z,50.35616438356164
spatialrisk,"Methods for spatial risk calculations. It offers an efficient approach to determine the sum of all observations within a 
     circle of a certain radius. This might be beneficial for insurers who are required (by a recent European Commission regulation) to determine 
     the maximum value of insured fire risk policies of all buildings that are partly or fully located within a circle of a radius of 200m. See 
     Church (1974) <doi:10.1007/BF01942293> for a description of the problem.",2021-11-10,Martin Haringa,"https://github.com/mharinga/spatialrisk,
https://mharinga.github.io/spatialrisk/",TRUE,https://github.com/mharinga/spatialrisk,19986,11,2021-12-07T08:44:46Z,1816.909090909091
spatialsample,"Functions and classes for spatial resampling to use with the
    'rsample' package, such as spatial cross-validation (Brenning, 2012)
    <doi:10.1109/IGARSS.2012.6352393>. The scope of 'rsample' and
    'spatialsample' is to provide the basic building blocks for creating
    and analyzing resamples of a spatial data set, but neither package
    includes functions for modeling or computing statistics. The resampled
    spatial data sets created by 'spatialsample' do not contain much
    overhead in memory.",2022-06-17,Julia Silge,"https://github.com/tidymodels/spatialsample,
https://spatialsample.tidymodels.org",TRUE,https://github.com/tidymodels/spatialsample,6449,41,2022-07-08T00:17:29Z,157.29268292682926
spatialTIME,"Visualization and analysis  of Vectra Immunoflourescent
    data. Options for calculating both the univariate and bivariate Ripley's K
    are included. Calculations are performed using a permutation-based 
    approach presented by Wilson et al.  <doi:10.1101/2021.04.27.21256104>. ",2022-06-23,Fridley Lab,https://github.com/FridleyLab/spatialTIME,TRUE,https://github.com/fridleylab/spatialtime,4794,1,2021-11-03T15:04:08Z,4794
spatialwarnings,Tools to compute and assess significance of early-warnings signals (EWS) of ecosystem degradation on raster data sets. EWS are metrics derived from the observed spatial structure of an ecosystem -- e.g. spatial autocorrelation -- that increase before an ecosystem undergoes a non-linear transition (Genin et al. (2018) <doi:10.1111/2041-210X.13058>).,2022-03-21,Alain Danet,https://github.com/spatial-ews/spatialwarnings,TRUE,https://github.com/spatial-ews/spatialwarnings,15909,8,2022-03-20T19:09:56Z,1988.625
spatPomp,"Inference on panel data using spatiotemporal partially-observed Markov process (SpatPOMP) models. To do so, it relies on and extends a number of facilities that the 'pomp' package provides for inference on time series data using partially-observed Markov process (POMP) models. Implemented methods include filtering and inference methods in Park and Ionides (2020) <doi:10.1007/s11222-020-09957-3>, Rebeschini and van Handel (2015) <doi:10.1214/14-AAP1061>, Evensen and van Leeuwen (1996) <doi:10.1029/94JC00572> and Ionides et al. (2021) <arXiv:2002.05211v2>. Pre-print statistical software article: Asfaw et al. (2021) <arXiv:2101.01157>.",2022-01-15,Kidus Asfaw,https://github.com/kidusasfaw/spatPomp,TRUE,https://github.com/kidusasfaw/spatpomp,4808,6,2022-05-25T18:27:17Z,801.3333333333334
spatsoc,"Detects spatial and temporal groups in GPS relocations 
    (Robitaille et al. (2020) <doi:10.1111/2041-210X.13215>). 
    It can be used to convert GPS relocations to 
    gambit-of-the-group format to build proximity-based social networks 
    In addition, the randomizations function provides data-stream 
    randomization methods suitable for GPS data. ",2021-02-24,Alec L. Robitaille,"https://docs.ropensci.org/spatsoc/,
https://github.com/ropensci/spatsoc,
http://spatsoc.robitalec.ca",TRUE,https://github.com/ropensci/spatsoc,15614,24,2021-08-09T00:02:31Z,650.5833333333334
spatstat,"Comprehensive open-source toolbox for analysing Spatial Point Patterns. Focused mainly on two-dimensional point patterns, including multitype/marked points, in any spatial region. Also supports three-dimensional point patterns, space-time point patterns in any number of dimensions, point patterns on a linear network, and patterns of other geometrical objects. Supports spatial covariate data such as pixel images. 
	Contains over 2000 functions for plotting spatial data, exploratory data analysis, model-fitting, simulation, spatial sampling, model diagnostics, and formal inference. 
	Data types include point patterns, line segment patterns, spatial windows, pixel images, tessellations, and linear networks. 
	Exploratory methods include quadrat counts, K-functions and their simulation envelopes, nearest neighbour distance and empty space statistics, Fry plots, pair correlation function, kernel smoothed intensity, relative risk estimation with cross-validated bandwidth selection, mark correlation functions, segregation indices, mark dependence diagnostics, and kernel estimates of covariate effects. Formal hypothesis tests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.
	Parametric models can be fitted to point pattern data using the functions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs and Cox point processes, Neyman-Scott cluster processes, and determinantal point processes. Models may involve dependence on covariates, inter-point interaction, cluster formation and dependence on marks. Models are fitted by maximum likelihood, logistic regression, minimum contrast, and composite likelihood methods. 
	A model can be fitted to a list of point patterns (replicated point pattern data) using the function mppm(). The model can include random effects and fixed effects depending on the experimental design, in addition to all the features listed above.
	Fitted point process models can be simulated, automatically. Formal hypothesis tests of a fitted model are supported (likelihood ratio test, analysis of deviance, Monte Carlo tests) along with basic tools for model selection (stepwise(), AIC()) and variable selection (sdr). Tools for validating the fitted model include simulation envelopes, residuals, residual plots and Q-Q plots, leverage and influence diagnostics, partial residuals, and added variable plots.",2022-04-01,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat,793693,153,2022-07-09T03:18:05Z,5187.535947712418
spatstat.core,"Functionality for data analysis and modelling of
	     spatial data, mainly spatial point patterns,
	     in the 'spatstat' family of packages.
	     (Excludes analysis of spatial data on a linear network,
	     which is covered by the separate package 'spatstat.linnet'.)
	     Exploratory methods include quadrat counts, K-functions and their simulation envelopes, nearest neighbour distance and empty space statistics, Fry plots, pair correlation function, kernel smoothed intensity, relative risk estimation with cross-validated bandwidth selection, mark correlation functions, segregation indices, mark dependence diagnostics, and kernel estimates of covariate effects. Formal hypothesis tests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.
	Parametric models can be fitted to point pattern data using the functions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs and Cox point processes, Neyman-Scott cluster processes, and determinantal point processes. Models may involve dependence on covariates, inter-point interaction, cluster formation and dependence on marks. Models are fitted by maximum likelihood, logistic regression, minimum contrast, and composite likelihood methods. 
	A model can be fitted to a list of point patterns (replicated point pattern data) using the function mppm(). The model can include random effects and fixed effects depending on the experimental design, in addition to all the features listed above.
	Fitted point process models can be simulated, automatically. Formal hypothesis tests of a fitted model are supported (likelihood ratio test, analysis of deviance, Monte Carlo tests) along with basic tools for model selection (stepwise(), AIC()) and variable selection (sdr). Tools for validating the fitted model include simulation envelopes, residuals, residual plots and Q-Q plots, leverage and influence diagnostics, partial residuals, and added variable plots.",2022-05-18,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.core,652116,6,2022-05-24T05:37:16Z,108686
spatstat.data,Contains all the datasets for the 'spatstat' family of packages.,2022-04-18,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.data,871235,5,2022-07-10T09:52:00Z,174247
spatstat.geom,"Defines spatial data types and supports geometrical operations
	     on them. Data types include point patterns, windows (domains),
	     pixel images, line segment patterns, tessellations and hyperframes.
	     Capabilities include creation and manipulation of data
	     (using command line or graphical interaction),
	     plotting, geometrical operations (rotation, shift, rescale,
	     affine transformation), convex hull, discretisation and
	     pixellation, Dirichlet tessellation, Delaunay triangulation,
	     pairwise distances, nearest-neighbour distances,
	     distance transform, morphological operations
	     (erosion, dilation, closing, opening), quadrat counting,
	     geometrical measurement, geometrical covariance,
	     colour maps, calculus on spatial domains,
	     Gaussian blur, level sets of images, transects of images,
	     intersections between objects, minimum distance matching.
	     (Excludes spatial data on a network, which are supported by
	     the package 'spatstat.linnet'.)",2022-03-29,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.geom,667572,2,2022-06-18T10:51:28Z,333786
spatstat.linnet,"Defines types of spatial data on a linear network
	     and provides functionality for geometrical operations,
	     data analysis and modelling of data on a linear network,
	     in the 'spatstat' family of packages.
	     Contains definitions and support for linear networks, including creation of networks, geometrical measurements, topological connectivity, geometrical operations such as inserting and deleting vertices, intersecting a network with another object, and interactive editing of networks.
	     Data types defined on a network include point patterns, pixel images, functions, and tessellations.
	     Exploratory methods include kernel estimation of intensity on a network, K-functions and pair correlation functions on a network, simulation envelopes, nearest neighbour distance and empty space distance, relative risk estimation with cross-validated bandwidth selection. Formal hypothesis tests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.
	Parametric models can be fitted to point pattern data using the function lppm() similar to glm(). Only Poisson models are implemented so far. Models may involve dependence on covariates and dependence on marks. Models are fitted by maximum likelihood.
	Fitted point process models can be simulated, automatically. Formal hypothesis tests of a fitted model are supported (likelihood ratio test, analysis of deviance, Monte Carlo tests) along with basic tools for model selection (stepwise(), AIC()) and variable selection (sdr). Tools for validating the fitted model include simulation envelopes, residuals, residual plots and Q-Q plots, leverage and influence diagnostics, partial residuals, and added variable plots.
	Random point patterns on a network can be generated using a variety of models.",2022-02-16,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.linnet,335726,4,2022-07-10T10:50:05Z,83931.5
spatstat.random,"Functionality for random generation of spatial data in the 'spatstat' family of packages.
	     Generates random spatial patterns of points according to many simple rules (complete spatial randomness,
	     Poisson, binomial, random grid, systematic, cell), randomised alteration of patterns
	     (thinning, random shift, jittering),  simulated realisations of random point processes
	     (simple sequential inhibition, Matern inhibition models, Matern cluster process,
	     Neyman-Scott cluster processes, log-Gaussian Cox processes, product shot noise cluster processes)
	     and simulation of Gibbs point processes (Metropolis-Hastings birth-death-shift algorithm,
	     alternating Gibbs sampler). Also generates random spatial patterns of line segments,
	     random tessellations, and random images (random noise, random mosaics).
	     Excludes random generation on a linear network,
	     which is covered by the separate package 'spatstat.linnet'.",2022-03-30,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.random,190958,3,2022-06-17T04:09:48Z,63652.666666666664
spatstat.sparse,"Defines sparse three-dimensional arrays
	     and supports standard operations on them.
	     The package also includes utility functions for
	     matrix calculations that are common in
	     statistics, such as quadratic forms.",2022-04-18,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.sparse,497284,0,2022-06-17T06:43:12Z,NA
spatstat.utils,"Contains utility functions for the 'spatstat' family of packages
             which may also be useful for other purposes.",2022-05-06,Adrian Baddeley,http://spatstat.org/,TRUE,https://github.com/spatstat/spatstat.utils,927134,4,2022-06-17T06:38:39Z,231783.5
spData,"Diverse spatial datasets for demonstrating, benchmarking and teaching spatial data analysis. 
    It includes R data of class sf (defined by the package 'sf'), Spatial ('sp'), and nb ('spdep').
    Unlike other spatial data packages such as 'rnaturalearth' and 'maps', 
    it also contains data stored in a range of file formats including GeoJSON, ESRI Shapefile and GeoPackage. 
    Some of the datasets are designed to illustrate specific analysis techniques.
    cycle_hire() and cycle_hire_osm(), for example, is designed to illustrate point pattern analysis techniques.",2021-10-14,Roger Bivand,https://nowosad.github.io/spData/,TRUE,https://github.com/nowosad/spdata,870470,51,2022-07-06T17:17:55Z,17068.039215686276
spdep,"A collection of functions to create spatial weights matrix
  objects from polygon 'contiguities', from point patterns by distance and
  tessellations, for summarizing these objects, and for permitting their
  use in spatial data analysis, including regional aggregation by minimum
  spanning tree; a collection of tests for spatial 'autocorrelation',
  including global 'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord'
  (1973, ISBN: 0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel'
  general cross product statistic, Empirical Bayes estimates and
  'Assunção/Reis' (1999) <doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO;2-I> Index, 'Getis/Ord' G ('Getis' and 'Ord' 1992)
  <doi:10.1111/j.1538-4632.1992.tb00261.x> and multicoloured
  join count statistics, 'APLE' ('Li 'et al.' )
  <doi:10.1111/j.1538-4632.2007.00708.x>, local 'Moran's I', 'Gearys C' 
  ('Anselin' 1995) <doi:10.1111/j.1538-4632.1995.tb00338.x> and
  'Getis/Ord' G ('Ord' and 'Getis' 1995)
  <doi:10.1111/j.1538-4632.1995.tb00912.x>,
  'saddlepoint' approximations ('Tiefelsdorf' 2002)
  <doi:10.1111/j.1538-4632.2002.tb01084.x> and exact tests
  for global and local 'Moran's I' ('Bivand et al.' 2009)
  <doi:10.1016/j.csda.2008.07.021> and 'LOSH' local indicators
  of spatial heteroscedasticity ('Ord' and 'Getis')
  <doi:10.1007/s00168-011-0492-y>. The implementation of most of
  the measures is described in 'Bivand' and 'Wong' (2018)
  <doi:10.1007/s11749-018-0599-x>, with further extensions in 'Bivand' (2022)
  <doi:10.1111/gean.12319>.
  From 'spdep' and 'spatialreg' versions >= 1.2-1, the model fitting functions
  previously present in this package are defunct in 'spdep' and may be found
  in 'spatialreg'.",2022-04-18,Roger Bivand,"https://github.com/r-spatial/spdep/,
https://r-spatial.github.io/spdep/",TRUE,https://github.com/r-spatial/spdep,1125037,91,2022-05-24T09:42:45Z,12363.043956043955
speakr,"It allows running 'Praat' scripts from R and it provides some
    wrappers for basic plotting. It also adds support for literate markdown
    tangling. The package is designed to bring reproducible phonetic research
    into R.",2021-07-22,Stefano Coretta  (<https://orcid.org/0000-0001-9627-5532>,https://github.com/stefanocoretta/speakr,TRUE,https://github.com/stefanocoretta/speakr,6501,15,2021-07-21T20:35:46Z,433.4
specr,"Provides utilities for conducting specification curve analyses (Simonsohn, Simmons & Nelson (2015, <doi: 10.2139/ssrn.2694998>) or multiverse analyses (Steegen, Tuerlinckx, Gelman & Vanpaemel, 2016, <doi: 10.1177/1745691616658637>) including functions to setup, run, evaluate, and plot all specifications.",2020-03-26,Philipp K. Masur,"https://masurp.github.io/specr/, https://github.com/masurp/specr",TRUE,https://github.com/masurp/specr,9727,47,2022-03-08T11:02:41Z,206.95744680851064
spectr,"Provides a consistent interface to use various methods to calculate
  the periodogram and estimate the period of a rhythmic time-course. Methods
  include Lomb-Scargle, fast Fourier transform, and three versions of the
  chi-square periodogram. See Tackenberg and Hughey (2021)
  <doi:10.1371/journal.pcbi.1008567>.",2022-02-07,Jake Hughey,"https://spectr.hugheylab.org, https://github.com/hugheylab/spectr",TRUE,https://github.com/hugheylab/spectr,1332,0,2022-05-18T16:35:13Z,NA
spectralGraphTopology,"In the era of big data and hyperconnectivity, learning
    high-dimensional structures such as graphs from data has become a prominent
    task in machine learning and has found applications in many fields such as
    finance, health care, and networks. 'spectralGraphTopology' is an open source,
    documented, and well-tested R package for learning graphs from data. It
    provides implementations of state of the art algorithms such as Combinatorial
    Graph Laplacian Learning (CGL), Spectral Graph Learning (SGL), Graph Estimation
    based on Majorization-Minimization (GLE-MM), and Graph Estimation based on
    Alternating Direction Method of Multipliers (GLE-ADMM). In addition, graph
    learning has been widely employed for clustering, where specific algorithms
    are available in the literature. To this end, we provide an implementation of
    the Constrained Laplacian Rank (CLR) algorithm.",2022-03-14,Ze Vinicius,"https://github.com/dppalomar/spectralGraphTopology,
https://mirca.github.io/spectralGraphTopology/,
https://www.danielppalomar.com",TRUE,https://github.com/dppalomar/spectralgraphtopology,16638,53,2022-03-14T14:09:14Z,313.92452830188677
spectralR,"Tools for obtaining, processing, and visualizing spectral reflectance data for the user-defined land or water surface classes for visual exploring in which wavelength the classes differ. Input should be a shapefile with polygons of surface classes (it might be different habitat types, crops, vegetation, etc.). The Sentinel-2 L2A satellite mission optical bands pixel data are obtained through the Google Earth Engine service (<https://earthengine.google.com/>) and used as a source of spectral data.",2022-06-28,Oleh Prylutskyi,https://github.com/olehprylutskyi/spectralR/,TRUE,https://github.com/olehprylutskyi/spectralr,148,1,2022-07-04T11:19:02Z,148
speech,"Converts the floor speeches of Uruguayan legislators, extracted from the 
    parliamentary minutes, to tidy data.frame where each observation is the intervention of a single legislator.",2021-10-30,Nicolas Schmidt,https://github.com/Nicolas-Schmidt/speech,TRUE,https://github.com/nicolas-schmidt/speech,9657,4,2021-11-01T13:40:06Z,2414.25
speechbr,"Scrap speech text and speaker informations of speeches of House of 
          Representatives of Brazil, and transform in a cleaned tibble.",2022-03-19,Douglas Cardoso,https://github.com/dcardosos/speechbr,TRUE,https://github.com/dcardosos/speechbr,1290,38,2022-02-24T00:46:59Z,33.94736842105263
speff2trial,"Performs estimation and testing of the treatment effect in a 2-group randomized clinical trial with a quantitative, dichotomous, or right-censored time-to-event endpoint. The method improves efficiency by leveraging baseline predictors of the endpoint. The inverse probability weighting technique of Robins, Rotnitzky, and Zhao (JASA, 1994) is used to provide unbiased estimation when the endpoint is missing at random.",2022-05-31,Michal Juraska,https://github.com/mjuraska/speff2trial,TRUE,https://github.com/mjuraska/speff2trial,16343,0,2022-05-28T00:04:41Z,NA
sperrorest,"Implements spatial error estimation and
    permutation-based variable importance measures for predictive models
    using spatial cross-validation and spatial block bootstrap.",2021-11-19,Alexander Brenning,"https://giscience-fsu.github.io/sperrorest/,
https://github.com/giscience-fsu/sperrorest",TRUE,https://github.com/giscience-fsu/sperrorest,25929,12,2022-06-26T20:20:01Z,2160.75
spfda,"Implements a group-bridge penalized function-on-scalar regression
    model proposed by Wang et al. (2020) <arXiv:2006.10163>, to simultaneously
    estimate functional coefficient and recover the local sparsity.",2022-03-18,Zhengjia Wang,"https://github.com/dipterix/spfda, http://dipterix.org/spfda/",TRUE,https://github.com/dipterix/spfda,6282,0,2022-03-21T14:58:55Z,NA
spfilteR,Tools to decompose (transformed) spatial connectivity matrices and perform supervised or unsupervised semiparametric spatial filtering in a regression framework. The package supports unsupervised spatial filtering in standard linear as well as some generalized linear regression models.,2022-03-09,Sebastian Juhl,https://github.com/sjuhl/spfilteR,TRUE,https://github.com/sjuhl/spfilter,6329,5,2022-03-26T15:55:54Z,1265.8
spflow,"
    Efficient estimation of spatial econometric models of origin-destination flows, which may exhibit spatial autocorrelation in the dependent variable, the explanatory variables or both.
    The model is the one proposed by LeSage and Pace (2008) <doi:10.1111/j.1467-9787.2008.00573.x>, who develop a matrix formulation that exploits the relational structure of flow data.
    The estimation procedures follow most closely those outlined by Dargel (2021) (preprint available at <https://www.tse-fr.eu/fr/publications/revisiting-estimation-methods-spatial-econometric-interaction-models>).",2021-09-09,Lukas Dargel,https://github.com/LukeCe/spflow,TRUE,https://github.com/lukece/spflow,2677,6,2021-09-14T09:20:39Z,446.1666666666667
sphet,"Functions for fitting Cliff-Ord-type spatial autoregressive models with and without heteroskedastic innovations using Generalized Method of Moments estimation are provided. Some support is available for fitting spatial HAC models, and for fitting with non-spatial endogeneous variables using instrumental variables.",2022-01-06,Gianfranco Piras,https://github.com/gpiras/sphet,TRUE,https://github.com/gpiras/sphet,33455,3,2022-01-18T16:46:18Z,11151.666666666666
sphunif,"Implementation of uniformity tests on the circle and
    (hyper)sphere. The main function of the package is unif_test(), which
    conveniently collects more than 30 tests for assessing uniformity on
    S^{p-1}={x in R^p : ||x||=1}, p >= 2. The test statistics are implemented
    in the unif_stat() function, which allows computing several statistics to
    several samples within a single call, thus facilitating Monte Carlo
    experiments. Furthermore, the unif_stat_MC() function allows
    parallelizing them in a simple way. The asymptotic null distributions of
    the statistics are available through the function unif_stat_distr(). The
    core of 'sphunif' is coded in C++ by relying on the 'Rcpp' package.
    The package also provides several novel datasets and gives the
    reproducibility for the data application in García-Portugués,
    Navarro-Esteban and Cuesta-Albertos (2020) <arXiv:2008.09897>.",2021-09-02,Eduardo García-Portugués,https://github.com/egarpor/sphunif,TRUE,https://github.com/egarpor/sphunif,3161,2,2021-09-02T07:53:42Z,1580.5
spikeSlabGAM,"Bayesian variable selection, model choice, and regularized
    estimation for (spatial) generalized additive mixed regression models
    via stochastic search variable selection with spike-and-slab priors.",2022-06-10,Fabian Scheipl,https://github.com/fabian-s/spikeSlabGAM,TRUE,https://github.com/fabian-s/spikeslabgam,19501,9,2022-06-10T09:39:32Z,2166.777777777778
spinifex,"Data visualization tours animates linear projection 
  of multivariate data as its basis (ie. orientation) changes. The 'spinifex' 
  packages generates paths for manual tours by manipulating the contribution of 
  a single variable at a time Cook & Buja (1997) 
  <doi:10.1080/10618600.1997.10474754>. Other types of tours, such as grand 
  (random walk) and guided (optimizing some objective function) are available 
  in the 'tourr' package Wickham et al. <doi:10.18637/jss.v040.i02>. 
  'spinifex' builds on 'tourr' and can render tours with 'gganimate' and 
  'plotly' graphics, and allows for exporting as an .html widget and as an .gif, 
  respectively. This work is fully discussed in Spyrison & Cook (2020) 
  <doi:10.32614/RJ-2020-027>.",2022-03-31,Nicholas Spyrison,https://github.com/nspyrison/spinifex/,TRUE,https://github.com/nspyrison/spinifex,16011,2,2022-04-17T08:26:38Z,8005.5
spiR,"In 2015, The 17 United Nations' Sustainable Development Goals were adopted. 'spiR' is a wrapper of several open datasets published by the Social Progress Imperative (<https://www.socialprogress.org/>), including the Social Progress Index (a synthetic measure of human development across the world). 'spiR''s goal is to provide data to help policymakers and researchers prioritize actions that accelerate social progress across the world in the context of the Sustainable Development Goals. Please cite: Warin, Th. (2019) ""spiR: An R Package for the Social Progress Index"", <doi:10.6084/m9.figshare.11421573.v2>.",2021-03-05,Thierry Warin,https://github.com/warint/spiR/,TRUE,https://github.com/warint/spir,11133,5,2021-08-20T14:00:20Z,2226.6
spiralize,"It visualizes data along an Archimedean spiral <https://en.wikipedia.org/wiki/Archimedean_spiral>, makes so-called spiral graph or spiral chart. 
    It has two major advantages for visualization: 1. It is able to visualize data with very long axis with high 
    resolution. 2. It is efficient for time series data to reveal periodic patterns.",2022-02-05,Zuguang Gu,https://github.com/jokergoo/spiralize,TRUE,https://github.com/jokergoo/spiralize,5155,114,2022-02-18T19:59:38Z,45.219298245614034
splash,"This program calculates bioclimatic indices and fluxes (radiation, 
    evapotranspiration, soil moisture) for use in studies of ecosystem function, 
    species distribution, and vegetation dynamics under changing climate 
    scenarios. Predictions are based on a minimum of required inputs: latitude, 
    precipitation, air temperature, and cloudiness. 
    Davis et al. (2017) <doi:10.5194/gmd-10-689-2017>.",2021-09-03,Wolfgang Cramer,"https://github.com/villegar/splash/,
https://splash.robertovillegas-diaz.com/,
https://bitbucket.org/labprentice/splash/",TRUE,https://github.com/villegar/splash,3816,1,2021-09-02T22:57:34Z,3816
spldv,"The current version of this package estimates spatial autoregressive models for binary dependent variables using GMM estimators. It supports one-step (Pinkse and Slade, 1998) <doi:10.1016/S0304-4076(97)00097-3> and two-step GMM estimator along with the linearized GMM estimator proposed by Klier and McMillen (2008) <doi:10.1198/073500107000000188>. It also allows for either Probit or Logit model and compute the average marginal effects. ",2022-05-09,Mauricio Sarrias,https://github.com/gpiras/spldv,TRUE,https://github.com/gpiras/spldv,1008,0,2022-05-02T13:35:19Z,NA
SPLICE,"An extension to the individual claim simulator called 'SynthETIC'
    (on CRAN), to simulate the evolution of case estimates of incurred losses
    through the lifetime of an insurance claim. The transactional simulation
    output now comprises key dates, and both claim payments and revisions of
    estimated incurred losses. An initial set of test parameters, designed to
    mirror the experience of a real insurance portfolio, were set up and applied
    by default to generate a realistic test data set of incurred histories (see
    vignette). However, the distributional assumptions used to generate this
    data set can be easily modified by users to match their experiences.
    Reference: Avanzi B, Taylor G, Wang M (2021) ""SPLICE: A Synthetic Paid Loss
    and Incurred Cost Experience Simulator"" <arXiv:2109.04058>.",2022-03-05,Melantha Wang,https://github.com/agi-lab/SPLICE,TRUE,https://github.com/agi-lab/splice,3253,4,2022-04-08T06:40:16Z,813.25
splines2,"Constructs basis matrix of B-splines, M-splines,
    I-splines, convex splines (C-splines), periodic M-splines,
    natural cubic splines, generalized Bernstein polynomials,
    and their integrals (except C-splines) and derivatives
    of given order by close-form recursive formulas.
    It also contains a C++ head-only library integrated with Rcpp.
    See Wang and Yan (2021) <doi:10.6339/21-JDS1020> for details.",2021-09-19,Wenjie Wang,"https://wwenjie.org/splines2,
https://github.com/wenjie2wang/splines2",TRUE,https://github.com/wenjie2wang/splines2,137939,23,2022-05-23T17:16:53Z,5997.347826086957
splithalfr,"Estimates split-half reliabilities for scoring algorithms of cognitive tasks and questionnaires. The 'splithalfr' supports researcher-provided scoring algorithms, with six vignettes illustrating how on included datasets. The package provides four splitting methods (first-second, odd-even, permutated, Monte Carlo), the option to stratify splits by task design, a number of reliability coefficients, and the option to sub-sample data.",2021-09-29,Thomas Pronk,https://github.com/tpronk/splithalfr,TRUE,https://github.com/tpronk/splithalfr,11533,0,2022-02-02T19:38:06Z,NA
SplitKnockoff,"Split Knockoff is a data adaptive variable selection framework for controlling the
             (directional) false discovery rate (FDR) in structural sparsity, where variable 
             selection on linear transformation of parameters is of concern. This proposed scheme
             relaxes the linear subspace constraint to its neighborhood, often known as variable
             splitting in optimization.
             Simulation experiments can be reproduced following the Vignette. We include data
             (both .mat and .csv format) and application with our method of Alzheimer's Disease 
             study in this package.
             'Split Knockoffs' is first defined in Cao et al. (2021) <arXiv:2103.16159>. ",2022-03-18,Haoxue Wang,https://github.com/wanghaoxue0/SplitKnockoff,TRUE,https://github.com/wanghaoxue0/splitknockoff,3493,0,2022-02-21T14:23:56Z,NA
splitTools,"Fast, lightweight toolkit for data splitting. Data sets can
    be partitioned into disjoint groups (e.g. into training, validation,
    and test) or into (repeated) k-folds for subsequent cross-validation.
    Besides basic splits, the package supports stratified, grouped as well
    as blocked splitting. Furthermore, cross-validation folds for time
    series data can be created. See e.g. Hastie et al. (2001)
    <doi:10.1007/978-0-387-84858-7> for the basic background on data
    partitioning and cross-validation.",2022-01-28,Michael Mayer,https://github.com/mayer79/splitTools,TRUE,https://github.com/mayer79/splittools,32087,10,2022-02-10T06:24:25Z,3208.7
splot,"Automates common plotting tasks to ease data exploration.
  Makes density plots (potentially overlaid on histograms),
  scatter plots with prediction lines, or bar or line plots with error bars.
  For each type, y, or x and y variables can be plotted at levels of other variables,
  all with minimal specification.",2022-01-30,Micah Iserman,https://miserman.github.io/splot/,TRUE,https://github.com/miserman/splot,15780,0,2022-07-05T21:21:50Z,NA
splusTimeDate,"A collection of classes and methods for working with
  times and dates. The code was originally available in S-PLUS.",2022-07-07,Stephen Kaluzny,https://github.com/spkaluzny/splusTimeDate,TRUE,https://github.com/spkaluzny/splustimedate,33645,0,2022-07-07T00:09:05Z,NA
splusTimeSeries,"A collection of classes and methods for working with time series.
  The code was originally available in S-PLUS.",2022-07-07,Stephen Kaluzny,https://github.com/spkaluzny/splusTimeSeries,TRUE,https://github.com/spkaluzny/splustimeseries,23997,0,2022-05-04T00:20:11Z,NA
splutil,"Utility functions that help with common base-R problems relating to lists.
    Lists in base-R are very flexible. This package provides functions to quickly and easily
    characterize types of lists. That is, to identify if all elements in a list
    are null, data.frames, lists, or fully named lists. Other functionality is provided
    for the handling of lists, such as the easy splitting of lists into equally sized
    groups, and the unnesting of data.frames within fully named lists.",2022-06-22,Richard Aubrey White,"https://docs.sykdomspulsen.no/splutil/,
https://github.com/sykdomspulsen-org/splutil",TRUE,https://github.com/sykdomspulsen-org/splutil,287,0,2022-06-20T04:47:48Z,NA
spNetwork,"Perform spatial analysis on network.
    Implement several methods for spatial analysis on network: Network Kernel Density estimation, 
    building of spatial matrices based on network distance ('listw' objects from 'spdep' package), K functions estimation 
    for point pattern analysis on network, k nearest neighbours on network, reachable area calculation, and graph generation
    References: Okabe et al (2019) <doi:10.1080/13658810802475491>;
    Okabe et al (2012, ISBN:978-0470770818);Baddeley et al (2015, ISBN:9781482210200).",2022-05-14,Jeremy Gelb,https://jeremygelb.github.io/spNetwork/,TRUE,https://github.com/jeremygelb/spnetwork,6292,17,2022-05-14T12:48:12Z,370.11764705882354
spocc,"A programmatic interface to many species occurrence data sources,
    including Global Biodiversity Information Facility ('GBIF'), 'USGSs'
    Biodiversity Information Serving Our Nation ('BISON'), 'iNaturalist',
    'eBird', Integrated Digitized
    'Biocollections' ('iDigBio'), 'VertNet', Ocean 'Biogeographic' Information
    System ('OBIS'), and Atlas of Living Australia ('ALA'). Includes
    functionality for retrieving species occurrence data, and combining
    those data.",2021-01-05,Scott Chamberlain,"https://github.com/ropensci/spocc (devel),
https://docs.ropensci.org/spocc/ (user manual)",TRUE,https://github.com/ropensci/spocc,119742,93,2021-09-23T12:40:24Z,1287.5483870967741
spOccupancy,"Fits single-species, multi-species, and integrated non-spatial and spatial occupancy models using Markov Chain Monte Carlo (MCMC). Models are fit using Polya-Gamma data augmentation detailed in Polson, Scott, and Windle (2013) <doi:10.1080/01621459.2013.829001>. Spatial models are fit using either Gaussian processes or Nearest Neighbor Gaussian Processes (NNGP) for large spatial datasets. Details on NNGP models are given in Datta, Banerjee, Finley, and Gelfand (2016) <doi:10.1080/01621459.2015.1044091> and Finley, Datta, and Banerjee (2020) <arXiv:2001.09111>. Provides functionality for data integration of multiple single-species occupancy data sets using a joint likelihood framework. Details on data integration are given in Miller, Pacifici, Sanderlin, and Reich (2019) <doi:10.1111/2041-210X.13110>. Details on single-species and multi-species models are found in MacKenzie, Nichols, Lachman, Droege, Royle, and Langtimm (2002) <doi:10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2> and Dorazio and Royle <doi:10.1198/016214505000000015>, respectively. ",2022-05-21,Jeffrey Doser,"https://www.jeffdoser.com/files/spoccupancy-web,
https://github.com/doserjef/spOccupancy",TRUE,https://github.com/doserjef/spoccupancy,3435,15,2022-07-08T11:32:04Z,229
sportyR,"Create scaled 'ggplot' representations of playing surfaces.
    Playing surfaces are drawn pursuant to rule-book specifications.
    This package should be used as a baseline plot for displaying player
    tracking data.",2021-04-20,Ross Drucker,https://github.com/rossdrucker/sportyR,TRUE,https://github.com/rossdrucker/sportyr,5206,72,2022-07-10T00:55:20Z,72.30555555555556
spotifyr,"An R wrapper for pulling data from the 'Spotify' Web API 
  <https://developer.spotify.com/documentation/web-api/> in bulk, or post items on a
  'Spotify' user's playlist.",2021-11-02,Daniel Antal,https://github.com/charlie86/spotifyr,TRUE,https://github.com/charlie86/spotifyr,20777,315,2021-11-03T00:06:46Z,65.95873015873016
spotoroo,An algorithm to cluster satellite hot spot data spatially and temporally.,2021-11-10,Weihao Li,"https://tengmcing.github.io/spotoroo/,
https://github.com/TengMCing/spotoroo/",TRUE,https://github.com/tengmcing/spotoroo,5183,3,2022-05-03T04:02:46Z,1727.6666666666667
spots,"The spots package is designed for spatial omics (10x Visium, etc.) data analysis. It performs various statistical analyses and tests, including spatial component analysis (SCA), both global and local spatial statistics, such as univariate and bivariate Moran's I, Getis-Ord Gi* statistics, etc. See Integrated protein and transcriptome high-throughput spatial profiling (2022) <doi:10.1101/2022.03.15.484516> for more details.",2022-05-03,X. Steve Niu,NA,TRUE,https://github.com/stevexniu/spots,439,0,2022-05-19T09:56:37Z,NA
SPQR,"Methods for flexible estimation of conditional density and quantile function, as well as model agnostic tools for analyzing quantile covariate effect and variable importance. The estimation method implements the semi-parametric quantile regression model described in Xu and Reich (2021) <doi:10.1111/biom.13576>, and the model agnostic tools extend accumulative local effects (ALE) to quantile regression setting.",2022-05-02,Steven Xu,https://github.com/stevengxu/SPQR,TRUE,https://github.com/stevengxu/spqr,428,0,2022-04-29T23:52:06Z,NA
spray,Sparse arrays interpreted as multivariate polynomials.,2022-07-05,Robin K. S. Hankin,https://github.com/RobinHankin/spray,TRUE,https://github.com/robinhankin/spray,35893,1,2022-07-05T20:23:21Z,35893
spreval,"Processing and analysis of field collected or simulated sprinkler 
    system catch data (depths) to characterize irrigation uniformity and efficiency using
    standard and other measures. Standard measures include the Christiansen coefficient
    of uniformity (CU) as found in Christiansen, J.E.(1942, ISBN:0138779295,
    ""Irrigation by Sprinkling""); and distribution uniformity (DU), potential
    efficiency of the low quarter (PELQ), and application efficiency of the low quarter (AELQ)
    that are implementations of measures of the same notation in Keller, J. and Merriam, 
    J.L. (1978) ""Farm Irrigation System Evaluation: A Guide for Management""
    <https://pdf.usaid.gov/pdf_docs/PNAAG745.pdf>. spreval::DU.lh is similar to spreval::DU
    but is the distribution uniformity of the low half instead of low quarter as in DU.
    spreval::PELQT is a version of spreval::PELQ adapted for traveling systems instead
    of lateral move or solid-set sprinkler systems. The function spreval::eff is
    analogous to the method used to compute application efficiency for furrow irrigation
    presented in Walker, W. and Skogerboe, G.V. (1987,ISBN:0138779295, ""Surface
    Irrigation: Theory and Practice""),that uses piecewise integration of infiltrated
    depth compared against soil-moisture deficit (SMD), when the argument ""target""
    is set equal to SMD.  The other functions contained in the package provide 
    graphical representation of sprinkler system uniformity, and other standard
    univariate parametric and non-parametric statistical measures as applied to
    sprinkler system catch depths. A sample data set of field test data spreval::catchcan
    (catch depths) is provided and is used in examples and vignettes. Agricultural systems
    emphasized, but this package can be used for landscape irrigation evaluation, and a
    landscape (turf) vignette is included as an example application.",2022-03-23,Garry Grabow,https://glgrabow.github.io/spreval/,TRUE,https://github.com/glgrabow/spreval,3855,0,2022-03-26T23:47:12Z,NA
spRingsteen,"An R data package containing setlists from all Bruce Springsteen concerts over 1973-2021. 
    Also includes all his song details such as lyrics and albums. Data extracted from: 
    <http://brucebase.wikidot.com/>.",2022-02-22,Joey OBrien,"https://github.com/obrienjoey/spRingsteen,
https://obrienjoey.github.io/spRingsteen/",TRUE,https://github.com/obrienjoey/springsteen,1066,0,2022-02-25T11:00:12Z,NA
sprintr,"An implementation of a computationally efficient method to fit large-scale interaction models based on the reluctant interaction selection principle. The method and its properties are described in greater depth in Yu, G., Bien, J., and Tibshirani, R.J. (2019) ""Reluctant interaction modeling"", which is available at <arXiv:1907.08414>.",2019-08-24,Guo Yu,NA,TRUE,https://github.com/hugogogo/sprintr,10400,3,2021-12-03T07:41:11Z,3466.6666666666665
sprtt,"The seq_ttest() function is the implementation of Abraham
    Wald’s (1947) <doi:10.2134/agronj1947.00021962003900070011x> Sequential Probability Ratio Test (SPRT) for the test of
    a normal mean (difference) with unknown variance in R (R Core Team, 2018).
    It performs sequential t tests developed by Rushton (1950) <doi:10.2307/2332385>, Rushton (1952) <doi:10.2307/2334026> and
    Hajnal (1961) <doi:10.2307/2333131>, based on the SPRT. Specifically, seq_ttest() performs
    one-sample, two-sample, and paired t tests for testing one- and
    two-sided hypotheses.  The test is to be applied to the data during
    the sampling process, ideally after each observation. At any stage, it
    will return a decision to either continue sampling or terminate and
    accept one of the specified hypotheses. For more information on the
    SPRT t test, see Schnuerch & Erdfelder (2019) <doi:10.1037/met0000234>.",2021-08-06,Meike Steinhilber,https://meikesteinhilber.github.io/sprtt/,TRUE,https://github.com/meikesteinhilber/sprtt,3470,3,2022-06-07T09:30:11Z,1156.6666666666667
sps,"Sequential Poisson sampling is a method for drawing probability-proportional-to-size samples with a given number of units, and is commonly used for price-index surveys. This package gives functions to draw stratified sequential Poisson samples according to the method by Ohlsson (1998, ISSN:0282-423X), and generate bootstrap replicate weights according to the generalized bootstrap method by Beaumont and Patak (2012, <doi:10.1111/j.1751-5823.2011.00166.x>).",2022-02-09,Steve Martin,https://github.com/marberts/sps,TRUE,https://github.com/marberts/sps,4480,1,2022-02-09T15:12:49Z,4480
spsComps,"The systemPipeShiny (SPS) framework comes with many UI and server components. However, installing the whole framework is heavy and takes some time. If you would like to use UI and server components from SPS in your own Shiny apps, do not hesitate to try this package.",2022-02-02,Le Zhang,https://github.com/lz100/spsComps,TRUE,https://github.com/lz100/spscomps,7174,16,2022-02-02T21:47:19Z,448.375
SPSP,"An implementation of the feature Selection procedure by Partitioning the entire Solution Paths
            (namely SPSP) to identify the relevant features rather than using a single tuning parameter. 
            By utilizing the entire solution paths, this procedure can obtain better selection accuracy than 
            the commonly used approach of selecting only one tuning parameter based on existing criteria, 
            cross-validation (CV), generalized CV, AIC, BIC, and extended BIC (Liu, Y., & Wang, P. (2018) 
            <doi:10.1214/18-EJS1434>). It is more stable and accurate (low false positive and 
            false negative rates) than other variable selection approaches. In addition, it can be flexibly 
            coupled with the solution paths of Lasso, adaptive Lasso, ridge regression, and other penalized 
            estimators.",2022-02-22,Xiaorui (Jeremy) Zhu,https://github.com/XiaoruiZhu/SPSP,TRUE,https://github.com/xiaoruizhu/spsp,3526,1,2022-02-25T19:39:31Z,3526
spsur,"A collection of functions to test and estimate Seemingly 
    Unrelated Regression (usually called SUR) models, with spatial structure, by maximum 
    likelihood and three-stage least squares. The package estimates the 
    most common spatial specifications, that is, SUR with Spatial Lag of 
    X regressors (called SUR-SLX), SUR with Spatial Lag Model (called SUR-SLM), 
    SUR with Spatial Error Model (called SUR-SEM), SUR with Spatial Durbin Model (called SUR-SDM), 
    SUR with Spatial Durbin Error Model (called SUR-SDEM), 
    SUR with Spatial Autoregressive terms and Spatial Autoregressive 
    Disturbances (called SUR-SARAR), SUR-SARAR with Spatial Lag of X 
    regressors (called SUR-GNM) and SUR with Spatially Independent 
    Model (called SUR-SIM). The methodology of these models can be found 
    in next references: Mur, J., Lopez, F., and Herrera, M. (2010) 
    <doi:10.1080/17421772.2010.516443>; 
    Lopez, F.A., Mur, J., and Angulo, A. (2014) 
    <doi:10.1007/s00168-014-0624-2> and 
    Lopez, F.A., Minguez, R. and Mur, J. (2020) 
    <doi:10.1007/s00168-019-00914-1>.",2022-04-22,Roman Minguez,https://CRAN.R-project.org/package=spsur,TRUE,https://github.com/rominsal/spsur,17110,10,2022-04-22T20:43:55Z,1711
spsurv,"A set of reliable routines to ease semiparametric survival regression modeling based on Bernstein polynomials. 'spsurv' includes proportional hazards, proportional odds and accelerated failure time frameworks for right-censored data. RV Panaro (2020) <arXiv:2003.10548>.",2020-03-31,Renato Panaro  (<https://orcid.org/0000-0002-1903-2091>,NA,TRUE,https://github.com/rvpanaro/spsurv,8601,2,2022-06-24T13:23:33Z,4300.5
spsurvey,"A design-based approach to statistical inference, with a focus on spatial data. Spatially balanced samples are selected using the Generalized Random Tessellation Stratified (GRTS) algorithm. The GRTS algorithm can be applied to finite resources (point geometries) and infinite resources (linear / linestring and areal / polygon geometries) and flexibly accommodates a diverse set of sampling design features, including stratification, unequal inclusion probabilities, proportional (to size) inclusion probabilities, legacy (historical) sites, a minimum distance between sites, and two options for replacement sites (reverse hierarchical order and nearest neighbor). Data are analyzed using a wide range of analysis functions that perform categorical variable analysis, continuous variable analysis, attributable risk analysis, risk difference analysis, relative risk analysis, change analysis, and trend analysis. spsurvey can also be used to summarize objects, visualize objects, select samples that are not spatially balanced, select panel samples, measure the amount of spatial balance in a sample, adjust design weights, and more.",2022-02-25,Michael Dumelle,https://github.com/USEPA/spsurvey,TRUE,https://github.com/usepa/spsurvey,38830,7,2022-02-25T00:35:49Z,5547.142857142857
spsUtil,"The systemPipeShiny (SPS) framework comes with many useful utility functions. However, installing the whole framework is heavy and takes some time. If you like only a few useful utility functions from SPS, install this package is enough.",2021-10-30,Le Zhang,https://github.com/lz100/spsUtil,TRUE,https://github.com/lz100/spsutil,6075,3,2021-11-12T19:50:27Z,2025
SPUTNIK,"A set of tools for the peak filtering of mass spectrometry
  imaging data (MSI or IMS) based on spatial distribution of signal. Given a 
  region-of-interest (ROI), representing the spatial region where the informative
  signal is expected to be localized, a series of filters determine which peak
  signals are characterized by an implausible spatial distribution. The filters
  reduce the dataset dimensionality and increase its information vs noise ratio,
  improving the quality of the unsupervised analysis results, reducing data
  dimensionality and simplifying the chemical interpretation.",2021-10-18,Paolo Inglese,https://github.com/paoloinglese/SPUTNIK,TRUE,https://github.com/paoloinglese/sputnik,13586,4,2021-10-23T18:29:45Z,3396.5
sqldf,"The sqldf() function is typically passed a single argument which 
	is an SQL select statement where the table names are ordinary R data 
	frame names.  sqldf() transparently sets up a database, imports the 
	data frames into that database, performs the SQL select or other
	statement and returns the result using a heuristic to determine which 
	class to assign to each column of the returned data frame.  The sqldf() 
	or read.csv.sql() functions can also be used to read filtered files 
	into R even if the original files are larger than R itself can handle.
	'RSQLite', 'RH2', 'RMySQL' and 'RPostgreSQL' backends are supported.",2017-06-28,G. Grothendieck,"https://github.com/ggrothendieck/sqldf,
https://groups.google.com/group/sqldf",TRUE,https://github.com/ggrothendieck/sqldf,1900404,223,2022-03-15T23:35:12Z,8521.991031390135
SqlRender,"A rendering tool for parameterized SQL that also translates into
  different SQL dialects.  These dialects include 'Microsoft Sql Server', 'Oracle', 
  'PostgreSql', 'Amazon RedShift', 'Apache Impala', 'IBM Netezza', 'Google BigQuery', 'Microsoft PDW', 'Apache Spark', and 'SQLite'.",2022-06-29,Martijn Schuemie,"https://ohdsi.github.io/SqlRender/,
https://github.com/OHDSI/SqlRender",TRUE,https://github.com/ohdsi/sqlrender,80658,52,2022-06-29T13:28:40Z,1551.1153846153845
squashinformr,"Scrape SquashInfo <http://www.squashinfo.com/> for data on the Professional Squash Association World Tour and other squash events. 'squashinformr' functions scrape, parse, and clean data associated with players, tournaments, and rankings.",2022-05-10,Hayden MacDonald,https://github.com/HaydenMacDonald/squashinformr,TRUE,https://github.com/haydenmacdonald/squashinformr,10758,4,2022-05-09T18:58:46Z,2689.5
SqueakR,"Data processing and visualizations for rodent vocalizations exported from
    'DeepSqueak'. These functions are compatible with the 'SqueakR' Shiny Dashboard,
    which can be used to visualize experimental results and analyses.",2022-06-28,Simon Ogundare,"https://osimon81.github.io/SqueakR/,
https://github.com/osimon81/SqueakR/",TRUE,https://github.com/osimon81/squeakr,350,1,2022-06-25T19:42:46Z,350
squid,"A simulation-based tool made to help researchers to become familiar with
    multilevel variations, and to build up sampling designs for their study. 
    This tool has two main objectives: First, it provides an educational tool useful for students, 
    teachers and researchers who want to learn to use mixed-effects models. 
    Users can experience how the mixed-effects model framework can be used to understand 
    distinct biological phenomena by interactively exploring simulated multilevel data. 
    Second, it offers research opportunities to those who are already familiar with 
    mixed-effects models, as it enables the generation of data sets that users may download 
    and use for a range of simulation-based statistical analyses such as power 
    and sensitivity analysis of multilevel and multivariate data [Allegue, H., Araya-Ajoy, Y.G., Dingemanse, 
    N.J., Dochtermann N.A., Garamszegi, L.Z., Nakagawa, S., Reale, D., Schielzeth, H. and Westneat, D.F. (2016) 
    <doi: 10.1111/2041-210X.12659>].",2022-01-21,Hassen Allegue,"https://github.com/squid-group/squid,
https://squid-group.github.io/squid/",TRUE,https://github.com/squid-group/squid,13848,30,2022-04-25T11:28:51Z,461.6
sRdpData,"Provides you with easy, programmatic access to SRDP data.",2022-03-29,Harriet Jane Goers,https://github.com/hgoers/sRdpData,TRUE,https://github.com/hgoers/srdpdata,798,0,2022-06-14T16:27:28Z,NA
srm,"
    Provides functionality for structural equation modeling for
    the social relations model (Kenny & La Voie, 1984;
    <doi:10.1016/S0065-2601(08)60144-6>; Warner, Kenny, & Soto, 1979,
    <doi:10.1037/0022-3514.37.10.1742>). Maximum likelihood
    estimation (Gill & Swartz, 2001, <doi:10.2307/3316080>;
    Nestler, 2018, <doi:10.3102/1076998617741106>) and
    least squares estimation is supported (Bond & Malloy, 2018,
    <doi:10.1016/B978-0-12-811967-9.00014-X>).",2019-12-15,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/srm,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/srm,10638,4,2022-04-04T10:40:45Z,2659.5
srt,"Read 'SubRip'
    <https://sourceforge.net/projects/subrip/> subtitle files as data
    frames for easy text analysis or manipulation.  Easily shift numeric
    timings and export subtitles back into valid 'SubRip' timestamp format
    to sync subtitles and audio.",2021-09-02,Kiernan Nicholls,"https://github.com/kiernann/srt, https://kiernann.com/srt/",TRUE,https://github.com/kiernann/srt,7297,0,2021-09-02T17:17:13Z,NA
srvyr,"Use piping, verbs like 'group_by' and 'summarize', and other
    'dplyr' inspired syntactic style when calculating summary statistics on survey
    data using functions from the 'survey' package.",2022-02-20,Greg Freedman Ellis,"http://gdfe.co/srvyr/, https://github.com/gergness/srvyr/",TRUE,https://github.com/gergness/srvyr,103700,183,2022-02-20T19:40:55Z,566.6666666666666
ss3sim,"Develops a framework for fisheries stock assessment simulation
    testing with Stock Synthesis (SS) as described in Anderson et al.
    (2014) <doi:10.1371/journal.pone.0092725>.",2019-11-08,Kelli F. Johnson,https://github.com/ss3sim/ss3sim,TRUE,https://github.com/ss3sim/ss3sim,16973,35,2022-06-14T14:20:22Z,484.9428571428571
SSBtools,"Functions used by other packages from Statistics Norway are gathered. General data manipulation functions, and functions for hierarchical computations are included (Langsrud, 2020) <doi:10.13140/RG.2.2.27313.61283>. The hierarchy specification functions are useful within statistical disclosure control.",2022-06-23,Øyvind Langsrud,https://github.com/statisticsnorway/SSBtools,TRUE,https://github.com/statisticsnorway/ssbtools,21717,3,2022-06-24T07:20:19Z,7239
ssdtools,"Species sensitivity distributions are cumulative probability
    distributions which are fitted to toxicity concentrations for
    different species as described by Posthuma et al.(2001)
    <isbn:9781566705783>.  The ssdtools package uses Maximum Likelihood to
    fit distributions such as the gamma, log-logistic, log-normal and
    Weibull to censored and/or weighted data.  Multiple distributions can
    be averaged using Akaike Information Criteria.  Confidence intervals
    on hazard concentrations and proportions are produced by parametric
    bootstrapping.",2022-05-14,Joe Thorley,https://github.com/bcgov/ssdtools,TRUE,https://github.com/bcgov/ssdtools,20340,22,2022-06-07T13:06:32Z,924.5454545454545
ssh,"Connect to a remote server over SSH to transfer files via SCP, 
    setup a secure tunnel, or run a command or script on the host while 
    streaming stdout and stderr directly to the client.",2021-05-03,Jeroen Ooms,"https://docs.ropensci.org/ssh/ (website),
https://github.com/ropensci/ssh (devel)",TRUE,https://github.com/ropensci/ssh,118475,121,2021-09-06T09:10:56Z,979.1322314049587
sship,"Convenient tools for exchanging files securely from within R. By
    encrypting the content safe passage of files (shipment) can be provided by
    common but insecure carriers such as ftp and email. Based on asymmetric
    cryptography no management of shared secrets is needed to make a secure
    shipment as long as authentic public keys are available. Public keys used
    for secure shipments may also be obtained from external providers as part of
    the overall process. Transportation of files will require that relevant
    services such as ftp and email servers are available.",2022-01-31,Are Edvardsen,https://github.com/Rapporteket/sship,TRUE,https://github.com/rapporteket/sship,4040,0,2022-05-13T08:20:53Z,NA
SSNbayes,"Fits Bayesian spatio-temporal models and makes predictions on stream networks using the approach by Santos-Fernandez, Edgar, et al. (2021).""Bayesian spatio-temporal models for stream networks"" <arXiv:2103.03538>. In these models, spatial dependence is captured using stream distance and flow connectivity, while temporal autocorrelation is modelled using vector autoregression methods. ",2021-10-22,Edgar Santos-Fernandez,https://github.com/EdgarSantos-Fernandez/SSNbayes,TRUE,https://github.com/edgarsantos-fernandez/ssnbayes,2626,7,2021-10-21T22:51:11Z,375.14285714285717
sspm,"Implement a gam-based spatial surplus production model, aimed at 
    modeling northern shrimp population in Atlantic Canada but potentially to 
    any stock in any location. The package is opinionated in its implementation 
    of SPMs as it internally makes the choice to use penalized spatial gams with 
    time lags. However, it also aims to provide options for the user to customize 
    their model.",2022-05-12,Valentin Lucet,https://pedersen-fisheries-lab.github.io/sspm/,TRUE,https://github.com/pedersen-fisheries-lab/sspm,398,2,2022-07-06T14:51:09Z,199
sss,"Tools to import survey files in the '.sss' (triple-s) format. 
    The package provides the function 'read.sss()' that reads the '.asc' 
    (or '.csv') and '.sss' files of a triple-s survey data file. 
    See also <https://www.triple-s.org/>.",2021-12-14,Andrie de Vries,https://andrie.github.io/sss/,TRUE,https://github.com/andrie/sss,16538,7,2021-12-15T16:21:29Z,2362.5714285714284
SSVS,"Functions for performing stochastic search variable selection (SSVS) 
    for binary and continuous outcomes and visualizing the results. 
    SSVS is a Bayesian variable selection method used to estimate the probability 
    that individual predictors should be included in a regression model. 
    Using MCMC estimation, the method samples thousands of regression models 
    in order to characterize the model uncertainty regarding both the predictor 
    set and the regression parameters. For details see Bainter, McCauley, Wager, 
    and Losin (2020) Improving practices for selecting a subset of important 
    predictors in psychology: An application to predicting pain, Advances in 
    Methods and Practices in Psychological Science 3(1), 66-80 
    <DOI:10.1177/2515245919885617>.",2022-05-29,Sierra Bainter,https://github.com/sabainter/SSVS,TRUE,https://github.com/sabainter/ssvs,1198,3,2022-05-28T01:10:19Z,399.3333333333333
StabilizedRegression,"Contains an implementation of 'StabilizedRegression', a regression framework for heterogeneous data introduced in Pfister et al. (2021) <arXiv:1911.01850>. The procedure uses averaging to estimate a regression of a set of predictors X on a response variable Y by enforcing stability with respect to a given environment variable. The resulting regression leads to a variable selection procedure which allows to distinguish between stable and unstable predictors. The package further implements a visualization technique which illustrates the trade-off between stability and predictiveness of individual predictors.",2022-06-30,Niklas Pfister,NA,TRUE,https://github.com/niklaspfister/stabilizedregression-r,9478,2,2022-06-30T07:54:24Z,4739
stable,"Density, distribution, quantile and hazard functions of a
    stable variate; generalized regression models for the parameters
    of a stable distribution. See the README for how to make equivalent calls
    to those of 'stabledist' (i.e., Nolan's 0-parameterization and 
    1-parameterization as detailed in Nolan (2020)). 
    See github for Lambert and Lindsey 1999 JRSS-C journal article, 
    which details the parameterization of the Buck (1995) stable.   
    See the Details section of the `?dstable` help file for context and 
    references.",2022-03-02,Bruce Swihart,https://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/stable,310856,5,2022-03-02T02:31:29Z,62171.2
stacks,"Model stacking is an ensemble technique
    that involves training a model to combine the outputs of many 
    diverse statistical models, and has been shown to improve 
    predictive performance in a variety of settings. 'stacks' 
    implements a grammar for 'tidymodels'-aligned model stacking.",2022-07-06,Simon Couch,"https://stacks.tidymodels.org/,
https://github.com/tidymodels/stacks",TRUE,https://github.com/tidymodels/stacks,24701,260,2022-07-06T20:11:03Z,95.00384615384615
stagedtrees,"Creates and fits staged event tree probability models, 
             which are probabilistic graphical models capable of representing 
             asymmetric conditional independence statements 
             for categorical variables. 
             Includes functions to create, plot and fit staged 
             event trees from data, as well as many efficient structure 
             learning algorithms.
             References:
             Collazo R. A., Görgen C. and Smith J. Q. 
             (2018, ISBN:9781498729604).
             Görgen C., Bigatti A., Riccomagno E. and Smith J. Q. (2018) 
             <arXiv:1705.09457>.
             Thwaites P. A., Smith, J. Q. (2017) <arXiv:1510.00186>.
             Barclay L. M., Hutton J. L. and Smith J. Q. (2013) 
             <doi:10.1016/j.ijar.2013.05.006>.
             Smith J. Q. and Anderson P. E. (2008) 
             <doi:10.1016/j.artint.2007.05.004>.",2022-04-28,Gherardo Varando,https://github.com/gherardovarando/stagedtrees,TRUE,https://github.com/gherardovarando/stagedtrees,13995,2,2022-04-29T10:06:20Z,6997.5
StAMPP,"Allows users to calculate pairwise Nei's Genetic Distances (Nei 1972), pairwise Fixation
 Indexes (Fst) (Weir & Cockerham 1984) and also Genomic Relationship matrixes following Yang et al. (2010) in mixed and single
 ploidy populations. Bootstrapping across loci is implemented during Fst calculation to generate confidence intervals and p-values
 around pairwise Fst values. StAMPP utilises SNP genotype data of any ploidy level (with the ability to handle missing data) and is coded to  
 utilise multithreading where available to allow efficient analysis of large datasets. StAMPP is able to handle genotype data from genlight objects 
 allowing integration with other packages such adegenet.
 Please refer to LW Pembleton, NOI Cogan & JW Forster, 2013, Molecular Ecology Resources, 13(5), 946-952. <doi:10.1111/1755-0998.12129> for the appropriate citation and user manual. Thank you in advance.",2021-08-08,LW Pembleton,https://github.com/lpembleton/StAMPP,TRUE,https://github.com/lpembleton/stampp,35469,1,2021-11-29T14:18:07Z,35469
stan4bart,"Fits semiparametric linear and multilevel models with non-parametric additive Bayesian additive regression tree (BART; Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>) components and Stan (Stan Development Team (2021) <https://mc-stan.org/>) sampled parametric ones. Multilevel models can be expressed using 'lme4' syntax (Bates, Maechler, Bolker, and Walker (2015) <doi:10.18637/jss.v067.i01>).",2022-03-31,Vincent Dorie,https://github.com/vdorie/stan4bart,TRUE,https://github.com/vdorie/stan4bart,2054,13,2022-06-16T19:19:20Z,158
standartox,"The <http://standartox.uni-landau.de> database offers cleaned,
    harmonized and aggregated ecotoxicological test data, which can
    be used for assessing effects and risks of chemical concentrations
    found in the environment.",2021-05-05,Andreas Scharmüller,https://github.com/andschar/standartox,TRUE,https://github.com/andschar/standartox,4387,9,2021-10-04T07:45:06Z,487.44444444444446
stanette,"Expansion and additions to 'rstan' to facilitate pharmacokinetics (PK)
    and pharmacodynamics (PD) modeling with 'rstan'.  A PKPD model often is specified
    via a set of ordinary differential equations(ODEs) and requires flexible and 
    different routes of drug administrations.  These features make PKPD modeling
    with plain 'rstan' challenging and tedious to code.  'stanette' provides a powerful 
    Stan-compatible ODE solver ('LSODA') and mechanism/utilities that make easy
    specification of flexible dosing records.",2022-05-11,Wenping Wang,"https://mc-stan.org/rstan/, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/rstan,1601,869,2021-11-09T21:19:20Z,1.8423475258918296
StanMoMo,"Implementation of popular mortality models using the 'rstan' 
    package, which provides the R interface to the 'Stan' C++ library for 
    Bayesian estimation. The package supports well-known models proposed in the 
    actuarial and demographic literature including the Lee-Carter (1992) 
    <doi:10.1080/01621459.1992.10475265> and the Cairns-Blake-Dowd (2006) 
    <doi:10.1111/j.1539-6975.2006.00195.x> models. By a simple call, the user 
    inputs deaths and exposures and the package outputs the MCMC simulations for
    each parameter, the log likelihoods and predictions. Moreover, the package 
    includes tools for model selection and Bayesian model averaging by leave 
    future-out validation.",2022-06-23,Karim Barigou,https://github.com/kabarigou/StanMoMo,TRUE,https://github.com/kabarigou/stanmomo,2717,12,2022-06-23T13:52:44Z,226.41666666666666
staplr,"Provides function to manipulate PDF files: 
    fill out PDF forms;
    merge multiple PDF files into one; 
    remove selected pages from a file;
    rename multiple files in a directory;
    rotate entire pdf document; 
    rotate selected pages of a pdf file;
    Select pages from a file;
    splits single input PDF document into individual pages;
    splits single input PDF document into parts from given points.
    'staplr' requires Java 8 installed on your system.",2021-01-11,Priyanga Dilini Talagala,NA,TRUE,https://github.com/pridiltal/staplr,26816,251,2022-03-16T19:24:08Z,106.83665338645419
staRdom,"This is a user-friendly way to run a parallel factor (PARAFAC) analysis (Harshman, 1971) <doi:10.1121/1.1977523> on excitation emission matrix (EEM) data from dissolved organic matter (DOM) samples (Murphy et al., 2013) <doi:10.1039/c3ay41160e>. The analysis includes profound methods for model validation. Some additional functions allow the calculation of absorbance slope parameters and create beautiful plots.",2022-03-21,Matthias Pucher,https://cran.r-project.org/package=staRdom,TRUE,https://github.com/matthiaspucher/stardom,21478,13,2022-03-30T13:47:55Z,1652.1538461538462
stars,"Reading, manipulating, writing and plotting
    spatiotemporal arrays (raster and vector data cubes) in 'R', using 'GDAL'
    bindings provided by 'sf', and 'NetCDF' bindings by 'ncmeta' and 'RNetCDF'.",2021-12-19,Edzer Pebesma,"https://r-spatial.github.io/stars/,
https://github.com/r-spatial/stars/",TRUE,https://github.com/r-spatial/stars,853927,445,2022-06-15T16:25:00Z,1918.9370786516854
starsExtra,"Miscellaneous functions for working with 'stars' objects, mainly single-band rasters. Currently includes functions for: (1) focal filtering, (2) detrending of Digital Elevation Models, (3) calculating flow length, (4) calculating the Convergence Index, (5) calculating topographic aspect and topographic slope.",2021-11-18,Michael Dorman,"https://michaeldorman.github.io/starsExtra/,
https://github.com/michaeldorman/starsExtra/",TRUE,https://github.com/michaeldorman/starsextra,12941,23,2021-11-18T15:41:19Z,562.6521739130435
starter,"Get started with new projects by dropping a skeleton of a new
    project into a new or existing directory, initialise git repositories,
    and create reproducible environments with the 'renv' package. The
    package allows for dynamically named files, folders, file content, as
    well as the functionality to drop individual template files into
    existing projects.",2022-04-20,Daniel D. Sjoberg,"https://github.com/ddsjoberg/starter,
https://www.danieldsjoberg.com/starter/index.html",TRUE,https://github.com/ddsjoberg/starter,7039,10,2022-06-20T19:17:18Z,703.9
starticles,"Provides a generic, publisher-independent Rmarkdown template for writing 
  scientific papers and reports in Rmarkdown. The template allows for all the basic features of a
  scientific article, including a title page with author affiliations and footnotes possibly shown
  in two common formats, multi-language abstracts and keywords, page headers and footers, and 
  the ability to place figures and tables at the end of the output PDF. Smart cross-referencing of
  figures, tables, equations and sections is provided using the bookdown package. See package
  README.md for basic package usage.",2022-06-09,David M. Kaplan,https://github.com/dmkaplan2000/starticles,TRUE,https://github.com/dmkaplan2000/starticles,248,0,2022-06-07T20:08:04Z,NA
STARTS,"
    Contains functions for estimating the STARTS model of
    Kenny and Zautra (1995, 2001) <DOI:10.1037/0022-006X.63.1.52>,
    <DOI:10.1037/10409-008>. Penalized maximum likelihood
    estimation and Markov Chain Monte Carlo estimation are
    also provided, see Luedtke, Robitzsch and Wagner (2018) 
    <DOI:10.1037/met0000155>.",2022-05-19,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/STARTS,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/starts,17977,2,2022-05-20T08:59:34Z,8988.5
startup,Adds support for R startup configuration via '.Renviron.d' and '.Rprofile.d' directories in addition to '.Renviron' and '.Rprofile' files.  This makes it possible to keep private / secret environment variables separate from other environment variables.  It also makes it easier to share specific startup settings by simply copying a file to a directory.,2022-05-14,Henrik Bengtsson,"https://henrikbengtsson.github.io/startup/,
https://github.com/HenrikBengtsson/startup",TRUE,https://github.com/henrikbengtsson/startup,32004,137,2022-07-05T10:19:32Z,233.6058394160584
starvars,"Allows the user to estimate a vector logistic smooth transition autoregressive model via maximum log-likelihood or nonlinear least squares. It further permits to test for linearity in the multivariate framework against a vector logistic smooth transition autoregressive model with a single transition variable. The estimation method is discussed in Terasvirta and Yang (2014, <doi:10.1108/S0731-9053(2013)0000031008>). Also, realized covariances can be constructed from stock market prices or returns, as explained in Andersen et al. (2001, <doi:10.1016/S0304-405X(01)00055-1>).",2022-01-17,Andrea Bucci,https://github.com/andbucci/starvars,TRUE,https://github.com/andbucci/starvars,9825,3,2022-01-17T17:03:29Z,3275
starvz,"Performance analysis workflow that combines the power of the R
    language (and the tidyverse realm) and many auxiliary tools to
    provide a consistent, flexible, extensible, fast, and versatile
    framework for the performance analysis of task-based applications
    that run on top of the StarPU runtime (with its MPI (Message
    Passing Interface) layer for multi-node support).  Its goal is to
    provide a fruitful prototypical environment to conduct performance
    analysis hypothesis-checking for task-based applications that run
    on heterogeneous (multi-GPU, multi-core) multi-node HPC
    (High-performance computing) platforms.",2022-02-13,Lucas Mello Schnorr,https://github.com/schnorr/starvz,TRUE,https://github.com/schnorr/starvz,8350,9,2022-05-03T16:49:44Z,927.7777777777778
starwarsdb,"Provides data about the 'Star Wars' movie franchise
    in a set of relational tables or as a complete 'DuckDB' database. All
    data was collected from the open source 'Star Wars' API
    <https://swapi.dev/>.",2020-11-02,Garrick Aden-Buie,https://github.com/gadenbuie/starwarsdb,TRUE,https://github.com/gadenbuie/starwarsdb,7924,34,2021-07-27T15:35:28Z,233.05882352941177
statcanR,"An easy connection with R to Statistics Canada's Web Data Service. Open economic data (formerly known as CANSIM tables, now identified by Product IDs (PID)) are accessible as a data frame, directly in the user's R environment.
    Warin, Le Duc (2019) <doi:10.6084/m9.figshare.10544735>.",2021-12-14,Thierry Warin,https://github.com/warint/statcanR/,TRUE,https://github.com/warint/statcanr,12380,10,2021-12-14T15:49:56Z,1238
statespacer,"A tool that makes estimating models in state space form 
    a breeze. See ""Time Series Analysis by State Space Methods"" by 
    Durbin and Koopman (2012, ISBN: 978-0-19-964117-8) for details 
    about the algorithms implemented.",2022-05-10,Dylan Beijers,"https://DylanB95.github.io/statespacer/,
https://github.com/DylanB95/statespacer/",TRUE,https://github.com/dylanb95/statespacer,12234,4,2022-05-10T17:38:49Z,3058.5
statgenGWAS,"Fast single trait Genome Wide Association Studies (GWAS) following 
    the method described in Kang et al. (2010), <doi:10.1038/ng.548>.        
    One of a series of statistical genetic packages for streamlining the 
    analysis of typical plant breeding experiments developed by Biometris.",2022-02-16,Bart-Jan van Rossum,"https://biometris.github.io/statgenGWAS/index.html,
https://github.com/Biometris/statgenGWAS/",TRUE,https://github.com/biometris/statgengwas,15180,6,2022-02-17T11:00:43Z,2530
statgenHTP,"Phenotypic analysis of data coming from high throughput 
    phenotyping (HTP) platforms, including different types of outlier detection,
    spatial analysis, and parameter estimation. The package is being developed
    within the EPPN2020 project (<https://eppn2020.plant-phenotyping.eu/>).
    Some functions have been created to be used in conjunction with the R 
    package 'asreml' for the 'ASReml' software, which can be obtained upon 
    purchase from 'VSN' international (<https://www.vsni.co.uk/software/asreml>).",2021-09-15,Bart-Jan van Rossum,"https://biometris.github.io/statgenHTP/index.html,
https://github.com/Biometris/statgenHTP/",TRUE,https://github.com/biometris/statgenhtp,6555,0,2022-04-14T13:42:04Z,NA
statgenIBD,"For biparental, three and four-way crosses Identity by Descent 
    (IBD) probabilities can be calculated using Hidden Markov Models and 
    inheritance vectors following Lander and Green
    (<https://www.jstor.org/stable/29713>) and Huang
    (<doi:10.1073/pnas.1100465108>). One of a series of statistical genetic 
    packages for streamlining the analysis of typical plant breeding experiments
    developed by Biometris.",2022-03-07,Martin Boer,"https://biometris.github.io/statgenIBD/index.html,
https://github.com/Biometris/statgenIBD/",TRUE,https://github.com/biometris/statgenibd,3608,0,2022-03-07T10:26:29Z,NA
statgenSTA,"Phenotypic analysis of field trials using mixed models with and 
    without spatial components. One of a series of statistical genetic packages 
    for streamlining the analysis of typical plant breeding experiments developed
    by Biometris.    
    Some functions have been created to be used in conjunction with the R 
    package 'asreml' for the 'ASReml' software, which can be obtained upon 
    purchase from 'VSN' international (<https://vsni.co.uk/software/asreml-r>). ",2022-06-24,Bart-Jan van Rossum,"https://biometris.github.io/statgenSTA/index.html,
https://github.com/Biometris/statgenSTA/",TRUE,https://github.com/biometris/statgensta,17145,1,2022-07-04T07:03:54Z,17145
statisfactory,"A collection of statistical and geometrical tools
	including the aligned rank transform (ART; Higgins et al.
	1990 <doi:10.4148/2475-7772.1443>; Peterson 2002
	<doi:10.22237/jmasm/1020255240>; Wobbrock et al. 2011
	<doi:10.1145/1978942.1978963>), 2-D histograms and
	histograms with overlapping bins, a function for making all
	possible formulae within a set of constraints, amongst others.",2022-03-07,Adam B. Smith,https://github.com/adamlilith/statisfactory,TRUE,https://github.com/adamlilith/statisfactory,1180,1,2022-03-03T02:53:25Z,1180
StatMatch,Integration of two data sources referred to the same target population which share a number of variables. Some functions can also be used to impute missing values in data sets through hot deck imputation methods. Methods to perform statistical matching when dealing  with data from complex sample surveys are available too.,2022-03-01,Marcello DOrazio,"https://github.com/marcellodo/StatMatch,
https://github.com/marcellodo/StatMatch/tree/master/Tutorials_Vignette_OtherDocs",TRUE,https://github.com/marcellodo/statmatch,58587,3,2022-03-01T11:53:33Z,19529
statnet.common,Non-statistical utilities used by the software developed by the Statnet Project. They may also be of use to others.,2022-05-02,Pavel N. Krivitsky  (<https://orcid.org/0000-0002-9101-3362>,https://statnet.org,TRUE,https://github.com/statnet/statnet.common,689042,8,2022-05-13T06:07:31Z,86130.25
statnipokladna,"Get programmatic access to data from the Czech public
    budgeting and accounting database, Státní pokladna
    <https://monitor.statnipokladna.cz/>.",2021-05-26,Petr Bouchal,"https://github.com/petrbouchal/statnipokladna,
https://petrbouchal.xyz/statnipokladna/",TRUE,https://github.com/petrbouchal/statnipokladna,10173,4,2022-03-28T21:37:06Z,2543.25
statpsych,"Implements confidence interval and sample size methods that are especially useful in psychological research. The methods can be applied in 1-group, 2-group, paired-samples, and multiple-group designs and to a variety of parameters including means, medians, proportions, slopes, standardized mean differences, standardized linear contrasts of means, plus several measures of correlation and association. The confidence intervals and sample size functions are applicable to single parameters as well as differences, ratios, and linear contrasts of parameters.  The sample size functions can be used to approximate the sample size needed to estimate a parameter or function of parameters with desired confidence interval precision or to perform a variety of hypothesis tests (directional two-sided, equivalence, superiority, noninferiority) with desired power. For details see:  Statistical Methods for Psychologists, Volumes 1 – 4, <https://dgbonett.sites.ucsc.edu/>.     ",2022-06-22,Douglas G. Bonett,NA,TRUE,https://github.com/dgbonett/statpsych,2925,0,2022-06-21T20:35:28Z,NA
statquotes,"Generates a random quotation from a data base of quotes on topics
    in statistics, data visualization and science. Other functions allow searching
    the quotes database or creating a word cloud.",2022-03-05,Michael Friendly,https://github.com/friendly/statquotes/,TRUE,https://github.com/friendly/statquotes,14267,5,2022-03-14T20:58:07Z,2853.4
stats19,"Tools to help download, process and analyse the UK road collision data collected using the
  'STATS19' form. The data are provided as 'CSV' files with detailed road safety data about the
  circumstances of car crashes and other incidents on the roads resulting in 
  casualties in Great Britain from 1979, the types
  (including make and model) of vehicles involved and the consequential casualties.  The
  statistics relate only to personal casualties on public roads that are reported
  to the police, and subsequently recorded, using the 'STATS19' accident reporting form. See
  the Department for Transport website 
  <https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data> for more
  information on these data.",2021-10-29,Robin Lovelace,"https://github.com/ropensci/stats19,
https://docs.ropensci.org/stats19/",TRUE,https://github.com/ropensci/stats19,46922,47,2021-10-25T10:52:00Z,998.3404255319149
statsearchanalyticsr,Pull data from the 'STAT Search Analytics' API <https://help.getstat.com/knowledgebase/api-services/>. It was developed by the Search Discovery team to help analyze keyword ranking data.,2021-09-28,Ben Woodard,https://searchdiscovery.github.io/statsearchanalyticsr/,TRUE,https://github.com/searchdiscovery/statsearchanalyticsr,3057,1,2021-09-28T18:02:13Z,3057
statsExpressions,"Utilities for producing dataframes with rich details for the
    most common types of statistical approaches and tests: parametric,
    nonparametric, robust, and Bayesian t-test, one-way ANOVA, correlation
    analyses, contingency table analyses, and meta-analyses. The
    functions are pipe-friendly and provide a consistent syntax to work
    with tidy data. These dataframes additionally contain expressions with
    statistical details, and can be used in graphing packages. This
    package also forms the statistical processing backend for
    'ggstatsplot'.",2022-05-20,Indrajeet Patil,"https://indrajeetpatil.github.io/statsExpressions/,
https://github.com/IndrajeetPatil/statsExpressions",TRUE,https://github.com/indrajeetpatil/statsexpressions,171760,264,2022-07-05T19:19:35Z,650.6060606060606
stdmod,"Functions for computing a standardized moderation effect
             in moderated regression and forming its confidence interval
             by nonparametric bootstrapping as proposed in
             Cheung, Cheung, Lau, Hui, and Vong (2002)
             <doi:10.1037/hea0001188>. Also includes simple-to-use
             functions for computing conditional effects (unstandardized
             or standardized) and plotting moderation effects.",2022-05-11,Shu Fai Cheung,https://sfcheung.github.io/stdmod/,TRUE,https://github.com/sfcheung/stdmod,409,1,2022-05-13T15:06:17Z,409
stepdownfdp,"Provides a step-down procedure for controlling the False
  Discovery Proportion (FDP) in a competition-based setup, implementing 
  Dong et al. (2020) <arXiv:2011.11939>. Such setups include target-decoy 
  competition (TDC) in computational mass spectrometry and the knockoff 
  construction in linear regression.",2022-03-16,Arya Ebadi,https://github.com/uni-Arya/stepdownfdp,TRUE,https://github.com/uni-arya/stepdownfdp,864,0,2022-03-15T05:14:21Z,NA
stevedata,"This is a collection of various kinds of data with broad uses for teaching. 
    My students, and academics like me who teach the same topics I teach, should find 
    this useful if their teaching workflow is also built around the R programming 
    language. The applications are multiple but mostly cluster on topics of statistical
    methodology, international relations, and political economy.",2022-04-02,Steve Miller,http://svmiller.com/stevedata/,TRUE,https://github.com/svmiller/stevedata,9765,4,2022-04-02T17:38:09Z,2441.25
stevedore,"Work with containers over the Docker API.  Rather than
    using system calls to interact with a docker client, using the
    API directly means that we can receive richer information from
    docker.  The interface in the package is automatically generated
    using the 'OpenAPI' (a.k.a., 'swagger') specification, and all
    return values are checked in order to make them type stable.",2021-10-22,Rich FitzJohn,https://github.com/richfitz/stevedore,TRUE,https://github.com/richfitz/stevedore,27548,121,2021-10-22T11:17:18Z,227.6694214876033
stevemisc,"These are miscellaneous functions that I find useful for my research and teaching.
    The contents include themes for plots, functions for simulating
    quantities of interest from regression models, functions for simulating various 
    forms of fake data for instructional/research purposes, and many more. All told, the functions
    provided here are broadly useful for data organization, data presentation, data recoding, 
    and data simulation. ",2022-04-12,Steve Miller,NA,TRUE,https://github.com/svmiller/stevemisc,8481,3,2022-05-22T11:19:53Z,2827
stfit,A general spatiotemporal satellite image imputation method based on sparse functional data analytic techniques. The imputation method applies and extends the Functional Principal Analysis by Conditional Estimation (PACE). The underlying idea for the proposed procedure is to impute a missing pixel by borrowing information from temporally and spatially contiguous pixels based on the best linear unbiased prediction.  ,2020-10-02,Weicheng Zhu,NA,TRUE,https://github.com/mingsnu/stfit,6449,0,2021-09-12T22:02:32Z,NA
STMr,"Strength training prescription using percent-based approach requires
    numerous computations and assumptions. 'STMr' package allow users to estimate 
    individual reps-max relationships, implement various progression tables, and
    create numerous set and rep schemes. The 'STMr' package is originally created as
    a tool to help writing Jovanović M. (2020) Strength Training Manual
    <ISBN:979-8604459898>.",2022-03-16,Mladen Jovanović,https://mladenjovanovic.github.io/STMr/,TRUE,https://github.com/mladenjovanovic/stmr,929,1,2022-03-15T13:18:05Z,929
stochvol,Efficient algorithms for fully Bayesian estimation of stochastic volatility (SV) models with and without asymmetry (leverage) via Markov chain Monte Carlo (MCMC) methods. Methodological details are given in Kastner and Frühwirth-Schnatter (2014) <doi:10.1016/j.csda.2013.01.002> and Hosszejni and Kastner (2019) <doi:10.1007/978-3-030-30611-3_8>; the most common use cases are described in Hosszejni and Kastner (2021) <doi:10.18637/jss.v100.i12> and Kastner (2016) <doi:10.18637/jss.v069.i05> and the package examples.,2021-11-26,Darjus Hosszejni,https://gregorkastner.github.io/stochvol/,TRUE,https://github.com/gregorkastner/stochvol,44503,9,2022-05-31T07:28:35Z,4944.777777777777
stochvolTMB,"Parameter estimation for stochastic volatility models using maximum likelihood. The latent log-volatility is 
    integrated out of the likelihood using the Laplace approximation. The models are fitted via 'TMB' (Template Model
    Builder) (Kristensen, Nielsen, Berg, Skaug, and Bell (2016) <doi:10.18637/jss.v070.i05>). ",2021-08-13,Jens Christian Wahl,https://github.com/JensWahl/stochvolTMB,TRUE,https://github.com/jenswahl/stochvoltmb,8078,7,2021-08-14T13:08:18Z,1154
stockfish,"An implementation of the UCI open communication protocol that
    ships with 'Stockfish' <https://stockfishchess.org/>, a very popular,
    open source, powerful chess engine written in C++.",2022-03-19,Caio Lente,https://github.com/curso-r/stockfish,TRUE,https://github.com/curso-r/stockfish,5952,28,2022-03-20T04:40:47Z,212.57142857142858
stokes,"Provides functionality for working with tensors, alternating
           tensors, wedge products, Stokes's theorem, and related concepts
	   from the exterior calculus.  Functionality for Grassman algebra
	   is provided.  The canonical reference would be:
	   M. Spivak (1965, ISBN:0-8053-9021-9) ""Calculus on Manifolds"".",2022-06-14,Robin K. S. Hankin,https://github.com/RobinHankin/stokes,TRUE,https://github.com/robinhankin/stokes,11728,2,2022-07-10T10:01:50Z,5864
stopwords,"Provides multiple sources of stopwords, for use in text analysis and natural language processing.",2021-10-28,Kenneth Benoit,https://github.com/quanteda/stopwords,TRUE,https://github.com/quanteda/stopwords,758417,105,2022-01-07T08:58:38Z,7223.019047619047
stortingscrape,"Functions for retrieving general and specific data from the Norwegian Parliament,
  through the Norwegian Parliament API at <https://data.stortinget.no>.",2022-06-07,Martin Søyland,https://github.com/martigso/stortingscrape,TRUE,https://github.com/martigso/stortingscrape,149,1,2022-06-06T21:03:54Z,149
stoRy,"Download, explore, and analyze Literary Theme Ontology themes
    and thematically annotated story data. To learn more about the project
    visit <https://github.com/theme-ontology/theming> and
    <https://themeontology.org>.",2021-11-08,Paul Sheridan,"https://github.com/theme-ontology/stoRy,
https://github.com/theme-ontology/theming,
https://themeontology.org/",TRUE,https://github.com/theme-ontology/story,14687,1,2021-11-08T11:35:28Z,14687
storywranglr,"An interface to explore trends in Twitter data using the 
    'Storywrangler' Application Programming Interface (API), which can be found
    here: <https://github.com/janeadams/storywrangler>.",2021-08-13,Christopher Belanger,https://github.com/chris31415926535/storywranglr,TRUE,https://github.com/chris31415926535/storywranglr,3337,0,2021-08-13T13:00:15Z,NA
stplanr,"Tools for transport planning with an emphasis on spatial transport
    data and non-motorized modes. Enables common transport planning tasks including:
    downloading and cleaning transport datasets; creating geographic ""desire lines""
    from origin-destination (OD) data; route assignment, locally and via
    interfaces to routing services such as <https://cyclestreets.net/> and
    calculation of route segment attributes such as bearing.
    The package implements the 'travel flow aggregration' method
    described in Morgan and Lovelace (2020) <doi:10.1177/2399808320942779>.
    Further information on the package's aim and scope can be found
    in the vignettes and in a paper in the R Journal
    (Lovelace and Ellison 2018) <doi:10.32614/RJ-2018-053>.
    This package Suggests the 'pct' package which at the time of writing
    is unavailable on CRAN. You can install it from the repository
    'itsleeds/pct' on GitHub.",2022-06-10,Robin Lovelace,"https://github.com/ropensci/stplanr,
https://docs.ropensci.org/stplanr/",TRUE,https://github.com/ropensci/stplanr,65441,383,2022-06-11T10:00:10Z,170.86422976501305
stppSim,"Generates artificial spatiotemporal (ST) point patterns 
  through the integration of microsimulation 
  (Holm, E., (2017)<doi:10.1002/9781118786352.wbieg0320>) 
  and agent-based models 
  (Bonabeau, E., (2002)<doi:10.1073/pnas.082080899>). 
  Allows a user to define the behaviours of a set of 'walkers' (agents, 
  objects, persons, etc.) whose interactions with the spatial (landscape) 
  (Quaglietta, L. and Porto, M., (2019)<doi:10.1186/s40462-019-0154-8>)
  and the temporal domains produce new point events. The resulting ST 
  patterns from the point cloud can be measured and utilized for spatial 
  and/or temporal model testings and evaluations. Application: With 
  increasingly limited availability of fine-grained spatially and 
  temporally stamped point data, the package provides an alternative 
  source of data for a wide range of research in social and life sciences.",2022-04-04,Monsuru Adepeju,https://github.com/MAnalytics/stppSim,TRUE,https://github.com/manalytics/stppsim,1229,1,2022-04-04T08:26:54Z,1229
stratallo,"Functions in this package provide solution to classical problem in
  survey methodology - an optimum sample allocation in stratified sampling
  schemes. In this context, the optimal allocation is in the classical
  Tschuprov-Neyman's sense and it satisfies additional either lower or upper
  bounds restrictions imposed on sample sizes in strata. There are few different
  algorithms available to use, and one them is based on popular sample
  allocation method that applies Neyman allocation to recursively reduced set of
  strata.
  This package also provides the function that computes a solution to the minimum
  sample size allocation problem, which is a minor modification of the classical
  optimium sample allocation. This problems lies in the determination
  of a vector of strata sample sizes that minimizes total sample size, under
  assumed fixed level of the pi-estimator's variance. As in the case of the
  classical optimal allocation, the problem of minimum sample size allocation
  can be complemented by imposing upper bounds constraints on sample sizes in
  strata.",2022-04-13,Wojciech Wójciak,https://github.com/wwojciech/stratallo,TRUE,https://github.com/wwojciech/stratallo,10351,0,2022-04-20T09:59:43Z,NA
stratamatch,"A pilot matching design to automatically 
    stratify and match large datasets.  The manual_stratify() function allows
    users to manually stratify a dataset based on categorical variables of 
    interest, while the auto_stratify() function does automatically by
    allocating a held-aside (pilot) data set, fitting a prognostic score  
    (see Hansen (2008) <doi:10.1093/biomet/asn004>) on the pilot set, and stratifying the data set based
    on prognostic score quantiles.  The strata_match() function then does optimal
    matching of the data set in parallel within strata.",2022-03-31,Rachael C. Aikens,https://github.com/raikens1/stratamatch,TRUE,https://github.com/raikens1/stratamatch,17350,3,2022-03-01T00:31:09Z,5783.333333333333
stratEst,"Variants of strategy estimation (Dal Bo & Frechette, 2011, <doi:10.1257/aer.101.1.411>), including the model with parameters for the choice probabilities of the strategies (Breitmoser, 2015, <doi:10.1257/aer.20130675>), and the model with individual level covariates for the selection of strategies by individuals (Dvorak & Fehrler, 2018, <doi:10.2139/ssrn.2986445>). ",2021-10-05,Fabian Dvorak,https://github.com/fdvorak/stratEst,TRUE,https://github.com/fdvorak/stratest,12649,3,2021-10-18T08:54:34Z,4216.333333333333
StratifiedMedicine,"A toolkit for stratified medicine, subgroup identification, and precision medicine.
    Current tools include (1) filtering models (reduce covariate space), (2) patient-level estimate
    models (counterfactual patient-level quantities, such as the conditional average treatment effect), 
    (3) subgroup identification models (find subsets of patients with similar treatment effects), 
    and (4) treatment effect estimation and inference (for the overall population and discovered 
    subgroups). These tools can be customized and are directly used in PRISM 
    (patient response identifiers for stratified medicine; Jemielita and Mehrotra 2019
    <arXiv:1912.03337>. This package is in beta and will be continually updated.",2022-03-29,Thomas Jemielita,https://github.com/thomasjemielita/StratifiedMedicine,TRUE,https://github.com/thomasjemielita/stratifiedmedicine,15796,2,2022-04-03T18:44:19Z,7898
StratifiedSampling,"Integrating a stratified structure in the population in a sampling design can considerably reduce the variance of the Horvitz-Thompson estimator. We propose in this package different methods to handle the selection of a balanced sample in stratified population. For more details see Raphaël Jauslin, Esther Eustache and Yves Tillé (2021) <arXiv:2101.05568>. The package propose also a method based on optimal transport and balanced sampling, see Raphaël Jauslin and Yves Tillé <arXiv:2105.08379>.",2021-09-24,Raphael Jauslin,https://github.com/RJauslin/StratifiedSampling,TRUE,https://github.com/rjauslin/stratifiedsampling,6402,0,2022-07-04T12:43:55Z,NA
stray,"
    This is a modification of 'HDoutliers' package. The 'HDoutliers' algorithm is a powerful 
    unsupervised algorithm for detecting anomalies in high-dimensional data, with a 
    strong theoretical foundation. However, it suffers from some limitations that 
    significantly hinder its performance level, under certain circumstances. This package 
    implements the algorithm proposed in Talagala, Hyndman and Smith-Miles (2019) 
    <arXiv:1908.04000>  for detecting anomalies in high-dimensional data
    that addresses these limitations of 'HDoutliers' algorithm. We define an anomaly as an observation that deviates markedly from the majority
    with a large distance gap. An approach based on extreme value theory is used 
    for the anomalous threshold calculation.",2020-06-29,Priyanga Dilini Talagala,NA,TRUE,https://github.com/pridiltal/stray,12049,54,2022-03-10T04:29:42Z,223.12962962962962
stream,A framework for data stream modeling and associated data mining tasks such as clustering and classification. The development of this package was supported in part by NSF IIS-0948893 and NIH R21HG005912. Hahsler et al (2017) <doi:10.18637/jss.v076.i14>.,2022-05-09,Michael Hahsler,https://github.com/mhahsler/stream,TRUE,https://github.com/mhahsler/stream,25021,29,2022-07-07T00:57:07Z,862.7931034482758
streamMOA,"Interface for data stream clustering algorithms implemented in the MOA (Massive Online Analysis) framework (Albert Bifet, Geoff Holmes, Richard Kirkby, Bernhard Pfahringer (2010). MOA: Massive Online Analysis, Journal of Machine Learning Research 11: 1601-1604).",2022-05-10,Michael Hahsler,NA,TRUE,https://github.com/mhahsler/streammoa,17082,10,2022-07-07T15:54:13Z,1708.2
string2path,"Extract glyph information from a font file, and translate the
    outline curves to flattened paths or tessellated polygons. The converted
    data is returned as a 'data.frame' in easy-to-plot format.",2021-11-22,Hiroaki Yutani,"https://yutannihilation.github.io/string2path/,
https://github.com/yutannihilation/string2path",TRUE,https://github.com/yutannihilation/string2path,3625,71,2022-05-14T06:38:41Z,51.056338028169016
stringdist,"Implements an approximate string matching version of R's native
    'match' function. Also offers fuzzy text search based on various string
     distance measures. Can calculate various string distances based on edits
    (Damerau-Levenshtein, Hamming, Levenshtein, optimal sting alignment), qgrams (q-
    gram, cosine, jaccard distance) or heuristic metrics (Jaro, Jaro-Winkler). An
    implementation of soundex is provided as well. Distances can be computed between
    character vectors while taking proper care of encoding or between integer
    vectors representing generic sequences. This package is built for speed and
    runs in parallel by using 'openMP'. An API for C or C++ is exposed as well.
    Reference: MPJ van der Loo (2014) <doi:10.32614/RJ-2014-011>.",2021-09-09,Mark van der Loo,https://github.com/markvanderloo/stringdist,TRUE,https://github.com/markvanderloo/stringdist,1125256,280,2021-10-06T08:08:03Z,4018.7714285714287
stringfish,"Provides an extendable, performant and multithreaded 'alt-string' implementation backed by 'C++' vectors and strings.",2022-04-13,Travers Ching,https://github.com/traversc/stringfish,TRUE,https://github.com/traversc/stringfish,138320,55,2022-04-13T06:00:06Z,2514.909090909091
stringi,"A collection of character string/text/natural language
    processing tools for pattern searching (e.g., with 'Java'-like regular
    expressions or the 'Unicode' collation algorithm), random string generation,
    case mapping, string transliteration, concatenation, sorting, padding,
    wrapping, Unicode normalisation, date-time formatting and parsing,
    and many more. They are fast, consistent, convenient, and -
    thanks to 'ICU' (International Components for Unicode) -
    portable across all locales and platforms.",2021-11-29,Marek Gagolewski,https://stringi.gagolewski.com/ https://icu.unicode.org/,TRUE,https://github.com/gagolews/stringi,25887469,251,2022-07-02T09:04:08Z,103137.32669322709
stringr,"A consistent, simple and easy to use set of
    wrappers around the fantastic 'stringi' package. All function and
    argument names (and positions) are consistent, all functions deal with
    ""NA""'s and zero length vectors in the same way, and the output from
    one function is easy to feed into the input of another.",2019-02-10,Hadley Wickham,"http://stringr.tidyverse.org, https://github.com/tidyverse/stringr",TRUE,https://github.com/tidyverse/stringr,25533377,471,2022-04-14T22:18:03Z,54210.991507431
stringx,"English is the native language for only 5% of the World population.
    Also, only 17% of us can understand this text. Moreover, the Latin alphabet
    is the main one for merely 36% of the total.
    The early computer era, now a very long time ago, was dominated by the US.
    Due to the proliferation of the internet, smartphones, social media, and
    other technologies and communication platforms, this is no longer the case.
    This package replaces base R string functions (such as grep(),
    tolower(), sprintf(), and strptime()) with ones that fully
    support the Unicode standards related to natural language and
    date-time processing. It also fixes some long-standing inconsistencies,
    and introduces some new, useful features.
    Thanks to 'ICU' (International Components for Unicode) and 'stringi',
    they are fast, reliable, and portable across different platforms.",2021-09-03,Marek Gagolewski,https://stringx.gagolewski.com/,TRUE,https://github.com/gagolews/stringx,2658,15,2022-02-09T00:59:06Z,177.2
striprtf,Extracts plain text from RTF (Rich Text Format) file.,2021-09-07,Kota Mori,https://github.com/kota7/striprtf,TRUE,https://github.com/kota7/striprtf,152511,16,2021-09-07T14:32:48Z,9531.9375
strm,"Implements a spatio-temporal regression model based on Chi, G. and Zhu, J. (2019) Spatial Regression Models for the Social Sciences <isbn:9781544302072>. The approach here fits a spatial error model while incorporating a temporally lagged response variable and temporally lagged explanatory variables. This package builds on the errorsarlm() function from the spatialreg package.",2022-01-19,Maria Kamenetsky,NA,TRUE,https://github.com/mkamenet3/strm,6816,1,2022-01-10T15:58:12Z,6816
strucchangeRcpp,"A fast implementation with additional experimental features for
             testing, monitoring and dating structural changes in (linear)
             regression models. 'strucchangeRcpp' features tests/methods from
	     the generalized fluctuation test framework as well as from
	     the F test (Chow test) framework. This includes methods to
             fit, plot and test fluctuation processes (e.g. cumulative/moving
             sum, recursive/moving estimates) and F statistics, respectively.
             These methods are described in Zeileis et al. (2002)
             <doi:10.18637/jss.v007.i02>.
             Finally, the breakpoints in regression models with structural
             changes can be estimated together with confidence intervals,
             and their magnitude as well as the model fit can be evaluated
             using a variety of statistical measures.",2021-11-26,Dainius Masiliunas,https://github.com/bfast2/strucchangeRcpp/,TRUE,https://github.com/bfast2/strucchangercpp,15266,4,2021-11-25T15:43:46Z,3816.5
strvalidator,"An open source platform for validation and process control.
    Tools to analyze data from internal validation of forensic short tandem
    repeat (STR) kits are provided. The tools are developed to provide
    the necessary data to conform with guidelines for internal validation
    issued by the European Network of Forensic Science Institutes (ENFSI)
    DNA Working Group, and the Scientific Working Group on DNA Analysis Methods
    (SWGDAM). A front-end graphical user interface is provided.
    More information about each function can be found in the
    respective help documentation.",2020-07-10,Oskar Hansson,https://sites.google.com/site/forensicapps/strvalidator,TRUE,https://github.com/oskarhansson/strvalidator,19466,4,2022-07-10T00:55:59Z,4866.5
styler,"Pretty-prints R code without changing the user's formatting
    intent.",2022-03-13,Lorenz Walthert,"https://github.com/r-lib/styler, https://styler.r-lib.org",TRUE,https://github.com/r-lib/styler,1571066,570,2022-07-10T16:39:58Z,2756.256140350877
stylo,"Supervised and unsupervised multivariate methods, supplemented by GUI and some visualizations, to perform various analyses in the field of computational stylistics, authorship attribution, etc. For further reference, see Eder et al. (2016), <https://journal.r-project.org/archive/2016/RJ-2016-007/index.html>. You are also encouraged to visit the Computational Stylistics Group's website <https://computationalstylistics.github.io/>, where a reasonable amount of information about the package and related projects are provided.",2020-12-06,Maciej Eder,https://github.com/computationalstylistics/stylo,TRUE,https://github.com/computationalstylistics/stylo,51522,127,2022-05-30T21:21:19Z,405.68503937007875
subformula,"A formula 'sub' is a subformula of 'formula' if all the terms
    on the right hand side of 'sub' are terms of 'formula' and their left hand 
    sides are identical. This package aids in the creation of subformulas.",2019-11-15,Jonas Moss,"https://github.com/JonasMoss/subformula,",TRUE,https://github.com/jonasmoss/subformula,9770,1,2022-01-27T06:10:28Z,9770
subplex,"The subplex algorithm for unconstrained optimization, developed by Tom Rowan <http://www.netlib.org/opt/subplex.tgz>.",2022-04-12,Aaron A. King,https://github.com/kingaa/subplex/,TRUE,https://github.com/kingaa/subplex,161669,7,2022-05-18T19:09:33Z,23095.571428571428
subsemble,"The Subsemble algorithm is a general subset ensemble prediction method, which can be used for small, moderate, or large datasets. Subsemble partitions the full dataset into subsets of observations, fits a specified underlying algorithm on each subset, and uses a unique form of k-fold cross-validation to output a prediction function that combines the subset-specific fits. An oracle result provides a theoretical performance guarantee for Subsemble. The paper, ""Subsemble: An ensemble method for combining subset-specific algorithm fits"" is authored by Stephanie Sapp, Mark J. van der Laan & John Canny (2014) <doi:10.1080/02664763.2013.864263>. ",2022-01-24,Erin LeDell,https://github.com/ledell/subsemble,TRUE,https://github.com/ledell/subsemble,2442,40,2022-01-21T08:03:18Z,61.05
success,"Quality control charts for survival outcomes.
    Allows users to construct the Continuous Time Generalized
    Rapid Response CUSUM (CGR-CUSUM), the Biswas & Kalbfleisch (2008)
    <doi:10.1002/sim.3216> CUSUM, the Bernoulli CUSUM and the
    risk-adjusted funnel plot for survival data. These procedures can be
    used to monitor survival processes for a change in the failure rate.",2022-04-15,Daniel Gomon,https://github.com/d-gomon/success,TRUE,https://github.com/d-gomon/success,648,1,2022-06-28T09:16:42Z,648
sudachir,"Interface to 'Sudachi' <https://github.com/WorksApplications/Sudachi>,
    a Japanese morphological analyzer. This is a port of what is available in Python.",2020-11-10,Shinya Uryu,https://github.com/uribo/sudachir,TRUE,https://github.com/uribo/sudachir,5890,5,2022-01-19T09:51:13Z,1178
suddengains,"Identify sudden gains based on the three criteria outlined by Tang and DeRubeis (1999) <doi:10.1037/0022-006X.67.6.894> to a selection of repeated measures. Sudden losses, defined as the opposite of sudden gains can also be identified. Two different datasets can be created, one including all sudden gains/losses and one including one selected sudden gain/loss for each case. It can extract scores around sudden gains/losses. It can plot the average change around sudden gains/losses and trajectories of individual cases.",2020-05-22,Milan Wiedemann,https://milanwiedemann.github.io/suddengains/,TRUE,https://github.com/milanwiedemann/suddengains,13441,4,2021-07-27T11:32:41Z,3360.25
summariser,"Functions to speed up the exploratory analysis of simple
    datasets using 'dplyr'. Functions are provided to do the 
    common tasks of calculating confidence intervals.",2020-03-30,Conor Neilson,https://github.com/condwanaland/summariser,TRUE,https://github.com/condwanaland/summariser,17866,0,2021-08-29T04:42:25Z,NA
summarytools,"Data frame summaries, cross-tabulations,
  weight-enabled frequency tables and common descriptive
  (univariate) statistics in concise tables available in a
  variety of formats (plain ASCII, Markdown and HTML). A good 
  point-of-entry for exploring data, both for experienced
  and new R users.",2022-05-20,Dominic Comtois,https://github.com/dcomtois/summarytools,TRUE,https://github.com/dcomtois/summarytools,388745,442,2021-08-11T04:56:57Z,879.5135746606335
SUMMER,"Provides methods for spatial and spatio-temporal smoothing of demographic and health indicators using survey data, with particular focus on estimating and projecting under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>, Li et al. (2019) <doi:10.1371/journal.pone.0210645> and Li et al. (2020) <arXiv:2007.05117>. ",2022-07-08,Zehang R Li,https://github.com/richardli/SUMMER,TRUE,https://github.com/richardli/summer,16276,14,2022-07-07T23:57:42Z,1162.5714285714287
sumSome,"It allows to quickly perform permutation-based closed testing by sum-based global tests, and construct lower confidence bounds for the TDP, simultaneously over all subsets of hypotheses. As a main feature, it produces simultaneous lower confidence bounds for the proportion of active voxels in different clusters for fMRI cluster analysis. Details may be found in Vesely, Finos, and Goeman (2020) <arXiv:2102.11759>.",2021-11-24,Anna Vesely,https://github.com/annavesely/sumSome,TRUE,https://github.com/annavesely/sumsome,1793,0,2022-06-29T18:07:22Z,NA
sunburstR,"Make interactive 'd3.js' sequence sunburst diagrams in R with the
    convenience and infrastructure of an 'htmlwidget'.",2021-09-19,Mike Bostock,https://github.com/timelyportfolio/sunburstR,TRUE,https://github.com/timelyportfolio/sunburstr,104010,196,2022-06-13T02:04:04Z,530.6632653061224
sundialr,"Provides a way to call the functions in 'SUNDIALS' C ODE solving library (<https://computing.llnl.gov/projects/sundials>). Currently the serial version of ODE solver, 'CVODE', sensitivity calculator 'CVODES' and differential algebraic solver 'IDA' from the 'SUNDIALS' library are implemented. The package requires ODE to be written as an 'R' or 'Rcpp' function and does not require the 'SUNDIALS' library to be installed on the local machine.",2021-05-16,Satyaprakash Nayak,https://github.com/sn248/sundialr,TRUE,https://github.com/sn248/sundialr,13864,10,2021-12-07T04:45:37Z,1386.4
SUNGEO,Tools for integrating spatially-misaligned GIS datasets. Part of the Sub-National Geospatial Data Archive System.,2022-01-31,Jason Byers,<https://github.com/zhukovyuri/SUNGEO>,TRUE,https://github.com/zhukovyuri/sungeo,14009,3,2022-01-31T22:47:28Z,4669.666666666667
supc,"Implements the self-updating process clustering algorithms proposed
    in Shiu and Chen (2016) <doi:10.1080/00949655.2015.1049605>.",2021-12-11,Wush Wu,https://github.com/wush978/supc,TRUE,https://github.com/wush978/supc,13786,9,2021-10-08T17:40:04Z,1531.7777777777778
supclust,"Methodology for supervised grouping aka ""clustering"" of
   potentially many predictor variables, such as genes etc, implementing
   algorithms 'PELORA' and 'WILMA'.",2021-09-27,Marcel Dettling <marcel.dettling@zhaw.ch> and Martin Maechler,https://github.com/mmaechler/supclust,TRUE,https://github.com/mmaechler/supclust,17668,0,2021-09-25T17:10:32Z,NA
superb,"
    Computes standard error and confidence interval of various descriptive statistics under 
    various designs and sampling schemes. The main function, superbPlot(), can either return a plot 
    or a dataframe with the statistic and its precision interval so that other plotting package
    can be used. See Cousineau and colleagues (2021) <doi:10.1177/25152459211035109> 
    or Cousineau (2017) <doi:10.5709/acp-0214-z> for a review as well as Cousineau (2005)
    <doi:10.20982/tqmp.01.1.p042>, Morey (2008) <doi:10.20982/tqmp.04.2.p061>, Baguley (2012)
    <doi:10.3758/s13428-011-0123-7>, Cousineau & Laurencelle (2016) <doi:10.1037/met0000055>,
    Cousineau & O'Brien (2014) <doi:10.3758/s13428-013-0441-z>, Calderini & Harding 
    <doi:10.20982/tqmp.15.1.p001> for specific references.",2022-05-11,Denis Cousineau,https://dcousin3.github.io/superb/,TRUE,https://github.com/dcousin3/superb,6614,15,2022-07-09T13:33:54Z,440.93333333333334
supercells,"Creates superpixels based on input spatial data. 
  This package works on spatial data with one variable (e.g., continuous raster), many variables (e.g., RGB rasters), and spatial patterns (e.g., areas in categorical rasters).
  It is based on the SLIC algorithm (Achanta et al. (2012) <doi:10.1109/TPAMI.2012.120>), and readapts it to work with arbitrary dissimilarity measures. ",2022-06-04,Jakub Nowosad,https://jakubnowosad.com/supercells/,TRUE,https://github.com/nowosad/supercells,1569,43,2022-06-02T22:23:39Z,36.48837209302326
SuperExactTest,"Identification of sets of objects with shared features is a common operation in all disciplines. Analysis of intersections among multiple sets is fundamental for in-depth understanding of their complex relationships. This package implements a theoretical framework for efficient computation of statistical distributions of multi-set intersections based upon combinatorial theory, and provides multiple scalable techniques for visualizing the intersection statistics. The statistical algorithm behind this package was published in Wang et al. (2015) <doi:10.1038/srep16923>.",2022-03-23,Minghui Wang,https://github.com/mw201608/SuperExactTest/,TRUE,https://github.com/mw201608/superexacttest,16706,14,2022-05-06T04:38:55Z,1193.2857142857142
SuperLearner,"Implements the super learner prediction method and contains a
    library of prediction algorithms to be used in the super learner.",2021-05-10,Eric Polley,https://github.com/ecpolley/SuperLearner,TRUE,https://github.com/ecpolley/superlearner,124839,231,2021-11-29T21:07:27Z,540.4285714285714
superml,"The idea is to provide a standard interface 
             to users who use both R and Python for building machine learning models. 
             This package provides a scikit-learn's fit, predict interface to 
             train machine learning models in R.    ",2022-05-23,Manish Saraswat,https://github.com/saraswatmks/superml,TRUE,https://github.com/saraswatmks/superml,112667,30,2022-05-23T14:33:24Z,3755.5666666666666
supernova,"Produces ANOVA tables in the format used by Judd, McClelland, and Ryan 
    (2017, ISBN: 978-1138819832) in their introductory textbook, Data Analysis. This includes 
    proportional reduction in error and formatting to improve ease the transition between the book 
    and R.",2022-01-27,Adam Blake,https://github.com/UCLATALL/supernova,TRUE,https://github.com/uclatall/supernova,19780,62,2022-02-01T16:41:39Z,319.03225806451616
SuperpixelImageSegmentation,"Image Segmentation using Superpixels, Affinity Propagation and Kmeans Clustering. The R code is based primarily on the article ""Image Segmentation using SLIC Superpixels and Affinity Propagation Clustering, Bao Zhou, International Journal of Science and Research (IJSR), 2013"" <https://www.ijsr.net/archive/v4i4/SUB152869.pdf>. ",2022-02-06,Lampros Mouselimis,https://github.com/mlampros/SuperpixelImageSegmentation,TRUE,https://github.com/mlampros/superpixelimagesegmentation,15146,10,2022-02-07T07:42:12Z,1514.6
Superpower,"Functions to perform simulations of ANOVA designs of up to three factors. Calculates the observed power and average observed effect size for all main effects and interactions in the ANOVA, and all simple comparisons between conditions. Includes functions for analytic power calculations and additional helper functions that compute effect sizes for ANOVA designs, observed error rates in the simulations, and functions to plot power curves. Please see Lakens, D., & Caldwell, A. R. (2021). ""Simulation-Based Power Analysis for Factorial Analysis of Variance Designs"". <doi:10.1177/2515245920951503>.",2022-05-17,Aaron Caldwell,https://aaroncaldwell.us/SuperpowerBook/,TRUE,https://github.com/arcaldwell49/superpower,18933,50,2022-05-16T17:44:41Z,378.66
suppdata,"Downloads data supplementary materials from manuscripts,
    using papers' DOIs as references. Facilitates open, reproducible
    research workflows: scientists re-analyzing published datasets can
    work with them as easily as if they were stored on their own
    computer, and others can track their analysis workflow
    painlessly. The main function suppdata() returns a (temporary)
    location on the user's computer where the file is stored, making
    it simple to use suppdata() with standard functions like
    read.csv().",2021-11-18,William D. Pearse,"https://docs.ropensci.org/suppdata/,
https://github.com/ropensci/suppdata/",TRUE,https://github.com/ropensci/suppdata,14404,29,2021-11-18T15:34:47Z,496.6896551724138
surveil,"Fits time series models for routine disease surveillance tasks and returns probability distributions for a variety of quantities of interest, including age-standardized rates, period and cumulative percent change, and measures of health inequality. Calculates Theil's index to measure inequality among multiple groups, and can be extended to measure inequality across multiple groups nested within geographies. Inference is completed using Markov chain Monte Carlo via the Stan modeling language. The models are appropriate for count data such as disease incidence and mortality data, employing a Poisson or binomial likelihood and the first-difference (random-walk) prior for unknown risk. Optionally add a covariance matrix for multiple, correlated time series models. References: Brandt and Williams (2007, ISBN:978-1-4129-0656-2); Clayton (1996, ISBN-13:978-0-412-05551-5); Stan Development Team (2021) <https://mc-stan.org>; Theil (1972, ISBN:0-444-10378-3).",2022-04-03,Connor Donegan,"https://connordonegan.github.io/surveil/,
https://github.com/ConnorDonegan/surveil/,
https://github.com/ConnorDonegan/surveil/,
https://cran.r-project.org/web//packages/surveil/",TRUE,https://github.com/connordonegan/surveil,2215,2,2022-04-03T17:50:36Z,1107.5
surveyCV,"Functions to generate K-fold cross validation (CV) folds
    and CV test error estimates that take into account
    how a survey dataset's sampling design was constructed
    (SRS, clustering, stratification, and/or unequal sampling weights).
    You can input linear and logistic regression models, along with data and a 
    type of survey design in order to get an output that can help you determine
    which model best fits the data using K-fold cross validation.
    Our paper on ""K-Fold Cross-Validation for Complex Sample Surveys""
    by Wieczorek, Guerin, and McMahon (2022)
    <doi:10.1002/sta4.454>
    explains why differing how we take folds based on survey design is useful.",2022-03-15,Jerzy Wieczorek,https://github.com/ColbyStatSvyRsch/surveyCV/,TRUE,https://github.com/colbystatsvyrsch/surveycv,1463,3,2022-05-26T20:20:09Z,487.6666666666667
surveyplanning,"Tools for sample survey planning, including sample size calculation, estimation of expected precision for the estimates of totals, and calculation of optimal sample size allocation.",2020-05-20,Juris Breidaks,https://csblatvia.github.io/surveyplanning/,TRUE,https://github.com/csblatvia/surveyplanning,19699,6,2021-09-09T17:18:09Z,3283.1666666666665
surveysd,Calculate point estimates and their standard errors in complex household surveys using bootstrap replicates. Bootstrapping considers survey design with a rotating panel. A comprehensive description of the methodology can be found under <https://statistikat.github.io/surveysd/articles/methodology.html>.,2020-12-10,Johannes Gussenbauer,https://github.com/statistikat/surveysd,TRUE,https://github.com/statistikat/surveysd,13613,6,2022-02-16T08:39:03Z,2268.8333333333335
survival,"Contains the core survival analysis routines, including
	     definition of Surv objects, 
	     Kaplan-Meier and Aalen-Johansen (multi-state) curves, Cox models,
	     and parametric accelerated failure time models.",2022-03-03,Terry M Therneau,https://github.com/therneau/survival,TRUE,https://github.com/therneau/survival,4567795,237,2022-06-20T13:42:09Z,19273.396624472574
survival.svb,"Implementation of methodology designed to perform: (i) variable 
    selection, (ii) effect estimation, and (iii) uncertainty quantification, 
    for high-dimensional survival data. Our method uses a spike-and-slab prior 
    with Laplace slab and Dirac spike and approximates the corresponding 
    posterior using variational inference, a popular method in machine learning 
    for scalable conditional inference. Although approximate, the variational 
    posterior provides excellent point estimates and good control of the false 
    discovery rate. For more information see Komodromos et al. (2021) 
    <arXiv:2112.10270>.",2022-01-17,Michael Komodromos,https://github.com/mkomod/survival.svb,TRUE,https://github.com/mkomod/survival.svb,1543,4,2022-03-21T14:35:11Z,385.75
survivalmodels,"Implementations of classical and machine learning models for survival analysis, including deep neural networks via 'keras' and 'tensorflow'. Each model includes a separated fit and predict interface with consistent prediction types for predicting risk, survival probabilities, or survival distributions with 'distr6' <https://CRAN.R-project.org/package=distr6>. Models are either implemented from 'Python' via 'reticulate' <https://CRAN.R-project.org/package=reticulate>, from code in GitHub packages, or novel implementations using 'Rcpp' <https://CRAN.R-project.org/package=Rcpp>. Novel machine learning survival models wil be included in the package in near-future updates. Neural networks are implemented from the 'Python' package 'pycox' <https://github.com/havakv/pycox> and are detailed by Kvamme et al. (2019) <https://jmlr.org/papers/v20/18-424.html>. The 'Akritas' estimator is defined in Akritas (1994) <doi:10.1214/aos/1176325630>. 'DNNSurv' is defined in Zhao and Feng (2020) <arXiv:1908.02337>.",2022-03-24,Raphael Sonabend,https://github.com/RaphaelS1/survivalmodels/,TRUE,https://github.com/raphaels1/survivalmodels,23445,27,2022-03-26T11:02:25Z,868.3333333333334
SurvivalPath,"Facilitates building personalized survival path models. The function survivalpath() return tree structure results, which can be used to draw easily beautiful and ready-to-publish survival path tree. See Shen L, et al (2018) <doi:10.1038/s41467-018-04633-7> .",2022-07-03,Zhang Tao,https://github.com/zhangt369/SurvivalPath,TRUE,https://github.com/zhangt369/survivalpath,103,1,2022-06-10T14:07:17Z,103
survivoR,"Several datasets which detail the results and events of each season of Survivor. This includes 
  details on the cast, voting history, immunity and reward challenges, jury votes and viewers. This data is 
  useful for practicing data wrangling, graph analytics and analysing how each season of Survivor played out. 
  Includes 'ggplot2' scales and colour palettes for visualisation.",2022-05-31,Daniel Oehm,https://github.com/doehm/survivoR,TRUE,https://github.com/doehm/survivor,8060,24,2022-07-04T11:56:35Z,335.8333333333333
SurvMetrics,"An implementation of popular evaluation metrics that are commonly used in survival prediction 
  including Concordance Index, Brier Score, Integrated Brier Score, 
  Integrated Square Error, Integrated Absolute Error and Mean Absolute Error.
  For a detailed information, see (Ishwaran H, Kogalur UB, Blackstone EH and Lauer MS (2008) <doi:10.1214/08-AOAS169>) and
  (Moradian H, Larocque D and Bellavance F (2017) <doi:10.1007/s10985-016-9372-1>) for different evaluation metrics.",2022-03-08,Hanpu Zhou,https://github.com/skyee1/SurvMetrics,TRUE,https://github.com/skyee1/survmetrics,3991,6,2022-04-12T13:55:58Z,665.1666666666666
survMS,"Package enables the data simulation from different survival models (Cox, AFT, and AH models). The simulated data will have various levels of complexity according to the survival model considered. The implemented methods for the Cox model are described in Ralf Bender, Thomas Augustin, Maria Blettner (2004) <doi:10.1002/sim.2059>.",2021-04-16,Mathilde Sautreuil,https://github.com/mathildesautreuil/survMS/,TRUE,https://github.com/mathildesautreuil/survms,4111,4,2022-06-08T20:27:49Z,1027.75
survParamSim,"Perform survival simulation with parametric survival model generated from 'survreg' function in 'survival' package.
    In each simulation coefficients are resampled from variance-covariance matrix of parameter estimates to 
    capture uncertainty in model parameters.
    Prediction intervals of Kaplan-Meier estimates and hazard ratio of treatment effect can be further calculated using simulated survival data.",2022-06-03,Kenta Yoshida,https://github.com/yoshidk6/survParamSim,TRUE,https://github.com/yoshidk6/survparamsim,13876,1,2022-06-02T19:24:49Z,13876
survPen,"Fits hazard and excess hazard models with multidimensional penalized splines allowing for 
        time-dependent effects, non-linear effects and interactions between several continuous covariates. In survival and net survival analysis, in addition to modelling the effect of time (via the baseline hazard), one has often to deal with several continuous covariates and model their functional forms, their time-dependent effects, and their interactions. Model specification becomes therefore a complex problem and penalized regression splines represent an appealing solution to that problem as splines offer the required flexibility while penalization limits overfitting issues. Current implementations of penalized survival models can be slow or unstable and sometimes lack some key features like taking into account expected mortality to provide net survival and excess hazard estimates. In contrast, survPen provides an automated, fast, and stable implementation (thanks to explicit calculation of the derivatives of the likelihood) and offers a unified framework for 
        multidimensional penalized hazard and excess hazard models. survPen may be of interest to those who 1) analyse any kind of time-to-event data: mortality, disease relapse, machinery breakdown, unemployment, etc 2) wish to describe the associated hazard and to understand which predictors impact its dynamics. 
	See Fauvernier et al. (2019a) <doi:10.21105/joss.01434> for an overview of the package and Fauvernier et al. (2019b) <doi:10.1111/rssc.12368> for the method.",2021-09-11,Mathieu Fauvernier,https://github.com/fauvernierma/survPen,TRUE,https://github.com/fauvernierma/survpen,19782,3,2022-07-01T09:55:30Z,6594
survtmle,"Targeted estimates of marginal cumulative incidence in survival
    settings with and without competing risks, including estimators that respect
    bounds (Benkeser, Carone, and Gilbert. Statistics in Medicine, 2017.
    <doi:10.1002/sim.7337>).",2019-04-16,David Benkeser,https://github.com/benkeser/survtmle,TRUE,https://github.com/benkeser/survtmle,13745,18,2022-01-10T20:44:22Z,763.6111111111111
susieR,"Implements methods for variable selection in linear
    regression based on the ""Sum of Single Effects"" (SuSiE) model, as
    described in Wang et al (2020) <DOI:10.1101/501114> and Zou et al
    (2021) <DOI:10.1101/2021.11.03.467167>. These methods provide
    simple summaries, called ""Credible Sets"", for accurately
    quantifying uncertainty in which variables should be selected.
    The methods are motivated by genetic fine-mapping applications,
    and are particularly well-suited to settings where variables are
    highly correlated and detectable effects are sparse. The fitting
    algorithm, a Bayesian analogue of stepwise selection methods
    called ""Iterative Bayesian Stepwise Selection"" (IBSS), is simple
    and fast, allowing the SuSiE model be fit to large data sets
    (thousands of samples and hundreds of thousands of variables).",2022-06-27,Peter Carbonetto,https://github.com/stephenslab/susieR,TRUE,https://github.com/stephenslab/susier,13691,116,2022-07-07T01:31:43Z,118.02586206896552
svd,"R bindings to SVD and eigensolvers (PROPACK, nuTRLan).",2022-03-28,Anton Korobeynikov,https://github.com/asl/svd,TRUE,https://github.com/asl/svd,251899,23,2022-07-09T11:46:21Z,10952.130434782608
svDialogs,"Quickly construct standard dialog boxes for your GUI, including 
  message boxes, input boxes, list, file or directory selection, ... In case R
  cannot display GUI dialog boxes, a simpler command line version of these
  interactive elements is also provided as fallback solution.",2022-05-10,Philippe Grosjean,"https://github.com/SciViews/svDialogs,
https://www.sciviews.org/svDialogs/",TRUE,https://github.com/sciviews/svdialogs,154780,5,2022-05-10T04:41:29Z,30956
svDialogstcltk,Reimplementation of the 'svDialogs' dialog boxes in Tcl/Tk.,2022-05-10,Philippe Grosjean,"https://github.com/SciViews/svDialogstcltk,
https://www.sciviews.org/svDialogstcltk/",TRUE,https://github.com/sciviews/svdialogstcltk,13321,0,2022-05-10T16:08:50Z,NA
svglite,"A graphics device for R that produces 'Scalable Vector Graphics'.
  'svglite' is a fork of the older 'RSvgDevice' package.",2022-02-03,Thomas Lin Pedersen,"https://svglite.r-lib.org, https://github.com/r-lib/svglite",TRUE,https://github.com/r-lib/svglite,2655970,162,2022-03-03T09:38:17Z,16394.876543209877
svGUI,"The 'SciViews' 'svGUI' package eases the management of Graphical
  User Interfaces (GUI) in R. It is independent from any particular GUI widgets
  ('Tk', 'Gtk2', native, ...). It centralizes info about GUI elements currently
  used, and it dispatches GUI calls to the particular toolkits in use in
  function of the context (is R run at the terminal, within a 'Tk' application,
  a HTML page?).",2021-04-16,Philippe Grosjean,"https://github.com/SciViews/svGUI, https://www.sciviews.org/svGUI/",TRUE,https://github.com/sciviews/svgui,124302,2,2022-05-06T14:44:38Z,62151
svHttp,A simple HTTP server allows to connect GUI clients to R.,2022-05-10,Philippe Grosjean,"https://github.com/SciViews/svHttp,
https://www.sciviews.org/svHttp/",TRUE,https://github.com/sciviews/svhttp,13740,0,2022-05-10T04:02:45Z,NA
svines,"Provides functionality to fit and simulate from stationary vine 
  copula models for time series, see Nagler et al. (2022) 
  <doi:10.1016/j.jeconom.2021.11.015>.",2022-04-13,Thomas Nagler,https://github.com/tnagler/svines,TRUE,https://github.com/tnagler/svines,1227,2,2022-04-08T08:40:20Z,613.5
svKomodo,"R-side code to implement an R editor and IDE in Komodo IDE
  with the SciViews-K extension.",2022-05-10,Philippe Grosjean,"https://github.com/SciViews/svKomodo,
https://www.sciviews.org/svKomodo/",TRUE,https://github.com/sciviews/svkomodo,14562,0,2022-05-10T15:09:06Z,NA
svMisc,"Miscellaneous functions for 'SciViews' or general use: manage a
  temporary environment attached to the search path for temporary variables you
  do not want to save() or load(), test if 'Aqua', 'Mac', 'Win', ... Show
  progress bar, etc.",2021-10-11,Philippe Grosjean,"https://github.com/SciViews/svMisc,
https://www.sciviews.org/svMisc/",TRUE,https://github.com/sciviews/svmisc,73679,0,2022-05-10T06:12:31Z,NA
svrep,"Provides tools for creating and working with survey replicate weights,
  extending functionality of the 'survey' package from Lumley (2004) <doi:10.18637/jss.v009.i08>.
  Methods are provided for applying nonresponse adjustments to
  both full-sample and replicate weights as suggested by 
  Rust and Rao (1996) <doi:10.1177/096228029600500305>.
  Implements methods for sample-based calibration described by Opsomer and Erciulescu (2021) 
  <https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm>.
  Diagnostic functions are included to compare weights and weighted estimates
  from different sets of replicate weights.",2022-07-06,Ben Schneider,https://github.com/bschneidr/svrep,TRUE,https://github.com/bschneidr/svrep,950,1,2022-07-06T02:46:57Z,950
svSocket,A socket server allows to connect clients to R.,2022-05-09,Philippe Grosjean,"https://github.com/SciViews/svSocket,
https://www.sciviews.org/svSocket/",TRUE,https://github.com/sciviews/svsocket,25126,11,2022-05-09T07:20:03Z,2284.181818181818
svSweave,"Functions to enumerate and reference figures, tables and equations
  in R Markdown documents that do not support these features (thus not
  'bookdown' or 'quarto'. Supporting functions for using 'Sweave' and 'Knitr'
  with 'LyX'. ",2022-05-10,Philippe Grosjean,"https://github.com/SciViews/svSweave,
https://www.sciviews.org/svSweave/",TRUE,https://github.com/sciviews/svsweave,14680,0,2022-05-10T08:40:22Z,NA
svUnit,A complete unit test system and functions to implement its GUI part.,2021-04-19,Philippe Grosjean,"https://github.com/SciViews/svUnit,
https://www.sciviews.org/svUnit/",TRUE,https://github.com/sciviews/svunit,163622,3,2022-05-10T07:40:59Z,54540.666666666664
SvyNom,"Builds, evaluates and validates a nomogram with survey data
    and right-censored outcomes. As described in Capanu (2015)
    <doi:10.18637/jss.v064.c01>, the package contains functions to create
    the nomogram, validate it using bootstrap, as well as produce the
    calibration plots.",2022-04-28,Mithat Gonen,"https://github.com/MSKCC-Epi-Bio/SvyNom,
https://mskcc-epi-bio.github.io/SvyNom/",TRUE,https://github.com/mskcc-epi-bio/svynom,14858,0,2022-04-28T17:27:13Z,NA
swagger,"A collection of 'HTML', 'JavaScript', and 'CSS' assets that
  dynamically generate beautiful documentation from a 'Swagger' compliant API:
  <https://swagger.io/specification/>.",2020-10-02,Barret Schloerke,https://github.com/rstudio/swagger,TRUE,https://github.com/rstudio/swagger,1745188,52,2021-11-19T16:10:10Z,33561.307692307695
swatches,"There are numerous places to create and download color
    palettes. These are usually shared in 'Adobe' swatch file formats of
    some kind. There is also often the need to use standard palettes
    developed within an organization to ensure that aesthetics are carried over
    into all projects and output. Now there is a way to read these swatch
    files in R and avoid transcribing or converting color values by hand or
    or with other programs. This package provides functions to read and
    inspect 'Adobe Color' ('ACO'), 'Adobe Swatch Exchange' ('ASE'), 'GIMP Palette' ('GPL'),
    'OpenOffice' palette ('SOC') files and 'KDE Palette' ('colors') files. Detailed
    descriptions of 'Adobe Color' and 'Swatch Exchange' file formats as well as other
    swatch file formats can be found at
    <http://www.selapa.net/swatches/colors/fileformats.php>.",2017-12-21,Bob Rudis,https://github.com/hrbrmstr/swatches,TRUE,https://github.com/hrbrmstr/swatches,13059,54,2022-04-02T15:03:18Z,241.83333333333334
sweater,"Conduct various tests for evaluating implicit biases in word embeddings: Word Embedding Association Test (Caliskan et al., 2017), <doi:10.1126/science.aal4230>, Relative Norm Distance (Garg et al., 2018), <doi:10.1073/pnas.1720347115>, Mean Average Cosine Similarity (Mazini et al., 2019) <arXiv:1904.04047>, SemAxis (An et al., 2018) <arXiv:1806.05521>, Relative Negative Sentiment Bias (Sweeney & Najafian, 2019) <doi:10.18653/v1/P19-1162>, and Embedding Coherence Test (Dev & Phillips, 2019) <arXiv:1901.07656>.",2022-05-04,Chung-hong Chan,https://github.com/chainsawriot/sweater,TRUE,https://github.com/chainsawriot/sweater,2815,22,2022-06-08T13:08:49Z,127.95454545454545
sweidnumbr,"Structural handling of identity numbers used in the Swedish
    administration such as personal identity numbers ('personnummer') and
    organizational identity numbers ('organisationsnummer').",2020-03-29,Mans Magnusson and Erik Bulow,https://github.com/rOpenGov/sweidnumbr/,TRUE,https://github.com/ropengov/sweidnumbr,15885,7,2022-03-16T07:04:24Z,2269.285714285714
swfscAirDAS,"Process and summarize aerial survey 'DAS' data (AirDAS) 
    <https://swfsc-publications.fisheries.noaa.gov/publications/TM/SWFSC/NOAA-TM-NMFS-SWFSC-185.PDF>
    collected using an aerial survey program from the 
    Southwest Fisheries Science Center (SWFSC) 
    <https://www.fisheries.noaa.gov/west-coast/science-data/california-current-marine-mammal-assessment-program>.
    PDF files detailing the relevant AirDAS data formats are included in this package.",2022-06-02,Sam Woodman,"https://smwoodman.github.io/swfscAirDAS/,
https://github.com/smwoodman/swfscAirDAS/",TRUE,https://github.com/smwoodman/swfscairdas,7368,0,2022-06-02T16:43:17Z,NA
swfscDAS,"Process and summarize shipboard 
    'DAS' <https://swfsc-publications.fisheries.noaa.gov/publications/TM/SWFSC/NOAA-TM-NMFS-SWFSC-305.PDF> data
    produced by the Southwest Fisheries Science Center (SWFSC) program 'WinCruz' 
    <https://www.fisheries.noaa.gov/west-coast/science-data/california-current-marine-mammal-assessment-program>.
    This package standardizes and streamlines basic DAS data processing,
    and includes a PDF with the DAS data format requirements.",2022-01-31,Sam Woodman,"https://smwoodman.github.io/swfscDAS/,
https://github.com/smwoodman/swfscDAS/",TRUE,https://github.com/smwoodman/swfscdas,9385,1,2022-06-02T00:42:14Z,9385
swfscMisc,"Collection of conversion, analytical, geodesic, mapping, and
    plotting functions. Used to support packages and code written by
    researchers at the Southwest Fisheries Science Center of the National
    Oceanic and Atmospheric Administration.",2022-04-21,Eric Archer,https://github.com/EricArcher/swfscMisc,TRUE,https://github.com/ericarcher/swfscmisc,35700,1,2022-06-18T05:04:04Z,35700
SWIM,"An efficient sensitivity analysis for stochastic models based on 
    Monte Carlo samples. Provides weights on simulated scenarios from a 
    stochastic model, such that stressed random variables fulfil given 
    probabilistic constraints (e.g. specified values for risk measures), 
    under the new scenario weights. Scenario weights are selected by 
    constrained minimisation of the relative entropy to the baseline model. 
    The 'SWIM' package is based on Pesenti S.M., Millossovich P., Tsanakas A. (2019)
    ""Reverse Sensitivity Testing: What does it take to break the model"" 
    <openaccess.city.ac.uk/id/eprint/18896/> and Pesenti S.M. (2021) 
    ""Reverse Sensitivity Analysis for Risk Modelling"" <https://www.ssrn.com/abstract=3878879>.",2022-01-09,Silvana M. Pesenti,"https://github.com/spesenti/SWIM,
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3515274,
https://utstat.toronto.edu/pesenti/?page_id=138",TRUE,https://github.com/spesenti/swim,13752,4,2022-01-10T12:41:16Z,3438
swissparl,"Retrieves the most important data on parliamentary activities of the Swiss Federal Assembly via 
    an open, machine-readable interface (see <https://ws.parlament.ch/odata.svc/>). ",2021-11-02,David Zumbach,https://www.parlament.ch/en/services/open-data-webservices,TRUE,https://github.com/zumbov2/swissparl,17838,23,2022-02-01T09:06:16Z,775.5652173913044
swmmr,"Functions to connect the widely used Storm Water Management Model (SWMM)
  of the United States Environmental Protection Agency (US EPA) 
  <https://www.epa.gov/water-research/storm-water-management-model-swmm> to R with
  currently two main goals: (1) Run a SWMM simulation from R and (2) provide fast 
  access to simulation results, i.e. SWMM's binary '.out'-files. High performance is achieved
  with help of Rcpp. Additionally, reading SWMM's '.inp' and '.rpt' files is supported to 
  glance model structures and to get direct access to simulation summaries.",2020-03-02,Dominik Leutnant,https://github.com/dleutnant/swmmr,TRUE,https://github.com/dleutnant/swmmr,18638,31,2022-02-02T09:43:32Z,601.2258064516129
SWMPr,"Tools for retrieving, organizing, and analyzing environmental
    data from the System Wide Monitoring Program of the National Estuarine
    Research Reserve System <http://cdmo.baruch.sc.edu/>. These tools
    address common challenges associated with continuous time series data
    for environmental decision making.",2021-09-02,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/swmpr,18416,10,2022-06-16T12:07:42Z,1841.6
SWMPrExtension,"Tools for performing routine analysis and plotting tasks with environmental
    data from the System Wide Monitoring Program of the National Estuarine
    Research Reserve System <http://cdmo.baruch.sc.edu/>. This package builds
    on the functionality of the 'SWMPr' package <https://cran.r-project.org/package=SWMPr>,
    which is used to retrieve and organize the data. The combined set of tools
    address common challenges associated with continuous time series data
    for environmental decision making, and are intended for use in annual reporting activities.
    References:
    Beck, Marcus W. (2016) <ISSN 2073-4859><https://journal.r-project.org/archive/2016-1/beck.pdf>
    Rudis, Bob (2014) <https://rud.is/b/2014/11/16/moving-the-earth-well-alaska-hawaii-with-r/>.
    United States Environmental Protection Agency (2015) <https://cfpub.epa.gov/si/si_public_record_Report.cfm?Lab=OWOW&dirEntryId=327030>.
    United States Environmental Protection Agency (2012) <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.1973&rep=rep1&type=pdf>.",2022-05-31,Kirk Waters,NA,TRUE,https://github.com/noaa-ocm/swmprextension,17708,8,2022-05-30T19:37:27Z,2213.5
SWTools,"Functions to speed up work flow for hydrological analysis. 
    Focused on Australian climate data (SILO climate data), hydrological models (eWater Source) and in particular South Australia (<https://water.data.sa.gov.au> hydrological data).",2022-07-04,Matt Gibbs,https://github.com/matt-s-gibbs/SWTools,TRUE,https://github.com/matt-s-gibbs/swtools,3323,3,2022-07-05T07:18:06Z,1107.6666666666667
sylcount,"An English language syllable counter, plus readability score
    measure-er. For readability, we support 'Flesch' Reading Ease and
    'Flesch-Kincaid' Grade Level ('Kincaid' 'et al'. 1975)
    <https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=1055&context=istlibrary>,
    Automated Readability Index ('Senter' and Smith 1967)
    <https://apps.dtic.mil/sti/citations/AD0667273>,
    Simple Measure of Gobbledygook (McLaughlin 1969)
    <https://www.semanticscholar.org/paper/SMOG-Grading-A-New-Readability-Formula.-Laughlin/5fccb74c14769762b3de010c5e8a1a7ce700d17a>,
    and 'Coleman-Liau' (Coleman and 'Liau' 1975) <doi:10.1037/h0076540>. The
    package has been carefully optimized and should be very efficient, both in
    terms of run time performance and memory consumption. The main methods are
    'vectorized' by document, and scores for multiple documents are computed in
    parallel via 'OpenMP'.",2022-03-11,Drew Schmidt,https://github.com/wrathematics/sylcount,TRUE,https://github.com/wrathematics/sylcount,19414,7,2022-03-05T23:39:55Z,2773.4285714285716
symengine,"
    Provides an R interface to 'SymEngine' <https://github.com/symengine/>,
    a standalone 'C++' library for fast symbolic manipulation. The package has functionalities
    for symbolic computation like calculating exact mathematical expressions, solving
    systems of linear equations and code generation.",2022-04-28,Jialin Ma,https://github.com/symengine/symengine.R,TRUE,https://github.com/symengine/symengine.r,19890,21,2022-04-28T18:35:51Z,947.1428571428571
SynDI,"Regression inference for multiple populations by integrating 
    summary-level data using stacked imputations. Gu, T., Taylor, J.M.G. and 
    Mukherjee, B. (2021) A synthetic data integration framework to leverage 
    external summary-level information from heterogeneous populations 
    <arXiv:2106.06835>.",2022-05-25,Michael Kleinsasser,https://github.com/umich-biostatistics/SynDI,TRUE,https://github.com/umich-biostatistics/syndi,329,1,2022-05-24T15:18:24Z,329
synoptReg,"Set of functions to compute different types of synoptic classification methods and for analysing their effect on environmental variables. More information about the methods used in Lemus-Canovas et al. 2019 <DOI:10.1016/j.atmosres.2019.01.018>,  Martin-Vide et al. 2008 <DOI:10.5194/asr-2-99-2008>, Jenkinson and Collison 1977.",2021-04-21,Marc Lemus-Canovas,<https://lemuscanovas.github.io/synoptreg/>,TRUE,https://github.com/lemuscanovas/synoptreg,14857,5,2022-04-25T16:38:17Z,2971.4
synr,"Explore synesthesia
  consistency test data, calculate consistency scores, 
  and classify participant data as valid or invalid.",2021-11-24,Lowe Wilsson,"https://datalowe.github.io/synr/, https://github.com/datalowe/synr",TRUE,https://github.com/datalowe/synr,1595,0,2022-03-07T16:29:36Z,NA
SynthETIC,"Creation of an individual claims simulator which generates various
    features of non-life insurance claims. An initial set of test parameters,
    designed to mirror the experience of an Auto Liability portfolio, were set
    up and applied by default to generate a realistic test data set of
    individual claims (see vignette). The simulated data set then allows
    practitioners to back-test the validity of various reserving models and to
    prove and/or disprove certain actuarial assumptions made in claims
    modelling. The distributional assumptions used to generate this data set can
    be easily modified by users to match their experiences. Reference: Avanzi B,
    Taylor G, Wang M, Wong B (2020) ""SynthETIC: an individual insurance claim
    simulator with feature control"" <arXiv:2008.05693>.",2021-09-02,Melantha Wang,https://github.com/agi-lab/SynthETIC,TRUE,https://github.com/agi-lab/synthetic,8354,6,2022-03-14T12:29:55Z,1392.3333333333333
sysfonts,"Loading system fonts and Google Fonts
    <https://fonts.google.com/> into R, in order to
    support other packages such as 'R2SWF' and 'showtext'.",2022-03-13,"Yixuan Qiu and authors/contributors of the
    included fonts. See file AUTHORS for details.",https://github.com/yixuan/sysfonts,TRUE,https://github.com/yixuan/sysfonts,929388,19,2022-02-09T15:04:28Z,48915.15789473684
systemfonts,"Provides system native access to the font catalogue. As font
    handling varies between systems it is difficult to correctly locate 
    installed fonts across different operating systems. The 'systemfonts' 
    package provides bindings to the native libraries on Windows, macOS and 
    Linux for finding font files that can then be used further by e.g. graphic
    devices. The main use is intended to be from compiled code but 'systemfonts'
    also provides access from R.",2022-02-11,Thomas Lin Pedersen,https://github.com/r-lib/systemfonts,TRUE,https://github.com/r-lib/systemfonts,5101224,81,2022-03-03T09:26:28Z,62978.07407407407
T4cluster,"Cluster analysis is one of the most fundamental problems in data science. We provide a variety of algorithms from clustering to the learning on the space of partitions. See Hennig, Meila, and Rocci (2016, ISBN:9781466551886) for general exposition to cluster analysis.",2021-08-16,Kisung You,https://kisungyou.com/T4cluster/,TRUE,https://github.com/kisungyou/t4cluster,8034,5,2021-09-23T04:42:04Z,1606.8
table.express,"A specialization of 'dplyr' data manipulation verbs that parse and build expressions
    which are ultimately evaluated by 'data.table', letting it handle all optimizations. A set of
    additional verbs is also provided to facilitate some common operations on a subset of the data.",2022-04-02,Alexis Sarda-Espinosa,"https://asardaes.github.io/table.express/,
https://github.com/asardaes/table.express",TRUE,https://github.com/asardaes/table.express,186146,63,2022-04-12T20:28:12Z,2954.6984126984125
table1,"Create HTML tables of descriptive statistics, as one would expect
    to see as the first table (i.e. ""Table 1"") in a medical/epidemiological journal
    article.",2021-06-06,Benjamin Rich,https://github.com/benjaminrich/table1,TRUE,https://github.com/benjaminrich/table1,142071,58,2022-05-27T17:23:02Z,2449.5
tablecompare,"A toolbox for comparing two data frames with the aim of quick and 
  simple functionality. Using a key-column common to both tables, see which rows 
  are common and highlight differing values by column. Also included are functions
  validating keys and uniqueness of in-group values.",2022-06-21,Ryan Dickerson,https://github.com/eutwt/tablecompare,TRUE,https://github.com/eutwt/tablecompare,203,1,2022-06-24T13:28:29Z,203
tableone,"Creates 'Table 1', i.e., description of baseline patient
    characteristics, which is essential in every medical research.
    Supports both continuous and categorical variables, as well as
    p-values and standardized mean differences. Weighted data are
    supported via the 'survey' package.",2022-04-15,Kazuki Yoshida,https://github.com/kaz-yos/tableone,TRUE,https://github.com/kaz-yos/tableone,267796,178,2022-04-15T14:27:35Z,1504.4719101123596
tablerDash,"'R' interface to the 'Tabler' HTML template. See more here <https://tabler.io>. 
    'tablerDash' is a light 'Bootstrap 4' dashboard template. There are different 
     layouts available such as a one page dashboard or a multi page template,
     where the navigation menu is contained in the navigation bar. A fancy example
     is available at <https://dgranjon.shinyapps.io/shinyMons/>.",2019-03-08,David Granjon,"https://rinterface.github.io/tablerDash/,
https://github.com/RinteRface/tablerDash/",TRUE,https://github.com/rinterface/tablerdash,71567,70,2021-11-18T17:24:43Z,1022.3857142857142
tableschema.r,"Allows to work with 'Table Schema' (<http://specs.frictionlessdata.io/table-schema/>). 'Table Schema' is well suited for use cases around handling and validating tabular data in text formats such as 'csv', but its utility extends well beyond this core usage, towards a range of applications where data benefits from a portable schema format. The 'tableschema.r' package can load and validate any table schema descriptor, allow the creation and modification of descriptors, expose methods for reading and streaming data that conforms to a 'Table Schema' via the 'Tabular Data Resource' abstraction.",2020-03-12,Kleanthis Koupidis,https://github.com/frictionlessdata/tableschema-r,TRUE,https://github.com/frictionlessdata/tableschema-r,12431,24,2021-09-02T12:21:21Z,517.9583333333334
tablet,"Creates a table of descriptive statistics
 for factor and numeric columns in a data frame. Displays
 these by groups, if any. Highly customizable, with support
 for 'html' and 'pdf' provided by 'kableExtra'. Respects
 original column order, column labels, and factor level order.
 See ?tablet.data.frame and vignettes.",2022-04-29,Tim Bergsma,NA,TRUE,https://github.com/bergsmat/tablet,8526,2,2022-04-29T00:39:43Z,4263
tabnet,"Implements the 'TabNet' model by Sercan O. Arik et al (2019) <arXiv:1908.07442>
    and provides a consistent interface for fitting and creating predictions. It's
    also fully compatible with the 'tidymodels' ecosystem.",2021-10-11,Daniel Falbel,https://github.com/mlverse/tabnet,TRUE,https://github.com/mlverse/tabnet,8704,78,2022-06-18T19:31:33Z,111.58974358974359
tabshiftr,"Helps the user to build and register schema descriptions of 
    disorganised (messy) tables. Disorganised tables are tables that are 
    not in a topologically coherent form, where packages such as 'tidyr' could 
    be used for reshaping. The schema description documents the arrangement of 
    input tables and is used to reshape them into a standardised (tidy) output 
    format.",2022-01-13,Steffen Ehrmann,https://github.com/EhrmannS/tabshiftr,TRUE,https://github.com/ehrmanns/tabshiftr,9043,3,2022-03-04T17:33:37Z,3014.3333333333335
tabula,"An easy way to examine archaeological count data. This
    package provides several tests and measures of diversity:
    heterogeneity and evenness (Brillouin, Shannon, Simpson, etc.),
    richness and rarefaction (Chao1, Chao2, ACE, ICE, etc.), turnover and
    similarity (Brainerd-Robinson, etc.). The package make it easy to
    visualize count data and statistical thresholds: rank vs abundance
    plots, heatmaps, Ford (1962) and Bertin (1977) diagrams.",2022-06-23,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>,"https://packages.tesselle.org/tabula/,
https://github.com/tesselle/tabula",TRUE,https://github.com/tesselle/tabula,24864,26,2022-06-23T14:32:40Z,956.3076923076923
tabularMLC,"
  The maximum likelihood classifier (MLC) is one of the most common classifiers used for 
  remote sensing imagery. 
  This package uses 'RcppArmadillo' to provide a fast implementation of the MLC to train 
  and predict over tabular data (data.frame).
  The algorithms were based on Mather (1985) <doi:10.1080/01431168508948456> method.",2021-10-05,Caio Hamamura,https://github.com/caiohamamura/tabularMLC,TRUE,https://github.com/caiohamamura/tabularmlc,2657,1,2021-10-04T20:48:28Z,2657
tabulate,"Generates pretty console output for tables allowing for full customization
  of cell colors, font type, borders and many others attributes. It also supports 'multibyte'
  characters and nested tables.",2022-02-16,Daniel Falbel,"https://github.com/mlverse/tabulate,
https://mlverse.github.io/tabulate/",TRUE,https://github.com/mlverse/tabulate,4168,40,2022-02-16T11:21:46Z,104.2
tabxplor,"Make it easy to deal with multiple cross-tables in data 
    exploration, by creating them, manipulating them, and adding color 
    helpers to highlight important informations (differences from totals, 
    comparisons between lines or columns, contributions to variance, margins 
    of error, etc.). All functions are pipe-friendly and render data frames 
    which can be easily manipulated. In the same time, time-taking operations 
    are done with `data.table` to go faster with big dataframes. Tables can
    be exported to Excel and in html with formats and colors.",2022-06-15,Brice Nocenti,https://github.com/BriceNocenti/tabxplor,TRUE,https://github.com/bricenocenti/tabxplor,3512,0,2022-06-15T19:55:33Z,NA
takos,"It includes functions for applying methodologies utilized for single-process kinetic analysis of solid-state processes were recently summarized and described in the Recommendation of ICTAC Kinetic Committee. These methods work with the basic kinetic equation. The Methodologies included refers to  Avrami, Friedman, Kissinger, Ozawa, OFM, Mo, Starink, isoconversional methodology (Vyazovkin) according to ICATAC Kinetics Committee recommendations as reported in Vyazovkin S, Chrissafis K, Di Lorenzo ML, et al. ICTAC Kinetics Committee recommendations for collecting experimental thermal analysis data for kinetic computations. Thermochim Acta. 2014;590:1-23. <doi:10.1016/J.TCA.2014.05.036> .",2020-10-19,Serena Berretta and Giorgio Luciano,https://github.com/sere3s/takos,TRUE,https://github.com/sere3s/takos,11767,2,2021-07-15T15:32:59Z,5883.5
TAM,"
    Includes marginal maximum likelihood estimation and joint maximum
    likelihood estimation for unidimensional and multidimensional 
    item response models. The package functionality covers the 
    Rasch model, 2PL model, 3PL model, generalized partial credit model, 
    multi-faceted Rasch model, nominal item response model, 
    structured latent class model, mixture distribution IRT models, 
    and located latent class models. Latent regression models and 
    plausible value imputation are also supported. For details see
    Adams, Wilson and Wang, 1997 <doi:10.1177/0146621697211001>,
    Adams, Wilson and Wu, 1997 <doi:10.3102/10769986022001047>,
    Formann, 1982 <doi:10.1002/bimj.4710240209>,
    Formann, 1992 <doi:10.1080/01621459.1992.10475229>.",2022-05-14,Alexander Robitzsch,"http://www.edmeasurementsurveys.com/TAM/Tutorials/,
https://github.com/alexanderrobitzsch/TAM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/tam,139838,14,2022-05-15T07:25:43Z,9988.42857142857
tanaka,"The Tanaka method enhances the representation of topography on
    a map using shaded contour lines. In this simplified implementation of
    the method, north-west white contours represent illuminated topography
    and south-east black contours represent shaded topography. See Tanaka
    (1950) <doi:10.2307/211219>.",2022-07-04,Timothée Giraud,https://github.com/riatelab/tanaka/,TRUE,https://github.com/riatelab/tanaka,13140,66,2022-07-04T09:59:59Z,199.0909090909091
tangram,"Provides an extensible formula system to quickly and easily create
    production quality tables. The steps of the process are formula parser,
    statistical content generation from data, to rendering. Each step of the process
    is separate and user definable thus creating a set of building blocks for
    highly extensible table generation. A user is not limited by any of the 
    choices of the package creator other than the formula grammar. For example,
    one could chose to add a different S3 rendering function and output a format
    not provided in the default package. Or possibly one would rather have Gini
    coefficients for their statistical content. Routines to achieve New England
    Journal of Medicine style, Lancet style and Hmisc::summaryM() statistics are
    provided. The package contains rendering for HTML5, Rmarkdown and an indexing
    format for use in tracing and tracking are provided.",2020-04-29,Shawn Garbett,https://github.com/spgarbet/tangram,TRUE,https://github.com/spgarbet/tangram,16231,59,2021-12-01T17:33:48Z,275.10169491525426
tangram.pipe,"Builds tables with customizable rows. Users can specify the type
             of data to use for each row, as well as how to handle missing
             data and the types of comparison tests to run on the table
             columns.",2022-04-20,Andrew Guide,https://github.com/thomasgstewart/tangram.pipe,TRUE,https://github.com/thomasgstewart/tangram.pipe,4134,0,2022-06-02T21:35:58Z,NA
tarchetypes,"Function-oriented Make-like declarative workflows for
  Statistics and data science are supported in the 'targets' R package.
  As an extension to 'targets', the 'tarchetypes' package provides
  convenient user-side functions to make 'targets' easier to use.
  By establishing reusable archetypes for common kinds of
  targets and pipelines, these functions help express complicated
  reproducible workflows concisely and compactly.
  The methods in this package were influenced by the 'drake' R package
  by Will Landau (2018) <doi:10.21105/joss.00550>.",2022-04-19,William Michael Landau,"https://docs.ropensci.org/tarchetypes/,
https://github.com/ropensci/tarchetypes",TRUE,https://github.com/ropensci/tarchetypes,27129,74,2022-06-29T21:10:54Z,366.6081081081081
targeted,"Various methods for targeted and semiparametric inference including
	     augmented inverse probability weighted estimators for missing data and
	     causal inference (Bang and Robins (2005) <doi:10.1111/j.1541-0420.2005.00377.x>)
	     and estimators for risk differences and relative risks (Richardson et al. (2017)
	     <doi:10.1080/01621459.2016.1192546>).",2021-10-26,Klaus K. Holst,https://www.targetlib.org/r/,TRUE,https://github.com/kkholst/targeted,7853,7,2021-10-25T11:52:37Z,1121.857142857143
targets,"As a pipeline toolkit for Statistics and data science in R,
  the 'targets' package brings together function-oriented programming and
  'Make'-like declarative workflows.
  It analyzes the dependency relationships among the tasks of a workflow,
  skips steps that are already up to date, runs the necessary
  computation with optional parallel workers, abstracts files as
  R objects, and provides tangible evidence that the results match
  the underlying code and data. The methodology in this package
  borrows from GNU 'Make' (2015, ISBN:978-9881443519)
  and 'drake' (2018, <doi:10.21105/joss.00550>).",2022-06-03,William Michael Landau,"https://docs.ropensci.org/targets/,
https://github.com/ropensci/targets",TRUE,https://github.com/ropensci/targets,90227,604,2022-06-30T18:43:44Z,149.38245033112582
taskscheduleR,"Schedule R scripts/processes with the Windows task scheduler. This
    allows R users to automate R processes on specific time points from R itself.",2022-03-16,Jan Wijffels,https://github.com/bnosac/taskscheduleR,TRUE,https://github.com/bnosac/taskscheduler,43925,289,2022-03-10T08:31:40Z,151.98961937716263
taxa,"Provides classes for storing and manipulating taxonomic data. 
 Most of the classes can be treated like base R vectors (e.g. can be used 
 in tables as columns and can be named). Vectorized classes can store taxon names
 and authorities, taxon IDs from databases, taxon ranks, and other types of
 information. More complex classes are provided to store taxonomic trees and
 user-defined data associated with them.",2022-04-12,Scott Chamberlain,"https://docs.ropensci.org/taxa/, https://github.com/ropensci/taxa",TRUE,https://github.com/ropensci/taxa,36869,44,2022-04-12T05:10:10Z,837.9318181818181
taxalight,"Creates a local Lightning Memory-Mapped Database ('LMDB') 
             of many commonly used taxonomic authorities
             and provides functions that can quickly query this data.
             Supported taxonomic authorities include 
             the Integrated Taxonomic Information System ('ITIS'),
             National Center for Biotechnology Information ('NCBI'),
             Global Biodiversity Information Facility ('GBIF'), 
             Catalogue of Life ('COL'), and Open Tree Taxonomy ('OTT'). 
             Name and identifier resolution using 'LMDB' can
             be hundreds of times faster than either relational databases or
             internet-based queries. Precise data provenance information for
             data derived from naming providers is also included.",2021-09-14,Carl Boettiger,https://github.com/cboettig/taxalight,TRUE,https://github.com/cboettig/taxalight,6040,4,2021-09-10T18:33:23Z,1510
taxize,"Interacts with a suite of web 'APIs' for taxonomic tasks,
    such as getting database specific taxonomic identifiers, verifying
    species names, getting taxonomic hierarchies, fetching downstream and
    upstream taxonomic names, getting taxonomic synonyms, converting
    scientific to common names and vice versa, and more.",2022-04-22,Zachary Foster,"https://docs.ropensci.org/taxize/ (website),
https://github.com/ropensci/taxize (devel), https://taxize.dev
(user manual)",TRUE,https://github.com/ropensci/taxize,191957,228,2022-04-21T16:03:14Z,841.9166666666666
taxlist,"Handling taxonomic lists through objects of class 'taxlist'.
    This package provides functions to import species lists from 'Turboveg'
    (<https://www.synbiosys.alterra.nl/turboveg/>) and the possibility to create
    backups from resulting R-objects.
    Also quick displays are implemented as summary-methods.",2021-07-15,Miguel Alvarez,"https://cran.r-project.org/package=taxlist,
https://github.com/ropensci/taxlist,
https://docs.ropensci.org/taxlist/",TRUE,https://github.com/ropensci/taxlist,19081,8,2022-01-10T10:17:55Z,2385.125
taxonbridge,"The NCBI taxonomy is a popular resource for taxonomic studies but it only contains
    data on species with sequence data whereas the GBIF has a more extensive coverage of
    extinct species. Taxonbridge is useful for the creation and analysis of custom taxonomies
    based on the NCBI taxonomy and GBIF backbone taxonomy.",2022-07-04,Werner Veldsman,https://github.com/MoultDB/taxonbridge,TRUE,https://github.com/moultdb/taxonbridge,2659,3,2022-07-04T11:46:45Z,886.3333333333334
taxonomizr,Functions for assigning taxonomy to NCBI accession numbers and taxon IDs based on NCBI's accession2taxid and taxdump files. This package allows the user to download NCBI data dumps and create a local database for fast and local taxonomic assignment.,2022-06-26,Scott Sherrill-Mix,NA,TRUE,https://github.com/sherrillmix/taxonomizr,20732,47,2022-06-24T22:12:11Z,441.1063829787234
taxotools,"Tools include matching and merging taxonomic lists, casting and 
  melting scientific names, managing taxonomic lists from GBIF and ITIS, 
  harvesting names from wikipedia and fuzzy matching.",2022-06-10,Vijay Barve,NA,TRUE,https://github.com/vijaybarve/taxotools,14484,5,2022-06-09T22:44:24Z,2896.8
taylor,"A comprehensive resource for data on Taylor Swift songs. Data is
    included for all officially released studio albums, extended plays (EPs),
    and individual singles are included. Data comes from
    'Genius' (lyrics) and 'Spotify' (song characteristics). Additional functions
    are included for easily creating data visualizations with color palettes
    inspired by Taylor Swift's album covers.",2021-12-14,W. Jake Thompson,"https://taylor.wjakethompson.com,
https://github.com/wjakethompson/taylor",TRUE,https://github.com/wjakethompson/taylor,4326,6,2022-06-24T14:05:56Z,721
TBRDist,"Fast calculation of the Subtree Prune and Regraft (SPR),
  Tree Bisection and Reconnection (TBR) and Replug distances between 
  unrooted trees, using the algorithms of Whidden and 
  Matsen (2017) <arxiv:1511.07529>.",2020-09-17,Martin R. Smith,"https://ms609.github.io/TBRDist/,
https://github.com/ms609/TBRDist/,
https://github.com/cwhidden/uspr/",TRUE,https://github.com/ms609/tbrdist,9443,0,2021-07-13T14:16:39Z,NA
tbrf,"Provides rolling statistical functions based
    on date and time windows instead of n-lagged observations.",2020-04-09,Michael Schramm,https://mps9506.github.io/tbrf/,TRUE,https://github.com/mps9506/tbrf,17529,3,2022-05-13T21:47:56Z,5843
TcGSA,"Implementation of Time-course Gene Set Analysis (TcGSA), a method for 
	analyzing longitudinal gene-expression data at the gene set level. Method is
	detailed in: Hejblum, Skinner & Thiebaut (2015) <doi: 10.1371/journal.pcbi.1004310>.",2022-02-28,Boris P Hejblum,http://sistm.github.io/TcGSA/,TRUE,https://github.com/sistm/tcgsa,15602,4,2022-02-28T19:59:14Z,3900.5
tci,"Implementation of target-controlled infusion algorithms for compartmental pharmacokinetic and pharmacokinetic-pharmacodynamic models. Jacobs (1990) <doi:10.1109/10.43622>; Marsh et al. (1991) <doi:10.1093/bja/67.1.41>; Shafer and Gregg (1993) <doi:10.1007/BF01070999>; Schnider et al. (1998) <doi:10.1097/00000542-199805000-00006>; Abuhelwa, Foster, and Upton (2015) <doi:10.1016/j.vascn.2015.03.004>; Eleveld et al. (2018) <doi:10.1016/j.bja.2018.01.018>.",2021-11-04,Ryan Jarrett,https://github.com/jarretrt/tci,TRUE,https://github.com/jarretrt/tci,4736,1,2022-05-10T16:11:15Z,4736
tcpl,"A set of tools for processing and modeling high-throughput and
    high-content chemical screening data. The package was developed for the
    the chemical screening data generated by the US EPA ToxCast program, but
    can be used for diverse chemical screening efforts.",2022-03-03,Richard S Judson,https://github.com/USEPA/CompTox-ToxCast-tcpl,TRUE,https://github.com/usepa/comptox-toxcast-tcpl,19305,14,2022-03-03T17:41:36Z,1378.9285714285713
tcsinvest,"R functions for Tinkoff Investments API <https://tinkoffcreditsystems.github.io/invest-openapi/>. Using this package, analysts and traders can interact with account and market data from within R.  Clients for both REST and Streaming protocols implemented.",2021-08-17,Vyacheslav Arbuzov,"https://github.com/arbuzovv/tcsinvest,tcsinvest.ru",TRUE,https://github.com/arbuzovv/tcsinvest,3243,4,2021-08-18T21:28:02Z,810.75
td,"The 'twelvedata' REST service offers access to current and historical
 data on stocks, standard as well as digital 'crypto' currencies, and other financial
 assets covering a wide variety of course and time spans. See <https://twelvedata.com/>
 for details, to create an account, and to request an API key for free-but-capped access
 to the data.",2022-01-26,Dirk Eddelbuettel and Kenneth Rose,"https://dirk.eddelbuettel.com/code/td.html,
https://github.com/eddelbuettel/td",TRUE,https://github.com/eddelbuettel/td,6568,10,2022-02-03T14:06:26Z,656.8
TDAstats,"A comprehensive toolset for any
    useR conducting topological data analysis, specifically via the
    calculation of persistent homology in a Vietoris-Rips complex.
    The tools this package currently provides can be conveniently split
    into three main sections: (1) calculating persistent homology; (2)
    conducting statistical inference on persistent homology calculations;
    (3) visualizing persistent homology and statistical inference.
    The published form of TDAstats can be found in Wadhwa et al. (2018)
    <doi:10.21105/joss.00860>.   
    For a general background on computing persistent homology for
    topological data analysis, see Otter et al. (2017)
    <doi:10.1140/epjds/s13688-017-0109-5>.
    To learn more about how the permutation test is used for
    nonparametric statistical inference in topological data analysis,
    read Robinson & Turner (2017) <doi:10.1007/s41468-017-0008-7>.
    To learn more about how TDAstats calculates persistent homology,
    you can visit the GitHub repository for Ripser, the software that
    works behind the scenes at <https://github.com/Ripser/ripser>.
    This package has been published as Wadhwa et al. (2018)
    <doi:10.21105/joss.00860>.",2019-12-12,Raoul Wadhwa,https://github.com/rrrlw/TDAstats,TRUE,https://github.com/rrrlw/tdastats,14638,26,2021-11-23T15:56:42Z,563
tdaunif,"Uniform random samples from simple manifolds, sometimes with noise,
    are commonly used to test topological data analytic (TDA) tools.
    This package includes samplers powered by two techniques: analytic
    volume-preserving parameterizations, as employed by Arvo (1995)
    <doi:10.1145/218380.218500>, and rejection sampling, as employed by
    Diaconis, Holmes, and Shahshahani (2013) <doi:10.1214/12-IMSCOLL1006>.",2020-10-26,Jason Cory Brunson,https://corybrunson.github.io/tdaunif/,TRUE,https://github.com/corybrunson/tdaunif,6091,2,2022-06-11T13:13:36Z,3045.5
TDbook,"The companion package that provides all the datasets used in the book
 ""Data Integration, Manipulation and Visualization of Phylogenetic Trees"" by Guangchuang Yu (2022, ISBN:9781032233574).",2022-03-03,Guangchuang Yu,https://github.com/YuLab-SMU/TDBook,TRUE,https://github.com/yulab-smu/tdbook,7656,9,2022-03-03T07:43:40Z,850.6666666666666
tdthap,"Functions and examples are provided for Transmission/disequilibrium tests
             for extended marker haplotypes, as in
             Clayton, D. and Jones, H. (1999) ""Transmission/disequilibrium tests
             for extended marker haplotypes"". Amer. J. Hum. Genet., 65:1161-1169,
             <doi:10.1086/302566>.",2019-08-22,David Clayton,https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,21430,6,2022-07-08T17:10:26Z,3571.6666666666665
telegram.bot,"Provides a pure interface for the 'Telegram Bot API'
    <http://core.telegram.org/bots/api>. In addition to the pure API
    implementation, it features a number of tools to make the development of
    'Telegram' bots with R easy and straightforward, providing an easy-to-use
    interface that takes some work off the programmer.",2019-10-19,Ernest Benedito,http://github.com/ebeneditos/telegram.bot,TRUE,https://github.com/ebeneditos/telegram.bot,76506,86,2022-07-06T12:35:28Z,889.6046511627907
telemac,"An R interface to the TELEMAC suite for modelling
    of free surface flow. This includes methods for model initialisation, simulation,
    and visualisation. So far only the TELEMAC-2D module for 2-dimensional hydrodynamic
    modelling is implemented. ",2022-02-07,Tobias Pilz,https://github.com/tpilz/telemac,TRUE,https://github.com/tpilz/telemac,4661,5,2022-02-09T09:06:23Z,932.2
tempdisagg,"Temporal disaggregation methods are used to disaggregate and
    interpolate a low frequency time series to a higher frequency series, where
    either the sum, the mean, the first or the last value of the resulting
    high frequency series is consistent with the low frequency series. Temporal
    disaggregation can be performed with or without one or more high frequency
    indicator series. Contains the methods of Chow-Lin, Santos-Silva-Cardoso,
    Fernandez, Litterman, Denton and Denton-Cholette, summarized in Sax and
    Steiner (2013) <doi:10.32614/RJ-2013-028>. Supports most R time series
    classes.",2020-02-07,Christoph Sax,https://journal.r-project.org/archive/2013-2/sax-steiner.pdf,TRUE,https://github.com/christophsax/tempdisagg,509801,30,2021-09-17T19:17:43Z,16993.366666666665
Tendril,"Compute the coordinates to produce a tendril plot. 
    In the tendril plot, each tendril (branch) represents a type of events, 
    and the direction of the tendril is dictated by on which treatment arm the 
    event is occurring. If an event is occurring on the first of the two 
    specified treatment arms, the tendril bends in a clockwise direction. 
    If an event is occurring on the second of the treatment arms, the
    tendril bends in an anti-clockwise direction. 
    Ref: Karpefors, M and Weatherall, J., ""The Tendril Plot - a novel visual summary 
    of the incidence, significance and temporal aspects of adverse events in 
    clinical trials"" - JAMIA 2018; 25(8): 1069-1073 <doi:10.1093/jamia/ocy016>.",2020-02-11,Martin Karpefors,https://github.com/Karpefors/Tendril,TRUE,https://github.com/karpefors/tendril,10586,5,2022-05-26T15:51:33Z,2117.2
tensorflow,"Interface to 'TensorFlow' <https://www.tensorflow.org/>,
  an open source software library for numerical computation using data
  flow graphs. Nodes in the graph represent mathematical operations,
  while the graph edges represent the multidimensional data arrays
  (tensors) communicated between them. The flexible architecture allows
  you to deploy computation to one or more 'CPUs' or 'GPUs' in a desktop,
  server, or mobile device with a single 'API'. 'TensorFlow' was originally
  developed by researchers and engineers working on the Google Brain Team
  within Google's Machine Intelligence research organization for the
  purposes of conducting machine learning and deep neural networks research,
  but the system is general enough to be applicable in a wide variety
  of other domains as well.",2022-05-21,Daniel Falbel [ctb,https://github.com/rstudio/tensorflow,TRUE,https://github.com/rstudio/tensorflow,1076448,1259,2022-06-29T17:25:50Z,855.0023828435266
TensorTest2D,"An implementation of fitting generalized linear models on
    second-order tensor type data. The functions within this package mainly focus on
    parameter estimation, including parameter coefficients and standard deviation.",2022-01-03,Mark Chen,https://github.com/yuting1214/TensorTest2D,TRUE,https://github.com/yuting1214/tensortest2d,8512,0,2021-12-28T09:24:33Z,NA
tensorTS,"Factor and autoregressive models for matrix and tensor valued time series. We provide functions for estimation, simulation and prediction. The models are discussed in 
    Li et al (2021) <arXiv:2110.00928>, Chen et al (2020) <DOI:10.1080/01621459.2021.1912757>, 
    Chen et al (2020) <DOI:10.1016/j.jeconom.2020.07.015>, and Xiao et al (2020) <arXiv:2006.02611>.",2022-05-08,Zebang Li,https://github.com/zebang/tensorTS,TRUE,https://github.com/zebang/tensorts,6503,9,2022-05-08T14:58:12Z,722.5555555555555
tensr,"A collection of functions for Kronecker structured covariance
    estimation and testing under the array normal model. For estimation,
    maximum likelihood and Bayesian equivariant estimation procedures are
    implemented. For testing, a likelihood ratio testing procedure is
    available. This package also contains additional functions for manipulating
    and decomposing tensor data sets. This work was partially supported by NSF
    grant DMS-1505136. Details of the methods are described in
    Gerard and Hoff (2015) <doi:10.1016/j.jmva.2015.01.020> and
    Gerard and Hoff (2016) <doi:10.1016/j.laa.2016.04.033>.",2018-08-15,David Gerard,NA,TRUE,https://github.com/dcgerard/tensr,14182,3,2022-03-30T15:11:49Z,4727.333333333333
tergm,"An integrated set of extensions to the 'ergm' package to analyze and simulate network evolution based on exponential-family random graph models (ERGM). 'tergm' is a part of the 'statnet' suite of packages for network analysis. See Krivitsky and Handcock (2014) <doi:10.1111/rssb.12014> and Carnegie, Krivitsky, Hunter, and Goodreau (2015) <doi:10.1080/10618600.2014.903087>.",2022-06-22,Pavel N. Krivitsky,https://statnet.org,TRUE,https://github.com/statnet/tergm,127476,17,2022-06-22T14:20:08Z,7498.588235294118
term,"Creates, manipulates, queries and repairs vectors of
    parameter terms.  Parameter terms are the labels used to reference
    values in vectors, matrices and arrays. They represent the names in
    coefficient tables and the column names in 'mcmc' and 'mcmc.list'
    objects.",2022-03-03,Joe Thorley,"https://poissonconsulting.github.io/term/,
https://github.com/poissonconsulting/term",TRUE,https://github.com/poissonconsulting/term,28915,10,2022-03-03T15:49:17Z,2891.5
Ternary,"Plots ternary diagrams (simplex plots / Gibbs triangles) and
  Holdridge life zone plots <doi:10.1126/science.105.2727.367> using the
  standard graphics functions.
  An alternative to 'ggtern', which uses the 'ggplot2' family of plotting 
  functions.
  Includes a 'Shiny' user interface for point-and-click ternary plotting.",2022-05-09,Martin R. Smith,"https://ms609.github.io/Ternary/,
https://github.com/ms609/Ternary/",TRUE,https://github.com/ms609/ternary,37708,18,2022-06-15T18:33:59Z,2094.8888888888887
terra,"Methods for spatial data analysis with raster and vector data. Raster methods allow for low-level data manipulation as well as high-level global, local, zonal, and focal computation. The predict and interpolate methods facilitate the use of regression type (interpolation, machine learning) models for spatial prediction, including with satellite remote sensing data. Processing of very large files is supported. See the manual and tutorials on <https://rspatial.org/terra/> to get started. 'terra' is very similar to the 'raster' package; but 'terra' can do more, is easier to use, and it is faster.",2022-06-09,Robert J. Hijmans,https://rspatial.org/terra/,TRUE,https://github.com/rspatial/terra,2941267,347,2022-07-10T00:15:08Z,8476.273775216137
terrainr,"Functions for the retrieval, manipulation, and visualization
    of 'geospatial' data, with an aim towards producing '3D' landscape
    visualizations in the 'Unity' '3D' rendering engine. Functions are
    also provided for retrieving elevation data and base map tiles from
    the 'USGS' National Map <https://apps.nationalmap.gov/services/>.",2022-05-05,Michael Mahoney,"https://docs.ropensci.org/terrainr/,
https://github.com/ropensci/terrainr",TRUE,https://github.com/ropensci/terrainr,8253,55,2022-07-06T20:38:50Z,150.05454545454546
tessellation,"Delaunay and Voronoï tessellations, with emphasis on the two-dimensional and the three-dimensional cases (the package provides functions to plot the tessellations for these cases). Delaunay tessellations are computed in C with the help of the 'Qhull' library <http://www.qhull.org/>.",2022-04-05,Stéphane Laurent,"https://github.com/stla/tessellation,
https://stla.github.io/tessellation/",TRUE,https://github.com/stla/tessellation,1865,13,2022-04-05T12:47:38Z,143.46153846153845
tesselle,"Easy install and load key packages from the 'tesselle' suite
    in a single step. The 'tesselle' suite is a collection of packages for
    research and teaching in archaeology. These packages focus on
    quantitative analysis methods developed for archaeology. The
    'tesselle' packages are designed to work seamlessly together and to
    complement general-purpose and other specialized statistical packages.
    These packages can be used to explore and analyze common data types in
    archaeology: count data, compositional data and chronological data.
    Learn more about 'tesselle' at <https://www.tesselle.org>.",2022-04-28,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>,"https://github.com/tesselle/tesselle,
https://packages.tesselle.org/tesselle/",TRUE,https://github.com/tesselle/tesselle,456,0,2022-04-28T10:07:00Z,NA
testdat,"Test your data! An extension of the 'testthat' unit testing
    framework with a family of functions and reporting tools for checking
    and validating data frames.",2022-01-04,Danny Smith,"https://socialresearchcentre.github.io/testdat/,
https://github.com/socialresearchcentre/testdat",TRUE,https://github.com/socialresearchcentre/testdat,2459,1,2022-01-11T23:00:35Z,2459
TestDesign,"Uses the optimal test design approach by Birnbaum (1968, ISBN:9781593119348) and
    van der Linden (2018) <doi:10.1201/9781315117430> to construct fixed, adaptive, and parallel tests.
    Supports the following mixed-integer programming (MIP) solver packages: 'lpsymphony', 'Rsymphony',
    'gurobi', 'lpSolve', and 'Rglpk'. The 'gurobi' package is not available from CRAN; see <https://www.gurobi.com/downloads/>. ",2022-05-16,Seung W. Choi,https://choi-phd.github.io/TestDesign/ (documentation),TRUE,https://github.com/choi-phd/testdesign,20621,2,2022-07-03T22:32:53Z,10310.5
testDriveR,"Provides data sets for teaching statistics and data science courses. 
    It includes a sample of data from John Edmund Kerrich's famous 
    coinflip experiment. These are data that I used for teaching SOC 4015 / SOC 
    5050 at Saint Louis University (SLU). The package also contains an R Markdown
    template with the required formatting for assignments in my courses 
    SOC 4015, SOC 4650, SOC 5050, and SOC 5650 at SLU.",2022-05-29,Christopher Prener,https://github.com/chris-prener/testDriveR,TRUE,https://github.com/chris-prener/testdriver,11035,2,2022-05-29T01:18:39Z,5517.5
testthat,"Software testing is important, but, in part because it is
    frustrating and boring, many of us avoid it. 'testthat' is a testing
    framework for R that is easy to learn and use, and integrates with
    your existing 'workflow'.",2022-04-26,Hadley Wickham,"https://testthat.r-lib.org, https://github.com/r-lib/testthat",TRUE,https://github.com/r-lib/testthat,19938096,796,2022-06-02T20:03:26Z,25047.859296482413
testthis,"Utility functions and 'RStudio' addins for writing,
    running and organizing automated tests. Integrates tightly with the
    packages 'testthat', 'devtools' and 'usethis'.  Hotkeys can be
    assigned to the 'RStudio' addins for running tests in a single file or
    to switch between a source file and the associated test file. In
    addition, testthis provides function to manage and run tests in
    subdirectories of the test/testthat directory.",2020-04-12,Stefan Fleck,https://s-fleck.github.io/testthis,TRUE,https://github.com/s-fleck/testthis,21641,31,2022-02-15T12:31:42Z,698.0967741935484
texmex,"Statistical extreme value modelling of threshold excesses, maxima
    and multivariate extremes. Univariate models for threshold excesses and maxima
    are the Generalised Pareto, and Generalised Extreme Value model respectively.
    These models may be fitted by using maximum (optionally penalised-)likelihood,
    or Bayesian estimation, and both classes of models may be fitted with covariates
    in any/all model parameters. Model diagnostics support the fitting process.
    Graphical output for visualising fitted models and return level estimates is
    provided. For serially dependent sequences, the intervals declustering algorithm
    of Ferro and Segers (2003) <doi:10.1111/1467-9868.00401> is provided, with
    diagnostic support to aid selection of threshold and declustering horizon.
    Multivariate modelling is performed via the conditional approach of Heffernan
    and Tawn (2004) <doi:10.1111/j.1467-9868.2004.02050.x>, with graphical tools for
    threshold selection and to diagnose estimation convergence.",2020-12-04,Harry Southworth,https://github.com/harrysouthworth/texmex,TRUE,https://github.com/harrysouthworth/texmex,19868,5,2022-03-15T08:28:05Z,3973.6
texPreview,"Compile snippets of 'LaTeX' directly into images
    from the R console to view in the 'RStudio' viewer pane, Shiny apps
    and 'RMarkdown' documents.",2022-03-31,Jonathan Sidi,https://github.com/yonicd/texPreview,TRUE,https://github.com/yonicd/texpreview,43215,48,2022-03-29T01:11:52Z,900.3125
texreg,"Converts coefficients, standard errors, significance stars, and goodness-of-fit statistics of statistical models into LaTeX tables or HTML tables/MS Word documents or to nicely formatted screen output for the R console for easy model comparison. A list of several models can be combined in a single table. The output is highly customizable. New model types can be easily implemented. Details can be found in Leifeld (2013), JStatSoft <doi:10.18637/jss.v055.i08>. (If the Zelig package, which this package enhances, cannot be found on CRAN, you can find it at <https://github.com/IQSS/Zelig>. If the mnlogit package, which this package enhances, cannot be found on CRAN, you can find an old version in the CRAN Archive at <https://cran.r-project.org/src/contrib/Archive/mnlogit/>.)",2022-04-06,Philip Leifeld,https://github.com/leifeld/texreg/,TRUE,https://github.com/leifeld/texreg,570164,96,2022-07-04T14:31:38Z,5939.208333333333
text,"Transforms text variables to word embeddings; where the word embeddings are used to statistically test the mean difference between set of texts, compute semantic similarity scores between texts, predict numerical variables, and visual statistically significant words according to various dimensions etc. For more information see  <https://www.r-text.org>.",2022-05-30,Oscar Kjell,"https://r-text.org/, https://github.com/OscarKjell/text/",TRUE,https://github.com/oscarkjell/text,7635,49,2022-07-10T14:01:46Z,155.81632653061226
text2sdg,"The United Nations’ Sustainable Development Goals (SDGs) have become an important guideline for organisations to monitor and plan their contributions to social, economic, and environmental transformations. The 'text2sdg' package is an open-source analysis package that identifies SDGs in text using scientifically developed query systems, opening up the opportunity to monitor any type of text-based data, such as scientific output or corporate publications.",2022-05-31,Dirk U. Wulff,https://github.com/dwulff/text2sdg,TRUE,https://github.com/dwulff/text2sdg,7009,5,2022-07-09T14:19:35Z,1401.8
text2vec,"Fast and memory-friendly tools for text vectorization, topic
    modeling (LDA, LSA), word embeddings (GloVe), similarities. This package
    provides a source-agnostic streaming API, which allows researchers to perform
    analysis of collections of documents which are larger than available RAM. All
    core functions are parallelized to benefit from multicore machines.",2022-04-21,Dmitriy Selivanov,http://text2vec.org,TRUE,https://github.com/dselivanov/text2vec,279055,770,2022-04-22T03:19:04Z,362.40909090909093
textclean,"Tools to clean and process text.  Tools are geared at checking for substrings that
          are not optimal for analysis and replacing or removing them (normalizing) with more
          analysis friendly substrings (see Sproat, Black, Chen, Kumar, Ostendorf, & Richards
          (2001) <doi:10.1006/csla.2001.0169>) or extracting them into new variables. For
          example, emoticons are often used in text but not always easily handled by analysis
          algorithms.  The replace_emoticon() function replaces emoticons with word
          equivalents.",2018-07-23,Tyler Rinker,https://github.com/trinker/textclean,TRUE,https://github.com/trinker/textclean,323592,206,2021-11-01T17:03:58Z,1570.8349514563106
textdata,"Provides a framework to download, parse, and store text
    datasets on the disk and load them when needed. Includes various
    sentiment lexicons and labeled text data sets for classification and
    analysis.",2022-05-02,Emil Hvitfeldt,https://github.com/EmilHvitfeldt/textdata,TRUE,https://github.com/emilhvitfeldt/textdata,187008,69,2022-05-02T21:37:44Z,2710.2608695652175
texter,"Implement text and sentiment analysis with 'texter'. 
             Generate sentiment scores on text data and also visualize sentiments.
             'texter' allows you to quickly generate insights on your data.
             It includes support for lexicons such as 'NRC' and 'Bing'.",2021-09-20,Simi Kafaru,https://github.com/simmieyungie/texter,TRUE,https://github.com/simmieyungie/texter,3551,2,2021-09-20T22:21:29Z,1775.5
textmineR,"An aid for text mining in R, with a syntax that
    should be familiar to experienced R users. Provides a wrapper for several 
    topic models that take similarly-formatted input and give similarly-formatted
    output. Has additional functionality for analyzing and diagnostics for
    topic models.",2021-06-28,Tommy Jones,https://www.rtextminer.com/,TRUE,https://github.com/tommyjones/textminer,72090,102,2022-05-11T01:57:33Z,706.7647058823529
textplot,"Visualise complex relations in texts. This is done by providing functionalities for displaying 
    text co-occurrence networks, text correlation networks, dependency relationships as well as text clustering and semantic text 'embeddings'. 
    Feel free to join the effort of providing interesting text visualisations.",2021-10-14,Jan Wijffels,https://github.com/bnosac/textplot,TRUE,https://github.com/bnosac/textplot,17756,48,2021-10-12T18:40:22Z,369.9166666666667
textreadr,A small collection of convenience tools for reading text documents into R.,2021-10-09,Tyler Rinker,https://github.com/trinker/textreadr,TRUE,https://github.com/trinker/textreadr,56259,65,2021-10-09T23:11:30Z,865.5230769230769
textrecipes,"Converting text to numerical features requires specifically
    created procedures, which are implemented as steps according to the
    'recipes' package. These steps allows for tokenization, filtering,
    counting (tf and tfidf) and feature hashing.",2022-07-02,Emil Hvitfeldt,"https://github.com/tidymodels/textrecipes,
https://textrecipes.tidymodels.org,
https://textrecipes.tidymodels.org/",TRUE,https://github.com/tidymodels/textrecipes,52256,134,2022-07-02T17:47:31Z,389.97014925373134
textshape,Tools that can be used to reshape and restructure text data.,2021-05-28,Tyler Rinker,https://github.com/trinker/textshape,TRUE,https://github.com/trinker/textshape,669762,42,2021-10-08T22:18:19Z,15946.714285714286
textshaping,"Provides access to the text shaping functionality in the 'HarfBuzz'
    library and the bidirectional algorithm in the 'Fribidi' library. 
    'textshaping' is a low-level utility package mainly for graphic devices that 
    expands upon the font tool-set provided by the 'systemfonts' package.",2021-10-13,Thomas Lin Pedersen,https://github.com/r-lib/textshaping,TRUE,https://github.com/r-lib/textshaping,21576740,12,2021-10-25T07:03:06Z,1798061.6666666667
textTinyR,"It offers functions for splitting, parsing, tokenizing and creating a vocabulary for big text data files. Moreover, it includes functions for building a document-term matrix and extracting information from those (term-associations, most frequent terms). It also embodies functions for calculating token statistics (collocations, look-up tables, string dissimilarities) and functions to work with sparse matrices. Lastly, it includes functions for Word Vector Representations (i.e. 'GloVe', 'fasttext') and incorporates functions for the calculation of (pairwise) text document dissimilarities. The source code is based on 'C++11' and exported in R through the 'Rcpp', 'RcppArmadillo' and 'BH' packages.",2021-10-26,Lampros Mouselimis,https://github.com/mlampros/textTinyR,TRUE,https://github.com/mlampros/texttinyr,21128,31,2021-10-29T09:18:39Z,681.5483870967741
textutils,"Utilities for handling character vectors
  that store human-readable text (either plain or with
  markup, such as HTML or LaTeX). The package provides,
  in particular, functions that help with the
  preparation of plain-text reports, e.g. for expanding
  and aligning strings that form the lines of such
  reports. The package also provides generic functions for
  transforming R objects to HTML and to plain text.",2021-04-01,Enrico Schumann,"http://enricoschumann.net/R/packages/textutils/,
https://github.com/enricoschumann/textutils",TRUE,https://github.com/enricoschumann/textutils,71998,9,2021-09-09T18:29:39Z,7999.777777777777
tfaddons,"'TensorFlow SIG Addons' <https://www.tensorflow.org/addons> is a repository 
             of community contributions that conform to well-established API patterns, 
             but implement new functionality not available in core 'TensorFlow'. 
             'TensorFlow' natively supports a large number of operators, layers, metrics, 
             losses, optimizers, and more. However, in a fast moving field like Machine Learning, 
             there are many interesting new developments that cannot be integrated into 
             core 'TensorFlow' (because their broad applicability is not yet clear, or 
             it is mostly used by a smaller subset of the community).",2020-06-02,Turgut Abdullayev,https://github.com/henry090/tfaddons,TRUE,https://github.com/henry090/tfaddons,7412,18,2022-03-25T12:10:20Z,411.77777777777777
tfarima,"Building customized transfer function and ARIMA models with multiple operators and parameter restrictions. Functions for model identification, model estimation (exact or conditional maximum likelihood), model diagnostic checking, automatic outlier detection, calendar effects, forecasting and seasonal adjustment. See Bell and Hillmer (1983) <doi:10.1080/01621459.1983.10478005>, Box, Jenkins, Reinsel and Ljung <ISBN:978-1-118-67502-1>, Box, Pierce and Newbold (1987) <doi:10.1080/01621459.1987.10478430>, Box and Tiao (1975) <doi:10.1080/01621459.1975.10480264>, Chen and Liu (1993) <doi:10.1080/01621459.1993.10594321>.",2022-05-20,Jose L. Gallego,https://github.com/gallegoj/tfarima,TRUE,https://github.com/gallegoj/tfarima,10267,0,2022-05-24T16:47:40Z,NA
tfautograph,Translate R control flow expressions into 'Tensorflow' graphs.,2021-09-17,Tomasz Kalinowski,https://t-kalinowski.github.io/tfautograph/,TRUE,https://github.com/t-kalinowski/tfautograph,314466,14,2022-03-10T19:15:11Z,22461.85714285714
tfdatasets,"Interface to 'TensorFlow' Datasets, a high-level library for
    building complex input pipelines from simple, re-usable pieces.
    See <https://www.tensorflow.org/guide> for additional
    details.",2022-06-29,Tomasz Kalinowski [ctb,https://github.com/rstudio/tfdatasets,TRUE,https://github.com/rstudio/tfdatasets,125746,30,2022-06-30T00:09:11Z,4191.533333333334
tfestimators,"Interface to 'TensorFlow' Estimators 
    <https://www.tensorflow.org/guide/estimator>, a high-level 
    API that provides implementations of many different model types 
    including linear models and deep neural networks. ",2021-08-09,Kevin Kuo,https://github.com/rstudio/tfestimators,TRUE,https://github.com/rstudio/tfestimators,112611,57,2021-11-22T19:46:54Z,1975.6315789473683
tfhub,"'TensorFlow' Hub is a library for the publication, discovery, and
    consumption of reusable parts of machine learning models. A module is a 
    self-contained piece of a 'TensorFlow' graph, along with its weights and 
    assets, that can be reused across different tasks in a process known as
    transfer learning. Transfer learning train a model with a smaller dataset,
    improve generalization, and speed up training.",2021-12-19,Tomasz Kalinowski,https://github.com/rstudio/tfhub,TRUE,https://github.com/rstudio/tfhub,14995,27,2021-12-20T21:43:19Z,555.3703703703703
tfio,"Interface to 'TensorFlow IO', Datasets and filesystem extensions maintained by `TensorFlow SIG-IO` <https://github.com/tensorflow/community/blob/master/sigs/io/CHARTER.md>.",2019-12-19,TensorFlow IO Contributors,https://github.com/tensorflow/io,TRUE,https://github.com/tensorflow/io,11054,564,2022-05-17T05:27:38Z,19.599290780141843
tfprobability,"Interface to 'TensorFlow Probability', a 'Python' library built on 'TensorFlow'
    that makes it easy to combine probabilistic models and deep learning on modern hardware ('TPU', 'GPU').
    'TensorFlow Probability' includes a wide selection of probability distributions and bijectors, probabilistic layers,
    variational inference, Markov chain Monte Carlo, and optimizers such as Nelder-Mead, BFGS, and SGLD.",2022-02-02,Tomasz Kalinowski [ctb,https://github.com/rstudio/tfprobability,TRUE,https://github.com/rstudio/tfprobability,22624,50,2022-02-01T18:33:24Z,452.48
tfruns,"Create and manage unique directories for each 'TensorFlow' 
  training run. Provides a unique, time stamped directory for each run
  along with functions to retrieve the directory of the latest run or 
  latest several runs. ",2021-02-26,Daniel Falbel [ctb,https://github.com/rstudio/tfruns,TRUE,https://github.com/rstudio/tfruns,1061596,32,2021-11-22T19:49:14Z,33174.875
tglkmeans,"Efficient implementation of K-Means++ algorithm. For more information see (1) ""kmeans++ the advantages of the k-means++ algorithm"" by David Arthur and Sergei Vassilvitskii (2007), Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, pp. 1027-1035, <http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf>, and (2) ""The Effectiveness of Lloyd-Type Methods for the k-Means Problem"" by Rafail Ostrovsky, Yuval Rabani, Leonard J. Schulman and Chaitanya Swamy <doi:10.1145/2395116.2395117>.",2022-04-20,Aviezer Lifshitz,NA,TRUE,https://github.com/tanaylab/tglkmeans,330,4,2022-04-28T09:47:11Z,82.5
tgstat,"A collection of high performance utilities to compute
    distance, correlation, auto correlation, clustering and other tasks.
    Contains graph clustering algorithm described in ""MetaCell: analysis
    of single-cell RNA-seq data using K-nn graph partitions"" (Yael Baran,
    Akhiad Bercovich, Arnau Sebe-Pedros, Yaniv Lubling, Amir Giladi, Elad
    Chomsky, Zohar Meir, Michael Hoichman, Aviezer Lifshitz & Amos Tanay,
    2019 <doi:10.1186/s13059-019-1812-2>).",2022-04-14,Aviezer Lifshitz,NA,TRUE,https://github.com/tanaylab/tgstat,6231,0,2022-05-10T09:29:18Z,NA
tgver,Turing Geovisualization Engine R package for geospatial visualization and analysis.,2022-03-08,Layik Hama,https://github.com/tgve/tgver,TRUE,https://github.com/tgve/tgver,977,5,2022-03-31T04:19:45Z,195.4
thaipdf,"Provide R Markdown templates and LaTeX preamble
    which are necessary for creating PDF from R Markdown documents in Thai language.",2022-04-22,Kittipos Sirivongrungson,https://lightbridge-ks.github.io/thaipdf/,TRUE,https://github.com/lightbridge-ks/thaipdf,502,3,2022-06-13T15:02:47Z,167.33333333333334
theft,"Consolidates and calculates different sets of time-series features from multiple
    'R' and 'Python' packages including 'Rcatch22' Henderson, T. (2021) <doi:10.5281/zenodo.5546815>,
    'feasts' O'Hara-Wild, M., Hyndman, R., and Wang, E. (2021) <https://CRAN.R-project.org/package=feasts>,
    'tsfeatures' Hyndman, R., Kang, Y., Montero-Manso, P., Talagala, T., Wang, E., Yang, Y., and O'Hara-Wild, M. (2020)
    <https://CRAN.R-project.org/package=tsfeatures>, 'tsfresh' Christ, M., Braun, N., Neuffer, J.,
    and Kempa-Liehr A.W. (2018) <doi:10.1016/j.neucom.2018.03.067>, 'TSFEL' Barandas, M., et al. (2020)
    <doi:10.1016/j.softx.2020.100456>, and 'Kats' Facebook Infrastructure Data Science (2021)
    <https://facebookresearch.github.io/Kats/>. Provides a standardised workflow from feature calculation to
    feature processing, machine learning classification procedures, and the production of statistical graphics.",2022-05-31,Trent Henderson,https://hendersontrent.github.io/theft/,TRUE,https://github.com/hendersontrent/theft,854,10,2022-07-05T00:58:44Z,85.4
theiaR,"Provides a simple interface to search available data provided by
    Theia (<https://theia.cnes.fr>), download it, and manage it. Data can be downloaded
    based on a search result or from a cart file downloaded from Theia website.",2020-11-19,Xavier Laviron,https://github.com/norival/theiaR,TRUE,https://github.com/norival/theiar,12073,3,2022-06-29T09:48:56Z,4024.3333333333335
themis,"A dataset with an uneven number of cases in each class is
    said to be unbalanced. Many models produce a subpar performance on
    unbalanced datasets. A dataset can be balanced by increasing the
    number of minority cases using SMOTE 2011 <arXiv:1106.1813>,
    BorderlineSMOTE 2005 <doi:10.1007/11538059_91> and ADASYN 2008
    <https://ieeexplore.ieee.org/document/4633969>. Or by decreasing the
    number of majority cases using NearMiss 2003
    <https://www.site.uottawa.ca/~nat/Workshop2003/jzhang.pdf> or Tomek
    link removal 1976 <https://ieeexplore.ieee.org/document/4309452>.",2022-07-02,Emil Hvitfeldt,"https://github.com/tidymodels/themis,
https://themis.tidymodels.org, https://themis.tidymodels.org/",TRUE,https://github.com/tidymodels/themis,118460,127,2022-07-02T17:41:15Z,932.7559055118111
Thermimage,"A collection of functions and routines for inputting thermal
    image video files, plotting and converting binary raw data into estimates of
    temperature.  First published 2015-03-26.  Written primarily for research purposes
    in biological applications of thermal images.  v1 included the base calculations 
    for converting thermal image binary values to temperatures. v2 included additional
    equations for providing heat transfer calculations and an import function for thermal
    image files (v2.2.3 fixed error importing thermal image to windows OS). v3. Added numerous
    functions for converting thermal image, videos, rewriting and exporting.  
    v3.1. Added new functions to convert files. v3.2.  Fixed the various functions related to finding frame times.
    v4.0. fixed an error in atmospheric attenuation constants, affecting raw2temp and temp2raw functions.
    Recommend update for use with long distance calculations. v.4.1.3 changed to frameLocates to reflect change to as.character() to format().",2021-09-27,Glenn J. Tattersall,"https://cran.r-project.org/package=Thermimage,
https://github.com/gtatters/Thermimage",TRUE,https://github.com/gtatters/thermimage,48864,127,2021-09-23T23:18:27Z,384.755905511811
thestats,A user-friendly R data package that is intended to make Turkish higher education statistics more accessible. ,2022-01-04,Olgun Aydin,https://github.com/analyticsresearchlab/thestats,TRUE,https://github.com/analyticsresearchlab/thestats,1527,13,2022-05-21T12:10:26Z,117.46153846153847
thinkr,"Some tools for cleaning up messy 'Excel' files to
    be suitable for R. People who have been working with 'Excel' for years
    built more or less complicated sheets with names, characters, formats
    that are not homogeneous. To be able to use them in R nowadays, we
    built a set of functions that will avoid the majority of importation
    problems and keep all the data at best.",2020-07-07,Vincent Guyader,https://github.com/Thinkr-open/thinkr,TRUE,https://github.com/thinkr-open/thinkr,19155,19,2021-07-16T10:39:06Z,1008.1578947368421
this.path,"Determine the full path of the executing script. Works when 
    running a line or selection from a script in 'RStudio' and 'Rgui', when 
    using 'source', 'sys.source', 'debugSource' in 'RStudio', and 
    'testthat::source_file', and when running R from a shell.",2022-04-24,Andrew Simmons,https://github.com/ArcadeAntics/this.path,TRUE,https://github.com/arcadeantics/this.path,19802,8,2022-07-10T02:00:13Z,2475.25
thredds,"Provides a crawler for programmatically navigating THREDDS Data Server (<https://www.unidata.ucar.edu/software/thredds/current/tds/TDS.html>) 
  catalogs, and access dataset metadata and resources.",2022-02-14,Emmanuel Blondel,"https://github.com/BigelowLab/thredds,
https://www.unidata.ucar.edu/software/thredds/current/tds/TDS.html",TRUE,https://github.com/bigelowlab/thredds,1344,2,2022-02-14T13:47:55Z,672
threejs,"Create interactive 3D scatter plots, network plots, and
    globes using the 'three.js' visualization library (<https://threejs.org>).",2020-01-21,B. W. Lewis,https://bwlewis.github.io/rthreejs,TRUE,https://github.com/bwlewis/rthreejs,533511,275,2021-08-31T02:43:52Z,1940.04
threshr,"Provides functions for the selection of thresholds for use in 
    extreme value models, based mainly on the methodology in 
    Northrop, Attalides and Jonathan (2017) <doi:10.1111/rssc.12159>.
    It also performs predictive inferences about future extreme values, 
    based either on a single threshold or on a weighted average of inferences 
    from multiple thresholds, using the 'revdbayes' package 
    <https://cran.r-project.org/package=revdbayes>.   
    At the moment only the case where the data can be treated as 
    independent identically distributed observations is considered.",2020-09-14,Paul J. Northrop,"https://paulnorthrop.github.io/threshr/,
https://github.com/paulnorthrop/threshr",TRUE,https://github.com/paulnorthrop/threshr,15629,5,2022-04-04T10:02:54Z,3125.8
thriftr,"Pure R implementation of Apache Thrift.
    This library doesn't require any code generation.
    To learn more about Thrift go to <https://thrift.apache.org>.",2022-05-10,Marek Jagielski,https://github.com/systemincloud/thriftr,TRUE,https://github.com/systemincloud/thriftr,10635,17,2022-05-08T13:12:21Z,625.5882352941177
thunder,Collection of functions for rapid computation and visualisation of convective parameters commonly used in the operational prediction of severe convective storms. Core algorithm is based on a highly optimized 'C++' code linked into 'R' via 'Rcpp'. Highly efficient engine allows to derive thermodynamic and kinematic parameters from large numerical datasets such as reanalyses or operational Numerical Weather Prediction models in a reasonable amount of time. Package has been developed since 2017 by research meteorologists specializing in severe thunderstorms.,2022-02-28,Bartosz Czernecki,https://bczernecki.github.io/thundeR/,TRUE,https://github.com/bczernecki/thunder,1681,17,2022-02-25T12:21:54Z,98.88235294117646
thurstonianIRT,"Fit Thurstonian Item Response Theory (IRT) models in R. This 
  package supports fitting Thurstonian IRT models and its extensions using 
  'Stan', 'lavaan', or 'Mplus' for the model estimation. Functionality for 
  extracting results, making predictions, and simulating data is provided as 
  well. References: 
  Brown & Maydeu-Olivares (2011) <doi:10.1177/0013164410375112>;
  Bürkner et al. (2019) <doi:10.1177/0013164419832063>.",2021-09-26,Paul-Christian Bürkner,https://github.com/paul-buerkner/thurstonianIRT,TRUE,https://github.com/paul-buerkner/thurstonianirt,15615,22,2021-09-26T11:55:05Z,709.7727272727273
tibble,"Provides a 'tbl_df' class (the 'tibble') with stricter checking and better formatting than the traditional
    data frame.",2022-05-03,Kirill Müller,"https://tibble.tidyverse.org/, https://github.com/tidyverse/tibble",TRUE,https://github.com/tidyverse/tibble,38380513,556,2022-06-30T03:32:06Z,69029.69964028777
tidybayes,"Compose data for and extract, manipulate, and visualize posterior draws from Bayesian models
    ('JAGS', 'Stan', 'rstanarm', 'brms', 'MCMCglmm', 'coda', ...) in a tidy data format. Functions are provided
    to help extract tidy data frames of draws from Bayesian models and that generate point
    summaries and intervals in a tidy format. In addition, 'ggplot2' 'geoms' and 'stats' are provided for
    common visualization primitives like points with multiple uncertainty intervals, eye plots (intervals plus
    densities), and fit curves with multiple, arbitrary uncertainty bands.",2022-01-05,Matthew Kay,"https://mjskay.github.io/tidybayes/,
https://github.com/mjskay/tidybayes/",TRUE,https://github.com/mjskay/tidybayes,122583,662,2022-02-20T03:22:46Z,185.17069486404833
tidyBdE,"Tools to download data series from 'Banco de España' ('BdE')
    on 'tibble' format. 'Banco de España' is the national central bank
    and, within the framework of the Single Supervisory Mechanism ('SSM'),
    the supervisor of the Spanish banking system along with the European
    Central Bank. This package is in no way sponsored endorsed or
    administered by 'Banco de España'.",2022-02-23,Diego H. Herrero,"https://ropenspain.github.io/tidyBdE/,
https://github.com/rOpenSpain/tidyBdE",TRUE,https://github.com/ropenspain/tidybde,6721,5,2022-05-19T06:45:11Z,1344.2
tidybins,"Multiple ways to bin numeric columns with a tidy output. Wraps a variety of existing binning methods into one function, and includes a new method for binning by equal value, which is useful for sales data. Provides a function to automatically summarize the properties of the binned columns. ",2021-10-14,Harrison Tietze,https://github.com/Harrison4192/tidybins,TRUE,https://github.com/harrison4192/tidybins,2864,2,2022-02-14T11:51:51Z,1432
tidycat,Create additional rows and columns on broom::tidy() output to allow for easier control on categorical parameter estimates. ,2021-08-02,Guy J. Abel,https://guyabel.github.io/tidycat/,TRUE,https://github.com/guyabel/tidycat,8906,4,2021-08-18T05:19:13Z,2226.5
tidycensus,"An integrated R interface to several United States Census Bureau 
    APIs (<https://www.census.gov/data/developers/data-sets.html>) and the US Census Bureau's 
    geographic boundary files. Allows R users to return Census and ACS data as 
    tidyverse-ready data frames, and optionally returns a list-column with feature geometry for mapping 
    and spatial analysis. ",2022-06-03,Kyle Walker,https://walker-data.com/tidycensus/,TRUE,https://github.com/walkerke/tidycensus,243109,525,2022-06-03T13:02:46Z,463.0647619047619
tidycharts,"There is a wide range of R packages created for data visualization, but still, there was no simple and easily accessible way to create clean and transparent charts - up to now. The 'tidycharts' package enables the user to generate charts compliant with International Business Communication Standards ('IBCS').
    It means unified bar widths, colors, chart sizes, etc. Creating homogeneous reports has never been that easy! Additionally, users can apply semantic notation to indicate different data scenarios (plan, budget, forecast). What's more, it is possible to customize the charts by creating a personal color pallet with the possibility of switching to default options after the experiments.
    We wanted the package to be helpful in writing reports, so we also made joining charts in a one, clear image possible.
    All charts are generated in SVG format and can be shown in the 'RStudio' viewer pane or exported to HTML output of 'knitr'/'markdown'.",2022-01-18,Bartosz Sawicki,"https://mi2datalab.github.io/tidycharts/,
https://github.com/MI2DataLab/tidycharts",TRUE,https://github.com/mi2datalab/tidycharts,3721,2,2022-01-18T11:19:10Z,1860.5
tidycmprsk,"Provides an intuitive interface for working with the
    competing risk endpoints. The package wraps the 'cmprsk' package, and
    exports functions for univariate cumulative incidence estimates and
    competing risk regression. Methods follow those introduced in Fine and
    Gray (1999) <doi:10.1002/sim.7501>.",2022-03-04,Daniel D. Sjoberg,https://mskcc-epi-bio.github.io/tidycmprsk/,TRUE,https://github.com/mskcc-epi-bio/tidycmprsk,8262,13,2022-03-04T18:26:03Z,635.5384615384615
TidyConsultant,"Loads the 5 packages in the Tidy Consultant Universe. This collection of packages is useful for anyone doing data science,
    data analysis, or quantitative consulting. The functions in these packages range from data cleaning, data validation, data binning, statistical modeling, and file exporting.  ",2021-11-02,Harrison Tietze,"https://harrison4192.github.io/TidyConsultant/,
https://github.com/Harrison4192/TidyConsultant",TRUE,https://github.com/harrison4192/tidyconsultant,2300,3,2022-02-14T11:58:51Z,766.6666666666666
tidyCpp,"Core parts of the C API of R are wrapped in a C++ namespace via a set
 of inline functions giving a tidier representation of the underlying data structures
 and functionality using a header-only implementation without additional dependencies.",2021-12-06,Dirk Eddelbuettel,"https://github.com/eddelbuettel/tidycpp,
https://dirk.eddelbuettel.com/code/tidycpp.html",TRUE,https://github.com/eddelbuettel/tidycpp,9272,37,2022-05-13T14:59:17Z,250.59459459459458
tidycwl,"The Common Workflow Language <https://www.commonwl.org/> is an
    open standard for describing data analysis workflows. This package takes
    the raw Common Workflow Language workflows encoded in JSON or 'YAML'
    and turns the workflow elements into tidy data frames or lists.
    A graph representation for the workflow can be constructed and visualized
    with the parsed workflow inputs, outputs, and steps. Users can embed the
    visualizations in their 'Shiny' applications, and export them
    as HTML files or static images.",2022-05-03,Soner Koc,"https://sbg.github.io/tidycwl/, https://github.com/sbg/tidycwl",TRUE,https://github.com/sbg/tidycwl,12347,7,2022-03-29T19:15:50Z,1763.857142857143
tidydatatutor,"Visualize your 'Tidyverse' data analysis pipelines via the 
    'Tidy Data Tutor'(<https://tidydatatutor.com/>) web application.",2021-12-10,Sean Kross,https://github.com/seankross/tidydatatutor,TRUE,https://github.com/seankross/tidydatatutor,1786,16,2021-12-13T17:33:17Z,111.625
TidyDensity,"
    To make it easy to generate random numbers based upon the underlying stats 
    distribution functions. All data is returned in a tidy and structured
    format making working with the data simple and straight forward. Given that the
    data is returned in a tidy 'tibble' it lends itself to working with the rest of the
    'tidyverse'.",2022-06-08,Steven Sanderson,https://github.com/spsanderson/TidyDensity,TRUE,https://github.com/spsanderson/tidydensity,2676,9,2022-07-07T17:35:50Z,297.3333333333333
tidydr,"Dimensionality reduction (DR) is widely used in many domain for analyzing and visualizing high-dimensional data. 'tidydr' provides uniform output and is compatible with multiple methods, including 'prcomp', 'mds', 'Rtsne'. etc.",2022-03-16,Guangchuang Yu,https://github.com/YuLab-SMU/tidydr/,TRUE,https://github.com/yulab-smu/tidydr,3806,8,2022-03-17T01:34:10Z,475.75
tidyestimate,"The 'ESTIMATE' package infers tumor purity from expression data as a 
  function of immune and stromal infiltrate, but requires writing of intermediate 
  files, is un-pipeable, and performs poorly when presented with modern datasets 
  with current gene symbols. 'tidyestimate' a fast, tidy, modern reimagination of
  'ESTIMATE' (2013) <doi:10.1038/ncomms3612>.",2021-09-09,Kai Aragaki,https://github.com/KaiAragaki/tidyestimate,TRUE,https://github.com/kaiaragaki/tidyestimate,2761,5,2022-04-21T18:49:24Z,552.2
tidyfst,"A toolkit of tidy data manipulation verbs with 'data.table' as the backend.
  Combining the merits of syntax elegance from 'dplyr' and computing performance from 'data.table', 
  'tidyfst' intends to provide users with state-of-the-art data manipulation tools with least pain.
  This package is an extension of 'data.table'. While enjoying a tidy syntax, 
  it also wraps combinations of efficient functions to facilitate frequently-used data operations.  ",2022-04-27,Tian-Yuan Huang,"https://github.com/hope-data-science/tidyfst,
https://hope-data-science.github.io/tidyfst/",TRUE,https://github.com/hope-data-science/tidyfst,22326,64,2022-04-29T06:51:18Z,348.84375
tidygate,"It interactively or programmatically label points within custom gates on two dimensions <https://github.com/stemangiola/tidygate>. 
    The information is added to your tibble. It is based on the package 'gatepoints' from Wajid Jawaid (who is also author of this package). The code of 'gatepoints' was nto integrated in 'tidygate'. 
    The benefits are (i) in interactive mode you can draw your gates on extensive 'ggplot'-like scatter plots; 
    (ii) you can draw multiple gates; and (iii) you can save your gates and apply the programmatically.",2022-01-20,Stefano Mangiola,https://github.com/stemangiola/tidygate,TRUE,https://github.com/stemangiola/tidygate,9436,13,2022-02-01T22:16:26Z,725.8461538461538
tidygeocoder,An intuitive interface for getting data from geocoding services. ,2021-11-02,Jesse Cambon,"https://jessecambon.github.io/tidygeocoder/,
https://github.com/jessecambon/tidygeocoder",TRUE,https://github.com/jessecambon/tidygeocoder,114581,229,2022-06-26T15:22:34Z,500.353711790393
tidygraph,"A graph, while not ""tidy"" in itself, can be thought of as two tidy
    data frames describing node and edge data respectively. 'tidygraph'
    provides an approach to manipulate these two virtual data frames using the
    API defined in the 'dplyr' package, as well as provides tidy interfaces to 
    a lot of common graph algorithms.",2022-04-05,Thomas Lin Pedersen,"https://tidygraph.data-imaginist.com,
https://github.com/thomasp85/tidygraph",TRUE,https://github.com/thomasp85/tidygraph,1374869,465,2022-04-06T06:24:20Z,2956.7075268817202
tidyHeatmap,"This is a tidy implementation for heatmap.  At the
    moment it is based on the (great) package 'ComplexHeatmap'.  The goal
    of this package is to interface a tidy data frame with this powerful
    tool.  Some of the advantages are: Row and/or columns colour
    annotations are easy to integrate just specifying one parameter
    (column names).  Custom grouping of rows is easy to specify providing
    a grouped tbl. For example: df %>% group_by(...).  Labels size
    adjusted by row and column total number.  Default use of Brewer and
    Viridis palettes.",2022-05-20,Stefano Mangiola,"https://www.r-project.org,
https://github.com/stemangiola/tidyHeatmap",TRUE,https://github.com/stemangiola/tidyheatmap,22988,215,2022-05-20T03:20:54Z,106.92093023255813
tidyhydat,"Provides functions to access historical and real-time national 'hydrometric'
    data from Water Survey of Canada data sources (<https://dd.weather.gc.ca/hydrometric/csv/> and
    <https://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/>) and then applies tidy data principles.",2022-03-18,Sam Albers,"https://docs.ropensci.org/tidyhydat/,
https://github.com/ropensci/tidyhydat/",TRUE,https://github.com/ropensci/tidyhydat,22925,64,2022-03-18T16:01:02Z,358.203125
tidylab,"Selection of packages designed to be loaded in concert. The
    'tidylab' package collection revolves around project development and
    deployment. The purpose of this is to make it easy to install and
    subsequently load those packages.",2021-11-08,Harel Lustiger,"https://tidylab.github.io/tidylab/,
https://github.com/tidylab/tidylab",TRUE,https://github.com/tidylab/tidylab,1825,0,2021-11-13T01:45:15Z,NA
tidylda,"Implements an algorithm for Latent Dirichlet
    Allocation (LDA), Blei et at. (2003) <https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf>,
    using style conventions from the 'tidyverse',
    Wickham et al. (2019)<doi:10.21105/joss.01686>,
    and 'tidymodels', Kuhn et al.<https://tidymodels.github.io/model-implementation-principles/>.
    Fitting is done via collapsed Gibbs sampling.
    Also implements several novel features for LDA such as guided models and
    transfer learning based on ongoing and, as yet, unpublished research.",2021-12-08,Tommy Jones,https://github.com/TommyJones/tidylda/,TRUE,https://github.com/tommyjones/tidylda,3612,39,2021-12-13T03:45:39Z,92.61538461538461
tidylo,"How can we measure how the usage or frequency of some
    feature, such as words, differs across some group or set, such as
    documents? One option is to use the log odds ratio, but the log odds
    ratio alone does not account for sampling variability; we haven't
    counted every feature the same number of times so how do we know which
    differences are meaningful? Enter the weighted log odds, which
    'tidylo' provides an implementation for, using tidy data principles.
    In particular, here we use the method outlined in Monroe, Colaresi,
    and Quinn (2008) <doi:10.1093/pan/mpn018> to weight the log odds ratio
    by a prior. By default, the prior is estimated from the data itself,
    an empirical Bayes approach, but an uninformative prior is also
    available.",2022-03-22,Julia Silge,"https://juliasilge.github.io/tidylo/,
https://github.com/juliasilge/tidylo",TRUE,https://github.com/juliasilge/tidylo,10459,76,2022-03-22T14:56:26Z,137.6184210526316
tidylog,Provides feedback about 'dplyr' and 'tidyr' operations.,2020-07-03,Benjamin Elbers,https://github.com/elbersb/tidylog/,TRUE,https://github.com/elbersb/tidylog,159546,516,2022-01-30T16:02:51Z,309.19767441860466
tidyLPA,"An interface to the 'mclust' package to easily
    carry out latent profile analysis (""LPA""). Provides functionality to
    estimate commonly-specified models. Follows a tidy approach, in that
    output is in the form of a data frame that can subsequently be
    computed on. Also has functions to interface to the commercial 'MPlus'
    software via the 'MplusAutomation' package.",2021-11-17,Joshua M Rosenberg,https://data-edu.github.io/tidyLPA/,TRUE,https://github.com/data-edu/tidylpa,39928,39,2022-02-22T17:13:48Z,1023.7948717948718
tidymodels,"The tidy modeling ""verse"" is a collection of packages for
    modeling and statistical analysis that share the underlying design
    philosophy, grammar, and data structures of the tidyverse.",2022-03-19,Max Kuhn,"https://tidymodels.tidymodels.org,
https://github.com/tidymodels/tidymodels",TRUE,https://github.com/tidymodels/tidymodels,942190,608,2022-04-28T16:51:32Z,1549.654605263158
TidyMultiqc,"Provides the means to convert 'multiqc_data.json' files,
    produced by the wonderful 'MultiQC' tool, into tidy data frames for downstream
    analysis in R. This analysis might involve cohort analysis, quality control visualisation,
    change-point detection, statistical process control, clustering, or any other
    type of quality analysis.",2022-02-10,Michael Milton,"https://multimeric.github.io/TidyMultiqc/,
https://github.com/multimeric/TidyMultiqc,
https://cran.r-project.org/package=TidyMultiqc",TRUE,https://github.com/multimeric/tidymultiqc,5188,8,2022-02-10T15:50:30Z,648.5
tidymv,"Provides functions for visualising generalised
    additive models and getting predicted values using tidy tools from the 'tidyverse' packages.",2022-04-18,Stefano Coretta,"https://github.com/stefanocoretta/tidymv,
https://stefanocoretta.github.io/tidymv/",TRUE,https://github.com/stefanocoretta/tidymv,29522,33,2022-04-18T20:44:03Z,894.6060606060606
tidync,"Tidy tools for 'NetCDF' data sources. Explore the contents of a 
 'NetCDF' source (file or URL) presented as variables organized by grid with a 
 database-like interface. The hyper_filter() interactive function translates the 
 filter value or index expressions to array-slicing form. No data is read until 
 explicitly requested, as a data frame or list of arrays via hyper_tibble() or 
 hyper_array(). ",2020-05-12,Michael Sumner,https://docs.ropensci.org/tidync/,TRUE,https://github.com/ropensci/tidync,37075,80,2022-04-01T23:42:07Z,463.4375
tidyndr,"The goal is to simplify routine analysis of the Nigeria National  Data Repository (NDR) <https://ndr.phis3project.org.ng> using the PEPFAR Monitoring, Evaluation, and Reporting (MER) indicators (see <https://datim.zendesk.com/hc/en-us/articles/360000084446-MER-Indicator-Reference-Guides>). It is designed to import in to R patient-level line-list downloaded as 'csv' file from the front-end of the NDR.",2022-04-08,Stephen Balogun,https://github.com/stephenbalogun/tidyndr,TRUE,https://github.com/stephenbalogun/tidyndr,5379,5,2022-05-13T11:27:00Z,1075.8
tidypaleo,"Provides a set of functions with a common framework for age-depth model management, 
  stratigraphic visualization, and common statistical transformations. The focus of the
  package is stratigraphic visualization, for which 'ggplot2' components are provided
  to reproduce the scales, geometries, facets, and theme elements commonly used in
  publication-quality stratigraphic diagrams. Helpers are also provided to reproduce
  the exploratory statistical summaries that are frequently included on
  stratigraphic diagrams. See Dunnington et al. (2021) <doi:10.18637/jss.v101.i07>.",2022-02-24,Dewey Dunnington,"https://paleolimbot.github.io/tidypaleo/,
https://github.com/paleolimbot/tidypaleo",TRUE,https://github.com/paleolimbot/tidypaleo,6204,30,2022-02-23T01:32:40Z,206.8
tidyposterior,"Bayesian analysis used here to answer the question: ""when
    looking at resampling results, are the differences between models
    'real'?"" To answer this, a model can be created were the performance
    statistic is the resampling statistics (e.g. accuracy or RMSE). These
    values are explained by the model types. In doing this, we can get
    parameter estimates for each model's affect on performance and make
    statistical (and practical) comparisons between models. The methods
    included here are similar to Benavoli et al (2017)
    <https://jmlr.org/papers/v18/16-305.html>.",2022-06-23,Max Kuhn,"https://tidyposterior.tidymodels.org,
https://github.com/tidymodels/tidyposterior",TRUE,https://github.com/tidymodels/tidyposterior,108519,99,2022-06-29T13:35:35Z,1096.1515151515152
tidypredict,"It parses a fitted 'R' model object, and returns a formula in
    'Tidy Eval' code that calculates the predictions.  It works with
    several databases back-ends because it leverages 'dplyr' and 'dbplyr'
    for the final 'SQL' translation of the algorithm. It currently
    supports lm(), glm(), randomForest(), ranger(), earth(),
    xgb.Booster.complete(), cubist(), and ctree() models.",2022-05-25,Max Kuhn,"https://tidypredict.tidymodels.org,
https://github.com/tidymodels/tidypredict",TRUE,https://github.com/tidymodels/tidypredict,102561,242,2022-05-31T22:15:43Z,423.8057851239669
tidyquant,"Bringing business and financial analysis to the 'tidyverse'. The 'tidyquant' 
    package provides a convenient wrapper to various 'xts', 'zoo', 'quantmod', 'TTR' 
    and 'PerformanceAnalytics' package 
    functions and returns the objects in the tidy 'tibble' format. The main 
    advantage is being able to use quantitative functions with the 'tidyverse'
    functions including 'purrr', 'dplyr', 'tidyr', 'ggplot2', 'lubridate', etc. See 
    the 'tidyquant' website for more information, documentation and examples.",2022-05-20,Matt Dancho,https://github.com/business-science/tidyquant,TRUE,https://github.com/business-science/tidyquant,665534,754,2022-05-20T12:20:44Z,882.6710875331565
tidyquery,"Use 'SQL' 'SELECT' statements to query 'R' data
    frames.",2021-12-02,Ian Cook,https://github.com/ianmcook/tidyquery,TRUE,https://github.com/ianmcook/tidyquery,16659,162,2021-12-02T20:07:00Z,102.83333333333333
tidyr,"Tools to help to create tidy data, where each column is a
    variable, each row is an observation, and each cell contains a single
    value.  'tidyr' contains tools for changing the shape (pivoting) and
    hierarchy (nesting and 'unnesting') of a dataset, turning deeply
    nested lists into rectangular data frames ('rectangling'), and
    extracting values out of string columns. It also includes tools for
    working with missing values (both implicit and explicit).",2022-02-01,Hadley Wickham,"https://tidyr.tidyverse.org, https://github.com/tidyverse/tidyr",TRUE,https://github.com/tidyverse/tidyr,29071232,1163,2022-06-23T21:55:53Z,24996.760103181427
tidyREDCap,"
    Helper functions for processing REDCap data in R. 'REDCap' (Research
    Electronic Data CAPture; <https://projectredcap.org>) is a web-enabled
    application for building and managing surveys and databases developed at
    Vanderbilt University.",2022-01-30,Raymond Balise,https://raymondbalise.github.io/tidyREDCap/index.html,TRUE,https://github.com/raymondbalise/tidyredcap,11677,4,2022-03-25T21:45:32Z,2919.25
tidyRSS,"
    With the objective of including data from RSS feeds into your analysis, 
    'tidyRSS' parses RSS, Atom and JSON feeds and returns a tidy data frame.",2022-05-29,Robert Myles McDonnell,https://github.com/RobertMyles/tidyrss,TRUE,https://github.com/robertmyles/tidyrss,66080,59,2022-05-30T08:34:12Z,1120
tidyselect,"A backend for the selecting functions of the 'tidyverse'.
    It makes it easy to implement select-like functions in your own
    packages in a way that is consistent with other 'tidyverse'
    interfaces for selection.",2022-02-21,Lionel Henry,"https://tidyselect.r-lib.org, https://github.com/r-lib/tidyselect",TRUE,https://github.com/r-lib/tidyselect,29358543,108,2022-07-09T08:15:47Z,271838.3611111111
tidySEM,"A tidy workflow for generating, estimating, reporting,
    and plotting structural equation models using 'lavaan', 'OpenMx', or
    'Mplus'. Throughout this workflow, elements of syntax, results, and graphs
    are represented as 'tidy' data, making them easy to customize.",2022-04-14,Caspar J. van Lissa,https://cjvanlissa.github.io/tidySEM/,TRUE,https://github.com/cjvanlissa/tidysem,24545,36,2022-05-20T06:37:45Z,681.8055555555555
tidyseurat,"It creates an invisible layer that allow to see the 'Seurat' object 
    as tibble and interact seamlessly with the tidyverse.",2022-05-20,Stefano Mangiola,https://github.com/stemangiola/tidyseurat,TRUE,https://github.com/stemangiola/tidyseurat,15113,75,2022-07-01T23:26:25Z,201.50666666666666
tidysmd,"Tidy standardized mean differences ('SMDs'). 'tidysmd' uses
    the 'smd' package to calculate standardized mean differences for
    variables in a data frame, returning the results in a tidy format.",2021-10-25,Malcolm Barrett,"https://github.com/malcolmbarrett/tidysmd,
https://malcolmbarrett.github.io/tidysmd/",TRUE,https://github.com/malcolmbarrett/tidysmd,2613,6,2021-10-25T16:16:03Z,435.5
tidysq,A tidy approach to analysis of biological sequences. All processing and data-storage functions are heavily optimized to allow the fastest and most efficient data storage.,2022-01-31,Dominik Rafacz,https://github.com/BioGenies/tidysq,TRUE,https://github.com/biogenies/tidysq,3994,28,2022-03-19T15:01:16Z,142.64285714285714
tidystats,"Save the output of statistical tests in an organized file that can 
  be shared with others or used to report statistics in scientific papers.",2022-01-04,Willem Sleegers,https://willemsleegers.github.io/tidystats/,TRUE,https://github.com/willemsleegers/tidystats,14950,15,2022-06-04T14:08:22Z,996.6666666666666
tidytable,"A tidy interface to 'data.table' that is 'rlang' compatible,
  giving users the speed of 'data.table' with the clean syntax of the tidyverse.",2022-06-11,Mark Fairbanks,https://github.com/markfairbanks/tidytable,TRUE,https://github.com/markfairbanks/tidytable,63039,323,2022-07-08T13:16:50Z,195.1671826625387
tidyterra,"Extension of the 'tidyverse' for 'SpatRaster' and
    'SpatVector' objects of the 'terra' package. It includes also new
    'geom_' functions that provide a convenient way of visualizing 'terra'
    objects with 'ggplot2'.",2022-06-21,Diego Hernangómez,"https://dieghernan.github.io/tidyterra/,
https://github.com/dieghernan/tidyterra",TRUE,https://github.com/dieghernan/tidyterra,1035,78,2022-07-04T16:04:19Z,13.26923076923077
tidytext,"Using tidy data principles can make many text mining tasks
    easier, more effective, and consistent with tools already in wide use.
    Much of the infrastructure needed for text mining with tidy data
    frames already exists in packages like 'dplyr', 'broom', 'tidyr', and
    'ggplot2'. In this package, we provide functions and supporting data
    sets to allow conversion of text to and from tidy formats, and to
    switch seamlessly between tidy tools and existing text mining
    packages.",2022-05-09,Julia Silge,https://github.com/juliasilge/tidytext,TRUE,https://github.com/juliasilge/tidytext,1590523,1054,2022-05-09T17:33:32Z,1509.0351043643263
tidytransit,Read General Transit Feed Specification (GTFS) zipfiles into a list of R dataframes. Perform validation of the data structure against the specification. Analyze the headways and frequencies at routes and stops. Create maps and perform spatial analysis on the routes and stops. Please see the GTFS documentation here for more detail: <https://gtfs.org/>.,2022-05-20,Flavio Poletti,https://github.com/r-transit/tidytransit,TRUE,https://github.com/r-transit/tidytransit,23184,102,2022-05-20T11:18:16Z,227.2941176470588
tidytreatment,"Functions for extracting tidy data from Bayesian treatment effect models, in particular BART, but extensions are possible. Functionality includes extracting tidy posterior summaries as in 'tidybayes' <https://github.com/mjskay/tidybayes>, estimating (average) treatment effects, common support calculations, and plotting useful summaries of these.",2022-02-21,Joshua J Bon,https://github.com/bonStats/tidytreatment,TRUE,https://github.com/bonstats/tidytreatment,4452,14,2022-02-19T09:56:48Z,318
tidytree,"Phylogenetic tree generally contains multiple components including node, edge, branch and associated data. 'tidytree' provides an approach to convert tree object to tidy data frame as well as provides tidy interfaces to manipulate tree data.",2022-03-04,Guangchuang Yu,https://yulab-smu.top/treedata-book/,TRUE,https://github.com/yulab-smu/tidytree,291219,34,2022-03-04T08:46:11Z,8565.264705882353
tidyUSDA,"Provides a consistent API to pull United States Department of
    Agriculture census and survey data from the National Agricultural
    Statistics Service (NASS) QuickStats service.",2022-05-01,Brad Lindblad,"https://bradlindblad.github.io/tidyUSDA/,
https://github.com/bradlindblad/tidyUSDA/",TRUE,https://github.com/bradlindblad/tidyusda,17767,36,2022-05-04T02:42:19Z,493.52777777777777
tidyverse,"The 'tidyverse' is a set of packages that work in harmony
    because they share common data representations and 'API' design. This
    package is designed to make it easy to install and load multiple
    'tidyverse' packages in a single step. Learn more about the
    'tidyverse' at <https://www.tidyverse.org>.",2021-04-15,Hadley Wickham,"https://tidyverse.tidyverse.org,
https://github.com/tidyverse/tidyverse",TRUE,https://github.com/tidyverse/tidyverse,23190015,1249,2022-07-02T01:32:42Z,18566.865492393914
tidyvpc,"Perform a Visual Predictive Check (VPC), while accounting for 
    stratification, censoring, and prediction correction. Using piping from 
    'magrittr', the intuitive syntax gives users a flexible and powerful method 
    to generate VPCs using both traditional binning and a new binless approach 
    Jamsen et al. (2018) <doi:10.1002/psp4.12319> with Additive Quantile 
    Regression (AQR) and Locally Estimated Scatterplot Smoothing (LOESS) 
    prediction correction. ",2022-03-10,James Craig,https://github.com/certara/tidyvpc,TRUE,https://github.com/certara/tidyvpc,11493,5,2022-03-10T15:19:21Z,2298.6
tidyxl,"Imports non-tabular from Excel files into R.  Exposes cell content,
    position and formatting in a tidy structure for further manipulation.
    Tokenizes Excel formulas.  Supports '.xlsx' and '.xlsm' via the embedded
    'RapidXML' C++ library <http://rapidxml.sourceforge.net>.  Does not support
    '.xlsb' or '.xls'.",2020-11-16,Duncan Garmonsway,https://github.com/nacnudus/tidyxl,TRUE,https://github.com/nacnudus/tidyxl,85695,201,2022-04-08T20:45:52Z,426.34328358208955
TIGERr,"
    The R implementation of TIGER. 
    TIGER integrates random forest algorithm into an innovative ensemble learning architecture. Benefiting from this advanced architecture, TIGER is resilient to outliers, free from model tuning and less likely to be affected by specific hyperparameters.
    TIGER supports targeted and untargeted metabolomics data and is competent to perform both intra- and inter-batch technical variation removal. TIGER can also be used for cross-kit adjustment to ensure data obtained from different analytical assays can be effectively combined and compared.
    Reference: Han S. et al. (2022) <doi:10.1093/bib/bbab535>.",2022-01-06,Siyu Han,NA,TRUE,https://github.com/han-siyu/tiger,2800,0,2022-01-06T13:36:23Z,NA
tigris,"Download TIGER/Line shapefiles from the United States Census Bureau 
    (<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html>) 
    and load into R as 'sf' objects.",2022-06-03,Kyle Walker,https://github.com/walkerke/tigris,TRUE,https://github.com/walkerke/tigris,312223,267,2022-06-03T16:16:30Z,1169.374531835206
tiledb,"The universal storage engine 'TileDB' introduces a
 powerful on-disk format for multi-dimensional arrays. It supports
 dense and sparse arrays, dataframes and key-values stores, cloud
 storage ('S3', 'GCS', 'Azure'), chunked arrays, multiple compression,
 encryption and checksum filters, uses a fully multi-threaded
 implementation, supports parallel I/O, data versioning ('time
 travel'), metadata and groups. It is implemented as an embeddable
 cross-platform C++ library with APIs from several languages, and
 integrations.",2022-06-23,Dirk Eddelbuettel,https://github.com/TileDB-Inc/TileDB-R,TRUE,https://github.com/tiledb-inc/tiledb-r,13648,78,2022-07-08T19:37:09Z,174.97435897435898
tilegramsR,"R spatial objects for Tilegrams.
  Tilegrams are tiled maps where the region size is proportional to
  the certain characteristics of the dataset.",2017-03-29,Bhaskar Karambelkar,https://github.com/bhaskarvk/tilegramsR,TRUE,https://github.com/bhaskarvk/tilegramsr,15906,49,2021-09-30T14:42:12Z,324.61224489795916
timbr,"Provides data frames for forest (or tree) data structures. You can 
    create forest data structures from data frames and process them based on 
    their hierarchies.",2022-03-29,Mizuki Uchida,https://github.com/UchidaMizuki/timbr,TRUE,https://github.com/uchidamizuki/timbr,829,3,2022-05-02T08:13:21Z,276.3333333333333
timereg,"Programs for Martinussen and Scheike (2006), `Dynamic Regression
    Models for Survival Data', Springer Verlag.  Plus more recent developments.
    Additive survival model, semiparametric proportional odds model, fast
    cumulative residuals, excess risk models and more. Flexible competing risks
    regression including GOF-tests. Two-stage frailty modelling. PLS for the
    additive risk model. Lasso in the 'ahaz' package.",2022-04-11,Thomas Scheike with contributions from Torben Martinussen,https://github.com/scheike/timereg,TRUE,https://github.com/scheike/timereg,282566,22,2022-07-06T06:47:55Z,12843.90909090909
TimeSeries.OBeu,"Estimate and return the needed parameters for visualizations designed for 'OpenBudgets.eu' <http://openbudgets.eu/> time series data. Calculate time series model and forecast parameters in budget time series data of municipalities across Europe, according to the 'OpenBudgets.eu' data model. There are functions for measuring deterministic and stochastic trend of the input time series data with 'ACF', 'PACF', 'Phillips Perron' test, 'Augmented Dickey Fuller (ADF)' test, 'Kwiatkowski-Phillips-Schmidt-Shin (KPSS)' test, 'Mann Kendall' test for monotonic trend and 'Cox and Stuart' trend test, decomposing with local regression models or 'stl' decomposition, fitting the appropriate 'arima' model and provide forecasts for the input 'OpenBudgets.eu' time series fiscal data. Also, can be used generally to extract visualization parameters convert them to 'JSON' format and use them as input in a different graphical interface.",2019-12-17,Kleanthis Koupidis,https://github.com/okgreece/TimeSeries.OBeu,TRUE,https://github.com/okgreece/timeseries.obeu,12303,1,2021-09-02T13:44:30Z,12303
timeseriesdb,"Archive and manage times series data from official statistics. The 'timeseriesdb' package was designed to manage a large catalog of time series from official statistics which are typically published on a monthly, quarterly or yearly basis. Thus timeseriesdb is optimized to handle updates caused by data revision as well as elaborate, multi-lingual meta information. ",2022-03-23,Matthias Bannert,https://github.com/mbannert/timeseriesdb,TRUE,https://github.com/mbannert/timeseriesdb,17814,20,2022-05-24T13:28:09Z,890.7
timetk,"
    Easy visualization, wrangling, and feature engineering of time series data for 
    forecasting and machine learning prediction. Consolidates and extends time series functionality 
    from packages including 'dplyr', 'stats', 'xts', 'forecast', 'slider', 'padr', 'recipes', and 'rsample'.",2022-05-31,Matt Dancho,"https://github.com/business-science/timetk,
https://business-science.github.io/timetk/",TRUE,https://github.com/business-science/timetk,1164295,502,2022-06-26T14:17:09Z,2319.312749003984
timevis,"Create rich and fully interactive timeline visualizations.
    Timelines can be included in Shiny apps and R markdown documents, or viewed
    from the R console and 'RStudio' Viewer. 'timevis' includes an extensive API
    to manipulate a timeline after creation, and supports getting data out of
    the visualization into R. Based on the 'vis.js' Timeline module and the
    'htmlwidgets' R package.",2021-12-20,Dean Attali  (R interface,"https://github.com/daattali/timevis,
https://daattali.com/shiny/timevis-demo/",TRUE,https://github.com/daattali/timevis,65896,538,2022-04-19T04:43:36Z,122.48327137546468
tint,"A 'tufte'-alike style for 'rmarkdown'.
 A modern take on the 'Tufte' design for pdf and html vignettes,
 building on the 'tufte' package with additional contributions
 from the 'knitr' and 'ggtufte' package, and also acknowledging
 the key influence of 'envisioned css'.",2020-07-18,Dirk Eddelbuettel and Jonathan Gilligan,http://dirk.eddelbuettel.com/code/tint.html,TRUE,https://github.com/eddelbuettel/tint,22217,254,2022-01-10T04:08:37Z,87.46850393700787
tinyarray,"Gene Expression Omnibus(GEO) and The Cancer Genome Atlas(TCGA) are common bioinformatics public databases. We integrate the regular analysis and charts for expression data, to analyze and display the data concisely and intuitively.",2021-11-08,Xiaojie Sun,https://github.com/xjsun1221/tinyarray,TRUE,https://github.com/xjsun1221/tinyarray,5359,39,2022-05-13T08:02:10Z,137.4102564102564
tinylabels,"Assign, extract, or remove variable labels from R vectors.
  Lightweight and dependency-free.",2022-02-06,Marius Barth,https://github.com/mariusbarth/tinylabels,TRUE,https://github.com/mariusbarth/tinylabels,13982,0,2022-02-06T12:41:56Z,NA
tinyscholar,"Provides functions to get personal 'Google Scholar'
    profile data from web API and show it in table or figure format.",2022-07-04,Shixiang Wang,https://github.com/ShixiangWang/tinyscholar,TRUE,https://github.com/shixiangwang/tinyscholar,8723,7,2022-07-03T16:02:23Z,1246.142857142857
tinytest,"Provides a lightweight (zero-dependency) and easy to use 
    unit testing framework. Main features: install tests with 
    the package. Test results are treated as data that can be stored and 
    manipulated. Test files are R scripts interspersed with test commands, that
    can be programmed over. Fully automated build-install-test sequence for 
    packages. Skip tests when not run locally (e.g. on CRAN). Flexible and 
    configurable output printing. Compare computed output with output stored 
    with the package. Run tests in parallel. Extensible by other packages.
    Report side effects.",2021-07-06,Mark van der Loo,https://github.com/markvanderloo/tinytest,TRUE,https://github.com/markvanderloo/tinytest,432595,189,2022-05-16T13:38:45Z,2288.862433862434
tinytex,"Helper functions to install and maintain the 'LaTeX' distribution
  named 'TinyTeX' (<https://yihui.org/tinytex/>), a lightweight, cross-platform,
  portable, and easy-to-maintain version of 'TeX Live'. This package also
  contains helper functions to compile 'LaTeX' documents, and install missing
  'LaTeX' packages automatically.",2022-06-15,Yihui Xie,https://github.com/rstudio/tinytex,TRUE,https://github.com/rstudio/tinytex,22094935,773,2022-07-06T13:56:03Z,28583.35705045278
tipa,"Accurately estimates phase shifts by accounting for period
  changes and for the point in the circadian cycle at which the stimulus occurs.",2022-02-02,Jake Hughey,"https://tipa.hugheylab.org, https://github.com/hugheylab/tipa",TRUE,https://github.com/hugheylab/tipa,1356,0,2022-05-18T16:35:08Z,NA
TippingPoint,"Using the idea of ""tipping point"" (proposed in
   Gregory Campbell, Gene Pennello and Lilly Yue(2011)
   <DOI:10.1080/10543406.2011.550094>) to visualize  the results
   of sensitivity analysis for missing data, the package provides
   a set of functions to list out all the possible combinations
   of missing values in two treatment arms, calculate
   corresponding estimated treatment effects and p values, and draw
   a colored heat-map. It could deal with randomized
   experiments with a binary outcome or a continuous outcome. In addition,
   the package provides a visualized method to compare various imputation
   methods by adding the rectangles or convex hulls on the basic plot.",2022-04-08,Shengjie Zhang,https://github.com/XikunHan/TippingPoint,TRUE,https://github.com/xikunhan/tippingpoint,3988,1,2022-02-28T01:02:17Z,3988
tippy,'Htmlwidget' of 'Tippyjs' to add tooltips to 'Shiny' apps and 'R markdown' documents.,2021-01-11,John Coene,https://tippy.john-coene.com/,TRUE,https://github.com/johncoene/tippy,29307,64,2022-03-26T10:54:29Z,457.921875
TKCat,"Facilitate the management of data from knowledge
   resources that are frequently used alone or together
   in research environments.
   In 'TKCat', knowledge resources are manipulated as modeled database (MDB)
   objects. These objects provide access to the data tables along with a general
   description of the resource and a detail data model documenting the
   tables, their fields and their relationships.
   These MDBs are then gathered in catalogs that can be easily
   explored an shared.
   Finally, 'TKCat' provides tools to easily subset, filter and combine MDBs and
   create new catalogs suited for specific needs.",2022-06-07,Patrice Godard,https://github.com/patzaw/TKCat,TRUE,https://github.com/patzaw/tkcat,4223,3,2022-06-27T15:28:48Z,1407.6666666666667
tmap,"Thematic maps are geographical maps in which spatial data distributions are visualized. This package offers a flexible, layer-based, and easy to use approach to create thematic maps, such as choropleths and bubble maps.",2022-03-02,Martijn Tennekes,https://github.com/r-tmap/tmap,TRUE,https://github.com/r-tmap/tmap,740262,670,2022-04-25T15:15:00Z,1104.868656716418
tmbstan,"Enables all 'rstan' functionality for a 'TMB' model object, in particular MCMC sampling and chain visualization. Sampling can be performed with or without Laplace approximation for the random effects. This is demonstrated in Monnahan & Kristensen (2018) <DOI:10.1371/journal.pone.0197954>.",2022-03-21,Kasper Kristensen,NA,TRUE,https://github.com/kaskr/tmbstan,17002,27,2022-03-18T16:32:44Z,629.7037037037037
TmCalculator,"This tool is extended from methods in Bio.SeqUtils.MeltingTemp of python. The melting temperature of nucleic acid sequences can be calculated in three method, the Wallace rule (Thein & Wallace (1986) <doi:10.1016/S0140-6736(86)90739-7>), empirical formulas based on G and C content (Marmur J. (1962) <doi:10.1016/S0022-2836(62)80066-7>, Schildkraut C. (2010) <doi:10.1002/bip.360030207>, Wetmur J G (1991) <doi:10.3109/10409239109114069>, Untergasser,A. (2012) <doi:10.1093/nar/gks596>, von Ahsen N (2001) <doi:10.1093/clinchem/47.11.1956>) and nearest neighbor thermodynamics (Breslauer K J (1986) <doi:10.1073/pnas.83.11.3746>, Sugimoto N (1996) <doi:10.1093/nar/24.22.4501>, Allawi H (1998) <doi:10.1093/nar/26.11.2694>, SantaLucia J (2004) <doi:10.1146/annurev.biophys.32.110601.141800>, Freier S (1986) <doi:10.1073/pnas.83.24.9373>, Xia T (1998) <doi:10.1021/bi9809425>, Chen JL (2012) <doi:10.1021/bi3002709>, Bommarito S (2000) <doi:10.1093/nar/28.9.1929>, Turner D H (2010) <doi:10.1093/nar/gkp892>, Sugimoto N (1995) <doi:10.1016/S0048-9697(98)00088-6>, Allawi H T (1997) <doi:10.1021/bi962590c>, Santalucia N (2005) <doi:10.1093/nar/gki918>), and it can also be corrected with salt ions and chemical compound (SantaLucia J (1996) <doi:10.1021/bi951907q>, SantaLucia J(1998) <doi:10.1073/pnas.95.4.1460>, Owczarzy R (2004) <doi:10.1021/bi034621r>, Owczarzy R (2008) <doi:10.1021/bi702363u>).",2022-02-21,Junhui Li,NA,TRUE,https://github.com/junhuili1017/tmcalculator,17688,3,2022-01-18T06:26:27Z,5896
tmsens,Sensitivity analysis using the trimmed means estimator.,2022-02-03,Audinga-Dea Hazewinkel,https://github.com/dea-hazewinkel/tmsens,TRUE,https://github.com/dea-hazewinkel/tmsens,1322,0,2022-02-04T11:12:24Z,NA
tmt,"Provides conditional maximum likelihood (CML) item parameter estimation of sequential as well as cumulative deterministic multistage designs (Zwitser & Maris, 2015, <doi:10.1007/s11336-013-9369-6>) as well as probabilistic sequential and cumulative multistage designs (Steinfeld & Robitzsch, 2021, <doi:10.31234/osf.io/ew27f>). Supports CML item parameter estimation of conventional linear designs and additional functions for the likelihood ratio test (Andersen, 1973, <doi:10.1007/BF02291180>) as well as functions for the simulation of several kinds of multistage designs. ",2022-05-17,Jan Steinfeld,"https://jansteinfeld.github.io/tmt/,
https://github.com/jansteinfeld/tmt",TRUE,https://github.com/jansteinfeld/tmt,11288,2,2022-05-16T20:17:01Z,5644
toastui,"Create interactive tables, calendars and charts with 'TOAST UI' <https://ui.toast.com/> libraries to
  integrate in 'shiny' applications or 'rmarkdown' 'HTML' documents.",2022-01-11,Victor Perrier,https://dreamrs.github.io/toastui/,TRUE,https://github.com/dreamrs/toastui,2501,51,2022-04-04T06:52:00Z,49.03921568627451
togglr,Use the <http://toggl.com> time tracker api through R.,2018-08-13,Vincent Guyader,https://github.com/ThinkR-open/togglr,TRUE,https://github.com/thinkr-open/togglr,14425,45,2022-03-31T22:13:04Z,320.55555555555554
tokenizers,"Convert natural language text into tokens. Includes tokenizers for
    shingled n-grams, skip n-grams, words, word stems, sentences, paragraphs,
    characters, shingled characters, lines, tweets, Penn Treebank, regular
    expressions, as well as functions for counting characters, words, and sentences,
    and a function for splitting longer texts into separate documents, each with
    the same number of words.  The tokenizers have a consistent interface, and
    the package is built on the 'stringi' and 'Rcpp' packages for  fast
    yet correct tokenization in 'UTF-8'. ",2018-03-29,Lincoln Mullen,https://lincolnmullen.com/software/tokenizers/,TRUE,https://github.com/ropensci/tokenizers,1199369,169,2021-07-14T20:54:14Z,7096.857988165681
tomba,"Email Finder R Client Library.
        Search emails are based on the website You give one domain name and it returns all the email addresses found on the internet.
        Email Finder generates or retrieves the most likely email address from a domain name, a first name and a last name.
        Email verify checks the deliverability of a given email address, verifies if it has been found in our database, and returns their sources.",2021-11-02,Abedrahim Ben rebia,"https://tomba.io/,https://github.com/tomba-io/r",TRUE,https://github.com/tomba-io/r,2266,0,2021-10-29T15:12:14Z,NA
tongfen,"Several functions to allow comparisons of data across different geographies, in particular for Canadian census data from different censuses.",2022-04-28,Jens von Bergmann,"https://github.com/mountainMath/tongfen,
https://mountainmath.github.io/tongfen/",TRUE,https://github.com/mountainmath/tongfen,7042,26,2022-05-12T20:36:56Z,270.84615384615387
toolStability,"Tools to calculate stability indices with parametric,
 non-parametric and probabilistic approaches. The basic data format requirement for 'toolStability' is a data frame with 3 columns including numeric trait values,
 genotype,and environmental labels. Output format of each function is the dataframe with chosen stability index for each genotype. 
 Function ""table_stability"" offers the summary table of all stability indices in this package. 
 Sample dataset in this package is from: 
 Casadebaig P, Zheng B, Chapman S et al. (2016) <doi: 10.1371/journal.pone.0146385>. 
 Indices used in this package are from:
 Döring TF, Reckling M (2018) <doi: 10.1016/j.eja.2018.06.007>.
 Eberhart SA, Russell WA (1966) <doi: 10.2135/cropsci1966.0011183X000600010011x>.
 Eskridge KM (1990) <doi: 10.2135/cropsci1990.0011183X003000020025x>.
 Finlay KW, Wilkinson GN (1963) <doi: 10.1071/AR9630742>.
 Hanson WD (1970) Genotypic stability. <doi: 10.1007/BF00285245>.
 Lin CS, Binns MR (1988) <https://cdnsciencepub.com/doi/abs/10.4141/cjps88-018>.
 Nassar R, Hühn M (1987).
 Pinthus MJ (1973) <doi: 10.1007/BF00021563>.
 Römer T (1917).
 Shukla GK (1972). 
 Wricke G (1962).",2022-01-12,Tien-Cheng Wang,"https://github.com/Illustratien/toolStability,
https://illustratien.github.io/toolStability/,
https://CRAN.R-project.org/package=toolStability,
https://doi.org/10.5281/zenodo.5804213",TRUE,https://github.com/illustratien/toolstability,2065,1,2022-06-17T12:47:46Z,2065
toOrdinal,Language specific cardinal to ordinal number conversion.,2022-02-24,Damian W. Betebenner,"https://centerforassessment.github.io/toOrdinal/,
https://github.com/centerforassessment/toOrdinal/,
https://cran.r-project.org/package=toOrdinal",TRUE,https://github.com/centerforassessment/toordinal,61696,6,2022-05-25T16:53:51Z,10282.666666666666
TopDom,"The 'TopDom' method identifies topological domains in genomes from Hi-C sequence data (Shin et al., 2016 <doi:10.1093/nar/gkv1505>).  The authors published an implementation of their method as an R script (two different versions; also available in this package).  This package originates from those original 'TopDom' R scripts and provides help pages adopted from the original 'TopDom' PDF documentation.  It also provides a small number of bug fixes to the original code.",2021-05-06,Henrik Bengtsson,https://github.com/HenrikBengtsson/TopDom,TRUE,https://github.com/henrikbengtsson/topdom,4584,10,2021-11-11T21:54:59Z,458.4
topmodel,"Set of hydrological functions including an R
        implementation of the hydrological model TOPMODEL, which is
        based on the 1995 FORTRAN version by Keith Beven. From version
        0.7.0, the package is put into maintenance mode.",2022-05-05,Wouter Buytaert,https://github.com/ICHydro/topmodel,TRUE,https://github.com/ichydro/topmodel,30601,9,2022-05-06T19:58:17Z,3400.1111111111113
topr,"A collection of functions for visualizing, exploring and annotating genetic association results. Association results from multiple traits can be viewed simultaneously along with gene annotation, over the entire genome (Manhattan plot) or in the more detailed regional view.",2022-01-12,Thorhildur Juliusdottir,https://github.com/GenuityScience/topr,TRUE,https://github.com/genuityscience/topr,1516,1,2021-12-17T14:51:14Z,1516
tor,"The goal of tor (to-R) is to help you to import
    multiple files from a single directory at once, and to do so as
    quickly, flexibly, and simply as possible.",2020-03-07,Mauro Lepore,https://github.com/maurolepore/tor,TRUE,https://github.com/maurolepore/tor,11202,19,2021-10-30T01:06:30Z,589.578947368421
torch,"Provides functionality to define and train neural networks similar to
    'PyTorch' by Paszke et al (2019) <arXiv:1912.01703> but written entirely in R
    using the 'libtorch' library. Also supports low-level tensor operations and
    'GPU' acceleration.",2022-06-09,Daniel Falbel,"https://torch.mlverse.org/docs, https://github.com/mlverse/torch",TRUE,https://github.com/mlverse/torch,65500,353,2022-06-14T18:11:16Z,185.55240793201133
torchdatasets,"Provides datasets in a format that can be easily consumed by torch 'dataloaders'.
  Handles data downloading from multiple sources, caching and pre-processing so
  users can focus only on their model implementations.",2021-10-07,Daniel Falbel,"https://mlverse.github.io/torchdatasets/,
https://github.com/mlverse/torchdatasets",TRUE,https://github.com/mlverse/torchdatasets,7390,7,2021-10-07T16:22:55Z,1055.7142857142858
torchopt,"Optimizers for 'torch' deep learning library. These
    functions include recent results published in the literature and are
    not part of the optimizers offered in 'torch'. Prospective users
    should test these optimizers with their data, since performance
    depends on the specific problem being solved.  The packages includes
    the following optimizers: (a) 'adabelief' by Zhuang et al (2020),
    <arXiv:2010.07468>; (b) 'adabound' by Luo et al.(2019),
    <arXiv:1902.09843>; (c) 'adahessian' by Yao et al.(2021)
    <arXiv:2006.00719>; (d) 'adamw' by Loshchilov & Hutter (2019),
    <arXiv:1711.05101>; (e) 'madgrad' by Defazio and Jelassi (2021),
    <arXiv:2101.11075>; (f) 'nadam' by Dozat (2019),
    <https://openreview.net/pdf/OM0jvwB8jIp57ZJjtNEZ.pdf>; (g) 'qhadam' by
    Ma and Yarats(2019), <arXiv:1810.06801>; (h) 'radam' by Liu et al.
    (2019), <arXiv:1908.03265>; (i) 'swats' by Shekar and Sochee (2018),
    <arXiv:1712.07628>; (j) 'yogi' by Zaheer et al.(2019),
    <https:://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization>. ",2022-06-30,Gilberto Camara,https://github.com/e-sensing/torchopt/,TRUE,https://github.com/e-sensing/torchopt,1008,22,2022-06-30T15:19:05Z,45.81818181818182
torchvision,"Provides access to datasets, models and preprocessing
    facilities for deep learning with images. Integrates seamlessly
    with the 'torch' package and it's 'API' borrows heavily from 
    'PyTorch' vision package.",2022-01-28,Daniel Falbel,"https://torchvision.mlverse.org,
https://github.com/mlverse/torchvision",TRUE,https://github.com/mlverse/torchvision,14981,54,2022-05-31T17:09:40Z,277.4259259259259
tornado,"Draws tornado plots for model sensitivity to univariate changes.  Implements methods for many modeling methods including linear models, generalized linear models, survival regression models, and arbitrary machine learning models in the caret package.  Also draws variable importance plots.  ",2022-01-10,Rob Carnell,https://github.com/bertcarnell/tornado,TRUE,https://github.com/bertcarnell/tornado,1642,0,2022-03-30T00:51:31Z,NA
toRvik,"A suite of functions to quickly scrape and tidy advanced metrics,
    detailed player and game statistics, team and coach histories, and more from
    Barttorvik<https://barttorvik.com/>.",2022-04-22,Andrew Weatherman,"https://www.torvik.dev/, https://github.com/andreweatherman/toRvik",TRUE,https://github.com/andreweatherman/torvik,596,3,2022-06-13T17:27:27Z,198.66666666666666
tosca,"A framework for statistical analysis in content analysis. In addition to a pipeline for preprocessing text corpora and linking to the latent Dirichlet allocation from the 'lda' package, plots are offered for the descriptive analysis of text corpora and topic models. In addition, an implementation of Chang's intruder words and intruder topics is provided. Sample data for the vignette is included in the toscaData package, which is available on gitHub: <https://github.com/Docma-TU/toscaData>.",2021-10-28,Lars Koppers,"https://github.com/Docma-TU/tosca,
https://doi.org/10.5281/zenodo.3591068",TRUE,https://github.com/docma-tu/tosca,14292,16,2021-10-27T13:29:15Z,893.25
tosr,"The goal of 'tosr' is to create the Tree of Science from 
             Web of Science (WoS) and Scopus data. It can read files 
             from both sources at the same time. More information 
             can be found in Valencia-Hernández (2020) 
             <https://revistas.unal.edu.co/index.php/ingeinv/article/view/77718>.",2022-01-15,Sebastian Robledo,"https://github.com/coreofscience/tosr,
https://coreofscience.github.io/tosr/",TRUE,https://github.com/coreofscience/tosr,4017,3,2022-01-17T14:25:48Z,1339
totalcensus,"Download summary files from Census Bureau <https://www2.census.gov/> 
    and extract data, in particular high resolution data at 
    block, block group, and tract level, from decennial census and 
    American Community Survey 1-year and 5-year estimates.",2021-06-14,Guanglai Li,https://github.com/GL-Li/totalcensus,TRUE,https://github.com/gl-li/totalcensus,37189,43,2022-03-19T18:40:08Z,864.8604651162791
touch,"R implementation of the software tools developed in the H-CUP
    (Healthcare Cost and Utilization Project) <https://www.hcup-us.ahrq.gov>
    and AHRQ (Agency for Healthcare Research and Quality)
    <https://www.ahrq.gov>.  It currently contains functions for mapping ICD-9
    codes to the AHRQ comorbidity measures and translating ICD-9
    (resp. ICD-10) codes to ICD-10 (resp. ICD-9) codes based on GEM (General
    Equivalence Mappings) from CMS (Centers for Medicare and Medicaid
    Services).",2022-07-08,Wenjie Wang,https://github.com/wenjie2wang/touch,TRUE,https://github.com/wenjie2wang/touch,13415,8,2022-07-08T13:59:10Z,1676.875
tourr,"Implements geodesic interpolation and basis
    generation functions that allow you to create new tour
    methods from R.",2020-12-11,Hadley Wickham,https://github.com/ggobi/tourr,TRUE,https://github.com/ggobi/tourr,53289,58,2022-07-06T09:21:27Z,918.7758620689655
toxEval,"Data analysis package for estimating potential biological effects from chemical concentrations in environmental samples. Included are a set of functions to analyze, visualize, and organize measured concentration data as it relates to user-selected chemical-biological interaction benchmark data such as water quality criteria. The intent of these analyses is to develop a better understanding of the potential biological relevance of environmental chemistry data. Results can be used to prioritize which chemicals at which sites may be of greatest concern. These methods are meant to be used as a screening technique to predict potential for biological influence from chemicals that ultimately need to be validated with direct biological assays. A description of the analysis can be found in Blackwell et al. (2017) <doi:10.1021/acs.est.7b01613>.",2020-10-09,Laura DeCicco,NA,TRUE,https://github.com/usgs-r/toxeval,13033,11,2022-06-08T12:15:08Z,1184.8181818181818
ToxicR,"Toxicology routines for analyzing dose-response data include dose-response analysis 
    and trend tests. Dose-Response methods are based upon the US EPA's benchmark dose software 3.  Methods have
    been extended to include additional functionality based on World Health Organization 
    guidelines.  It further supports the European Food Safety Authority's 
    draft guidance on model averaging. The dose-response methods and datasets used in this package are 
    described in Wheeler et al. (2019) <doi:10.1111/risa.13218>, Wheeler et al. (2020) <doi:10.1111/risa.13537>,
    and Wheeler et al. (2022) <doi:10.1002/env.2728>.  NTP routines are described in 
    Bailer and Portier (1988) <doi:10.2307/2531856>, Bieler and Williams (1993) <doi:10.2307/2532200>, 
    Williams (1971) <doi:10.2307/2528930>, and Shirley (1977) <doi:10.2307/2529789>.",2022-06-09,Matt Wheeler,https://github.com/NIEHS/ToxicR,TRUE,https://github.com/niehs/toxicr,418,2,2022-06-27T19:53:51Z,209
toxpiR,"
  Enables users to build 'ToxPi' prioritization models and provides 
  functionality within the grid framework for plotting ToxPi graphs.
  'toxpiR' allows for more customization than the 'ToxPi GUI' 
  (<https://toxpi.org>) and integration into existing workflows for greater 
  ease-of-use, reproducibility, and transparency.
  toxpiR package behaves nearly identically to the GUI; the package 
  documentation includes notes about all differences.
  The vignettes download example files from 
  <https://github.com/ToxPi/ToxPi-example-files>.",2022-02-18,Dayne L Filer,"https://github.com/ToxPi/toxpiR, https://toxpi.github.io/toxpiR/",TRUE,https://github.com/toxpi/toxpir,1392,1,2022-02-18T21:25:23Z,1392
Tplyr,A tool created to simplify the data manipulation necessary to create clinical reports.,2022-01-27,Eli Miller,https://github.com/atorus-research/Tplyr,TRUE,https://github.com/atorus-research/tplyr,14039,61,2022-01-27T15:03:18Z,230.14754098360655
TPmsm,"Estimation of transition probabilities for the
	illness-death model and or the three-state progressive model.",2021-10-15,Artur Araujo,https://github.com/arturstat/TPmsm,TRUE,https://github.com/arturstat/tpmsm,17491,0,2022-04-15T19:51:28Z,NA
TR8,"Plant ecologists often need to collect ""traits"" data
    about plant species which are often scattered among various
    databases: TR8 contains a set of tools which take care of
    automatically retrieving some of those functional traits data
    for plant species from publicly available databases (Biolflor,
    The Ecological Flora of the British Isles, LEDA traitbase, Ellenberg
    values for Italian Flora, Mycorrhizal intensity databases, Catminat, BROT,
    PLANTS, Jepson Flora Project).
    The TR8 name, inspired by ""car plates"" jokes, was chosen since
    it both reminds of the main object of the package and is
    extremely short to type.",2020-12-01,Gionata Bocci,https://github.com/GioBo/TR8,TRUE,https://github.com/giobo/tr8,16940,18,2022-06-09T21:37:17Z,941.1111111111111
track2KBA,"Functions for preparing and analyzing animal tracking data, 
    with the intention of identifying areas which are potentially important at 
    the population level and therefore of conservation interest. Areas identified 
    using this package may be checked against global or regionally-defined criteria,
    such as those set by the Key Biodiversity Area program. The method
    published herein is described in full in Beal et al. 2021 <doi:10.1111/2041-210X.13713>.",2022-04-26,Martin Beal,https://github.com/BirdLifeInternational/track2kba,TRUE,https://github.com/birdlifeinternational/track2kba,3742,7,2022-04-26T10:18:05Z,534.5714285714286
trackdem,"Obtain population density and body size structure, using video material or image sequences as input. Functions assist in the creation of image sequences from videos, background detection and subtraction, particle identification and tracking. An artificial neural network can be trained for noise filtering. The goal is to supply accurate estimates of population size, structure and/or individual behavior, for use in  evolutionary and ecological studies.",2021-09-24,Marjolein Bruijning,https://github.com/marjoleinbruijning/trackdem,TRUE,https://github.com/marjoleinbruijning/trackdem,18181,6,2021-09-24T19:29:03Z,3030.1666666666665
trackdown,"Collaborative writing and editing of R Markdown (or Sweave) documents. The local .Rmd (or .Rnw) is uploaded as a plain-text file to Google Drive. By taking advantage of the easily readable Markdown (or LaTeX) syntax and the well-known online interface offered by Google Docs, collaborators can easily contribute to the writing and editing process. After integrating all authors’ contributions, the final document can be downloaded and rendered locally.",2021-12-19,Emily Kothe,"https://github.com/claudiozandonella/trackdown/,
https://claudiozandonella.github.io/trackdown/",TRUE,https://github.com/claudiozandonella/trackdown,4746,150,2022-04-04T18:25:26Z,31.64
trackeRapp,"Provides an integrated user interface and workflow for
             the analysis of running, cycling and swimming data from GPS-enabled
             tracking devices through the 'trackeR' <https://CRAN.R-project.org/package=trackeR> R package.",2022-02-15,Ioannis Kosmidis,https://github.com/trackerproject/trackeRapp,TRUE,https://github.com/trackerproject/trackerapp,11708,27,2022-02-15T12:00:24Z,433.6296296296296
tradepolicy,"Datasets from An Advanced Guide to Trade Policy Analysis
    (Year: 2016, ISBN: 978-92-870-4367-2) by Yotov, et al. and functions to 
    report regression summaries with clustered robust standard errors.",2022-04-07,Mauricio Vargas,https://r.tiid.org/R_structural_gravity/,TRUE,https://github.com/pachadotdev/tradepolicy,3757,2,2022-05-10T20:03:07Z,1878.5
tradestatistics,Access 'Open Trade Statistics' API from R to download international trade data.,2022-03-01,Mauricio Vargas,https://docs.ropensci.org/tradestatistics/,TRUE,https://github.com/ropensci/tradestatistics,11762,61,2022-05-13T18:53:31Z,192.81967213114754
trainR,"The goal of 'trainR' is to provide a simple interface to the 
    National Rail Enquiries (NRE) systems. There are few data feeds 
    available, the simplest of them is Darwin, which provides real-time 
    arrival and departure predictions, platform numbers, delay estimates, 
    schedule changes and cancellations. Other data feeds provide historical 
    data, Historic Service Performance (HSP), and much more. 'trainR' 
    simplifies the data retrieval, so that the users can focus on their 
    analyses. For more details visit 
    <https://www.nationalrail.co.uk/46391.aspx>. ",2021-01-20,Roberto Villegas-Diaz,"https://github.com/villegar/trainR/,
https://villegar.github.io/trainR/",TRUE,https://github.com/villegar/trainr,6179,3,2021-08-10T21:04:29Z,2059.6666666666665
traipse,"A collection of commonly used tools for animal movement and other tracking 
 data. Variously distance, angle, bearing, distance-to, bearing-to and speed are 
 provided for geographic data that can be used directly or within 'tidyverse' 
 syntax. Distances and bearings are calculated using modern geodesic methods as 
 provided by Charles F. F. Karney (2013) <doi:10.1007/s00190-012-0578-z> 
 via the 'geodist' and 'geosphere' packages. ",2021-10-12,Michael Sumner,https://github.com/Trackage/traipse,TRUE,https://github.com/trackage/traipse,20779,17,2021-10-12T13:34:33Z,1222.2941176470588
traitdataform,"Assistance for handling ecological trait data and applying the 
    Ecological Trait-Data Standard terminology (Schneider et al. 2019
    <doi:10.1111/2041-210X.13288>). There are two major use cases: (1) preparation of
    own trait datasets for publication, and (2) harmonizing
    trait datasets from different sources by re-formatting them into a unified
    format. See 'traitdataform' website for full documentation. ",2022-05-25,Florian D. Schneider,"https://ecologicaltraitdata.github.io/traitdataform/,
https://github.com/ecologicaltraitdata/traitdataform",TRUE,https://github.com/ecologicaltraitdata/traitdataform,13808,29,2022-05-25T13:38:14Z,476.13793103448273
trajeR,"Find the probability and the trajectory of longitudinal mixture model. Methods used in the package refer to Nagin (2005),
      <doi:10.4159/9780674041318>,
      Nagin, D. (2005). Group-Based Modeling of Development. Cambridge, MA: Harvard University Press.
      and Noel (2022),
      <https://orbilu.uni.lu/>,
      thesis.",2022-02-21,Cédric NOEL - Jang Schiltz,https://github.com/gitedric/trajeR,TRUE,https://github.com/gitedric/trajer,1193,1,2022-02-18T09:49:26Z,1193
trajr,"A toolbox to assist with statistical analysis of 2-dimensional animal trajectories.
    It provides simple access to algorithms for calculating and assessing a variety of 
    characteristics such as speed and acceleration, as well as multiple measures of 
    straightness or tortuosity. McLean & Skowron Volponi (2018) <doi:10.1111/eth.12739>.",2020-12-17,Jim McLean,https://github.com/JimMcL/trajr,TRUE,https://github.com/jimmcl/trajr,18331,17,2022-07-08T17:38:42Z,1078.2941176470588
trampoline,"Implements a trampoline algorithm for R that let's users write recursive functions
    that get around R's stack call limitations, enabling theoretically infinite recursion. The
    algorithm is based around generator function as implemented in the 'coro' package, and is
    based almost completely on the 'trampoline' module from Python <https://gitlab.com/ferreum/trampoline>.",2022-01-04,Russell Dinnage,"https://github.com/rdinnager/trampoline,
https://rdinnager.github.io/trampoline/",TRUE,https://github.com/rdinnager/trampoline,1894,20,2022-01-25T15:17:39Z,94.7
TRAMPR,"Matching terminal restriction fragment length
        polymorphism ('TRFLP') profiles between unknown samples and a
        database of known samples.  'TRAMPR' facilitates analysis of
        many unknown profiles at once, and provides tools for working
        directly with electrophoresis output through to generating
        summaries suitable for community analyses with R's rich set of
        statistical functions.  'TRAMPR' also resolves the issues of
        multiple 'TRFLP' profiles within a species, and shared 'TRFLP'
        profiles across species.",2022-02-07,Rich FitzJohn,https://github.com/richfitz/TRAMPR,TRUE,https://github.com/richfitz/trampr,21041,0,2022-02-07T18:48:13Z,NA
tranSurv,"A latent, quasi-independent truncation time is assumed to be linked with the observed dependent truncation time, the event time, and an unknown transformation parameter via a structural transformation model. The transformation parameter is chosen to minimize the conditional Kendall's tau (Martin and Betensky, 2005) <doi:10.1198/016214504000001538> or the regression coefficient estimates (Jones and Crowley, 1992) <doi:10.2307/2336782>. The marginal distribution for the truncation time and the event time are completely left unspecified. The methodology is applied to survival curve estimation and regression analysis.",2021-01-12,Sy Han (Steven) Chiou,https://github.com/stc04003/tranSurv,TRUE,https://github.com/stc04003/transurv,14215,0,2021-07-17T17:33:17Z,NA
TreeBUGS,"User-friendly analysis of hierarchical multinomial processing tree (MPT) 
    models that are often used in cognitive psychology. Implements the latent-trait 
    MPT approach (Klauer, 2010) <DOI:10.1007/s11336-009-9141-0> and the beta-MPT 
    approach (Smith & Batchelder, 2010) <DOI:10.1016/j.jmp.2009.06.007> to model 
    heterogeneity of participants. MPT models are conveniently specified by an
    .eqn-file as used by other MPT software and data are provided by a .csv-file 
    or directly in R. Models are either fitted by calling JAGS or by an MPT-tailored 
    Gibbs sampler in C++ (only for nonhierarchical and beta MPT models). Provides 
    tests of heterogeneity and MPT-tailored summaries and plotting functions.
    A detailed documentation is available in Heck, Arnold, & Arnold (2018) 
    <DOI:10.3758/s13428-017-0869-7>.",2021-01-08,Daniel W. Heck,https://github.com/danheck/TreeBUGS,TRUE,https://github.com/danheck/treebugs,22271,10,2022-04-25T15:36:51Z,2227.1
treeclim,"Bootstrapped response and correlation functions,
    seasonal correlations and evaluation of reconstruction
    skills for use in dendroclimatology and dendroecology,
    see Zang and Biondi (2015) <doi:10.1111/ecog.01335>.",2022-02-08,Christian Zang,https://github.com/cszang/treeclim,TRUE,https://github.com/cszang/treeclim,24812,13,2022-02-08T10:39:39Z,1908.6153846153845
TreeDist,"Implements measures of tree similarity, including 
  information-based generalized Robinson-Foulds distances
  (Phylogenetic Information Distance, Clustering Information Distance,
  Matching Split Information Distance; Smith 2020)
  <doi:10.1093/bioinformatics/btaa614>; 
  Jaccard-Robinson-Foulds distances (Bocker et al. 2013)
  <doi:10.1007/978-3-642-40453-5_13>, 
  including the Nye et al. (2006) metric <doi:10.1093/bioinformatics/bti720>;
  the Matching Split Distance (Bogdanowicz & Giaro 2012)
  <doi:10.1109/TCBB.2011.48>;
  Maximum Agreement Subtree distances;
  the Kendall-Colijn (2016) distance <doi:10.1093/molbev/msw124>, and the
  Nearest Neighbour Interchange (NNI) distance, approximated per Li et al. 
  (1996) <doi:10.1007/3-540-61332-3_168>.
  Includes tools for visualizing mappings of tree space (Smith 2022)
  <doi:10.1093/sysbio/syab100>,
  for calculating the median of sets of trees,
  and for computing the information content of trees and splits.",2022-03-23,Martin R. Smith,"https://ms609.github.io/TreeDist/,
https://github.com/ms609/TreeDist/",TRUE,https://github.com/ms609/treedist,16772,11,2022-06-24T09:45:06Z,1524.7272727272727
treefit,"Perform two types of analysis: 1) checking the
    goodness-of-fit of tree models to your single-cell gene expression
    data; and 2) deciding which tree best fits your data.",2022-01-18,Momoko Hayamizu,"https://hayamizu-lab.github.io/treefit-r/,
https://github.com/hayamizu-lab/treefit-r/",TRUE,https://github.com/hayamizu-lab/treefit-r,7751,3,2022-01-18T08:12:00Z,2583.6666666666665
treeheatr,"Creates interpretable decision tree visualizations 
    with the data represented as a heatmap at the tree's leaf nodes.
    'treeheatr' utilizes the customizable 'ggparty' package for 
    drawing decision trees.",2020-11-19,Trang Le,"https://trang1618.github.io/treeheatr/index.html,
https://trang1618.github.io/treeheatr-manuscript/",TRUE,https://github.com/trang1618/treeheatr,8952,51,2021-09-13T20:54:14Z,175.52941176470588
treenomial,"Provides functionality for creation and comparison of polynomials that uniquely
  describe trees as introduced in Liu (2019, <arXiv:1904.03332>). The core method
  converts rooted unlabeled phylo objects from 'ape' to the tree defining polynomials 
  described with coefficient matrices. Additionally, a conversion for rooted binary trees 
  with binary trait labels is also provided. Once the polynomials of trees are calculated 
  there are functions to calculate distances, distance matrices and plot different distance 
  trees from a target tree. Manipulation and conversion to the tree defining polynomials is 
  implemented in C++ with 'Rcpp' and 'RcppArmadillo'. Furthermore, parallel programming with 
  'RcppThread' is used to improve performance converting to polynomials and calculating distances. ",2022-06-06,Matthew Gould,https://github.com/gouldmatt/treenomial,TRUE,https://github.com/gouldmatt/treenomial,12605,1,2022-06-05T03:25:08Z,12605
TreeSearch,"Reconstruct phylogenetic trees from discrete data.
  Inapplicable character states are handled using the algorithm of Brazeau,
  Guillerme and Smith (2019) <doi:10.1093/sysbio/syy083> with the ""Morphy""
  library, under equal or implied step weights.
  Contains a ""shiny"" user interface for interactive tree search and exploration
  of results, including character visualization, rogue taxon detection,
  tree space mapping, and cluster consensus trees (Smith 2022a, b)
  <doi:10.1093/sysbio/syab099>, <doi:10.1093/sysbio/syab100>.
  Profile Parsimony (Faith and Trueman, 2001) <doi:10.1080/10635150118627>, 
  Successive Approximations (Farris, 1969) <doi:10.2307/2412182>
  and custom optimality criteria are implemented.",2022-05-11,Martin R. Smith,"https://ms609.github.io/TreeSearch/,
https://github.com/ms609/TreeSearch/",TRUE,https://github.com/ms609/treesearch,20568,3,2022-06-27T08:59:46Z,6856
TreeTools,"Efficient implementations of functions for the creation, 
  modification and analysis of phylogenetic trees.
  Applications include:
  generation of trees with specified shapes;
  tree rearrangement;
  analysis of tree shape;
  rooting of trees and extraction of subtrees;
  calculation and depiction of split support;
  plotting the position of rogue taxa (Klopfstein & Spasojevic 2019)
  <doi:10.1371/journal.pone.0212942>;
  calculation of ancestor-descendant relationships,
  of 'stemwardness' (Asher & Smith, 2021) <doi:10.1093/sysbio/syab072>,
  and of tree balance (Mir et al. 2013) <doi:10.1016/j.mbs.2012.10.005>;
  artificial extinction (Asher & Smith, 2022) <doi:10.1093/sysbio/syab072>;
  import and export of trees from Newick, Nexus (Maddison et al. 1997)
  <doi:10.1093/sysbio/46.4.590>,
  and TNT <http://www.lillo.org.ar/phylogeny/tnt/> formats;
  and analysis of splits and cladistic information.",2022-05-24,Martin R. Smith,"https://ms609.github.io/TreeTools/,
https://github.com/ms609/TreeTools/",TRUE,https://github.com/ms609/treetools,30497,9,2022-07-08T09:21:09Z,3388.5555555555557
treetop,Set of tools implemented into a shiny-based application for extracting and analyzing individual tree forest attributes from LiDAR (Light Detection and Ranging) data.,2022-02-04,Carlos Alberto Silva,https://github.com/carlos-alberto-silva/weblidar-treetop,TRUE,https://github.com/carlos-alberto-silva/weblidar-treetop,6031,101,2022-03-08T19:45:50Z,59.71287128712871
trelliscopejs,"Trelliscope is a scalable, flexible, interactive approach to visualizing data (Hafen, 2013 <doi:10.1109/LDAV.2013.6675164>). This package provides methods that make it easy to create a Trelliscope display specification for TrelliscopeJS. High-level functions are provided for creating displays from within 'tidyverse' or 'ggplot2' workflows. Low-level functions are also provided for creating new interfaces.",2021-02-01,Ryan Hafen,https://github.com/hafen/trelliscopejs,TRUE,https://github.com/hafen/trelliscopejs,29837,235,2022-06-09T20:37:09Z,126.96595744680852
trendeval,"Provides a coherent interface for evaluating models fit with the
  trending package.  This package is part of the RECON
  (<https://www.repidemicsconsortium.org/>) toolkit for outbreak analysis.",2020-11-20,Dirk Schumacher,https://github.com/reconhub/trendeval,TRUE,https://github.com/reconhub/trendeval,12723,1,2021-09-30T14:13:36Z,12723
trending,"Provides a coherent interface to multiple modelling tools for
  fitting trends along with a standardised approach for generating confidence
  and prediction intervals.",2021-04-19,Dirk Schumacher,https://github.com/reconhub/trending,TRUE,https://github.com/reconhub/trending,16249,7,2021-10-14T16:27:03Z,2321.285714285714
TRES,"Provides three estimators for tensor response regression (TRR) and tensor predictor regression (TPR) models with tensor envelope structure. The three types of estimation approaches are generic and can be applied to any envelope estimation problems. The full Grassmannian (FG) optimization is often associated with likelihood-based estimation but requires heavy computation and good initialization; the one-directional optimization approaches (1D and ECD algorithms) are faster, stable and does not require carefully chosen initial values; the SIMPLS-type is motivated by the partial least squares regression and is computationally the least expensive. For details of TRR, see Li L, Zhang X (2017) <doi:10.1080/01621459.2016.1193022>. For details of TPR, see Zhang X, Li L (2017) <doi:10.1080/00401706.2016.1272495>. For details of 1D algorithm, see Cook RD, Zhang X (2016) <doi:10.1080/10618600.2015.1029577>. For details of ECD algorithm, see Cook RD, Zhang X (2018) <doi:10.5705/ss.202016.0037>. For more details of the package, see Zeng J, Wang W, Zhang X (2021) <doi:10.18637/jss.v099.i12>.",2021-10-20,Jing Zeng,https://github.com/leozeng15/TRES,TRUE,https://github.com/leozeng15/tres,13821,0,2021-11-12T00:30:57Z,NA
trialr,"A collection of clinical trial designs and methods, implemented in 
    'rstan' and R, including: the Continual Reassessment Method by O'Quigley et 
    al. (1990) <doi:10.2307/2531628>; EffTox by Thall & Cook (2004) 
    <doi:10.1111/j.0006-341X.2004.00218.x>; the two-parameter logistic method of
    Neuenschwander, Branson & Sponer (2008) <doi:10.1002/sim.3230>; and the 
    Augmented Binary method by Wason & Seaman (2013) <doi:10.1002/sim.5867>; and
    more. We provide functions to aid model-fitting and analysis. 
    The 'rstan' implementations may also serve as a cookbook to anyone looking 
    to extend or embellish these models. We hope that this package encourages 
    the use of Bayesian methods in clinical trials. There is a preponderance of 
    early phase trial designs because this is where Bayesian methods are used 
    most. If there is a method you would like implemented, please get in touch.",2020-10-15,Kristian Brock,https://github.com/brockk/trialr,TRUE,https://github.com/brockk/trialr,22258,37,2021-10-22T08:41:52Z,601.5675675675676
triangle,"Provides the ""r, q, p, and d"" distribution functions for the triangle distribution.",2019-02-14,Rob Carnell,https://bertcarnell.github.io/triangle/,TRUE,https://github.com/bertcarnell/triangle,110701,2,2021-09-10T00:54:30Z,55350.5
TriDimRegression,"Fits 2D and 3D geometric transformations via 'Stan' probabilistic programming engine ( 
    Stan Development Team (2021) <https://mc-stan.org>). Returns posterior distribution for individual
    parameters of the fitted distribution. Allows for computation of LOO and WAIC information criteria 
    (Vehtari A, Gelman A, Gabry J (2017) <doi:10.1007/s11222-016-9696-4>) as well as Bayesian R-squared
    (Gelman A, Goodrich B, Gabry J, and Vehtari A (2018) <doi:10.1080/00031305.2018.1549100>).",2021-10-05,Alexander (Sasha) Pastukhov,https://github.com/alexander-pastukhov/tridim-regression,TRUE,https://github.com/alexander-pastukhov/tridim-regression,5082,0,2022-02-17T09:40:49Z,NA
triebeard,"'Radix trees', or 'tries', are key-value data structures optimised for efficient lookups, similar in purpose
             to hash tables. 'triebeard' provides an implementation of 'radix trees' for use in R programming and in
             developing packages with 'Rcpp'.",2016-08-04,Oliver Keyes,https://github.com/Ironholds/triebeard/,TRUE,https://github.com/ironholds/triebeard,1006233,29,2021-10-20T14:43:44Z,34697.68965517241
trimr,"Provides various commonly-used response time trimming
    methods, including the recursive / moving-criterion methods reported by
    Van Selst and Jolicoeur (1994). By passing trimming functions raw data files,
    the package will return trimmed data ready for inferential testing.",2022-05-05,James Grange,https://github.com/JimGrange/trimr,TRUE,https://github.com/jimgrange/trimr,14915,8,2022-05-05T03:08:44Z,1864.375
troopdata,These functions generate data frames on troop deployments and military basing using U.S. Department of Defense data on overseas military deployments. This package provides functions for pulling country-year troop deployment and basing data. Subsequent versions will hopefully include cross-national data on deploying countries.,2022-01-31,Michael Flynn,https://github.com/meflynn/troopdata,TRUE,https://github.com/meflynn/troopdata,6099,26,2022-01-31T21:19:39Z,234.57692307692307
TropFishR,"A compilation of fish stock assessment methods for the
    analysis of length-frequency data in the context of data-poor
    fisheries. Includes methods and examples included in the FAO
    Manual by P. Sparre and S.C. Venema (1998), ""Introduction to tropical fish
    stock assessment"" (<http://www.fao.org/documents/card/en/c/9bb12a06-2f05-5dcb-a6ca-2d6dd3080f65/>),
    as well as other more recent methods.",2021-10-04,Tobias K. Mildenberger,https://github.com/tokami/TropFishR,TRUE,https://github.com/tokami/tropfishr,25540,19,2022-03-04T09:05:29Z,1344.2105263157894
truelies,"Implements Bayesian methods, described in
    Hugh-Jones (2019) <doi:10.1007/s40881-019-00069-x>, for estimating the
    proportion of liars in coin flip-style experiments, where subjects
    report a random outcome and are paid for reporting a ""good"" outcome.",2019-08-26,David Hugh-Jones,https://github.com/hughjonesd/truelies,TRUE,https://github.com/hughjonesd/truelies,10350,0,2021-09-14T21:13:05Z,NA
TrueSkillThroughTime,"
    Most estimators implemented by the video game industry cannot obtain reliable initial estimates nor guarantee comparability between distant estimates. TrueSkill Through Time solves all these problems by modeling the entire history of activities using a single Bayesian network allowing the information to propagate correctly throughout the system. This algorithm requires only a few iterations to converge, allowing millions of observations to be analyzed using any low-end computer.
    The core ideas implemented in this project were developed by Dangauthier P, Herbrich R, Minka T, Graepel T (2007). ""Trueskill through time: Revisiting the history of chess."" <https://dl.acm.org/doi/10.5555/2981562.2981605>.",2021-12-10,Gustavo Landfried,https://github.com/glandfried/TrueSkillThroughTime.R,TRUE,https://github.com/glandfried/trueskillthroughtime.r,1688,2,2022-02-14T19:07:14Z,844
truh,"Implements the TRUH test statistic for two sample testing under heterogeneity. TRUH incorporates the underlying heterogeneity and imbalance in the samples, and provides a conservative test for the composite null hypothesis that the two samples arise from the 
   same mixture distribution but may differ with respect to the mixing weights. See Trambak Banerjee, Bhaswar B. Bhattacharya, Gourab Mukherjee Ann. Appl. Stat. 14(4): 1777-1805 (December 2020). <DOI:10.1214/20-AOAS1362> for more details.",2021-09-08,Nathan Smith,https://github.com/natesmith07/truh,TRUE,https://github.com/natesmith07/truh,2988,0,2021-08-30T20:06:22Z,NA
TruncatedNormal,"A collection of functions to deal with the truncated univariate and multivariate normal and Student distributions, described in Botev (2017) <doi:10.1111/rssb.12162> and Botev and L'Ecuyer (2015) <doi:10.1109/WSC.2015.7408180>.",2021-09-08,Zdravko Botev,NA,TRUE,https://github.com/lbelzile/truncatednormal,41287,4,2022-05-13T14:22:10Z,10321.75
TruncExpFam,"Handles truncated members from the exponential family of
	probability distributions. Contains functions such as rtruncnorm() and
	dtruncpois(), which are truncated versions of rnorm() and dpois() from the
	stats package that also offer richer output containing, for example, the
	distribution parameters. It also provides functions to retrieve the original
	distribution parameters from a truncated sample by maximum-likelihood
	estimation.",2022-02-24,Waldir Leoncio,https://github.com/ocbe-uio/TruncExpFam,TRUE,https://github.com/ocbe-uio/truncexpfam,1040,0,2022-05-12T14:05:37Z,NA
trustOptim,"Trust region algorithm for nonlinear optimization. Efficient when
    the Hessian of the objective function is sparse (i.e., relatively few nonzero
    cross-partial derivatives). See Braun, M. (2014) <doi:10.18637/jss.v060.i04>.",2021-10-11,Michael Braun,"https://braunm.github.io/trustOptim/,
https://github.com/braunm/trustOptim/",TRUE,https://github.com/braunm/trustoptim,207595,3,2021-10-07T17:53:18Z,69198.33333333333
TrustVDJ,"A toolkit for read and prepare immune repertoire data. 'TrustVDJ' package focuses on the reading and processing of 'TRUST4' and '10x cellranger' software output results by using 'ReadTrust' and 'Read10x' functions, respectively, and also provides a convenience function 'build_IMGT_reference' to download the 'IMGT' database reference and split its sequences by species.",2022-03-16,Lianhao Song,NA,TRUE,https://github.com/hatsunecode/trustvdj,912,0,2022-06-22T14:56:11Z,NA
tryCatchLog,"Advanced tryCatch() and try() functions for better error handling
             (logging, stack trace with source code references and support for post-mortem analysis via dump files).",2021-10-25,Juergen Altfeld,https://github.com/aryoda/tryCatchLog,TRUE,https://github.com/aryoda/trycatchlog,34335,68,2021-11-04T09:33:07Z,504.9264705882353
ts.extend,"Stationary Gaussian ARMA processes and the stationary 'GARMA' distribution are fundamental in time series analysis. Here we give utilities to compute 
    the auto-covariance/auto-correlation for a stationary Gaussian ARMA process, as well as the probability functions (density, cumulative distribution, random 
    generation) for random vectors from this distribution.  We also give functions for the spectral intensity, and the permutation-spectrum test for testing 
    a time-series vector for the presence of a signal.",2020-11-14,Ben ONeill,https://github.com/ben-oneill/ts.extend,TRUE,https://github.com/ben-oneill/ts.extend,7264,2,2021-12-26T04:52:41Z,3632
ts2net,"Transforming one or multiple time series into networks. This package is 
    useful for complex systems modeling, time series data mining, or time series analysis using networks. 
    An introduction to the topic and the descriptions of the methods implemented 
    in this package can be found in Mitchell (2006) <doi:10.1016/j.artint.2006.10.002>, 
    Silva and Zhao (2016) <doi:10.1007/978-3-319-17290-3>, and Silva et al. (2021) <doi:10.1002/widm.1404>.",2022-06-09,Leonardo N. Ferreira,https://github.com/lnferreira/ts2net,TRUE,https://github.com/lnferreira/ts2net,227,3,2022-07-07T16:05:49Z,75.66666666666667
tsbox,"Time series toolkit with identical behavior for all
  time series classes: 'ts','xts', 'data.frame', 'data.table', 'tibble', 'zoo',
  'timeSeries', 'tsibble', 'tis' or 'irts'. Also converts reliably between these classes.",2021-09-16,Christoph Sax,"https://www.tsbox.help, https://github.com/christophsax/tsbox",TRUE,https://github.com/christophsax/tsbox,88532,132,2022-04-19T10:37:05Z,670.6969696969697
tsdb,"A terribly-simple data base for numeric
  time series, written purely in R, so no external
  database-software is needed. Series are stored in
  plain-text files (the most-portable and enduring file
  type) in CSV format. Timestamps are encoded using R's
  native numeric representation for 'Date'/'POSIXct',
  which makes them fast to parse, but keeps them
  accessible with other software. The package provides
  tools for saving and updating series in this
  standardised format, for retrieving and joining data,
  for summarising files and directories, and for
  coercing series from and to other data types (such as
  'zoo' series).",2021-01-06,Enrico Schumann,"http://enricoschumann.net/R/packages/tsdb/,
https://github.com/enricoschumann/tsdb,
https://gitlab.com/enricoschumann/tsdb",TRUE,https://github.com/enricoschumann/tsdb,13300,10,2021-10-28T07:43:10Z,1330
TSDFGS,"We propose an optimality criterion to determine the required training set, r-score, which is derived directly from Pearson's correlation between the genomic estimated breeding values and phenotypic values of the test set <doi:10.1007/s00122-019-03387-0>. This package provides two main functions to determine a good training set and its size.",2022-06-07,Jen-Hsiang Ou,https://github.com/oumarkme/TSDFGS,TRUE,https://github.com/oumarkme/tsdfgs,10239,1,2022-06-07T13:57:14Z,10239
TSDT,Implements a method for identifying subgroups with superior response relative to the overall sample.,2022-04-06,Brian Denton,https://github.com/EliLillyCo/CRAN_TSDT,TRUE,https://github.com/elilillyco/cran_tsdt,10805,0,2022-04-06T22:11:00Z,NA
tsentiment,"Which uses Twitter APIs for the necessary data in sentiment analysis, acts as a middleware with the approved Twitter Application.
    A special access key is given to users who subscribe to the application with their Twitter account. With this special access key, the user defined keyword for sentiment analysis can be searched in twitter recent searches and results can be obtained( more information <https://github.com/hakkisabah/tsentiment> ).
    In addition, a service named tsentiment-services has been developed to provide all these operations ( for more information <https://github.com/hakkisabah/tsentiment-services> ).
    After the successful results obtained and in line with the permissions given by the user, the results of the analysis of the word cloud and bar graph saved in the user folder directory can be seen. In each analysis performed, the previous analysis visual result is deleted and this is the basic information you need to know as a practice rule.
    'tsentiment' package provides a free service that acts as a middleware for easy data extraction from Twitter, and in return, the user rate limit is reduced by 30 requests from the total limit and the remaining requests are used. These 30 requests are reserved for use in application analytics. For information about endpoints, you can refer to the limit information in the ""GET search/tweets"" row in the Endpoints column in the list at <https://developer.twitter.com/en/docs/twitter-api/v1/rate-limits>.",2021-11-30,Hakki Sabah,"https://github.com/hakkisabah/tsentiment,
https://www.tsentiment.com",TRUE,https://github.com/hakkisabah/tsentiment,2052,0,2022-01-10T09:34:32Z,NA
tsfeatures,"Methods for extracting various features from time series data. The features provided are those from Hyndman, Wang and Laptev (2013) <doi:10.1109/ICDMW.2015.104>, Kang, Hyndman and Smith-Miles (2017) <doi:10.1016/j.ijforecast.2016.09.004> and from Fulcher, Little and Jones (2013) <doi:10.1098/rsif.2013.0048>. Features include spectral entropy, autocorrelations, measures of the strength of seasonality and trend, and so on. Users can also define their own feature functions.",2020-06-07,Rob Hyndman,https://pkg.robjhyndman.com/tsfeatures/,TRUE,https://github.com/robjhyndman/tsfeatures,520967,225,2022-03-01T07:54:24Z,2315.4088888888887
tsfgrnn,"A general regression neural network (GRNN) is a variant of a
    Radial Basis Function Network characterized by a fast single-pass learning.
    'tsfgrnn' allows you to forecast time series using a GRNN model Francisco 
    Martinez et al. (2019) <doi:10.1007/978-3-030-20521-8_17> and Francisco
    Martinez et al. (2022) <doi:10.1016/j.neucom.2021.12.028>. When the forecasting
    horizon is higher than 1, two multi-step ahead forecasting strategies can be used.
    The model built is autoregressive, that is, it is only based on the 
    observations of the time series. You can consult and plot how the
    prediction was done. It is also possible to assess the forecasting accuracy
    of the model using rolling origin evaluation.",2022-05-30,Francisco Martinez,https://github.com/franciscomartinezdelrio/tsfgrnn,TRUE,https://github.com/franciscomartinezdelrio/tsfgrnn,12846,5,2022-05-30T11:24:29Z,2569.2
TSGS,"Obtaining relevant set of trait specific genes from gene expression data is important for clinical diagnosis of disease and discovery of disease mechanisms in plants and animals. This process involves identification of relevant genes and removal of redundant genes as much as possible from a whole gene set. This package returns the trait specific gene set from the high dimensional RNA-seq count data by applying combination of two conventional machine learning algorithms, support vector machine (SVM) and genetic algorithm (GA). GA is used to control and optimize the subset of genes sent to the SVM for classification and evaluation. Genetic algorithm uses repeated learning steps and cross validation over number of possible solution and selects the best. The algorithm selects the set of genes based on a fitness function that is obtained via support vector machines. Using SVM as the classifier performance and the genetic algorithm for feature selection, a set of trait specific gene set is obtained.",2021-09-08,Sudhir Srivastava,https://github.com/SudhirSrivastava/TSGS,TRUE,https://github.com/sudhirsrivastava/tsgs,3003,0,2021-08-27T07:30:22Z,NA
tsibble,"Provides a 'tbl_ts' class (the 'tsibble') for
    temporal data in an data- and model-oriented format. The 'tsibble'
    provides tools to easily manipulate and analyse temporal data, such as
    filling in time gaps and aggregating over calendar periods.",2021-12-03,Earo Wang,https://tsibble.tidyverts.org,TRUE,https://github.com/tidyverts/tsibble,543077,501,2021-12-04T11:46:59Z,1083.9860279441118
tsibbledata,"Provides diverse datasets in the 'tsibble' data structure. These datasets are useful for learning and demonstrating how tidy temporal data can tidied, visualised, and forecasted.",2022-01-07,Mitchell OHara-Wild,"https://tsibbledata.tidyverts.org/,
https://github.com/tidyverts/tsibbledata/",TRUE,https://github.com/tidyverts/tsibbledata,124989,19,2022-01-12T01:35:24Z,6578.368421052632
tsna,"Temporal SNA tools for continuous- and discrete-time longitudinal networks having vertex, edge, and attribute dynamics stored in the 'networkDynamic' format. This work was supported by grant R01HD68395 from the National Institute of Health.",2021-11-01,Skye Bender-deMoll,http://statnet.org/,TRUE,https://github.com/statnet/tsna,73834,4,2021-10-31T15:30:38Z,18458.5
TSP,"Basic infrastructure and some algorithms for the traveling
    salesperson problem (also traveling salesman problem; TSP).
    The package provides some simple algorithms and
    an interface to the Concorde TSP solver and its implementation of the
    Chained-Lin-Kernighan heuristic. The code for Concorde
    itself is not included in the package and has to be obtained separately.
    Hahsler and Hornik (2007) <doi:10.18637/jss.v023.i02>.",2022-02-21,Michael Hahsler,https://github.com/mhahsler/TSP,TRUE,https://github.com/mhahsler/tsp,853102,52,2022-07-06T00:31:56Z,16405.80769230769
tstools,"Plot official statistics' time series conveniently: automatic legends, highlight windows, stacked bar chars with positive and negative contributions, sum-as-line option, two y-axes with automatic horizontal grids that fit both axes and other popular chart types. 'tstools' comes with a plethora of defaults to let you plot without setting an abundance of parameters first, but gives you the flexibility to tweak the defaults. In addition to charts, 'tstools' provides a super fast, 'data.table' backed time series I/O that allows the user to export / import long format, wide format and transposed wide format data to various file types. ",2022-03-30,Matthias Bannert,https://github.com/mbannert/tstools/,TRUE,https://github.com/mbannert/tstools,26998,9,2022-03-29T17:54:59Z,2999.777777777778
tsutils,"Includes: (i) tests and visualisations that can help the modeller explore time series components and perform decomposition; (ii) modelling shortcuts, such as functions to construct lagmatrices and seasonal dummy variables of various forms; (iii) an implementation of the Theta method; (iv) tools to facilitate the design of the forecasting process, such as ABC-XYZ analyses; and (v) ""quality of life"" functions, such as treating time series for trailing and leading values.",2022-07-05,Nikolaos Kourentzes,https://github.com/trnnick/tsutils/,TRUE,https://github.com/trnnick/tsutils,72283,9,2022-07-10T09:46:39Z,8031.444444444444
ttbbeer,"U.S. Department of the Treasury, Alcohol and Tobacco Tax and
    Trade Bureau (TTB) collects data and reports on monthly beer
    industry production and operations. This data package includes
    a collection of 10 years (2006 - 2015) worth of data on materials
    used at U.S. breweries in pounds reported by the Brewer's Report
    of Operations and the Quarterly Brewer's Report of Operations
    forms, ready for data analysis. This package also includes historical
    tax rates on distilled spirits, wine, beer, champagne, and tobacco
    products as individual data sets.",2016-08-01,Jasmine Dumas,https://github.com/jasdumas/ttbbeer,TRUE,https://github.com/jasdumas/ttbbeer,16565,23,2022-06-02T00:36:10Z,720.2173913043479
ttdo,"The 'tinytest' package offers a light-weight zero-dependency unit-testing
 framework to which this package adds support of the 'diffobj' package for 'diff'-style
 comparison of R objects.",2021-07-17,Dirk Eddelbuettel and Alton Barbehenn,"https://github.com/eddelbuettel/ttdo/,
https://dirk.eddelbuettel.com/code/ttdo.html",TRUE,https://github.com/eddelbuettel/ttdo,14222,20,2022-01-26T02:50:35Z,711.1
TTR,"A collection of over 50 technical indicators for creating technical trading rules. The package also provides fast implementations of common rolling-window functions, and several volatility calculations.",2021-12-12,Joshua Ulrich,https://github.com/joshuaulrich/TTR,TRUE,https://github.com/joshuaulrich/ttr,8395093,273,2022-06-26T13:57:15Z,30751.25641025641
ttt,"Create structured, formatted HTML tables of in a flexible and
    convenient way.",2021-05-07,Benjamin Rich,https://github.com/benjaminrich/ttt,TRUE,https://github.com/benjaminrich/ttt,4465,6,2022-03-16T12:36:52Z,744.1666666666666
tuber,"Get comments posted on YouTube videos, information on how many 
    times a video has been liked, search for videos with particular content, and 
    much more. You can also scrape captions from a few videos. To learn more about
    the YouTube API, see <https://developers.google.com/youtube/v3/>.",2020-06-11,Gaurav Sood,http://github.com/soodoku/tuber,TRUE,https://github.com/soodoku/tuber,31681,164,2022-06-15T07:01:14Z,193.1768292682927
TUFLOWR,"Helper functions for 'TUFLOW FV' models. Current functionality includes reading in and plotting
    output POINTS files and generating initial conditions based on point observations.",2021-10-18,Matt Gibbs,<https://github.com/matt-s-gibbs/TUFLOWR>,TRUE,https://github.com/matt-s-gibbs/tuflowr,6005,1,2021-10-15T05:17:15Z,6005
tufte,"Provides R Markdown output formats to use Tufte styles for
    PDF and HTML output.",2022-01-27,Yihui Xie,https://github.com/rstudio/tufte,TRUE,https://github.com/rstudio/tufte,222248,350,2022-06-15T14:15:46Z,634.9942857142858
TukeyC,"Perform the conventional Tukey test from formula, 
             lm, aov, aovlist and lmer objects.",2021-10-28,José Cláudio Faria,https://github.com/jcfaria/TukeyC,TRUE,https://github.com/jcfaria/tukeyc,23834,4,2021-10-28T01:16:59Z,5958.5
tune,"The ability to tune models is important. 'tune' contains
    functions and classes to be used in conjunction with other
    'tidymodels' packages for finding reasonable values of
    hyper-parameters in models, pre-processing methods, and
    post-processing steps.",2022-07-07,Max Kuhn,"https://tune.tidymodels.org/, https://github.com/tidymodels/tune",TRUE,https://github.com/tidymodels/tune,780935,206,2022-07-07T20:51:53Z,3790.9466019417478
tvR,"Provides tools for denoising noisy signal and images via
    Total Variation Regularization. Reducing the total variation of
    the given signal is known to remove spurious detail while preserving
    essential structural details. For the seminal work on the topic,
    see Rudin et al (1992) <doi:10.1016/0167-2789(92)90242-F>.",2021-08-22,Kisung You,https://github.com/kisungyou/tvR,TRUE,https://github.com/kisungyou/tvr,14767,3,2021-08-22T04:40:33Z,4922.333333333333
tvReg,"Fitting time-varying coefficient models for single and multi-equation regressions, using kernel smoothing techniques.",2022-06-30,Isabel Casas,https://github.com/icasas/tvReg,TRUE,https://github.com/icasas/tvreg,20951,15,2021-11-12T12:32:54Z,1396.7333333333333
tvthemes,"Contains various 'ggplot2' themes and color palettes based on TV shows 
    such as 'Game of Thrones', 'Brooklyn Nine-Nine', 'Avatar: The Last Airbender',
    'Spongebob Squarepants', and more.",2022-03-16,Ryo Nakagawara,https://github.com/Ryo-N7/tvthemes,TRUE,https://github.com/ryo-n7/tvthemes,19434,118,2022-03-17T06:08:29Z,164.6949152542373
tweenr,"In order to create smooth animation between states of data,
    tweening is necessary. This package provides a range of functions for
    creating tweened data that can be used as basis for animation. Furthermore 
    it adds a number of vectorized interpolaters for common R data 
    types such as numeric, date and colour.",2021-03-23,Thomas Lin Pedersen,https://github.com/thomasp85/tweenr,TRUE,https://github.com/thomasp85/tweenr,1939781,388,2021-12-06T06:55:04Z,4999.43556701031
Twitmo,"Tailored for topic modeling with tweets and fit for visualization tasks in R.
    Collect, pre-process and analyze the contents of tweets using 
    LDA and structural topic models (STM). Comes with visualizing capabilities like tweet and hashtag maps 
    and built-in support for 'LDAvis'.",2021-12-06,Andreas Buchmueller,https://github.com/abuchmueller/Twitmo,TRUE,https://github.com/abuchmueller/twitmo,2888,17,2022-07-06T11:28:27Z,169.88235294117646
TwitterAutomatedTrading,"Provides an integration to the 'metatrader 5'. 
    The functionalities carry out automated trading using
    sentiment indexes computed from 'twitter' and/or 'stockwits'. 
    The sentiment indexes are based on the ph.d. dissertation 
    ""Essays on Economic Forecasting Models"" (Godeiro,2018) <https://repositorio.ufpb.br/jspui/handle/123456789/15198>
    The integration between the 'R' and the 'metatrader 5' allows sending buy/sell orders to the brokerage. ",2020-05-31,Lucas Godeiro,https://github.com/lucasgodeiro/TwitterAutomatedTrading,TRUE,https://github.com/lucasgodeiro/twitterautomatedtrading,6878,5,2022-07-10T10:59:39Z,1375.6
twn,"The TWN-list (Taxa Waterbeheer Nederland) is the Dutch standard for naming 
    taxons in Dutch Watermanagement. This package makes it easier to use the 
    TWN-list for ecological analyses. It  consists of two parts. First it makes the 
    TWN-list itself available in R. Second, it has a few functions that make it 
    easy to perform some basic and often recurring tasks for checking and consulting
    taxonomic data from the TWN-list. ",2022-04-27,Johan van Tent,https://redtent.github.io/twn/,TRUE,https://github.com/redtent/twn,8228,0,2022-04-27T14:31:12Z,NA
TwoRegression,"Application of two-regression algorithms for wearable
    research devices. It provides an easy way for users to read in
    device data files and apply an appropriate two-regression
    algorithm. More information is available from
    Hibbing PR, LaMunion SR, Kaplan AS, & Crouter SE (2017)
    <doi:10.1249/MSS.0000000000001532>.",2018-03-19,Paul R. Hibbing,https://github.com/paulhibbing/TwoRegression,TRUE,https://github.com/paulhibbing/tworegression,12713,0,2021-08-30T02:40:07Z,NA
twosamples,"Fast randomization based two sample tests. 
  Testing the hypothesis that two samples come from the same distribution using randomization to create p-values. Included tests are: Kolmogorov-Smirnov, Kuiper, Cramer-von Mises, Anderson-Darling, Wasserstein, and DTS. The default test (two_sample) is based on the DTS test statistic, as it is the most powerful, and thus most useful to most users. 
  The DTS test statistic builds on the Wasserstein distance by using a weighting scheme like that of Anderson-Darling. See the companion paper at <arXiv:2007.01360> or <https://codowd.com/public/DTS.pdf> for details of that test statistic, and non-standard uses of the package (parallel for big N, weighted observations, one sample tests, etc). We also include the permutation scheme to make test building simple for others.",2022-06-06,Connor Dowd,"https://twosampletest.com, https://github.com/cdowd/twosamples",TRUE,https://github.com/cdowd/twosamples,17877,8,2022-07-09T17:43:27Z,2234.625
twosigma,Implements the TWO-Component Single Cell Model-Based Association Method (TWO-SIGMA) for gene-level differential expression (DE) analysis and DE-based gene set testing of single-cell RNA-sequencing datasets. See Van Buren et al. (2020) <doi:10.1002/gepi.22361> and Van Buren et al. (2021) <doi:10.1101/2021.01.24.427979>.   ,2021-12-13,Eric Van Buren,https://github.com/edvanburen/twosigma,TRUE,https://github.com/edvanburen/twosigma,1448,7,2021-12-13T15:34:22Z,206.85714285714286
txshift,"Efficient estimation of the population-level causal effects of
    stochastic interventions on a continuous-valued exposure. Both one-step and
    targeted minimum loss estimators are implemented for the counterfactual mean
    value of an outcome of interest under an additive modified treatment policy,
    a stochastic intervention that may depend on the natural value of the
    exposure. To accommodate settings with outcome-dependent two-phase
    sampling, procedures incorporating inverse probability of censoring
    weighting are provided to facilitate the construction of inefficient and
    efficient one-step and targeted minimum loss estimators.  The causal
    parameter and its estimation were first described by Díaz and van der Laan
    (2013) <doi:10.1111/j.1541-0420.2011.01685.x>, while the multiply robust
    estimation procedure and its application to data from two-phase sampling
    designs is detailed in NS Hejazi, MJ van der Laan, HE Janes, PB Gilbert,
    and DC Benkeser (2020) <doi:10.1111/biom.13375>. The software package
    implementation is described in NS Hejazi and DC Benkeser (2020)
    <doi:10.21105/joss.02447>. Estimation of nuisance parameters may be
    enhanced through the Super Learner ensemble model in 'sl3', available for
    download from GitHub using 'remotes::install_github(""tlverse/sl3"")'.",2022-02-09,Nima Hejazi,https://github.com/nhejazi/txshift,TRUE,https://github.com/nhejazi/txshift,7100,10,2022-02-09T21:45:09Z,710
typed,"A type system for R. It supports setting variable types in a script or the body of a function, so variables can't be assigned illegal values. Moreover it supports setting argument and return types for functions.",2021-03-19,Antoine Fabri,https://github.com/moodymudskipper/typed,TRUE,https://github.com/moodymudskipper/typed,6825,110,2022-03-07T13:57:58Z,62.04545454545455
typehint,"Type hints are special comments within a function body indicating the intended nature of the function's arguments in terms of data types, dimensions and permitted values. The actual parameters with which the function is called are evaluated against these type hint comments at run-time.",2021-08-10,Joachim Zuckarelli,https://github.com/jsugarelli/typehint/,TRUE,https://github.com/jsugarelli/typehint,3195,1,2021-08-08T09:13:08Z,3195
tzdb,"Provides an up-to-date copy of the Internet Assigned Numbers
    Authority (IANA) Time Zone Database. It is updated periodically to
    reflect changes made by political bodies to time zone boundaries, UTC
    offsets, and daylight saving time rules. Additionally, this package
    provides a C++ interface for working with the 'date' library. 'date'
    provides comprehensive support for working with dates and date-times,
    which this package exposes to make it easier for other R packages to
    utilize. Headers are provided for calendar specific calculations,
    along with a limited interface for time zone manipulations.",2022-03-28,Davis Vaughan,"https://tzdb.r-lib.org, https://github.com/r-lib/tzdb",TRUE,https://github.com/r-lib/tzdb,8099765,2,2022-05-09T00:11:51Z,4049882.5
u5mr,"Contains functions for calculating under-five child mortality estimates using the Trussell version of the Brass method (United Nations (1990) <https://www.un.org/en/development/desa/population/publications/pdf/mortality/stepguide_childmort.pdf> and United Nations (1983) <https://www.un.org/en/development/desa/population/publications/pdf/mortality/stepguide_childmort.pdf>) as well as applying the cohort-derived methods by Rajaratnam and colleagues (Rajaratnam JK, Tran LN, Lopez AD, Murray CJL (2010) ""Measuring Under-Five Mortality: Validation of New Low-Cost Methods"" <doi:10.1371/journal.pmed.1000253>).",2021-09-09,Myo Minn Oo,https://github.com/myominnoo/u5mr,TRUE,https://github.com/myominnoo/u5mr,2483,0,2021-09-09T15:46:13Z,NA
uavRmp,The Unmanned Aerial Vehicle Mission Planner provides an easy to use work flow for planning autonomous obstacle avoiding surveys of (almost) ready to fly unmanned aerial vehicles to retrieve aerial or spot related data. It creates either intermediate flight control files for the DJI phantom series or ready to upload control files for the pixhawk based flight controller as used in the 3DR Solo. Additionally it contains some useful tools for digitizing and data manipulation.,2022-05-31,Chris Reudenbach,https://github.com/gisma/uavRmp,TRUE,https://github.com/gisma/uavrmp,13293,14,2022-05-31T19:04:35Z,949.5
ubiquity,"Complete work flow for the analysis of pharmacokinetic pharmacodynamic (PKPD), physiologically-based pharmacokinetic (PBPK) and systems pharmacology models including: creation of ordinary differential equation-based models, pooled parameter estimation, individual/population based simulations, rule-based simulations for clinical trial design and modeling assays, deployment with a customizable 'Shiny' app, and non-compartmental analysis. System-specific analysis templates can be generated and each element includes integrated reporting with 'PowerPoint' and 'Word'. ",2021-09-03,John Harrold,https://ubiquity.tools/rworkflow,TRUE,https://github.com/john-harrold/ubiquity,14787,8,2022-01-01T06:00:19Z,1848.375
ubms,"Fit Bayesian hierarchical models of animal abundance and occurrence
    via the 'rstan' package, the R interface to the 'Stan' C++ library.
    Supported models include single-season occupancy, dynamic occupancy, and
    N-mixture abundance models. Covariates on model parameters are specified
    using a formula-based interface similar to package 'unmarked', while also
    allowing for estimation of random slope and intercept terms. References:
    Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>;
    Fiske and Chandler (2011) <doi:10.18637/jss.v043.i10>.",2021-11-30,Ken Kellner,https://kenkellner.com/ubms/,TRUE,https://github.com/kenkellner/ubms,6838,27,2022-04-12T14:54:12Z,253.25925925925927
UCSCXenaShiny,"Provides functions and a Shiny application for downloading,
    analyzing and visualizing datasets from UCSC Xena
    (<http://xena.ucsc.edu/>), which is a collection of UCSC-hosted public
    databases such as TCGA, ICGC, TARGET, GTEx, CCLE, and others.",2022-06-07,Shixiang Wang,https://github.com/openbiox/UCSCXenaShiny,TRUE,https://github.com/openbiox/ucscxenashiny,15862,61,2022-06-06T13:21:31Z,260.0327868852459
UCSCXenaTools,"Download and explore datasets from UCSC Xena data hubs, which
    are a collection of UCSC-hosted public databases such as TCGA, ICGC,
    TARGET, GTEx, CCLE, and others.  Databases are normalized so they can
    be combined, linked, filtered, explored and downloaded.",2022-06-20,Shixiang Wang,"https://docs.ropensci.org/UCSCXenaTools/,
https://github.com/ropensci/UCSCXenaTools",TRUE,https://github.com/ropensci/ucscxenatools,29973,72,2022-06-20T08:08:34Z,416.2916666666667
udpipe,"This natural language processing toolkit provides language-agnostic
    'tokenization', 'parts of speech tagging', 'lemmatization' and 'dependency
    parsing' of raw text. Next to text parsing, the package also allows you to train
    annotation models based on data of 'treebanks' in 'CoNLL-U' format as provided
    at <https://universaldependencies.org/format.html>. The techniques are explained
    in detail in the paper: 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0
    with UDPipe', available at <doi:10.18653/v1/K17-3009>. 
    The toolkit also contains functionalities for commonly used data manipulations on texts 
    which are enriched with the output of the parser. Namely functionalities and algorithms 
    for collocations, token co-occurrence, document term matrix handling, 
    term frequency inverse document frequency calculations,
    information retrieval metrics (Okapi BM25), handling of multi-word expressions,
    keyword detection (Rapid Automatic Keyword Extraction, noun phrase extraction, syntactical patterns) 
    sentiment scoring and semantic similarity analysis.",2022-03-24,Jan Wijffels,"https://bnosac.github.io/udpipe/en/index.html,
https://github.com/bnosac/udpipe",TRUE,https://github.com/bnosac/udpipe,167592,188,2022-03-23T22:36:14Z,891.4468085106383
uGMAR,"Maximum likelihood estimation of univariate Gaussian Mixture Autoregressive (GMAR),
    Student's t Mixture Autoregressive (StMAR), and Gaussian and Student's t Mixture Autoregressive (G-StMAR) models, 
    quantile residual tests, graphical diagnostics, forecast and simulate from GMAR, StMAR and G-StMAR processes. 
    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2015) <doi:10.1111/jtsa.12108>, 
    Mika Meitz, Daniel Preve, Pentti Saikkonen (2021) <doi:10.1080/03610926.2021.1916531>,
    Savi Virolainen (2021) <doi:10.1515/snde-2020-0060>.",2022-06-07,Savi Virolainen,NA,TRUE,https://github.com/saviviro/ugmar,22048,0,2022-01-24T12:21:13Z,NA
uiucthemes,"A set of custom 'R' 'Markdown' templates for documents and
   presentations with the University of Illinois at Urbana-Champaign (UIUC)
   color scheme and identity standards.",2020-07-25,James Balamuta,"https://github.com/illinois-r/uiucthemes,
http://thecoatlessprofessor.com/projects/uiucthemes/",TRUE,https://github.com/illinois-r/uiucthemes,15525,45,2021-08-20T04:33:05Z,345
UKB.COVID19,"Process UK Biobank COVID-19 test result data for susceptibility, severity and mortality analyses, perform potential non-genetic COVID-19 risk factor and co-morbidity association tests. Wang et al. (2021) <doi:10.5281/zenodo.5174381>.",2022-01-04,Longfei Wang,https://github.com/bahlolab/UKB.COVID19,TRUE,https://github.com/bahlolab/ukb.covid19,2985,1,2022-04-27T05:54:53Z,2985
ukbabynames,"Full listing of UK baby names occurring more than three times per year between 1974 and 2020, and rankings of baby name popularity by decade from 1904 to 1994.",2022-03-25,Mine Çetinkaya-Rundel,https://mine-cetinkaya-rundel.github.io/ukbabynames/,TRUE,https://github.com/mine-cetinkaya-rundel/ukbabynames,18121,16,2022-03-25T14:38:24Z,1132.5625
umap,"Uniform manifold approximation and projection is a technique
    for dimension reduction. The algorithm was described by McInnes and
    Healy (2018) in <arXiv:1802.03426>. This package provides an interface
    for two implementations. One is written from scratch, including components
    for nearest-neighbor search and for embedding. The second implementation
    is a wrapper for 'python' package 'umap-learn' (requires separate
    installation, see vignette for more details).",2022-03-23,Tomasz Konopka,https://github.com/tkonopka/umap,TRUE,https://github.com/tkonopka/umap,227275,119,2022-03-23T19:00:42Z,1909.873949579832
umiAnalyzer,"Tools for analyzing sequencing data containing unique
    molecular identifiers generated by 'UMIErrorCorrect'
    (<https://github.com/stahlberggroup/umierrorcorrect>).",2021-11-25,Stefan Filges,https://github.com/sfilges/umiAnalyzer,TRUE,https://github.com/sfilges/umianalyzer,1209,0,2021-11-25T11:29:34Z,NA
uncorbets,"Implements Minimum Torsion for portfolio diversification as
    described in Meucci, Attilio (2013) <doi:10.2139/ssrn.2276632>.",2021-09-24,Bernardo Reckziegel,https://github.com/Reckziegel/uncorbets,TRUE,https://github.com/reckziegel/uncorbets,12998,4,2021-09-24T23:21:41Z,3249.5
UNF,"Computes a 'universal numeric fingerprint' ('UNF') for an R data
    object. 'UNF' is a hash or signature that can be used to uniquely
    identify (a version of) a rectangular dataset, or a subset thereof. 'UNF' can
    be used, in tandem with a 'DOI', to form a persistent citation to a versioned
    dataset.",2022-04-13,Thomas J. Leeper,https://github.com/leeper/UNF,TRUE,https://github.com/leeper/unf,21221,19,2022-04-12T01:04:55Z,1116.8947368421052
unifir,"Functions for the creation and manipulation of scenes and objects
    within the 'Unity' '3D' video game engine (<https://unity.com/>). Specific
    focuses include the creation and import of terrain data and 'GameObjects' as
    well as scene management.",2022-05-13,Michael Mahoney,"https://docs.ropensci.org/unifir/,
https://github.com/ropensci/unifir",TRUE,https://github.com/ropensci/unifir,901,18,2022-05-13T13:27:09Z,50.05555555555556
uniformly,"Uniform sampling on various geometric shapes, such as spheres, ellipsoids, simplices.",2022-03-13,Stéphane Laurent,https://github.com/stla/uniformly,TRUE,https://github.com/stla/uniformly,13061,6,2022-03-11T09:45:49Z,2176.8333333333335
unikn,"Define and use graphical elements of corporate design manuals in R. The 'unikn' package provides color functions (by defining dedicated colors and color palettes, and commands for changing, viewing, and using them) and styled text elements (e.g., for marking, underlining, or plotting colored titles). The pre-defined range of colors and text functions is based on the corporate design of the University of Konstanz <https://www.uni-konstanz.de/>, but can be adapted and extended for other institutions and purposes. ",2021-03-27,Hansjoerg Neth,https://CRAN.R-project.org/package=unikn,TRUE,https://github.com/hneth/unikn,26486,7,2022-01-02T15:07:16Z,3783.714285714286
UniprotR,"Connect to Uniprot <https://www.uniprot.org/> to retrieve information about proteins using their accession number such information could be name or taxonomy information, For detailed information kindly read the publication <https://www.sciencedirect.com/science/article/pii/S1874391919303859>.",2022-07-03,Mohamed Soudy,https://github.com/Proteomicslab57357/UniprotR,TRUE,https://github.com/proteomicslab57357/uniprotr,28849,29,2022-07-03T11:07:38Z,994.7931034482758
uniqtag,"For each string in a set of strings, determine a unique tag that is a substring of fixed size k unique to that string, if it has one. If no such unique substring exists, the least frequent substring is used. If multiple unique substrings exist, the lexicographically smallest substring is used. This lexicographically smallest substring of size k is called the ""UniqTag"" of that string.",2022-06-10,Shaun Jackman,https://github.com/sjackman/uniqtag,TRUE,https://github.com/sjackman/uniqtag,57132,25,2022-05-10T21:36:33Z,2285.28
uniset,"Any package (subsequently called 'target package') is enabled to provide its users an easily accessible, user-friendly and human readable text file where key=value pairs (used by functions defined in the target package) can be saved. This settings file lives in a location defined by the user of the target package, and its user-defined values remain unchanged even when the author of the target package is introducing or deleting keys, or when the target package is updated or re-installed. ",2022-03-27,Bernhard Pollner,"https://bpollner.github.io/uniset/,
https://github.com/bpollner/uniset",TRUE,https://github.com/bpollner/uniset,6863,1,2022-03-30T08:24:09Z,6863
uniswappeR,"Routines to interact with the Uniswap trading platform and its API <https://uniswap.org>.
  The package contains codebase to interact with the uniswap platform directly from R console, Ability 
  to pull and export data related to the platform and analyse some aspects.",2022-05-27,Eric Hare,https://github.com/Omni-Analytics-Group/uniswappeR,TRUE,https://github.com/omni-analytics-group/uniswapper,328,6,2022-05-26T14:58:28Z,54.666666666666664
unitizer,"Simplifies regression tests by comparing objects produced by test
    code with earlier versions of those same objects.  If objects are unchanged
    the tests pass, otherwise execution stops with error details.  If in
    interactive mode, tests can be reviewed through the provided interactive
    environment.",2022-03-23,Brodie Gaslam,https://github.com/brodieG/unitizer,TRUE,https://github.com/brodieg/unitizer,61217,38,2022-03-23T23:49:11Z,1610.9736842105262
units,"Support for measurement units in R vectors, matrices
    and arrays: automatic propagation, conversion, derivation
    and simplification of units; raising errors in case of unit
    incompatibility. Compatible with the POSIXct, Date and difftime 
    classes. Uses the UNIDATA udunits library and unit database for 
    unit compatibility checking and conversion.
    Documentation about 'units' is provided in the paper by Pebesma, Mailund &
    Hiebert (2016, <doi:10.32614/RJ-2016-061>), included in this package as a
    vignette; see 'citation(""units"")' for details.",2022-02-05,Edzer Pebesma,https://github.com/r-quantities/units/,TRUE,https://github.com/r-quantities/units,17869782,140,2022-05-22T13:50:11Z,127641.3
unittest,"
    Concise TAP <http://testanything.org/> compliant unit testing package. Authored tests can be run using CMD check with minimal implementation overhead.",2019-11-21,Jamie Lentin,NA,TRUE,https://github.com/ravingmantis/unittest,17792,3,2021-12-07T10:45:37Z,5930.666666666667
univariateML,"User-friendly maximum likelihood estimation (Fisher (1921) 
    <doi:10.1098/rsta.1922.0009>) of univariate densities.",2022-01-25,Jonas Moss,"https://github.com/JonasMoss/univariateML,
https://jonasmoss.github.io/univariateML/",TRUE,https://github.com/jonasmoss/univariateml,72523,7,2022-01-25T13:29:50Z,10360.42857142857
universals,"Provides S3 generic methods and some default implementations
    for Bayesian analyses that generate Markov Chain Monte Carlo (MCMC) samples.
    The purpose of 'universals' is to reduce package dependencies and conflicts.
    The 'nlist' package implements many of the methods for its 'nlist' class.",2020-09-24,Joe Thorley,"https://poissonconsulting.github.io/universals,
https://github.com/poissonconsulting/universals",TRUE,https://github.com/poissonconsulting/universals,25704,4,2022-06-17T21:41:05Z,6426
univOutl,"Well known outlier detection techniques in the univariate case. Methods to deal with skewed distribution are included too. The Hidiroglou-Berthelot (1986) method to search for outliers in ratios of historical data is implemented as well. When available, survey weights can be used in outliers detection.",2022-05-31,Marcello DOrazio,https://github.com/marcellodo/univOutl,TRUE,https://github.com/marcellodo/univoutl,48653,1,2022-06-21T08:59:40Z,48653
unix,"Bindings to system utilities found in most Unix systems such as
    POSIX functions which are not part of the Standard C Library.",2021-11-16,Jeroen Ooms,https://github.com/jeroen/unix,TRUE,https://github.com/jeroen/unix,29627,20,2021-11-15T22:12:25Z,1481.35
unnest,"Fast flattening of hierarchical data structures (e.g. JSON, XML)
             into data.frames with a flexible spec language.",2021-09-23,Vitalie Spinu,https://github.com/vspinu/unnest,TRUE,https://github.com/vspinu/unnest,7924,8,2021-09-22T16:49:42Z,990.5
unpivotr,"Tools for converting data from complex or irregular layouts to a
    columnar structure.  For example, tables with multilevel column or row
    headers, or spreadsheets.  Header and data cells are selected by their
    contents and position, as well as formatting and comments where available,
    and are associated with one other by their proximity in given directions.
    Functions for data frames and HTML tables are provided.",2021-08-22,Duncan Garmonsway,https://github.com/nacnudus/unpivotr,TRUE,https://github.com/nacnudus/unpivotr,26811,157,2022-05-15T21:06:43Z,170.77070063694268
unrtf,"Wraps the 'unrtf' utility to extract text from RTF files. Supports
    document conversion to HTML, LaTeX or plain text. Output in HTML is recommended
    because 'unrtf' has limited support for converting between character encodings.",2021-12-09,Jeroen Ooms,"https://docs.ropensci.org/unrtf/,
https://github.com/ropensci/unrtf (devel)
https://www.gnu.org/software/unrtf/ (upstream)",TRUE,https://github.com/ropensci/unrtf,17489,13,2022-05-02T20:48:44Z,1345.3076923076924
untb,Hubbell's Unified Neutral Theory of Biodiversity.,2019-03-03,Robin K. S. Hankin,https://github.com/RobinHankin/untb.git,TRUE,https://github.com/robinhankin/untb,25036,1,2022-06-05T08:49:55Z,25036
unusualprofile,"Calculates a Mahalanobis distance for every row of a set of outcome variables (Mahalanobis, 1936 <doi:10.1007/s13171-019-00164-5>). The conditional Mahalanobis distance is calculated using a conditional covariance matrix (i.e., a covariance matrix of the outcome variables after controlling for a set of predictors). Plotting the output of the cond_maha() function can help identify which elements of a profile are unusual after controlling for the predictors.",2021-05-13,W. Joel Schneider,https://github.com/wjschne/unusualprofile,TRUE,https://github.com/wjschne/unusualprofile,3898,2,2022-03-28T03:07:15Z,1949
updog,"Implements empirical Bayes approaches to genotype
       polyploids from next generation sequencing data while
       accounting for allele bias, overdispersion, and sequencing
       error. The main functions are flexdog() and multidog(), 
       which allow the specification
       of many different genotype distributions. Also provided are functions to
       simulate genotypes, rgeno(), and read-counts, rflexdog(), as well as
       functions to calculate oracle genotyping error rates, oracle_mis(), and
       correlation with the true genotypes, oracle_cor(). These latter two
       functions are useful for read depth calculations. Run
       browseVignettes(package = ""updog"") in R for example usage. See
       Gerard et al. (2018) <doi:10.1534/genetics.118.301468> and
       Gerard and Ferrao (2020) <doi:10.1093/bioinformatics/btz852> for details 
       on the implemented methods.",2022-01-24,David Gerard,https://github.com/dcgerard/updog/,TRUE,https://github.com/dcgerard/updog,16579,13,2022-03-29T18:28:54Z,1275.3076923076924
upsetjs,"'UpSet.js' is a re-implementation of 'UpSetR' to create interactive set visualizations for more than three sets.
  This is a 'htmlwidget' wrapper around the 'JavaScript' library 'UpSet.js'.",2022-05-11,Samuel Gratzl,https://github.com/upsetjs/upsetjs_r/,TRUE,https://github.com/upsetjs/upsetjs_r,10399,32,2022-07-07T12:34:34Z,324.96875
UpSetVP,"Using matrix layout to visualize the unique, common, or individual contribution of each predictor (or matrix of predictors) towards explained variation on canonical analysis. These contributions were derived from variance partitioning analysis (VPA) and hierarchical partitioning (HP), applying the algorithm of Lai J., Zou Y., Zhang J., Peres-Neto P. (2022) Generalizing hierarchical and variation partitioning in multiple regression and canonical analyses using the rdacca.hp R package.Methods in Ecology and Evolution, 13: 782-788 <doi:10.1111/2041-210X.13800>.",2022-05-03,Yao Liu,https://github.com/LiuXYh/UpSetVP,TRUE,https://github.com/liuxyh/upsetvp,473,5,2022-05-10T12:16:57Z,94.6
UPSvarApprox,"Variance approximations for the 
    Horvitz-Thompson total estimator in Unequal Probability Sampling
    using only first-order inclusion probabilities. 
    See Matei and Tillé (2005) and Haziza, Mecatti and Rao (2008) for details.",2022-06-12,Roberto Sichera,NA,TRUE,https://github.com/rhobis/upsvarapprox,15485,0,2022-06-12T06:23:38Z,NA
urlchecker,"Provide the URL checking tools available in R 4.1+ as a
    package for earlier versions of R. Also uses concurrent requests so
    can be much faster than the serial versions.",2021-11-30,R Core team,https://github.com/r-lib/urlchecker,TRUE,https://github.com/r-lib/urlchecker,8959,42,2022-03-15T14:11:45Z,213.3095238095238
ursa,"S3 classes and methods for manipulation with georeferenced raster data: reading/writing, processing, multi-panel visualization. SWU.",2022-03-08,Nikita Platonov,https://github.com/nplatonov/ursa,TRUE,https://github.com/nplatonov/ursa,15656,6,2022-06-29T14:33:00Z,2609.3333333333335
USAboundaries,"The boundaries for geographical units in the United States of
    America contained in this package include state, county, congressional
    district, and zip code tabulation area. Contemporary boundaries are provided
    by the U.S. Census Bureau (public domain). Historical boundaries for the
    years from 1629 to 2000 are provided form the Newberry Library's 'Atlas of
    Historical County Boundaries' (licensed CC BY-NC-SA). Additional  data is
    provided in the 'USAboundariesData' package; this package provides an
    interface to access that data.",2021-10-12,Lincoln Mullen,"http://lincolnmullen.com/software/usaboundaries/,
https://github.com/ropensci/USAboundaries",TRUE,https://github.com/ropensci/usaboundaries,33859,50,2021-10-12T14:59:19Z,677.18
usdata,Demographic data on the United States at the county and state levels spanning multiple years.,2021-06-21,Mine Çetinkaya-Rundel,https://github.com/OpenIntroStat/usdata,TRUE,https://github.com/openintrostat/usdata,132635,3,2021-12-15T04:30:12Z,44211.666666666664
usemodels,"Code snippets to fit models using the tidymodels framework
    can be easily created for a given data set.",2022-02-18,Max Kuhn,"https://usemodels.tidymodels.org/,
https://github.com/tidymodels/usemodels",TRUE,https://github.com/tidymodels/usemodels,13727,78,2022-04-28T16:51:24Z,175.98717948717947
usethat,"Automate analytic project setup tasks that are otherwise performed 
    manually. This includes setting up docker, spinning up a microservice, and 
    more.",2021-09-20,Harel Lustiger,"https://tidylab.github.io/usethat/,
https://github.com/tidylab/usethat",TRUE,https://github.com/tidylab/usethat,3407,10,2021-09-20T10:19:44Z,340.7
usethis,"Automate package and project setup tasks that are
    otherwise performed manually. This includes setting up unit testing,
    test coverage, continuous integration, Git, 'GitHub', licenses,
    'Rcpp', 'RStudio' projects, and more.",2022-05-25,Hadley Wickham,"https://usethis.r-lib.org, https://github.com/r-lib/usethis",TRUE,https://github.com/r-lib/usethis,19006433,705,2022-06-14T18:18:46Z,26959.479432624114
usincometaxes,"Calculates federal and state income taxes in the United States. It acts as a wrapper 
    to the NBER's TAXSIM 35 (<http://taxsim.nber.org/taxsim35/>) tax simulator. TAXSIM 35 conducts 
    the calculations, while 'usincometaxes' prepares the data for TAXSIM 35, sends the data to 
    TAXSIM 35's server or communicates with the Web Assembly file, retrieves the data, and places it 
    into a data frame. All without the user worrying about this process.",2022-07-08,Shane Orr,"https://github.com/shanejorr/usincometaxes,
https://shaneorr.io/r/usincometaxes",TRUE,https://github.com/shanejorr/usincometaxes,338,7,2022-07-09T23:24:21Z,48.285714285714285
usl,"The Universal Scalability Law (Gunther 2007)
    <doi:10.1007/978-3-540-31010-5> is a model to predict hardware and
    software scalability. It uses system capacity as a function of load to
    forecast the scalability for the system.",2020-03-02,Stefan Moeding,NA,TRUE,https://github.com/smoeding/usl,16962,33,2021-07-18T10:45:54Z,514
usmap,"Obtain United States map data frames of varying region types (e.g. county, 
    state). The map data frames include Alaska and Hawaii conveniently placed to the
    bottom left, as they appear in most maps of the US. Convenience functions for plotting
    choropleths and working with FIPS codes are also provided.",2022-02-27,Paolo Di Lorenzo,https://usmap.dev,TRUE,https://github.com/pdil/usmap,120917,51,2022-02-27T17:19:12Z,2370.921568627451
usmapdata,"Provides a container for data used by the 'usmap' package.
    The data used by 'usmap' has been extracted into this package so that the
    file size of the 'usmap' package can be reduced greatly. The data in this
    package will be updated roughly once per year (plus bug fixes) as new
    shape files are provided by the US Census bureau.",2022-02-09,Paolo Di Lorenzo,https://usmap.dev,TRUE,https://github.com/pdil/usmapdata,17141,2,2022-04-09T16:56:41Z,8570.5
USpopcenters,"Centers of population (centroid) data for census areas in the
    United States.",2021-11-09,Nik Krieger,"https://www.census.gov/geographies/reference-files/time-series/geo/centers-population.html,
https://github.com/NikKrieger/USpopcenters",TRUE,https://github.com/nikkrieger/uspopcenters,3083,0,2021-11-09T17:15:00Z,NA
ustfd,Make requests from the US Treasury Fiscal Data API endpoints.,2022-04-18,Guillermo Roditi Dominguez,https://github.com/groditi/ustfd,TRUE,https://github.com/groditi/ustfd,610,0,2022-04-18T00:58:45Z,NA
utf8,"Process and print 'UTF-8' encoded international
    text (Unicode). Input, validate, normalize, encode, format, and
    display.",2021-07-24,Kirill Müller,"https://ptrckprry.com/r-utf8/, https://github.com/patperry/r-utf8",TRUE,https://github.com/patperry/r-utf8,22420317,106,2022-05-14T00:31:36Z,211512.4245283019
utile.tables,A collection of functions to make building customized ready-to-export tables for publication purposes easier and creating summaries of large datasets for review a breeze.,2020-06-14,Eric Finnesgard,https://github.com/efinite/utile.tables,TRUE,https://github.com/efinite/utile.tables,12778,1,2022-04-09T14:27:53Z,12778
utile.tools,"A set of tools for preparing and summarizing data for publication purposes. Includes functions for tabulating models, means to produce human-readable summary statistics from raw data, macros for calculating duration of time, and simplistic hypothesis testing tools.",2022-02-20,Eric Finnesgard,https://github.com/efinite/utile.tools,TRUE,https://github.com/efinite/utile.tools,14555,1,2022-02-20T21:19:18Z,14555
utile.visuals,A small set of functions to aid in the production of visuals in ggplot2. Includes minimalist themes with transparent backgrounds and tools for building survival curves with risk tables.,2022-02-14,Eric Finnesgard,https://github.com/efinite/utile.visuals,TRUE,https://github.com/efinite/utile.visuals,13892,2,2022-02-14T17:10:44Z,6946
utilities,"Data utility functions for use in probability and statistics.  Includes functions for computing higher-moments for samples and their decompositions.
  Also includes utilities to examine functional mappings between factor variables and other variables in a data set.",2022-07-01,Ben ONeill,https://github.com/ben-oneill/utilities/,TRUE,https://github.com/ben-oneill/utilities,8936,2,2022-07-01T00:41:17Z,4468
uuid,Tools for generating and handling of UUIDs (Universally Unique Identifiers).,2022-04-19,Simon Urbanek,https://www.rforge.net/uuid,TRUE,https://github.com/s-u/uuid,11197273,15,2022-04-19T03:55:17Z,746484.8666666667
uwot,"An implementation of the Uniform Manifold Approximation and 
    Projection dimensionality reduction by McInnes et al. (2018) 
    <arXiv:1802.03426>. It also provides means to transform new data and to 
    carry out supervised dimensionality reduction. An implementation of the 
    related LargeVis method of Tang et al. (2016) <arXiv:1602.00370> is also 
    provided. This is a complete re-implementation in R (and C++, via the 'Rcpp'
    package): no Python installation is required. See the uwot website 
    (<https://github.com/jlmelville/uwot>) for more documentation and examples.",2021-12-02,James Melville,https://github.com/jlmelville/uwot,TRUE,https://github.com/jlmelville/uwot,470008,269,2022-05-08T22:05:26Z,1747.2416356877322
V8,"An R interface to V8: Google's open source JavaScript and WebAssembly 
    engine. This package can be compiled either with V8 version 6 and up or NodeJS
    when built as a shared library.",2022-05-14,Jeroen Ooms,https://github.com/jeroen/v8 (devel) https://v8.dev (upstream),TRUE,https://github.com/jeroen/v8,8445136,178,2022-05-14T17:23:44Z,47444.58426966292
valhallr,"An interface to the 'Valhalla' routing engine’s
    application programming interfaces (APIs) for turn-by-turn routing,
    isochrones, and origin-destination analyses. Also includes several
    user-friendly functions for plotting outputs, and strives to follow
    ""tidy"" design principles. Please note that this package requires
    access to a running instance of 'Valhalla', which is open source and
    can be downloaded from <https://github.com/valhalla/valhalla>.",2021-03-09,Christopher Belanger,https://github.com/chris31415926535/valhallr,TRUE,https://github.com/chris31415926535/valhallr,4935,9,2022-01-25T15:54:23Z,548.3333333333334
validata,Functions for validating the structure and properties of data frames. Answers essential questions about a data set after initial import or modification. What are the unique or missing values? What columns form a primary key? What are the properties of the numeric or categorical columns? What kind of overlap or mapping exists between 2 columns?,2021-10-05,Harrison Tietze,"https://harrison4192.github.io/validata/,
https://github.com/Harrison4192/validata",TRUE,https://github.com/harrison4192/validata,2960,6,2022-04-25T16:51:02Z,493.3333333333333
validate,"Declare data validation rules and data quality indicators;
        confront data with them and analyze or visualize the results.
        The package supports rules that are per-field, in-record,
        cross-record or cross-dataset. Rules can be automatically
        analyzed for rule type and connectivity. Supports checks implied
        by an SDMX DSD file as well. See also Van der Loo
        and De Jonge (2018) <doi:10.1002/9781118897126>, Chapter 6
        and the JSS paper (2021) <doi:10.18637/jss.v097.i10>.",2022-03-24,Mark van der Loo,https://github.com/data-cleaning/validate,TRUE,https://github.com/data-cleaning/validate,112110,341,2022-06-15T13:45:37Z,328.7683284457478
validatedb,"Check whether records in a database table are valid using 
   validation rules in R syntax specified with R package 'validate'. 
   R validation checks are automatically translated to SQL using 'dbplyr'.",2021-10-06,Edwin de Jonge,https://github.com/data-cleaning/validatedb,TRUE,https://github.com/data-cleaning/validatedb,4252,16,2022-06-03T14:09:02Z,265.75
valr,"Read and manipulate genome intervals and signals. Provides
    functionality similar to command-line tool suites within R, enabling
    interactive analysis and visualization of genome-scale data.  Riemondy
    et al. (2017) <doi:10.12688/f1000research.11997.1>.",2021-12-08,Jay Hesselberth,"https://github.com/rnabioco/valr/,
https://rnabioco.github.io/valr/",TRUE,https://github.com/rnabioco/valr,20877,74,2022-07-10T12:17:29Z,282.1216216216216
valuemap,"
    You can easily visualize your 'sf' polygons or data.frame with h3 address.
    While 'leaflet' package is too raw for data analysis, 
    this package can save data analysts' efforts & time with pre-set visualize options.",2022-03-09,Heoncheol Ha,https://github.com/Curycu/valuemap,TRUE,https://github.com/curycu/valuemap,998,2,2022-03-10T08:41:13Z,499
VancouvR,"Wrapper around the 'City of Vancouver' Open Data API <https://opendata.vancouver.ca/api/v2/console> to simplify and standardize access to 'City of Vancouver' open data. 
  Functionality to list the data catalogue and access data and geographic records.",2021-10-21,Jens von Bergmann,"https://github.com/mountainMath/VancouvR,
https://mountainmath.github.io/VancouvR/",TRUE,https://github.com/mountainmath/vancouvr,13478,17,2021-10-21T03:56:39Z,792.8235294117648
vangogh,Palettes generated from Vincent van Gogh's paintings.,2022-05-27,Cheryl Isabella,https://github.com/cherylisabella/vangogh,TRUE,https://github.com/cherylisabella/vangogh,310,0,2022-05-28T10:00:51Z,NA
vapour,"Provides low-level access to 'GDAL' functionality for R packages.  
  'GDAL' is the 'Geospatial Data Abstraction Library' a translator for raster and vector geospatial data formats 
  that presents a single raster abstract data model and single vector abstract data model to the calling application 
  for all supported formats <https://gdal.org/>. ",2021-10-07,Michael Sumner,https://github.com/hypertidy/vapour,TRUE,https://github.com/hypertidy/vapour,17351,64,2022-07-04T06:28:03Z,271.109375
varbvs,"Fast algorithms for fitting Bayesian variable selection
    models and computing Bayes factors, in which the outcome (or
    response variable) is modeled using a linear regression or a
    logistic regression. The algorithms are based on the variational
    approximations described in ""Scalable variational inference for
    Bayesian variable selection in regression, and its accuracy in
    genetic association studies"" (P. Carbonetto & M. Stephens, 2012,
    <DOI:10.1214/12-BA703>). This software has been applied to large
    data sets with over a million variables and thousands of samples.",2019-03-07,Peter Carbonetto,http://github.com/pcarbo/varbvs,TRUE,https://github.com/pcarbo/varbvs,16416,38,2022-05-13T14:23:31Z,432
vardpoor,"Generation of domain variables, linearization of several non-linear population statistics (the ratio of two totals, weighted income percentile, relative median income ratio, at-risk-of-poverty rate, at-risk-of-poverty threshold, Gini coefficient, gender pay gap, the aggregate replacement ratio, the relative median income ratio, median income below at-risk-of-poverty gap, income quintile share ratio, relative median at-risk-of-poverty gap), computation of regression residuals in case of weight calibration, variance estimation of sample surveys by the ultimate cluster method (Hansen, Hurwitz and Madow, Sample Survey Methods And Theory, vol. I: Methods and Applications; vol. II: Theory. 1953, New York: John Wiley and Sons), variance estimation for longitudinal, cross-sectional measures and measures of change for single and multistage stage cluster sampling designs (Berger, Y. G., 2015, <doi:10.1111/rssa.12116>). Several other precision measures are derived - standard error, the coefficient of variation, the margin of error, confidence interval, design effect.",2020-11-30,Martins Liberts,"https://csblatvia.github.io/vardpoor/,
https://github.com/CSBLatvia/vardpoor/",TRUE,https://github.com/csblatvia/vardpoor,30438,10,2022-02-17T14:50:27Z,3043.8
VariantScan,"Portable, scalable and highly computationally efficient tool for genetic association studies.""VariantScan"" provides a set of machine learning methods (Linear, Local Polynomial Regression Fitting and Generalized Additive Model with Local Polynomial Smoothing) 
             for genetic association studies that test for disease or trait association with genetic variants 
             (biomarkers, e.g.,genomic (genetic loci), transcriptomic (gene expressions), epigenomic (methylations), proteomic (proteins), metabolomic (metabolites)).
             It is particularly useful when local associations and complex nonlinear associations exist.",2022-06-30,Xinghu Qin,https://github.com/xinghuq/VariantScan,TRUE,https://github.com/xinghuq/variantscan,114,0,2022-06-27T01:23:24Z,NA
varTestnlme,"An implementation of the Likelihood ratio Test (LRT) for testing that,
    in a (non)linear mixed effects model, the variances of a subset of the random
    effects are equal to zero. There is no restriction on the subset of variances
    that can be tested: for example, it is possible to test that all the variances
    are equal to zero. Note that the implemented test is asymptotic.
    This package should be used on model fits from packages 'nlme', 'lmer', and 'saemix'.
    Charlotte Baey, Paul-Henry Cournède and Estelle Kuhn (2019) <doi:10.1016/j.csda.2019.01.014>.",2022-03-08,Charlotte Baey,https://github.com/baeyc/varTestnlme/,TRUE,https://github.com/baeyc/vartestnlme,13566,1,2022-01-18T09:35:36Z,13566
varycoef,"Implements a maximum likelihood estimation (MLE)
    method for estimation and prediction of Gaussian process-based
    spatially varying coefficient (SVC) models 
    (Dambon et al. (2021a) <doi:10.1016/j.spasta.2020.100470>). 
    Covariance tapering (Furrer et al. (2006) <doi:10.1198/106186006X132178>) can 
    be applied such that the method scales to large data. Further, it implements
    a joint variable selection of the fixed and random effects (Dambon et al. 
    (2021b) <arXiv:2101.01932>). The package and its capabilities are described
    in (Dambon et al. (2021c) <arXiv:2106.02364>).",2022-05-31,Jakob A. Dambon,https://github.com/jakobdambon/varycoef,TRUE,https://github.com/jakobdambon/varycoef,15787,5,2022-06-29T20:39:26Z,3157.4
VC2copula,"Provides new classes for (rotated) BB1, BB6, BB7, BB8, and 
  Tawn copulas, extends the existing Gumbel and Clayton families with 
  rotations, and allows to set up a vine copula model using the 'copula' API.
  Corresponding objects from the 'VineCopula' API can easily be converted.",2022-01-10,Thomas Nagler,https://github.com/tnagler/VC2copula,TRUE,https://github.com/tnagler/vc2copula,13714,4,2022-01-10T16:20:22Z,3428.5
vcdExtra,"Provides additional data sets, methods and documentation to complement the 'vcd' package for Visualizing Categorical Data
    and the 'gnm' package for Generalized Nonlinear Models.
	In particular, 'vcdExtra' extends mosaic, assoc and sieve plots from 'vcd' to handle 'glm()' and 'gnm()' models and
	adds a 3D version in 'mosaic3d'.  Additionally, methods are provided for comparing and visualizing lists of
	'glm' and 'loglm' objects. This package is now a support package for the book, ""Discrete Data Analysis with R"" by
  Michael Friendly and David Meyer.",2022-04-21,Michael Friendly,https://friendly.github.io/vcdExtra/,TRUE,https://github.com/friendly/vcdextra,166331,15,2022-06-17T16:11:37Z,11088.733333333334
vcfR,"Facilitates easy manipulation of variant call format (VCF) data.
    Functions are provided to rapidly read from and write to VCF files. Once
    VCF data is read into R a parser function extracts matrices of data. This
    information can then be used for quality control or other purposes. Additional
    functions provide visualization of genomic data. Once processing is complete
    data may be written to a VCF file (*.vcf.gz). It also may be converted into
    other popular R objects (e.g., genlight, DNAbin). VcfR provides a link between
    VCF data and familiar R software.",2020-09-01,Brian J. Knaus,"https://github.com/knausb/vcfR,
https://knausb.github.io/vcfR_documentation/",TRUE,https://github.com/knausb/vcfr,107238,191,2022-04-15T19:20:14Z,561.4554973821989
vcmeta,"Implements functions for varying coefficient meta-analysis methods. 
  These methods do not assume effect size homogeneity. Subgroup effect size 
  comparisons, general linear effect size contrasts, and linear models of 
  effect sizes based on varying coefficient methods can be used to describe 
  effect size heterogeneity. Varying coefficient meta-analysis methods do not 
  require the unrealistic assumptions of the traditional fixed-effect and 
  random-effects meta-analysis methods.  
  For details see:  Statistical Methods for Psychologists, Volume 5, <https://dgbonett.sites.ucsc.edu/>.",2022-06-17,Douglas G. Bonett,https://github.com/dgbonett/vcmeta,TRUE,https://github.com/dgbonett/vcmeta,2805,0,2022-06-15T20:15:39Z,NA
vcr,"Record test suite 'HTTP' requests and replays them during
    future runs. A port of the Ruby gem of the same name
    (<https://github.com/vcr/vcr/>). Works by hooking into the 'webmockr'
    R package for matching 'HTTP' requests by various rules ('HTTP' method,
    'URL', query parameters, headers, body, etc.), and then caching
    real 'HTTP' responses on disk in 'cassettes'. Subsequent 'HTTP' requests
    matching any previous requests in the same 'cassette' use a cached
    'HTTP' response.",2021-05-31,Scott Chamberlain,"https://github.com/ropensci/vcr/ (devel)
https://books.ropensci.org/http-testing/ (user manual)",TRUE,https://github.com/ropensci/vcr,73765,67,2022-02-22T14:54:39Z,1100.9701492537313
vctrs,"Defines new notions of prototype and size that are
    used to provide tools for consistent and well-founded type-coercion
    and size-recycling, and are in turn connected to ideas of type- and
    size-stability useful for analysing function interfaces.",2022-04-13,Lionel Henry,https://vctrs.r-lib.org/,TRUE,https://github.com/r-lib/vctrs,47124110,237,2022-07-07T20:21:34Z,198835.9071729958
vdiffr,"An extension to the 'testthat' package that makes it easy
    to add graphical unit tests. It provides a Shiny application to
    manage the test cases.",2022-03-15,Lionel Henry,"https://vdiffr.r-lib.org/, https://github.com/r-lib/vdiffr",TRUE,https://github.com/r-lib/vdiffr,6182779,165,2022-03-15T10:28:27Z,37471.38787878788
vdra,"Implements linear, logistic, and Cox regression on vertically
    partitioned data across several data partners.  Data is not shared
    between data partners or the analysis center and the computations can
    be considered secure.  Three different protocols are implemented. 
	2-Party: two data partners which communicate directly without an 
	intermediate analysis center; 2T-Party: two data partners communicate 
	indirectly via an analysis center, and KT-Party: two or more 
	data partners plus an analysis center are all allowed to 
	communicate directly.  2-Party and 2^T-Party use a form of secure 
	multiplication as found in Karr, et. al. (2009) ""Privacy-Preserving Analysis
    of Vertically Partitioned Data Using Secure Matrix Products""
    and Slavkovic et. al. (2007) ""Secure Logistic Regression of Horizontally 
    and Vertically Partitioned Distributed Databases"" <doi:10.1109/ICDMW.2007.114>.  
    Full details can be found in Samizo (In preparation).   ",2021-09-09,Thomas Kent,NA,TRUE,https://github.com/kentedegrees/vdra,2908,1,2021-09-06T17:46:32Z,2908
vec2dtransf,Applies affine and similarity transformations on vector spatial data (sp objects). Transformations can be defined from control points or directly from parameters. If redundant control points are provided Least Squares is applied allowing to obtain residuals and RMSE.,2022-04-26,German Carrillo,https://github.com/gacarrillor/vec2dtransf,TRUE,https://github.com/gacarrillor/vec2dtransf,16560,3,2022-04-26T18:10:44Z,5520
vegan,"Ordination methods, diversity analysis and other
  functions for community and vegetation ecologists.",2022-04-17,Jari Oksanen,https://github.com/vegandevs/vegan,TRUE,https://github.com/vegandevs/vegan,1446877,315,2022-06-23T08:17:24Z,4593.260317460317
vegawidget,"'Vega' and 'Vega-Lite' parse text in 'JSON' notation to render 
  chart-specifications into 'HTML'. This package is used to facilitate the 
  rendering. It also provides a means to interact with signals, events,
  and datasets in a 'Vega' chart using 'JavaScript' or 'Shiny'.",2022-01-29,Ian Lyttle,https://vegawidget.github.io/vegawidget/,TRUE,https://github.com/vegawidget/vegawidget,46594,60,2022-01-29T21:05:30Z,776.5666666666667
vegperiod,"Collection of common methods to determine growing season length in
  a simple manner. Start and end dates of the vegetation periods are calculated
  solely based on daily mean temperatures and the day of the year.",2021-02-02,Robert Nuske,https://github.com/rnuske/vegperiod,TRUE,https://github.com/rnuske/vegperiod,13678,3,2022-06-21T14:50:47Z,4559.333333333333
vegtable,"Import and handling data from vegetation-plot databases, especially
    data stored in 'Turboveg 2' (<https://www.synbiosys.alterra.nl/turboveg/>).
    Also import/export routines for exchange of data with 'Juice'
    (<https://www.sci.muni.cz/botany/juice/>) are implemented.",2021-10-13,Miguel Alvarez,https://github.com/kamapu/vegtable,TRUE,https://github.com/kamapu/vegtable,15077,3,2022-06-21T11:24:58Z,5025.666666666667
vein,"Elaboration of vehicular emissions inventories,
    consisting in four stages, pre-processing activity data, preparing 
    emissions factors, estimating the emissions and post-processing of emissions 
    in maps and databases. More details in Ibarra-Espinosa et al (2018) <doi:10.5194/gmd-11-2209-2018>.
    Before using VEIN you need to know the vehicular composition of your study area, in other words,
    the combination of of type of vehicles, size and fuel of the fleet. Then, it is recommended to
    start with the project to download a template to create a structure of directories and scripts.",2022-05-13,Sergio Ibarra-Espinosa,https://github.com/atmoschem/vein,TRUE,https://github.com/atmoschem/vein,22676,33,2022-05-17T20:01:26Z,687.1515151515151
vembedr,"A set of functions for generating HTML to
    embed hosted video in your R Markdown documents or Shiny applications.",2021-12-11,Ian Lyttle,https://github.com/ijlyttle/vembedr,TRUE,https://github.com/ijlyttle/vembedr,100746,55,2021-12-11T21:45:16Z,1831.7454545454545
venn,"Draws and displays Venn diagrams up to 7 sets, and any Boolean union of set intersections.",2022-06-08,Adrian Dusa,https://github.com/dusadrian/venn,TRUE,https://github.com/dusadrian/venn,68069,12,2022-06-08T21:14:03Z,5672.416666666667
verbalisr,"Describe in words the genealogical relationship between two
    members of a given pedigree. 'verbalisr' is part of the 'ped suite'
    collection of packages for pedigree analysis. For a demonstration of
    'verbalisr', see the online app 'QuickPed' at
    <https://magnusdv.shinyapps.io/quickped>.",2021-12-08,Magnus Dehli Vigeland,"https://github.com/magnusdv/verbalisr,
https://magnusdv.github.io/pedsuite/",TRUE,https://github.com/magnusdv/verbalisr,2450,1,2022-06-09T20:36:44Z,2450
vetiver,"The goal of 'vetiver' is to provide fluent tooling to
    version, share, deploy, and monitor a trained model. Functions handle
    both recording and checking the model's input data prototype, and
    predicting from a remote API endpoint. The 'vetiver' package is
    extensible, with generics that can support many kinds of models.",2022-07-06,Julia Silge,"https://vetiver.rstudio.com, https://rstudio.github.io/vetiver-r/,
https://github.com/rstudio/vetiver-r/",TRUE,https://github.com/rstudio/vetiver-r,3912,114,2022-07-08T19:41:23Z,34.31578947368421
vetr,"Declarative template-based framework for verifying that objects
  meet structural requirements, and auto-composing error messages when they do
  not.",2022-07-07,Brodie Gaslam,https://github.com/brodieG/vetr,TRUE,https://github.com/brodieg/vetr,18675,64,2022-07-08T00:40:36Z,291.796875
VFS,"Empirical models for runoff, erosion, and phosphorus loss 
    across a vegetated filter strip, given slope, soils, climate, and 
    vegetation (Gall et al., 2018) <doi:10.1007/s00477-017-1505-x>. 
    It also includes functions for deriving climate parameters from 
    measured daily weather data, and for simulating rainfall. Models 
    implemented include MUSLE (Williams, 1975) and APLE (Vadas et al., 
    2009 <doi:10.2134/jeq2008.0337>).",2018-10-12,Sarah Goslee,NA,TRUE,https://github.com/sgoslee/vfs,10419,1,2022-05-23T19:13:43Z,10419
VIC5,"The Variable Infiltration Capacity (VIC) model is a macroscale
    hydrologic model that solves full water and energy balances, originally
    developed by Xu Liang at the University of Washington (UW).
    The version of VIC source code used is of 5.0.1 on <https://github.com/UW-Hydro/VIC/>,
    see Hamman et al. (2018).
    Development and maintenance of the current official version
    of the VIC model at present is led by the UW Hydro (Computational Hydrology
    group) in the Department of Civil and Environmental Engineering at UW. VIC is
    a research model and in its various forms it has been applied to most of the
    major river basins around the world, as well as globally 
    <http://vic.readthedocs.io/en/master/Documentation/References/>. 
    References: ""Liang, X., D. P. Lettenmaier, E. F. Wood, and
    S. J. Burges (1994), A simple hydrologically based model of land surface water
    and energy fluxes for general circulation models, J. Geophys. Res., 99(D7),
    14415-14428, <doi:10.1029/94JD00483>""; 
    ""Hamman, J. J., Nijssen, B., Bohn, T. J., Gergel, D. R., and Mao, Y. (2018), The
    Variable Infiltration Capacity model version 5 (VIC-5): infrastructure improvements
    for new applications and reproducibility, Geosci. Model Dev., 11, 3481-3496, 
    <doi:10.5194/gmd-11-3481-2018>"".",2021-12-08,Dongdong Kong,https://github.com/rpkgs/VIC5,TRUE,https://github.com/rpkgs/vic5,3345,4,2021-12-09T09:01:33Z,836.25
vici,"A shiny app for accurate estimation of vaccine induced immunogenicity 
    with bivariate linear modeling. Method is detailed in: Lhomme, Hejblum, Lacabaratz, 
    Wiedemann, Lelievre, Levy, Thiebaut & Richert (2020). Journal of Immunological Methods, 
    477:112711. <doi:10.1016/j.jim.2019.112711>.",2022-06-27,Boris Hejblum,NA,TRUE,https://github.com/sistm/vici,10334,0,2022-06-14T09:18:27Z,NA
VicmapR,"Easily interfaces R to spatial datasets available through 
  the Victorian Government's WFS (Web Feature Service): <https://services.land.vic.gov.au/catalogue/publicproxy/guest/dv_geoserver/wfs?request=getCapabilities>, 
  which allows users to read in 'sf' data from these sources. VicmapR uses the lazy querying approach and code developed by Teucher et al. (2021) for the 'bcdata' R package <doi:10.21105/joss.02927>.",2022-06-10,Justin Cally,"https://justincally.github.io/VicmapR/,
https://mapshare.vic.gov.au/vicplan/,
https://github.com/justincally/VicmapR/",TRUE,https://github.com/justincally/vicmapr,4931,14,2022-06-13T22:55:41Z,352.2142857142857
vietnameseConverter,"Conversion of characters from unsupported Vietnamese character encodings to Unicode characters. These Vietnamese encodings (TCVN3, VISCII, VPS) are not natively supported in R and lead to printing of wrong characters and garbled text (mojibake). This package fixes that problem and provides readable output with the correct Unicode characters (with or without diacritics). ",2021-10-20,Juergen Niedballa,https://github.com/jniedballa/vietnameseConverter,TRUE,https://github.com/jniedballa/vietnameseconverter,3011,0,2021-12-02T10:19:14Z,NA
viewpoly,"Provides a graphical user interface to integrate, visualize and explore results 
            from linkage and quantitative trait loci analysis, together with genomic information for autopolyploid 
            species. The app is meant for interactive use and allows users to optionally upload different sources 
            of information, including  gene annotation and alignment files, enabling the exploitation and search for 
            candidate genes in a genome browser. In its current version, 'VIEWpoly' supports inputs from 'MAPpoly', 
            'polymapR', 'diaQTL', 'QTLpoly' and 'polyqtlR' packages. ",2022-06-07,Cristiane Taniguti,https://github.com/mmollina/viewpoly,TRUE,https://github.com/mmollina/viewpoly,2005,0,2022-06-10T01:26:56Z,NA
villager,"This is a package for creating and running Agent Based Models (ABM). It provides a set of base classes with core functionality to allow bootstrapped models. For more intensive modeling, the supplied classes can be extended to fit researcher needs.",2022-04-15,Thomas Thelen,https://github.com/zizroc/villager/,TRUE,https://github.com/zizroc/villager,679,41,2022-05-03T01:52:55Z,16.5609756097561
VIM,"New tools for the visualization of missing and/or imputed values
    are introduced, which can be used for exploring the data and the structure of
    the missing and/or imputed values. Depending on this structure of the missing
    values, the corresponding methods may help to identify the mechanism generating
    the missing values and allows to explore the data including missing values.
    In addition, the quality of imputation can be visually explored using various
    univariate, bivariate, multiple and multivariate plot methods. A graphical user
    interface available in the separate package VIMGUI allows an easy handling of
    the implemented plot methods.",2021-07-22,Matthias Templ,https://github.com/statistikat/VIM,TRUE,https://github.com/statistikat/vim,674985,64,2022-04-22T09:03:20Z,10546.640625
vimp,"Calculate point estimates of and valid confidence intervals for
    nonparametric, algorithm-agnostic variable importance measures in high and low dimensions,
    using flexible estimators of the underlying regression functions. For more information
    about the methods, please see Williamson et al. (Biometrics, 2020),  Williamson et al. (arXiv, 2020+) <arXiv:2004.03683>, and Williamson and Feng (ICML, 2020).",2021-08-16,Brian D. Williamson,"https://bdwilliamson.github.io/vimp/,
https://github.com/bdwilliamson/vimp",TRUE,https://github.com/bdwilliamson/vimp,19409,15,2022-03-31T20:32:04Z,1293.9333333333334
VineCopula,"Provides tools for the statistical analysis of regular vine copula 
    models, see Aas et al. (2009) <doi:10.1016/j.insmatheco.2007.02.001> and 
    Dissman et al. (2013) <doi:10.1016/j.csda.2012.08.010>.
    The package includes tools for parameter estimation, model selection,
    simulation, goodness-of-fit tests, and visualization. Tools for estimation,
    selection and exploratory data analysis of bivariate copula models are also
    provided.",2022-05-24,Thomas Nagler,https://github.com/tnagler/VineCopula,TRUE,https://github.com/tnagler/vinecopula,108284,48,2022-05-24T14:34:31Z,2255.9166666666665
vinereg,"
  Implements D-vine quantile regression models with
  parametric or nonparametric pair-copulas. See 
  Kraus and Czado (2017) <doi:10.1016/j.csda.2016.12.009> and
  Schallhorn et al. (2017) <arXiv:1705.08310>.",2022-03-23,Thomas Nagler,https://tnagler.github.io/vinereg/,TRUE,https://github.com/tnagler/vinereg,15662,4,2022-03-19T15:37:41Z,3915.5
vioplot,A violin plot is a combination of a box plot and a kernel density plot. This package allows extensive customisation of violin plots. ,2021-07-27,S. Thomas Kelly,https://github.com/TomKellyGenetics/vioplot,TRUE,https://github.com/tomkellygenetics/vioplot,260780,25,2022-05-25T05:01:18Z,10431.2
vip,"A general framework for constructing variable importance plots from 
  various types of machine learning models in R. Aside from some standard model-
  specific variable importance measures, this package also provides model-
  agnostic approaches that can be applied to any supervised learning algorithm.
  These include 1) an efficient permutation-based variable importance measure, 
  2) variable importance based on Shapley values (Strumbelj and Kononenko, 
  2014) <doi:10.1007/s10115-013-0679-x>, and 3) the variance-based 
  approach described in Greenwell et al. (2018) <arXiv:1805.04755>. A 
  variance-based method for quantifying the relative strength of interaction 
  effects is also included (see the previous reference for details).",2020-12-17,Brandon Greenwell,https://github.com/koalaverse/vip/,TRUE,https://github.com/koalaverse/vip,215078,165,2021-09-22T02:58:55Z,1303.5030303030303
viridis,"Color maps designed to improve graph readability for readers with 
    common forms of color blindness and/or color vision deficiency. The color 
    maps are also perceptually-uniform, both in regular form and also when 
    converted to black-and-white for printing. This package also contains 
    'ggplot2' bindings for discrete and continuous color and fill scales. A lean
    version of the package called 'viridisLite' that does not include the 
    'ggplot2' bindings can be found at 
    <https://cran.r-project.org/package=viridisLite>.",2021-10-13,Simon Garnier,"https://sjmgarnier.github.io/viridis/,
https://github.com/sjmgarnier/viridis/",TRUE,https://github.com/sjmgarnier/viridis,10993217,251,2021-10-13T12:01:45Z,43797.677290836655
virtualPollen,"Tools to generate virtual environmental drivers with a given temporal autocorrelation, and to simulate pollen curves at annual resolution over millennial time-scales based on these drivers and virtual taxa with different life traits and niche features. It also provides the means to simulate quasi-realistic pollen-data conditions by applying simulated accumulation rates and given depth intervals between consecutive samples.",2022-02-13,Blas M. Benito,https://github.com/BlasBenito/virtualPollen,TRUE,https://github.com/blasbenito/virtualpollen,10688,1,2022-02-11T17:46:27Z,10688
VirtualPop,"Generates lifespans and fertility histories in continuous time using individual-level state transition (multi-state) models and data from the Human Mortality Database and the Human Fertility Database. To facilitate virtual population analysis, data on virtual individuals are stored in a data structure commonly used in sample surveys. Life histories are generated for multiple generations. The genealogies that result facilitate the study of family ties. ",2022-06-23,Frans Willekens,NA,TRUE,https://github.com/willekens/virtualpop,168,2,2022-07-08T07:45:07Z,84
virtuoso,"Provides users with a simple and convenient
             mechanism to manage and query a 'Virtuoso' database using the 'DBI' (Data-Base Interface)
             compatible 'ODBC' (Open Database Connectivity) interface.
             'Virtuoso' is a high-performance ""universal server,"" which can act
             as both a relational database, supporting standard Structured Query
             Language ('SQL') queries, while also supporting data following the
             Resource Description Framework ('RDF') model for Linked Data.
             'RDF' data can be queried using 'SPARQL' ('SPARQL' Protocol and 'RDF' Query Language)
             queries, a graph-based query that supports semantic reasoning.
             This allows users to leverage the performance of local or remote 'Virtuoso' servers using
             popular 'R' packages such as 'DBI' and 'dplyr', while also providing a 
             high-performance solution for working with large 'RDF' 'triplestores' from 'R.'
             The package also provides helper routines to install, launch, and manage
             a 'Virtuoso' server locally on 'Mac', 'Windows' and 'Linux' platforms using
             the standard interactive installers from the 'R' command-line.  By 
             automatically handling these setup steps, the package can make using 'Virtuoso'
             considerably faster and easier for a most users to deploy in a local
             environment. Managing the bulk import of triples
             from common serializations with a single intuitive command is another key
             feature of this package.  Bulk import performance can be tens to
             hundreds of times faster than the comparable imports using existing 'R' tools,
             including 'rdflib' and 'redland' packages.  ",2021-11-02,Carl Boettiger,https://github.com/ropensci/virtuoso,TRUE,https://github.com/ropensci/virtuoso,8101,8,2021-12-21T19:47:38Z,1012.625
virustotal,"Use VirusTotal, a Google service that analyzes files and URLs 
    for viruses, worms, trojans etc., provides category of the content hosted by a 
    domain from a variety of prominent services, provides passive DNS information,
    among other things. See <http://www.virustotal.com> for more information. ",2021-11-04,Gaurav Sood,https://github.com/themains/virustotal,TRUE,https://github.com/themains/virustotal,13784,11,2021-12-16T01:20:41Z,1253.090909090909
visae,Implementation of 'shiny' app to visualize adverse events based on the Common Terminology Criteria for Adverse Events (CTCAE) using stacked correspondence analysis as described in Diniz et. al (2021)<doi:10.1186/s12874-021-01368-w>.,2021-11-10,Marcio A. Diniz,NA,TRUE,https://github.com/dnzmarcio/visae,5627,1,2021-11-10T14:32:49Z,5627
viscomplexr,"Functionality for creating phase portraits of functions in the
    complex number plane. Works with R base graphics, whose full 
    functionality is available. Parallel processing is used for optimum 
    performance.",2021-09-18,Peter Biber,"https://peterbiber.github.io/viscomplexr/,
https://github.com/PeterBiber/viscomplexr/",TRUE,https://github.com/peterbiber/viscomplexr,5406,3,2021-09-18T16:50:56Z,1802
visdat,"Create preliminary exploratory data visualisations of an entire 
    dataset to identify problems or unexpected features using 'ggplot2'.",2019-02-15,Nicholas Tierney,"http://visdat.njtierney.com/, https://github.com/ropensci/visdat",TRUE,https://github.com/ropensci/visdat,673887,402,2022-06-29T11:28:05Z,1676.3358208955224
visNetwork,"Provides an R interface to the 'vis.js' JavaScript charting
    library. It allows an interactive visualization of networks.",2021-09-29,Almende B.V. and Contributors,http://datastorm-open.github.io/visNetwork/,TRUE,https://github.com/datastorm-open/visnetwork,1738655,468,2022-01-31T10:21:26Z,3715.074786324786
visR,"To enable fit-for-purpose, reusable clinical and medical
    research focused visualizations and tables with sensible defaults and
    based on graphical principles as described in: ""Vandemeulebroecke et
    al. (2018)"" <doi:10.1002/pst.1912>, ""Vandemeulebroecke et al. (2019)""
    <doi:10.1002/psp4.12455>, and ""Morris et al. (2019)""
    <doi:10.1136/bmjopen-2019-030215>.",2022-06-24,Mark Baillie,https://github.com/openpharma/visR,TRUE,https://github.com/openpharma/visr,5134,156,2022-06-28T12:52:26Z,32.91025641025641
vistime,"A library for creating time based charts, like Gantt or timelines. Possible outputs 
  include 'ggplot2' diagrams, 'plotly.js' graphs, 'Highcharts.js' widgets and data.frames. Results can be
  used in the 'RStudio' viewer pane, in 'RMarkdown' documents or in Shiny apps. In the 
  interactive outputs created by vistime() and hc_vistime(), you can interact with the 
  plot using mouse hover or zoom.",2021-04-10,Sandro Raabe,https://shosaco.github.io/vistime/,TRUE,https://github.com/shosaco/vistime,35598,133,2022-03-08T17:16:03Z,267.65413533834584
vistributions,"Visualize and compute percentiles/probabilities of normal, t, f, chi square 
    and binomial distributions.",2021-05-20,Aravind Hebbali,"https://github.com/rsquaredacademy/vistributions,
https://vistributions.rsquaredacademy.com",TRUE,https://github.com/rsquaredacademy/vistributions,20967,12,2021-07-16T10:57:44Z,1747.25
visxhclust,"A Shiny application and functions for visual exploration of hierarchical clustering with numeric datasets. Allows users to iterative set hyperparameters, select features and evaluate results through various plots and computation of evaluation criteria.",2021-10-19,Rafael Henkin,https://github.com/rhenkin/visxhclust,TRUE,https://github.com/rhenkin/visxhclust,2784,2,2022-02-07T08:50:36Z,1392
vitae,Provides templates and functions to simplify the production and maintenance of curriculum vitae.,2021-12-06,Mitchell OHara-Wild,"https://pkg.mitchelloharawild.com/vitae/,
https://github.com/mitchelloharawild/vitae",TRUE,https://github.com/mitchelloharawild/vitae,45215,880,2022-06-23T09:38:14Z,51.38068181818182
vizdraws,"Interactive visualization for Bayesian prior and posterior distributions. 
             When both distributions are provided the animation shows a transition from 
             prior to posterior. Finally, the animation splits the distribution using the provided 
             'breaks' into bars that show the probability for each region. 
             If no 'breaks' are providers it will use zero by default.",2022-02-04,Ignacio Martinez,"https://github.com/ignacio82/vizdraws/,
https://vizdraws.martinez.fyi/",TRUE,https://github.com/ignacio82/vizdraws,8860,10,2022-02-04T20:55:53Z,886
VLTimeCausality,"A framework to infer causality on a pair of time series of real numbers based on variable-lag Granger causality and transfer entropy. Typically, Granger causality and transfer entropy have an assumption of a fixed and constant time delay between the cause and effect. However, for a non-stationary time series, this assumption is not true. For example, considering two time series of velocity of person A and person B where B follows A. At some time, B stops tying his shoes, then running to catch up A. The fixed-lag assumption is not true in this case. We propose a framework that allows variable-lags between cause and effect in Granger causality and transfer entropy to allow them to deal with variable-lag non-stationary time series. Please see Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Berger-Wolf (2021) <doi:10.1145/3441452> when referring to this package in publications.  ",2022-01-24,Chainarong Amornbunchornvej,https://github.com/DarkEyes/VLTimeSeriesCausality,TRUE,https://github.com/darkeyes/vltimeseriescausality,13791,36,2022-01-24T06:38:26Z,383.0833333333333
VMDecomp,"'RcppArmadillo' implementation for the Matlab code of the 'Variational Mode Decomposition' and 'Two-Dimensional Variational Mode Decomposition'. For more information, see (i) 'Variational Mode Decomposition' by K. Dragomiretskiy and D. Zosso in IEEE Transactions on Signal Processing, vol. 62, no. 3, pp. 531-544, Feb.1, 2014, <doi:10.1109/TSP.2013.2288675>; (ii) 'Two-Dimensional Variational Mode Decomposition' by Dragomiretskiy, K., Zosso, D. (2015), In: Tai, XC., Bae, E., Chan, T.F., Lysaker, M. (eds) Energy Minimization Methods in Computer Vision and Pattern Recognition. EMMCVPR 2015. Lecture Notes in Computer Science, vol 8932. Springer, <doi:10.1007/978-3-319-14612-6_15>.",2022-07-04,Lampros Mouselimis,https://github.com/mlampros/VMDecomp,TRUE,https://github.com/mlampros/vmdecomp,329,1,2022-07-08T14:34:44Z,329
volcano3D,"Generates interactive plots for analysing and visualising 
    three-class high dimensional data. It is particularly suited to visualising 
    differences in continuous attributes such as gene/protein/biomarker 
    expression levels between three groups. Differential gene/biomarker 
    expression analysis between two classes is typically shown as a volcano 
    plot. However, with three groups this type of visualisation is particularly 
    difficult to interpret. This package generates 3D volcano plots and 3-way 
    polar plots for easier interpretation of three-class data.",2022-07-05,Katriona Goldmann,"https://katrionagoldmann.github.io/volcano3D/index.html,
https://github.com/KatrionaGoldmann/volcano3D",TRUE,https://github.com/katrionagoldmann/volcano3d,9744,19,2022-07-08T09:46:31Z,512.8421052631579
volesti,"Provides an R interface for 'volesti' C++ package. 'volesti' computes estimations of volume 
             of polytopes given by (i) a set of points, (ii) linear inequalities or (iii) Minkowski sum of segments 
             (a.k.a. zonotopes). There are three algorithms for volume estimation as well as algorithms 
             for sampling, rounding and rotating polytopes. Moreover, 'volesti' provides algorithms for 
             estimating copulas useful in computational finance.",2021-07-14,Vissarion Fisikopoulos,NA,TRUE,https://github.com/geomscale/volume_approximation,14169,105,2022-07-06T10:33:56Z,134.94285714285715
voluModel,"Facilitates modeling species' ecological niches and 
  geographic distributions based on occurrences and environments that 
  have a vertical as well as horizontal component, and projecting models 
  into three-dimensional geographic space. Working in three dimensions is 
  useful in an aquatic context when the organisms one wishes to model can 
  be found across a wide range of depths in the water column. The package
  also contains functions to automatically generate marine training
  model training regions using machine learning, and interpolate and smooth
  patchily sampled environmental rasters using thin plate splines.
  Davis Rabosky AR, Cox CL, Rabosky DL, Title PO, Holmes IA, Feldman A, McGuire JA (2016) <doi:10.1038/ncomms11484>.
  Nychka D, Furrer R, Paige J, Sain S (2021) <doi:10.5065/D6W957CT>.
  Pateiro-Lopez B, Rodriguez-Casal A (2022) <https://CRAN.R-project.org/package=alphahull>.",2022-06-27,Hannah L. Owens,https://hannahlowens.github.io/voluModel/,TRUE,https://github.com/hannahlowens/volumodel,1127,3,2022-06-28T12:02:56Z,375.6666666666667
voson.tcn,"Collects tweets and metadata for threaded conversations and
    generates networks.",2022-04-05,Bryan Gertzel,https://github.com/vosonlab/voson.tcn,TRUE,https://github.com/vosonlab/voson.tcn,4647,7,2022-06-01T16:11:27Z,663.8571428571429
VOSONDash,"A 'Shiny' application for the interactive visualisation and
    analysis of networks that also provides a web interface for collecting
    social media data using 'vosonSML'.",2020-07-27,Bryan Gertzel,https://github.com/vosonlab/VOSONDash,TRUE,https://github.com/vosonlab/vosondash,14338,45,2022-02-15T10:40:02Z,318.6222222222222
vosonSML,"A suite of tools for collecting and constructing networks from social media data.
    Provides easy-to-use functions for collecting data across popular platforms (Twitter, YouTube
    and Reddit) and generating different types of networks for analysis.",2020-07-18,Timothy Graham,https://github.com/vosonlab/vosonSML,TRUE,https://github.com/vosonlab/vosonsml,24516,64,2022-02-12T20:50:51Z,383.0625
vpc,"Visual predictive checks are a commonly used diagnostic plot in pharmacometrics, showing how certain statistics (percentiles) for observed data compare to those same statistics for data simulated from a model. The package can generate VPCs for continuous, categorical, censored, and (repeated) time-to-event data.",2021-01-11,Ron Keizer,https://github.com/ronkeizer/vpc,TRUE,https://github.com/ronkeizer/vpc,29144,29,2022-06-04T15:20:14Z,1004.9655172413793
vrnmf,"Implements a set of routines to perform structured matrix factorization with minimum volume constraints. The NMF procedure decomposes a matrix X into a product C * D. Given conditions such that the matrix C is non-negative and has sufficiently spread columns, then volume minimization of a matrix D delivers a correct and unique, up to a scale and permutation, solution (C, D). This package provides both an implementation of volume-regularized NMF and ""anchor-free"" NMF, whereby the standard NMF problem is reformulated in the covariance domain. This algorithm was applied in Vladimir B. Seplyarskiy Ruslan A. Soldatov, et al. ""Population sequencing data reveal a compendium of mutational processes in the human germ line"". Science, 12 Aug 2021. <doi:10.1126/science.aba7408>. This package interacts with data available through the 'simulatedNMF' package, which is available in a 'drat' repository. To access this data package, see the instructions at <https://github.com/kharchenkolab/vrnmf>. The size of the 'simulatedNMF' package is approximately 8 MB.",2022-02-25,Evan Biederstedt,https://github.com/kharchenkolab/vrnmf,TRUE,https://github.com/kharchenkolab/vrnmf,3529,18,2022-04-14T14:35:05Z,196.05555555555554
vroom,"The goal of 'vroom' is to read and write data (like
    'csv', 'tsv' and 'fwf') quickly. When reading it uses a quick initial
    indexing step, then reads the values lazily , so only the data you
    actually use needs to be read.  The writer formats the data in
    parallel and writes to disk asynchronously from formatting.",2021-11-30,Jim Hester,"https://vroom.r-lib.org, https://github.com/r-lib/vroom",TRUE,https://github.com/r-lib/vroom,8879080,556,2022-06-14T17:36:55Z,15969.568345323742
vsp,"Provides fast spectral estimation of latent factors in random
    dot product graphs using the vsp estimator. Under mild assumptions,
    the vsp estimator is consistent for (degree-corrected) stochastic
    blockmodels, (degree-corrected) mixed-membership stochastic
    blockmodels, and degree-corrected overlapping stochastic blockmodels.",2022-02-10,Alex Hayes,https://github.com/RoheLab/vsp,TRUE,https://github.com/rohelab/vsp,1157,22,2022-02-20T23:44:36Z,52.59090909090909
vstsr,"Implementation of 'Azure DevOps' <https://azure.microsoft.com/> API calls. 
    It enables the extraction of information about repositories, build and release definitions and individual releases. 
    It also helps create repositories and work items within a project without logging into 'Azure DevOps'. 
    There is the ability to use any API service with a shell for any non-predefined call.",2021-11-08,Ashley Baldry,"https://github.com/ashbaldry/vstsr,
https://docs.microsoft.com/en-us/rest/api/azure/devops",TRUE,https://github.com/ashbaldry/vstsr,11219,2,2021-11-08T22:26:55Z,5609.5
VSURF,"Three steps variable selection procedure based on random forests.
    Initially developed to handle high dimensional data (for which number of
    variables largely exceeds number of observations), the package is very
    versatile and can treat most dimensions of data, for regression and
    supervised classification problems. First step is dedicated to eliminate
    irrelevant variables from the dataset. Second step aims to select all
    variables related to the response for interpretation purpose. Third step
    refines the selection by eliminating redundancy in the set of variables
    selected by the second step, for prediction purpose.
    Genuer, R. Poggi, J.-M. and Tuleau-Malot, C. (2015)
    <https://journal.r-project.org/archive/2015-2/genuer-poggi-tuleaumalot.pdf>.",2019-07-18,Robin Genuer,https://github.com/robingenuer/VSURF,TRUE,https://github.com/robingenuer/vsurf,25925,22,2022-07-01T13:34:58Z,1178.409090909091
vtable,"Automatically generates HTML variable documentation including variable names, labels, classes, value labels (if applicable), value ranges, and summary statistics. See the vignette ""vtable"" for a package overview.",2021-08-05,Nick Huntington-Klein,https://nickch-k.github.io/vtable/,TRUE,https://github.com/nickch-k/vtable,60035,24,2022-07-02T23:22:38Z,2501.4583333333335
vtreat,"A 'data.frame' processor/conditioner that prepares real-world data for predictive modeling in a statistically sound manner.
    'vtreat' prepares variables so that data has fewer exceptional cases, making
    it easier to safely use models in production. Common problems 'vtreat' defends
    against: 'Inf', 'NA', too many categorical levels, rare categorical levels, and new
    categorical levels (levels seen during application, but not during training). Reference: 
    ""'vtreat': a data.frame Processor for Predictive Modeling"", Zumel, Mount, 2016, <DOI:10.5281/zenodo.1173313>.",2021-06-11,John Mount,"https://github.com/WinVector/vtreat/,
https://winvector.github.io/vtreat/",TRUE,https://github.com/winvector/vtreat,187936,277,2022-01-26T16:13:19Z,678.4693140794224
vtree,"A tool for calculating and drawing ""variable trees"". Variable trees display information about nested subsets of a data frame.",2021-10-03,"Nick Barrowman 
  Sebastian Gatscha","https://github.com/nbarrowman/vtree,
https://nbarrowman.github.io/vtree",TRUE,https://github.com/nbarrowman/vtree,36049,67,2022-06-23T18:37:01Z,538.044776119403
vueR,"Make it easy to use 'vue' in R with helper
              dependency functions and examples.",2021-11-29,Evan You,https://github.com/vue-r/vueR,TRUE,https://github.com/vue-r/vuer,1852,126,2021-11-26T15:11:24Z,14.698412698412698
VulnToolkit,"Contains functions for analysis and summary of tidal datasets. Also provides access to tidal data collected by the National Oceanic and Atmospheric Administration's Center for Operational Oceanographic Products and Services and the Permanent Service for Mean Sea Level. For detailed description and application examples, see Hill, T.D. and S.C. Anisfeld (2021) <doi:10.6084/m9.figshare.14161202.v1> and Hill, T.D. and S.C. Anisfeld (2015) <doi:10.1016/j.ecss.2015.06.004>.",2021-08-02,Troy Hill,https://github.com/troyhill/VulnToolkit,TRUE,https://github.com/troyhill/vulntoolkit,6194,6,2021-08-02T12:39:35Z,1032.3333333333333
wacolors,"Color palettes taken from the landscapes and cities of Washington 
    state. Colors were extracted from a set of photographs, and then combined to 
    form a set of continuous and discrete palettes.  Continuous palettes were 
    designed to be perceptually uniform, while discrete palettes were chosen to
    maximize contrast at several different levels of overall brightness and 
    saturation. Each palette has been evaluated to ensure colors are 
    distinguishable by colorblind people.",2022-03-01,Cory McCartan,https://github.com/CoryMcCartan/wacolors,TRUE,https://github.com/corymccartan/wacolors,4064,7,2022-03-01T15:32:50Z,580.5714285714286
waiter,"Full screen and partial loading screens for 'Shiny' with spinners, progress bars, and notifications.",2022-01-03,John Coene,"https://waiter.john-coene.com/,
https://github.com/JohnCoene/waiter",TRUE,https://github.com/johncoene/waiter,212973,434,2022-05-21T07:57:07Z,490.721198156682
waldo,"Compare complex R objects and reveal the key differences.
    Designed particularly for use in testing packages where being able to
    quickly isolate key differences makes understanding test failures much
    easier.",2022-03-16,Hadley Wickham,"https://waldo.r-lib.org, https://github.com/r-lib/waldo",TRUE,https://github.com/r-lib/waldo,10094532,233,2022-03-16T22:28:16Z,43324.17167381974
walker,"Efficient Bayesian generalized linear models with time-varying coefficients 
    as in Helske (2022, <doi:10.1016/j.softx.2022.101016>). Gaussian, Poisson, and binomial 
    observations are supported. The Markov chain Monte Carlo (MCMC) computations are done using 
    Hamiltonian Monte Carlo provided by Stan, using a state space representation 
    of the model in order to marginalise over the coefficients for efficient sampling. 
    For non-Gaussian models, the package uses the importance sampling type estimators based on 
    approximate marginal MCMC as in Vihola, Helske, Franks (2020, <doi:10.1111/sjos.12492>).",2022-03-03,Jouni Helske,https://github.com/helske/walker,TRUE,https://github.com/helske/walker,21556,37,2022-07-10T17:45:05Z,582.5945945945946
walrus,"A toolbox of common robust statistical tests, including robust
  descriptives, robust t-tests, and robust ANOVA. It is also available as a
  module for 'jamovi' (see <https://www.jamovi.org> for more information).
  Walrus is based on the WRS2 package by Patrick Mair, which is in turn based on
  the scripts and work of Rand Wilcox. These analyses are described in depth in
  the book 'Introduction to Robust Estimation & Hypothesis Testing'.",2022-03-09,Jonathon Love,https://github.com/jamovi/walrus,TRUE,https://github.com/jamovi/walrus,15171,2,2022-03-09T03:55:55Z,7585.5
warbleR,"Functions aiming to facilitate the analysis of the structure of animal acoustic signals in 'R'. 'warbleR' makes use of the basic sound analysis tools from the package 'seewave', and offers new tools for acoustic structure analysis. The main features of the package are the use of loops to apply tasks through acoustic signals referenced in a selection (annotation) table and the production of spectrograms in image files that allow to organize data and verify acoustic analyzes. The package offers functions to explore, organize and manipulate multiple sound files, explore and download 'Xeno-Canto' recordings, detect signals automatically, create spectrograms of complete recordings or individual signals, run different measures of acoustic signal structure, evaluate the performance of measurement methods, catalog signals, characterize different structural levels in acoustic signals, run statistical analysis of duet coordination and consolidate databases and annotation tables, among others.",2022-02-23,Marcelo Araya-Salas,https://marce10.github.io/warbleR/,TRUE,https://github.com/marce10/warbler,31540,42,2022-07-04T20:50:59Z,750.952380952381
washex,Gets data from the Washington State Legislature.,2021-11-17,Rohnin Randles,https://github.com/rwrandles/washex-r,TRUE,https://github.com/rwrandles/washex-r,3895,0,2021-11-17T15:32:48Z,NA
waterquality,"The main purpose of waterquality is to quickly and easily convert
    satellite-based reflectance imagery into one or many well-known water quality
    algorithms designed for the detection of harmful algal blooms or the following
    pigment proxies: chlorophyll-a, blue-green algae (phycocyanin), and turbidity.
    Johansen et al. (2019) <doi:10.21079/11681/35053>. ",2022-02-09,Richard Johansen,https://github.com/RAJohansen/waterquality,TRUE,https://github.com/rajohansen/waterquality,13021,31,2022-04-19T16:19:13Z,420.03225806451616
waves,"Originally designed application in the context of
    resource-limited plant research and breeding programs, 'waves'
    provides an open-source solution to spectral data processing and model
    development by bringing useful packages together into a streamlined
    pipeline.  This package is wrapper for functions related to the
    analysis of point visible and near-infrared reflectance measurements.
    It includes visualization, filtering, aggregation, preprocessing,
    cross-validation set formation, model training, and prediction
    functions to enable open-source association of spectral and reference
    data. This package is documented in a peer-reviewed manuscript in the
    Plant Phenome Journal <doi:10.1002/ppj2.20012>.  Specialized
    cross-validation schemes are described in detail in Jarquín et al.
    (2017) <doi:10.3835/plantgenome2016.12.0130>. Example data is from
    Ikeogu et al. (2017) <doi:10.1371/journal.pone.0188918>.",2022-03-29,Jenna Hershberger,https://github.com/GoreLab/waves,TRUE,https://github.com/gorelab/waves,8239,3,2022-03-17T22:27:35Z,2746.3333333333335
WaveSampling,"Spatial data are generally auto-correlated, meaning that if two 
  units selected are close to each other, then it is likely that they share the
  same properties. For this reason, when sampling in the population it is often
  needed that the sample is well spread over space. A new method to draw a sample
  from a population with spatial coordinates is proposed. This method is called
  wave (Weakly Associated Vectors) sampling. It uses the less correlated vector
  to a spatial weights matrix to update the inclusion probabilities vector
  into a sample. For more details see Raphaël Jauslin and Yves Tillé (2019) <doi:10.1007/s13253-020-00407-1>.",2022-05-02,Raphaël Jauslin,https://github.com/RJauslin/WaveSampling,TRUE,https://github.com/rjauslin/wavesampling,11137,1,2022-05-02T13:35:44Z,11137
wbacon,"The BACON algorithms are methods for multivariate outlier
    nomination (detection) and robust linear regression by Billor, Hadi,
    and Velleman (2000) <doi:10.1016/S0167-9473(99)00101-2>. The extension
    to weighted problems is due to Beguin and Hulliger (2008)
    <https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X200800110616>; see
    also <doi:10.21105/joss.03238>.",2021-11-04,Tobias Schoch,https://github.com/tobiasschoch/wbacon,TRUE,https://github.com/tobiasschoch/wbacon,4455,1,2021-11-04T20:20:17Z,4455
wcde,Download and plot education specific demographic data from the Wittgenstein Centre for Demography and Human Capital Data Explorer <http://dataexplorer.wittgensteincentre.org/>.,2022-06-06,Guy J. Abel,https://guyabel.github.io/wcde/,TRUE,https://github.com/guyabel/wcde,5144,1,2022-06-24T03:06:11Z,5144
wdm,"Provides efficient implementations of weighted dependence measures
  and related asymptotic tests for independence. Implemented measures are
  the Pearson correlation, Spearman's rho, Kendall's tau, Blomqvist's beta, and
  Hoeffding's D; see, e.g., Nelsen (2006) <doi:10.1007/0-387-28678-0> and
  Hollander et al. (2015, ISBN:9780470387375).",2022-03-17,Thomas Nagler,https://github.com/tnagler/wdm-r,TRUE,https://github.com/tnagler/wdm-r,56911,3,2022-03-16T23:56:17Z,18970.333333333332
wdman,"There are a number of binary files associated with the
    'Webdriver'/'Selenium' project (see <http://www.seleniumhq.org/download/>,
    <https://sites.google.com/a/chromium.org/chromedriver/>,
    <https://github.com/mozilla/geckodriver>,
    <http://phantomjs.org/download.html> and
    <https://github.com/SeleniumHQ/selenium/wiki/InternetExplorerDriver> for
    more information). This package provides functions to download these
    binaries and to manage processes involving them.",2020-01-31,John Harrison,"https://docs.ropensci.org/wdman, https://github.com/ropensci/wdman",TRUE,https://github.com/ropensci/wdman,139431,29,2022-02-18T00:53:31Z,4807.9655172413795
wdpar,"Fetch and clean data from the World Database on Protected
    Areas (WDPA) and the World Database on Other Effective Area-Based
    Conservation Measures (WDOECM). Data is obtained from Protected Planet
    <https://www.protectedplanet.net/en>. To augment data cleaning procedures,
    users can install the 'prepr' R package (available at
    <https://github.com/dickoa/prepr>).",2022-07-08,Jeffrey O Hanson,"https://prioritizr.github.io/wdpar/,
https://github.com/prioritizr/wdpar",TRUE,https://github.com/prioritizr/wdpar,22781,33,2022-07-08T08:01:35Z,690.3333333333334
weaana,"Functions are collected to analyse weather data for agriculture 
    purposes including to read weather records in multiple formats, 
    calculate extreme climate index.",2021-09-27,Bangyou Zheng,"https://weaana.bangyou.me/, https://github.com/byzheng/weaana",TRUE,https://github.com/byzheng/weaana,3116,2,2022-06-14T04:55:08Z,1558
WebAnalytics,"Provides Apache and IIS log analytics for transaction performance, client populations and workload definitions.",2022-04-23,Greg Hunt,https://github.com/gregfrog/WebAnalytics,TRUE,https://github.com/gregfrog/webanalytics,1771,0,2022-04-24T04:04:43Z,NA
webchem,"Chemical information from around the web. This package interacts 
    with a suite of web services for chemical information. Sources include: Alan
    Wood's Compendium of Pesticide Common Names, Chemical Identifier Resolver,
    ChEBI, Chemical Translation Service, ChemIDplus, ChemSpider, ETOX,
    Flavornet, NIST Chemistry WebBook, OPSIN, PAN Pesticide Database, PubChem,
    SRS, Wikidata.",2022-06-15,Eduard Szöcs,"https://docs.ropensci.org/webchem/,
https://github.com/ropensci/webchem",TRUE,https://github.com/ropensci/webchem,31002,123,2022-06-14T09:39:01Z,252.0487804878049
webdriver,"A client for the 'WebDriver' 'API'. It allows driving a
    (probably headless) web browser, and can be used to test web
    applications, including 'Shiny' apps. In theory it works with any
    'WebDriver' implementation, but it was only tested with 'PhantomJS'.",2021-01-12,Ariya Hidayat,https://github.com/rstudio/webdriver,TRUE,https://github.com/rstudio/webdriver,316438,61,2022-01-25T20:56:00Z,5187.508196721312
webexercises,"Functions for easily creating interactive web pages using
    'R Markdown' that students can use in self-guided learning.",2021-09-15,Dale Barr,https://github.com/psyteachr/webexercises,TRUE,https://github.com/psyteachr/webexercises,4379,9,2021-09-14T10:58:06Z,486.55555555555554
WebGestaltR,"The web version WebGestalt <http://www.webgestalt.org> supports 12 organisms, 354 gene identifiers and 321,251 function categories. Users can upload the data and functional categories with their own gene identifiers. In addition to the Over-Representation Analysis, WebGestalt also supports Gene Set Enrichment Analysis and Network Topology Analysis. The user-friendly output report allows interactive and efficient exploration of enrichment results. The WebGestaltR package not only supports all above functions but also can be integrated into other pipeline or simultaneously analyze multiple gene lists.",2020-07-24,Yuxing Liao,https://github.com/bzhanglab/WebGestaltR,TRUE,https://github.com/bzhanglab/webgestaltr,24240,22,2021-12-14T15:42:37Z,1101.8181818181818
webmockr,"Stubbing and setting expectations on 'HTTP' requests.
    Includes tools for stubbing 'HTTP' requests, including expected
    request conditions and response conditions. Match on
    'HTTP' method, query parameters, request body, headers and
    more. Can be used for unit tests or outside of a testing 
    context.",2021-03-14,Scott Chamberlain,"https://github.com/ropensci/webmockr (devel)
https://books.ropensci.org/http-testing/ (user manual)
https://docs.ropensci.org/webmockr/ (documentation)",TRUE,https://github.com/ropensci/webmockr,78057,43,2021-10-14T16:04:47Z,1815.2790697674418
webmorphR,"Create reproducible image stimuli, 
    specialised for face images with 'psychomorph' or 'webmorph' templates.",2022-06-02,Lisa DeBruine,"https://debruine.github.io/webmorphR/,
https://github.com/debruine/webmorphR",TRUE,https://github.com/debruine/webmorphr,258,2,2022-07-01T20:19:05Z,129
webshot,"Takes screenshots of web pages, including Shiny applications and R
    Markdown documents.",2022-04-14,Winston Chang,"http://wch.github.io/webshot/, https://github.com/wch/webshot/",TRUE,https://github.com/wch/webshot,3456350,210,2022-03-31T16:07:09Z,16458.809523809523
webshot2,"Takes screenshots of web pages, including Shiny applications and R
    Markdown documents. 'webshot2' uses headless Chrome or Chromium as the browser
    back-end.",2022-05-18,Winston Chang,https://github.com/rstudio/webshot2,TRUE,https://github.com/rstudio/webshot2,7331,89,2022-05-25T18:07:47Z,82.37078651685393
websocket,"Provides a 'WebSocket' client interface for R.
    'WebSocket' is a protocol for low-overhead real-time communication:
    <https://en.wikipedia.org/wiki/WebSocket>.",2021-08-18,Winston Chang,NA,TRUE,https://github.com/rstudio/websocket,405831,83,2021-11-19T16:25:19Z,4889.530120481928
wehoop,"A utility for working with women's basketball data. A scraping and aggregating interface for the WNBA Stats API <https://stats.wnba.com/> and ESPN's <https://www.espn.com> women's college basketball and WNBA statistics. It provides users with the capability to access the game play-by-plays, box scores, standings and results to analyze the data for themselves.",2022-06-17,Saiem Gilani,"https://wehoop.sportsdataverse.org,
https://github.com/sportsdataverse/wehoop",TRUE,https://github.com/sportsdataverse/wehoop,2634,7,2022-06-17T11:59:46Z,376.2857142857143
weibullness,"Performs a goodness-of-fit test of Weibull distribution (weibullness test) and provides the maximum likelihood estimates of the three-parameter Weibull distribution. Note that the threshold parameter is estimated based on the correlation from the Weibull plot. For more details, see Park (2018) <doi:10.1155/2018/6056975>. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (No. NRF-2017R1A2B4004169).",2019-08-19,Chanseok Park,https://github.com/AppliedStat/R,TRUE,https://github.com/appliedstat/r,18875,1,2022-05-23T09:20:56Z,18875
weibulltools,"Provides statistical methods and visualizations that are often 
             used in reliability engineering. Comprises a compact and easily 
             accessible set of methods and visualization tools that make the 
             examination and adjustment as well as the analysis and interpretation 
             of field data (and bench tests) as simple as possible.
             Non-parametric estimators like Median Ranks, 
             Kaplan-Meier (Abernethy, 2006, <ISBN:978-0-9653062-3-2>), 
             Johnson (Johnson, 1964, <ISBN:978-0444403223>), and Nelson-Aalen 
             for failure probability estimation within samples that contain 
             failures as well as censored data are included.   
             The package supports methods like Maximum Likelihood and Rank Regression, 
             (Genschel and Meeker, 2010, <DOI:10.1080/08982112.2010.503447>) 
             for the estimation of multiple parametric lifetime distributions,  
             as well as the computation of confidence intervals of quantiles and 
             probabilities using the delta method related to Fisher's confidence 
             intervals (Meeker and Escobar, 1998, <ISBN:9780471673279>) and the 
             beta-binomial confidence bounds. 
             If desired, mixture model analysis can be done with segmented regression
             and the EM algorithm.
             Besides the well-known Weibull analysis, the package also contains 
             Monte Carlo methods for the correction and completion of imprecisely 
             recorded or unknown lifetime characteristics.
             (Verband der Automobilindustrie e.V. (VDA), 2016, <ISSN:0943-9412>). 
             Plots are created statically ('ggplot2') or interactively ('plotly') and 
             can be customized with functions of the respective visualization package.
             The graphical technique of probability plotting as well as the addition 
             of regression lines and confidence bounds to existing plots are 
             supported. ",2021-01-12,Tim-Gunnar Hensel,"https://tim-tu.github.io/weibulltools,
https://github.com/Tim-TU/weibulltools",TRUE,https://github.com/tim-tu/weibulltools,14405,8,2022-04-01T12:31:47Z,1800.625
WeightIt,"Generates balancing weights for causal effect estimation in observational studies with
             binary, multi-category, or continuous point or longitudinal treatments by easing and
             extending the functionality of several R packages and providing in-house estimation methods.
             Available methods include propensity score weighting using generalized linear models, gradient
             boosting machines, the covariate balancing propensity score algorithm, Bayesian additive regression trees, and
             SuperLearner, and directly estimating balancing weights using entropy balancing, empirical
             balancing calibration weights, energy balancing, and optimization-based weights. Also
             allows for assessment of weights and checking of covariate balance by interfacing directly
             with the 'cobalt' package. See the vignette ""Installing Supporting Packages"" for instructions on how
             to install any package 'WeightIt' uses, including those that may not be on CRAN.",2022-06-28,Noah Greifer,"https://ngreifer.github.io/WeightIt/,
https://github.com/ngreifer/WeightIt",TRUE,https://github.com/ngreifer/weightit,44357,65,2022-06-24T17:31:01Z,682.4153846153846
weightQuant,"Estimation of observation-specific weights for incomplete longitudinal data and bootstrap procedure for weighted quantile regressions. See Jacqmin-Gadda, Rouanet, Mba, Philipps, Dartigues (2020) for details <doi:10.1177/0962280220909986>.",2022-01-05,Viviane Philipps,NA,TRUE,https://github.com/vivianephilipps/weightquant,14761,1,2022-01-05T11:18:36Z,14761
WeightSVM,"Functions for subject/instance weighted support vector machines (SVM). 
    It uses a modified version of 'libsvm' and is compatible with package 'e1071'. ",2021-10-11,Tianchen Xu,https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances,TRUE,https://github.com/zjph602xtc/wsvm,18693,2,2022-07-07T14:39:00Z,9346.5
WeMix,"Run mixed-effects models that include weights at every level. The WeMix package fits a weighted mixed model, also known as a multilevel, mixed, or hierarchical linear model (HLM). The weights could be inverse selection probabilities, such as those developed for an education survey where schools are sampled probabilistically, and then students inside of those schools are sampled probabilistically. Although mixed-effects models are already available in R, WeMix is unique in implementing methods for mixed models using weights at multiple levels. Both linear and logit models are supported. Models may have up to three levels. ",2021-12-07,Paul Bailey,https://american-institutes-for-research.github.io/WeMix/,TRUE,https://github.com/american-institutes-for-research/wemix,24323,3,2021-12-13T23:53:51Z,8107.666666666667
wesanderson,Palettes generated mostly from 'Wes Anderson' movies.,2018-04-20,Karthik Ram,https://github.com/karthik/wesanderson,TRUE,https://github.com/karthik/wesanderson,320138,1586,2022-02-08T23:04:53Z,201.85245901639345
weyl,"A suite of routines for Weyl algebras.  Notation follows
   Coutinho (1995, ISBN 0-521-55119-6, ""A Primer of Algebraic D-Modules"").",2022-01-21,Robin K. S. Hankin,https://github.com/RobinHankin/weyl,TRUE,https://github.com/robinhankin/weyl,1436,2,2022-06-22T20:00:30Z,718
wheatmap,"Builds complex plots, heatmaps in particular, using natural semantics. Bigger plots can be assembled using directives such as 'LeftOf', 'RightOf', 'TopOf', and 'Beneath' and more. Other features include clustering, dendrograms and integration with 'ggplot2' generated grid objects. This package is particularly designed for bioinformaticians to assemble complex plots for publication.",2022-02-27,Wanding Zhou,https://github.com/zwdzwd/wheatmap,TRUE,https://github.com/zwdzwd/wheatmap,19420,9,2022-02-27T16:29:33Z,2157.777777777778
whippr,Set of tools for manipulating gas exchange data from cardiopulmonary exercise testing.,2022-03-09,Felipe Mattioni Maturana,https://github.com/fmmattioni/whippr,TRUE,https://github.com/fmmattioni/whippr,868,6,2022-03-06T10:49:43Z,144.66666666666666
whitebox,"An R frontend for the 'WhiteboxTools' library, which is an advanced geospatial data analysis platform developed by Prof. John Lindsay at the University of Guelph's Geomorphometry and Hydrogeomatics Research Group. 'WhiteboxTools' can be used to perform common geographical information systems (GIS) analysis operations, such as cost-distance analysis, distance buffering, and raster reclassification. Remote sensing and image processing tasks include image enhancement (e.g. panchromatic sharpening, contrast adjustments), image mosaicing, numerous filtering operations, simple classification (k-means), and common image transformations. 'WhiteboxTools' also contains advanced tooling for spatial hydrological analysis (e.g. flow-accumulation, watershed delineation, stream network analysis, sink removal), terrain analysis (e.g. common terrain indices such as slope, curvatures, wetness index, hillshading; hypsometric analysis; multi-scale topographic position analysis), and LiDAR data processing. Suggested citation: Lindsay (2016) <doi:10.1016/j.cageo.2016.07.003>.",2022-05-15,Qiusheng Wu,https://github.com/giswqs/whiteboxR,TRUE,https://github.com/giswqs/whiteboxr,7427,134,2022-05-18T08:35:50Z,55.42537313432836
whomds,"The Model Disability Survey (MDS) <https://www.who.int/activities/collection-of-data-on-disability> is a World Health Organization (WHO) general population survey
    instrument to assess the distribution of disability within a country or 
    region, grounded in the International Classification of Functioning, 
    Disability and Health <https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health>. This package provides fit-for-purpose functions 
    for calculating and presenting the results from this survey, as used by 
    the WHO. The package primarily provides functions for implementing
    Rasch Analysis (see Andrich (2011) <doi:10.1586/erp.11.59>) to
    calculate a metric scale for disability.",2022-05-27,Lindsay Lee,https://github.com/lindsayevanslee/whomds,TRUE,https://github.com/lindsayevanslee/whomds,2136,2,2022-05-26T22:47:57Z,1068
widgetframe,"Provides two functions 'frameableWidget()', and 'frameWidget()'.
  The 'frameableWidget()' is used to add extra code to a 'htmlwidget' which
  allows is to be rendered correctly inside a responsive 'iframe'.
  The 'frameWidget()' is a 'htmlwidget' which displays content of another 'htmlwidget'
  inside a responsive 'iframe'.
  These functions allow for easier embedding of 'htmlwidgets' in content management systems
  such as 'wordpress', 'blogger' etc.
  They also allow for separation of widget content from main HTML content where
  CSS of the main HTML could interfere with the widget.",2017-12-20,Bhaskar Karambelkar,"https://github.com/bhaskarvk/widgetframe,
https://bhaskarvk.github.io/widgetframe/",TRUE,https://github.com/bhaskarvk/widgetframe,329973,68,2021-09-30T14:38:42Z,4852.544117647059
widyr,"Encapsulates the pattern of untidying data into a wide matrix,
  performing some processing, then turning it back into a tidy form. This
  is useful for several operations such as co-occurrence counts,
  correlations, or clustering that are mathematically convenient on wide matrices.",2021-08-12,David Robinson,https://github.com/dgrtwo/widyr,TRUE,https://github.com/dgrtwo/widyr,98103,291,2021-08-12T00:16:57Z,337.12371134020617
wiesbaden,Retrieve and import data from different databases of the Federal Statistical Office of Germany (DESTATIS) using their SOAP XML web service <https://www-genesis.destatis.de/>.,2022-01-03,Moritz Marbach,https://github.com/sumtxt/wiesbaden/,TRUE,https://github.com/sumtxt/wiesbaden,14129,32,2022-07-02T19:42:15Z,441.53125
wig,Import WIG data into R in long format.,2021-10-04,Ramiro Magno,https://github.com/ramiromagno/wig,TRUE,https://github.com/ramiromagno/wig,2445,0,2021-10-04T16:54:29Z,NA
WikidataR,"Read from, interogate, and write to Wikidata <https://www.wikidata.org> -
    the multilingual, interdisciplinary, semantic knowledgebase. Includes functions to:
    read from wikidata (single items, properties, or properties); query wikidata (retrieving
    all items that match a set of criterial via Wikidata SPARQL query service); write to
    Wikidata (adding new items or statements via QuickStatements); and handle and manipulate
    Wikidata objects (as lists and tibbles). Uses the Wikidata and Quickstatements APIs. ",2021-11-16,Thomas Shafee,https://github.com/TS404/WikidataR,TRUE,https://github.com/ts404/wikidatar,159831,17,2022-05-29T09:25:46Z,9401.823529411764
wikilake,Scrape lake metadata tables from Wikipedia <https://www.wikipedia.org/>. ,2021-10-05,Jemma Stachelek,https://github.com/jsta/wikilake,TRUE,https://github.com/jsta/wikilake,15474,9,2021-10-04T02:16:51Z,1719.3333333333333
wildmeta,"Conducts single coefficient tests and multiple-contrast hypothesis tests of meta-regression models using cluster wild bootstrapping, based on methods examined in Joshi, Pustejovsky, and Beretvas (2022) <DOI:10.1002/jrsm.1554>. ",2022-06-29,Megha Joshi,https://meghapsimatrix.github.io/wildmeta/index.html,TRUE,https://github.com/meghapsimatrix/wildmeta,5663,2,2022-06-30T18:51:29Z,2831.5
wildviz,"Fetches data from three disparate data sources and allows user to perform analyses on them. It offers two core components: 1. A robust data retrieval and preparation infrastructure for wildfire, climate, and air quality index data and 2. A simple, informative, and interactive visualizations of the aforementioned datasets for California counties from 2011 through 2015. The sources of data are: wildfire data from Kaggle <https://www.kaggle.com/rtatman/188-million-us-wildfires>, climate data from the National Oceanic and Atmospheric Administration  <https://www.ncdc.noaa.gov/cdo-web/token>, and air quality data from the Environmental Protection Agency <https://aqs.epa.gov/aqsweb/documents/data_api.html>. ",2021-08-23,Bradley Rafferty,https://github.com/bradraff/wildviz,TRUE,https://github.com/bradraff/wildviz,4333,1,2021-08-22T00:27:38Z,4333
winch,"Obtain the native stack trace and fuse it with R's
    stack trace for easier debugging of R packages with native code.",2022-03-17,Kirill Müller,"https://r-prof.github.io/winch/, https://github.com/r-prof/winch",TRUE,https://github.com/r-prof/winch,8128,10,2022-05-14T02:29:08Z,812.8
windsoraiR,"Collect multichannel marketing data from sources such as Google analytics, Facebook Ads, and many others using the 'Windsor.ai' API <https://www.windsor.ai/api-fields/>.",2021-05-10,Novica Nakov,https://github.com/windsor-ai/windsoraiR/,TRUE,https://github.com/windsor-ai/windsorair,4980,1,2021-10-20T17:58:53Z,4980
winfapReader,"Obtain information on peak flow data from the National River Flow Archive (NRFA) in the United Kingdom, either from the Peak Flow Dataset files <https://nrfa.ceh.ac.uk/peak-flow-dataset> once these have been downloaded to the user's computer or using the NRFA's API. These files are in a format suitable for direct use in the 'WINFAP' software, hence the name of the package. ",2021-02-19,Ilaria Prosdocimi,https://ilapros.github.io/winfapReader/,TRUE,https://github.com/ilapros/winfapreader,7714,2,2022-05-17T15:27:08Z,3857
wiqid,"Provides simple, fast functions for maximum likelihood and Bayesian estimates of wildlife population parameters, suitable for use with simulated data or bootstraps. Early versions were indeed quick and dirty, but optional error-checking routines and meaningful error messages have been added. Includes single and multi-season occupancy, closed capture population estimation, survival, species richness and distance measures.",2022-06-20,Mike Meredith,https://mmeredith.net/R/wiqid/,TRUE,https://github.com/mikemeredith/wiqid,22631,2,2022-06-19T09:53:11Z,11315.5
wiseR,"A Shiny application for learning Bayesian Decision Networks from data. This package can be used for probabilistic reasoning (in the observational setting), causal inference (in the presence of interventions) and learning policy decisions (in Decision Network setting). Functionalities include end-to-end implementations for data-preprocessing, structure-learning, exact inference, approximate inference, extending the learned structure to Decision Networks and policy optimization using statistically rigorous methods such as bootstraps, resampling, ensemble-averaging and cross-validation. In addition to Bayesian Decision Networks, it also features correlation networks, community-detection, graph visualizations, graph exports and web-deployment of the learned models as Shiny dashboards.   ",2018-11-29,Tavpritesh Sethi,https://github.com/SAFE-ICU/wiseR,TRUE,https://github.com/safe-icu/wiser,22622,8,2021-10-17T16:55:12Z,2827.75
wk,"Provides a minimal R and C++ API for parsing
  well-known binary and well-known text representation of
  geometries to and from R-native formats. 
  Well-known binary is compact
  and fast to parse; well-known text is human-readable
  and is useful for writing tests. These formats are only
  useful in R if the information they contain can be 
  accessed in R, for which high-performance functions 
  are provided here.",2022-01-03,Dewey Dunnington,"https://paleolimbot.github.io/wk/,
https://github.com/paleolimbot/wk",TRUE,https://github.com/paleolimbot/wk,1563935,31,2022-01-05T01:16:06Z,50449.51612903226
wmm,"Calculate magnetic field at a given location and time according to 
  the World Magnetic Model (WMM). Both the main field and secular variation 
  components are returned. This functionality is useful for physicists and 
  geophysicists who need orthogonal components from WMM. Currently, this package 
  supports annualized time inputs between 2000 and 2025. If desired, users can
  specify which WMM version to use, e.g., the original WMM2015 release or the 
  recent out-of-cycle WMM2015 release. Methods used to implement WMM, including 
  the Gauss coefficients for each release, are described in the following 
  publications: Chulliat et al (2020) <doi:10.25923/ytk1-yx35>,
  Chulliat et al (2019) <doi:10.25921/xhr3-0t19>, 
  Chulliat et al (2015) <doi:10.7289/V5TB14V7>, 
  Maus et al (2010) <https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/WMM2010_Report.pdf>, 
  McLean et al (2004) <https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/TRWMM_2005.pdf>,
  and Macmillian et al (2000) <https://www.ngdc.noaa.gov/geomag/WMM/data/WMMReports/wmm2000.pdf>.",2021-09-06,Will Frierson,https://github.com/wfrierson/wmm,TRUE,https://github.com/wfrierson/wmm,11350,3,2022-07-09T22:58:21Z,3783.3333333333335
wodds,"Descriptive statistics for large data tend to be low resolution on the tails. 
    Whisker Odds generate a table of descriptive statistics for large data. This is the same as
    letter-values, but with an alternative naming of depths which allow for depths beyond 26. For 
    a reference to letter-values see 'Heike Hofmann' and 'Hadley Wickham' and 'Karen Kafadar' (2017) <doi:10.1080/10618600.2017.1305277>.",2022-04-15,Alex Hallam,https://github.com/alexhallam/wodds,TRUE,https://github.com/alexhallam/wodds,640,0,2022-05-27T21:22:32Z,NA
woodValuationDE,"Monetary valuation of wood in German forests
             (stumpage values), including estimations of harvest quantities, 
             wood revenues, and harvest costs. The functions are sensitive to
             tree species, mean diameter of the harvested trees, stand quality,
             and logging method. The functions include estimations for the
             consequences of disturbances on revenues and costs. The underlying
             assortment tables are taken from Offer and Staupendahl (2018) with
             corresponding functions for salable and skidded volume derived in
             Fuchs et al. (in preparation). Wood revenue and harvest cost
             functions were taken from v. Bodelschwingh (2018). The consequences
             of disturbances refer to Dieter (2001), Moellmann and Moehring
             (2017), and Fuchs et al. (2022a, 2022b). For the full references 
             see documentation of the functions, package README, and Fuchs et
             al. (in preparation). Apart from Dieter (2001) and Moellmann and
             Moehring (2017), all functions and factors are based on data from
             HessenForst, the forest administration of the Federal State of
             Hesse in Germany.",2022-07-03,Jasper M. Fuchs,https://github.com/Forest-Economics-Goettingen/woodValuationDE,TRUE,https://github.com/forest-economics-goettingen/woodvaluationde,96,0,2022-07-04T14:53:31Z,NA
wooldridge,"Students learning both econometrics and R may find the introduction 
    to both challenging. The wooldridge data package aims to lighten the task by efficiently 
    loading any data set found in the text with a single command. Data sets have been 
    compressed to a fraction of their original size. Documentation files contain page numbers, 
    the original source, time of publication, and notes from the author suggesting avenues for 
    further analysis and research. If one needs an introduction to R model syntax, a 
    vignette contains solutions to examples from chapters of the text. 
    Data sets are from the 7th edition (Wooldridge 2020, ISBN-13: 978-1-337-55886-0), 
    and are backwards compatible with all previous versions of the text.",2021-11-08,Justin M. Shea,https://justinmshea.github.io/wooldridge/,TRUE,https://github.com/justinmshea/wooldridge,241510,144,2021-11-09T03:07:13Z,1677.1527777777778
worcs,"Create reproducible and transparent research projects in 'R'.
    This package is based on the Workflow for Open
    Reproducible Code in Science (WORCS), a step-by-step procedure based on best
    practices for
    Open Science. It includes an 'RStudio' project template, several
    convenience functions, and all dependencies required to make your project
    reproducible and transparent. WORCS is explained in the tutorial paper
    by Van Lissa, Brandmaier, Brinkman, Lamprecht, Struiksma, & Vreede (2020).
    <doi:10.17605/OSF.IO/ZCVBS>.",2021-02-02,Caspar J. van Lissa,https://github.com/cjvanlissa/worcs,TRUE,https://github.com/cjvanlissa/worcs,10852,58,2022-07-10T07:28:35Z,187.10344827586206
wordler,"The 'Wordle' game. Players have six attempts to guess a 
    five-letter word. After each guess, the player is informed which 
    letters in their guess are either: anywhere in the word; in the right 
    position in the word. This can be used to inform the next guess. Can be 
    played interactively in the console, or programmatically. Based on Josh 
    Wardle's game <https://www.powerlanguage.co.uk/wordle/>.",2022-02-01,David Smith,https://github.com/DavidASmith/wordler,TRUE,https://github.com/davidasmith/wordler,1409,5,2022-03-31T07:37:17Z,281.8
wordpiece,"Apply 'Wordpiece' (<arXiv:1609.08144>) tokenization to input text, 
 given an appropriate vocabulary. The 'BERT' (<arXiv:1810.04805>) tokenization 
 conventions are used by default.",2022-03-03,Jonathan Bratt,https://github.com/macmillancontentscience/wordpiece,TRUE,https://github.com/macmillancontentscience/wordpiece,5866,7,2022-03-03T14:09:42Z,838
wordpiece.data,"Provides data to be used by the wordpiece algorithm in order to 
    tokenize text into somewhat meaningful chunks. Included vocabularies were 
    retrieved from 
    <https://huggingface.co/bert-base-cased/resolve/main/vocab.txt> and 
    <https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt> and parsed
    into an R-friendly format.",2022-03-03,Jonathan Bratt,https://github.com/macmillancontentscience/wordpiece.data,TRUE,https://github.com/macmillancontentscience/wordpiece.data,3539,0,2022-03-03T13:59:35Z,NA
wordpredictor,"A framework for developing n-gram models for text prediction.
    It provides data cleaning, data sampling, extracting tokens from text,
    model generation, model evaluation and word prediction. For information on how n-gram models 
    work we referred to: ""Speech and Language Processing""
    <https://web.stanford.edu/~jurafsky/slp3/3.pdf>. For optimizing R code and
    using R6 classes we referred to ""Advanced R"" 
    <https://adv-r.hadley.nz/r6.html>. For writing R extensions we referred to 
    ""R Packages"", <https://r-pkgs.org/index.html>.",2022-01-04,Nadir Latif,"https://github.com/pakjiddat/word-predictor,
https://pakjiddat.github.io/word-predictor/",TRUE,https://github.com/pakjiddat/word-predictor,4389,2,2022-01-04T12:17:54Z,2194.5
workboots,"Provides functions for generating bootstrap prediction
    intervals from a 'tidymodels' workflow. 'tidymodels'
    <https://www.tidymodels.org/> is a collection of packages for modeling
    and machine learning using 'tidyverse' <https://www.tidyverse.org/>
    principles. This package is not affiliated with or maintained by
    'RStudio' or the 'tidymodels' maintainers.",2022-05-16,Mark Rieke,"https://github.com/markjrieke/workboots,
https://markjrieke.github.io/workboots/",TRUE,https://github.com/markjrieke/workboots,1465,10,2022-07-05T01:36:07Z,146.5
workflowr,"Provides a workflow for your analysis projects by combining
  literate programming ('knitr' and 'rmarkdown') and version control
  ('Git', via 'git2r') to generate a website containing time-stamped,
  versioned, and documented results.",2021-12-21,John Blischak,https://github.com/workflowr/workflowr,TRUE,https://github.com/workflowr/workflowr,26854,719,2022-06-16T16:38:00Z,37.349095966620304
workflows,"Managing both a 'parsnip' model and a preprocessor, such as a
    model formula or recipe from 'recipes', can often be challenging. The
    goal of 'workflows' is to streamline this process by bundling the
    model alongside the preprocessor, all within the same object.",2022-07-05,Davis Vaughan,"https://github.com/tidymodels/workflows,
https://workflows.tidymodels.org",TRUE,https://github.com/tidymodels/workflows,864162,171,2022-07-05T15:25:45Z,5053.578947368421
workflowsets,"A workflow is a combination of a model and preprocessors
    (e.g, a formula, recipe, etc.) (Kuhn and Silge (2021)
    <https://www.tmwr.org/>). In order to try different combinations of
    these, an object can be created that contains many workflows. There
    are functions to create workflows en masse as well as training them
    and visualizing the results.",2022-03-15,Max Kuhn,"https://github.com/tidymodels/workflowsets,
https://workflowsets.tidymodels.org",TRUE,https://github.com/tidymodels/workflowsets,545057,75,2022-06-12T14:47:09Z,7267.426666666666
workloopR,"Functions for the import, transformation, and analysis of data 
    from muscle physiology experiments. The work loop technique is used to 
    evaluate the mechanical work and power output of muscle. Josephson (1985) 
    <doi:10.1242/jeb.114.1.493> modernized the technique for
    application in comparative biomechanics. Although our initial motivation 
    was to provide functions to analyze work loop experiment data, as we 
    developed the package we incorporated the ability to analyze data from 
    experiments that are often complementary to work loops. There are currently 
    three supported experiment types: work loops, simple twitches, and tetanus 
    trials. Data can be imported directly from .ddf files or via an object 
    constructor function. Through either method, data can then be cleaned or 
    transformed via methods typically used in studies of muscle physiology. 
    Data can then be analyzed to determine the timing and magnitude of force 
    development and relaxation (for isometric trials) or the magnitude of work, 
    net power, and instantaneous power among other things (for work loops). 
    Although we do not provide plotting functions, all resultant objects are 
    designed to be friendly to visualization via either base-R plotting or 
    'tidyverse' functions.
 This package has been peer-reviewed by rOpenSci (v. 1.1.0).",2021-05-06,Vikram B. Baliga,"https://docs.ropensci.org/workloopR/,
https://github.com/ropensci/workloopR/",TRUE,https://github.com/ropensci/workloopr,4402,3,2021-07-28T18:07:12Z,1467.3333333333333
worldfootballR,"Allow users to obtain clean and tidy
    football (soccer) game, team and player data. Data is collected from a
    number of popular sites, including 'FBref'<https://fbref.com/en/>,
    transfer and valuations data from
    'Transfermarkt'<https://www.transfermarkt.com/> and shooting location
    and other match stats data from 'Understat'<https://understat.com/>
    and 'fotmob'<https://www.fotmob.com/>. It gives users the
    ability to access data more efficiently, rather than having to export
    data tables to files before being able to complete their analysis.",2022-06-15,Jason Zivkovic,https://github.com/JaseZiv/worldfootballR,TRUE,https://github.com/jaseziv/worldfootballr,4414,207,2022-06-24T22:16:57Z,21.32367149758454
wpa,"Opinionated functions that enable easier and faster
    analysis of Viva Insights data. There are three main types of functions in 'wpa':
    (i) Standard functions create a 'ggplot' visual or a summary table based on a specific
    Viva Insights metric; (2) Report Generation functions generate HTML reports on
    a specific analysis area, e.g. Collaboration; (3) Other miscellaneous functions cover
    more specific applications (e.g. Subject Line text mining) of Viva Insights data.
    This package adheres to 'tidyverse' principles and works well with the pipe syntax.
    'wpa' is built with the beginner-to-intermediate R users in mind, and is optimised for
    simplicity. ",2022-07-05,Martin Chan,https://github.com/microsoft/wpa/,TRUE,https://github.com/microsoft/wpa,14584,23,2022-07-05T15:07:24Z,634.0869565217391
wql,"Functions to assist in the processing and
    exploration of data from environmental monitoring programs.
    The package name stands for ""water quality"" and reflects the
    original focus on time series data for physical and chemical
    properties of water, as well as the biota. Intended for
    programs that sample approximately monthly, quarterly or
    annually at discrete stations, a feature of many legacy data
    sets. Most of the functions should be useful for analysis of
    similar-frequency time series regardless of the subject
    matter.",2017-07-04,Alan Jassby,https://github.com/jsta/wql,TRUE,https://github.com/jsta/wql,19235,9,2021-08-04T14:14:31Z,2137.222222222222
wrapr,"Tools for writing and debugging R code. Provides: 
    '%.>%' dot-pipe (an 'S3' configurable pipe), unpack/to (R style multiple assignment/return),
    'build_frame()'/'draw_frame()' ('data.frame' example tools),
    'qc()' (quoting concatenate), 
    ':=' (named map builder), 'let()' (converts non-standard evaluation interfaces to parametric standard
    evaluation interfaces, inspired by 'gtools::strmacro()' and 'base::bquote()'), and more.",2022-01-26,John Mount,"https://github.com/WinVector/wrapr,
https://winvector.github.io/wrapr/",TRUE,https://github.com/winvector/wrapr,334557,131,2022-01-26T20:40:42Z,2553.8702290076335
wrassp,"A wrapper around Michel Scheffers's 'libassp' (<http://libassp.sourceforge.net/>). 
    The 'libassp' (Advanced Speech Signal Processor) library aims at providing
    functionality for handling speech signal files in most common audio formats
    and for performing analyses common in phonetic science/speech science. This
    includes the calculation of formants, fundamental frequency, root mean
    square, auto correlation, a variety of spectral analyses, zero crossing
    rate, filtering etc. This wrapper provides R with a large subset of
    'libassp's signal processing functions and provides them to the user in a
    (hopefully) user-friendly manner.",2021-05-19,Raphael Winkelmann,https://github.com/IPS-LMU/wrassp,TRUE,https://github.com/ips-lmu/wrassp,21080,20,2021-08-17T12:38:43Z,1054
WriteXLS,"Cross-platform Perl based R function to create Excel 2003 (XLS) and Excel 2007 (XLSX)
             files from one or more data frames. Each data frame will be
             written to a separate named worksheet in the Excel spreadsheet.
             The worksheet name will be the name of the data frame it contains
             or can be specified by the user. ",2022-02-24,Marc Schwartz <marc_schwartz@me.com> and various authors for Perl modules listed in each .pm file.,https://github.com/marcschwartz/WriteXLS,TRUE,https://github.com/marcschwartz/writexls,201863,20,2022-02-24T13:39:53Z,10093.15
wrswoR,"A collection of implementations of classical and
    novel algorithms for weighted sampling without replacement.",2020-07-26,Kirill Müller,http://krlmlr.github.io/wrswoR,TRUE,https://github.com/krlmlr/wrswor,21720,17,2022-05-14T00:31:35Z,1277.6470588235295
WRTDStidal,"An adaptation for estuaries (tidal waters) of weighted regression
    on time, discharge, and season to evaluate trends in water quality time series.",2019-11-17,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/wtreg_for_estuaries,14654,1,2022-06-20T13:53:30Z,14654
wru,"Predicts individual race/ethnicity using surname, first name, middle name, geolocation,
    and other attributes, such as gender and age. The method utilizes Bayes'
    Rule (with optional measurement error correction) to compute the posterior probability of each racial category for any given
    individual. The package implements methods described in Imai and Khanna (2016)
    ""Improving Ecological Inference by Predicting Individual Ethnicity from Voter
    Registration Records"" Political Analysis <DOI:10.1093/pan/mpw001>.",2022-06-21,Brandon Bertelsen,https://github.com/kosukeimai/wru,TRUE,https://github.com/kosukeimai/wru,21454,96,2022-06-21T04:43:18Z,223.47916666666666
wsrf,"
    A parallel implementation of Weighted Subspace Random Forest.  The
    Weighted Subspace Random Forest algorithm was proposed in the
    International Journal of Data Warehousing and Mining by Baoxun Xu,
    Joshua Zhexue Huang, Graham Williams, Qiang Wang, and Yunming Ye
    (2012) <DOI:10.4018/jdwm.2012040103>.  The algorithm can classify
    very high-dimensional data with random forests built using small
    subspaces.  A novel variable weighting method is used for variable
    subspace selection in place of the traditional random variable
    sampling.This new approach is particularly useful in building
    models from high-dimensional data.",2022-03-13,He Zhao,"https://github.com/SimonYansenZhao/wsrf, https://togaware.com",TRUE,https://github.com/simonyansenzhao/wsrf,34197,10,2022-03-13T13:21:49Z,3419.7
wv,"Provides a series of tools to compute and plot quantities related to classical and robust wavelet variance for time series and regular lattices. More details can be found, for example, in Serroukh, A., Walden, A.T., & Percival, D.B. (2000) <doi:10.2307/2669537> and Guerrier, S. & Molinari, R. (2016) <arXiv:1607.05858>.  ",2020-01-16,Stéphane Guerrier,https://github.com/SMAC-Group/wv,TRUE,https://github.com/smac-group/wv,11145,13,2021-12-08T06:13:29Z,857.3076923076923
x12,The 'X13-ARIMA-SEATS' <https://www.census.gov/data/software/x13as.html> methodology and software is a widely used software and developed by the US Census Bureau. It can be accessed from 'R' with this package and 'X13-ARIMA-SEATS' binaries are provided by the 'R' package 'x13binary'.,2022-05-19,Alexander Kowarik,https://github.com/statistikat/x12,TRUE,https://github.com/statistikat/x12,31904,16,2022-05-19T08:59:50Z,1994
x13binary,"The US Census Bureau provides a seasonal adjustment program now
 called 'X-13ARIMA-SEATS' building on both earlier programs called X-11 and
 X-12 as well as the SEATS program by the Bank of Spain. The US Census Bureau
 offers both source and binary versions -- which this package integrates for
 use by other R packages.",2022-02-07,Dirk Eddelbuettel and Christoph Sax,https://github.com/x13org/x13binary,TRUE,https://github.com/x13org/x13binary,331574,6,2022-02-07T04:05:00Z,55262.333333333336
x3ptools,"The x3p file format  is specified in ISO standard 5436:2000 to 
    describe 3d surface measurements. 'x3ptools' allows reading, writing and 
    basic modifications to the 3D surface measurements.",2021-11-26,Heike Hofmann,https://github.com/heike/x3ptools,TRUE,https://github.com/heike/x3ptools,10419,5,2021-11-29T18:21:22Z,2083.8
xadmix,"A few functions which provide a quick way of subsetting
    genomic admixture data and generating customizable stacked barplots.",2022-07-08,Lukas Schönmann,https://github.com/SpaceCowboy-71/xadmix,TRUE,https://github.com/spacecowboy-71/xadmix,23,0,2022-07-09T07:32:56Z,NA
xaringan,"Create HTML5 slides with R Markdown and the JavaScript library
    'remark.js' (<https://remarkjs.com>).",2022-06-14,Yihui Xie,https://github.com/yihui/xaringan,TRUE,https://github.com/yihui/xaringan,173971,1358,2022-06-16T18:48:11Z,128.10824742268042
xaringanExtra,"Extras and extensions for 'xaringan' slides. Navigate your
    slides with tile view. Make your slides editable, live! Announce slide
    changes with subtle tones. Animate slide transitions with
    'animate.css'. Add tabbed panels to slides with 'panelset'. Use the
    'Tachyons CSS' utility toolkit for rapid slide development. Scribble
    on your slides. Add a copy button to your code chunks with
    'clipboard'. Add a logo or top or bottom banner to every slide.
    Broadcast slides to stay in sync with remote viewers. Include yourself
    in your slides with 'webcam'.  Plus a whole lot more!",2022-06-07,Garrick Aden-Buie,"https://pkg.garrickadenbuie.com/xaringanExtra/,
https://github.com/gadenbuie/xaringanExtra",TRUE,https://github.com/gadenbuie/xaringanextra,1423,424,2022-06-24T13:28:12Z,3.356132075471698
xaringanthemer,"Create beautifully color-coordinated and customized themes
    for your 'xaringan' slides, without writing any CSS. Complete your
    slide theme with 'ggplot2' themes that match the font and colors used
    in your slides.  Customized styles can be created directly in your
    slides' 'R Markdown' source file or in a separate external script.",2021-11-21,Garrick Aden-Buie,"https://pkg.garrickadenbuie.com/xaringanthemer/,
https://github.com/gadenbuie/xaringanthemer",TRUE,https://github.com/gadenbuie/xaringanthemer,33161,434,2022-01-08T13:40:17Z,76.40783410138249
xefun,"Miscellaneous functions used for x-engineering (feature engineering) or 
  for supporting in other packages maintained by 'Shichen Xie'.",2022-07-03,Shichen Xie,https://github.com/ShichenXie/xefun,TRUE,https://github.com/shichenxie/xefun,427,2,2022-07-03T03:08:00Z,213.5
xfun,Miscellaneous functions commonly used in other packages maintained by 'Yihui Xie'.,2022-05-10,Yihui Xie,https://github.com/yihui/xfun,TRUE,https://github.com/yihui/xfun,28267835,105,2022-05-20T14:28:07Z,269217.4761904762
xgb2sql,"This tool enables in-database scoring of 'XGBoost' models built in R, by translating trained model objects into SQL query. 
  'XGBoost' <https://xgboost.readthedocs.io/en/latest/index.html> provides parallel tree boosting (also known as gradient boosting machine, or GBM) algorithms
  in a highly efficient, flexible and portable way. GBM algorithm is introduced by Friedman (2001) <doi:10.1214/aos/1013203451>, 
  and more details on 'XGBoost' can be found in Chen & Guestrin (2016) <doi:10.1145/2939672.2939785>.",2019-03-13,Chengjun Hou,https://github.com/chengjunhou/xgb2sql,TRUE,https://github.com/chengjunhou/xgb2sql,19111,21,2022-03-16T21:15:59Z,910.047619047619
XLS,"Given the date column as an ascending entry, future errors are included in the sum of squares of error that should be minimized based on the number of steps and weights you determine. Thus, it is prevented that the variables affect each other's coefficients unrealistically.",2022-03-10,Samet Sokel,NA,TRUE,https://github.com/sametsoekel/extreme-least-squares,3702,0,2022-03-26T12:43:38Z,NA
xlsx,Provide R functions to read/write/format Excel 2007 and Excel 97/2000/XP/2003 file formats.,2020-11-10,Cole Arendt,https://github.com/colearendt/xlsx,TRUE,https://github.com/colearendt/xlsx,4650564,78,2022-01-30T09:30:59Z,59622.61538461538
xml2,"Work with XML files using a simple, consistent
    interface. Built on top of the 'libxml2' C library.",2021-11-30,Hadley Wickham,"https://xml2.r-lib.org/, https://github.com/r-lib/xml2",TRUE,https://github.com/r-lib/xml2,18633292,198,2022-02-28T20:24:54Z,94107.53535353535
xml2relational,"Import an XML document with nested object structures and convert
    it into a relational data model. The result is a set of R dataframes 
    with foreign key relationships. The data model and the data can be exported as
    SQL code of different SQL flavors.",2022-02-10,Joachim Zuckarelli,https://github.com/jsugarelli/xml2relational/,TRUE,https://github.com/jsugarelli/xml2relational,7845,6,2022-02-10T19:03:31Z,1307.5
xmlr,"'XML' package for creating and reading and manipulating 'XML', with an object model based on 'Reference Classes'.",2020-05-12,Per Nyfelt,https://github.com/Alipsa/xmlr,TRUE,https://github.com/alipsa/xmlr,7998,7,2022-03-06T16:58:55Z,1142.5714285714287
xoi,"Analysis of crossover interference in experimental crosses,
    particularly regarding the gamma model. See, for example,
    Broman and Weber (2000) <doi:10.1086/302923>.",2022-01-21,Karl W Broman,https://github.com/kbroman/xoi,TRUE,https://github.com/kbroman/xoi,15365,3,2022-01-21T17:07:21Z,5121.666666666667
xpectr,"Helps systematize and ease the process of 
    building unit tests with the 'testthat' package by providing 
    tools for generating expectations.",2022-01-20,Ludvig Renbo Olsen,https://github.com/ludvigolsen/xpectr,TRUE,https://github.com/ludvigolsen/xpectr,19508,29,2022-01-19T23:53:16Z,672.6896551724138
xportr,Tools to build CDISC compliant data sets and check for CDISC compliance.,2022-06-21,Eli Miller,https://github.com/atorus-research/xportr,TRUE,https://github.com/atorus-research/xportr,217,16,2022-07-01T20:17:34Z,13.5625
xpose4,"A model building aid for nonlinear mixed-effects 
    (population) model analysis using NONMEM, facilitating data set 
    checkout, exploration and visualization, model diagnostics, candidate 
    covariate identification and model comparison. The methods are described 
    in Keizer et al. (2013) <doi:10.1038/psp.2013.24>, and Jonsson et al. (1999) 
    <doi:10.1016/s0169-2607(98)00067-4>.",2022-05-31,Andrew C. Hooker,"https://uupharmacometrics.github.io/xpose4/,
https://github.com/UUPharmacometrics/xpose4",TRUE,https://github.com/uupharmacometrics/xpose4,28767,23,2022-05-31T08:10:30Z,1250.7391304347825
xQTLbiolinks,"User can query, download, and visualize of molecular quantitative trait locus and gene expression data from public resources through the application programming interface <https://gtexportal.org/home/api-docs/index.html> of 'GTEx'. ",2022-06-28,Ruofan Ding,https://github.com/dingruofan/xQTLbiolinks,TRUE,https://github.com/dingruofan/xqtlbiolinks,149,2,2022-06-29T03:19:51Z,74.5
xrf,"An implementation of the RuleFit algorithm as described in Friedman & Popescu 
  (2008) <doi:10.1214/07-AOAS148>. eXtreme Gradient Boosting ('XGBoost') is used 
  to build rules, and 'glmnet' is used to fit a sparse linear model on the raw and rule features. The result
  is a model that learns similarly to a tree ensemble, while often offering improved interpretability
  and achieving improved scoring runtime in live applications. Several algorithms for
  reducing rule complexity are provided, most notably hyperrectangle de-overlapping. All algorithms scale to 
  several million rows and support sparse representations to handle tens of thousands of dimensions.",2022-03-31,Karl Holub,https://github.com/holub008/xrf,TRUE,https://github.com/holub008/xrf,35957,39,2022-06-09T03:47:01Z,921.974358974359
xSub,"Tools to download and merge data files on sub-national conflict, violence and protests from <http://www.x-sub.org>.",2022-06-30,Yuri Zhukov,https://github.com/zhukovyuri/xSub,TRUE,https://github.com/zhukovyuri/xsub,13536,1,2022-06-30T16:26:34Z,13536
xts,"Provide for uniform handling of R's different time-based data classes by extending zoo, maximizing native format information preservation and allowing for user level customization and extension, while simplifying cross-class interoperability.",2020-09-09,Joshua M. Ulrich,https://github.com/joshuaulrich/xts,TRUE,https://github.com/joshuaulrich/xts,11739920,193,2022-06-13T14:00:46Z,60828.60103626943
xutils,"This is a collection of some useful functions when dealing with text data. 
    Currently it only contains a very efficient function of decoding HTML entities
    in character vectors by 'Rcpp' routine.",2021-09-06,Fangzhou Xie,"https://github.com/fangzhou-xie/xutils,
https://fangzhou-xie.github.io/xutils/index.html",TRUE,https://github.com/fangzhou-xie/xutils,5231,1,2021-11-19T20:07:19Z,5231
yaConsensus,"Procedures to perform consensus clustering starting from a dissimilarity matrix or a data matrix. It's allowed to select if the subsampling has to be by samples or features. In case of computational heavy load, the procedures can run in parallel.",2021-07-01,Stefano Maria Pagnotta,https://github.com/stefanoMP/yaConsensus,TRUE,https://github.com/stefanomp/yaconsensus,2303,0,2021-09-03T10:51:45Z,NA
yaml,"Implements the 'libyaml' 'YAML' 1.1 parser and emitter
  (<https://pyyaml.org/wiki/LibYAML>) for R.",2022-02-21,Jeremy Stephens,https://github.com/vubiostat/r-yaml/,TRUE,https://github.com/vubiostat/r-yaml,20008300,129,2022-02-19T02:41:45Z,155103.1007751938
yamlet,"A YAML-based
 mechanism for working with table metadata. Supports
 compact syntax for creating, modifying, viewing, exporting,
 importing, displaying, and plotting metadata coded as column 
 attributes. The 'yamlet' dialect is valid 'YAML' with
 defaults and conventions chosen to improve readability. 
 See ?yamlet, ?decorate.data.frame and ?modify.default.
 See ?read_yamlet ?write_yamlet, ?io_csv, and ?ggplot.decorated.",2022-04-18,Tim Bergsma,NA,TRUE,https://github.com/bergsmat/yamlet,19184,1,2022-07-05T12:14:40Z,19184
yamlme,"Setting layout through 'YAML' headers in 'R-Markdown' documents,
    enabling their automatic generation.
    Functions and methods may summarize 'R' objects in automatic reports, for
    instance check-lists and further reports applied to the packages 'taxlist'
    and 'vegtable'.",2021-01-06,Miguel Alvarez,"https://github.com/kamapu/yamlme,
https://kamapu.github.io/rpkg/yamlme/",TRUE,https://github.com/kamapu/yamlme,6284,1,2022-06-06T11:52:12Z,6284
yardstick,"Tidy tools for quantifying how well model fits to a data set
    such as confusion matrices, class probability curve summaries, and
    regression metrics (e.g., RMSE).",2022-06-06,Davis Vaughan,"https://github.com/tidymodels/yardstick,
https://yardstick.tidymodels.org",TRUE,https://github.com/tidymodels/yardstick,1050856,312,2022-06-06T20:37:44Z,3368.128205128205
yarr,"A parser and a writer for 'WEKA' Attribute-Relation File Format
    <https://waikato.github.io/weka-wiki/arff_stable/> in pure R, with no dependencies. 
    As opposed to other R implementations, this package can read standard
    (dense) as well as sparse files, i.e. those where each row does only contain 
    nonzero components. Unlike 'RWeka', 'yarr' does not require any 'Java' installation
    nor is dependent on external software. This implementation is generalized from 
    those in packages 'mldr' and 'mldr.datasets'.",2019-08-10,David Charte,https://github.com/fdavidcl/yarr,TRUE,https://github.com/fdavidcl/yarr,11578,0,2022-05-26T18:51:37Z,NA
yatah,"Provides functions to manage taxonomy when lineages
    are described with strings and ranks separated with special patterns
    like ""|*__"" or "";*__"".",2020-03-01,Antoine Bichat,"https://github.com/abichat/yatah, https://abichat.github.io/yatah",TRUE,https://github.com/abichat/yatah,10561,6,2022-03-20T16:56:36Z,1760.1666666666667
ycevo,"Nonparametric estimation of the discount rate and yield curve. 
    Koo, B., La Vecchia, D., & Linton, O. B. (2021) <doi:10.1016/j.jeconom.2020.04.014> 
    describe the application with the Center for Research in Security Prices (CRSP) Bond Data 
    and document the methods of this package.",2022-06-28,Yangzhuoran Fin Yang,https://github.com/bonsook/ycevo,TRUE,https://github.com/bonsook/ycevo,450,3,2022-06-28T08:23:07Z,150
yesno,Asks Yes-No questions with variable or custom responses.,2020-07-10,Joe Thorley,https://github.com/poissonconsulting/yesno,TRUE,https://github.com/poissonconsulting/yesno,53817,7,2021-11-17T23:54:17Z,7688.142857142857
yfR,"Facilitates download of financial data from Yahoo Finance <https://finance.yahoo.com/>, 
 a vast repository of stock price data across multiple financial exchanges. The package offers a local caching system
 and support for parallel computation.",2022-06-30,Marcelo Perlin,"https://github.com/ropensci/yfR, https://docs.ropensci.org/yfR/",TRUE,https://github.com/ropensci/yfr,227,17,2022-07-01T11:40:22Z,13.352941176470589
ymd,"Convert 'YMD' format number or string to Date efficiently, using Rust's
    standard library. It also provides helper functions to handle Date, e.g., quick
    finding the beginning or ending of the given period, adding months to Date, etc.",2022-01-06,Xianying Tan,"https://shrektan.github.io/ymd/, https://github.com/shrektan/ymd",TRUE,https://github.com/shrektan/ymd,1664,26,2022-03-19T12:32:05Z,64
ymlthis,"Write 'YAML' front matter for R Markdown and related
    documents. Work with 'YAML' objects more naturally and write the
    resulting 'YAML' to your clipboard or to 'YAML' files related to your
    project.",2022-06-24,Malcolm Barrett,"https://ymlthis.r-lib.org, https://github.com/r-lib/ymlthis",TRUE,https://github.com/r-lib/ymlthis,26123,154,2022-06-24T23:23:08Z,169.62987012987014
yonder,"Build 'shiny' applications with the latest Bootstrap components
    and design utilities. Includes refreshed reactive inputs and outputs.
    Use responsive layouts to design and construct applications for devices
    of all sizes.",2020-01-10,Nathan Teetor,https://nteetor.github.io/yonder,TRUE,https://github.com/nteetor/yonder,11542,130,2022-06-05T02:37:54Z,88.78461538461538
yorkr,"Analyzing performances of cricketers and cricket teams
             based on 'yaml' match data from Cricsheet <https://cricsheet.org/>.",2022-06-11,Tinniam V Ganesh,https://github.com/tvganesh/yorkr/,TRUE,https://github.com/tvganesh/yorkr,21895,14,2022-04-17T04:28:03Z,1563.9285714285713
youngSwimmers,Dataset from the young elite swimmers study.,2022-02-14,Matías Castillo Aguilar,"https://github.com/NIM-ACh/youngSwimmers/,
https://nim-ach.github.io/youngSwimmers/",TRUE,https://github.com/nim-ach/youngswimmers,1025,0,2022-02-25T03:51:13Z,NA
yowie,Longitudinal wages data sets and several demographic variables from the National Longitudinal Survey of Youth from 1979 to 2018. There are three data sets in this package: The wages data from the cohort whose highest grade completed is up to high school; The wages data of the high school dropouts and; The demographic data of the cohort in the survey year 1979.,2021-09-06,Dewi Amaliah,https://github.com/numbats/yowie,TRUE,https://github.com/numbats/yowie,3261,1,2022-06-07T04:14:23Z,3261
ypr,"An implementation of equilibrium-based yield per recruit
    methods.  Yield per recruit methods can used to estimate the optimal
    yield for a fish population as described by Walters and Martell (2004)
    <isbn:0-691-11544-3>.  The yield can be based on the number of fish
    caught (or harvested) or biomass caught for all fish or just large
    (trophy) individuals.",2021-07-03,Joe Thorley,https://github.com/poissonconsulting/ypr,TRUE,https://github.com/poissonconsulting/ypr,15124,6,2022-05-03T14:57:54Z,2520.6666666666665
zCompositions,"Principled methods for the imputation of zeros, left-censored and missing data in
    compositional data sets (Palarea-Albaladejo and Martin-Fernandez (2015) <doi:10.1016/j.chemolab.2015.02.019>).",2022-03-26,Javier Palarea-Albaladejo,https://github.com/Japal/zCompositions,TRUE,https://github.com/japal/zcompositions,166001,1,2022-03-26T18:08:13Z,166001
zdeskR,"Facilitates making a connection to the 
  'Zendesk' API and executing various queries. You can use it to
  get ticket data and ticket metrics. The 'Zendesk' documentation is 
  available at <https://developer.zendesk.com/rest_api
  /docs/support/introduction>. This package is not supported by 
  'Zendesk' (owner of the software).",2022-03-16,Chris Umphlett,https://github.com/chrisumphlett/zdeskR,TRUE,https://github.com/chrisumphlett/zdeskr,16406,1,2022-04-26T18:31:10Z,16406
zebu,"Implements the estimation of local (and global) association measures: Lewontin's D, Ducher's Z, pointwise mutual information, normalized pointwise mutual information and chi-squared residuals. The significance of local (and global) association is accessed using p-values estimated by permutations.",2022-04-17,Olivier M. F. Martin,https://github.com/oliviermfmartin/zebu,TRUE,https://github.com/oliviermfmartin/zebu,14847,0,2022-04-17T10:30:39Z,NA
zen4R,"Provides an Interface to 'Zenodo' (<https://zenodo.org>) REST API, 
  including management of depositions, attribution of DOIs by 'Zenodo' and 
  upload and download of files.",2022-06-17,Emmanuel Blondel,https://github.com/eblondel/zen4R,TRUE,https://github.com/eblondel/zen4r,18302,33,2022-07-05T06:19:10Z,554.6060606060606
zenplots,"Graphical tools for visualizing high-dimensional data along a path
 of alternating one- and two-dimensional plots. Note that this
 includes interactive graphics plots based on 'loon' in turn based on 'tcltk'
 (included as part of the standard R distribution).  It also requires 'graph' from Bioconductor.
 For more detail on use and algorithms, see <doi:10.18637/jss.v095.i04>.",2021-09-08,Wayne Oldford,https://github.com/great-northern-diver/zenplots,TRUE,https://github.com/great-northern-diver/zenplots,12232,2,2021-09-08T18:29:06Z,6116
zfit,"The goal of 'zfit' is to improve the usage of basic 
  model fitting functions within a piped work flow, in particular 
  when passing and processing a data.frame using 'dplyr' or 
  similar packages.",2022-01-17,Magnus Thor Torfason,"https://torfason.github.io/zfit/, https://github.com/torfason/zfit",TRUE,https://github.com/torfason/zfit,6647,1,2022-01-31T14:20:52Z,6647
zipangu,"Some data treated by the Japanese R user require
    unique operations and processing. These are caused by address, Kanji,
    and traditional year representations. 'zipangu' transforms specific
    to Japan into something more general one.",2022-03-11,Shinya Uryu,"https://uribo.github.io/zipangu/, https://github.com/uribo/zipangu",TRUE,https://github.com/uribo/zipangu,19418,46,2022-05-23T02:53:38Z,422.1304347826087
zipcodeR,"Make working with ZIP codes in R painless with an integrated dataset of U.S. ZIP codes and functions for working with them. 
             Search ZIP codes by multiple geographies, including state, county, city & across time zones. Also included are functions for relating
             ZIP codes to Census data, geocoding & distance calculations.",2022-06-25,Gavin Rozzi,"https://github.com/gavinrozzi/zipcodeR/,
https://www.gavinrozzi.com/project/zipcoder/",TRUE,https://github.com/gavinrozzi/zipcoder,40571,62,2022-06-25T01:02:18Z,654.3709677419355
zmisc,"A collection of utility functions that facilitate 
  looking up vector values from a lookup  table, and support a 
  safer approach to vector  sampling, sequence generation, 
  and aggregation. ",2022-04-29,Magnus Thor Torfason,"https://github.com/torfason/zmisc/,
https://torfason.github.io/zmisc/",TRUE,https://github.com/torfason/zmisc,1317,0,2022-04-29T17:43:42Z,NA
zoid,Fits Dirichlet regression and zero-and-one inflated Dirichlet regression with Bayesian methods implemented in Stan. These models are sometimes referred to as trinomial mixture models; covariates and overdispersion can optionally be included.,2022-02-09,Eric J. Ward,https://nwfsc-cb.github.io/zoid/,TRUE,https://github.com/nwfsc-cb/zoid,2155,3,2022-02-10T20:03:21Z,718.3333333333334
zoltr,"'Zoltar' <https://www.zoltardata.com/> is a website that provides a repository of model forecast results
    in a standardized format and a central location. It supports storing, retrieving, comparing, and analyzing time
    series forecasts for prediction challenges of interest to the modeling community. This package provides functions
    for working with the 'Zoltar' API, including connecting and authenticating, getting information about projects,
    models, and forecasts, deleting and uploading forecast data, and downloading scores.",2020-04-15,Matthew Cornell,"https://github.com/reichlab/zoltr , http://reichlab.io/zoltr/",TRUE,https://github.com/reichlab/zoltr,13330,1,2022-04-04T13:54:02Z,13330
zonebuilder,"Functions, documentation and example data to help divide
    geographic space into discrete polygons (zones).
    The functions are motivated by research into the merits of different zoning systems
    <doi:10.1068/a090169>. A flexible 'ClockBoard' zoning system is
    provided, which breaks-up space by concentric rings
    and radial lines emanating from a central point.
    By default, the diameter of the rings grow according the triangular number sequence
    <doi:10.1080/26375451.2019.1598687> with the first 4 'doughnuts'
    (or 'annuli') measuring 1, 3, 6, and 10 km wide.
    These annuli are subdivided into equal segments (12 by default), creating the
    visual impression of a dartboard. Zones are labelled according to
    distance to the centre and angular distance from North, creating a simple
    geographic zoning and labelling system useful for visualising geographic
    phenomena with a clearly demarcated central location such as cities.",2021-07-12,Robin Lovelace,"https://github.com/zonebuilders/zonebuilder,
https://zonebuilders.github.io/zonebuilder/",TRUE,https://github.com/zonebuilders/zonebuilder,5511,29,2021-11-23T18:14:29Z,190.0344827586207
ztable,"Makes zebra-striped tables (tables with alternating row colors)
    in LaTeX and HTML formats easily from a data.frame, matrix, lm, aov, anova,
    glm, coxph, nls, fitdistr, mytable and cbind.mytable objects.",2021-09-28,Keon-Woong Moon,https://github.com/cardiomoon/ztable,TRUE,https://github.com/cardiomoon/ztable,114437,21,2021-09-28T00:25:51Z,5449.380952380952
ztpln,"Functions for obtaining the density, random variates
             and maximum likelihood estimates of the Zero-truncated Poisson lognormal
             distribution and their mixture distribution.",2021-10-09,Masatoshi Katabuchi,https://github.com/mattocci27/ztpln,TRUE,https://github.com/mattocci27/ztpln,8082,0,2021-10-09T15:06:26Z,NA
