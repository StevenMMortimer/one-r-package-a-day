name,description,published,author,url,github_ind,github_url,downloads,stars,last_commit
abbyyR,"Get text from images of text using Abbyy Cloud Optical Character
    Recognition (OCR) API. Easily OCR images, barcodes, forms, documents with
    machine readable zones, e.g. passports. Get the results in a variety of formats
    including plain text and XML. To learn more about the Abbyy OCR API, see 
    <http://ocrsdk.com/>.",2018-05-30,Gaurav Sood,http://github.com/soodoku/abbyyR,TRUE,https://github.com/soodoku/abbyyr,25953,36,1549384577
ABCoptim,"An implementation of Karaboga (2005) Artificial Bee Colony
    Optimization algorithm <http://mf.erciyes.edu.tr/abc/pub/tr06_2005.pdf>.
    This (working) version is a Work-in-progress, which is
    why it has been implemented using pure R code. This was developed upon the basic
    version programmed in C and distributed at the algorithm's official website.",2017-11-06,George Vega Yon,"http://github.com/gvegayon/ABCoptim, http://mf.erciyes.edu.tr/abc/",TRUE,https://github.com/gvegayon/abcoptim,27147,16,1531033423
abctools,Tools for approximate Bayesian computation including summary statistic selection and assessing coverage.,2018-07-17,Matt Nunes,https://github.com/dennisprangle/abctools,TRUE,https://github.com/dennisprangle/abctools,130057,5,1531835371
ABHgenotypeR,"Easy to use functions to visualize marker data
    from biparental populations. Useful for both analyzing and
    presenting genotypes in the ABH format.",2016-02-04,Stefan Reuscher,http://github.com/StefanReuscher/ABHgenotypeR,TRUE,https://github.com/stefanreuscher/abhgenotyper,12634,4,1528676655
abjutils,"The Brazilian Jurimetrics Association (ABJ in
    Portuguese, see <http://www.abjur.org.br/en/> for more information) is
    a non-profit organization which aims to investigate and promote the
    use of statistics and probability in the study of Law and its
    institutions.  This package implements general purpose tools used by
    ABJ, such as functions for sampling and basic manipulation of
    Brazilian lawsuits identification number. It also implements functions
    for text cleaning, such as accentuation removal.",2019-02-07,Caio Lente,https://github.com/abjur/abjutils,TRUE,https://github.com/abjur/abjutils,10232,11,1551129780
ACMEeqtl,"We use a non-linear model, termed ACME,
        that reflects a parsimonious biological model for
        allelic contributions of cis-acting eQTLs.
        With non-linear least-squares algorithm we
        estimate maximum likelihood parameters. The ACME model
        provides interpretable effect size estimates and
        p-values with well controlled Type-I error.
        Includes both R and (much faster) C implementations.
        For more details see Palowitch et al. (2017) <doi:10.1111/biom.12810>.",2018-03-06,Andrey A Shabalin  (<https://orcid.org/0000-0003-0309-6821>),https://github.com/andreyshabalin/ACMEeqtl,TRUE,https://github.com/andreyshabalin/acmeeqtl,8925,0,1550594311
adapr,"Tracks reading and writing within R scripts that are organized into
    a directed acyclic graph. Contains an interactive shiny application adaprApp().
    Uses git2r package, Git and file hashes to track version histories of input
    and output. See package vignette for how to get started. V1.02 adds parallel
    execution of project scripts and function map in vignette. Makes project
    specification argument last in order. V2.0 adds project specific libraries, packrat option, and adaprSheet().",2017-11-30,Jon Gelfond,NA,TRUE,https://github.com/gelfondjal/adapr,10871,8,1553178019
adaptMCMC,Enables sampling from arbitrary distributions if the log density is known up to a constant; a common situation in the context of Bayesian inference. The implemented sampling algorithm was proposed by Vihola (2012) <DOI:10.1007/s11222-011-9269-5> and achieves often a high efficiency by tuning the proposal distributions to a user defined acceptance rate.,2018-01-14,Andreas Scheidegger,https://github.com/scheidan/adaptMCMC,TRUE,https://github.com/scheidan/adaptmcmc,25336,6,1547481671
adaptMT,"Implementation of adaptive p-value thresholding (AdaPT), including both a framework that allows the user to specify any 
  algorithm to learn local false discovery rate and a pool of convenient functions that implement specific 
  algorithms. See Lei, Lihua and Fithian, William (2016) <arXiv:1609.06035>.",2018-07-31,Lihua Lei,"https://arxiv.org/abs/1609.06035,
https://github.com/lihualei71/adaptMT",TRUE,https://github.com/lihualei71/adaptmt,3029,6,1541176886
AdaSampling,"Implements the adaptive sampling procedure, a framework for both positive unlabeled learning and learning with class label noise. Yang, P., Ormerod, J., Liu, W., Ma, C., Zomaya, A., Yang, J. (2018) <doi:10.1109/TCYB.2018.2816984>.",2018-06-27,Pengyi Yang & Dinuka Perera,https://github.com/PengyiYang/AdaSampling/,TRUE,https://github.com/pengyiyang/adasampling,4273,4,1530146361
addinslist,"Browse through a continuously updated list of existing RStudio 
    addins and install/uninstall their corresponding packages.",2016-09-29,Dean Attali,https://github.com/daattali/addinslist,TRUE,https://github.com/daattali/addinslist,25213,450,1545104433
ade4,"Tools for multivariate data analysis. Several methods are provided for the analysis (i.e., ordination) of one-table (e.g., principal component analysis, correspondence analysis), two-table (e.g., coinertia analysis, redundancy analysis), three-table (e.g., RLQ analysis) and K-table (e.g., STATIS, multiple coinertia analysis). The philosophy of the package is described in Dray and Dufour (2007) <doi:10.18637/jss.v022.i04>.",2018-08-31,Stéphane Dray <stephane.dray@univ-lyon1.fr>,"http://pbil.univ-lyon1.fr/ADE-4, Mailing list:
http://listes.univ-lyon1.fr/wws/info/adelist",TRUE,https://github.com/sdray/ade4,1087403,8,1539853609
adegenet,"Toolset for the exploration of genetic and genomic data. Adegenet
    provides formal (S4) classes for storing and handling various genetic data,
    including genetic markers with varying ploidy and hierarchical population
    structure ('genind' class), alleles counts by populations ('genpop'), and
    genome-wide SNP data ('genlight'). It also implements original multivariate
    methods (DAPC, sPCA), graphics, statistical tests, simulation tools, distance
    and similarity measures, and several spatial methods. A range of both empirical
    and simulated datasets is also provided to illustrate various methods.",2018-02-02,Thibaut Jombart,https://github.com/thibautjombart/adegenet,TRUE,https://github.com/thibautjombart/adegenet,205368,69,1549425918
adegraphics,Graphical functionalities for the representation of multivariate data. It is a complete re-implementation of the functions available in the 'ade4' package.,2018-12-18,Stéphane Dray <stephane.dray@univ-lyon1.fr> and Aurélie Siberchicot <aurelie.siberchicot@univ-lyon1.fr>,"http://pbil.univ-lyon1.fr/ADE-4, Mailing list:
http://listes.univ-lyon1.fr/wws/info/adelist",TRUE,https://github.com/sdray/adegraphics,82848,5,1553534056
AdhereR,"Computation of adherence to medications from Electronic Health care 
    Data and visualization of individual medication histories and adherence 
    patterns. The package implements a set of S3 classes and
    functions consistent with current adherence guidelines and definitions. 
    It allows the computation of different measures of
    adherence (as defined in the literature, but also several original ones), 
    their publication-quality plotting,
    the estimation of event duration and time to initiation,
    the interactive exploration of patient medication history and 
    the real-time estimation of adherence given various parameter settings.
    It scales from very small datasets stored in flat CSV files to very large 
    databases and from single-thread processing on mid-range consumer
    laptops to parallel processing on large heterogeneous computing clusters.
    It exposes a standardized interface allowing it to be used from other
    programming languages and platforms, such as Python.",2019-02-11,Dan Dediu,https://github.com/ddediu/AdhereR,TRUE,https://github.com/ddediu/adherer,10205,11,1549891268
adjclust,"Implements a constrained version of hierarchical agglomerative 
    clustering, in which each observation is associated to a position, and 
    only adjacent clusters can be merged. Typical application fields in 
    bioinformatics include Genome-Wide Association Studies or Hi-C data 
    analysis, where the similarity between items is a decreasing function of 
    their genomic distance. Taking advantage of this feature, the implemented 
    algorithm is time and memory efficient. This algorithm is described in 
    Chapter 4 of Alia Dehman (2015) 
    <https://hal.archives-ouvertes.fr/tel-01288568v1>.",2018-09-26,Pierre Neuvial,https://github.com/pneuvial/adjclust,TRUE,https://github.com/pneuvial/adjclust,5695,10,1541523365
ADMMsigma,"Estimates a penalized precision matrix via the alternating direction method of multipliers (ADMM) algorithm. It currently supports a general elastic-net penalty that allows for both ridge and lasso-type penalties as special cases. This package is an alternative to the 'glasso' package.
    See Boyd et al (2010) <doi:10.1561/2200000016> for details regarding the estimation method.",2018-08-02,Matt Galloway,https://github.com/MGallow/ADMMsigma,TRUE,https://github.com/mgallow/admmsigma,5984,2,1533172670
adnuts,"Bayesian inference using the no-U-turn (NUTS) algorithm by 
 Hoffman and Gelman (2014) <http://www.jmlr.org/papers/v15/hoffman14a.html>. 
 Designed for 'AD Model Builder' ('ADMB') models,
 or when R functions for log-density and log-density gradient
 are available, such as 'Template Model Builder' ('TMB')
 models and other special cases. Functionality is similar to 'Stan', 
 and the 'rstan' and 'shinystan' packages are used for diagnostics and 
 inference.",2019-04-04,Cole Monnahan,https://github.com/colemonnahan/adnuts,TRUE,https://github.com/colemonnahan/adnuts,3904,12,1554391527
adoptr,"Optimize one or two-arm, two-stage designs for clinical trials with respect to several 
    pre-implemented objective criteria or implement custom objectives.
    Optimization under uncertainty and conditional (given stage-one outcome) constraints are supported.",2019-04-01,Kevin Kunzmann,https://github.com/kkmann/adoptr,TRUE,https://github.com/kkmann/adoptr,389,2,1554300504
adpss,"Provides the functions for planning and conducting a
  clinical trial with adaptive sample size determination. Maximal statistical
  efficiency will be exploited even when dramatic or multiple adaptations
  are made. Such a trial consists of adaptive determination of sample size
  at an interim analysis and implementation of frequentist statistical test at the
  interim and final analysis with a prefixed significance level. The required
  assumptions for the stage-wise test statistics are independent and stationary
  increments and normality. Predetermination of adaptation rule is not required.",2018-09-20,Kosuke Kashiwabara,https://github.com/ca4wa/R-adpss,TRUE,https://github.com/ca4wa/r-adpss,3114,0,1537434072
afex,"Convenience functions for analyzing factorial experiments using ANOVA or
         mixed models. aov_ez(), aov_car(), and aov_4() allow specification of
         between, within (i.e., repeated-measures), or mixed (i.e., split-plot) 
         ANOVAs for data in long format (i.e., one observation per row),
         automatically aggregating multiple observations per individual and cell 
         of the design. mixed() fits mixed models using lme4::lmer() and computes 
         p-values for all fixed effects using either Kenward-Roger or Satterthwaite 
         approximation for degrees of freedom (LMM only), parametric bootstrap 
         (LMMs and GLMMs), or likelihood ratio tests (LMMs and GLMMs). 
         afex_plot() provides a high-level interface for interaction or one-way 
         plots using ggplot2, combining raw data and model estimates. afex uses 
         type 3 sums of squares as default (imitating commercial statistical software).",2019-02-19,Henrik Singmann  (<https://orcid.org/0000-0002-4842-3657>),"http://afex.singmann.science/, https://github.com/singmann/afex",TRUE,https://github.com/singmann/afex,124129,51,1553249597
aftgee,"A collection of methods for both the rank-based estimates and least-square estimates
	      to the Accelerated Failure Time (AFT) model.
	      For rank-based estimation, it provides approaches that include the computationally
	      efficient Gehan's weight and the general's weight such as the logrank weight.
	      Details of the rank-based estimation can be found in
	      Chiou et al. (2014) <doi:10.1007/s11222-013-9388-2> and
	      Chiou et al. (2015) <doi:10.1002/sim.6415>.
	      For the least-square estimation, the estimating equation is solved with
	      generalized estimating equations (GEE).
	      Moreover, in multivariate cases, the dependence working correlation structure
	      can be specified in GEE's setting.
	      Details on the least-squares estimation can be found in
	      Chiou et al. (2014) <doi:10.1007/s10985-014-9292-x>.",2018-07-24,Sy Han Chiou,http://github.com/stc04003/aftgee,TRUE,https://github.com/stc04003/aftgee,28456,0,1545867174
AGD,"Tools for the analysis of growth data: to extract an 
    LMS table from a gamlss object, to calculate the standard 
    deviation scores and its inverse, and to superpose two wormplots 
    from different models. The package contains a some varieties of 
    reference tables, especially for The Netherlands.",2018-05-29,Stef van Buuren <stef.vanbuuren@tno.nl>,https://github.com/stefvanbuuren/AGD,TRUE,https://github.com/stefvanbuuren/agd,87381,1,1527715724
AGHmatrix,"Computation of A (pedigree), G (genomic-base), and H (A corrected
    by G) relationship matrices for diploid and autopolyploid species. Several methods
    are implemented considering additive and non-additive models.",2019-03-26,Rodrigo Amadeu,http://github.com/prmunoz/AGHmatrix,TRUE,https://github.com/prmunoz/aghmatrix,4100,1,1553206261
agop,"Tools supporting multi-criteria and group decision making,
    including variable number of criteria, by means of
    aggregation operators, spread measures,
    fuzzy logic connectives, fusion functions,
    and preordered sets. Possible applications include,
    but are not limited to, quality management, scientometrics,
    software engineering, etc.",2019-03-08,Marek Gagolewski,http://www.gagolewski.com/software/,TRUE,https://github.com/gagolews/agop,19318,3,1552474311
AGread,"Standardize the process of bringing various modes of output files
    into R. For more information, see:
    <https://actigraph.desk.com/customer/en/portal/articles/2515800-what-do-the-different-mode-numbers-mean-in-a-csv-or-dat-file->.
    Additionally, processes are provided to read and minimally pre-
    process raw data from primary accelerometer and inertial measurement unit files,
    as well as binary .gt3x files. ActiGraph monitors are used to estimate physical
    activity outcomes via body-worn sensors that measure (e.g.) acceleration or
    rotational velocity.",2019-03-13,Paul R. Hibbing,https://github.com/paulhibbing/AGread,TRUE,https://github.com/paulhibbing/agread,4814,1,1552529341
agridat,"Datasets from books, papers, and websites related to agriculture.
    Example graphics and analyses are included. Data come from small-plot trials,
    multi-environment trials, uniformity trials, yield monitors, and more.",2018-07-06,Kevin Wright  (<https://orcid.org/0000-0002-0617-8673>),https://github.com/kwstat/agridat,TRUE,https://github.com/kwstat/agridat,41094,47,1554409853
agriwater,"Spatial modeling of energy balance and actual 
    evapotranspiration using satellite images and meteorological data. 
    Options of satellite are: Landsat-8 (with and without thermal bands), 
    Sentinel-2 and MODIS. Respectively spatial resolutions are 30, 100, 
    10 and 250 meters. User can use data from a single meteorological 
    station or a grid of meteorological stations (using any spatial 
    interpolation method). Teixeira (2010) <doi:10.3390/rs0251287>. 
    Teixeira et al. (2015) <doi:10.3390/rs71114597>.
    Silva, Manzione, and Albuquerque Filho (2018) <doi:10.3390/horticulturae4040044>.",2019-01-30,"Cesar de Oliveira Ferreira Silva 
    (<https://orcid.org/0000-0002-5152-6497>)",NA,TRUE,https://github.com/cesarofs/agriwater,846,1,1547247824
ahnr,"Implementation of the Artificial Hydrocarbon Networks for data
    modeling.",2018-06-18,Jose Roberto Ayala Solares,https://github.com/jroberayalas/ahnr,TRUE,https://github.com/jroberayalas/ahnr,7370,1,1532034689
aire.zmvm,"Tools for downloading hourly averages, daily maximums and minimums from each of the 
    pollution, wind, and temperature measuring stations or geographic zones in the Mexico City 
    metro area. The package also includes the locations of each of the stations and zones. See 
    <http://aire.cdmx.gob.mx/> for more information.",2019-03-30,Diego Valle-Jones,"https://hoyodesmog.diegovalle.net/aire.zmvm/,
https://github.com/diegovalle/aire.zmvm",TRUE,https://github.com/diegovalle/aire.zmvm,8810,5,1554405358
airportr,"Retrieves open source airport data and provides tools to look up information, translate names into codes and vice-verse, as well as some basic calculation functions for measuring distances.",2018-10-06,Dmitry Shkolnik,https://github.com/dshkol/airportr,TRUE,https://github.com/dshkol/airportr,2256,4,1538849707
airr,"Schema definitions and read, write and validation tools for data 
    formatted in accordance with the AIRR Data Representation schemas defined 
    by the AIRR Community <http://docs.airr-community.org>.",2018-08-17,Jason Vander Heiden,http://docs.airr-community.org,TRUE,https://github.com/airr-community/airr-standards,3887,10,1554392190
ALA4R,"The Atlas of Living Australia (ALA) provides tools to enable users
    of biodiversity information to find, access, combine and visualise data on
    Australian plants and animals; these have been made available from
    <https://ala.org.au/>. ALA4R provides a subset of the tools to be
    directly used within R. It enables the R community to directly access data
    and resources hosted by the ALA.",2019-04-02,Peggy Newman,https://github.com/AtlasOfLivingAustralia/ALA4R,TRUE,https://github.com/atlasoflivingaustralia/ala4r,12430,29,1554182431
albopictus,Implements discrete time deterministic and stochastic age-structured population dynamics models described in Erguler and others (2016) <doi:10.1371/journal.pone.0149282> and Erguler and others (2017) <doi:10.1371/journal.pone.0174293>.,2018-11-29,Kamil Erguler,https://github.com/kerguler/albopictusR,TRUE,https://github.com/kerguler/albopictusr,7574,0,1549446934
alfred,"Provides direct access to the ALFRED (<https://alfred.stlouisfed.org>) and FRED (<https://fred.stlouisfed.org>) databases.
    Its functions return tidy data frames for different releases of the specified time series. 
    Note that this product uses the FRED© API but is not endorsed or certified by the Federal Reserve Bank of St. Louis.",2019-04-01,Onno Kleen  (<https://orcid.org/0000-0003-4731-4640>),https://github.com/onnokleen/alfred/,TRUE,https://github.com/onnokleen/alfred,13415,6,1554108449
alignfigR,"Create extensible figures of multiple sequence alignments, using the 'ggplot2' plotting engine. 'alignfigr' will create a baseline figure of a multiple sequence alignment which can be fully customized to the user's liking with standard 'ggplot2' features.",2018-07-05,Stephanie J. Spielman,https://github.com/sjspielman/alignfigR,TRUE,https://github.com/sjspielman/alignfigr,3017,6,1532355701
alpaca,"Provides a routine to concentrate out factors with many levels during the
  optimization of the log-likelihood function of the corresponding generalized linear model (glm).
  The package is based on the algorithm proposed by Stammann (2018) <arXiv:1707.01815> and is
  restricted to glm's that are based on maximum likelihood estimation and non-linear. It also offers
  an efficient algorithm to recover estimates of the fixed effects in a post-estimation routine.
  The package also includes robust and multi-way clustered standard errors.",2018-07-31,Amrei Stammann,https://github.com/amrei-stammann/alpaca,TRUE,https://github.com/amrei-stammann/alpaca,3137,9,1541927992
alphavantager,"
    Alpha Vantage has free historical financial information. 
    All you need to do is get a free API key at <https://www.alphavantage.co>.
    Then you can use the R interface to retrieve free equity information.
    Refer to the Alpha Vantage website for more information.",2019-03-11,Matt Dancho,https://github.com/business-science/alphavantager,TRUE,https://github.com/business-science/alphavantager,19760,28,1552596113
alterryx,"A tool to access each of the 'Alteryx' Gallery 'API' endpoints.
    Users can queue jobs, poll job status, and retrieve application output as
    a data frame. You will need an 'Alteryx' Server license and have 'Alteryx'
    Gallery running to utilize this package. The 'API' is accessed through the
    'URL' that you setup for the server running 'Alteryx' Gallery and more
    information on the endpoints can be found at
    <https://gallery.alteryx.com/api-docs/>.",2018-11-21,Michael Treadwell,"https://github.com/mtreadwell/alterryx,
https://gallery.alteryx.com/api-docs/",TRUE,https://github.com/mtreadwell/alterryx,8815,2,1542824694
ambient,"Generation of natural looking noise has many application within 
    simulation, procedural generation, and art, to name a few. The 'ambient' 
    package provides an interface to the 'FastNoise' C++ library and allows for
    efficient generation of perlin, simplex, worley, cubic, value, and white 
    noise with optional pertubation in either 2, 3, or 4 (in case of simplex and
    white noise) dimensions.",2018-08-30,Thomas Lin Pedersen,https://github.com/thomasp85/ambient,TRUE,https://github.com/thomasp85/ambient,2465,30,1535554163
ameco,Annual macro-economic database provided by the European Commission.,2018-05-04,Eric Persson,http://github.com/expersso/ameco,TRUE,https://github.com/expersso/ameco,19586,3,1547638079
amt,"Manage and analyze animal movement data. The functionality of 'amt' includes methods to calculate track statistics (e.g. step lengths, speed, or turning angles), prepare data for fitting habitat selection analyses (resource and step-selection functions), and simulation of space-use from fitted step-selection functions.",2019-03-19,Johannes Signer,https://github.com/jmsigner/amt,TRUE,https://github.com/jmsigner/amt,8313,4,1553759254
AmyloGram,"Predicts amyloid proteins using random forests trained on the
    n-gram encoded peptides. The implemented algorithm can be accessed from
    both the command line and shiny-based GUI.",2017-10-11,Michal Burdukiewicz,https://github.com/michbur/AmyloGram,TRUE,https://github.com/michbur/amylogram,8446,4,1554366129
analogsea,"Provides a set of functions for interacting with the 'Digital
    Ocean' API at <https://developers.digitalocean.com/documentation/v2>, including
    creating images, destroying them, rebooting, getting details on regions, and
    available images.",2018-01-04,Scott Chamberlain,https://github.com/sckott/analogsea,TRUE,https://github.com/sckott/analogsea,27040,99,1553629515
analogue,"Fits Modern Analogue Technique and Weighted Averaging transfer 
  	     function models for prediction of environmental data from species 
	     data, and related methods used in palaeoecology.",2018-10-23,Gavin L. Simpson  (<https://orcid.org/0000-0002-9084-8413>),https://github.com/gavinsimpson/analogue,TRUE,https://github.com/gavinsimpson/analogue,47691,9,1539121291
analysisPipelines,"Enables data scientists to compose pipelines of analysis which consist of data manipulation, exploratory analysis & reporting, as well as modeling steps. Data scientists can use tools of their choice through an R interface, and compose interoperable pipelines between R, Spark, and Python.
    Credits to Mu Sigma for supporting the development of the package.
    Note - To enable pipelines involving Spark tasks, the package uses the 'SparkR' package. 
    The SparkR package needs to be installed to use Spark as an engine within a pipeline. SparkR is distributed natively with Apache Spark and is not distributed on CRAN. The SparkR version needs to directly map to the Spark version (hence the native distribution), and care needs to be taken to ensure that this is configured properly.
    To install SparkR from Github, run the following command if you know the Spark version: 'devtools::install_github('apache/spark@v2.x.x', subdir='R/pkg')'.
    The other option is to install SparkR by running the following terminal commands if Spark has already been installed: '$ export SPARK_HOME=/path/to/spark/directory && cd $SPARK_HOME/R/lib/SparkR/ && R -e ""devtools::install('.')""'.",2019-01-08,Mu Sigma,https://github.com/Mu-Sigma/analysis-pipelines,TRUE,https://github.com/mu-sigma/analysis-pipelines,1312,10,1552218953
angstroms,"Helper functions for working with Regional Ocean Modeling System 'ROMS' output. See
    <https://www.myroms.org/> for more information about 'ROMS'. ",2017-05-01,Michael D. Sumner,https://github.com/mdsumner/angstroms,TRUE,https://github.com/mdsumner/angstroms,5490,2,1553489875
animation,"Provides functions for animations in statistics, covering topics
    in probability theory, mathematical statistics, multivariate statistics,
    non-parametric statistics, sampling survey, linear models, time series,
    computational statistics, data mining and machine learning. These functions
    may be helpful in teaching statistics and data analysis. Also provided in this
    package are a series of functions to save animations to various formats, e.g.
    Flash, 'GIF', HTML pages, 'PDF' and videos. 'PDF' animations can be inserted
    into 'Sweave' / 'knitr' easily.",2018-12-11,Yihui Xie,https://yihui.name/animation,TRUE,https://github.com/yihui/animation,471249,139,1553106824
ANN2,"Training of neural networks for classification and regression tasks
    using mini-batch gradient descent. Special features include a function for 
    training autoencoders, which can be used to detect anomalies, and some 
    related plotting functions. Multiple activation functions are supported, 
    including tanh, relu, step and ramp. For the use of the step and ramp 
    activation functions in detecting anomalies using autoencoders, see 
    Hawkins et al. (2002) <doi:10.1007/3-540-46145-0_17>. Furthermore, 
    several loss functions are supported, including robust ones such as Huber 
    and pseudo-Huber loss, as well as L1 and L2 regularization. The possible 
    options for optimization algorithms are RMSprop, Adam and SGD with momentum.
    The package contains a vectorized C++ implementation that facilitates 
    fast training through mini-batch learning.",2019-03-30,Bart Lammers,https://github.com/bflammers/ANN2,TRUE,https://github.com/bflammers/ann2,18351,4,1554461429
AnnotationBustR,Extraction of subsequences into FASTA files from GenBank annotations where gene names may vary among accessions.,2018-04-09,Samuel R. Borstein <sam@borstein.com>,"https://github.com/sborstein/AnnotationBustR,
https://www.ncbi.nlm.nih.gov/nuccore,
https://en.wikipedia.org/wiki/FASTA_format",TRUE,https://github.com/sborstein/annotationbustr,7471,0,1536774614
anomalize,"
    The 'anomalize' package enables a ""tidy"" workflow for detecting anomalies in data.
    The main functions are time_decompose(), anomalize(), and time_recompose().
    When combined, it's quite simple to decompose time series, detect anomalies,
    and create bands separating the ""normal"" data from the anomalous data at scale (i.e. for multiple time series). 
    Time series decomposition is used to remove trend and seasonal components via the time_decompose() function
    and methods include seasonal decomposition of time series by Loess (""stl"") and 
    seasonal decomposition by piecewise medians (""twitter""). The anomalize() function implements
    two methods for anomaly detection of residuals including using an inner quartile range (""iqr"")
    and generalized extreme studentized deviation (""gesd""). These methods are based on
    those used in the 'forecast' package and the Twitter 'AnomalyDetection' package. 
    Refer to the associated functions for specific references for these methods. ",2018-04-17,Matt Dancho,https://github.com/business-science/anomalize,TRUE,https://github.com/business-science/anomalize,17802,160,1523961692
antaresProcessing,"
    Process results generated by 'Antares', a powerful open source software developed by
    RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems (more information about
    'Antares' here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>). You can see the results of several ANTARES studies here : <http://bpnumerique.rte-france.com/>. 
    This package provides functions to create new columns like net load, load factors, upward and
    downward margins or to compute aggregated statistics like economic surpluses
    of consumers, producers and sectors.",2018-12-10,Jalal-Edine ZAWAM,https://github.com/rte-antares-rpackage/antaresProcessing,TRUE,https://github.com/rte-antares-rpackage/antaresprocessing,20207,8,1538147862
antaresRead,"Import, manipulate and explore results generated by 'Antares', a 
    powerful open source software developed by RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems
    (more information about 'Antares' here : <https://github.com/AntaresSimulatorTeam/Antares_Simulator>). You can see the results of several ANTARES studies here : <http://bpnumerique.rte-france.com/>. ",2019-02-13,Frederic Breant,https://github.com/rte-antares-rpackage/antaresRead,TRUE,https://github.com/rte-antares-rpackage/antaresread,26259,7,1550048909
antaresViz,"Visualize results generated by Antares, a powerful open source software
    developed by RTE to simulate and study electric power systems
    (more information about Antares here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>).
    This package provides functions that create interactive charts to help
    Antares users visually explore the results of their simulations. 
    You can see the results of several ANTARES studies here : <http://bpnumerique.rte-france.com/>.",2018-10-11,Jalal-Edine ZAWAM,https://github.com/rte-antares-rpackage/antaresViz,TRUE,https://github.com/rte-antares-rpackage/antaresviz,13861,12,1539250460
anthro,"Provides WHO Child Growth Standards (z-scores) with
             confidence intervals and standard errors around the
             prevalence estimates, taking into account complex sample designs.
             More information on the methods is
             available online:
             <http://www.who.int/childgrowth/standards/en/>.",2019-03-23,Dirk Schumacher,https://github.com/dirkschumacher/anthro,TRUE,https://github.com/dirkschumacher/anthro,592,6,1554405078
AntWeb,"A complete programmatic interface to the AntWeb database from the
    California Academy of Sciences.",2014-08-14,Karthik Ram,https://github.com/ropensci/AntWeb,TRUE,https://github.com/ropensci/antweb,24674,7,1526049821
anytime,"Convert input in any one of character, integer, numeric, factor,
 or ordered type into 'POSIXct' (or 'Date') objects, using one of a number of
 predefined formats, and relying on Boost facilities for date and time parsing.",2018-11-14,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/anytime.html,TRUE,https://github.com/eddelbuettel/anytime,134743,95,1554256626
apa,"Formatter functions in the 'apa' package take the return value of a
    statistical test function, e.g. a call to chisq.test() and return a string
    formatted according to the guidelines of the APA (American Psychological
    Association).",2019-03-04,Daniel Gromer,https://github.com/dgromer/apa,TRUE,https://github.com/dgromer/apa,14483,23,1551703797
ApacheLogProcessor,Provides capabilities to process Apache HTTPD Log files.The main functionalities are to extract data from access and error log files to data frames.,2018-07-19,Diogo Silveira Mendonca,https://github.com/diogosmendonca/ApacheLogProcessor,TRUE,https://github.com/diogosmendonca/apachelogprocessor,17190,8,1531967229
apaTables,"A common task faced by researchers is the creation of APA style
    (i.e., American Psychological Association style) tables from statistical
    output. In R a large number of function calls are often needed to obtain all of
    the desired information for a single APA style table. As well, the process of
    manually creating APA style tables in a word processor is prone to transcription
    errors. This package creates Word files (.doc files) containing APA style tables
    for several types of analyses. Using this package minimizes transcription errors
    and reduces the number commands needed by the user.",2018-08-29,David Stanley,https://github.com/dstanley4/apaTables,TRUE,https://github.com/dstanley4/apatables,47726,22,1540144915
apcf,"The adapted pair correlation function transfers the concept of the
  pair correlation function from point patterns to patterns of objects of 
  finite size and irregular shape (e.g. lakes within a country). This is a 
  reimplementation of the method suggested by Nuske et al. (2009) 
  <doi:10.1016/j.foreco.2009.09.050> using the libraries 'GEOS' and 'GDAL' 
  directly instead of through 'PostGIS'. ",2019-01-17,Robert Nuske  (<https://orcid.org/0000-0001-9773-2061>),https://github.com/rnuske/apcf,TRUE,https://github.com/rnuske/apcf,1048,1,1553173722
aphid,"Designed for the development and application of
    hidden Markov models and profile HMMs for biological sequence analysis. 
    Contains functions for multiple and pairwise sequence alignment, 
    model construction and parameter optimization, file import/export,
    implementation of the forward, backward and Viterbi algorithms for 
    conditional sequence probabilities, tree-based sequence weighting, 
    and sequence simulation. 
    Features a wide variety of potential applications including 
    database searching, gene-finding and annotation, phylogenetic 
    analysis and sequence classification.
    Based on the models and algorithms described in Durbin et 
    al (1998, ISBN: 9780521629713).",2019-03-15,Shaun Wilkinson,http://github.com/shaunpwilkinson/aphid,TRUE,https://github.com/shaunpwilkinson/aphid,11547,9,1552783289
aprof,"Assists the evaluation of whether and
    where to focus code optimization, using Amdahl's law and visual aids
    based on line profiling. Amdahl's profiler organizes profiling output
    files (including memory profiling) in a visually appealing way.
    It is meant to help to balance development
    vs. execution time by helping to identify the most promising sections
    of code to optimize and projecting potential gains. The package is
    an addition to R's standard profiling tools and is not a wrapper for them.",2018-05-22,Marco D. Visser,http://github.com/MarcoDVisser/aprof,TRUE,https://github.com/marcodvisser/aprof,23594,22,1526559932
aqp,"The Algorithms for Quantitative Pedology (AQP) project was started in 2009 to organize a loosely-related set of concepts and source code on the topic of soil profile visualization, aggregation, and classification into this package (aqp). Over the past 8 years, the project has grown into a suite of related R packages that enhance and simplify the quantitative analysis of soil profile data. Central to the AQP project is a new vocabulary of specialized functions and data structures that can accommodate the inherent complexity of soil profile information; freeing the scientist to focus on ideas rather than boilerplate data processing tasks <doi:10.1016/j.cageo.2012.10.020>. These functions and data structures have been extensively tested and documented, applied to projects involving hundreds of thousands of soil profiles, and deeply integrated into widely used tools such as SoilWeb <https://casoilresource.lawr.ucdavis.edu/soilweb-apps/>. Components of the AQP project (aqp, soilDB, sharpshootR, soilReports packages) serve an important role in routine data analysis within the USDA-NRCS Soil Science Division. The AQP suite of R packages offer a convenient platform for bridging the gap between pedometric theory and practice.",2019-01-03,Dylan Beaudette,https://github.com/ncss-tech/aqp,TRUE,https://github.com/ncss-tech/aqp,118737,10,1553721632
ar.matrix,Using sparse precision matricies and Choleski factorization simulates data that is auto-regressive.,2018-12-02,Neal Marquez,NA,TRUE,https://github.com/nmmarquez/ar.matrix,1531,2,1550357398
arc,"Implements the Classification-based on
    Association Rules (CBA) (Bing Liu, Wynne Hsu,	Yiming Ma (1999) <http://dl.acm.org/citation.cfm?id=3000292.3000305>) algorithm for association rule classification (ARC).
    The package also contains several convenience methods that allow to automatically
    set CBA parameters (minimum confidence, minimum support) and it also natively
    handles numeric attributes by integrating a pre-discretization step.
    The rule generation phase is handled by the 'arules' package. 
    To further decrease the size of the CBA models produced by the 'arc' package, postprocessing by the 
    'qCBA' package is suggested.",2018-04-18,Tomas Kliegr,https://github.com/kliegr/arc,TRUE,https://github.com/kliegr/arc,11926,2,1535645783
archiDART,"Analysis of complex plant root system architectures (RSA) using the output files created by Data Analysis of Root Tracings (DART), an open-access software dedicated to the study of plant root architecture and development across time series (Le Bot et al (2010) ""DART: a software to analyse root system architecture and development from captured images"", Plant and Soil, <DOI:10.1007/s11104-009-0005-2>), and RSA data encoded with the Root System Markup Language (RSML) (Lobet et al (2015) ""Root System Markup Language: toward a unified root architecture description language"", Plant Physiology, <DOI:10.1104/pp.114.253625>). More information can be found in Delory et al (2016) ""archiDART: an R package for the automated computation of plant root architectural traits"", Plant and Soil, <DOI:10.1007/s11104-015-2673-4>.",2018-04-03,Benjamin M Delory,https://archidart.github.io/,TRUE,https://github.com/archidart/archidart,18931,0,1554215702
archivist,"Data exploration and modelling is a process in which a lot of data
    artifacts are produced. Artifacts like: subsets, data aggregates, plots,
    statistical models, different versions of data sets and different versions
    of results. The more projects we work with the more artifacts are produced
    and the harder it is to manage these artifacts. Archivist helps to store
    and manage artifacts created in R. Archivist allows you to store selected
    artifacts as a binary files together with their metadata and relations.
    Archivist allows to share artifacts with others, either through shared
    folder or github. Archivist allows to look for already created artifacts by
    using it's class, name, date of the creation or other properties. Makes it
    easy to restore such artifacts. Archivist allows to check if new artifact
    is the exact copy that was produced some time ago. That might be useful
    either for testing or caching.",2019-01-02,Przemyslaw Biecek,https://pbiecek.github.io/archivist/,TRUE,https://github.com/pbiecek/archivist,76766,52,1550870611
areal,"A pipeable, transparent implementation of areal weighted interpolation
    with support for interpolating multiple variables in a single function call.
    These tools provide a full-featured workflow for validation and estimation
    that fits into both modern data management (e.g. tidyverse) and spatial 
    data (e.g. sf) frameworks.",2018-12-31,Christopher Prener  (<https://orcid.org/0000-0002-4310-9888>),https://github.com/slu-openGIS/areal,TRUE,https://github.com/slu-opengis/areal,1814,30,1553395038
arena2r,Reads Arena <https://www.arenasimulation.com/> CSV output files and generates nice tables and plots. The package contains a Shiny App that can be used to interactively visualize Arena's results.,2018-10-19,Pedro Nascimento de Lima,https://github.com/pedroliman/arena2r,TRUE,https://github.com/pedroliman/arena2r,2424,0,1539982420
argonDash,"Create awesome 'Bootstrap 4' dashboards powered by 'Argon'.
   See more here <https://rinterface.github.io/argonDash/>.",2018-12-03,David Granjon,https://github.com/RinteRface/argonDash,TRUE,https://github.com/rinterface/argondash,3456,34,1553607923
argonR,"R wrapper around the argon HTML library.
    More at <https://demos.creative-tim.com/argon-design-system/>.",2018-11-18,David Granjon,https://github.com/RinteRface/argonR,TRUE,https://github.com/rinterface/argonr,3597,26,1554238733
argparse,"A command line parser to
    be used with Rscript to write ""#!"" shebang scripts that gracefully
    accept positional and optional arguments and automatically generate usage.",2019-03-08,Trevor L Davis,https://github.com/trevorld/r-argparse,TRUE,https://github.com/trevorld/r-argparse,95354,29,1552077763
aricode,"Implements an efficient O(n) algorithm based on bucket-sorting for 
    fast computation of standard clustering comparison measures. Available measures
    include adjusted Rand index (ARI), normalized information distance (NID), 
    normalized mutual information (NMI), normalized variation information (NVI) and
    entropy, as described in Vinh et al (2009) <doi:10.1145/1553374.1553511>.",2018-05-02,Julien Chiquet  (<https://orcid.org/0000-0002-3629-3429>),https://github.com/jchiquet/aricode (dev version),TRUE,https://github.com/jchiquet/aricode,3195,2,1530795732
arkdb,"Flat text files provide a robust, compressible, and portable
  way to store tables from databases.  This package provides convenient
  functions for exporting tables from relational database connections
  into compressed text files and streaming those text files back into
  a database without requiring the whole table to fit in working memory.",2018-10-31,Carl Boettiger,https://github.com/ropensci/arkdb,TRUE,https://github.com/ropensci/arkdb,7154,45,1545679673
aroma.affymetrix,A cross-platform R framework that facilitates processing of any number of Affymetrix microarray samples regardless of computer system.  The only parameter that limits the number of chips that can be processed is the amount of available disk space.  The Aroma Framework has successfully been used in studies to process tens of thousands of arrays.  This package has actively been used since 2006.,2018-04-16,Henrik Bengtsson,"http://www.aroma-project.org/,
https://github.com/HenrikBengtsson/aroma.affymetrix",TRUE,https://github.com/henrikbengtsson/aroma.affymetrix,54003,3,1523911260
aroma.core,"Core methods and classes used by higher-level 'aroma.*' packages
        part of the Aroma Project, e.g. 'aroma.affymetrix' and 'aroma.cn'.",2018-05-03,Henrik Bengtsson,"https://github.com/HenrikBengtsson/aroma.core,
http://www.aroma-project.org/",TRUE,https://github.com/henrikbengtsson/aroma.core,66119,1,1527555941
arsenal,"An Arsenal of 'R' functions for large-scale statistical summaries,
  which are streamlined to work within the latest reporting tools in 'R' and
  'RStudio' and which use formulas and versatile summary statistics for summary
  tables and models. The primary functions include tableby(), a Table-1-like
  summary of multiple variable types 'by' the levels of one or more categorical
  variables; paired(), a Table-1-like summary of multiple variable types paired across
  two time points; modelsum(), which performs simple model fits on one or more endpoints
  for many variables (univariate or adjusted for covariates);
  freqlist(), a powerful frequency table across many categorical variables;
  comparedf(), a function for comparing data.frames; and
  write2(), a function to output tables to a document.",2019-03-25,Ethan Heinzen,"https://github.com/eheinzen/arsenal,
https://cran.r-project.org/package=arsenal",TRUE,https://github.com/eheinzen/arsenal,31852,45,1553785123
ARTool,"The Aligned Rank Transform for nonparametric
    factorial ANOVAs as described by J. O. Wobbrock,
    L. Findlater, D. Gergle, & J. J. Higgins, ""The Aligned
    Rank Transform for nonparametric factorial analyses
    using only ANOVA procedures"", CHI 2011 <DOI:10.1145/1978942.1978963>.",2019-02-03,Matthew Kay,https://github.com/mjskay/ARTool,TRUE,https://github.com/mjskay/artool,24153,15,1549235077
ARTP2,Pathway and gene level association test using raw data or summary statistics.,2018-11-30,Han Zhang,https://github.com/zhangh12/ARTP2,TRUE,https://github.com/zhangh12/artp2,11876,3,1550252555
arules,"Provides the infrastructure for representing,
    manipulating and analyzing transaction data and patterns (frequent
    itemsets and association rules). Also provides
    C implementations of the association mining algorithms Apriori and Eclat.",2019-03-07,Michael Hahsler,https://github.com/mhahsler/arules,TRUE,https://github.com/mhahsler/arules,1005922,89,1551917088
arulesCBA,"Provides a function to build an association rule-based classifier for data frames, and to classify incoming data frames using such a classifier.",2018-12-16,Ian Johnson,https://github.com/ianjjohnson/arulesCBA,TRUE,https://github.com/ianjjohnson/arulescba,26741,20,1550595506
arulesViz,Extends package 'arules' with various visualization techniques for association rules and itemsets. The package also includes several interactive visualizations for rule exploration.,2018-12-05,Michael Hahsler,"https://github.com/mhahsler/arulesViz,
http://lyle.smu.edu/IDA/arules/",TRUE,https://github.com/mhahsler/arulesviz,537582,21,1550618572
aRxiv,"An interface to the API for 'arXiv'
    (<https://arxiv.org>), a repository of electronic preprints for
    computer science, mathematics, physics, quantitative biology,
    quantitative finance, and statistics.",2017-04-28,Karl Broman,https://github.com/ropensci/aRxiv,TRUE,https://github.com/ropensci/arxiv,28044,35,1553257533
asciiSetupReader,"Lets you open a fixed-width ASCII file (.txt or
    .dat) that has an accompanying setup file (.sps or .sas). These file
    combinations are sometimes referred to as .txt+.sps, .txt+.sas,
    .dat+.sps, or .dat+.sas. This will only run in a txt-sps or txt-sas
    pair in which the setup file contains instructions to open that text
    file. It will NOT open other text files, .sav, .sas, or .por data
    files.  Fixed-width ASCII files with setup files are common in older
    (pre-2000) government data.",2019-02-05,Jacob Kaplan,https://github.com/jacobkap/asciiSetupReader,TRUE,https://github.com/jacobkap/asciisetupreader,7191,3,1551107293
ashr,"The R package 'ashr' implements an Empirical Bayes
    approach for large-scale hypothesis testing and false discovery
    rate (FDR) estimation based on the methods proposed in
    M. Stephens, 2016, ""False discovery rates: a new deal"",
    <DOI:10.1093/biostatistics/kxw041>. These methods can be applied
    whenever two sets of summary statistics---estimated effects and
    standard errors---are available, just as 'qvalue' can be applied
    to previously computed p-values. Two main interfaces are
    provided: ash(), which is more user-friendly; and ash.workhorse(),
    which has more options and is geared toward advanced users. The
    ash() and ash.workhorse() also provides a flexible modeling
    interface that can accomodate a variety of likelihoods (e.g.,
    normal, Poisson) and mixture priors (e.g., uniform, normal).",2019-02-22,Peter Carbonetto,https://github.com/stephens999/ashr,TRUE,https://github.com/stephens999/ashr,12539,55,1552591855
AsioHeaders,"'Asio' is a cross-platform C++ library for network and low-level
 I/O programming that provides developers with a consistent asynchronous model
 using a modern C++ approach. It is also included in Boost but requires linking
 when used with Boost. Standalone it can be used header-only (provided a recent
 compiler). 'Asio' is written and maintained by Christopher M. Kohlhoff, and
 released under the 'Boost Software License', Version 1.0.",2018-09-10,Dirk Eddelbuettel,NA,TRUE,https://github.com/eddelbuettel/asioheaders,18442,8,1536589727
aslib,"Provides an interface to the algorithm selection benchmark library
    at <http://www.aslib.net> and the 'LLAMA' package
    (<https://cran.r-project.org/web/packages/llama/index.html>) for building
    algorithm selection models.",2016-11-25,Bernd Bischl <bernd_bischl@gmx.net>,https://github.com/coseal/aslib-r/,TRUE,https://github.com/coseal/aslib-r,6826,5,1545686670
assertr,"Provides functionality to assert conditions
    that have to be met so that errors in data used in
    analysis pipelines can fail quickly. Similar to
    'stopifnot()' but more powerful, friendly, and easier
    for use in pipelines.",2019-01-22,Tony Fischetti,https://github.com/ropensci/assertr,TRUE,https://github.com/ropensci/assertr,31679,233,1549897311
ASSISTant,"Clinical trial design for subgroup selection in three-stage group
    sequential trial. Includes facilities for design, exploration and analysis of
    such trials. An implementation of the initial DEFUSE-3 trial is also provided
    as a vignette.",2016-05-03,Balasubramanian Narasimhan,https://github.com/bnaras/ASSISTant,TRUE,https://github.com/bnaras/assistant,8959,0,1548825804
atsd,"Provides functions for retrieving time-series and related
    meta-data such as entities, metrics, and tags from the Axibase
    Time-Series Database (ATSD). ATSD is a non-relational clustered
    database used for storing performance measurements from IT infrastructure
    resources: servers, network devices, storage systems, and applications.",2018-01-29,Axibase Corporation,https://github.com/axibase/atsd-api-r/,TRUE,https://github.com/axibase/atsd-api-r,12437,1,1537508168
auditor,"Provides an easy to use unified interface for creating validation plots for any model. 
  The 'auditor' helps to avoid repetitive work consisting of writing code needed to create residual plots. 
  This visualizations allow to asses and compare the goodness of fit, performance, and similarity of models. ",2018-09-19,Alicja Gosiewska,https://mi2datalab.github.io/auditor/,TRUE,https://github.com/mi2datalab/auditor,6380,18,1554395124
augmentedRCBD,"Functions for analysis of data generated from experiments in
    augmented randomised complete block design according to Federer, W.T. (1961)
    <doi:10.2307/2527837>. Computes analysis of variance, adjusted means,
    descriptive statistics, genetic variability statistics etc. Further includes
    data visualization and report generation functions.",2018-07-10,J. Aravind  (<https://orcid.org/0000-0002-4791-442X>),https://github.com/aravind-j/augmentedRCBD,TRUE,https://github.com/aravind-j/augmentedrcbd,2931,1,1547726857
auk,"Extract and process bird sightings records from
    eBird (<http://ebird.org>), an online tool for recording bird
    observations.  Public access to the full eBird database is via the
    eBird Basic Dataset (EBD; see <http://ebird.org/ebird/data/download>
    for access), a downloadable text file. This package is an interface to
    AWK for extracting data from the EBD based on taxonomic, spatial, or
    temporal filters, to produce a manageable file size that can be
    imported into R.",2019-02-04,"Matthew Strimas-Mackey 
    (<https://orcid.org/0000-0001-8929-7776>)","https://github.com/CornellLabofOrnithology/auk,
http://CornellLabofOrnithology.github.io/auk/",TRUE,https://github.com/cornelllabofornithology/auk,12715,49,1552661071
auth0,"Uses Auth0 API (see <https://auth0.com> for more 
    information) to use a simple and secure authentication system. It provides 
    tools to log in and out a shiny application using social networks or a list
    of e-mails.",2019-02-13,Julio Trecenti,NA,TRUE,https://github.com/curso-r/auth0,2390,22,1553034800
autocogs,Automatically calculates cognostic groups for plot objects and list column plot objects.  Results are returned in a nested data frame.,2019-02-12,Barret Schloerke,https://github.com/schloerke/autocogs,TRUE,https://github.com/schloerke/autocogs,5516,2,1549910028
AutoDeskR,"An interface to the 'AutoDesk' 'API' Platform including the Authentication 
    'API' for obtaining authentication to the 'AutoDesk' Forge Platform, Data Management 
    'API' for managing data across the platform's cloud services, Design Automation 'API'
    for performing automated tasks on design files in the cloud, Model
    Derivative 'API' for translating design files into different formats, sending
    them to the viewer app, and extracting design data, and Viewer for rendering
    2D and 3D models (see <https://developer.autodesk.com> for more information).",2017-07-10,Paul Govan,https://github.com/paulgovan/autodeskr,TRUE,https://github.com/paulgovan/autodeskr,8909,5,1541553107
automagic,Parse R code in a given directory for R packages and attempt to install them from CRAN or GitHub. Optionally use a dependencies file for tighter control over which package versions to install.,2019-03-05,Cole Brokamp,https://github.com/cole-brokamp/automagic,TRUE,https://github.com/cole-brokamp/automagic,7263,33,1552186260
automultinomial,"Fits the autologistic model described in Besag's famous 1974 paper on auto- models <http://www.jstor.org/stable/2984812>. Fits a multicategory generalization of the autologistic model when there are more than 2 response categories. Provides support for both asymptotic and bootstrap confidence intervals. For full model descriptions and a guide to the use of this package, please see the vignette.",2018-10-31,Stephen Berg,NA,TRUE,https://github.com/stephenberg/automultinomial,7842,4,1541005003
autoplotly,"Functionalities to automatically generate interactive visualizations for
             statistical results supported by 'ggfortify', such as time series, PCA,
             clustering and survival analysis, with 'plotly.js' <https://plot.ly/>  and
             'ggplot2' style. The generated visualizations can also be easily extended
             using 'ggplot2' and 'plotly' syntax while staying interactive.",2018-04-21,Yuan Tang  (<https://orcid.org/0000-0001-5243-233X>),https://github.com/terrytangyuan/autoplotly,TRUE,https://github.com/terrytangyuan/autoplotly,6442,36,1524322544
autoshiny,Static code compilation of a 'shiny' app given an R function (into 'ui.R' and 'server.R' files or into a 'shiny' app object). See examples at <https://github.com/alekrutkowski/autoshiny>.,2018-06-25,Aleksander Rutkowski,https://github.com/alekrutkowski/autoshiny,TRUE,https://github.com/alekrutkowski/autoshiny,3617,4,1529313640
autovarCore,"Automatically find the best vector autoregression
    models and networks for a given time series data set. 'AutovarCore'
    evaluates eight kinds of models: models with and without log
    transforming the data, lag 1 and lag 2 models, and models with and
    without weekday dummy variables. For each of these 8 model configurations,
    'AutovarCore' evaluates all possible combinations for including
    outlier dummies (at 2.5x the standard deviation of the residuals)
    and retains the best model. Model evaluation includes the Eigenvalue
    stability test and a configurable set of residual tests. These eight
    models are further reduced to four models because 'AutovarCore'
    determines whether adding weekday dummies improves the model fit.",2018-06-04,Ando Emerencia,NA,TRUE,https://github.com/roqua/autovarcore,16536,3,1531407626
av,"Bindings to 'FFmpeg' <http://www.ffmpeg.org/> AV library for working with audio 
    and video in R. Generate high quality videos files by capturing images from the R graphics
    device combined with custom audio stream. This package interfaces directly to the C API
    and does not require any command line utilities.",2018-09-30,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),"https://github.com/ropensci/av (devel) http://www.ffmpeg.org/
(upstream)",TRUE,https://github.com/ropensci/av,15556,56,1547079798
available,"Check if a given package name is available to use. It checks the
  name's validity. Checks if it is used on 'GitHub', 'CRAN' and 'Bioconductor'. Checks
  for unintended meanings by querying Urban Dictionary, 'Wiktionary' and Wikipedia.",2018-11-08,Jim Hester,https://github.com/ropenscilabs/available,TRUE,https://github.com/ropenscilabs/available,7925,88,1541687975
aweek,"Which day a week starts depends heavily on the either the local or
  professional context. This package is designed to be a lightweight solution
  to easily switching between week-based date definitions. ",2019-03-08,Zhian N. Kamvar,https://github.com/reconhub/aweek,TRUE,https://github.com/reconhub/aweek,1875,3,1552921298
aws.cloudtrail,"A simple client package for the Amazon Web Services ('AWS') 'CloudTrail'
    'API' <https://aws.amazon.com/cloudtrail/>.",2017-07-04,Thomas J. Leeper,https://github.com/cloudyr/aws.cloudtrail,TRUE,https://github.com/cloudyr/aws.cloudtrail,5805,0,1533052999
aws.comprehend,"Client for 'AWS Comprehend' <https://aws.amazon.com/comprehend>, a cloud natural language processing service that can perform a number of quantitative text analyses, including language detection, sentiment analysis, and feature extraction.",2018-04-12,Thomas J. Leeper,https://github.com/cloudyr/aws.comprehend,TRUE,https://github.com/cloudyr/aws.comprehend,3278,3,1533052886
aws.ec2metadata,Retrieve Amazon EC2 instance metadata from within the running instance.,2018-07-26,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/cloudyr/aws.ec2metadata,TRUE,https://github.com/cloudyr/aws.ec2metadata,111777,5,1532605923
aws.iam,"A simple client for the Amazon Web Services ('AWS') Identity
    and Access Management ('IAM') 'API' <https://aws.amazon.com/iam/>.",2017-07-01,Thomas J. Leeper,https://github.com/cloudyr/aws.iam,TRUE,https://github.com/cloudyr/aws.iam,7731,6,1533052967
aws.kms,"Client package for the 'AWS Key Management Service' <https://aws.amazon.com/kms/>, a cloud service for managing encryption keys.",2018-08-01,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/cloudyr/aws.kms,TRUE,https://github.com/cloudyr/aws.kms,2659,0,1533052758
aws.lambda,A simple client package for the Amazon Web Services ('AWS') Lambda 'API' <https://aws.amazon.com/lambda/>.,2017-07-02,Thomas J. Leeper,https://github.com/cloudyr/aws.lambda,TRUE,https://github.com/cloudyr/aws.lambda,5950,16,1533053050
aws.polly,"A client for AWS Polly <http://aws.amazon.com/documentation/polly>, a speech synthesis service.",2016-12-08,Thomas J. Leeper,https://github.com/cloudyr/aws.polly,TRUE,https://github.com/cloudyr/aws.polly,8703,17,1533158731
aws.s3,"A simple client package for the Amazon Web Services ('AWS') Simple
    Storage Service ('S3') 'REST' 'API' <https://aws.amazon.com/s3/>.",2018-05-25,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/cloudyr/aws.s3,TRUE,https://github.com/cloudyr/aws.s3,736119,214,1535995202
aws.ses,"A simple client package for the Amazon Web Services (AWS) Simple
    Email Service (SES) <http://aws.amazon.com/ses/> REST API.",2016-12-20,Thomas J. Leeper,https://github.com/cloudyr/aws.ses,TRUE,https://github.com/cloudyr/aws.ses,7540,5,1533053144
aws.signature,"Generates version 2 and version 4 request signatures for Amazon Web Services ('AWS') <https://aws.amazon.com/> Application Programming Interfaces ('APIs') and provides a mechanism for retrieving credentials from environment variables, 'AWS' credentials files, and 'EC2' instance metadata. For use on 'EC2' instances, users will need to install the suggested package 'aws.ec2metadata' <https://cran.r-project.org/package=aws.ec2metadata>.",2018-07-27,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/cloudyr/aws.signature,TRUE,https://github.com/cloudyr/aws.signature,688907,14,1533739617
aws.sns,"A simple client package for the Amazon Web Services ('AWS') Simple
    Notification Service ('SNS') 'API' <https://aws.amazon.com/sns/>.",2017-07-04,Thomas J. Leeper,https://github.com/cloudyr/aws.sns,TRUE,https://github.com/cloudyr/aws.sns,8935,9,1533053166
aws.sqs,"A simple client package for the Amazon Web Services ('AWS') Simple
    Queue Service ('SQS') <https://aws.amazon.com/sqs/> 'API'.",2017-07-04,Thomas J. Leeper,https://github.com/cloudyr/aws.sqs,TRUE,https://github.com/cloudyr/aws.sqs,9018,12,1534001502
aws.transcribe,"Client for 'AWS Transcribe' <https://aws.amazon.com/documentation/transcribe>, a cloud transcription service that can convert an audio media file in English and other languages into a text transcript.",2018-04-09,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/cloudyr/aws.transcribe,TRUE,https://github.com/cloudyr/aws.transcribe,3183,1,1533053224
aws.translate,"A client for 'AWS Translate' <https://aws.amazon.com/documentation/translate>, a machine translation service that will convert a text input in one language into a text output in another language.",2018-04-12,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/cloudyr/aws.translate,TRUE,https://github.com/cloudyr/aws.translate,3171,2,1533053251
awsjavasdk,"Provides boilerplate access to all of the classes included in the 
    Amazon Web Services ('AWS') Java Software Development Kit (SDK) via 
    package:'rJava'.  According to Amazon, the 'SDK helps take the complexity 
    out of coding by providing Java APIs for many AWS services including 
    Amazon S3, Amazon EC2, DynamoDB, and more'.  You can read more about the 
    included Java code on Amazon's website: 
    <https://aws.amazon.com/sdk-for-java/>.",2017-01-01,Russell Pierce,https://github.com/zapier/awsjavasdk,TRUE,https://github.com/zapier/awsjavasdk,6834,4,1542898372
awspack,A bundle of all of 'cloudyr' project <http://cloudyr.github.io/> packages for Amazon Web Services ('AWS') <https://aws.amazon.com/>. It depends upon all of the 'cloudyr' project's 'AWS' packages. It is mainly useful for installing the entire suite of packages; more likely than not you will only want to load individual packages one at a time.,2017-07-05,Thomas J. Leeper,https://github.com/cloudyr/awspack,TRUE,https://github.com/cloudyr/awspack,6036,13,1533053285
AzureAuth,"Provides Azure Active Directory (AAD) authentication functionality for R users of Microsoft's 'Azure' cloud <https://azure.microsoft.com/>. Use this package to obtain 'OAuth' 2.0 tokens for services including Azure Resource Manager, Azure Storage and others. It supports both AAD v1.0 and v2.0, as well as multiple authentication methods, including device code and resource owner grant. Tokens are cached in a user-specific directory obtained using the 'rappdirs' package. The interface is based on the 'OAuth' framework in the 'httr' package, but customised and streamlined for Azure.",2019-03-22,Hong Ooi,https://github.com/cloudyr/AzureAuth,TRUE,https://github.com/cloudyr/azureauth,3099,3,1553500521
AzureContainers,"An interface to container functionality in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/en-us/overview/containers/>. Manage 'Azure Container Instance' (ACI), 'Azure Container Registry' (ACR) and 'Azure Kubernetes Service' (AKS) resources, push and pull images, and deploy services. On the client side, lightweight shells to the 'docker', 'kubectl' and 'helm' commandline tools are provided.",2019-02-14,Hong Ooi,https://github.com/cloudyr/AzureContainers,TRUE,https://github.com/cloudyr/azurecontainers,1856,6,1554082368
AzureGraph,"A simple interface to the 'Microsoft Graph' API <https://docs.microsoft.com/en-us/graph/overview>. 'Graph' is a comprehensive framework for accessing data in various online Microsoft services. Currently, this package aims to provide an R interface only to the 'Azure Active Directory' part, with a view to supporting interoperability of R and 'Azure': users, groups, registered apps and service principals. However it can be easily extended to cover other services.",2019-03-31,Hong Ooi,https://github.com/cloudyr/AzureGraph,TRUE,https://github.com/cloudyr/azuregraph,79,1,1554267235
AzureRMR,"A lightweight but powerful R interface to the 'Azure Resource Manager' REST API. The package exposes classes and methods for 'OAuth' authentication and working with subscriptions and resource groups. It also provides functionality for creating and deleting 'Azure' resources and deploying templates. While 'AzureRMR' can be used to manage any 'Azure' service, it can also be extended by other packages to provide extra functionality for specific services.",2019-04-02,Hong Ooi,https://github.com/cloudyr/AzureRMR,TRUE,https://github.com/cloudyr/azurermr,4111,14,1554113364
AzureStor,"Manage storage in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/services/storage>. On the admin side, 'AzureStor' includes features to create, modify and delete storage accounts. On the client side, it includes an interface to blob storage, file storage, and 'Azure Data Lake Storage Gen2': upload and download files and blobs; list containers and files/blobs; create containers; and so on. Authenticated access to storage is supported, via either a shared access key or a shared access signature (SAS).",2019-03-21,Hong Ooi,https://github.com/cloudyr/AzureStor,TRUE,https://github.com/cloudyr/azurestor,3708,12,1553172531
AzureVM,"Functionality for working with virtual machines (VMs) in Microsoft's 'Azure' cloud: <https://azure.microsoft.com/en-us/services/virtual-machines/>. Includes facilities to create, startup, shutdown, and cleanly delete VMs and VM clusters. With a running VM, execute scripts and install optional extensions. A selection of VM templates based on the 'Data Science Virtual Machine' (DSVM) is supplied; this allows fast and easy provisioning of a VM preinstalled with several software packages useful for data science. Alternatively, users can provide VM templates of their own.",2018-12-25,Hong Ooi,https://github.com/cloudyr/AzureVM,TRUE,https://github.com/cloudyr/azurevm,2499,2,1552376732
babynames,"US baby names provided by the SSA. This package contains all
    names used for at least 5 children of either sex.",2019-01-12,Hadley Wickham,http://github.com/hadley/babynames,TRUE,https://github.com/hadley/babynames,89588,83,1553201016
BacArena,"Can be used for simulation of organisms living in
    communities. Each organism is represented individually and genome scale
    metabolic models determine the uptake and release of compounds. Biological
    processes such as movement, diffusion, chemotaxis and kinetics are available
    along with data analysis techniques.",2019-02-15,Johannes Zimmermann,https://BacArena.github.io/,TRUE,https://github.com/euba/bacarena,13756,8,1553094440
backpipe,"Provides a backward-pipe operator for 'magrittr' (%<%) or 
    'pipeR' (%<<%) that allows for a performing operations from right-to-left. 
    This allows writing more legible code where right-to-left ordering is 
    natural. This is common with hierarchies and nested structures such as 
    trees, directories or markup languages (e.g. HTML and XML). 
    The package also includes a R-Studio add-in that can be bound to a keyboard 
    shortcut. ",2018-06-26,Christopher Brown,https://github.com/decisionpatterns/backpipe,TRUE,https://github.com/decisionpatterns/backpipe,11918,16,1529949776
backports,"
    Functions introduced or changed since R v3.0.0 are re-implemented in this
    package. The backports are conditionally exported in order to let R resolve
    the function name to either the implemented backport, or the respective base
    version, if available. Package developers can make use of new functions or
    arguments by selectively importing specific backports to
    support older installations.",2018-12-14,Michel Lang  (<https://orcid.org/0000-0001-9754-0393>),https://github.com/r-lib/backports,TRUE,https://github.com/r-lib/backports,7403535,38,1552899719
badgecreatr,"Tired of copy and pasting almost identical markdown for badges in
    every new R-package that you create, on Github or other code-sharing sites? 
    This package allows you to easily paste badges. If you want to, it will also search 
    your DESCRIPTION file and extract the package name,
    license, R-version, and current projectversion and transform that into 
    badges. It will also search for a "".travis.yml"" file and create a ""Travis"""" badge,
    if you use ""Codecov.io"" to check your code coverage after a ""Travis"" build 
    this package will also build a ""Codecov.io""-badge. All the badges can be placed
    individually or can be placed below the top ""YAML"""" content of your ""RMarkdown 
    file"" (Readme.Rmd) or ""README.md"" file. 
    Currently creates badges for  Projectstatus (""Repostatus.org""), license
    Travis Build Status, Codecov, Minimal R version, CRAN status, CRAN downloads, 
    Github stars and forks, Package rank, rdocumentation, 
    current version of your package and last change of ""README.Rmd"".",2019-01-07,Roel M. Hogervorst,"https://github.com/RMHogervorst/badgecreatr,
https://rmhogervorst.nl/badgecreatr",TRUE,https://github.com/rmhogervorst/badgecreatr,7567,47,1549708118
badger,"Query information and generate badge for using in README
    and GitHub Pages.",2019-01-08,Guangchuang Yu  (<https://orcid.org/0000-0002-6485-8781>),https://github.com/GuangchuangYu/badger,TRUE,https://github.com/guangchuangyu/badger,6606,42,1547805376
balance,"Balances have become a cornerstone of compositional data analysis. However,
 conceptualizing balances is difficult, especially for high-dimensional data. Most often,
 investigators visualize balances with ""balance dendrograms"". However, this visualization
 tool does not scale well for large data. This package provides an alternative scheme for
 visualizing balances, described in [Quinn (2018) <DOI:10.12688/f1000research.15858.1>].
 This package also provides a method for principal balance analysis.",2018-12-10,Thomas Quinn,http://github.com/tpq/balance,TRUE,https://github.com/tpq/balance,2803,2,1554417807
BALCONY,Facilitates the evolutionary analysis and structure conservation study of specified amino acids in proteins.,2019-02-28,Michal Stolarczyk,NA,TRUE,https://github.com/michalstolarczyk/balcony,10241,1,1554563146
Ball,"Hypothesis tests and sure independence screening (SIS) procedure based on ball statistics, including ball divergence <doi:10.1214/17-AOS1579>, ball covariance, and ball correlation <doi:10.1080/01621459.2018.1462709>, are developed to analyze complex data. The ball divergence and ball covariance based distribution-free tests are implemented to detecting distribution difference and association in metric spaces <arXiv:1811.03750>. Furthermore, a generic non-parametric SIS procedure based on ball correlation and all of its variants are implemented to tackle the challenge in the context of ultra high dimensional data.",2018-12-14,Xueqin Wang,https://github.com/Mamba413/Ball,TRUE,https://github.com/mamba413/ball,12129,7,1552611292
BAMBI,Fit (using Bayesian methods) and simulate mixtures of univariate and bivariate angular distributions. Chakraborty and Wong (2017) <arXiv:1708.07804> .,2019-03-16,Saptarshi Chakraborty,https://arxiv.org/abs/1708.07804,TRUE,https://github.com/c7rishi/bambi,13702,0,1554182231
bamboo,"Implementation of the Bamboo methods described in Li, Dahl, Vannucci, Joo, and Tsai (2014) <DOI:10.1371/journal.pone.0109832>.",2018-10-19,David B. Dahl,https://github.com/dbdahl/bamboo,TRUE,https://github.com/dbdahl/bamboo,12287,2,1549412347
BaMORC,"Provides reference correction for protein NMR spectra. Bayesian Model Optimized Reference Correction (BaMORC) is utilizing Bayesian probabilistic framework to perform protein NMR referencing correction, currently for alpha and beta carbon-13 chemical shifts, without any resonance assignment and/or three-dimensional protein structure. For more detailed explanation, please refer to the paper ""Automatic 13C Chemical Shift Reference Correction for Unassigned Protein NMR Spectra"" <https://rdcu.be/4ly5> (Journal of Biomolecular NMR, Aug 2018)"" <doi:10.1007/s10858-018-0202-5>.",2019-01-02,Xi Chen  (<https://orcid.org/0000-0001-7094-6748>),https://github.com/MoseleyBioinformaticsLab/BaMORC,TRUE,https://github.com/moseleybioinformaticslab/bamorc,1655,0,1541164054
bamp,"Bayesian Age-Period-Cohort Modeling and Prediction using efficient Markov Chain Monte Carlo Methods. This is the R version of the previous BAMP software as described in Volker Schmid and Leonhard Held (2007) <DOI:10.18637/jss.v021.i08> Bayesian Age-Period-Cohort Modeling and Prediction - BAMP, Journal of Statistical Software 21:8. This package includes checks of convergence using Gelman's R.",2019-01-08,Volker Schmid,https://volkerschmid.github.io/bamp/,TRUE,https://github.com/volkerschmid/bamp,2379,2,1546943112
BANEScarparkinglite,"Contains functions for importing and working with the BANES car parking
  records and other related datasets. For the full version of the package, including
  all datasets, see the repo at <https://github.com/owenjonesuob/BANEScarparking>.
  The original dataset of parking records can be found at
  <https://data.bathhacked.org/Government-and-Society/BANES-Historic-Car-Park-Occupancy/x29s-cczc>.",2018-06-30,Owen Jones,https://github.com/owenjonesuob/BANEScarparkinglite,TRUE,https://github.com/owenjonesuob/banescarparkinglite,4543,0,1530370054
bang,"Provides functions for the Bayesian analysis of some simple 
    commonly-used models, without using Markov Chain Monte Carlo (MCMC) 
    methods such as Gibbs sampling.  The 'rust' package  
    <https://cran.r-project.org/package=rust> is used 
    to simulate a random sample from the required posterior distribution.  
    At the moment three conjugate hierarchical models are available:
    beta-binomial, gamma-Poisson and a 1-way analysis of variance (ANOVA).",2017-11-20,Paul J. Northrop,http://github.com/paulnorthrop/bang,TRUE,https://github.com/paulnorthrop/bang,4486,3,1526918444
banR,"A client for the ""Base Adresses Nationale"" (BAN) API, which allows to (batch)
    geocode and reverse-geocode French addresses. For more information about the BAN and its API, please see <https://adresse.data.gouv.fr/api>. ",2017-08-03,Joel Gombin,http://github.com/joelgombin/banR,TRUE,https://github.com/joelgombin/banr,5292,14,1527691415
baRcodeR,"Tools to generate unique identifiers and printable barcoded labels for sample management. 
    The creation of unique ID codes and printable PDF files can be initiated by standard commands, 
    user prompts, or through a GUI addin for R Studio. Both single-level and hierarchical labels can 
    be created in the command line interactively or non-interactively. ",2019-01-10,Robert Colautti,https://github.com/yihanwu/baRcodeR,TRUE,https://github.com/yihanwu/barcoder,3484,10,1552342683
BAS,"Package for Bayesian Variable Selection and  Model Averaging in linear models and
    generalized linear models using stochastic or
    deterministic sampling without replacement from posterior
    distributions.  Prior distributions on coefficients are
    from Zellner's g-prior or mixtures of g-priors
    corresponding to the Zellner-Siow Cauchy Priors or the
    mixture of g-priors from Liang et al (2008)
    <DOI:10.1198/016214507000001337>
    for linear models or mixtures of g-priors in GLMs of Li and Clyde (2018)
    <arXiv:1503.06913>. Other model
    selection criteria include AIC, BIC and Empirical Bayes estimates of g.
    Sampling probabilities may be updated based on the sampled models
    using Sampling w/out Replacement or an efficient MCMC algorithm
    samples models using the BAS tree structure as an efficient hash table.
    Uniform priors over all models or beta-binomial prior distributions on
    model size are allowed, and for large p truncated priors on the model
    space may be used.  The user may force variables to always be included.
    Details behind the sampling algorithm are provided in
    Clyde, Ghosh and Littman (2010)   <DOI:10.1198/jcgs.2010.09049>.
    This material is based upon work supported by the National Science
    Foundation under Grant DMS-1106891.  Any opinions, findings, and
    conclusions or recommendations expressed in this material are those of
    the author(s) and do not necessarily reflect the views of the
    National Science Foundation.",2018-10-30,Merlise Clyde,"https://www.r-project.org, https://github.com/merliseclyde/BAS",TRUE,https://github.com/merliseclyde/bas,75739,21,1540912868
base2grob,"Convert base plot function call (using expression or formula) to 'grob' object that compatible to the 'grid' ecosystem. With this package, we are able to e.g. using 'cowplot' to align base plots with 'ggplot' objects and using 'ggsave' to export base plot to file.",2018-04-25,Guangchuang Yu  (<https://orcid.org/0000-0002-6485-8781>),https://github.com/GuangchuangYu/base2grob,TRUE,https://github.com/guangchuangyu/base2grob,6125,8,1524633768
base64url,"In contrast to RFC3548, the 62nd character (""+"") is replaced with
    ""-"", the 63rd character (""/"") is replaced with ""_"". Furthermore, the encoder
    does not fill the string with trailing ""="". The resulting encoded strings
    comply to the regular expression pattern ""[A-Za-z0-9_-]"" and thus are
    safe to use in URLs or for file names.
    The package also comes with a simple base32 encoder/decoder suited for
    case insensitive file systems.",2018-05-14,Michel Lang  (<https://orcid.org/0000-0001-9754-0393>),https://github.com/mllg/base64url,TRUE,https://github.com/mllg/base64url,30907,8,1536838772
baseballDBR,"A tool for gathering and analyzing data from the Baseball Databank <http://www.baseball-databank.org/>, which includes player performance statistics from major league baseball in the United States beginning in the year 1871.",2017-06-15,Kris Eberwein,https://github.com/keberwein/moneyball,TRUE,https://github.com/keberwein/moneyball,5027,6,1539094809
basictabler,"Easily create tables from data 
    frames/matrices.  Create/manipulate tables 
    row-by-row, column-by-column or cell-by-cell.  
    Use common formatting/styling to output 
    rich tables as 'HTML', 'HTML widgets' or to 
    'Excel'. ",2019-03-21,Christopher Bailiss,https://github.com/cbailiss/basictabler,TRUE,https://github.com/cbailiss/basictabler,7291,11,1553163623
basicTrendline,"Plot, draw regression line and confidence interval, and show regression equation, R-square and P-value,  as simple as possible, by using different models (""line2P"", ""line3P"", ""log2P"", ""exp2P"", ""exp3P"", ""power2P"", ""power3P"") built in the 'trendline()' function.",2018-07-26,Weiping Mei,https://github.com/PhDMeiwp/basicTrendline,TRUE,https://github.com/phdmeiwp/basictrendline,9018,6,1535162680
batchtools,"As a successor of the packages 'BatchJobs' and 'BatchExperiments',
    this package provides a parallel implementation of the Map function for high
    performance computing systems managed by schedulers 'IBM Spectrum LSF'
    (<https://www.ibm.com/us-en/marketplace/hpc-workload-management>),
    'OpenLava' (<http://www.openlava.org/>), 'Univa Grid Engine'/'Oracle Grid
    Engine' (<http://www.univa.com/>), 'Slurm' (<http://slurm.schedmd.com/>),
    'TORQUE/PBS'
    (<http://www.adaptivecomputing.com/products/open-source/torque/>), or
    'Docker Swarm' (<https://docs.docker.com/swarm/>).
    A multicore and socket mode allow the parallelization on a local machines,
    and multiple machines can be hooked up via SSH to create a makeshift
    cluster. Moreover, the package provides an abstraction mechanism to define
    large-scale computer experiments in a well-organized and reproducible way.",2018-08-16,Michel Lang  (<https://orcid.org/0000-0001-9754-0393>),https://github.com/mllg/batchtools,TRUE,https://github.com/mllg/batchtools,42070,88,1550492098
bayesAB,"A suite of functions that allow the user to analyze A/B test
    data in a Bayesian framework. Intended to be a drop-in replacement for
    common frequentist hypothesis test such as the t-test and chi-sq test.",2018-07-14,Frank Portman,https://github.com/FrankPortman/bayesAB,TRUE,https://github.com/frankportman/bayesab,19819,214,1547739917
bayesboot,"Functions for performing the Bayesian bootstrap as introduced by
    Rubin (1981) <doi:10.1214/aos/1176345338> and for summarizing the result.
    The implementation can handle both summary statistics that works on a
    weighted version of the data and summary statistics that works on a
    resampled data set.",2018-06-29,Rasmus Bååth,https://github.com/rasmusab/bayesboot,TRUE,https://github.com/rasmusab/bayesboot,11465,39,1530223211
bayesCT,"Simulation and analysis of Bayesian adaptive clinical trial, incorporates historical 
      data and allows early stopping for futility or early success. ",2019-03-13,Thevaa Chandereng,https://github.com/thevaachandereng/bayesCT/,TRUE,https://github.com/thevaachandereng/bayesct,1387,4,1552855671
BayesCTDesign,"A set of functions to help clinical trial researchers calculate power and sample size for two-arm Bayesian randomized clinical trials that do or do not incorporate historical control data.  At some point during the design process, a clinical trial researcher who is designing a basic two-arm Bayesian randomized clinical trial needs to make decisions about power and sample size within the context of hypothesized treatment effects.  Through simulation, the simple_sim() function will estimate power and other user specified clinical trial characteristics at user specified sample sizes given user defined scenarios about treatment effect,control group characteristics, and outcome.  If the clinical trial researcher has access to historical control data, then the researcher can design a two-arm Bayesian randomized clinical trial that incorporates the historical data.  In such a case, the researcher needs to work through the potential consequences of historical and randomized control differences on trial characteristics, in addition to working through issues regarding power in the context of sample size, treatment effect size, and outcome.  If a researcher designs a clinical trial that will incorporate historical control data, the researcher needs the randomized controls to be from the same population as the historical controls.  What if this is not the case when the designed trial is implemented?  During the design phase, the researcher needs to investigate the negative effects of possible historic/randomized control differences on power, type one error, and other trial characteristics.  Using this information, the researcher should design the trial to mitigate these negative effects.  Through simulation, the historic_sim() function will estimate power and other user specified clinical trial characteristics at user specified sample sizes given user defined scenarios about historical and randomized control differences as well as treatment effects and outcomes.  The results from historic_sim() and simple_sim() can be printed with print_table() and graphed with plot_table() methods.  Outcomes considered are Gaussian, Poisson, Bernoulli, Lognormal, Weibull, and Piecewise Exponential.  ",2018-08-14,Barry Eggleston,http://github.com/begglest/BayesCTDesign,TRUE,https://github.com/begglest/bayesctdesign,2136,0,1534174324
bayesdfa,"Implements Bayesian dynamic factor analysis with 'Stan'. Dynamic 
    factor analysis is a dimension reduction tool for multivariate time series.
    'bayesdfa' extends conventional dynamic factor models in several ways. 
    First, extreme events may be estimated in the latent trend by modeling
    process error with a student-t distribution. Second, autoregressive and 
    moving average components can be optionally included. Third, the estimated
    dynamic factors can be analyzed with hidden Markov models to evaluate
    support for latent regimes.",2019-03-05,Eric J. Ward,https://github.com/fate-ewi/bayesdfa,TRUE,https://github.com/fate-ewi/bayesdfa,3345,8,1551798992
bayesDP,"Functions for data augmentation using the
    Bayesian discount prior function for 1 arm and 2 arm clinical trials.",2018-07-10,Shawn Balcome,https://github.com/donaldmusgrove/bayesDP,TRUE,https://github.com/donaldmusgrove/bayesdp,14915,3,1539615039
BayesFactor,"A suite of functions for computing
    various Bayes factors for simple designs, including contingency tables,
    one- and two-sample designs, one-way designs, general ANOVA designs, and
    linear regression.",2018-05-19,Richard D. Morey,https://richarddmorey.github.io/BayesFactor/,TRUE,https://github.com/richarddmorey/bayesfactor,139578,82,1551430715
BayesianNetwork,"A 'Shiny' web application for creating interactive Bayesian Network models,
    learning the structure and parameters of Bayesian networks, and utilities for classic
    network analysis.",2018-12-02,Paul Govan  (<https://orcid.org/0000-0002-1821-8492>),https://github.com/paulgovan/bayesiannetwork,TRUE,https://github.com/paulgovan/bayesiannetwork,11438,53,1543716268
BayesianTools,"General-purpose MCMC and SMC samplers, as well as plot and
    diagnostic functions for Bayesian statistics, with a particular focus on
    calibrating complex system models. Implemented samplers include various
    Metropolis MCMC variants (including adaptive and/or delayed rejection MH), the
    T-walk, two differential evolution MCMCs, two DREAM MCMCs, and a sequential
    Monte Carlo (SMC) particle filter.",2019-01-21,Florian Hartig,https://github.com/florianhartig/BayesianTools,TRUE,https://github.com/florianhartig/bayesiantools,17623,49,1550846657
BayesMallows,"An implementation of the Bayesian version of the Mallows rank model (Vitelli et al., Journal of Machine Learning Research, 2018 <http://jmlr.org/papers/v18/15-481.html>; Crispino et al., to appear in Annals of Applied Statistics). Both Cayley, footrule, Hamming, Kendall, Spearman, and Ulam distances are supported in the models. The rank data to be analyzed can be in the form of complete rankings, top-k rankings, partially missing rankings, as well as consistent and inconsistent pairwise preferences. Several functions for plotting and studying the posterior distributions of parameters are provided. The package also provides functions for estimating the partition function (normalizing constant) of the Mallows rank model, both with the importance sampling algorithm of Vitelli et al. and asymptotic approximation with the IPFP algorithm (Mukherjee, Annals of Statistics, 2016 <doi:10.1214/15-AOS1389>).",2019-02-22,Oystein Sorensen,https://github.com/osorensen/BayesMallows,TRUE,https://github.com/osorensen/bayesmallows,3908,2,1551082731
BayesNetBP,"Belief propagation methods in Bayesian Networks to propagate evidence through the network. The implementation of these methods are based on the article: Cowell, RG (2005). Local Propagation in Conditional Gaussian Bayesian Networks <http://www.jmlr.org/papers/volume6/cowell05a/>.",2018-08-22,Han Yu,https://github.com/hyu-ub/BayesNetBP,TRUE,https://github.com/hyu-ub/bayesnetbp,8181,5,1550525383
bayesplot,"Plotting functions for posterior analysis, model checking,
    and MCMC diagnostics. The package is designed not only to provide convenient
    functionality for users, but also a common set of functions that can be
    easily used by developers working on a variety of R packages for Bayesian
    modeling, particularly (but not exclusively) packages interfacing with 'Stan'.",2018-08-02,Jonah Gabry,http://mc-stan.org/bayesplot,TRUE,https://github.com/stan-dev/bayesplot,302667,166,1552429023
BayesTwin,"Bayesian analysis of item-level hierarchical twin data using an integrated item response theory model. Analyses are based on Schwabe & van den Berg (2014) <doi:10.1007/s10519-014-9649-7>, Molenaar & Dolan (2014) <doi:10.1007/s10519-014-9647-9>, Schwabe, Jonker & van den Berg (2016) <doi:10.1007/s10519-015-9768-9> and Schwabe, Boomsma & van den Berg (2016) <doi:10.1016/j.lindif.2017.01.018>.",2017-06-26,Inga Schwabe,http://www.ingaschwabe.com,TRUE,https://github.com/ingaschwabe/bayestwin,4423,0,1538136274
BayesVarSel,"Conceived to calculate Bayes factors in linear models and then to provide a formal Bayesian answer to testing and variable selection problems. From a theoretical side, the emphasis in this package is placed on the prior distributions and it allows a wide range of them: Jeffreys (1961); Zellner and Siow(1980)<DOI:10.1007/bf02888369>; Zellner and Siow(1984); Zellner (1986)<DOI:10.2307/2233941>; Fernandez et al. (2001)<DOI:10.1016/s0304-4076(00)00076-2>; Liang et al. (2008)<DOI:10.1198/016214507000001337>  and Bayarri et al. (2012)<DOI:10.1214/12-aos1013>. The interaction with the package is through a friendly interface that syntactically mimics the well-known lm() command of R. The resulting objects can be easily explored providing the user very valuable information (like marginal, joint and conditional inclusion probabilities of potential variables; the highest posterior probability model, HPM; the median probability model, MPM) about the structure of the true -data generating- model. Additionally, this package incorporates abilities to handle problems with a large number of potential explanatory variables through parallel and heuristic versions of the main commands, Garcia-Donato and Martinez-Beneito (2013)<DOI:10.1080/01621459.2012.742443>.",2017-12-04,Anabel Forte,https://github.com/carlosvergara/BayesVarSel,TRUE,https://github.com/carlosvergara/bayesvarsel,26662,0,1540813034
bayfoxr,"A Bayesian, global planktic foraminifera core top calibration to 
    modern sea-surface temperatures. Includes four calibration models, 
    considering species-specific calibration parameters and seasonality.",2019-02-06,Steven Malevich,https://github.com/brews/bayfoxr/,TRUE,https://github.com/brews/bayfoxr,684,1,1549650077
BayLum,"Bayesian analysis of luminescence data and C-14 age estimates. Bayesian models are based on the following publications: Combes, B. & Philippe, A. (2017) <doi:10.1016/j.quageo.2017.02.003> and Combes et al (2015) <doi:10.1016/j.quageo.2015.04.001>. This includes, amongst others, data import, export, application of age models and palaeodose model.",2018-09-19,Anne Philippe,NA,TRUE,https://github.com/r-lum/baylum,6605,2,1551289173
baytrends,"Enable users to evaluate long-term trends using a Generalized 
    Additive Modeling (GAM) approach. The model development includes selecting a 
    GAM structure to describe nonlinear seasonally-varying changes over time, 
    incorporation of hydrologic variability via either a river flow or salinity, 
    the use of an intervention to deal with method or laboratory changes 
    suspected to impact data values, and representation of left- and 
    interval-censored data. The approach has been applied to water quality data 
    in the Chesapeake Bay, a major estuary on the east coast of the United 
    States to provide insights to a range of management- and research-focused 
    questions.",2019-03-14,Rebecca Murphy,https://github.com/tetratech/baytrends,TRUE,https://github.com/tetratech/baytrends,3102,2,1552586101
bazar,"A collection of miscellaneous functions for 
    copying objects to the clipboard ('Copy');
    manipulating strings ('concat', 'mgsub', 'trim', 'verlan'); 
    loading or showing packages ('library_with_dep', 'require_with_dep', 
    'sessionPackages'); 
    creating or testing for named lists ('nlist', 'as.nlist', 'is.nlist'), 
    formulas ('is.formula'), empty objects ('as.empty', 'is.empty'), 
    whole numbers ('as.wholenumber', 'is.wholenumber'); 
    testing for equality ('almost.equal', 'almost.zero') and computing 
    uniqueness ('almost.unique'); 
    getting modified versions of usual functions ('rle2', 'sumNA'); 
    making a pause or a stop ('pause', 'stopif'); 
    converting into a function ('as.fun'); 
    providing a C like ternary operator ('condition %?% true %:% false'); 
    finding packages and functions ('get_all_pkgs', 'get_all_funs');
    and others ('erase', '%nin%', 'unwhich', 'top', 'bot', 'normalize'). ",2019-03-15,Paul Poncet,https://github.com/paulponcet/bazar,TRUE,https://github.com/paulponcet/bazar,39251,0,1554455660
BBI,"Set of functions to calculate Benthic Biotic Indices from
	composition data, obtained whether from morphotaxonomic inventories or
	sequencing data. Based on reference ecological weights publicly available for
	a set of commonly used marine biotic indices, such as AMBI (A Marine Biotic Index, Borja et al., 2000) <doi:10.1016/S0025-326X(00)00061-8>
	NSI (Norwegian Sensitivity Index) and ISI (Indicator Species Index) (Rygg 2013, <ISBN:978-82-577-6210-0>). It provides the ecological quality status of the samples based on each BBI as well as the normalized Ecological Quality Ratio.",2018-10-17,Tristan Cordier,https://github.com/trtcrd/BBI,TRUE,https://github.com/trtcrd/bbi,3872,1,1544017201
bbw,"The blocked weighted bootstrap (BBW) is an estimation technique 
    for use with data from two-stage cluster sampled surveys in which either 
    prior weighting (e.g. population-proportional sampling or PPS as used in 
    Standardized Monitoring and Assessment of Relief and Transitions or SMART 
    surveys) or posterior weighting (e.g. as used in rapid assessment method or
    RAM and simple spatial sampling method or S3M surveys). The method was 
    developed by Accion Contra la Faim, Brixton Health, Concern Worldwide, 
    Global Alliance for Improved Nutrition, UNICEF Sierra Leone,  UNICEF Sudan
    and Valid International. It has been tested by the Centers for Disease
    Control (CDC) using infant and young child feeding (IYCF) data. See Cameron
    et al (2008) <doi:10.1162/rest.90.3.414> for application of bootstrap
    to cluster samples. See Aaron et al (2016) <doi:10.1371/journal.pone.0163176> 
    and Aaron et al (2016) <doi:10.1371/journal.pone.0162462> for application 
    of the blocked weighted bootstrap to estimate indicators from two-stage 
    cluster sampled surveys.",2018-01-17,Mark Myatt,https://github.com/validmeasures/bbw,TRUE,https://github.com/validmeasures/bbw,3648,1,1543834566
bcaboot,Computation of bootstrap confidence intervals in an almost automatic fashion.,2018-08-31,Balasubramanian Narasimhan,"https://bnaras.github.io/bcaboot,
https://github.com/bnaras/bcaboot",TRUE,https://github.com/bnaras/bcaboot,2310,5,1547767679
Bchron,"Enables quick calibration of radiocarbon dates under various 
  calibration curves (including user generated ones); age-depth modelling 
  as per the algorithm of Haslett and Parnell (2008) <DOI:10.1111/j.1467-9876.2008.00623.x>; Relative sea level 
  rate estimation incorporating time uncertainty in polynomial regression 
  models (Parnell and Gehrels 2015) <DOI:10.1002/9781118452547.ch32>; non-parametric phase modelling via 
  Gaussian mixtures as a means to determine the activity of a site 
  (and as an alternative to the Oxcal function SUM; currently 
  unpublished), and reverse calibration of dates from calibrated into 
  un-calibrated years (also unpublished).",2018-06-15,Andrew Parnell,https://github.com/andrewcparnell/Bchron,TRUE,https://github.com/andrewcparnell/bchron,39321,12,1539938915
bcmaps,"Provides access to various spatial layers for B.C., such as 
    administrative boundaries, natural resource management boundaries, etc. 
    All layers are imported from the 'bcmapsdata' package as 'sf' or 'Spatial' objects
    through function calls in this package. All layers are in B.C. 'Albers' equal-area projection 
    <http://spatialreference.org/ref/epsg/nad83-bc-albers/>, which is the B.C. 
    government standard.",2019-02-15,Andy Teucher,https://github.com/bcgov/bcmaps,TRUE,https://github.com/bcgov/bcmaps,5906,40,1550254080
bdchecks,Supplies a Shiny app and a set of functions to perform and managing data checks for biodiversity data. ,2019-02-18,Povilas Gibas  (<https://orcid.org/0000-0001-5311-6021>),https://github.com/bd-R/bdchecks,TRUE,https://github.com/bd-r/bdchecks,778,0,1554051128
beautier,"'BEAST2' (<http://www.beast2.org>) is a widely used
  Bayesian phylogenetic tool, that uses DNA/RNA/protein data
  and many model priors to create a posterior of jointly estimated 
  phylogenies and parameters.
  'BEAUti 2' (which is part of 'BEAST2') is a GUI tool 
  that allows users to specify the many possible setups
  and generates the XML file 'BEAST2' needs to run.
  This package provides a way to create 'BEAST2' input
  files without active user input, but using
  R function calls instead.",2019-03-01,"Richèl J.C. Bilderbeek 
    (<https://orcid.org/0000-0003-1107-7049>)",https://github.com/ropensci/beautier,TRUE,https://github.com/ropensci/beautier,1116,3,1552304068
BEDMatrix,"A matrix-like data structure that allows for efficient,
    convenient, and scalable subsetting of binary genotype/phenotype files
    generated by PLINK (<https://www.cog-genomics.org/plink2>), the whole
    genome association analysis toolset, without loading the entire file into
    memory.",2018-08-06,Alexander Grueneberg,https://github.com/QuantGen/BEDMatrix,TRUE,https://github.com/quantgen/bedmatrix,13743,5,1551895939
beezdemand,"Facilitates many of the analyses performed in studies of
    behavioral economic demand. The package supports commonly-used options for
		modeling operant demand including (1) data screening proposed by Stein,
		Koffarnus, Snider, Quisenberry, & Bickel (2015; <doi:10.1037/pha0000020>),
		(2) fitting models of demand such as linear (Hursh, Raslear, Bauman,
		& Black, 1989, <doi:10.1007/978-94-009-2470-3_22>), exponential	(Hursh & Silberberg, 2008,
		<doi:10.1037/0033-295X.115.1.186>) and modified exponential (Koffarnus,
		Franck, Stein, & Bickel, 2015, <doi:10.1037/pha0000045>), and (3) calculating
		numerous measures	relevant to applied behavioral economists (Intensity,
		Pmax, Omax). Also	supports plotting and comparing data.",2018-07-31,Brent Kaplan,https://github.com/brentkaplan/beezdemand,TRUE,https://github.com/brentkaplan/beezdemand,2574,5,1553010448
beginr,"Useful functions for R beginners, including hints for the arguments of the 'plot()' function, self-defined functions for error bars, user-customized pair plots and hist plots, enhanced linear regression figures, etc.. This package could be helpful to R experts as well.",2019-02-28,Peng Zhao,https://github.com/pzhaonet/beginr,TRUE,https://github.com/pzhaonet/beginr,7478,8,1551349413
behaviorchange,"Contains specialised analyses and
    visualisation tools for behavior change science.
    These facilitate conducting determinant studies
    (for example, using confidence interval-based
    estimation of relevance, CIBER, or CIBERlite
    plots), systematically developing, reporting,
    and analysing interventions (for example, using
    acyclic behavior change diagrams or ABCDs), and
    reporting about intervention effectiveness (for
    example, using the Numbers Needed for Change). This
    package is especially useful for researchers in
    the field of behavior change or health psychology
    and to behavior change professionals such as
    intervention developers and prevention workers.",2019-01-17,Gjalt-Jorn Peters,https://a-bc.eu/R/behaviorchange,TRUE,https://github.com/academy-of-behavior-change/behaviorchange,3571,0,1547674110
behavr,Implements an S3 class based on 'data.table' to store and process efficiently ethomics (high-throughput behavioural) data.,2019-01-03,Quentin Geissmann,https://github.com/rethomics/behavr,TRUE,https://github.com/rethomics/behavr,4676,2,1554501780
belg,"Calculates the Boltzmann entropy of a landscape gradient.
    This package uses the analytical method created by Gao, P., Zhang, H.
    and Li, Z., 2018 (<doi:10.1111/tgis.12315>). It also extend the original 
    idea by allowing calculations on data with missing values.",2018-06-17,Jakub Nowosad  (<https://orcid.org/0000-0002-1057-3721>),https://github.com/Nowosad/belg,TRUE,https://github.com/nowosad/belg,5196,8,1550344483
bench,Tools to accurately benchmark and analyze execution times for R expressions.,2018-06-06,Jim Hester,https://github.com/r-lib/bench,TRUE,https://github.com/r-lib/bench,10821,118,1540559286
benchmarkme,"Benchmark your CPU and compare against other CPUs. Also provides 
    functions for obtaining system specifications, such as
    RAM, CPU type, and R version.",2019-01-28,Colin Gillespie,https://github.com/csgillespie/benchmarkme,TRUE,https://github.com/csgillespie/benchmarkme,25603,15,1550652440
benchmarkmeData,Crowd sourced benchmarks from running the 'benchmarkme' package.,2019-03-08,Colin Gillespie,https://github.com/csgillespie/benchmarkme-data,TRUE,https://github.com/csgillespie/benchmarkme-data,24985,1,1552031800
benford.analysis,Provides tools that make it easier to validate data using Benford's Law.,2018-12-21,Carlos Cinelli,http://github.com/carloscinelli/benford.analysis,TRUE,https://github.com/carloscinelli/benford.analysis,29475,20,1545373160
berryFunctions,"Draw horizontal histograms, color scattered points by 3rd dimension,
    enhance date- and log-axis plots, zoom in X11 graphics, trace errors and warnings, 
    use the unit hydrograph in a linear storage cascade, convert lists to data.frames and arrays, 
    fit multiple functions.",2018-03-25,Berry Boessenkool,https://github.com/brry/berryFunctions,TRUE,https://github.com/brry/berryfunctions,43998,5,1553942576
bestNormalize,"Estimate a suite of normalizing transformations, including 
    a new adaptation of a technique based on ranks which can guarantee 
    normally distributed transformed data if there are no ties: ordered 
    quantile normalization (ORQ). ORQ normalization combines a rank-mapping
    approach with a shifted logit approximation that allows
    the transformation to work on data outside the original domain. It is 
    also able to handle new data within the original domain via linear 
    interpolation. The package is built to estimate the best normalizing 
    transformation for a vector consistently and accurately. It implements 
    the Box-Cox transformation, the Yeo-Johnson transformation, three types 
    of Lambert WxF transformations, and the ordered quantile normalization 
    transformation. It also estimates the normalization efficacy of other
    commonly used transformations. ",2018-09-25,Ryan Andrew Peterson,https://github.com/petersonR/bestNormalize,TRUE,https://github.com/petersonr/bestnormalize,10815,9,1537897483
BETS,"It provides access to and information about the most important
    Brazilian economic time series - from the Getulio Vargas Foundation <http://portal.fgv.br/en>,
    the Central Bank of Brazil <http://www.bcb.gov.br> and the Brazilian Institute of Geography
    and Statistics <http://www.ibge.gov.br>. It also presents tools for managing, analysing (e.g.
    generating dynamic reports with a complete analysis of a series) and exporting
    these time series.",2018-09-28,Talitha Speranza,https://github.com/nmecsys/BETS,TRUE,https://github.com/nmecsys/bets,30766,8,1542832881
bfsl,"Provides the solution from York (1968) <doi:10.1016/S0012-821X(68)80059-7>
  for fitting a straight line to bivariate data with errors in both coordinates.
  It gives unbiased estimates of the intercept, slope and standard errors of the
  best-fit straight line to independent points with (possibly correlated) 
  normally distributed errors in both x and y. Other commonly used 
  errors-in-variables methods, such as orthogonal distance regression, geometric
  mean regression or Deming regression are special cases of York’s solution.",2018-12-16,Patrick Sturm,https://github.com/pasturm/bfsl,TRUE,https://github.com/pasturm/bfsl,1170,0,1545384367
bfw,"Derived from the work of Kruschke (2015, <ISBN:9780124058880>),
    the present package aims to provide a framework for conducting Bayesian
    analysis using Markov chain Monte Carlo (MCMC) sampling utilizing the
    Just Another Gibbs Sampler ('JAGS', Plummer, 2003, <http://mcmc-jags.sourceforge.net/>).
    The initial version includes several modules for conducting Bayesian
    equivalents of chi-squared tests, analysis of variance (ANOVA),
    multiple (hierarchical) regression, softmax regression, and for fitting data
    (e.g., structural equation modeling).",2019-02-04,Øystein Olav Skaar,https://github.com/oeysan/bfw/,TRUE,https://github.com/oeysan/bfw,4989,8,1549277646
BGData,"An umbrella package providing a phenotype/genotype data structure
    and scalable and efficient computational methods for large genomic datasets
    in combination with several other packages: 'BEDMatrix', 'LinkedMatrix',
    and 'symDMatrix'.",2019-01-25,Alexander Grueneberg,https://github.com/QuantGen/BGData,TRUE,https://github.com/quantgen/bgdata,6784,12,1550613353
BH,"Boost provides free peer-reviewed portable C++ source 
 libraries.  A large part of Boost is provided as C++ template code
 which is resolved entirely at compile-time without linking.  This 
 package aims to provide the most useful subset of Boost libraries 
 for template use among CRAN package. By placing these libraries in 
 this package, we offer a more efficient distribution system for CRAN 
 as replication of this code in the sources of other packages is 
 avoided. As of release 1.69.0-1, the following Boost libraries are
 included: 'algorithm' 'align' 'any' 'atomic' 'bimap' 'bind'
 'circular_buffer' 'compute' 'concept' 'config' 'container' 'date_time'
 'detail' 'dynamic_bitset' 'exception' 'filesystem' 'flyweight' 'foreach'
 'functional' 'fusion' 'geometry' 'graph' 'heap' 'icl' 'integer'
 'interprocess' 'intrusive' 'io' 'iostreams' 'iterator' 'math' 'move' 'mpl'
 'multiprcecision' 'numeric' 'pending' 'phoenix' 'preprocessor'
 'propery_tree' 'random' 'range' 'scope_exit' 'smart_ptr' 'sort' 'spirit'
 'tuple' 'type_traits' 'typeof' 'unordered' 'utility' 'uuid'.",2019-01-07,Dirk Eddelbuettel,NA,TRUE,https://github.com/eddelbuettel/bh,12056296,56,1549379145
BIFIEsurvey,"
    Contains tools for survey statistics (especially in educational
    assessment) for datasets with replication designs (jackknife, 
    bootstrap, replicate weights; see Kolenikov, 2010;
    Pfefferman & Rao, 2009a, 2009b, <doi:10.1016/S0169-7161(09)70003-3>,
    <doi:10.1016/S0169-7161(09)70037-9>); Shao, 1996, 
    <doi:10.1080/02331889708802523>). 
    Descriptive statistics, linear and logistic regression, 
    path models for manifest variables with measurement error 
    correction and two-level hierarchical regressions for weighted 
    samples are included. Statistical inference can be conducted for 
    multiply imputed datasets and nested multiply imputed datasets
    and is in particularly suited for the analysis of plausible values
    (for details see George, Oberwimmer & Itzlinger-Bruneforth, 2016; 
    Bruneforth, Oberwimmer & Robitzsch, 2016; Robitzsch, Pham &
    Yanagida, 2016; <doi:10.17888/fdb-demo:bistE813I-16a>).    
    The package development was supported by BIFIE (Federal Institute for 
    Educational Research, Innovation and Development of the Austrian 
    School System; Salzburg, Austria).",2019-03-20,Alexander Robitzsch,"http://www.bifie.at,
https://www.bifie.at/bildungsforschung/forschungsdatenbibliothek,
https://www.bifie.at/large-scale-assessment-mit-r-methodische-grundlagen-der-oesterreichischen-bildungsstandardueberpruefung,
https://github.com/alexanderrobitzsch/BIFIEsurvey,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/bifiesurvey,90660,0,1553884077
BIGDAWG,"Data sets and functions for chi-squared Hardy-Weinberg and case-control association tests of highly polymorphic genetic data [e.g., human leukocyte antigen (HLA) data]. Performs association tests at multiple levels of polymorphism (haplotype, locus and HLA amino-acids) as described in Pappas DJ, Marin W, Hollenbach JA, Mack SJ (2016) <doi:10.1016/j.humimm.2015.12.006>. Combines rare variants to a common class to account for sparse cells in tables as described by Hollenbach JA, Mack SJ, Thomson G, Gourraud PA (2012) <doi:10.1007/978-1-61779-842-9_14>.",2018-02-08,Derek Pappas <dpappas@chori.org>,"http://tools.immunogenomics.org/,
https://github.com/IgDAWG/BIGDAWG",TRUE,https://github.com/igdawg/bigdawg,21052,1,1538077802
bigdist,"Provides utilities to compute, store and access distance matrices on disk as file-backed matrices provided by the 'bigstatsr' package. File-backed distance matrices are stored as a symmetric matrix to facilitate out-of-memory operations on file-backed matrix while the in-memory 'dist' object stores only the lower diagonal elements. 'disto' provides an unified interface to work with in-memory and disk-based distance matrices.",2019-03-16,Komala Sheshachala Srikanth,https://github.com/talegari/bigdist,TRUE,https://github.com/talegari/bigdist,264,1,1552737650
bigIntegerAlgos,"Features the multiple polynomial quadratic sieve algorithm
    for factoring large integers and a vectorized factoring function that
    returns the complete factorization of an integer. Utilizes the C
    library GMP (GNU Multiple Precision Arithmetic) and classes created
    by Antoine Lucas et al. found in the 'gmp' package.",2018-04-30,Joseph Wood,"https://github.com/jwood000/bigIntegerAlgos,
http://mathworld.wolfram.com/QuadraticSieve.html",TRUE,https://github.com/jwood000/bigintegeralgos,4003,3,1525103537
bigKRLS,"Functions for Kernel-Regularized Least Squares optimized for speed and memory usage are provided along with visualization tools. For working papers, sample code, and recent presentations visit <https://sites.google.com/site/petemohanty/software/>. bigKRLS, as well its dependencies, require current versions of R and its compilers (and RStudio if used). For details, see <https://github.com/rdrr1990/bigKRLS/blob/master/INSTALL.md>.",2019-03-22,Pete Mohanty  (<https://orcid.org/0000-0001-8531-3345>),https://github.com/rdrr1990/bigKRLS,TRUE,https://github.com/rdrr1990/bigkrls,14815,24,1553031005
BIGL,"Response surface methods for drug synergy analysis. Available
    methods include generalized and classical Loewe formulations as well as Highest
    Single Agent methodology. Response surfaces can be plotted in an interactive
    3-D plot and formal statistical tests for presence of synergistic effects are
    available. Implemented methods and tests are described in the article 
    ""BIGL: Biochemically Intuitive Generalized Loewe null model for prediction 
    of the expected combined effect compatible with partial agonism and antagonism""
    by Koen Van der Borght, Annelies Tourny, Rytis Bagdziunas, Olivier Thas, 
    Maxim Nazarov, Heather Turner, Bie Verbist & Hugo Ceulemans (2017) 
    <doi:10.1038/s41598-017-18068-5>.",2019-02-28,Heather Turner,https://github.com/openanalytics/BIGL,TRUE,https://github.com/openanalytics/bigl,10701,4,1552074397
bigmemory,"Create, store, access, and manipulate massive matrices.
    Matrices are allocated to shared memory and may use memory-mapped
    files.  Packages 'biganalytics', 'bigtabulate', 'synchronicity', and
    'bigalgebra' provide advanced functionality.",2018-01-11,Michael J. Kane <kaneplusplus@gmail.com>,https://github.com/kaneplusplus/bigmemory,TRUE,https://github.com/kaneplusplus/bigmemory,259751,73,1542397483
bigQueryR,"Interface with 'Google BigQuery',
    see <https://cloud.google.com/bigquery/> for more information.
    This package uses 'googleAuthR' so is compatible with similar packages, 
    including 'Google Cloud Storage' (<https://cloud.google.com/storage/>) for result extracts. ",2018-06-08,Mark Edmondson,http://code.markedmondson.me/bigQueryR/,TRUE,https://github.com/cloudyr/bigqueryr,26902,27,1554280979
bigreadr,Read large text files by splitting them in smaller files.,2018-08-13,Florian Privé,https://github.com/privefl/bigreadr,TRUE,https://github.com/privefl/bigreadr,4260,17,1535307245
bigrquery,Easily talk to Google's 'BigQuery' database from R.,2019-02-05,Hadley Wickham,https://github.com/rstats-db/bigrquery,TRUE,https://github.com/rstats-db/bigrquery,273020,329,1552823701
bigstatsr,"Easy-to-use, efficient, flexible and scalable statistical tools.
  Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping.
  It provides for instance matrix operations, Principal Component Analysis,
  sparse linear supervised models, utility functions and more
  <doi:10.1093/bioinformatics/bty185>.",2019-03-03,Florian Privé,https://privefl.github.io/bigstatsr,TRUE,https://github.com/privefl/bigstatsr,8640,69,1554469309
bigstep,"Selecting linear and generalized linear models for large data sets
    using modified stepwise procedure and modern selection criteria (like
    modifications of Bayesian Information Criterion). Selection can be
    performed on data which exceed RAM capacity.",2019-03-21,Piotr Szulc,http://github.com/pmszulc/bigstep,TRUE,https://github.com/pmszulc/bigstep,8283,1,1536776764
bigtime,"Estimation of large Vector AutoRegressive (VAR), Vector AutoRegressive with Exogenous Variables X (VARX) and Vector AutoRegressive Moving Average (VARMA) Models with Structured Lasso Penalties, see Nicholson, Bien and Matteson (2017) <arXiv:1412.5250v2> and Wilms, Basu, Bien and Matteson (2017) <arXiv:1707.09208>.",2017-11-09,Ines Wilms,http://github.com/ineswilms/bigtime,TRUE,https://github.com/ineswilms/bigtime,5153,6,1535724920
BigVAR,Estimates VAR and VARX models with structured Lasso Penalties.,2019-01-22,Will Nicholson,http://www.github.com/wbnicholson/BigVAR,TRUE,https://github.com/wbnicholson/bigvar,14575,22,1548391180
bikedata,"Download and aggregate data from all public hire bicycle systems
    which provide open data, currently including 'Santander' Cycles in London,
    U.K., and from the U.S.A., 'citibike' in New York City NY, 'Divvy' in
    Chicago IL, 'Capital Bikeshare' in Washington DC, 'Hubway' in Boston MA, 
    'Metro' in Los Angeles LA, and 'Indego' in Philadelphia PA.",2018-10-22,Mark Padgham  (<https://orcid.org/0000-0003-2172-5265>),https://github.com/ropensci/bikedata,TRUE,https://github.com/ropensci/bikedata,14773,54,1543307367
bikeshare14,"Anonymised Bay Area bike share trip data for the year 2014. 
    Also contains additional metadata on stations and weather.",2019-01-03,Arunkumar Srinivasan,http://github.com/arunsrinivasan/bikeshare14,TRUE,https://github.com/arunsrinivasan/bikeshare14,6645,1,1546398851
billboarder,"Provides an 'htmlwidgets' interface to 'billboard.js', 
    a re-usable easy interface JavaScript chart library, based on D3 v4+.
    Chart types include line charts, scatterplots, bar/lollipop charts, histogram/density plots, pie/donut charts and gauge charts.
    All charts are interactive, and a proxy method is implemented to smoothly update a chart without rendering it again in 'shiny' apps. ",2019-01-03,Victor Perrier,https://github.com/dreamRs/billboarder,TRUE,https://github.com/dreamrs/billboarder,11717,101,1553031014
binb,"A collection of 'LaTeX' styles using 'Beamer' customization for
 pdf-based presentation slides in 'RMarkdown'. At present it contains
 'RMarkdown' adaptations of the LaTeX themes 'Metropolis' (formerly 'mtheme')
 theme by Matthias Vogelgesang and others (now included in 'TeXLive'), the
 'IQSS' by Ista Zahn (which is included here), and the 'Monash' theme by
 Rob J Hyndman. Additional (free) fonts may be needed: 'Metropolis' prefers
 'Fira', and 'IQSS' requires 'Libertinus'.",2018-10-12,Dirk Eddelbuettel,https://github.com/eddelbuettel/binb,TRUE,https://github.com/eddelbuettel/binb,4238,73,1553654598
binman,"Tools and functions for managing the download of binary files.
    Binary repositories are defined in 'YAML' format. Defining new 
    pre-download, download and post-download templates allow additional 
    repositories to be added.",2018-07-18,John Harrison (original author),https://github.com/ropensci/binman,TRUE,https://github.com/ropensci/binman,81760,11,1547017532
binneR,A spectral binning approach for high resolution flow infusion mass spectrometry data.,2019-03-19,Jasen Finch,https://github.com/aberHRML/binneR,TRUE,https://github.com/aberhrml/binner,5607,0,1553006830
BinQuasi,Identify peaks in ChIP-seq data with biological replicates using a one-sided quasi-likelihood ratio test in quasi-Poisson or quasi-negative binomial models.,2018-07-27,Emily Goren,https://github.com/emilygoren/BinQuasi,TRUE,https://github.com/emilygoren/binquasi,4427,2,1532672019
bioacoustics,"Contains all the necessary tools to process audio recordings of
             various formats (e.g., WAV, WAC, MP3, ZC), filter noisy files, 
             display audio signals, detect and extract automatically acoustic
             features for further analysis such as classification.",2019-02-08,Jean Marchal,https://github.com/wavx/bioacoustics/,TRUE,https://github.com/wavx/bioacoustics,11256,15,1552584216
BioCircos,"Implement in 'R' interactive Circos-like visualizations of genomic data, to map information
	such as genetic variants, genomic fusions and aberrations to a circular genome, as proposed by the
	'JavaScript' library 'BioCircos.js', based on the 'JQuery' and 'D3' technologies. The output is by 
	default displayed in stand-alone HTML documents or in the 'RStudio' viewer pane. Moreover it can be
	integrated in 'R Markdown' documents and 'Shiny' applications.",2019-03-19,Loan Vulliard [trl,https://github.com/lvulliard/BioCircos.R,TRUE,https://github.com/lvulliard/biocircos.r,6385,19,1552403505
BiocManager,A convenient tool to install and update Bioconductor packages.,2018-11-13,Martin Morgan (<https://orcid.org/0000-0002-5874-8148>),NA,TRUE,https://github.com/bioconductor/biocmanager,253427,20,1554155736
biogram,"Tools for extraction and analysis of various
    n-grams (k-mers) derived from biological sequences (proteins
    or nucleic acids). Contains QuiPT (quick permutation test) for fast
    feature-filtering of the n-gram data.",2017-01-06,Michal Burdukiewicz,https://github.com/michbur/biogram,TRUE,https://github.com/michbur/biogram,16638,3,1553767849
BioInstaller,"
    Can be used to integrate massive bioinformatics resources, such as tool/script and database. It provides the R functions and Shiny web application. Hundreds of bioinformatics tool/script and database have been included.",2018-11-20,Jianfeng Li  (<https://orcid.org/0000-0003-2349-208X>),https://github.com/JhuangLab/BioInstaller,TRUE,https://github.com/jhuanglab/bioinstaller,28979,20,1542727846
biomartr,"Perform large scale genomic data retrieval and functional annotation retrieval. This package aims to provide users with a standardized
                way to automate genome, proteome, 'RNA', coding sequence ('CDS'), 'GFF', and metagenome
                retrieval from 'NCBI RefSeq', 'NCBI Genbank', 'ENSEMBL', 'ENSEMBLGENOMES',
                and 'UniProt' databases. Furthermore, an interface to the 'BioMart' database
                (Smedley et al. (2009) <doi:10.1186/1471-2164-10-22>) allows users to retrieve
                functional annotation for genomic loci. In addition, users can download entire databases such
                as 'NCBI RefSeq' (Pruitt et al. (2007) <doi:10.1093/nar/gkl842>), 'NCBI nr',
                'NCBI nt', 'NCBI Genbank' (Benson et al. (2013) <doi:10.1093/nar/gks1195>), etc. as
                well as 'ENSEMBL' and 'ENSEMBLGENOMES' with only one command.",2018-06-27,Hajk-Georg Drost  (<https://orcid.org/0000-0002-1567-306X>),https://github.com/ropensci/biomartr,TRUE,https://github.com/ropensci/biomartr,37444,94,1554225582
BIOMASS,"Contains functions to estimate aboveground biomass/carbon and its uncertainty in tropical forests. 
	These functions allow to (1) retrieve and to correct taxonomy, (2) estimate wood density and its uncertainty, 
	(3) construct height-diameter models, (4) manage tree and plot coordinates, 
	(5) estimate the aboveground biomass/carbon at the stand level with associated uncertainty. 
	To cite BIOMASS, please use citation(""BIOMASS""). 
	See more in the article of Réjou-Méchain et al. (2017) <doi:10.1111/2041-210X.12753>.",2019-03-26,Maxime Réjou-Méchain,https://github.com/AMAP-dev/BIOMASS,TRUE,https://github.com/amap-dev/biomass,11734,1,1553589774
BioMedR,"Calculating 293 chemical descriptors and 14 kinds of chemical fingerprints, 9920 protein descriptors based on protein sequences, more than 6000 DNA/RNA descriptors from nucleotide sequences, and six types of interaction descriptors using three different combining strategies. ",2019-04-04,Min-feng Zhu <wind2zhu@163.com>,https://github.com/wind22zhu/BioMedR,TRUE,https://github.com/wind22zhu/biomedr,1219,0,1523890937
bioRad,"Extract, visualize and summarize aerial movements of birds and
    insects from weather radar data.",2018-12-14,Adriaan M. Dokter  (<https://orcid.org/0000-0001-6573-066X>),"https://github.com/adokter/bioRad,
https://adokter.github.io/bioRad",TRUE,https://github.com/adokter/biorad,1525,9,1544821263
bioset,"Functions to help dealing with raw data from measurements, like
    reading and transforming raw values organized in matrices, calculating and
    converting concentrations and calculating precision of duplicates /
    triplicates / ... . It is compatible with and building on top of some
    'tidyverse'-packages.",2018-11-13,Eike Christian Kühn,https://github.com/randomchars42/bioset,TRUE,https://github.com/randomchars42/bioset,6243,2,1542118356
bipartite,"Functions to visualise webs and calculate a series of indices commonly used to describe pattern in (ecological) webs. It focuses on webs consisting of only two levels (bipartite), e.g. pollination webs or predator-prey-webs. Visualisation is important to get an idea of what we are actually looking at, while the indices summarise different aspects of the web's topology. ",2018-07-11,Carsten F. Dormann,https://github.com/biometry/bipartite,TRUE,https://github.com/biometry/bipartite,90246,9,1553449061
BIS,"Provides an interface to data provided by the Bank for International 
  Settlements <https://www.bis.org>, allowing for programmatic retrieval of a 
  large quantity of (central) banking data.",2018-05-22,Eric Persson,https://www.bis.org,TRUE,https://github.com/expersso/bis,6350,5,1526979620
bisect,"An implementation of Bisect, a method for inferring cell type composition of samples based on methylation sequencing data (Whole Genome Bisulfite Sequencing and Reduced Representation Sequencing). The method is specifically tailored for sequencing data, and therefore works better than methods developed for methylation arrays. It contains a supervised mode that requires a reference (the methylation probabilities in the pure cell types), and a semi-supervised mode, that requires cell counts for a subset of the samples, but does not require a reference.",2018-04-16,Eyal Fisher,https://github.com/EyalFisher/BiSect,TRUE,https://github.com/eyalfisher/bisect,2676,0,1523904149
BivRec,"Alternating recurrent event data arise frequently in biomedical and social sciences where 2 types of events such as hospital admissions and discharge occur alternatively over time. 
    As such we implement a collection of non-parametric and semiparametric methods to analyze such data.   
    The main functions are biv.rec.fit() and biv.rec.np(). Use biv.rec.fit() for estimation of covariate effects on the two alternating event gap times (xij and yij) using semiparametric methods. The method options are ""Lee.et.al"" and ""Chang"".   
    Use biv.rec.np() for estimation of the joint cumulative distribution function (cdf) for the two alternating events gap times (xij and yij) as well as the marginal survival function for type I gap times (xij) and the conditional cdf of the type II gap times (yij) given an interval of type I gap times (xij) in a non-parametric fashion.   
    The package also provides options to simulate and visualize the data and results of analysis. ",2018-11-16,Sandra Castro-Pearson,NA,TRUE,https://github.com/sandracastropearson/bivrec,1737,1,1553790334
biwavelet,"This is a port of the WTC MATLAB package written by Aslak Grinsted
    and the wavelet program written by Christopher Torrence and Gibert P.
    Compo. This package can be used to perform univariate and bivariate
    (cross-wavelet, wavelet coherence, wavelet clustering) analyses.",2018-05-19,Tarik C. Gouhier,https://github.com/tgouhier/biwavelet,TRUE,https://github.com/tgouhier/biwavelet,34495,18,1535549173
bizdays,"Business days calculations based on a list of holidays and
    nonworking weekdays. Quite useful for fixed income and derivatives pricing.",2018-06-25,Wilson Freitas <wilson.freitas@gmail.com>,https://github.com/wilsonfreitas/R-bizdays,TRUE,https://github.com/wilsonfreitas/r-bizdays,63921,22,1554370851
bjscrapeR,"Drawing heavy influence from 'blscrapeR', this package scrapes crime data from <https://www.bjs.gov/>. Specifically, it scrapes data from the National Crime Victimization Survey which tracks personal and household crime in the USA. The idea is to utilize the 'tidyverse' methodology to create an efficient work flow when dealing with crime statistics.",2018-06-06,Dylan McDowell,https://github.com/dylanjm/bjscrapeR,TRUE,https://github.com/dylanjm/bjscraper,2704,3,1530031071
blandr,"Carries out Bland Altman analyses (also known as a Tukey
    mean-difference plot) as described by JM Bland and DG Altman in
    1986 <doi:10.1016/S0140-6736(86)90837-8>. This package was created in 
    2015 as existing Bland-Altman analysis functions did not calculate 
    confidence intervals. This package was created to rectify this, 
    and create reproducible plots. This package is also available as a module
    for the 'jamovi' statistical spreadsheet (see <https://www.jamovi.org>
    for more information).",2018-05-10,Deepankar Datta,https://github.com/deepankardatta/blandr/,TRUE,https://github.com/deepankardatta/blandr,6928,7,1548686068
blastula,"Compose and send out responsive HTML email messages that render
    perfectly across a range of email clients and device sizes. Messages are
    composed using 'Markdown' and a text interpolation system that allows for
    the injection of evaluated R code within the message body, footer, and
    subject line. Helper functions let the user insert embedded images, web
    link buttons, and 'ggplot2' plot objects into the message body. Messages
    can be sent through an 'SMTP' server or through the 'Mailgun' API service
    <http://mailgun.com/>.",2018-07-19,Richard Iannone  (<https://orcid.org/0000-0003-3925-190X>),https://github.com/rich-iannone/blastula,TRUE,https://github.com/rich-iannone/blastula,10566,188,1553177963
blme,"Maximum a posteriori estimation for linear and generalized
             linear mixed-effects models in a Bayesian setting. Extends
             'lme4' by Douglas Bates, Martin Maechler, Ben Bolker, and Steve Walker.",2015-06-14,Vincent Dorie <vjd4@nyu.edu>,https://github.com/vdorie/blme,TRUE,https://github.com/vdorie/blme,118844,14,1548384631
blob,"R's raw vector is useful for storing a single binary object.
    What if you want to put a vector of them in a data frame? The 'blob'
    package provides the blob object, a list of raw vectors, suitable for
    use as a column in data frame.",2018-03-25,Kirill Müller,https://github.com/tidyverse/blob,TRUE,https://github.com/tidyverse/blob,1448135,21,1553334597
blockseg,"Segments a matrix in blocks with constant values.
    BRAULT V, CHIQUET J. and LEVY-LEDUC C. (2017) <doi:10.1214/17-EJS1270>.",2018-07-03,"Authors@R: c(
    person(Julien",https://github.com/jchiquet/blockseg (dev version),TRUE,https://github.com/jchiquet/blockseg,8978,0,1552063477
blogdown,"Write blog posts and web pages in R Markdown. This package supports
    the static site generator 'Hugo' (<https://gohugo.io>) best, and it also
    supports 'Jekyll' (<http://jekyllrb.com>) and 'Hexo' (<https://hexo.io>).",2019-03-11,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/rstudio/blogdown,TRUE,https://github.com/rstudio/blogdown,63702,930,1552582269
blorr,"Tools designed to make it easier for beginner and intermediate users to build and validate 
    binary logistic regression models. Includes bivariate analysis, comprehensive regression output, 
    model fit statistics, variable selection procedures, model validation techniques and a 'shiny' 
    app for interactive model building.",2019-03-12,Aravind Hebbali  (<https://orcid.org/0000-0001-9220-9669>),"URL: https://blorr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/blorr",TRUE,https://github.com/rsquaredacademy/blorr,4180,9,1552461177
blscrapeR,"Scrapes various data from <https://www.bls.gov/>. The U.S. Bureau of Labor Statistics is the statistical branch of the United States Department of Labor. The package has additional functions to help parse, analyze and visualize the data.",2019-01-29,Kris Eberwein,https://github.com/keberwein/blscrapeR,TRUE,https://github.com/keberwein/blscraper,23516,50,1548866413
bmlm,Easy estimation of Bayesian multilevel mediation models with Stan.,2019-02-21,Matti Vuorre  (<https://orcid.org/0000-0001-5052-066X>),https://github.com/mvuorre/bmlm/,TRUE,https://github.com/mvuorre/bmlm,21403,16,1550777883
BMRBr,"Nuclear magnetic resonance (NMR) is a highly versatile analytical technique for studying molecular configuration, conformation, 
        and dynamics, especially those of biomacromolecules such as proteins. Biological Magnetic Resonance Data Bank ('BMRB') is a repository
        for Data from NMR Spectroscopy on Proteins, Peptides, Nucleic Acids, and other Biomolecules. Currently, 'BMRB' offers an R package 
        'RBMRB' to fetch data, however, it doesn't easily offer individual data file downloading and storing in a local directory. When using 
        'RBMRB', the data will stored as an R object, which fundamentally hinders the NMR researches to access the rich information from raw 
        data, for example, the metadata. Here, 'BMRBr' File Downloader ('BMRBr') offers a more fundamental, low level downloader, which will 
        download original deposited .str format file. This type of file contains information such as entry title, authors, citation, protein
        sequences, and so on.
        Many factors affect NMR experiment outputs, such as temperature, resonance sensitivity and etc., approximately 40% of the entries in the 'BMRB' have 
        chemical shift accuracy problems [1,2] Unfortunately, current reference correction methods are heavily dependent on the availability of
        assigned protein chemical shifts or protein structure. This is my current research project is going to solve, which will be included
        in the future release of the package. The current version of the package is sufficient and robust enough for downloading individual 
        'BMRB' data file from the 'BMRB' database <http://www.bmrb.wisc.edu>. The functionalities of this package includes but not limited:
        * To simplifies NMR researches by combine data downloading and results analysis together.
        * To allows NMR data reaches a broader audience that could utilize more than just chemical shifts but also metadata.
        * To offer reference corrected data for entries without assignment or structure information (future release).
        Reference:
        [1] E.L. Ulrich, H. Akutsu, J.F. Doreleijers, Y. Harano, Y.E. Ioannidis, J. Lin, et al., BioMagResBank, Nucl. Acids Res. 36 (2008) D402–8. <doi:10.1093/nar/gkm957>.
        [2] L. Wang, H.R. Eghbalnia, A. Bahrami, J.L. Markley, Linear analysis of carbon-13 chemical shift differences and its application to the detection and correction of errors in referencing and spin system identifications, J. Biomol. NMR. 32 (2005) 13–22. <doi:10.1007/s10858-005-1717-0>.",2018-08-24,Xi Chen  (<https://orcid.org/0000-0001-7094-6748>),https://github.com/billchenxi/BMRBr,TRUE,https://github.com/billchenxi/bmrbr,4524,1,1552016555
BMTME,"Genomic selection and prediction models with the capacity to use multiple traits and environments, through ready-to-use Bayesian models. It consists a group of functions 
             that help to create regression models for some genomic models proposed by Montesinos-López, et al. (2016) <doi:10.1534/g3.116.032359>
             also in Montesinos-López et al. (2018) <doi:10.1534/g3.118.200728> and Montesinos-López et al. (2018) <doi:10.2134/agronj2018.06.0362>.",2019-02-12,"Francisco Javier Luna-Vazquez 
    (<https://orcid.org/0000-0002-5370-7152>)",https://github.com/frahik/BMTME,TRUE,https://github.com/frahik/bmtme,937,3,1553391691
bnclassify,"State-of-the art algorithms for learning discrete Bayesian network classifiers from data, including a number of those described in Bielza & Larranaga (2014) <doi:10.1145/2576868>, with functions for prediction, model evaluation and inspection.",2019-03-14,Mihaljevic Bojan,http://github.com/bmihaljevic/bnclassify,TRUE,https://github.com/bmihaljevic/bnclassify,17527,16,1554312211
bnpsd,"The Pritchard-Stephens-Donnelly (PSD) admixture model has k intermediate subpopulations from which n individuals draw their alleles dictated by their individual-specific admixture proportions.  The BN-PSD model additionally imposes the Balding-Nichols (BN) allele frequency model to the intermediate populations, which therefore evolved independently from a common ancestral population T with subpopulation-specific FST (Wright's fixation index) parameters.  The BN-PSD model can be used to yield complex population structures.  Method described in Ochoa and Storey (2016) <doi:10.1101/083923>.",2019-02-12,Alejandro Ochoa,https://github.com/StoreyLab/bnpsd/,TRUE,https://github.com/storeylab/bnpsd,3849,4,1550087321
bnspatial,"Allows spatial implementation of Bayesian networks and mapping in geographical space. It makes maps of expected value (or most likely state) given known and unknown conditions, maps of uncertainty measured as coefficient of variation or Shannon index (entropy), maps of probability associated to any states of any node of the network. Some additional features are provided as well: parallel processing options, data discretization routines and function wrappers designed for users with minimal knowledge of the R language. Outputs can be exported to any common GIS format. Development was funded by the European Union FP7 (2007-2013), under project ROBIN (<http://robinproject.info>).",2019-03-21,Dario Masante,http://github.com/dariomasante/bnspatial,TRUE,https://github.com/dariomasante/bnspatial,13188,8,1553260076
bold,"A programmatic interface to the Web Service methods provided by
    Bold Systems (<http://www.boldsystems.org/>) for genetic 'barcode' data.
    Functions include methods for searching by sequences by taxonomic names,
    ids, collectors, and institutions; as well as a function for searching
    for specimens, and downloading trace files.",2018-12-14,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/bold,TRUE,https://github.com/ropensci/bold,114631,10,1552004666
bomrang,"Provides functions to interface with Australian Government Bureau
    of Meteorology ('BOM') data, fetching data and returning a tidy data frame
    of precis forecasts, historical and current weather data from stations,
    agriculture bulletin data, 'BOM' 0900 or 1500 weather bulletins and
    downloading and importing radar and satellite imagery files.  Data (c)
    Australian Government Bureau of Meteorology Creative Commons (CC)
    Attribution 3.0 licence or Public Access Licence (PAL) as appropriate.  See
    <http://www.bom.gov.au/other/copyright.shtml> for further details.",2019-03-21,Adam Sparks  (<https://orcid.org/0000-0002-0061-8359>),"https://github.com/ropensci/bomrang,
https://ropensci.github.io/bomrang/",TRUE,https://github.com/ropensci/bomrang,17588,47,1554547089
bookdown,Output formats and utilities for authoring books and technical documents with R Markdown.,2018-12-21,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/rstudio/bookdown,TRUE,https://github.com/rstudio/bookdown,254749,1377,1553542138
bookdownplus,"A collection and selector of R 'bookdown' templates. 'bookdownplus' helps you write academic journal articles, guitar books, chemical equations, mails, calendars, and diaries. R 'bookdownplus' extends the features of 'bookdown', and simplifies the procedure. Users only have to choose a template, clarify the book title and author name, and then focus on writing the text. No need to struggle in 'YAML' and 'LaTeX'.",2019-03-03,Peng Zhao,https://github.com/pzhaonet/bookdownplus,TRUE,https://github.com/pzhaonet/bookdownplus,17427,136,1554364213
bootstrapFP,"Finite Population bootstrap algorithms to estimate the variance
    of the Horvitz-Thompson estimator for single-stage sampling. 
    For a survey of bootstrap methods for finite populations, see Mashreghi et Al. (2016) <doi:10.1214/16-SS113>.",2019-02-24,Roberto Sichera,NA,TRUE,https://github.com/rhobis/bootstrapfp,845,0,1551003738
BootstrapQTL,"Identifies genome-related molecular traits with significant 
  evidence of genetic regulation and performs a bootstrap procedure to 
  correct estimated effect sizes for over-estimation present in cis-QTL
  mapping studies (The ""Winner's Curse""), described in Huang QQ *et al.* 
  2018 <doi: 10.1093/nar/gky780>. ",2018-09-21,Scott Ritchie,NA,TRUE,https://github.com/inouyelab/bootstrapqtl,2022,3,1536941993
boxr,"An R interface for the remote file hosting service 'Box' 
    (<https://www.box.com/>). In addition to uploading and downloading files,
    this package includes functions which mirror base R operations for local 
    files, (e.g. box_load(), box_save(), box_read(), box_setwd(), etc.), as well
    as 'git' style functions for entire directories (e.g. box_fetch(), 
    box_push()).",2017-01-12,Brendan Rocks,https://github.com/brendan-r/boxr/,TRUE,https://github.com/brendan-r/boxr,18760,35,1553895826
bpbounds,"Implementation of the nonparametric bounds for the average causal 
    effect under an instrumental variable model by Balke and Pearl (Bounds on 
    Treatment Effects from Studies with Imperfect Compliance, JASA, 1997, 92, 
    439, 1171-1176). The package can calculate bounds for a binary outcome, a 
    binary treatment/phenotype, and an instrument with either 2 or 3 
    categories. The package implements bounds for situations where these 3 
    variables are measured in the same dataset (trivariate data) or where the 
    outcome and instrument are measured in one study and the 
    treatment/phenotype and instrument are measured in another study 
    (bivariate data).",2019-02-10,Tom Palmer  (<https://orcid.org/0000-0003-4655-4511>),https://github.com/remlapmot/bpbounds,TRUE,https://github.com/remlapmot/bpbounds,2163,0,1549801092
bpnreg,"Fitting Bayesian multiple and mixed-effect regression models for 
    circular data based on the projected normal distribution. Both continuous 
    and categorical predictors can be included. Sampling from the posterior is 
    performed via an MCMC algorithm. Posterior descriptives of all parameters, 
    model fit statistics and Bayes factors for hypothesis tests for inequality 
    constrained hypotheses are provided. See Cremers, Mulder & Klugkist (2018) 
    <doi:10.1111/bmsp.12108> and Nuñez-Antonio & Guttiérez-Peña (2014) 
    <doi:10.1016/j.csda.2012.07.025>.",2018-02-27,Jolien Cremers,https://github.com/joliencremers/bpnreg,TRUE,https://github.com/joliencremers/bpnreg,2913,1,1547560965
BradleyTerry2,"Specify and fit the Bradley-Terry model, including structured versions in which the parameters are related to explanatory variables through a linear predictor and versions with contest-specific effects, such as a home advantage.",2019-02-25,Heather Turner,https://github.com/hturner/BradleyTerry2,TRUE,https://github.com/hturner/bradleyterry2,418687,8,1552408867
BradleyTerryScalable,"Facilities are provided for fitting the simple, unstructured Bradley-Terry model to networks of binary comparisons. The implemented methods are designed to scale well to large, potentially sparse, networks. A fairly high degree of scalability is achieved through the use of EM and MM algorithms, which are relatively undemanding in terms of memory usage (relative to some other commonly used methods such as iterative weighted least squares, for example). Both maximum likelihood and Bayesian MAP estimation methods are implemented. The package provides various standard methods for a newly defined 'btfit' model class, such as the extraction and summarisation of model parameters and the simulation of new datasets from a fitted model. Tools are also provided for reshaping data into the newly defined ""btdata"" class, and for analysing the comparison network, prior to fitting the Bradley-Terry model. This package complements, rather than replaces, the existing 'BradleyTerry2' package. (BradleyTerry2 has rather different aims, which are mainly the specification and fitting of ""structured"" Bradley-Terry models in which the strength parameters depend on covariates.)",2017-06-29,Ella Kaye,https://github.com/EllaKaye/BradleyTerryScalable,TRUE,https://github.com/ellakaye/bradleyterryscalable,5080,10,1533663278
BrailleR,"Blind users do not have access to the graphical output from R
    without printing the content of graphics windows to an embosser of some kind. This
    is not as immediate as is required for efficient access to statistical output.
    The functions here are created so that blind people can make even better use
    of R. This includes the text descriptions of graphs, convenience functions
    to replace the functionality offered in many GUI front ends, and experimental
    functionality for optimising graphical content to prepare it for embossing as
    tactile images.",2018-08-10,A. Jonathan R. Godfrey,https://github.com/ajrgodfrey/BrailleR,TRUE,https://github.com/ajrgodfrey/brailler,26451,32,1548460027
brainGraph,"A set of tools for performing graph theory analysis of brain MRI
    data. It works with data from a Freesurfer analysis (cortical thickness,
    volumes, local gyrification index, surface area), diffusion tensor
    tractography data (e.g., from FSL) and resting-state fMRI data (e.g., from
    DPABI). It contains a graphical user interface for graph visualization and
    data exploration, along with several functions for generating useful
    figures.",2018-05-29,Christopher G. Watson <cgwatson@bu.edu>,https://github.com/cwatson/brainGraph,TRUE,https://github.com/cwatson/braingraph,16267,51,1544853850
brandwatchR,"Interact with the 'Brandwatch' API <https://developers.brandwatch.com/docs>. 
  Allows you to authenticate to the API and obtain data for projects, queries, query groups tags and categories.
  Also allows you to directly obtain mentions and aggregate data for a specified query or query group.",2018-08-13,Donal Phipps,https://github.com/Phippsy/brandwatchR,TRUE,https://github.com/phippsy/brandwatchr,2350,9,1534428545
breakDown,"Model agnostic tool for decomposition of predictions from black boxes.
    Break Down Table shows contributions of every variable to a final prediction. 
    Break Down Plot presents variable contributions in a concise graphical way. 
    This package work for binary classifiers and general regression models. ",2018-06-14,Przemyslaw Biecek,https://pbiecek.github.io/breakDown/,TRUE,https://github.com/pbiecek/breakdown,13615,72,1553643040
breathtestcore,"Reads several formats of 13C data (IRIS/Wagner, BreathID) and CSV.
        Creates artificial sample data for testing. 
        Fits Maes/Ghoos, Bluck-Coward self-correcting formula using 'nls', 'nlme'.
        Methods to fit breath test curves with Bayesian Stan methods are refactored to 
        package 'breathteststan'. For a Shiny GUI, see package 
        'dmenne/breathtestshiny' on github.",2018-12-18,Dieter Menne,https://github.com/dmenne/breathtestcore,TRUE,https://github.com/dmenne/breathtestcore,8186,1,1551173088
breathteststan,"Stan-based curve-fitting function
  for use with package 'breathtestcore' by the same author.
  Stan functions are refactored here for easier testing.",2018-11-07,Dieter Menne,https://github.com/dmenne/breathteststan,TRUE,https://github.com/dmenne/breathteststan,10919,2,1541579272
bReeze,"A collection of functions to analyse, visualize and interpret wind data
         and to calculate the potential energy production of wind turbines.",2018-11-14,Christian Graul and Carsten Poppinga,https://github.com/chgrl/bReeze,TRUE,https://github.com/chgrl/breeze,22938,13,1541967721
brglm,"Fit generalized linear models with binomial responses using either an adjusted-score approach to bias reduction or maximum penalized likelihood where penalization is by Jeffreys invariant prior. These procedures return estimates with improved frequentist properties (bias, mean squared error) that are always finite even in cases where the maximum likelihood estimates are infinite (data separation). Fitting takes place by fitting generalized linear models on iteratively updated pseudo-data. The interface is essentially the same as 'glm'.  More flexibility is provided by the fact that custom pseudo-data representations can be specified and used for model fitting. Functions are provided for the construction of confidence intervals for the reduced-bias estimates.",2019-04-02,Ioannis Kosmidis  (<https://orcid.org/0000-0003-1556-0302>),https://github.com/ikosmidis/brglm,TRUE,https://github.com/ikosmidis/brglm,408252,0,1554218062
brglm2,"Estimation and inference from generalized linear models based on various methods for bias reduction. The 'brglmFit' fitting method can achieve reduction of estimation bias by solving either the mean bias-reducing adjusted score equations in Firth (1993) <doi:10.1093/biomet/80.1.27> and Kosmidis and Firth (2009) <doi:10.1093/biomet/asp055>, or the median bias-reduction adjusted score equations in Kenne et al. (2016) <arXiv:1604.04768>, or through the direct subtraction of an estimate of the bias of the maximum likelihood estimator from the maximum likelihood estimates as in Cordeiro and McCullagh (1991) <http://www.jstor.org/stable/2345592>. Estimation in all cases takes place via a quasi Fisher scoring algorithm, and S3 methods for the construction of of confidence intervals for the reduced-bias estimates are provided. In the special case of generalized linear models for binomial and multinomial responses (both ordinal and nominal), the adjusted score approaches return estimates with improved frequentist properties, that are also always finite, even in cases where the maximum likelihood estimates are infinite (e.g. complete and quasi-complete separation). 'brglm2' also provides pre-fit and post-fit methods for detecting separation and infinite maximum likelihood estimates in binomial response generalized linear models.",2019-02-14,Ioannis Kosmidis  (<https://orcid.org/0000-0003-1556-0302>),https://github.com/ikosmidis/brglm2,TRUE,https://github.com/ikosmidis/brglm2,11192,2,1550165259
bridgesampling,"Provides functions for estimating marginal likelihoods, Bayes
    factors, posterior model probabilities, and normalizing constants in general,
    via different versions of bridge sampling (Meng & Wong, 1996, 
    <http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n43/j6n43.htm>).",2018-10-21,Quentin F. Gronau  (<https://orcid.org/0000-0001-5510-6943>),https://github.com/quentingronau/bridgesampling,TRUE,https://github.com/quentingronau/bridgesampling,77987,17,1546942516
BRISC,Fits Bootstrap with univariate spatial regression models using Bootstrap for Rapid Inference on Spatial Covariances (BRISC) for large datasets using Nearest Neighbor Gaussian Processes detailed in Saha and Datta (2018) <doi:10.1002/sta4.184>.,2018-07-22,Arkajyoti Saha,https://github.com/ArkajyotiSaha/BRISC,TRUE,https://github.com/arkajyotisaha/brisc,2383,0,1532036212
brms,"Fit Bayesian generalized (non-)linear multivariate multilevel models
    using 'Stan' for full Bayesian inference. A wide range of distributions 
    and link functions are supported, allowing users to fit -- among others -- 
    linear, robust linear, count data, survival, response times, ordinal, 
    zero-inflated, hurdle, and even self-defined mixture models all in a 
    multilevel context. Further modeling options include non-linear and 
    smooth terms, auto-correlation structures, censored data, meta-analytic 
    standard errors, and quite a few more. In addition, all parameters of the 
    response distribution can be predicted in order to perform distributional 
    regression. Prior specifications are flexible and explicitly encourage 
    users to apply prior distributions that actually reflect their beliefs.
    Model fit can easily be assessed and compared with posterior predictive 
    checks and leave-one-out cross-validation. References: Bürkner (2017)
    <doi:10.18637/jss.v080.i01>; Carpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",2019-03-15,Paul-Christian Bürkner,"https://github.com/paul-buerkner/brms,
http://discourse.mc-stan.org",TRUE,https://github.com/paul-buerkner/brms,232606,482,1554471589
Brobdingnag,"Handles very large numbers in R.  Real numbers are held
        using their natural logarithms, plus a logical flag indicating
        sign.  The package includes a vignette that gives a
        step-by-step introduction to using S4 methods.",2018-08-13,Robin K. S. Hankin,https://github.com/RobinHankin/Brobdingnag.git,TRUE,https://github.com/robinhankin/brobdingnag,102758,0,1550519799
broman,"Miscellaneous R functions, including functions related to
    graphics (mostly for base graphics), permutation tests, running
    mean/median, and general utilities.",2018-07-25,Karl W Broman <kbroman@biostat.wisc.edu>,https://github.com/kbroman/broman,TRUE,https://github.com/kbroman/broman,32825,133,1553092138
broom,"Summarizes key information about statistical
    objects in tidy tibbles. This makes it easy to report results, create
    plots and consistently work with large numbers of models at once.
    Broom provides three verbs that each provide different types of
    information about a model. tidy() summarizes information about model
    components such as coefficients of a regression. glance() reports
    information about an entire model, such as goodness of fit measures
    like AIC and BIC. augment() adds information about individual
    observations to a dataset, such as fitted values or influence
    measures.",2018-12-05,Alex Hayes  (<https://orcid.org/0000-0002-4985-5160>),http://github.com/tidyverse/broom,TRUE,https://github.com/tidyverse/broom,4171850,840,1554435363
broom.mixed,"Convert fitted objects from various R mixed-model packages
    into tidy data frames along the lines of the 'broom' package.
    The package provides three
    S3 generics for each model: tidy(), which summarizes a model's statistical findings such as
    coefficients of a regression; augment(), which adds columns to the original
    data such as predictions, residuals and cluster assignments; and glance(), which
    provides a one-row summary of model-level statistics.",2019-02-21,Ben Bolker  (<https://orcid.org/0000-0002-2127-0443>),http://github.com/bbolker/broom.mixed,TRUE,https://github.com/bbolker/broom.mixed,10398,106,1552526379
broomExtra,"Collection of functions to assist 'broom' and
    'broom.mixed' package-related data analysis workflows. In particular,
    the generic functions tidy(), glance(), and augment() choose
    appropriate S3 methods from these two packages depending on which
    package exports the needed method. Additionally, 'grouped_' variants
    of the generics provides a convenient way to execute functions across
    a combination of grouping variable(s) in a dataframe.",2019-04-03,Indrajeet Patil  (<https://orcid.org/0000-0003-1995-6531>),"https://indrajeetpatil.github.io/broomExtra/,
https://github.com/IndrajeetPatil/broomExtra",TRUE,https://github.com/indrajeetpatil/broomextra,1822,6,1554307717
brranching,"Includes methods for fetching 'phylogenies' from a variety
    of sources, including the 'Phylomatic' web service 
    (<http://phylodiversity.net/phylomatic>), and 'Phylocom' 
    (<https://github.com/phylocom/phylocom/>).",2018-12-05,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/brranching,TRUE,https://github.com/ropensci/brranching,15257,10,1552069168
brunnermunzel,"Provides the functions for Brunner-Munzel test and
    permuted Brunner-Munzel test,
    which enable to use formula, matrix, and table as argument.
    These functions are based on Brunner and Munzel (2000)
     <doi:10.1002/(SICI)1521-4036(200001)42:1%3C17::AID-BIMJ17%3E3.0.CO;2-U>
    and Neubert and Brunner (2007) <doi:10.1016/j.csda.2006.05.024>,
    and are written with FORTRAN.",2019-03-28,Toshiaki Ara,https://github.com/toshi-ara/brunnermunzel,TRUE,https://github.com/toshi-ara/brunnermunzel,1053,2,1553778759
bs4Dash,"Make 'Bootstrap 4' dashboards. Use the full power
    of 'AdminLTE3', a dashboard template built on top of 'Bootstrap 4' 
    <https://github.com/almasaeed2010/AdminLTE/tree/v3-dev>.",2019-04-06,David Granjon,"https://rinterface.github.io/bs4Dash/index.html,
https://github.com/RinteRface/bs4Dash",TRUE,https://github.com/rinterface/bs4dash,5237,77,1554559401
bsam,"Tools to fit Bayesian state-space models to animal tracking data. Models are provided for location 
    filtering, location filtering and behavioural state estimation, and their hierarchical versions. 
    The models are primarily intended for fitting to ARGOS satellite tracking data but options exist to fit 
    to other tracking data types. For Global Positioning System data, consider the 'moveHMM' package. 
    Simplified Markov Chain Monte Carlo convergence diagnostic plotting is provided but users are encouraged 
    to explore tools available in packages such as 'coda' and 'boa'.",2017-07-01,Ian Jonsen,https://github.com/ianjonsen/bsam,TRUE,https://github.com/ianjonsen/bsam,9826,13,1525723049
bsplus,"The Bootstrap framework lets you add some JavaScript functionality to your web site by
  adding attributes to your HTML tags - Bootstrap takes care of the JavaScript
  <https://getbootstrap.com/javascript>. If you are using R Markdown or Shiny, you can
  use these functions to create collapsible sections, accordion panels, modals, tooltips,
  popovers, and an accordion sidebar framework (not described at Bootstrap site).",2018-04-05,Ian Lyttle,https://github.com/ijlyttle/bsplus,TRUE,https://github.com/ijlyttle/bsplus,10600,79,1550627039
bssm,"Efficient methods for Bayesian inference of state space models 
    via particle Markov chain Monte Carlo and parallel importance sampling type weighted 
    Markov chain Monte Carlo (Vihola, Helske, and Franks, 2017, <arXiv:1609.02541>). 
    Gaussian, Poisson, binomial, or negative binomial 
    observation densities and basic stochastic volatility models with Gaussian state 
    dynamics, as well as general non-linear Gaussian models and discretised diffusion models 
    are supported.",2018-11-22,Jouni Helske,NA,TRUE,https://github.com/helske/bssm,11849,8,1554476142
btergm,"Temporal Exponential Random Graph Models (TERGM) estimated by maximum pseudolikelihood with bootstrapped confidence intervals or Markov Chain Monte Carlo maximum likelihood. Goodness of fit assessment for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs.",2018-08-24,Philip Leifeld,http://github.com/leifeld/btergm,TRUE,https://github.com/leifeld/btergm,84770,6,1554558835
bucky,"Provides functions for various statistical techniques commonly used in the social sciences, including functions to compute clustered robust standard errors, combine results across multiply-imputed data sets, and simplify the addition of robust and clustered robust standard errors. The package was originally developed, in part, to assist porting of replication code from 'Stata' and attempts to replicate default options from 'Stata' where possible.",2018-10-29,Alexander Tahk,http://github.com/atahk/bucky,TRUE,https://github.com/atahk/bucky,5706,2,1547572771
buildmer,"Finds the largest possible regression model that will still converge
    for various types of regression analyses (including mixed models and generalized
    additive models) and then optionally performs stepwise elimination similar to the
    forward and backward effect selection methods in SAS, based on the change in
    log-likelihood, Akaike's Information Criterion, or the Bayesian Information Criterion.",2019-03-31,Cesko Voeten,NA,TRUE,https://github.com/cvoeten/buildmer,195,0,1554207798
burnr,Basic tools to analyze forest fire history data (e.g. FHX) in R.,2019-03-08,Steven Malevich,https://github.com/ltrr-arizona-edu/burnr/,TRUE,https://github.com/ltrr-arizona-edu/burnr,13846,6,1552074703
busdater,"Get a current financial year, start of current
    month, End of current month, start of financial year and end of it.
    Allow for offset from the date.",2019-01-30,Mick Mioduszewski,"https://mickmioduszewski.github.io/busdater/,
https://github.com/mickmioduszewski/busdater/",TRUE,https://github.com/mickmioduszewski/busdater,934,0,1548872760
BuyseTest,"Implementation of the Generalized Pairwise Comparisons (GPC).
             GPC compare two groups of observations (intervention vs. control group)
			 regarding several prioritized endpoints.
			 The net benefit and win ratio statistics can then be estimated
			 and corresponding confidence intervals and p-values can be
			 estimated using resampling methods or the asymptotic U-statistic
			 theory. The software enables the use of thresholds of minimal
			 importance difference, stratification, and corrections to deal
			 with right-censored endpoints or missing values.",2019-01-16,Brice Ozenne  (<https://orcid.org/0000-0001-9694-2956>),https://github.com/bozenne/BuyseTest,TRUE,https://github.com/bozenne/buysetest,11343,0,1554141419
BWStest,"Performs the 'Baumgartner-Weiss-Schindler' two-sample test of equal
   probability distributions, <doi:10.2307/2533862>. Also performs
   similar rank-based tests for equal probability distributions due to
   Neuhauser <doi:10.1080/10485250108832874> and
   Murakami <doi:10.1080/00949655.2010.551516>.",2018-10-18,Steven E. Pav  (<https://orcid.org/0000-0002-4197-6195>),https://github.com/shabbychef/BWStest,TRUE,https://github.com/shabbychef/bwstest,19211,0,1539835005
bysykkel,"Functions to get, download, and read open data from each City Bike
    website, and each City Bike API, in Norway that is made available under the
    NLOD 2.0 <https://data.norge.no/nlod/en/2.0>. These functions speed up the
    process of reading city bike data directly to R, and to download the data 
    to disk, so that the user can focus on data analysis. The data is 
    retrieved from the ""developer"" or ""open data"" pages of 
    Oslo City Bike <https://developer.oslobysykkel.no/>, 
    Oslo Winter Bike <https://oslovintersykkel.no/en/open-data>, 
    Bergen City Bike <https://bergenbysykkel.no/en/open-data>, and
    Trondheim City Bike <https://trondheimbysykkel.no/en/open-data>.",2019-03-31,Iman Ghayoornia,http://github.com/PersianCatsLikeToMeow/bysykkel,TRUE,https://github.com/persiancatsliketomeow/bysykkel,184,0,1553448110
c14bazAAR,"Query different C14 date databases and apply basic data cleaning, merging and calibration steps.",2018-10-28,Clemens Schmid,https://github.com/ISAAKiel/c14bazAAR,TRUE,https://github.com/isaakiel/c14bazaar,1855,8,1540801236
c3,"Create interactive charts with the 'C3.js' <http://c3js.org/> charting library. All plot 
    types in 'C3.js' are available and include line, bar, scatter, and mixed geometry plots. Plot 
    annotations, labels and axis are highly adjustable. Interactive web based charts can be embedded 
    in R Markdown documents or Shiny web applications. ",2018-05-29,Matt Johnson,https://github.com/mrjoh3/c3,TRUE,https://github.com/mrjoh3/c3,3436,31,1544843486
C50,"C5.0 decision trees and rule-based models for pattern recognition that extend the work of Quinlan (1993, ISBN:1-55860-238-0).",2018-05-22,Max Kuhn,https://topepo.github.io/C5.0,TRUE,https://github.com/topepo/c5.0,362755,31,1527011871
caesar,"Encrypts and decrypts strings using either the Caesar cipher or a
    pseudorandom number generation (using set.seed()) method.",2017-01-18,Jacob Kaplan,https://github.com/jacobkap/caesar,TRUE,https://github.com/jacobkap/caesar,5917,1,1545065848
caffsim,"Simulate plasma caffeine concentrations using population pharmacokinetic model described in Lee, Kim, Perera, McLachlan and Bae (2015) <doi:10.1007/s00431-015-2581-x>.",2017-08-28,Sungpil Han,https://github.com/asancpt/caffsim,TRUE,https://github.com/asancpt/caffsim,4853,2,1533625164
CAISEr,"Functions for performing experimental comparisons of algorithms 
             using adequate sample sizes for power and accuracy.",2018-07-24,Felipe Campelo,https://fcampelo.github.io/CAISEr/,TRUE,https://github.com/fcampelo/caiser,5255,1,1532402689
calibrar,"Automated parameter estimation for complex (ecological) models in R. 
  This package allows the parameter estimation or calibration of complex models, 
  including stochastic ones. It is a generic tool that can be used for fitting 
  any type of models, especially those with non-differentiable objective functions. 
  It supports multiple phases and constrained optimization. 
  It implements maximum likelihood estimation methods and automated construction 
  of the objective function from simulated model outputs. 
  See <http://roliveros-ramos.github.io/calibrar> for more details.",2016-02-17,Ricardo Oliveros-Ramos,http://roliveros-ramos.github.io/calibrar,TRUE,https://github.com/roliveros-ramos/calibrar,7708,3,1549327443
calibrator,"Performs Bayesian calibration of computer models as per
 Kennedy and O'Hagan 2001.  The package includes routines to find the
 hyperparameters and parameters; see the help page for stage1() for a
 worked example using the toy dataset.  A tutorial is provided in the
 calex.Rnw vignette; and a suite of especially simple one dimensional
 examples appears in inst/doc/one.dim/.",2019-03-07,Robin K. S. Hankin  (<https://orcid.org/0000-0001-5982-0415>),https://github.com/RobinHankin/calibrator.git,TRUE,https://github.com/robinhankin/calibrator,28498,0,1551900104
calpassapi,"Implements methods for querying data from CalPASS using its API.
 CalPASS Plus.  MMAP API V1. <https://mmap.calpassplus.org/docs/index.html>.",2018-08-27,Vinh Nguyen,https://github.com/vinhdizzo/calpassapi,TRUE,https://github.com/vinhdizzo/calpassapi,2573,0,1535394464
camsRad,"Copernicus Atmosphere Monitoring Service (CAMS) radiations service 
    provides time series of global, direct, and diffuse irradiations on horizontal
    surface, and direct irradiation on normal plane for the actual weather 
    conditions as well as for clear-sky conditions.
    The geographical coverage is the field-of-view of the Meteosat satellite,
    roughly speaking Europe, Africa, Atlantic Ocean, Middle East. The time coverage
    of data is from 2004-02-01 up to 2 days ago. Data are available with a time step
    ranging from 15 min to 1 month. For license terms and to create an account,
    please see <http://www.soda-pro.com/web-services/radiation/cams-radiation-service>. ",2016-11-30,Lukas Lundstrom,https://github.com/ropenscilabs/camsRad,TRUE,https://github.com/ropenscilabs/camsrad,6036,6,1532931982
camtrapR,"Management of and data extraction from camera trap photographs in wildlife studies. The package provides a workflow for storing and sorting camera trap photos, tabulates records of species and individuals, and creates detection/non-detection matrices for occupancy and spatial capture-recapture analyses with great flexibility. In addition, it provides simple mapping functions (number of species, number of independent species detections by station including GIS export) and can visualise species activity data.",2019-03-13,Juergen Niedballa,"https://github.com/jniedballa/camtrapR,
https://groups.google.com/forum/#!forum/camtrapr",TRUE,https://github.com/jniedballa/camtrapr,30792,0,1551542405
cancensus,"Integrated, convenient, and uniform access to Canadian
    Census data and geography retrieved using the 'CensusMapper' API. This package produces analysis-ready 
    tidy data frames and spatial data in multiple formats, as well as convenience functions
    for working with Census variables, variable hierarchies, and region selection. API
    keys are freely available with free registration at <https://censusmapper.ca/api>.
    Census data and boundary geometries are reproduced and distributed on an ""as
    is"" basis with the permission of Statistics Canada (Statistics Canada 2006;
    2011; 2016).",2018-11-20,Jens von Bergmann (API creator and maintainer),"https://github.com/mountainMath/cancensus,
https://mountainmath.github.io/cancensus/,
https://censusmapper.ca/api",TRUE,https://github.com/mountainmath/cancensus,5451,31,1542695017
Canopy,"A statistical framework and computational procedure for identifying
  the sub-populations within a tumor, determining the mutation profiles of each 
  subpopulation, and inferring the tumor's phylogenetic history. The input are 
  variant allele frequencies (VAFs) of somatic single nucleotide alterations 
  (SNAs) along with allele-specific coverage ratios between the tumor and matched
  normal sample for somatic copy number alterations (CNAs). These quantities can
  be directly taken from the output of existing software. Canopy provides a 
  general mathematical framework for pooling data across samples and sites to 
  infer the underlying parameters. For SNAs that fall within CNA regions, Canopy
  infers their temporal ordering and resolves their phase.  When there are 
  multiple evolutionary configurations consistent with the data, Canopy outputs 
  all configurations along with their confidence assessment.",2017-12-18,Yuchao Jiang,https://github.com/yuchaojiang/Canopy,TRUE,https://github.com/yuchaojiang/canopy,10685,33,1539719674
canprot,"Datasets are collected here for differentially (up- and down-)
        expressed proteins identified in proteomic studies of cancer and in cell
        culture experiments. Tables of amino acid compositions of proteins are
        used for calculations of chemical composition, projected into selected
        basis species. Plotting functions are used to visualize the compositional
        differences and thermodynamic potentials for proteomic transformations.",2019-02-26,Jeffrey Dick,http://github.com/jedick/canprot,TRUE,https://github.com/jedick/canprot,5767,2,1551095932
cansim,"Searches for, accesses, and retrieves new-format and old-format Statistics Canada data 
    tables, as well as individual vectors, as tidy data frames. This package deals with encoding issues, allows for 
    bilingual English or French language data retrieval, and bundles convenience functions 
    to make it easier to work with retrieved table data. Optional caching features are provided.",2019-01-07,Jens von Bergmann,"https://github.com/mountainMath/cansim,
https://mountainmath.github.io/cansim/",TRUE,https://github.com/mountainmath/cansim,1818,11,1548362054
canvasXpress,"Enables creation of visualizations using the CanvasXpress framework
    in R. CanvasXpress is a standalone JavaScript library for reproducible research
    with complete tracking of data and end-user modifications stored in a single
    PNG image that can be played back. See <http://canvasxpress.org> for more
    information.",2019-02-25,Connie Brett,https://github.com/neuhausi/canvasXpress.git,TRUE,https://github.com/neuhausi/canvasxpress,33559,213,1554494354
captr,"Get text from images of text using Captricity Optical Character
    Recognition (OCR) API. Captricity allows you to get text from handwritten
    forms --- think surveys --- and other structured paper documents. And it can
    output data in form a delimited file keeping field information intact. For more
    information, read <https://shreddr.captricity.com/developer/overview/>.",2017-04-15,Gaurav Sood,http://github.com/soodoku/captR,TRUE,https://github.com/soodoku/captr,11495,10,1523646559
caRamel,"Multi-objective optimizer initially developed for the calibration of hydrological models.
     The algorithm is a hybrid of the MEAS algorithm (Efstratiadis and Koutsoyiannis (2005) <doi:10.13140/RG.2.2.32963.81446>) by using the directional search method based on the simplexes of the objective space 
     and the epsilon-NGSA-II algorithm with the method of classification of the parameter vectors archiving management by epsilon-dominance (Reed and Devireddy <doi:10.1142/9789812567796_0004>).",2018-03-05,Fabrice Zaoui,https://github.com/fzao/caRamel,TRUE,https://github.com/fzao/caramel,3328,0,1553847860
CARBayes,"Implements a class of univariate and multivariate spatial generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, multinomial, Poisson or zero-inflated Poisson (ZIP), and spatial autocorrelation is modelled by a set of random effects that are assigned a conditional autoregressive (CAR) prior distribution. A number of different models are available for univariate spatial data, including models with no random effects as well as random effects modelled by different types of CAR prior, including the BYM model (Besag et al. (1991) <doi:10.1007/BF00116466>), the Leroux model (Leroux et al. (2000) <doi:10.1007/978-1-4612-1284-3_4>) and the localised model (Lee et al. (2015) <doi:10.1002/env.2348>). Additionally,  a multivariate CAR (MCAR) model for multivariate spatial data is available, as is a two-level hierarchical model for modelling data relating to individuals within areas. Full details are given in the vignette accompanying this package. The initial creation of this package was supported by the Economic and Social Research Council (ESRC) grant RES-000-22-4256, and on-going development has been supported by the Engineering and Physical Science Research Council (EPSRC) grant EP/J017442/1, ESRC grant ES/K006460/1, Innovate UK / Natural Environment Research Council (NERC) grant NE/N007352/1 and the TB Alliance. ",2018-12-06,Duncan Lee,http://github.com/duncanplee/CARBayes,TRUE,https://github.com/duncanplee/carbayes,92784,2,1544095345
CARBayesST,"Implements a class of spatio-temporal generalised linear mixed models for areal unit data, with inference in a Bayesian setting using Markov chain Monte Carlo (MCMC) simulation. The response variable can be binomial, Gaussian, or Poisson, but for some models only the binomial and Poisson data likelihoods are available. The spatio-temporal autocorrelation is modelled by  random effects, which are assigned conditional autoregressive (CAR) style prior distributions. A number of different random effects structures are available, including Bernardinelli et al. (1995) <doi:10.1002/sim.4780142112>, Rushworth et al. (2014) <doi:10.1016/j.sste.2014.05.001> and Lee et al. (2016) <doi:10.1214/16-AOAS941>. Full details are given in the vignette accompanying this package. The creation of this package was supported by the Engineering and Physical Sciences Research Council (EPSRC) grant EP/J017442/1 and the Medical Research Council (MRC) grant MR/L022184/1.",2019-01-08,Duncan Lee,http://github.com/duncanplee/CARBayesST,TRUE,https://github.com/duncanplee/carbayesst,30725,2,1545385849
carbonate,Create beautiful images of source code using 'carbon.js'<https://carbon.now.sh/about>.,2019-02-13,Jonathan Sidi  (<https://orcid.org/0000-0002-4222-1819>),https://github.com/yonicd/carbonate,TRUE,https://github.com/yonicd/carbonate,2923,95,1550020966
careless,"When taking online surveys, participants sometimes respond to items without regard to their content.
    These types of responses, referred to as careless or insufficient effort responding, constitute significant problems for data quality, leading to distortions in data analysis and hypothesis testing, such as spurious correlations. The 'R' package 'careless' provides solutions designed to detect such careless / insufficient effort responses by allowing easy calculation of indices proposed in the literature. It currently supports the calculation of longstring, even-odd consistency, psychometric synonyms/antonyms, Mahalanobis distance, and intra-individual response variability (also termed inter-item standard deviation). For a review of these methods, see Curran (2016) <doi:10.1016/j.jesp.2015.07.006>.",2018-06-19,Richard Yentes,https://github.com/ryentes/careless/,TRUE,https://github.com/ryentes/careless,2647,3,1529414310
caret,"Misc functions for training and plotting classification and
    regression models.",2019-03-26,Max Kuhn. Contributions from Jed Wing,https://github.com/topepo/caret/,TRUE,https://github.com/topepo/caret,3688679,1039,1554314296
carpenter,"Mainly used to build tables that are commonly presented for
    bio-medical/health research, such as basic characteristic tables or
    descriptive statistics.",2019-02-05,Luke Johnston  (<https://orcid.org/0000-0003-4169-2616>),https://github.com/lwjohnst86/carpenter,TRUE,https://github.com/lwjohnst86/carpenter,7315,7,1549536660
carrier,"Sending functions to remote processes can be wasteful of
    resources because they carry their environments with them. With
    the carrier package, it is easy to create functions that are
    isolated from their environment. These isolated functions, also
    called crates, print at the console with their total size and can
    be easily tested locally before being sent to a remote.",2018-10-16,Lionel Henry,https://github.com/r-lib/carrier,TRUE,https://github.com/r-lib/carrier,2116,22,1539263442
cartogram,Construct continuous and non-contiguous area cartograms.,2018-12-01,"Sebastian Jeworutzki 
    (<https://orcid.org/0000-0002-2671-5253>)",https://github.com/sjewo/cartogram,TRUE,https://github.com/sjewo/cartogram,57328,75,1543649419
cartography,"Create and integrate maps in your R workflow. This package helps to design cartographic representations such as proportional symbols, choropleth, typology, flows or discontinuities maps. It also offers several features that improve the graphic presentation of maps, for instance, map palettes, layout elements (scale, north arrow, title...), labels or legends. See Giraud and Lambert (2017) <doi:10.1007/978-3-319-57336-6_13>.",2019-02-07,Timothée Giraud,https://github.com/riatelab/cartography/,TRUE,https://github.com/riatelab/cartography,53358,241,1549631528
Cascade,"A modeling tool allowing gene selection, reverse engineering, and prediction in cascade networks. Jung, N., Bertrand, F., Bahram, S., Vallat, L., and Maumy-Bertrand, M. (2014) <doi:10.1093/bioinformatics/btt705>.",2019-02-18,Frederic Bertrand  (<https://orcid.org/0000-0002-0837-8281>),"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/Cascade",TRUE,https://github.com/fbertran/cascade,764,1,1549746114
CascadeData,"These experimental expression data (5 leukemic 'CLL' B-lymphocyte of aggressive form from 'GSE39411', <doi:10.1073/pnas.1211130110>), after B-cell receptor stimulation, are used as examples by packages such as the 'Cascade' one, a modeling tool allowing gene selection, reverse engineering, and prediction in cascade networks. Jung, N., Bertrand, F., Bahram, S., Vallat, L., and Maumy-Bertrand, M. (2014) <doi:10.1093/bioinformatics/btt705>.",2019-02-07,Frederic Bertrand  (<https://orcid.org/0000-0002-0837-8281>),"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/CascadeData",TRUE,https://github.com/fbertran/cascadedata,1026,1,1549746151
CaseBasedReasoning,"Given a large set of problems and their individual solutions case based reasoning seeks to solve a new problem by referring to the solution of that problem which is ""most similar"" to the new problem. Crucial in case based reasoning is the decision which problem ""most closely"" matches a given new problem. The basic idea is to define a family of distance functions and to use these distance functions as parameters of local averaging regression estimates of the final result. Then that distance function is chosen for which the resulting estimate is optimal with respect to a certain error measure used in regression estimation. The idea is based on: Dippon J. et al. (2002) <DOI:10.1016/S0167-9473(02)00058-0>. ",2018-06-12,Dr. Simon Mueller <simon.mueller@muon-stat.com>,NA,TRUE,https://github.com/sipemu/case-based-reasoning,2558,3,1535564974
casino,"Play casino games in the R console,
  including poker, blackjack, and a slot machine.
  Try to build your fortune before you succumb to the gambler's ruin!",2019-01-17,Anthony Pileggi,"https://anthonypileggi.github.io/casino,
https://github.com/anthonypileggi/casino",TRUE,https://github.com/anthonypileggi/casino,964,1,1549035587
CAST,"Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. This package includes functions to improve spatial-temporal modelling tasks using 'caret'. It prepares data for Leave-Location-Out and Leave-Time-Out cross-validation which are target-oriented validation strategies for spatial-temporal models. To decrease overfitting and improve model performances, the package implements a forward feature selection that selects suitable predictor variables in view to their contribution to the target-oriented performance.",2018-11-19,Hanna Meyer,https://github.com/environmentalinformatics-marburg/CAST,TRUE,https://github.com/environmentalinformatics-marburg/cast,8248,10,1549541952
cattonum,"Functions for dummy encoding, frequency encoding,
    label encoding, leave-one-out encoding, mean encoding,
    median encoding, and one-hot encoding.",2018-05-02,Bernie Gray,https://github.com/bfgray3/cattonum,TRUE,https://github.com/bfgray3/cattonum,4067,27,1547860075
cbar,"Detect contextual anomalies in time-series data with Bayesian data
  analysis. It focuses on determining a normal range of target value, and
  provides simple-to-use functions to abstract the outcome.",2017-10-24,Kim Seonghyun <shyeon.kim@scipi.net>,https://github.com/zedoul/cbar,TRUE,https://github.com/zedoul/cbar,6923,2,1540822257
CBDA,"Classification performed on Big Data. It uses concepts from compressive sensing, and implements ensemble predictor (i.e., 'SuperLearner') and knockoff filtering as the main machine learning and feature mining engines.",2018-04-16,Simeone Marino,https://github.com/SOCR/CBDA,TRUE,https://github.com/socr/cbda,3075,8,1552577453
cbsodataR,"The data and meta data from Statistics
    Netherlands (www.cbs.nl) can be browsed and downloaded. The client uses
    the open data API of Statistics Netherlands.",2019-02-21,Edwin de Jonge,https://github.com/edwindj/cbsodataR,TRUE,https://github.com/edwindj/cbsodatar,12714,9,1550603968
ccafs,"Client for Climate Change, Agriculture, and Food Security ('CCAFS')
    General Circulation Models ('GCM') data. Data is stored in Amazon 'S3', from
    which we provide functions to fetch data.",2017-02-24,Scott Chamberlain,https://github.com/ropensci/ccafs,TRUE,https://github.com/ropensci/ccafs,5968,9,1552069194
ccdrAlgorithm,"Implementation of the CCDr (Concave penalized Coordinate Descent with reparametrization) structure learning algorithm as described in Aragam and Zhou (2015) <http://www.jmlr.org/papers/v16/aragam15a.html>. This is a fast, score-based method for learning Bayesian networks that uses sparse regularization and block-cyclic coordinate descent.",2018-06-01,Bryon Aragam,https://github.com/itsrainingdata/ccdrAlgorithm,TRUE,https://github.com/itsrainingdata/ccdralgorithm,11076,4,1527860244
cdata,"Supplies higher-order coordinatized data specification and fluid transform operators that include pivot and anti-pivot as special cases. 
    The methodology is describe in 'Zumel', 2018, ""Fluid data reshaping with 'cdata'"", <http://winvector.github.io/FluidData/FluidDataReshapingWithCdata.html> , doi:10.5281/zenodo.1173299 .
    This package introduces the idea of  control table specification of data transforms (later also adapted from 'cdata' by 'tidyr').
    Works on in-memory data or on remote data using 'rquery' and 'SQL' database interfaces.",2019-03-30,John Mount,"https://github.com/WinVector/cdata/,
https://winvector.github.io/cdata/",TRUE,https://github.com/winvector/cdata,40867,24,1554227065
cdcsis,"Conditional distance correlation <doi:10.1080/01621459.2014.993081> is a novel conditional dependence measurement of two multivariate random variables given a confounding variable. This package provides conditional distance correlation, performs the conditional distance correlation sure independence screening procedure for ultrahigh dimensional data <doi:10.5705/ss.202014.0117>, and conducts conditional distance covariance test for conditional independence assumption of two multivariate variable.",2019-01-09,Wenhao Hu,https://github.com/Mamba413/cdcsis,TRUE,https://github.com/mamba413/cdcsis,12989,0,1547361533
CDM,"
    Functions for cognitive diagnosis modeling and multidimensional item response modeling 
    for dichotomous and polytomous item responses. This package enables the estimation of 
    the DINA and DINO model (Junker & Sijtsma, 2001, <doi:10.1177/01466210122032064>),
    the multiple group (polytomous) GDINA model (de la Torre, 2011, 
    <doi:10.1007/s11336-011-9207-7>), the multiple choice DINA model (de la Torre, 2009, 
    <doi:10.1177/0146621608320523>), the general diagnostic model (GDM; von Davier, 2008, 
    <doi:10.1348/000711007X193957>), the structured latent class model (SLCA; Formann, 1992, 
    <doi:10.1080/01621459.1992.10475229>) and regularized latent class analysis 
    (Chen, Li, Liu, & Ying, 2017, <doi:10.1007/s11336-016-9545-6>). 
    See George, Robitzsch, Kiefer, Gross, and Uenlue (2017) <doi:10.18637/jss.v074.i02> 
    for further details on estimation and the package structure.
    For tutorials on how to use the CDM package see 
    George and Robitzsch (2015, <doi:10.20982/tqmp.11.3.p189>) as well as
    Ravand and Robitzsch (2015).",2019-03-18,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/CDM,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/cdm,174580,7,1552988315
CEC,"CEC divides data into Gaussian type clusters. The implementation allows the simultaneous use of various type Gaussian mixture models, performs the reduction of unnecessary clusters and it's able to discover new groups. Based on Spurek, P. and Tabor, J. (2014) <doi:10.1016/j.patcog.2014.03.006>.",2018-07-26,Konrad Kamieniecki,https://github.com/azureblue/cec,TRUE,https://github.com/azureblue/cec,16792,6,1532636283
ceg,"Create and learn Chain Event Graph (CEG) models using a Bayesian 
    framework. It provides us with a Hierarchical Agglomerative algorithm to 
    search the CEG model space.
    The package also includes several facilities for visualisations of the
    objects associated with a CEG. The CEG class can represent a range of
    relational data types, and supports arbitrary vertex, edge and graph
    attributes. A Chain Event Graph is a tree-based graphical model that
    provides a powerful graphical interface through which domain experts can
    easily translate a process into sequences of observed events using plain
    language. CEGs have been a useful class of graphical model especially to
    capture context-specific conditional independences. References: Collazo R, 
    Gorgen C, Smith J. Chain Event Graph. CRC Press, ISBN 9781498729604, 2018
    (forthcoming); and Barday LM, Collazo RA, Smith JQ, Thwaites PA, Nicholson AE. 
    The Dynamic Chain Event Graph. Electronic Journal of Statistics, 9 (2) 2130-2169
    <doi:10.1214/15-EJS1068>.",2017-11-27,Pier Taranti,https://github.com/ptaranti/ceg,TRUE,https://github.com/ptaranti/ceg,3610,1,1527209112
cellranger,"Helper functions to work with spreadsheets and the ""A1:D10"" style
    of cell range specification.",2016-07-27,Jennifer Bryan,https://github.com/rsheets/cellranger,TRUE,https://github.com/rsheets/cellranger,4189154,30,1523141984
censusapi,"A wrapper for the U.S. Census Bureau APIs that returns data frames of 
	Census data and metadata. Available datasets include the 
	Decennial Census, American Community Survey, Small Area Health Insurance Estimates,
	Small Area Income and Poverty Estimates, and Population Estimates and Projections.
	See <https://www.census.gov/data/developers/data-sets.html> for more information.",2018-08-19,Hannah Recht,https://github.com/hrecht/censusapi,TRUE,https://github.com/hrecht/censusapi,19103,64,1552832136
CePa,"Use pathway topology information to assign weight to
        pathway nodes.",2018-06-04,Zuguang Gu,https://github.com/jokergoo/CePa,TRUE,https://github.com/jokergoo/cepa,20003,0,1528125384
cetcolor,"Collection of perceptually uniform colour maps made by Peter Kovesi
    (2015) ""Good Colour Maps: How to Design Them"" <arXiv:1509.03700> 
    at the Centre for Exploration Targeting (CET).",2018-07-10,James Balamuta,"https://github.com/coatless/cetcolor,
http://thecoatlessprofessor.com/projects/cetcolor/,
http://peterkovesi.com/projects/colourmaps/",TRUE,https://github.com/coatless/cetcolor,4784,19,1531235493
ceterisParibus,"Ceteris Paribus Profiles (What-If Plots) are designed to present model 
    responses around selected points in a feature space. 
    For example around a single prediction for an interesting observation. 
    Plots are designed to work in a model-agnostic fashion, they are working 
    for any predictive Machine Learning model and allow for model comparisons.
    Ceteris Paribus Plots supplement the Break Down Plots from 'breakDown' package.",2019-01-29,Przemyslaw Biecek  (<https://orcid.org/0000-0001-8423-1823>),https://pbiecek.github.io/ceterisParibus/,TRUE,https://github.com/pbiecek/ceterisparibus,4561,31,1548752078
cghRA,"Provides functions to import data from Agilent CGH arrays and process them according to the cghRA workflow. Implements several algorithms such as WACA, STEPS and cnvScore and an interactive graphical interface.",2017-03-03,Sylvain Mareschal,http://www.ovsa.fr/cghRA,TRUE,https://github.com/maressyl/r.cghra,5207,0,1549294392
CGPfunctions,Miscellaneous functions useful for teaching statistics as well as actually practicing the art. They typically are not “new” methods but rather wrappers around either base R or other packages.,2019-03-22,Chuck Powell,https://github.com/ibecav/CGPfunctions,TRUE,https://github.com/ibecav/cgpfunctions,6944,9,1554319182
cgraph,"Allows to create, evaluate, and differentiate computational graphs in R. A computational graph is a graph representation of a multivariate function decomposed by its (elementary) operations. Nodes in the graph represent arrays while edges represent dependencies among the arrays. An advantage of expressing a function as a computational graph is that this enables to differentiate the function by automatic differentiation. The 'cgraph' package supports various operations including basic arithmetic, trigonometry operations, and linear algebra operations. It differentiates computational graphs by reverse automatic differentiation. The flexible architecture of the package makes it applicable to solve a variety of problems including local sensitivity analysis, gradient-based optimization, and machine learning.",2019-04-06,Ron Triepels,https://cgraph.org/,TRUE,https://github.com/triepels/cgraph,10834,6,1554539471
chandwich,"Performs adjustments of a user-supplied independence loglikelihood 
    function using a robust sandwich estimator of the parameter covariance 
    matrix, based on the methodology in Chandler and Bate (2007) 
    <doi:10.1093/biomet/asm015>.  This can be used for cluster correlated data 
    when interest lies in the parameters of the marginal distributions or for 
    performing inferences that are robust to certain types of model 
    misspecification.  Functions for profiling the adjusted loglikelihoods are 
    also provided, as are functions for calculating and plotting confidence 
    intervals, for single model parameters, and confidence regions, for pairs 
    of model parameters.  Nested models can be compared using an adjusted 
    likelihood ratio test.",2018-11-28,Paul J. Northrop,http://github.com/paulnorthrop/chandwich,TRUE,https://github.com/paulnorthrop/chandwich,4168,0,1552415763
changepoint,"Implements various mainstream and specialised changepoint methods for finding single and multiple changepoints within data.  Many popular non-parametric and frequentist methods are included.  The cpt.mean(), cpt.var(), cpt.meanvar() functions should be your first point of call.",2016-10-04,Rebecca Killick,https://github.com/rkillick/changepoint/,TRUE,https://github.com/rkillick/changepoint,107003,59,1541755949
changer,Changing the name of an existing R package is annoying but common task especially in the early stages of package development. This package (mostly) automates this task.,2018-10-21,Jouni Helske  (<https://orcid.org/0000-0001-7130-793X>),https://github.com/helske/changer,TRUE,https://github.com/helske/changer,2160,5,1540114774
charlatan,"Make fake data, supporting addresses, person names, dates,
    times, colors, coordinates, currencies, digital object identifiers
    ('DOIs'), jobs, phone numbers, 'DNA' sequences, doubles and integers
    from distributions and within a range.",2018-10-18,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/charlatan,TRUE,https://github.com/ropensci/charlatan,7930,116,1550174033
chartql,"Provides a very simple syntax for the user to generate custom plot(s) without having to remember complicated 'ggplot2' syntax. The 'chartql' package uses 'ggplot2' and manages all the syntax complexities internally. As an example, to generate a bar chart of company sales faceted by product category further faceted by season of the year, we simply write: ""CHART bar X category, season Y sales"".",2019-04-04,Rohail Syed,https://github.com/rmsyed/chartql,TRUE,https://github.com/rmsyed/chartql,97,5,1554086331
chebpol,"Contains methods for creating multivariate/multidimensional
  interpolations of functions on a hypercube. If available through fftw3, the DCT-II/FFT
  is used to compute coefficients for a Chebyshev interpolation.
  Other interpolation methods for arbitrary Cartesian grids are also provided, a piecewise multilinear,
  and the Floater-Hormann barycenter method. For scattered data polyharmonic splines with a linear term
  is provided. The time-critical parts are written in C for speed. All interpolants are parallelized if
  used to evaluate more than one point.",2019-03-11,Simen Gaure  (<https://orcid.org/0000-0001-7251-8747>),https://github.com/sgaure/chebpol,TRUE,https://github.com/sgaure/chebpol,31264,1,1552306687
checkLuhn,"Confirms if the number is Luhn compliant.
    Can check if credit card, IMEI number or any other Luhn based number is correct. 
    For more info see: <https://en.wikipedia.org/wiki/Luhn_algorithm>.",2018-09-24,Adam Deacon,https://github.com/adamjdeacon/checkLuhn,TRUE,https://github.com/adamjdeacon/checkluhn,4400,1,1538411496
checkmate,"Tests and assertions to perform frequent argument checks. A
    substantial part of the package was written in C to minimize any worries
    about execution time overhead.",2019-01-15,Michel Lang  (<https://orcid.org/0000-0001-9754-0393>),https://github.com/mllg/checkmate,TRUE,https://github.com/mllg/checkmate,3204871,108,1550186550
checkpoint,"The goal of checkpoint is to solve the problem of package
    reproducibility in R. Specifically, checkpoint allows you to install packages
    as they existed on CRAN on a specific snapshot date as if you had a CRAN time
    machine. To achieve reproducibility, the checkpoint() function installs the
    packages required or called by your project and scripts to a local library
    exactly as they existed at the specified point in time. Only those packages
    are available to your project, thereby avoiding any package updates that came
    later and may have altered your results. In this way, anyone using checkpoint's
    checkpoint() can ensure the reproducibility of your scripts or projects at any
    time. To create the snapshot archives, once a day (at midnight UTC) Microsoft
    refreshes the Austria CRAN mirror on the ""Microsoft R Archived Network""
    server (<https://mran.microsoft.com/>). Immediately after completion
    of the rsync mirror process, the process takes a snapshot, thus creating the
    archive. Snapshot archives exist starting from 2014-09-17.",2018-09-10,Microsoft Corporation,https://github.com/RevolutionAnalytics/checkpoint,TRUE,https://github.com/revolutionanalytics/checkpoint,66197,114,1523311852
checkr,"Expressive, assertive, pipe-friendly functions 
  to check the properties of common R objects.
  In the case of failure the functions issue informative error messages.",2018-11-01,Joe Thorley  (<https://orcid.org/0000-0002-7683-4592>),https://github.com/poissonconsulting/checkr,TRUE,https://github.com/poissonconsulting/checkr,9791,8,1551991051
cheddar,"Provides a flexible, extendable representation of an ecological community and a range of functions for analysis and visualisation, focusing on food web, body mass and numerical abundance data. Allows inter-web comparisons such as examining changes in community structure over environmental, temporal or spatial gradients.",2018-06-10,Lawrence Hudson with contributions from Dan Reuman and Rob Emerson,https://github.com/quicklizard99/cheddar/,TRUE,https://github.com/quicklizard99/cheddar,23955,12,1528581121
cheese,Contains flexible and intuitive functions to assist in carrying out tasks in a statistical analysis and to get from the raw data to presentation-ready results. A user-friendly interface is used in specialized functions that are aimed at common tasks such as building a univariate descriptive table for variables in a dataset. These high-level functions are built on a collection of low(er)-level functions that may be useful for aspects of a custom statistical analysis workflow or for general programming use. ,2019-04-01,Alex Zajichek,https://github.com/zajichek/cheese,TRUE,https://github.com/zajichek/cheese,317,2,1554459367
chemCal,"Simple functions for plotting linear
	calibration functions and estimating standard errors for measurements
	according to the Handbook of Chemometrics and Qualimetrics: Part A
	by Massart et al. There are also functions estimating the limit
	of detection (LOD) and limit of quantification (LOQ).
	The functions work on model objects from - optionally weighted - linear
	regression (lm) or robust linear regression ('rlm' from the 'MASS' package).",2018-07-17,Johannes Ranke,"https://pkgdown.jrwb.de/chemCal,
https://cgit.jrwb.de/chemCal/about",TRUE,https://github.com/jranke/chemcal,24455,1,1550761405
chemmodlab,"Contains a set of methods for fitting models and methods for
    validating the resulting models. The statistical methodologies comprise
    a comprehensive collection of approaches whose validity and utility have
    been accepted by experts in the Cheminformatics field. As promising new
    methodologies emerge from the statistical and data-mining communities, they
    will be incorporated into the laboratory. These methods are aimed at discovering
    quantitative structure-activity relationships (QSARs). However, the user can
    directly input their own choices of descriptors and responses, so the capability
    for comparing models is effectively unlimited.",2017-04-21,Jeremy Ash,https://github.com/jrash/ChemModLab,TRUE,https://github.com/jrash/chemmodlab,4696,6,1543532467
ChemometricsWithR,"Functions and scripts used in the book ""Chemometrics with R - Multivariate Data Analysis in the Natural Sciences and Life Sciences"" by Ron Wehrens, Springer (2011). Data used in the package are available from github.",2019-01-07,Ron Wehrens,https://github.com/rwehrens/CWR,TRUE,https://github.com/rwehrens/cwr,34150,4,1546850432
ChemoSpec,"A collection of functions for top-down exploratory data analysis
    of spectral data including nuclear magnetic resonance (NMR), infrared (IR),
    Raman, X-ray fluorescence (XRF) and other similar types of spectroscopy.
    Includes functions for plotting and inspecting spectra, peak alignment,
    hierarchical cluster analysis (HCA), principal components analysis (PCA) and
    model-based clustering. Robust methods appropriate for this type of
    high-dimensional data are available. ChemoSpec is designed for structured
    experiments, such as metabolomics investigations, where the samples fall into
    treatment and control groups. Graphical output is formatted consistently for
    publication quality plots. ChemoSpec is intended to be very user friendly and
    to help you get usable results quickly. A vignette covering typical operations
    is available.",2019-03-01,Bryan A. Hanson  (ORCID 0000-0003-3536-8246),https://bryanhanson.github.io/ChemoSpec/,TRUE,https://github.com/bryanhanson/chemospec,49726,25,1551558858
ChemoSpec2D,"A collection of functions for exploratory chemometrics of 2D spectroscopic data sets such as COSY (correlated spectroscopy) and HSQC (heteronuclear single quantum coherence) 2D NMR (nuclear magnetic resonance) spectra. 'ChemoSpec2D' deploys methods aimed primarily at classification of samples and the identification of spectral features which are important in distinguishing samples from each other. Each 2D spectrum (a matrix) is treated as the unit of observation, and thus the physical sample in the spectrometer corresponds to the  sample from a statistical perspective.  In addition to chemometric tools, a few tools are provided for plotting 2D spectra, but these are not intended to replace the functionality typically available on the spectrometer. 'ChemoSpec2D' takes many of its cues from 'ChemoSpec' and tries to create consistent graphical output and to be very user friendly.",2019-03-01,Bryan A. Hanson  (ORCID 0000-0003-3536-8246),https://github.com/bryanhanson/ChemoSpec2D,TRUE,https://github.com/bryanhanson/chemospec2d,1321,0,1551495598
ChemoSpecUtils,Functions supporting the common needs of packages 'ChemoSpec' and 'ChemoSpec2D'.,2019-03-01,Bryan A. Hanson  (ORCID 0000-0003-3536-8246),https://github.com/bryanhanson/ChemoSpecUtils,TRUE,https://github.com/bryanhanson/chemospecutils,5395,0,1551449859
childesr,"Tools for connecting to 'CHILDES', an open repository for
    transcripts of parent-child interaction. For more information on the
    underlying data, see <http://childes-db.stanford.edu>.",2018-05-18,Mika Braginsky,https://github.com/langcog/childesr,TRUE,https://github.com/langcog/childesr,2685,7,1526402778
childsds,"Calculation of standard deviation scores and percentiles adduced from different
    growth standards (WHO, UK, Germany, Italy, China, etc). Therefore, the calculation of SDS-values
    for different measures like BMI, weight, height, head circumference, different
    ratios, etc. are easy to carry out. Also, references for laboratory values in
    children and adults are available, e.g., serum lipids, iron-related blood parameters, IGF, liver enzymes. In the
    new version, there are also functions combining the lms() function from package 'gamlss' with
    resampling methods for using with repeated measurements and family dependencies. A searchable list
    of items can be found here: <https://github.com/mvogel78/childsds/wiki>.",2019-03-26,Mandy Vogel,NA,TRUE,https://github.com/mvogel78/childsds,22606,3,1528614331
chipPCR,"A collection of functions to pre-process amplification curve data from polymerase chain reaction (PCR) or isothermal amplification reactions. Contains functions to normalize and baseline amplification curves, to detect both the start and end of an amplification reaction, several smoothers (e.g., LOWESS, moving average, cubic splines, Savitzky-Golay), a function to detect false positive amplification reactions and a function to determine the amplification efficiency. Quantification point (Cq) methods include the first (FDM) and second approximate derivative maximum (SDM) methods (calculated by a 5-point-stencil) and the cycle threshold method. Data sets of experimental nucleic acid amplification systems (VideoScan HCU, capillary convective PCR (ccPCR)) and commercial systems are included. Amplification curves were generated by helicase dependent amplification (HDA), ccPCR or PCR. As detection system intercalating dyes (EvaGreen, SYBR Green) and hydrolysis probes (TaqMan) were used. ",2015-04-10,Stefan Roediger,https://github.com/michbur/chipPCR,TRUE,https://github.com/michbur/chippcr,18408,4,1538033561
CHMM,"An exact and a variational inference for
    coupled Hidden Markov Models applied to the joint detection of copy number variations.",2017-09-29,Julie Aubert,http://github.com/julieaubert/CHMM,TRUE,https://github.com/julieaubert/chmm,5766,0,1544700308
cholera,"Amends errors, augments data and aids analysis of John Snow's map
  of the 1854 London cholera outbreak.",2019-03-08,Peter Li,https://github.com/lindbrook/cholera,TRUE,https://github.com/lindbrook/cholera,7949,101,1554396513
CholWishart,"Sampling from the Cholesky factorization of a Wishart random 
    variable, sampling from the inverse Wishart distribution, sampling from 
    the Cholesky factorization of an inverse Wishart random variable, sampling
    from the pseudo Wishart distribution, sampling from the generalized
    inverse Wishart distribution, computing densities for the Wishart 
    and inverse Wishart distributions, and computing the multivariate gamma 
    and digamma functions.",2019-01-25,Geoffrey Thompson,https://github.com/gzt/CholWishart,TRUE,https://github.com/gzt/cholwishart,5943,0,1548528946
chorrrds,"Extracts music chords from the 'CifraClub' website <https://www.cifraclub.com.br/>.
	The package also has functions for cleaning the extracted data and 
	feature extraction.  ",2019-01-28,Bruna Wundervald,https://github.com/r-music/chorrrds,TRUE,https://github.com/r-music/chorrrds,5080,53,1553471072
chromer,"A programmatic interface to the Chromosome Counts Database
    (http://ccdb.tau.ac.il/). This package is part of the rOpenSci suite
    (http://ropensci.org)",2015-01-13,Matthew Pennell,http://www.github.com/ropensci/chromer,TRUE,https://github.com/ropensci/chromer,12240,3,1554162536
chunked,"Text data can be processed chunkwise using 'dplyr' commands. These
    are recorded and executed per data chunk, so large files can be processed with
    limited memory using the 'LaF' package.",2017-07-01,Edwin de Jonge,https://github.com/edwindj/chunked,TRUE,https://github.com/edwindj/chunked,11764,136,1527693315
cimir,"Connect to the California Irrigation Management 
    Information System (CIMIS) Web API. See the CIMIS main page 
    <https://cimis.water.ca.gov/> and web API documentation
    <https://et.water.ca.gov> for more information.",2019-03-14,Michael Koohafkan,https://github.com/mkoohafkan/cimir,TRUE,https://github.com/mkoohafkan/cimir,1025,2,1553317433
CIplot,"Plot confidence interval from the objects of statistical tests such as
  t.test(), var.test(), cor.test(), prop.test() and fisher.test() ('htest' class),
  Tukey test [TukeyHSD()], Dunnett test [glht() in 'multcomp' package],
  logistic regression [glm()], and Tukey or Games-Howell test [posthocTGH() in
  'userfriendlyscience' package].
  Users are able to set the styles of lines and points.
  This package contains the function to calculate odds ratios and their confidence
  intervals from the result of logistic regression.",2017-08-14,Toshiaki Ara,https://github.com/toshi-ara/CIplot,TRUE,https://github.com/toshi-ara/ciplot,4576,0,1536294994
circglmbayes,"Perform a Bayesian analysis of a circular outcome General Linear
    Model (GLM), which allows regressing a circular outcome on linear and
    categorical predictors. Posterior samples are obtained by means of an MCMC
    algorithm written in 'C++' through 'Rcpp'. Estimation and credible intervals
    are provided, as well as hypothesis testing through Bayes Factors.
    See Mulder and Klugkist (2017) <doi:10.1016/j.jmp.2017.07.001>.",2018-03-09,Kees Mulder,https://github.com/keesmulder/circglmbayes,TRUE,https://github.com/keesmulder/circglmbayes,3075,1,1536826062
circlize,"Circular layout is an efficient way for the visualization of huge 
    amounts of information. Here this package provides an implementation 
    of circular layout generation in R as well as an enhancement of available 
    software. The flexibility of the package is based on the usage of low-level 
    graphics functions such that self-defined high-level graphics can be easily 
    implemented by users for specific purposes. Together with the seamless 
    connection between the powerful computational and visual environment in R, 
    it gives users more convenience and freedom to design figures for 
    better understanding complex patterns behind multiple dimensional data.",2019-04-03,Zuguang Gu,"https://github.com/jokergoo/circlize,
http://jokergoo.github.io/circlize_book/book/",TRUE,https://github.com/jokergoo/circlize,340596,350,1550580132
circumplex,"Tools for analyzing and visualizing circular data, including
    scoring functions for relevant instruments and a generalization of the 
    bootstrapped structural summary method from Zimmermann & Wright (2017) 
    <doi:10.1177/1073191115621795> and functions for creating publication-ready
    tables and figures from the results. Future versions will include tools for 
    circular fit and reliability analyses, as well as visualization enhancements.",2018-11-29,Jeffrey Girard  (<https://orcid.org/0000-0002-7359-3746>),https://github.com/jmgirard/circumplex,TRUE,https://github.com/jmgirard/circumplex,6081,4,1543508401
cIRT,"Jointly model the accuracy of cognitive responses and item choices
    within a bayesian hierarchical framework as described by Culpepper and
    Balamuta (2015) <doi:10.1007/s11336-015-9484-7>. In addition, the package
    contains the datasets used within the analysis of the paper.",2019-01-24,Steven Andrew Culpepper,https://github.com/tmsalab/cIRT,TRUE,https://github.com/tmsalab/cirt,11738,3,1548214573
CITAN,"Supports quantitative
    research in scientometrics and bibliometrics. Provides
    various tools for preprocessing bibliographic
    data retrieved, e.g., from Elsevier's SciVerse Scopus,
    computing bibliometric impact of individuals,
    or modeling many phenomena encountered in the social sciences.",2015-12-13,Marek Gagolewski,NA,TRUE,https://github.com/rexamine/citan,18087,6,1552475543
ciTools,"Functions to append confidence intervals, prediction intervals,
    and other quantities of interest to data frames. All appended quantities
    are for the response variable, after conditioning on the model and covariates.
    This package has a data frame first syntax that allows for easy piping.
    Currently supported models include (log-) linear, (log-) linear mixed,
    generalized linear models, generalized linear mixed models, and
    accelerated failure time models.",2019-01-08,John Haman,https://github.com/jthaman/ciTools,TRUE,https://github.com/jthaman/citools,13818,92,1546977080
citr,"Functions and an 'RStudio' add-in that search a 'Bib(La)TeX'-file to create and
  insert formatted Markdown citations into the current document.",2018-12-18,Frederik Aust  (<https://orcid.org/0000-0003-4900-788X>),https://github.com/crsh/citr,TRUE,https://github.com/crsh/citr,18502,194,1554204949
civis,"A convenient interface for making
  requests directly to the 'Civis data science API' <https://www.civisanalytics.com/platform/>.",2019-02-12,Patrick Miller,https://github.com/civisanalytics/civis-r,TRUE,https://github.com/civisanalytics/civis-r,69273,10,1552425925
ckanr,"Client for 'CKAN' 'API' (http://ckan.org/). Includes interface
    to 'CKAN' 'APIs' for search, list, show for packages, organizations, and
    resources. In addition, provides an interface to the 'datastore' 'API'.",2015-10-22,Scott Chamberlain,https://github.com/ropensci/ckanr,TRUE,https://github.com/ropensci/ckanr,17405,61,1541094121
classInt,Selected commonly used methods for choosing univariate class intervals for mapping or other graphics purposes.,2018-12-18,Roger Bivand  (<https://orcid.org/0000-0003-2392-6140>),https://github.com/r-spatial/classInt/,TRUE,https://github.com/r-spatial/classint,1087517,14,1553540177
classyfireR,Access to the ClassyFire RESTful API <http://classyfire.wishartlab.com>. Retrieve existing entity classifications and submit new entities for classification. ,2019-02-25,Tom Wilson,https://github.com/wilsontom/classyfireR,TRUE,https://github.com/wilsontom/classyfirer,2979,1,1551813265
cld2,"Bindings to Google's C++ library Compact Language Detector 2
    (see <https://github.com/cld2owners/cld2#readme> for more information). Probabilistically
    detects over 80 languages in plain text or HTML. For mixed-language input it returns the
    top three detected languages and their approximate proportion of the total classified 
    text bytes (e.g. 80% English and 20% French out of 1000 bytes). There is also a 'cld3'
    package on CRAN which uses a neural network model instead.",2018-05-11,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),"https://github.com/ropensci/cld2 (devel)
https://github.com/cld2owners/cld2 (upstream)",TRUE,https://github.com/ropensci/cld2,9997,29,1534951037
cld3,"Google's Compact Language Detector 3 is a neural network model for language 
    identification and the successor of 'cld2' (available from CRAN). The algorithm is still
    experimental and takes a novel approach to language detection with different properties
    and outcomes. It can be useful to combine this with the Bayesian classifier results 
    from 'cld2'. See <https://github.com/google/cld3#readme> for more information.",2018-06-28,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),"https://github.com/ropensci/cld3 (devel)
https://github.com/google/cld3 (upstream)",TRUE,https://github.com/ropensci/cld3,7958,13,1551005858
cleandata,"Functions to work with data frames to prepare data for further analysis.
    The functions for imputation, encoding, partitioning, and other manipulation can produce log files to keep track of process.",2018-12-01,Sherry Zhao,https://github.com/sherrisherry/cleandata,TRUE,https://github.com/sherrisherry/cleandata,3414,3,1543721988
cleanEHR,"An electronic health care record (EHR) data cleaning and processing
    platform. It focus on heterogeneous high resolution longitudinal data. It works with 
    Critical Care Health Informatics Collaborative (CCHIC) dataset. It is
    created to address various data reliability and accessibility problems of
    EHRs as such. ",2017-12-16,Sinan Shi,"https://github.com/CC-HIC/cleanEHR, http://www.hic.nihr.ac.uk",TRUE,https://github.com/cc-hic/cleanehr,6256,34,1536153213
cleanNLP,"Provides a set of fast tools for converting a textual corpus into a set of normalized
  tables. Users may make use of the 'udpipe' back end with no external dependencies, a Python back
  end with 'spaCy' <https://spacy.io> or the Java back end 'CoreNLP'
  <http://stanfordnlp.github.io/CoreNLP/>. Exposed annotation tasks include
  tokenization, part of speech tagging, named entity recognition, entity linking, sentiment
  analysis, dependency parsing, coreference resolution, and word embeddings. Summary
  statistics regarding token unigram, part of speech tag, and dependency type frequencies
  are also included to assist with analyses.",2018-11-18,Taylor B. Arnold,https://statsmaths.github.io/cleanNLP/,TRUE,https://github.com/statsmaths/cleannlp,15555,120,1551190235
clifro,"CliFlo is a web portal to the New Zealand National Climate
    Database and provides public access (via subscription) to around 6,500
    various climate stations (see <https://cliflo.niwa.co.nz/> for more
    information). Collating and manipulating data from CliFlo
    (hence clifro) and importing into R for further analysis, exploration and
    visualisation is now straightforward and coherent. The user is required to
    have an internet connection, and a current CliFlo subscription (free) if
    data from stations, other than the public Reefton electronic weather
    station, is sought.",2019-03-20,Blake Seers  (<https://orcid.org/0000-0001-6841-4312>),https://github.com/ropensci/clifro,TRUE,https://github.com/ropensci/clifro,23304,17,1553054842
climdex.pcic,"PCIC's implementation of Climdex routines for computation of
    extreme climate indices.",2019-01-16,"David Bronaugh <bronaugh@uvic.ca> for the Pacific Climate Impacts
    Consortium",https://www.r-project.org,TRUE,https://github.com/pacificclimate/climdex.pcic,30114,5,1533068498
ClimDown,"A suite of routines for downscaling coarse scale global
    climate model (GCM) output to a fine spatial resolution. Includes
    Bias-Corrected Spatial Downscaling (BCDS), Constructed Analogues
    (CA), Climate Imprint (CI), and Bias Correction/Constructed
    Analogues with Quantile mapping reordering (BCCAQ). Developed by
    the the Pacific Climate Impacts Consortium (PCIC), Victoria,
    British Columbia, Canada.",2016-12-02,James Hiebert,https://www.r-project.org,TRUE,https://github.com/pacificclimate/climdown,6458,19,1553527981
climwin,"Contains functions to detect and visualise periods of climate
    sensitivity (climate windows) for a given biological response.",2017-11-10,Liam D. Bailey and Martijn van de Pol,https://github.com/LiamDBailey/climwin,TRUE,https://github.com/liamdbailey/climwin,16968,4,1550659127
ClinReport,"It enables to create easily formatted statistical tables in 'Microsoft Word' documents in pretty formats according to 'clinical standards'. It can be used also outside the scope of clinical trials, for any statistical reporting in 'Word'. Descriptive tables for quantitative statistics (mean, median, max etc..) and/or qualitative statistics (frequencies and percentages) are available and formatted tables of Least Square Means of Linear Models, Linear Mixed Models and Generalized Linear Mixed Models coming from emmeans() function are also available. The package works with 'officer' and 'flextable' packages to export the outputs into 'Microsoft Word' documents.       ",2019-04-02,Jean-Francois Collin,https://jfrancoiscollin.github.io/ClinReport,TRUE,https://github.com/jfrancoiscollin/clinreport,1203,1,1554214003
clipr,"Simple utility functions to read from and write to
    the Windows, OS X, and X11 clipboards.",2019-01-11,Matthew Lincoln  (<https://orcid.org/0000-0002-4387-3384>),https://github.com/mdlincoln/clipr,TRUE,https://github.com/mdlincoln/clipr,2890283,81,1547673185
cliqueMS,"Annotates data from liquid chromatography coupled to mass spectrometry (LC/MS) metabolomics experiments. Based on a network algorithm (O.Senan, A. Aguilar- Mogas, M. Navarro, O. Yanes, R.Guimerà and M. Sales-Pardo, Metabolomics Conference (2016), Dublin), 'CliqueMS' builds a weighted similarity network where nodes are features and edges are weighted according to the similarity of this features. Then it searches for the most plausible division of the similarity network into cliques (fully connected components). Finally it annotates metabolites within each clique, obtaining for each annotated metabolite the neutral mass and their features, corresponding to isotopes, ionization adducts and fragmentation adducts of that metabolite.",2019-01-30,Oriol Senan Campos,https://github.com/osenan/cliqueMS,TRUE,https://github.com/osenan/cliquems,4101,5,1548845313
clisymbols,"A small subset of Unicode symbols, that are useful
    when building command line applications. They fall back to
    alternatives on terminals that do not support Unicode.
    Many symbols were taken from the 'figures' 'npm' package
    (see <https://github.com/sindresorhus/figures>).",2017-05-21,Gábor Csárdi,https://github.com/gaborcsardi/clisymbols,TRUE,https://github.com/gaborcsardi/clisymbols,1063719,44,1553632947
CLME,"Estimation and inference for linear models where some or all of the
    fixed-effects coefficients are subject to order restrictions. This package uses
    the robust residual bootstrap methodology for inference, and can handle some
    structure in the residual variance matrix.",2019-02-07,Casey M. Jelsema,NA,TRUE,https://github.com/jelsema/clme,18944,1,1549569345
clogitLasso,"Fit a sequence of conditional logistic regression models with lasso, for small to large sized samples. Avalos, M., Pouyes, H., Grandvalet, Y., Orriols, L., & Lagarde, E. (2015) <doi:10.1186/1471-2105-16-S6-S1>.",2018-06-27,Marta Avalos,NA,TRUE,https://github.com/mavalosf/clogitlasso,7062,1,1529076175
clubSandwich,"Provides several cluster-robust variance estimators (i.e.,
    sandwich estimators) for ordinary and weighted least squares linear regression
    models, including the bias-reduced linearization estimator introduced by Bell
    and McCaffrey (2002) 
    <http://www.statcan.gc.ca/pub/12-001-x/2002002/article/9058-eng.pdf> and 
    developed further by Pustejovsky and Tipton (2017) 
    <DOI:10.1080/07350015.2016.1247004>. The package includes functions for estimating
    the variance- covariance matrix and for testing single- and multiple-
    contrast hypotheses based on Wald test statistics. Tests of single regression
    coefficients use Satterthwaite or saddle-point corrections. Tests of multiple-
    contrast hypotheses use an approximation to Hotelling's T-squared distribution.
    Methods are provided for a variety of fitted models, including lm() and mlm
    objects, glm(), ivreg (from package 'AER'), plm() (from package 'plm'), gls()
    and lme() (from 'nlme'), robu() (from 'robumeta'), and rma.uni() and rma.mv()
    (from 'metafor').",2019-01-24,James Pustejovsky,https://github.com/jepusto/clubSandwich,TRUE,https://github.com/jepusto/clubsandwich,49523,24,1551150968
clustcurv,"A method for determining groups in multiple survival
    curves with an automatic selection of their number based on k-means or 
    k-medians algorithms. The selection of the optimal number is provided by 
    bootstrap methods.
     Implemented methods are:
    Grouping multiple survival curves described by Villanueva et al. (2018) <doi:10.1002/sim.8016>.",2019-03-25,Nora M. Villanueva  (<https://orcid.org/0000-0001-8085-2745>),https://github.com/noramvillanueva/clustcurv,TRUE,https://github.com/noramvillanueva/clustcurv,449,0,1553280351
Cluster.OBeu,"Estimate and return the needed parameters for visualisations designed for 'OpenBudgets' <http://openbudgets.eu/> data. Calculate cluster analysis measures in Budget data of municipalities across Europe, according to the 'OpenBudgets' data model. It involves a set of techniques and algorithms used to find and divide the data into groups of similar observations. Also, can be used generally to extract visualisation parameters convert them to 'JSON' format and use them as input in a different graphical interface.",2019-01-20,Kleanthis Koupidis,https://github.com/okgreece/Cluster.OBeu,TRUE,https://github.com/okgreece/cluster.obeu,3976,1,1551974953
ClusterBootstrap,Provides functionality for the analysis of clustered data using the cluster bootstrap. ,2018-06-26,Mathijs Deen,https://github.com/mathijsdeen/ClusterBootstrap,TRUE,https://github.com/mathijsdeen/clusterbootstrap,6455,1,1530046055
clusteredinterference,"Estimating causal effects from observational studies assuming 
    clustered (or partial) interference. These inverse probability-weighted
    estimators target new estimands arising from population-level treatment 
    policies. The estimands and estimators are introduced in Barkley et al. 
    (2017) <arXiv:1711.04834>.",2019-03-18,Brian G. Barkley  (<https://orcid.org/0000-0003-1787-4735>),http://github.com/BarkleyBG/clusteredinterference,TRUE,https://github.com/barkleybg/clusteredinterference,3484,3,1552840270
clustermq,"Evaluate arbitrary function calls using workers on HPC schedulers
    in single line of code. All processing is done on the network without
    accessing the file system. Remote schedulers are supported via SSH.",2019-02-22,Michael Schubert <mschu.dev@gmail.com>,https://github.com/mschubert/clustermq,TRUE,https://github.com/mschubert/clustermq,19880,64,1550845276
clusternor,"The clustering 'NUMA' Optimized Routines package or 'clusternor' is a highly optimized package for performing clustering in parallel with accelerations specifically targeting multi-core Non-Uniform Memory Access ('NUMA') hardware architectures. Disa Mhembere, Da Zheng, Carey E. Priebe, Joshua T. Vogelstein, Randal Burns (2019) <arXiv:1902.09527>.",2019-03-29,Disa Mhembere,https://github.com/neurodata/knorR,TRUE,https://github.com/neurodata/knorr,1048,6,1550642303
ClusterR,"Gaussian mixture models, k-means, mini-batch-kmeans, k-medoids and affinity propagation clustering with the option to plot, validate, predict (new data) and estimate the optimal number of clusters. The package takes advantage of 'RcppArmadillo' to speed up the computationally intensive parts of the functions. For more information, see (i) ""Clustering in an Object-Oriented Environment"" by Anja Struyf, Mia Hubert, Peter Rousseeuw (1997), Journal of Statistical Software, <doi:10.18637/jss.v001.i04>; (ii) ""Web-scale k-means clustering"" by D. Sculley (2010), ACM Digital Library, <doi:10.1145/1772690.1772862>; (iii) ""Armadillo: a template-based C++ library for linear algebra"" by Sanderson et al (2016), The Journal of Open Source Software, <doi:10.21105/joss.00026>; (iv) ""Clustering by Passing Messages Between Data Points"" by Brendan J. Frey and Delbert Dueck, Science 16 Feb 2007: Vol. 315, Issue 5814, pp. 972-976, <doi:10.1126/science.1136800>.",2019-01-11,Lampros Mouselimis,https://github.com/mlampros/ClusterR,TRUE,https://github.com/mlampros/clusterr,44544,36,1553717329
clustRcompaR,"Provides an interface to perform cluster analysis on a corpus of
    text. Interfaces to Quanteda to assemble text corpuses easily. Deviationalizes
    text vectors prior to clustering using technique described by Sherin (Sherin,
    B. [2013]. A computational study of commonsense science: An exploration in the
    automated analysis of clinical interview data. Journal of the Learning Sciences,
    22(4), 600-638. Chicago. <doi:10.1080/10508406.2013.836654>). Uses
    cosine similarity as distance metric for two stage clustering process, involving
    Ward's algorithm hierarchical agglomerative clustering, and k-means clustering.
    Selects optimal number of clusters to maximize ""variance explained"" by clusters,
    adjusted by the number of clusters. Provides plotted output of clustering
    results as well as printed output. Assesses ""model fit"" of clustering solution
    to a set of preexisting groups in dataset.",2018-01-28,Joshua Rosenberg,https://github.com/alishinski/clustRcompaR,TRUE,https://github.com/alishinski/clustrcompar,6145,2,1533951236
clustree,"Deciding what resolution to use can be a difficult question when
    approaching a clustering analysis. One way to approach this problem is to
    look at how samples move as the number of clusters increases. This package
    allows you to produce clustering trees, a visualisation for interrogating
    clusterings as resolution increases.",2019-02-24,Luke Zappia  (<https://orcid.org/0000-0001-7744-8565>),https://github.com/lazappi/clustree,TRUE,https://github.com/lazappi/clustree,8285,68,1551001942
cmrutils,"A collection of useful helper routines developed by
  students of the Center for Mathematical Research, Stankin,
  Moscow.",2018-09-03,Andrey Paramonov,https://github.com/aparamon/cmrutils,TRUE,https://github.com/aparamon/cmrutils,26908,0,1534583164
cmvnorm,Various utilities for the complex multivariate Gaussian distribution.,2018-08-16,Robin K. S. Hankin,https://github.com/RobinHankin/cmvnorm.git,TRUE,https://github.com/robinhankin/cmvnorm,16293,1,1534374733
cNORM,"Conventional methods for producing standard scores in psychometrics or biometrics 
    are often plagued with ""jumps"" or ""gaps"" (i.e., discontinuities) in norm tables and low 
    confidence for assessing extreme scores. The continuous norming method introduced by A. 
    Lenhard et al. (2016), <doi:10.1177/1073191116656437>, generates continuous test norm 
    scores on the basis of the raw data from standardization samples, without requiring 
    assumptions about the distribution of the raw data: Norm scores are directly established 
    from raw data by modeling the latter ones as a function of both percentile scores and an 
    explanatory variable (e.g., age). The method minimizes bias arising from sampling and 
    measurement error, while handling marked deviations from normality, addressing bottom 
    or ceiling effects and capturing almost all of the variance in the original norm data 
    sample.",2019-03-15,Wolfgang Lenhard  (<https://orcid.org/0000-0002-8184-6889>),"https://www.psychometrica.de/cNorm_en.html,
https://github.com/WLenhard/cNORM",TRUE,https://github.com/wlenhard/cnorm,2985,0,1554495141
CNVScope,"Provides the ability to create interaction maps, discover CNV map domains (edges), gene annotate interactions, and create interactive visualizations of these CNV interaction maps.",2018-10-20,James Dalgeish,https://github.com/jamesdalg/CNVScope/,TRUE,https://github.com/jamesdalg/cnvscope,1875,2,1551762083
coala,"Coalescent simulators can rapidly simulate biological sequences
    evolving according to a given model of evolution.
    You can use this package to specify such models, to conduct the simulations
    and to calculate additional statistics from the results.
    It relies on existing simulators for doing the simulation, and currently
    supports the programs 'ms', 'msms' and 'scrm'. It also supports finite-sites
    mutation models by combining the simulators with the program 'seq-gen'.",2017-10-30,Paul Staab,https://github.com/statgenlmu/coala,TRUE,https://github.com/statgenlmu/coala,14758,12,1551123361
coalitions,"An implementation of a MCMC method to calculate
    probabilities for a coalition majority based on survey results,
    see Bender and Bauer (2018) <doi:10.21105/joss.00606>.",2018-10-06,Andreas Bender  (<https://orcid.org/0000-0001-5628-8611>),"https://github.com/adibender/coalitions/,
http://adibender.github.io/coalitions/",TRUE,https://github.com/adibender/coalitions,4327,7,1552057461
cobalt,"Generate balance tables and plots for covariates of groups preprocessed through matching, weighting or subclassification, for example, using propensity scores. Includes integration with 'MatchIt', 'twang', 'Matching', 'optmatch', 'CBPS', 'ebal', 'WeightIt', and 'designmatch' for assessing balance on the output of their preprocessing functions. Users can also specify data for balance assessment not generated through the above packages. Also included are methods for assessing balance in clustered or multiply imputed data sets or data sets with longitudinal treatments.",2019-01-16,Noah Greifer,https://github.com/ngreifer/cobalt,TRUE,https://github.com/ngreifer/cobalt,48230,13,1549956785
cocktailApp,"A 'shiny' app to discover cocktails. The
    app allows one to search for cocktails by ingredient,
    filter on rating, and number of ingredients. The
    package also contains data with the ingredients of
    nearly 16 thousand cocktails scraped from the web.",2018-08-19,Steven E. Pav  (<https://orcid.org/0000-0002-4197-6195>),https://github.com/shabbychef/cocktailApp,TRUE,https://github.com/shabbychef/cocktailapp,2937,29,1534695460
cocorresp,"Fits predictive and symmetric co-correspondence analysis (CoCA) models to relate one data matrix
  to another data matrix. More specifically, CoCA maximises the weighted covariance 
  between the weighted averaged species scores of one community and the weighted averaged species
  scores of another community. CoCA attempts to find patterns that are common to both communities.",2016-02-29,"Original Matlab routines by C.J.F. ter Braak and A.P. Schaffers. R port by Gavin L. Simpson.
  Function simpls based on simpls.fit (package pls) by Ron Wehrens and Bjorn-Helge Mevik.",https://github.com/gavinsimpson/cocorresp,TRUE,https://github.com/gavinsimpson/cocorresp,27340,2,1528685526
codebook,"Easily automate the following tasks to describe data frames:
		Summarise the distributions, and labelled missings of variables graphically
		and using descriptive statistics.
		For surveys, compute and summarise reliabilities (internal consistencies, 
		retest, multilevel) for psychological scales.
		Combine this information with metadata (such as item labels and labelled 
		values) that is derived from R attributes.
		To do so, the package relies on 'rmarkdown' partials, so you can generate 
		HTML, PDF, and Word documents. 
		Codebooks are also available as tables (CSV, Excel, etc.) and in JSON-LD, so
		that search engines can find your data and index the metadata.
		The metadata are also available at your fingertips via RStudio Addins.",2019-02-21,Ruben Arslan,https://github.com/rubenarslan/codebook,TRUE,https://github.com/rubenarslan/codebook,9197,39,1553079096
CodeDepends,"Tools for analyzing R expressions
  or blocks of code and determining the dependencies between them.
  It focuses on R scripts, but can be used on the bodies of functions.
  There are many facilities including the ability to summarize  or get a high-level
  view of code, determining dependencies between variables,  code improvement
  suggestions.",2018-07-17,Duncan Temple Lang,https://github.com/duncantl/CodeDepends,TRUE,https://github.com/duncantl/codedepends,15209,50,1539876449
codemetar,"The 'Codemeta' Project defines a 'JSON-LD' format for describing
  software metadata, as detailed at <https://codemeta.github.io>. This package
  provides utilities to generate, parse, and modify 'codemeta.json' files 
  automatically for R packages, as well as tools and examples for working with
  'codemeta.json' 'JSON-LD' more generally.",2019-03-12,Carl Boettiger,"https://github.com/ropensci/codemetar,
https://ropensci.github.io/codemetar",TRUE,https://github.com/ropensci/codemetar,5606,28,1554292413
codified,"Augment clinical data with metadata to create
    output used in conventional publications and reports.",2018-09-30,Will Beasley  (<https://orcid.org/0000-0002-5613-5006>),"https://ouhscbbmc.github.io/codified/,
https://github.com/OuhscBbmc/codified,
https://github.com/higgi13425/nih_enrollment_table",TRUE,https://github.com/ouhscbbmc/codified,1877,2,1553317365
codyn,"Univariate and multivariate temporal and spatial diversity indices, 
    rank abundance curves, and community stability measures. The functions 
    implement measures that are either explicitly temporal and include the 
    option to calculate them over multiple replicates, or spatial and include 
    the option to calculate them over multiple time points. Functions fall into 
    five categories: static diversity indices, temporal diversity indices, 
    spatial diversity indices, rank abundance curves, and community stability 
    measures. The diversity indices are temporal and spatial analogs to 
    traditional diversity indices. Specifically, the package includes functions 
    to calculate community richness, evenness and diversity at a given point in 
    space and time. In addition, it contains functions to calculate species 
    turnover, mean rank shifts, and lags in community similarity between two 
    time points.",2019-03-08,Matthew B. Jones,https://github.com/NCEAS/codyn/,TRUE,https://github.com/nceas/codyn,12003,18,1553715634
cofeatureR,"Generate cofeature (feature by sample) matrices. The package 
  utilizes ggplot2::geom_tile() to generate the matrix allowing for easy
  additions from the base matrix.",2018-06-24,Fong Chun Chan,https://github.com/tinyheero/cofeatureR,TRUE,https://github.com/tinyheero/cofeaturer,8972,0,1529850699
coga,"Evaluation for density and distribution function of convolution of gamma
    distributions in R. Two related exact methods and one approximate method are
    implemented with efficient algorithm and C++ code. A quick guide for choosing
    correct method and usage of this package is given in package vignette.",2018-05-08,Chaoran Hu,https://github.com/ChaoranHu/coga,TRUE,https://github.com/chaoranhu/coga,8012,0,1552428361
coindeskr,Extract real-time Bitcoin price details by accessing 'CoinDesk' Bitcoin price Index API <https://www.coindesk.com/api/>. ,2018-01-05,AbdulMajedRaja RS,https://github.com/amrrs/coindeskr,TRUE,https://github.com/amrrs/coindeskr,5225,2,1525677814
coinmarketcapr,To extract and monitor price and market cap of 'Crypto currencies' from 'Coin Market Cap' <https://coinmarketcap.com/api/>. ,2017-09-26,AbdulMajedRaja RS,http://github.com/amrrs/coinmarketcapr,TRUE,https://github.com/amrrs/coinmarketcapr,6992,27,1525201900
collapsibleTree,"
    Interactive Reingold-Tilford tree diagrams created using 'D3.js', where every node can be expanded and collapsed by clicking on it.
    Tooltips and color gradients can be mapped to nodes using a numeric column in the source data frame.
    See 'collapsibleTree' website for more information and examples.",2018-08-22,Adeel Khan,"https://github.com/AdeelK93/collapsibleTree,
https://AdeelK93.github.io/collapsibleTree/",TRUE,https://github.com/adeelk93/collapsibletree,15683,81,1542036544
collateral,"The purrr package allows you to capture the side effects (errors, warning, messages and other output) of functions using safely() and quietly(). Using collateral, you can quickly see which elements of a list (or list-column) returned results, which threw errors and which returned warnings or other output.",2018-11-19,James Goldie  (<https://orcid.org/0000-0002-5024-6207>),"https://rensa.co/collateral/index.html,
https://github.com/rensa/collateral",TRUE,https://github.com/rensa/collateral,1452,21,1542779260
CollessLike,"Computation of Colless-Like, Sackin and cophenetic balance indices of a phylogenetic tree and study of the distribution of these balance indices under the alpha-gamma model. For more details see A. Mir, F. Rossello, L. Rotger (2013) <doi:10.1016/j.mbs.2012.10.005>, M. J. Sackin (1972) <doi:10.1093/sysbio/21.2.225>, D. H. Colless (1982) <doi:10.2307/2413420>.",2018-04-03,Arnau Mir,https://github.com/LuciaRotger/CollessLike,TRUE,https://github.com/luciarotger/collesslike,3053,1,1524076369
colorednoise,"Temporally autocorrelated populations are correlated in their vital rates (growth, death, etc.) from year to year. It is very common for populations, whether they be bacteria, plants, or humans, to be temporally autocorrelated. This poses a challenge for stochastic population modeling, because a temporally correlated population will behave differently from an uncorrelated one.
    This package provides tools for simulating populations with white noise (no temporal autocorrelation), red noise (positive temporal autocorrelation), and blue noise (negative temporal autocorrelation).  The algebraic formulation for autocorrelated noise comes from Ruokolainen et al. (2009) <doi:10.1016/j.tree.2009.04.009>. Models for unstructured populations and for structured populations (matrix models) are available.",2019-01-23,Julia Pilowsky  (<https://orcid.org/0000-0002-6376-2585>),NA,TRUE,https://github.com/japilo/colorednoise,6337,0,1548243175
colorfindr,"Extracts colors from various image types, returns customized reports and plots treemaps 
    and 3D scatterplots of image compositions. Color palettes can also be created. ",2019-02-01,David Zumbach,NA,TRUE,https://github.com/zumbov2/colorfindr,3999,23,1547193210
colourpicker,"A colour picker that can be used as an input in Shiny apps
    or Rmarkdown documents. The colour picker supports alpha opacity, custom
    colour palettes, and many more options. A Plot Colour Helper tool is
    available as an RStudio Addin, which helps you pick colours to use in your
    plots. A more generic Colour Picker RStudio Addin is also provided to let 
    you select colours to use in your R code.",2017-09-27,Dean Attali,https://github.com/daattali/colourpicker,TRUE,https://github.com/daattali/colourpicker,306734,90,1554335475
colt,"
  A collection of command-line color styles based on the 'crayon'
  package. 'Colt' styles are defined in themes that can easily be switched, to
  ensure command line output looks nice on dark as well as light consoles.",2017-10-10,Stefan Fleck,https://github.com/s-fleck/colt,TRUE,https://github.com/s-fleck/colt,4712,10,1540649054
commonmark,"The CommonMark specification defines a rationalized version of markdown
    syntax. This package uses the 'cmark' reference implementation for converting
    markdown text into various formats including html, latex and groff man. In
    addition it exposes the markdown parse tree in xml format. Also includes opt-in
    support for GFM extensions including tables, autolinks, and strikethrough text.",2018-12-01,Jeroen Ooms,"http://github.com/jeroen/commonmark (devel)
https://github.github.com/gfm/ (spec)",TRUE,https://github.com/jeroen/commonmark,658429,58,1543665294
commonsMath,Java JAR files for the Apache Commons Mathematics Library for use by users and other packages.,2018-10-26,David B. Dahl,https://github.com/dbdahl/commonsMath,TRUE,https://github.com/dbdahl/commonsmath,8286,2,1553291063
comorbidity,"Computing comorbidity scores such as the weighted Charlson score
  (Charlson, 1987 <doi:10.1016/0021-9681(87)90171-8>) and the Elixhauser
  comorbidity score (Elixhauser, 1998 <doi:10.1097/00005650-199801000-00004>)
  using ICD-9-CM or ICD-10 codes (Quan, 2005 <doi:10.1097/01.mlr.0000182534.19832.83>).",2019-03-22,"Alessandro Gasparini 
    (<https://orcid.org/0000-0002-8319-7624>)",https://github.com/ellessenne/comorbidity,TRUE,https://github.com/ellessenne/comorbidity,7502,10,1553687560
CompareCausalNetworks,"Unified interface for the estimation of causal networks, including
    the methods 'backShift' (from package 'backShift'), 'bivariateANM' (bivariate
    additive noise model), 'bivariateCAM' (bivariate causal additive model),
    'CAM' (causal additive model) (from package 'CAM'), 'hiddenICP' (invariant
    causal prediction with hidden variables), 'ICP' (invariant causal prediction)
    (from package 'InvariantCausalPrediction'), 'GES' (greedy equivalence
    search), 'GIES' (greedy interventional equivalence search), 'LINGAM', 'PC' (PC
    Algorithm), 'FCI' (fast causal inference), 
    'RFCI' (really fast causal inference) (all from package 'pcalg') and
    regression.",2018-05-18,Christina Heinze-Deml <heinzedeml@stat.math.ethz.ch>,https://github.com/christinaheinze/CompareCausalNetworks,TRUE,https://github.com/christinaheinze/comparecausalnetworks,14524,9,1526647989
comparer,"Makes comparisons quickly for different functions or code
    blocks performing the same task with the function mbc(). 
    Can be used to compare model fits to the same data or
    see which function runs faster.",2018-01-08,Collin Erickson,https://github.com/CollinErickson/comparer,TRUE,https://github.com/collinerickson/comparer,3922,2,1554260199
comperank,"Compute ranking and rating based on competition results. Methods of
    different nature are implemented: with fixed Head-to-Head structure, with
    variable Head-to-Head structure and with iterative nature. All algorithms
    are taken from the book 'Who’s #1?: The science of rating and ranking' by
    Amy N. Langville and Carl D. Meyer (2012, ISBN:978-0-691-15422-0).",2018-05-30,Evgeni Chasnovski,https://github.com/echasnovski/comperank,TRUE,https://github.com/echasnovski/comperank,2709,5,1547238497
comperes,"Tools for storing and managing competition results. Competition is
    understood as a set of games in which players gain some abstract scores.
    There are two ways for storing results: in long (one row per game-player)
    and wide (one row per game with fixed amount of players) formats. This
    package provides functions for creation and conversion between them. Also
    there are functions for computing their summary and Head-to-Head values for
    players. They leverage grammar of data manipulation from 'dplyr'.",2019-01-12,Evgeni Chasnovski,https://github.com/echasnovski/comperes,TRUE,https://github.com/echasnovski/comperes,4037,4,1547305515
COMPoissonReg,"Fit Conway-Maxwell Poisson (COM-Poisson or CMP) regression models
    to count data (Sellers & Shmueli, 2010) <doi:10.1214/09-AOAS306>. The
    package provides functions for model estimation, dispersion testing, and
    diagnostics. Zero-inflated CMP regression (Sellers & Raim, 2016)
    <doi:10.1016/j.csda.2016.01.007> is also supported.",2018-12-09,"Kimberly Sellers <kfs7@georgetown.edu>
	Thomas Lotze <thomas.lotze@thomaslotze.com>
	Andrew Raim <andrew.raim@gmail.com>",https://github.com/lotze/COMPoissonReg,TRUE,https://github.com/lotze/compoissonreg,22148,0,1547657283
comprehenr,"Provides 'Python'-style list comprehensions.
    List comprehension expressions use usual loops (for(), while() and repeat()) and
    usual if() as list producers. In many cases it gives more concise notation than
    standard ""*apply + filter"" strategy.",2019-03-17,Gregory Demin,https://github.com/gdemin/comprehenr,TRUE,https://github.com/gdemin/comprehenr,841,7,1552857040
comtradr,"Interface with and extract data from the United Nations Comtrade 
  API <https://comtrade.un.org/data/>. Comtrade provides country level shipping 
  data for a variety of commodities, these functions allow for easy API query 
  and data returned as a tidy data frame.",2018-10-05,Chris Muir,https://github.com/ropensci/comtradr,TRUE,https://github.com/ropensci/comtradr,8776,18,1541973831
concurve,"Allows one to compute confidence (compatibility/consonance) intervals for various statistical tests along with their corresponding P-values and S-values. The intervals can be plotted to create consonance functions allowing one to see what effect sizes are compatible with the test model at various compatibility levels rather than being limited to one interval estimate such as 95%. These methods are discussed by Poole C. (1987) <doi:10.2105/AJPH.77.2.195>, Schweder T, Hjort NL. (2002) <doi:10.1111/1467-9469.00285>, Singh K, Xie M, Strawderman WE. (2007) <arXiv:0708.0976>, Rothman KJ, Greenland S, Lash TL. (2008, ISBN:9781451190052), Amrhein V, Trafimow D, Greenland S. (2019) <doi:10.1080/00031305.2018.1543137>, and Greenland S. (2019) <doi:10.1080/00031305.2018.1529625>.",2019-03-21,Zad Chow  (<https://orcid.org/0000-0003-1545-8199>),"https://data.lesslikely.com/concurve/,
https://github.com/Zadchow/concurve, https://lesslikely.com/",TRUE,https://github.com/zadchow/concurve,883,6,1553155839
condformat,"Apply and visualize conditional formatting to data frames in R.
    It renders a data frame with cells formatted according to
    criteria defined by rules, using a tidy evaluation syntax. The table is
    printed either opening a web browser or within the 'RStudio' viewer if
    available. The conditional formatting rules allow to highlight cells
    matching a condition or add a gradient background to a given column. This
    package supports both 'HTML' and 'LaTeX' outputs in 'knitr' reports, and
    exporting to an 'xlsx' file.",2018-10-29,Sergio Oller Moreno,http://github.com/zeehio/condformat,TRUE,https://github.com/zeehio/condformat,16803,13,1553759292
CondIndTests,"Code for a variety of nonlinear conditional independence tests: 
  Kernel conditional independence test (Zhang et al., UAI 2011, <arXiv:1202.3775>),
  Residual Prediction test (based on Shah and Buehlmann, <arXiv:1511.03334>),
  Invariant environment prediction,
  Invariant target prediction,
  Invariant residual distribution test,
  Invariant conditional quantile prediction (all from Heinze-Deml et al., <arXiv:1706.08576>).",2018-05-07,Christina Heinze-Deml <heinzedeml@stat.math.ethz.ch>,https://github.com/christinaheinze/nonlinearICP-and-CondIndTests,TRUE,https://github.com/christinaheinze/nonlinearicp-and-condindtests,6296,5,1525356604
conditions,"Implements specialized conditions, i.e., typed errors,
    warnings and messages. Offers a set of standardized conditions (value error,
    deprecated warning, io message, ...) in the fashion of Python's built-in
    exceptions.",2017-01-18,Michel Lang <michellang@gmail.com>,https://github.com/mllg/conditions,TRUE,https://github.com/mllg/conditions,5268,10,1551693759
condvis,"Exploring fitted models by interactively taking 2-D and 3-D
  sections in data space.",2018-09-13,Mark OConnell,http://markajoc.github.io/condvis/,TRUE,https://github.com/markajoc/condvis,16061,17,1536793538
config,"Manage configuration values across multiple environments (e.g.
  development, test, production). Read values using a function that determines
  the current environment and returns the appropriate value.",2018-03-27,JJ Allaire,https://github.com/rstudio/config,TRUE,https://github.com/rstudio/config,1106605,111,1525205321
configr,"
    Implements the JSON, INI, YAML and TOML parser for R setting and writing of configuration file. The functionality of this package is similar to that of package 'config'. ",2018-11-13,Jianfeng Li  (<https://orcid.org/0000-0003-2349-208X>),https://github.com/Miachol/configr,TRUE,https://github.com/miachol/configr,31613,28,1542167564
configural,"R functions for criterion profile analysis, Davison and Davenport (2002) <doi:10.1037/1082-989X.7.4.468> and meta-analytic criterion profile analysis, Wiernik, Wilmot, Davison, and Ones (2019). Sensitivity analyses to aid in interpreting criterion profile analysis results are also included.",2019-02-19,Brenton M. Wiernik,NA,TRUE,https://github.com/bwiernik/configural,656,0,1549759622
confinterpret,"Produces descriptive interpretations of confidence intervals.
    Includes (extensible) support for various test types, specified as sets
    of interpretations dependent on where the lower and upper confidence limits
    sit. Provides plotting functions for graphical display of interpretations.",2017-10-03,Jim Vine,https://github.com/jimvine/confinterpret,TRUE,https://github.com/jimvine/confinterpret,6468,0,1529679294
conflicted,"R's default conflict management system gives the most recently
    loaded package precedence. This can make it hard to detect conflicts, 
    particularly when they arise because a package update creates ambiguity
    that did not previously exist. 'conflicted' takes a different approach, 
    making every conflict an error and forcing you to choose which function 
    to use.",2019-03-29,Hadley Wickham,https://github.com/r-lib/conflicted,TRUE,https://github.com/r-lib/conflicted,9988,121,1553949252
CongreveLamsdell2016,"Includes the 100 datasets simulated by Congreve and Lamsdell (2016) 
  <doi:10.1111/pala.12236>, and analyses of the partition and quartet distance of
  reconstructed trees from the generative tree, as analysed by Smith (2019) 
  <doi:10.1098/rsbl.2018.0632>.",2019-02-07,Martin R. Smith,https://github.com/ms609/CongreveLamsdell2016,TRUE,https://github.com/ms609/congrevelamsdell2016,1205,0,1549542271
ConR,"Multi-species estimation of geographical range parameters
	for preliminary assessment of conservation status following Criterion B of the 
	International Union for Conservation of Nature (IUCN, 
	see <http://www.iucnredlist.org>).",2018-06-07,Gilles Dauby,https://github.com/gdauby/ConR,TRUE,https://github.com/gdauby/conr,8947,3,1553793371
constants,"CODATA internationally recommended values of the fundamental physical 
    constants, provided as symbols for direct use within the R language. Optionally, 
    the values with errors and/or the values with units are also provided if the 
    'errors' and/or the 'units' packages are installed. The Committee on Data
    for Science and Technology (CODATA) is an interdisciplinary committee of the
    International Council for Science which periodically provides the internationally 
    accepted set of values of the fundamental physical constants. This package 
    contains the ""2014 CODATA"" version, published on 25 June 2015:
    Mohr, P. J., Newell, D. B. and Taylor, B. N. (2016)
    <DOI:10.1103/RevModPhys.88.035009>, <DOI:10.1063/1.4954402>.",2018-01-08,Iñaki Ucar,https://github.com/r-quantities/constants,TRUE,https://github.com/r-quantities/constants,5071,10,1534169156
constellation,"Examine any number of time series data frames to identify 
    instances in which various criteria are met within specified time
    frames. In clinical medicine, these types of events are often
    called ""constellations of signs and symptoms"", because a single 
    condition depends on a series of events occurring within a certain 
    amount of time of each other. This package was written to work with
    any number of time series data frames and is optimized for speed 
    to work well with data frames with millions of rows.",2018-03-27,Mark Sendak,https://github.com/marksendak/constellation,TRUE,https://github.com/marksendak/constellation,5007,2,1542166511
container,"Common container data structures deque, set and dict (resembling
    'Python's dict type) with typical member functions to insert, delete and
    access container elements. Provides iterators and reference semantics.",2018-12-01,Roman Pahl,https://github.com/rpahl/container,TRUE,https://github.com/rpahl/container,2603,2,1543771276
contextual,"Facilitates the simulation and evaluation of context-free
    and contextual multi-Armed Bandit policies or algorithms to ease the
    implementation, evaluation, and dissemination of both existing and
    new bandit algorithms and policies.",2019-03-17,Robin van Emden  (<https://orcid.org/0000-0001-5820-8638>),https://github.com/Nth-iteration-labs/contextual,TRUE,https://github.com/nth-iteration-labs/contextual,2110,20,1552834388
contfrac,Various utilities for evaluating continued fractions.,2018-05-17,Robin K. S. Hankin,https://github.com/RobinHankin/contfrac.git,TRUE,https://github.com/robinhankin/contfrac,160411,0,1548880958
ContourFunctions,"Provides functions for making contour plots.
  The contour plot can be created from grid data, a function,
  or a data set. If non-grid data is given, then a Gaussian
  process is fit to the data and used to create the contour plot.",2017-05-04,Collin Erickson,https://github.com/CollinErickson/contour,TRUE,https://github.com/collinerickson/contour,5179,5,1529460919
control,"Solves control systems problems relating to time/frequency response, LTI systems design and analysis, transfer function manipulations, and system conversion.",2017-12-12,Ben C. Ubah,NA,TRUE,https://github.com/benubah/control,3756,10,1525694086
ConvergenceClubs,"Functions for clustering regions that form convergence clubs, according to the definition of Phillips and Sul (2009) <doi:10.1002/jae.1080>.",2018-12-14,Roberto Sichera,https://CRAN.R-project.org/package=ConvergenceClubs,TRUE,https://github.com/rhobis/convergenceclubs,5354,0,1548328072
convexjlr,"Provides a simple high-level wrapper for
    'Julia' package 'Convex.jl' (see <https://github.com/JuliaOpt/Convex.jl> for
    more information),
    which makes it easy to describe and solve convex optimization problems in R.
    The problems can be dealt with include:
    linear programs,
    second-order cone programs,
    semidefinite programs,
    exponential cone programs.",2018-12-16,Changcheng Li,https://github.com/Non-Contradiction/convexjlr,TRUE,https://github.com/non-contradiction/convexjlr,6902,9,1545176635
convey,"Variance estimation on indicators of income concentration and
    poverty using complex sample survey designs. Wrapper around the
    survey package.",2018-06-19,Djalma Pessoa,https://guilhermejacob.github.io/context/,TRUE,https://github.com/djalmapessoa/convey,13866,10,1526655399
coop,"Fast implementations of the co-operations: covariance,
    correlation, and cosine similarity.  The implementations are
    fast and memory-efficient and their use is resolved
    automatically based on the input data, handled by R's S3
    methods.  Full descriptions of the algorithms and benchmarks
    are available in the package vignettes.",2017-11-14,Drew Schmidt,https://github.com/wrathematics/coop,TRUE,https://github.com/wrathematics/coop,12528,14,1554337144
CoordinateCleaner,"Automated flagging of common spatial and temporal errors in biological and paleontological collection data, for the use in conservation, ecology and paleontology. Includes automated tests to easily flag (and exclude) records assigned to country or province centroid, the open ocean, the headquarters of the Global Biodiversity Information Facility, urban areas or the location of biodiversity institutions (museums, zoos, botanical gardens, universities). Furthermore identifies per species outlier coordinates, zero coordinates, identical latitude/longitude and invalid coordinates. Also implements an algorithm to identify data sets with a significant proportion of rounded coordinates. Especially suited for large data sets.",2019-04-02,Alexander Zizka,https://ropensci.github.io/CoordinateCleaner/,TRUE,https://github.com/ropensci/coordinatecleaner,11104,22,1554189401
coppeCosenzaR,"The program implements the COPPE-Cosenza Fuzzy Hierarchy Model. 
    The model was based on the evaluation of local alternatives, representing 
    regional potentialities, so as to fulfill demands of economic projects. 
    After defining demand profiles in terms of their technological coefficients, 
    the degree of importance of factors is defined so as to represent  
    the productive activity. The method can detect a surplus of supply without 
    the restriction of the distance of classical algebra, defining a hierarchy 
    of location alternatives. In COPPE-Cosenza Model, the distance between 
    factors is measured in terms of the difference between grades of memberships
    of the same factors belonging to two or more  sets under comparison. The 
    required factors are classified under the following linguistic variables: 
    Critical (CR); Conditioning (C); Little Conditioning (LC); and Irrelevant 
    (I). And the alternatives can assume the following linguistic variables: 
    Excellent (Ex), Good (G), Regular (R), Weak (W), Empty (Em), Zero (Z) and 
    Inexistent (In). The model also provides flexibility, allowing different 
    aggregation rules to be performed and defined by the Decision Maker. Such 
    feature is considered in this package, allowing the user to define other 
    aggregation matrices, since it considers the same linguistic variables 
    mentioned. ",2017-10-28,Pier Taranti,https://github.com/ptaranti/coppeCosenzaR,TRUE,https://github.com/ptaranti/coppecosenzar,5853,0,1527205913
copulaedas,"Provides a platform where EDAs (estimation of
    distribution algorithms) based on copulas can be implemented and
    studied. The package offers complete implementations of various
    EDAs based on copulas and vines, a group of well-known
    optimization problems, and utility functions to study the
    performance of the algorithms. Newly developed EDAs can be easily
    integrated into the package by extending an S4 class with generic
    functions for their main components.",2018-07-29,Yasser Gonzalez-Fernandez,https://github.com/yasserglez/copulaedas,TRUE,https://github.com/yasserglez/copulaedas,20878,1,1532841489
coRanking,"Calculates the co-ranking matrix to assess the
    quality of a dimensionality reduction.",2018-10-01,Guido Kraemer,https://github.com/gdkrmr/coRanking,TRUE,https://github.com/gdkrmr/coranking,14296,4,1545039155
Corbi,"Provides a bundle of basic and fundamental bioinformatics tools,
    such as network querying and alignment, subnetwork extraction and search,
    network biomarker identification.",2019-03-04,Ling-Yun Wu,https://github.com/wulingyun/Corbi,TRUE,https://github.com/wulingyun/corbi,11030,2,1553042762
coreCT,"Computed tomography (CT) imaging is a powerful tool for understanding the composition of sediment cores. This package streamlines and accelerates the analysis of CT data generated in the context of environmental science. Included are tools for processing raw DICOM images to characterize sediment composition (sand, peat, etc.). Root analyses are also enabled, including measures of external surface area and volumes for user-defined root size classes. For a detailed description of the application of computed tomography imaging for sediment characterization, see: Davey, E., C. Wigand, R. Johnson, K. Sundberg, J. Morris, and C. Roman. (2011) <DOI: 10.1890/10-2037.1>.",2018-06-24,Troy D. Hill <Hill.Troy@gmail.com>,https://github.com/troyhill/coreCT,TRUE,https://github.com/troyhill/corect,4967,1,1546523244
cornet,Implements lasso and ridge regression for dichotomised outcomes (Rauschenberger et al. 2019). Such outcomes are not naturally but artificially binary. They indicate whether an underlying measurement is greater than a threshold.,2019-03-21,Armin Rauschenberger,https://github.com/rauschenberger/cornet,TRUE,https://github.com/rauschenberger/cornet,321,0,1552981509
coroICA,"Contains an implementation of a confounding robust independent component analysis (ICA) for noisy and grouped data. The main function coroICA() performs a blind source separation, by maximizing an independence across sources and allows to adjust for varying confounding based on user-specified groups. Additionally, the package contains the function uwedge() which can be used to approximately jointly diagonalize a list of matrices. For more details see the project website <https://sweichwald.de/coroICA/>.",2018-12-30,Niklas Pfister and Sebastian Weichwald,https://github.com/sweichwald/coroICA-R,TRUE,https://github.com/sweichwald/coroica-r,1013,1,1545124153
CoRpower,"Calculates power for assessment of intermediate biomarker responses as correlates of risk in the active treatment group in clinical efficacy trials, as described in Gilbert, Janes, and Huang, Power/Sample Size Calculations for Assessing Correlates of Risk in Clinical Efficacy Trials (2016, Statistics in Medicine). The methods differ from past approaches by accounting for the level of clinical treatment efficacy overall and in biomarker response subgroups, which enables the correlates of risk results to be interpreted in terms of potential correlates of efficacy/protection. The methods also account for inter-individual variability of the observed biomarker response that is not biologically relevant (e.g., due to technical measurement error of the laboratory assay used to measure the biomarker response), which is important because power to detect a specified correlate of risk effect size is heavily affected by the biomarker's measurement error. The methods can be used for a general binary clinical endpoint model with a univariate dichotomous, trichotomous, or continuous biomarker response measured in active treatment recipients at a fixed timepoint after randomization, with either case-cohort Bernoulli sampling or case-control without-replacement sampling of the biomarker (a baseline biomarker is handled as a trivial special case). In a specified two-group trial design, the computeN() function can initially be used for calculating additional requisite design parameters pertaining to the target population of active treatment recipients observed to be at risk at the biomarker sampling timepoint. Subsequently, the power calculation employs an inverse probability weighted logistic regression model fitted by the tps() function in the 'osDesign' package. Power results as well as the relationship between the correlate of risk effect size and treatment efficacy can be visualized using various plotting functions.",2018-10-06,Michal Juraska,https://github.com/mjuraska/CoRpower,TRUE,https://github.com/mjuraska/corpower,1466,0,1554332243
corpustools,"Provides text analysis in R, focusing on the use of a tokenized text format. In this format, the positions of tokens are maintained, and each token can be annotated (e.g., part-of-speech tags, dependency relations).
    Prominent features include advanced Lucene-like querying for specific tokens or contexts (e.g., documents, sentences),
    similarity statistics for words and documents, exporting to DTM for compatibility with many text analysis packages,
    and the possibility to reconstruct original text from tokens to facilitate interpretation.",2018-04-20,Kasper Welbers and Wouter van Atteveldt,http://github.com/kasperwelbers/corpustools,TRUE,https://github.com/kasperwelbers/corpustools,7180,17,1543924294
corrgram,"Calculates correlation of variables and displays the results
    graphically. Included panel functions can display points, shading, ellipses, and
    correlation values with confidence intervals. See Friendly (2002) <doi:10.1198/000313002533>.",2018-07-09,Kevin Wright  (<https://orcid.org/0000-0002-0617-8673>),https://github.com/kwstat/corrgram,TRUE,https://github.com/kwstat/corrgram,327933,10,1540829795
corrplot,"A graphical display of a correlation matrix or general matrix.
    It also contains some algorithms to do matrix reordering. In addition,
    corrplot is good at details, including choosing color, text labels,
    color labels, layout, etc.",2017-10-16,Taiyun Wei,https://github.com/taiyun/corrplot,TRUE,https://github.com/taiyun/corrplot,1370281,170,1539741483
corrr,"A tool for exploring correlations.
    It makes it possible to easily perform routine tasks when
    exploring correlation matrices such as ignoring the diagonal,
    focusing on the correlations of certain variables against others,
    or rearranging and visualising the matrix in terms of the
    strength of the correlations.",2019-03-06,Simon Jackson,https://github.com/drsimonj/corrr,TRUE,https://github.com/drsimonj/corrr,39135,264,1551889660
cosinor2,"Statistical procedures for calculating population–mean cosinor, non–stationary cosinor, estimation of best–fitting period, tests of population rhythm differences and more. See Cornélissen, G. (2014). <doi:10.1186/1742-4682-11-16>.",2018-10-15,Augustin Mutak <mutak94@gmail.com>,https://github.com/amutak/cosinor2,TRUE,https://github.com/amutak/cosinor2,5637,3,1539622583
costsensitive,"Reduction-based techniques for cost-sensitive multi-class classification, in which each observation has a different cost for classifying it into one class, and the goal is to predict the class with the minimum expected cost for each new observation.
	Implements Weighted All-Pairs (Beygelzimer, A., Langford, J., & Zadrozny, B., 2008, <doi:10.1007/978-0-387-79361-0_1>), Weighted One-Vs-Rest (Beygelzimer, A., Dani, V., Hayes, T., Langford, J., & Zadrozny, B., 2005, <https://dl.acm.org/citation.cfm?id=1102358>) and Regression One-Vs-Rest.
	Works with arbitrary classifiers taking observation weights, or with regressors. Also implements cost-proportionate rejection sampling for working with classifiers
	that don't accept observation weights.",2019-03-03,David Cortes,https://github.com/david-cortes/costsensitive,TRUE,https://github.com/david-cortes/costsensitive,629,13,1551980520
countfitteR,"A large number of measurements generate count data. This is a statistical data type that only assumes non-negative integer values and is generated by counting. Typically, counting data can be found in biomedical applications, such as the analysis of DNA double-strand breaks. The number of DNA double-strand breaks can be counted in individual cells using various bioanalytical methods. For diagnostic applications, it is relevant to record the distribution of the number data in order to determine their biomedical significance (Roediger, S. et al., 2018. Journal of Laboratory and Precision Medicine. <doi:10.21037/jlpm.2018.04.10>). The software offers functions for a comprehensive automated evaluation of distribution models of count data. In addition to programmatic interaction, a graphical user interface (web server) is included, which enables fast and interactive data-scientific analyses. The user is supported in selecting the most suitable counting distribution for his own data set.",2019-02-03,Jaroslaw Chilimoniuk,https://github.com/jarochi/countfitteR,TRUE,https://github.com/jarochi/countfitter,842,2,1550349235
countrycode,"Standardize country names, convert them into one of
    eleven coding schemes, convert between coding schemes, and
    assign region descriptors.",2018-10-27,"Vincent Arel-Bundock 
    (<https://orcid.org/0000-0003-2042-7063>)",https://github.com/vincentarelbundock/countrycode,TRUE,https://github.com/vincentarelbundock/countrycode,126317,162,1552588248
covafillr,"Facilitates local polynomial regression for state dependent covariates in state-space models. The functionality can also be used from 'C++' based model builder tools such as 'Rcpp'/'inline', 'TMB', or 'JAGS'.",2018-09-13,"Christoffer Moesgaard Albertsen 
    (<https://orcid.org/0000-0003-0088-4363>)",https://github.com/calbertsen/covafillr,TRUE,https://github.com/calbertsen/covafillr,10393,0,1536842905
coveffectsplot,"Produce forest plots to visualize covariate effects using either
    the command line or an interactive 'Shiny' application.",2019-02-25,Samer Mouksassi  (<https://orcid.org/0000-0002-7152-6654>),https://github.com/smouksassi/interactiveforestplot,TRUE,https://github.com/smouksassi/interactiveforestplot,2640,5,1551956744
covequal,"Computes p-values using the largest root test using 
    an approximation to the null distribution by Johnstone (2008) <DOI:10.1214/08-AOS605>.",2017-10-14,Maxime Turgeon,http://github.com/turgeonmaxime/covequal,TRUE,https://github.com/turgeonmaxime/covequal,3602,0,1530984454
covr,"Track and report code coverage for your package and (optionally)
    upload the results to a coverage service like 'Codecov' <http://codecov.io> or
    'Coveralls' <http://coveralls.io>. Code coverage is a measure of the amount of
    code being exercised by a set of tests. It is an indirect measure of test
    quality and completeness. This package is compatible with any testing
    methodology or framework and tracks coverage of both R code and compiled
    C/C++/FORTRAN code.",2018-10-18,Jim Hester,https://github.com/r-lib/covr,TRUE,https://github.com/r-lib/covr,1337510,230,1549906479
covTestR,"Testing functions for Covariance Matrices. These tests include high-dimension homogeneity of covariance
  matrix testing described by Schott (2007) <doi:10.1016/j.csda.2007.03.004> and high-dimensional one-sample tests of 
  covariance matrix structure described by Fisher, et al. (2010) <doi:10.1016/j.jmva.2010.07.004>. Covariance matrix
  tests use C++ to speed performance and allow larger data sets.",2018-08-17,Ben Barnard,https://covtestr.bearstatistics.com,TRUE,https://github.com/benbarnard/covtestr,9636,0,1534533199
cowplot,"Some helpful extensions and modifications to the 'ggplot2'
    package. In particular, this package makes it easy to combine multiple
    'ggplot2' plots into one and label them with letters, e.g. A, B, C, etc.,
    as is often required for scientific publications. The package also provides
    a streamlined and clean theme that is used in the Wilke lab, hence the
    package name, which stands for Claus O. Wilke's plot package.",2019-01-08,Claus O. Wilke,https://github.com/wilkelab/cowplot,TRUE,https://github.com/wilkelab/cowplot,1261957,379,1551654633
cowsay,"Allows printing of character strings as messages/warnings/etc.
    with ASCII animals, including cats, cows, frogs, chickens, ghosts,
    and more.",2018-09-18,Scott Chamberlain,https://github.com/sckott/cowsay,TRUE,https://github.com/sckott/cowsay,26298,190,1549047428
coxed,"Functions for generating, simulating, and visualizing expected
    durations and marginal changes in duration from the Cox proportional hazards
    model.",2018-08-23,Kropko,https://github.com/jkropko/coxed,TRUE,https://github.com/jkropko/coxed,3128,3,1553865002
coxrt,Fits Cox regression based on retrospectively ascertained times-to-event. The method uses Inverse-Probability-Weighting estimating equations. ,2019-01-05,Bella Vakulenko-Lagun,https://github.com/Bella2001/coxrt,TRUE,https://github.com/bella2001/coxrt,2538,0,1546716549
CPBayes,"A Bayesian meta-analysis method for studying cross-phenotype
    genetic associations. It uses summary-level data across multiple phenotypes to
    simultaneously measure the evidence of aggregate-level pleiotropic association
    and estimate an optimal subset of traits associated with the risk locus. CPBayes
    is based on a spike and slab prior.",2019-01-12,Arunabha Majumdar <statgen.arunabha@gmail.com>,https://github.com/ArunabhaCodes/CPBayes,TRUE,https://github.com/arunabhacodes/cpbayes,7422,1,1547320453
cpgen,"Frequently used methods in genomic applications with emphasis on parallel computing (OpenMP).
 At its core, the package has a Gibbs Sampler that allows running univariate linear
 mixed models that have both, sparse and dense design matrices. The parallel sampling method
 in case of dense design matrices (e.g. Genotypes) allows running Ridge Regression or BayesA for
 a very large number of individuals. The Gibbs Sampler is capable of running Single Step Genomic Prediction models.
 In addition, the package offers parallelized functions for common tasks like genome-wide
 association studies and cross validation in a memory efficient way.",2015-09-15,Claas Heuer,https://github.com/cheuerde/cpgen,TRUE,https://github.com/cheuerde/cpgen,8497,3,1532465358
cplm,"Likelihood-based and Bayesian methods for various compound Poisson linear models based on Zhang, Yanwei (2013) <https://link.springer.com/article/10.1007/s11222-012-9343-7>.",2019-03-05,Yanwei (Wayne) Zhang,https://github.com/actuaryzhang/cplm,TRUE,https://github.com/actuaryzhang/cplm,54235,3,1528668141
cpr,"Implementation of the Control Polygon Reduction and Control Net
    Reduction methods for finding parsimonious B-spline regression models.",2017-03-07,Peter DeWitt,https://github.com/dewittpe/cpr/,TRUE,https://github.com/dewittpe/cpr,5108,2,1535950930
cprr,"Calculate date of birth, age, and gender, and generate anonymous
    sequence numbers from CPR numbers.
    <https://en.wikipedia.org/wiki/Personal_identification_number_(Denmark)>.",2019-03-17,Jacob Anhoej,http://github.com/anhoej/cprr,TRUE,https://github.com/anhoej/cprr,4599,2,1552806166
cptcity,Incorporates colour gradients from the 'cpt-city' web archive available at <http://soliton.vm.bytemark.co.uk/pub/cpt-city/>. ,2019-03-07,"Sergio Ibarra-Espinosa 
    (<https://orcid.org/0000-0002-3162-1905>)",https://github.com/ibarraespinosa/cptcity,TRUE,https://github.com/ibarraespinosa/cptcity,4815,6,1551957598
cranlike,"A set of functions to manage 'CRAN'-like repositories
    efficiently.",2018-11-26,Gábor Csárdi,https://github.com/r-hub/cranlike,TRUE,https://github.com/r-hub/cranlike,6783,20,1543230408
cranly,"Provides core visualisations and summaries for the CRAN package database. The package provides comprehensive methods for cleaning up and organising the information in the CRAN package database, for building package directives networks (depends, imports, suggests, enhances, linking to) and collaboration networks, producing package dependence trees, and for computing useful summaries and producing interactive visualisations from the resulting networks. The package also provides functions to coerce the networks to 'igraph' <https://CRAN.R-project.org/package=igraph> objects for further analyses and modelling.",2019-02-14,Ioannis Kosmidis  (<https://orcid.org/0000-0003-1556-0302>),https://github.com/ikosmidis/cranly,TRUE,https://github.com/ikosmidis/cranly,4051,30,1550163820
CREAM,"Provides a new method for identification of clusters of genomic
 regions within chromosomes. Primarily, it is used for calling clusters of 
 cis-regulatory elements (COREs). 'CREAM' uses genome-wide maps of genomic regions
 in the tissue or cell type of interest, such as those generated from chromatin-based 
 assays including DNaseI, ATAC or ChIP-Seq. 'CREAM' considers proximity of the elements 
 within chromosomes of a given sample to identify COREs in the following steps:
 1) It identifies window size or the maximum allowed distance between the elements 
 within each CORE, 2) It identifies number of elements which should be clustered 
 as a CORE, 3) It calls COREs, 4) It filters the COREs with lowest order which 
 does not pass the threshold considered in the approach.",2018-06-06,Benjamin Haibe-Kains,https://github.com/bhklab/CREAM,TRUE,https://github.com/bhklab/cream,5060,4,1544113475
credentials,"Setup and retrieve HTTPS and SSH credentials for use with 'git' and 
    other services. For HTTPS remotes the package interfaces the 'git-credential' 
    utility which 'git' uses to store HTTP usernames and passwords. For SSH 
    remotes we provide convenient functions to find or generate appropriate SSH 
    keys. The package both helps the user to setup a local git installation, and
    also provides a back-end for git/ssh client libraries to authenticate with 
    existing user credentials.",2019-03-12,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),https://github.com/r-lib/credentials,TRUE,https://github.com/r-lib/credentials,1445,23,1552393786
cregg,"Simple tidying, analysis, and visualization of conjoint (factorial) experiments, including estimation and visualization of average marginal component effects ('AMCEs') and marginal means ('MMs') for weighted and un-weighted survey data, along with useful reference category diagnostics and statistical tests. Estimation of 'AMCEs' is based upon methods described by Hainmueller, Hopkins, and Yamamoto (2014) <doi:10.1093/pan/mpt024>.",2018-07-30,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/leeper/cregg,TRUE,https://github.com/leeper/cregg,1973,17,1532690068
cRegulome,"Builds a 'SQLite' database file of pre-calculated transcription 
    factor/microRNA-gene correlations (co-expression) in cancer from the 
    Cistrome Cancer Liu et al. (2011) <doi:10.1186/gb-2011-12-8-r83> and 
    'miRCancerdb' databases (in press). Provides custom classes and functions 
    to query, tidy and plot the correlation data.",2019-01-03,Mahmoud Ahmed  (<https://orcid.org/0000-0002-4377-6541>),https://github.com/ropensci/cRegulome,TRUE,https://github.com/ropensci/cregulome,5571,2,1554374195
CRF,"Implements modeling and computational tools for conditional
    random fields (CRF) model as well as other probabilistic undirected
    graphical models of discrete data with pairwise and unary potentials.",2019-03-04,Ling-Yun Wu,https://github.com/wulingyun/CRF,TRUE,https://github.com/wulingyun/crf,25349,10,1551675207
cricketr,"Tools for analyzing performances of cricketers based on stats in
    ESPN Cricinfo Statsguru. The toolset can  be used for analysis of Tests,ODIs 
    and Twenty20 matches of both batsmen and bowlers.",2019-03-07,Tinniam V Ganesh,https://github.com/tvganesh/cricketr,TRUE,https://github.com/tvganesh/cricketr,13230,37,1552008286
crimedata,"Gives convenient access to publicly available police-recorded open
    crime data from large cities in the United States that are included in the
    Crime Open Database <https://osf.io/zyaqn/>.",2019-03-21,Matthew Ashby  (<https://orcid.org/0000-0003-4201-9239>>),https://github.com/mpjashby/crimedata,TRUE,https://github.com/mpjashby/crimedata,2166,2,1553205230
crminer,"Text mining client for 'Crossref' (<https://crossref.org>). Includes
    functions for getting getting links to full text of articles, fetching full
    text articles from those links or Digital Object Identifiers ('DOIs'),
    and text extraction from 'PDFs'.",2018-10-15,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/crminer,TRUE,https://github.com/ropensci/crminer,12093,13,1552069779
crmPack,"Implements a wide range of model-based dose
    escalation designs, ranging from classical and modern continual
    reassessment methods (CRMs) based on dose-limiting toxicity endpoints to
    dual-endpoint designs taking into account a biomarker/efficacy outcome. The
    focus is on Bayesian inference, making it very easy to setup a new design
    with its own JAGS code. However, it is also possible to implement 3+3
    designs for comparison or models with non-Bayesian estimation. The whole
    package is written in a modular form in the S4 class system, making it very
    flexible for adaptation to new models, escalation or stopping rules.",2018-12-21,Giuseppe Palermo,https://github.com/roche/crmPack,TRUE,https://github.com/roche/crmpack,14281,1,1543913428
crochet,"Functions to help implement the extraction / subsetting / indexing
    function [ and replacement function [<- of custom matrix-like types (based
    on S3, S4, etc.), modeled as closely to the base matrix class as possible
    (with tests to prove it).",2018-08-06,Alexander Grueneberg,https://github.com/agrueneberg/crochet,TRUE,https://github.com/agrueneberg/crochet,8197,4,1553272411
cropdatape,"Provides peruvian agricultural production data from the Agriculture Minestry of Peru (MINAGRI). The first version includes
             6 crops: rice, quinoa, potato, sweet potato, tomato and wheat; all of them across 24 departments. Initially,  in excel files which has been transformed
             and assembled using tidy data principles, i.e. each variable is in a column, each observation is a row and each value is in a cell.
             The variables variables are sowing and harvest area per crop, yield, production and price per plot, every one year, from 2004 to 2014.",2017-03-02,Omar Benites-Alfaro,"https://github.com/omarbenites/cropdatape,
http://siea.minagri.gob.pe/siea/?q=publicaciones/anuarios-estadisticos",TRUE,https://github.com/omarbenites/cropdatape,4707,0,1543896752
CrossClustering,"Provide the CrossClustering algorithm (Tellaroli et al. (2016)
    <doi:10.1371/journal.pone.0152333>), which is a partial clustering algorithm
    that combines the Ward's minimum variance and Complete Linkage algorithms,
    providing automatic estimation of a suitable number of clusters and
    identification of outlier elements.",2018-07-30,Paola Tellaroli,https://CRAN.R-project.org/package=CrossClustering,TRUE,https://github.com/corradolanera/crossclustering,8341,0,1532961604
crossrun,"Joint distribution of number of crossings and the 
  longest run in a series of independent Bernoulli trials. The
  computations uses an iterative procedure where computations 
  are based on results from shorter series. The procedure 
  conditions on the start value and partitions by further 
  conditioning on the position of the first crossing (or none).",2018-10-08,Tore Wentzel-Larsen,https://github.com/ToreWentzel-Larsen/crossrun,TRUE,https://github.com/torewentzel-larsen/crossrun,1519,0,1540531073
crosstalk,"Provides building blocks for allowing HTML widgets to communicate
    with each other, with Shiny or without (i.e. static .html files). Currently
    supports linked brushing and filtering.",2016-12-21,Joe Cheng,https://rstudio.github.io/crosstalk/,TRUE,https://github.com/rstudio/crosstalk,2260990,172,1544483811
crosswalkr,"A pair of functions for renaming and encoding data frames
	     using external crosswalk files. It is especially useful when
	     constructing master data sets from multiple smaller data
	     sets that do not name or encode variables consistently
	     across files. Based on similar commands in 'Stata'.",2019-03-04,Benjamin Skinner  (<https://orcid.org/0000-0002-0337-7415>),https://github.com/btskinner/crosswalkr,TRUE,https://github.com/btskinner/crosswalkr,5736,3,1551900840
crplyr,"In order to facilitate analysis of datasets hosted on the Crunch
    data platform <http://crunch.io/>, the 'crplyr' package implements 'dplyr'
    methods on top of the Crunch backend. The usual methods 'select', 'filter',
    'group_by', 'summarize', and 'collect' are implemented in such a way as to
    perform as much computation on the server and pull as little data locally
    as possible.",2019-04-03,Jonathan Keane,"https://crunch.io/r/crplyr/, https://github.com/Crunch-io/crplyr",TRUE,https://github.com/crunch-io/crplyr,6787,3,1554331544
crs,"Regression splines that handle a mix of continuous and categorical (discrete) data often encountered in applied settings. I would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <http://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <http://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <https://www.sharcnet.ca>).",2018-05-01,Jeffrey S. Racine,https://github.com/JeffreyRacine/R-Package-crs,TRUE,https://github.com/jeffreyracine/r-package-crs,63347,9,1527003216
crseEventStudy,"Based on Dutta et al. (2018) <doi:10.1016/j.jempfin.2018.02.004>, this package provides their standardized test for abnormal returns in long-horizon event studies. The methods used improve the major weaknesses of size, power, and robustness of long-run statistical tests described in Kothari/Warner (2007) <doi:10.1016/B978-0-444-53265-7.50015-9>. Abnormal returns are weighted by their statistical precision (i.e., standard deviation), resulting in abnormal standardized returns. This procedure efficiently captures the heteroskedasticity problem. Clustering techniques following Cameron et al. (2011) <10.1198/jbes.2010.07136> are adopted for computing cross-sectional correlation robust standard errors. The statistical tests in this package therefore accounts for potential biases arising from returns' cross-sectional correlation, autocorrelation, and volatility clustering without power loss.",2019-02-13,"Siegfried Köstlmeier 
    (<https://orcid.org/0000-0002-7221-6981>)",https://github.com/skoestlmeier/crseEventStudy,TRUE,https://github.com/skoestlmeier/crseeventstudy,1978,1,1550074729
crsra,"Tidies and performs preliminary analysis of 'Coursera' research
    export data. These export data can be downloaded by anyone who has classes
    on Coursera and wants to analyze the data. Coursera is one of the leading 
    providers of MOOCs and was launched in January 2012. With over 25 million 
    learners, Coursera is the most popular provider in the world being followed 
    by EdX, the MOOC provider that was a result of a collaboration between 
    Harvard University and MIT, with over 10 million users. Coursera has over 
    150 university partners from 29 countries and offers a total of 2000+ 
    courses from computer science to philosophy. Besides, Coursera offers 180+ 
    specialization, Coursera's credential system, and four fully online Masters 
    degrees. For more information about Coursera check Coursera's
    About page on <https://blog.coursera.org/about/>.",2018-05-05,Aboozar Hadavand,NA,TRUE,https://github.com/jhudsl/crsra,2510,1,1550518493
crul,"A simple HTTP client, with tools for making HTTP requests,
    and mocking HTTP requests. The package is built on R6, and takes
    inspiration from Ruby's 'faraday' gem (<https://rubygems.org/gems/faraday>).
    The package name is a play on curl, the widely used command line tool
    for HTTP, and this package is built on top of the R package 'curl', an
    interface to 'libcurl' (<https://curl.haxx.se/libcurl>).",2019-03-28,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),"https://github.com/ropensci/crul (devel)
https://ropensci.github.io/http-testing-book/ (user manual)",TRUE,https://github.com/ropensci/crul,202953,55,1553790082
crunch,"The Crunch.io service <http://crunch.io/> provides a cloud-based
    data store and analytic engine, as well as an intuitive web interface.
    Using this package, analysts can interact with and manipulate Crunch
    datasets from within R. Importantly, this allows technical researchers to
    collaborate naturally with team members, managers, and clients who prefer a
    point-and-click interface.",2019-04-02,Jonathan Keane,"https://crunch.io/r/crunch/, https://github.com/Crunch-io/rcrunch",TRUE,https://github.com/crunch-io/rcrunch,46481,6,1554438488
crunchy,"To facilitate building custom dashboards on the Crunch data
    platform <https://crunch.io/>, the 'crunchy' package provides tools for
    working with 'shiny'. These tools include utilities to manage authentication
    and authorization automatically and custom stylesheets to help match the
    look and feel of the Crunch web application. The package also includes
    several gadgets for use in 'RStudio'.",2019-04-03,Jonathan Keane,"https://crunch.io/r/crunchy/, https://github.com/Crunch-io/crunchy",TRUE,https://github.com/crunch-io/crunchy,6070,3,1554325221
crypto,"Retrieves crypto currency current and historical information as well as information on the exchanges they are listed on. For current and historical it will retrieve the daily open, high, low and close values for all crypto currencies. This retrieves the historical market data by web scraping tables provided by 'Cryptocurrency Market Capitalizations' <https://coinmarketcap.com>.",2019-01-13,Jesse Vent,"https://github.com/JesseVent/crypto,
https://CRAN.R-project.org/package=crypto",TRUE,https://github.com/jessevent/crypto,21044,72,1547365413
cstab,"Selection of the number of clusters in cluster analysis using
    stability methods.",2018-06-19,Jonas M. B. Haslbeck,NA,TRUE,https://github.com/jmbh/cstab,8566,2,1529426170
csvread,"Functions for loading large (10M+ lines) CSV
    and other delimited files, similar to read.csv, but typically faster and
    using less memory than the standard R loader. While not entirely general,
    it covers many common use cases when the types of columns in the CSV file
    are known in advance. In addition, the package provides a class 'int64',
    which represents 64-bit integers exactly when reading from a file. The
    latter is useful when working with 64-bit integer identifiers exported from
    databases. The CSV file loader supports common column types including
    'integer', 'double', 'string', and 'int64', leaving further type
    transformations  to the user.",2018-12-05,Sergei Izrailev,http://github.com/jabiru/csvread,TRUE,https://github.com/jabiru/csvread,30305,0,1544473585
csvy,"Support for import from and export to the CSVY file format. CSVY is a file format that combines the simplicity of CSV (comma-separated values) with the metadata of other plain text and binary formats (JSON, XML, Stata, etc.) by placing a YAML header on top of a regular CSV.",2018-08-01,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/leeper/csvy,TRUE,https://github.com/leeper/csvy,53237,29,1533079588
ctmm,"Functions for identifying, fitting, and applying continuous-space, continuous-time stochastic movement models to animal tracking data.
  The package is described in Calabrese et al (2016) <doi:10.1111/2041-210X.12559> and its methods are based on those introduced in
  Fleming & Calabrese et al (2014) <doi:10.1086/675504>,
  Fleming et al (2014) <doi:10.1111/2041-210X.12176>,
  Fleming et al (2015) <doi:10.1890/14-2010.1>,
  Fleming et al (2016) <doi:10.1890/15-1607>,
  Péron & Fleming et al (2016) <doi:10.1186/s40462-016-0084-7>,
  Fleming & Calabrese (2016) <doi:10.1111/2041-210X.12673>,
  Péron et al (2017) <doi:10.1002/ecm.1260>,
  Fleming et al (2017) <doi:10.1016/j.ecoinf.2017.04.008>,
  Fleming et al (2018) <doi:10.1002/eap.1704>,
  and
  Winner & Noonan et al (2018) <doi:10.1111/2041-210X.13027>.",2019-02-11,Christen H. Fleming,"https://github.com/ctmm-initiative/ctmm,
http://biology.umd.edu/movement.html",TRUE,https://github.com/ctmm-initiative/ctmm,30905,7,1554072730
ctrdata,"Provides functions for querying, retrieving and analysing protocol- and results-related information on clinical trials from two public registers, the European Union Clinical Trials Register (EUCTR, <https://www.clinicaltrialsregister.eu/>) and ClinicalTrials.gov (CTGOV, <https://clinicaltrials.gov/>). The information is transformed and then stored in a database (mongo). Functions are provided for accessing and analysing the locally stored information on the clinical trials, as well as for identifying duplicate records. The package is motivated by the need for aggregating and trend-analysing the design, conduct and outcomes across clinical trials.",2019-03-27,Ralf Herold  (<https://orcid.org/0000-0002-8148-6748>),https://github.com/rfhb/ctrdata,TRUE,https://github.com/rfhb/ctrdata,732,6,1553792234
CTRE,"
    Models extremes of 'bursty' time series via
    Continuous Time Random Exceedances (CTRE).
    See <arXiv:1802.05218>, K. Hees, S. Nayak, P.Straka, 2018.",2018-05-07,Peter Straka,https://unsw-math.github.io/CTRE/,TRUE,https://github.com/unsw-math/ctre,2910,0,1525923368
ctsem,"A hierarchical, multivariate, continuous (and discrete) time dynamic modelling
    package for panel and time series data, using stochastic differential
    equations. Contains a faster frequentist set of functions using OpenMx for
    single subject and mixed-effects (random intercepts only) structural
    equation models, or a hierarchical Bayesian implementation using Stan that
    allows for random effects and non-linearity over all model parameters. 
    Allows for modelling of multiple noisy measurements of multiple stochastic 
    processes, time varying input / event covariates, and time invariant 
    covariates used to predict the parameters. Bayesian formulation not available on 
    32 bit Windows systems.",2019-02-03,Charles Driver,https://github.com/cdriveraus/ctsem,TRUE,https://github.com/cdriveraus/ctsem,29207,11,1552656939
cubature,"R wrappers around the cubature C library of Steven
    G. Johnson for adaptive multivariate integration over hypercubes
    and the Cuba C library of Thomas Hahn for deterministic and
    Monte Carlo integration. Scalar and vector interfaces for 
    cubature and Cuba routines are provided; the vector interfaces
    are highly recommended as demonstrated in the package
    vignette.",2018-12-18,Balasubramanian Narasimhan,https://bnaras.github.io/cubature,TRUE,https://github.com/bnaras/cubature,498783,5,1553448252
Cubist,Regression modeling using rules with added instance-based corrections.,2018-05-21,Max Kuhn,https://topepo.github.io/Cubist,TRUE,https://github.com/topepo/cubist,371418,16,1526920330
CUFF,"Utility functions that provides wrapper to descriptive base functions
  like cor, mean and table.  It makes use of the formula interface to pass
  variables to functions.  It also provides operators to concatenate (%+%), to
  repeat (%n%) and manage character vectors for nice display.",2019-01-22,Charles-Édouard Giguère,https://github.com/giguerch/CUFF,TRUE,https://github.com/giguerch/cuff,10456,0,1554169962
cultevo,"Provides tools for measuring the compositionality of signalling systems (in particular the information-theoretic measure due to Spike (2016) <http://hdl.handle.net/1842/25930> and the Mantel test for distance matrix correlation (after Dietz 1983) <doi:10.1093/sysbio/32.1.21>), functions for computing string and meaning distance matrices as well as an implementation of the Page test for monotonicity of ranks (Page 1963) <doi:10.1080/01621459.1963.10500843> with exact p-values up to k = 22.",2018-04-24,Kevin Stadler,https://kevinstadler.github.io/cultevo/,TRUE,https://github.com/kevinstadler/cultevo,2628,6,1524576123
customLayout,"Create complicated drawing areas for multiple elements by combining much simpler layouts. It is an extended version of layout function from the 'graphics' package, but it also works with 'grid' graphics. It also supports arranging elements inside 'PowerPoint' slides created using the 'officer' package.",2018-10-31,Zygmunt Zawadzki,"https://www.customlayout.zstat.pl/,
https://github.com/zzawadz/customLayout",TRUE,https://github.com/zzawadz/customlayout,4840,42,1540906923
customsteps,"Customizable higher-order recipe step functions for 
    the 'recipes' package. These step functions take 'prep' and 'bake' helper 
    functions as inputs and create specifications of customized recipe steps 
    as output.",2018-12-03,Lars Kjeldgaard,https://github.com/smaakage85/customsteps,TRUE,https://github.com/smaakage85/customsteps,1440,1,1544169059
cutpointr,"Estimate cutpoints that optimize a specified metric in binary classification tasks
    and validate performance using bootstrapping. Some methods for more robust cutpoint
    estimation and various plotting functions are included.",2019-03-27,Christian Thiele,https://github.com/thie1e/cutpointr,TRUE,https://github.com/thie1e/cutpointr,5228,39,1553638638
cvar,"Compute expected shortfall (ES) and Value at Risk (VaR) from a
    quantile function, distribution function, random number generator or
    probability density function.  ES is also known as Conditional Value at
    Risk (CVaR). Virtually any continuous distribution can be specified.
    The functions are vectorized over the arguments. The computations are
    done directly from the definitions, see e.g. Acerbi and Tasche (2002)
    <doi:10.1111/1468-0300.00091>. Some support for GARCH models is provided,
    as well.",2019-03-15,Georgi N. Boshnakov,https://github.com/GeoBosh/cvar https://geobosh.github.io/cvar/,TRUE,https://github.com/geobosh/cvar,7179,1,1538810666
cvequality,"Contains functions for testing for significant differences between multiple coefficients of variation. Includes Feltz and Miller's (1996) <DOI:10.1002/(SICI)1097-0258(19960330)15:6%3C647::AID-SIM184%3E3.0.CO;2-P> asymptotic test and Krishnamoorthy and Lee's (2014) <DOI:10.1007/s00180-013-0445-2> modified signed-likelihood ratio test. See the vignette for more, including full details of citations.",2019-01-07,Ben Marwick,https://github.com/benmarwick/cvequality,TRUE,https://github.com/benmarwick/cvequality,8031,3,1546846170
CVglasso,"Estimates a lasso penalized precision matrix via the blockwise coordinate descent (BCD). This package is a simple wrapper around the popular 'glasso' package that extends and enhances its capabilities. These enhancements include built-in cross validation and visualizations.
              See Friedman et al (2008) <doi:10.1093/biostatistics/kxm045> for details regarding the estimation method.",2018-06-04,Matt Galloway,https://github.com/MGallow/CVglasso,TRUE,https://github.com/mgallow/cvglasso,2688,0,1533088935
CVXR,"An object-oriented modeling language for disciplined convex
    programming (DCP). It allows the user to formulate convex optimization problems
    in a natural way following mathematical convention and DCP rules. The system
    analyzes the problem, verifies its convexity, converts it into a canonical form,
    and hands it off to an appropriate solver to obtain the solution.",2019-03-13,Anqi Fu,"https://cvxr.rbind.io, https://anqif.github.io/CVXR",TRUE,https://github.com/anqif/cvxr,13820,77,1553127968
cxhull,"Computes the convex hull in arbitrary dimension, based on the Qhull library (<http://www.qhull.org>). The package provides a complete description of the convex hull: edges, ridges, facets, adjacencies. Triangulation is optional.",2019-03-13,C. B. Barber [cph (author of the Qhull library),https://github.com/stla/cxhull,TRUE,https://github.com/stla/cxhull,3484,2,1552476686
Cyclops,"This model fitting tool incorporates cyclic coordinate descent and
    majorization-minimization approaches to fit a variety of regression models
    found in large-scale observational healthcare data.  Implementations focus
    on computational optimization and fine-scale parallelization to yield
    efficient inference in massive datasets.  Please see:
    Suchard, Simpson, Zorych, Ryan and Madigan (2013) <doi:10.1145/2414416.2414791>.",2019-03-17,Marc A. Suchard,https://github.com/ohdsi/cyclops,TRUE,https://github.com/ohdsi/cyclops,14139,20,1552834916
cyphr,"Encryption wrappers, using low-level support from
    'sodium' and 'openssl'.  'cyphr' tries to smooth over some pain
    points when using encryption within applications and data analysis
    by wrapping around differences in function names and arguments in
    different encryption providing packages.  It also provides
    high-level wrappers for input/output functions for seamlessly
    adding encryption to existing analyses.",2019-03-23,Rich FitzJohn,https://github.com/ropensci/cyphr,TRUE,https://github.com/ropensci/cyphr,588,56,1553519994
cytofan,"An implementation of Fan plots for cytometry data in 'ggplot2'. 
    For reference see Britton, E.; Fisher, P. & J. Whitley (1998) The Inflation Report Projections: Understanding the Fan Chart 
    <https://www.bankofengland.co.uk/quarterly-bulletin/1998/q1/the-inflation-report-projections-understanding-the-fan-chart>).",2018-07-30,Yann Abraham,https://github.com/yannabraham/cytofan,TRUE,https://github.com/yannabraham/cytofan,2340,2,1533031588
cytometree,"Given the hypothesis of a bi-modal distribution of cells for
    each marker, the algorithm constructs a binary tree, the nodes of which are
    subpopulations of cells. At each node, observed cells and markers are modeled
    by both a family of normal distributions and a family of bi-modal normal mixture
    distributions. Splitting is done according to a normalized difference of AIC
    between the two families.",2019-01-12,Chariff Alkhassim,NA,TRUE,https://github.com/sistm/cytometree,6621,4,1547297207
cytominer,"Typical morphological profiling datasets have millions of cells
    and hundreds of features per cell. When working with this data, you must
    clean the data, normalize the features to make them comparable across
    experiments, transform the features, select features based on their
    quality, and aggregate the single-cell data, if needed. 'cytominer' makes
    these steps fast and easy. Methods used in practice in the field are
    discussed in Caicedo (2017) <doi:10.1038/nmeth.4397>. An overview of the
    field is presented in Caicedo (2016) <doi:10.1016/j.copbio.2016.04.003>.",2017-09-17,Shantanu Singh,https://github.com/cytomining/cytominer,TRUE,https://github.com/cytomining/cytominer,3572,21,1530895584
d3r,"Provides a suite of functions to help ease the use of 'd3.js' in R.
              These helpers include 'htmltools::htmlDependency' functions, hierarchy
              builders, and conversion tools for 'partykit', 'igraph,' 'table',
              and 'data.frame' R objects into the 'JSON' that 'd3.js' expects.",2019-01-29,Mike Bostock,https://github.com/timelyportfolio/d3r,TRUE,https://github.com/timelyportfolio/d3r,147120,115,1548729162
d3Tree,"Create and customize interactive collapsible 'D3' trees using the 'D3'
    JavaScript library and the 'htmlwidgets' package. These trees can be used
    directly from the R console, from 'RStudio', in Shiny apps and R Markdown documents.
    When in Shiny the tree layout is observed by the server and can be used as a reactive filter
    of structured data.",2017-06-13,Jonathan Sidi,https://github.com/metrumresearchgroup/d3Tree,TRUE,https://github.com/metrumresearchgroup/d3tree,9071,55,1543319122
daff,"Diff, patch and merge for data frames. Document changes in data
    sets and use them to apply patches. Changes to data can be made visible by using
    render_diff. The V8 package is used to wrap the 'daff.js' JavaScript library
    which is included in the package.",2017-05-10,Paul Fitzpatrick (JavaScript original,http://github.com/edwindj/daff,TRUE,https://github.com/edwindj/daff,16910,95,1549035136
dagitty,"A port of the web-based software 'DAGitty', available at 
    <http://dagitty.net>, for analyzing structural causal models 
    (also known as directed acyclic graphs or DAGs).
    This package computes covariate adjustment sets for estimating causal
    effects, enumerates instrumental variables, derives testable
    implications (d-separation and vanishing tetrads), generates equivalent
    models, and includes a simple facility for data simulation. ",2016-08-26,Johannes Textor,"http://www.dagitty.net, https://github.com/jtextor/dagitty",TRUE,https://github.com/jtextor/dagitty,26112,44,1545404868
DALEX,"Machine Learning (ML) models are widely used and have various applications in classification 
  or regression. Models created with boosting, bagging, stacking or similar techniques are often
  used due to their high performance, but such black-box models usually lack of interpretability.
  DALEX package contains various explainers that help to understand the link between input variables and model output.
  The single_variable() explainer extracts conditional response of a model as a function of a single selected variable.
  It is a wrapper over packages 'pdp' (Greenwell 2017) <doi:10.32614/RJ-2017-016>, 
  'ALEPlot' (Apley 2018) <arXiv:1612.08468>  and 'factorMerger' (Sitko and Biecek 2017) <arXiv:1709.04412>.
  The single_prediction() explainer attributes parts of a model prediction to particular variables used in the model.
  It is a wrapper over 'breakDown' package (Staniak and Biecek 2018) <doi:10.32614/RJ-2018-072>.
  The variable_dropout() explainer calculates variable importance scores based on variable shuffling 
  (Fisher at al. 2018) <arXiv:1801.01489>.
  All these explainers can be plotted with generic plot() function and compared across different models.
  'DALEX' is a part of the 'DrWhy.AI' universe (Biecek 2018) <arXiv:1806.08915>.",2019-03-25,Przemyslaw Biecek  (<https://orcid.org/0000-0001-8423-1823>),https://pbiecek.github.io/DALEX/,TRUE,https://github.com/pbiecek/dalex,19248,360,1554414103
DALEX2,"Machine Learning models are widely used and have various applications in classification or regression tasks. 
    Due to increasing computational power, availability of new data sources and new methods, ML models are more and more complex. 
    Models created with techniques like boosting, bagging of neural networks are true black boxes. 
    It is hard to trace the link between input variables and model outcomes. 
    They are used because of high performance, but lack of interpretability is one of their weakest sides.
    In many applications we need to know, understand or prove how input variables are used in the model and what impact do they have on final model prediction. 
    DALEX2 is a collection of tools that help to understand how complex predictive models are working.
    DALEX2 is a part of DrWhy universe for tools for Explanation, Exploration and Visualisation for Predictive Models.",2018-12-23,Przemyslaw Biecek,https://ModelOriented.github.io/DALEX2/,TRUE,https://github.com/modeloriented/dalex2,2453,1,1546991614
damr,"Loads behavioural data from the widely used Drosophila Activity Monitor System (DAMS, TriKinetics) into the rethomics framework.",2018-05-15,Quentin Geissmann,https://github.com/rethomics/damr,TRUE,https://github.com/rethomics/damr,2693,2,1554501563
DAP,An implementation of Discriminant Analysis via Projections (DAP) method for high-dimensional binary classification in the case of unequal covariance matrices. See Irina Gaynanova and Tianying Wang (2018) <arXiv:1711.04817v2>.,2018-03-05,Tianying Wang and Irina Gaynanova,http://github.com/irinagain/DAP,TRUE,https://github.com/irinagain/dap,3022,0,1523556408
dapr,"An easy-to-use, dependency-free set of functions for iterating over
    elements of various input objects. Functions are wrappers around base
    apply()/lapply()/vapply() functions but designed to have similar
    functionality to the mapping functions in the 'purrr' package
    <https://purrr.tidyverse.org/>. Specifically, function names more explicitly
    communicate the expected class of the output and functions also allow for
    the convenient shortcut of '~ .x' instead of the more verbose
    'function(.x) .x'.",2019-01-20,Michael W. Kearney  (<https://orcid.org/0000-0002-0730-4694>),https://github.com/mkearney/dapr,TRUE,https://github.com/mkearney/dapr,1454,52,1547412463
darksky,"Provides programmatic access to the 'Dark Sky' 'API' 
    <https://darksky.net/dev/docs>, which provides current or historical global 
    weather conditions.",2017-09-20,Bob Rudis,https://github.com/hrbrmstr/darksky,TRUE,https://github.com/hrbrmstr/darksky,9188,69,1527623736
data.table,"Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.",2019-01-13,Matt Dowle,http://r-datatable.com,TRUE,https://github.com/rdatatable/data.table,10443426,1826,1554178395
data.tree,"Create tree structures from hierarchical data, and traverse the
    tree in various orders. Aggregate, cumulate, print, plot, convert to and from
    data.frame and more. Useful for decision trees, machine learning, finance,
    conversion from and to JSON, and many other applications.",2018-09-24,Chris Hammil [ctb (improve getting),http://github.com/gluc/data.tree,TRUE,https://github.com/gluc/data.tree,170021,129,1537799615
data.world,"High-level tools for working with 'data.world' data sets. 'data.world' is a platform 
    where you can find interesting data, store and showcase your own data and data projects, 
    and find and collaborate with other members. In addition to exploring, querying and 
    charting data on the data.world site, you can access data via 'API' endpoints and 
    integrations. Use this package to access, query and explore data sets, and to 
    publish your insights. Visit <https://data.world>, for additional information.",2018-04-04,Rafael Pereira,https://github.com/datadotworld/data.world-r,TRUE,https://github.com/datadotworld/data.world-r,9394,45,1545322798
DatabaseConnector,"An R 'DataBase Interface' ('DBI') compatible interface to various database platforms ('PostgreSQL', 'Oracle', 'Microsoft SQL Server', 
    'Amazon Redshift', 'Microsoft Parallel Database Warehouse', 'IBM Netezza', 'Apache Impala', 'Google BigQuery', and 'SQLite'). Also includes support for
    fetching data as 'ffdf' objects. Uses 'Java Database Connectivity' ('JDBC') to connect to databases (except SQLite).",2019-02-21,Martijn Schuemie,"https://ohdsi.github.io/DatabaseConnector,
https://github.com/OHDSI/DatabaseConnector",TRUE,https://github.com/ohdsi/databaseconnector,8829,18,1554026044
DatabaseConnectorJars,Provides external JAR dependencies for the 'DatabaseConnector' package.,2018-05-14,Martijn Schuemie,https://github.com/OHDSI/DatabaseConnectorJars,TRUE,https://github.com/ohdsi/databaseconnectorjars,5718,0,1554475906
DatabionicSwarm,"Algorithms implementing populations of agents that interact with one another and sense their environment may exhibit emergent behavior such as self-organization and swarm intelligence. Here, a swarm system called databionic swarm (DBS) is introduced. DBS is able to adapt itself to structures of high-dimensional data such as natural clusters characterized by distance and/or density based structures in the data space. The first module is the parameter-free projection method called Pswarm (Pswarm()), which exploits the concepts of self-organization and emergence, game theory, swarm intelligence and symmetry considerations. The second module is the parameter-free high-dimensional data visualization technique, which generates projected points on the topographic map with hypsometric tints defined by the generalized U-matrix (GeneratePswarmVisualization()). The third module is the clustering method itself with non-critical parameters (DBSclustering()). Clustering can be verified by the visualization and vice versa. The term DBS refers to the method as a whole. It enables even a non-professional in the field of data mining to apply its algorithms for visualization and/or clustering to data sets with completely different structures drawn from diverse research fields. The package is based on the book of Thrun, M.C.: ""Projection Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <DOI:10.1007/978-3-658-20540-9>. A comparison to 26 common clustering algorithms on 15 datasets is presented on the website.",2019-01-27,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/databionicswarm,9007,0,1551597587
dataCompareR,"Easy comparison of two tabular data
    objects in R. Specifically designed to show differences between two sets of
    data in a useful way that should make it easier to understand the differences,
    and if necessary, help you work out how to remedy them. Aims
    to offer a more useful output than all.equal() when your two data sets do not
    match, but isn't intended to replace all.equal() as a way to test for equality.",2018-09-19,Rob Noble-Eddy,https://github.com/capitalone/dataCompareR,TRUE,https://github.com/capitalone/datacomparer,7792,44,1536335484
datadigest,"An R interface for Rho's 'web-codebook' 'JavaScript' charting library, which provides a simple interactive framework for exploring data. 'datadigest' includes two key functions (codebook() and explorer()) that deliver a concise summary of every variable in a data frame, along with interactive features such as real-time filters, grouping, and highlighting. Each function has an associated 'RStudio' addin/'Shiny' app for quick and convenient exploration of one or more data frames.",2018-09-03,Becca Krouse,https://github.com/RhoInc/datadigest,TRUE,https://github.com/rhoinc/datadigest,3957,38,1548084238
datadogr,Query for metrics from 'Datadog' (<https://www.datadoghq.com/>) via its API.,2018-05-17,Hiroaki Yutani,https://yutannihilation.github.io/K9,TRUE,https://github.com/yutannihilation/k9,5596,3,1526555369
DataExplorer,"Automated data exploration process for analytic tasks and predictive modeling, so
    that users could focus on understanding data and extracting insights. The package scans and
    analyzes each variable, and visualizes them with typical graphical techniques. Common
    data processing methods are also available to treat and format data.",2019-03-17,Boxuan Cui,http://boxuancui.github.io/DataExplorer/,TRUE,https://github.com/boxuancui/dataexplorer,59957,213,1553693388
datafsm,"Automatic generation of finite state machine models of dynamic 
    decision-making that both have strong predictive power and are 
    interpretable in human terms. We use an efficient model representation and 
    a genetic algorithm-based estimation process to generate simple 
    deterministic approximations that explain most of the structure of complex 
    stochastic processes. We have applied the software to empirical data, and 
    demonstrated it's ability to recover known data-generating processes by 
    simulating data with agent-based models and correctly deriving the 
    underlying decision models for multiple agent models and degrees of
    stochasticity.",2018-08-08,Gilligan Jonathan M.,https://github.com/jonathan-g/datafsm,TRUE,https://github.com/jonathan-g/datafsm,10165,8,1546032762
dataMaid,"Data screening is an important first step of any statistical
    analysis. dataMaid auto generates a customizable data report with a thorough
    summary of the checks and the results that a human can use to identify possible
    errors. It provides an extendable suite of test for common potential
    errors in a dataset. ",2018-10-03,Claus Thorn Ekstrøm,https://github.com/ekstroem/dataMaid,TRUE,https://github.com/ekstroem/datamaid,17957,63,1551965901
datamaps,"Easily create interactive choropleth maps then add bubbles and arcs by coordinates or region name. 
    These maps can be used directly from the console, from 'RStudio', in 'Shiny' apps and 'R Markdown' documents. 'Shiny' 
    proxies allow to interactively add arcs and bubbles, change choropleth values, or change labels.",2018-05-14,John Coene,http://datamaps.john-coene.com,TRUE,https://github.com/johncoene/datamaps,4095,13,1526328677
dataone,"Provides read and write access to data and metadata from
    the DataONE network <https://www.dataone.org> of data repositories.  
    Each DataONE repository implements a consistent repository application 
    programming interface. Users call methods in R to access these remote 
    repository functions, such as methods to query the metadata catalog, get 
    access to metadata for particular data packages, and read the data objects 
    from the data repository. Users can also insert and update data objects on 
    repositories that support these methods.",2019-01-29,Matthew B. Jones,https://github.com/DataONEorg/rdataone,TRUE,https://github.com/dataoneorg/rdataone,17388,20,1548794742
datapack,"Provides a flexible container to transport and
    manipulate complex sets of data. These data may consist of multiple data files and
    associated meta data and ancillary files. Individual data objects have
    associated system level meta data, and data files are linked together using
    the OAI-ORE standard resource map which describes the relationships between the files. 
    The OAI-ORE standard is described at <https://www.openarchives.org/ore>. Data packages 
    can be serialized and transported as structured files that have been created following 
    the BagIt specification. The BagIt specification is described at 
    <https://tools.ietf.org/html/draft-kunze-bagit-08>.",2017-08-29,Matthew B. Jones,NA,TRUE,https://github.com/ropensci/datapack,15085,32,1533858733
datapackage.r,"Work with 'Frictionless Data Packages' (<https://frictionlessdata.io/specs/data-package/>). Allows to load and validate any descriptor for a data package profile, create and modify descriptors and provides expose methods for reading and streaming data in the package. When a descriptor is a 'Tabular Data Package', it uses the 'Table Schema' package (<https://CRAN.R-project.org/package=tableschema.r>) and exposes its functionality, for each resource object in the resources field.",2019-03-08,Kleanthis Koupidis,https://github.com/frictionlessdata/datapackage-r,TRUE,https://github.com/frictionlessdata/datapackage-r,342,14,1552070756
DataPackageR,"A framework to help construct R data packages in a 
  reproducible manner. Potentially time consuming processing of 
  raw data sets into analysis ready data sets is done in a reproducible 
  manner and decoupled from the usual R CMD build process so that
  data sets can be processed into R objects in the data package and 
  the data package can then be shared, built, and installed by others
  without the need to repeat computationally costly data processing.
  The package maintains data provenance by turning the data processing
  scripts into package vignettes, as well as enforcing documentation 
  and version checking of included data objects. Data packages can be
  version controlled in github, and used to share data for manuscripts,
  collaboration and general reproducibility.",2019-03-30,Greg Finak,https://github.com/ropensci/DataPackageR,TRUE,https://github.com/ropensci/datapackager,5854,90,1554211278
datapasta,RStudio addins and R functions that make copy-pasting vectors and tables to text painless.,2018-01-24,Miles McBain,https://github.com/milesmcbain/datapasta,TRUE,https://github.com/milesmcbain/datapasta,20460,471,1551585991
dataPreparation,Do most of the painful data preparation for a data science project with a minimum amount of code; Take advantages of data.table efficiency and use some algorithmic trick in order to perform data preparation in a time and RAM efficient way.,2019-03-25,Emmanuel-Lin Toulemonde,NA,TRUE,https://github.com/eltoulemonde/datapreparation,19177,18,1553792194
dataRetrieval,"Collection of functions to help retrieve U.S. Geological Survey
    (USGS) and U.S. Environmental Protection Agency (EPA) water quality and
    hydrology data from web services. USGS web services are discovered from 
    National Water Information System (NWIS) <https://waterservices.usgs.gov/> and <https://waterdata.usgs.gov/nwis>. 
    Both EPA and USGS water quality data are obtained from the Water Quality Portal <https://www.waterqualitydata.us/>.",2019-03-25,Laura DeCicco  (<https://orcid.org/0000-0002-3915-9487>),https://pubs.usgs.gov/tm/04/a10/,TRUE,https://github.com/usgs-r/dataretrieval,50529,113,1554472654
datasauRus,"The Datasaurus Dozen is a set of datasets with the same summary statistics. They 
             retain the same summary statistics despite having radically different distributions.
             The datasets represent a larger and quirkier object lesson that is typically taught
             via Anscombe's Quartet (available in the 'datasets' package). Anscombe's Quartet
             contains four very different distributions with the same summary statistics and as 
             such highlights the value of visualisation in understanding data, over and above
             summary statistics. As well as being an engaging variant on the Quartet, the data
             is generated in a novel way. The simulated annealing process used to derive datasets 
             from the original Datasaurus is detailed in ""Same Stats, Different Graphs: Generating 
             Datasets with Varied Appearance and Identical Statistics through Simulated Annealing"" 
             <doi:10.1145/3025453.3025912>.",2018-09-20,Steph Locke,"https://github.com/lockedata/datasauRus,
https://itsalocke.com/datasaurus/",TRUE,https://github.com/lockedata/datasaurus,12373,134,1548250724
DataSpaceR,"Provides a convenient API interface to access immunological data
    within 'the CAVD DataSpace'(<https://dataspace.cavd.org>), a data sharing 
    and discovery tool that facilitates exploration of HIV immunological data 
    from pre-clinical and clinical HIV vaccine studies.",2019-04-05,Ju Yeong Kim,https://github.com/ropensci/DataSpaceR,TRUE,https://github.com/ropensci/dataspacer,0,6,1554353408
datastructures,"Implementation of advanced data structures such as hashmaps,
    heaps, or queues. Advanced data structures are essential
    in many computer science and statistics problems, for example graph
    algorithms or string analysis. The package uses 'Boost' and 'STL' data
    types and extends these to R with 'Rcpp' modules.",2018-12-19,Simon Dirmeier,https://github.com/dirmeier/datastructures,TRUE,https://github.com/dirmeier/datastructures,8350,53,1535912267
DataVisualizations,"The flagship idea of 'DataVisualizations' is the mirrored density plot (MD-plot) which is a PDE-optimized violin plot for either classified or non-classified multivariate data. The MD-plot is an alternative to the box-and-whisker diagram (box plot) and bean plot. Furthermore, a collection of various visualization methods for univariate data is provided. In the case of exploratory data analysis, 'DataVisualizations' makes it possible to inspect the distribution of each feature of a dataset visually through a combination of four methods. One of these methods is the Pareto density estimation (PDE) of the probability density function (pdf). Additionally, visualizations of the distribution of distances using PDE, the scatter-density plot using PDE for two variables as well as the Shepard density plot and the Bland-Altman plot are presented here. Pertaining to classified high-dimensional data, a number of visualizations are described, such as f.ex. the heat map and silhouette plot. A political map of the world or Germany can be visualized with the additional information defined by a classification of countries or regions. By extending the political map further, an uncomplicated function for a Choropleth map can be used which is useful for measurements across a geographic area. For categorical features, the Pie charts, slope charts and fan plots, improved by the ABC analysis, become usable. More detailed explanations are found in the book by Thrun, M.C.: ""Projection-Based Clustering through Self-Organization and Swarm Intelligence"" (2018) <doi:10.1007/978-3-658-20540-9>.",2019-03-08,Michael Thrun,http://www.deepbionics.org,TRUE,https://github.com/mthrun/datavisualizations,7411,3,1553243418
datoramar,"A thin wrapper around the 'Datorama' API.
    Ideal for analyzing marketing data from <https://datorama.com>.",2017-12-20,Kade Killary,https://github.com/beigebrucewayne/datoramar,TRUE,https://github.com/beigebrucewayne/datoramar,3162,4,1552031284
datr,"Interface with the 'Dat' p2p network protocol <https://datproject.org>. Clone archives from the network, share your own files, and install packages from the network.",2018-03-26,Chris Hartgerink,https://github.com/libscie/datr,TRUE,https://github.com/libscie/datr,2758,47,1524648507
daymetr,"Programmatic interface to the 'Daymet' web services
    (<http://daymet.ornl.gov>). Allows for easy downloads of
    'Daymet' climate data directly to your R workspace or your computer.
    Routines for both single pixel data downloads and
    gridded (netCDF) data are provided.",2019-02-07,Hufkens Koen,https://github.com/khufkens/daymetr,TRUE,https://github.com/khufkens/daymetr,5586,5,1553877181
dbarts,"Fits Bayesian additive regression trees (BART; Chipman, George, and McCulloch (2010) <doi:10.1214/09-AOAS285>) while allowing the updating of predictors or response so that BART can be incorporated as a conditional model in a Gibbs/MH sampler. Also serves as a drop-in replacement for package 'BayesTree'.",2018-12-18,Vincent Dorie,https://github.com/vdorie/dbarts,TRUE,https://github.com/vdorie/dbarts,23938,20,1554501979
DBHC,"Provides an implementation of a mixture of hidden Markov models 
    (HMMs) for discrete sequence data in the Discrete Bayesian HMM Clustering 
    (DBHC) algorithm. The DBHC algorithm is an HMM Clustering 
    algorithm that finds a mixture of discrete-output HMMs while using 
    heuristics based on Bayesian Information Criterion (BIC) to search for the 
    optimal number of HMM states and the optimal number of clusters. ",2018-04-13,Gabriel Budel,https://github.com/gabybudel/DBHC,TRUE,https://github.com/gabybudel/dbhc,2968,1,1523609699
dbhydroR,"Client for programmatic access to the South Florida Water
  Management District's 'DBHYDRO' database at 
  <https://www.sfwmd.gov/science-data/dbhydro>, with functions
  for accessing hydrologic and water quality data. ",2019-02-15,Joseph Stachelek  (<https://orcid.org/0000-0002-5924-2464>),https://github.com/ropensci/dbhydroR,TRUE,https://github.com/ropensci/dbhydror,13867,7,1551223692
DBI,"A database interface definition for communication
    between R and relational database management systems.  All
    classes in this package are virtual and need to be extended by
    the various R/DBMS implementations.",2018-05-02,Kirill Müller  (<https://orcid.org/0000-0002-1416-3412>),http://r-dbi.github.io/DBI,TRUE,https://github.com/r-dbi/dbi,8578230,154,1553429405
DBItest,"A helper that tests 'DBI' back ends for conformity
    to the interface.",2018-01-25,Kirill Müller,NA,TRUE,https://github.com/rstats-db/dbitest,72350,14,1552856538
dbmss,"Simple computation of spatial statistic functions of distance to characterize the spatial structures of mapped objects, following Marcon, Traissac, Puech, and Lang (2015) <doi:10.18637/jss.v067.c03>.
             Includes classical functions (Ripley's K and others) and more recent ones used by spatial economists (Duranton and Overman's Kd, Marcon and Puech's M). 
             Relies on 'spatstat' for some core calculation.",2019-03-25,Eric Marcon  (<https://orcid.org/0000-0002-5249-321X>),https://github.com/EricMarcon/dbmss,TRUE,https://github.com/ericmarcon/dbmss,34648,0,1553601973
dbparser,"This tool is for parsing the 'DrugBank' XML database <http://drugbank.ca/>. The parsed 
    data are then returned in a proper 'R' dataframe with the ability to save 
    them in a given database.",2018-12-17,Mohammed Ali,https://github.com/Dainanahan/dbparser,TRUE,https://github.com/dainanahan/dbparser,1221,3,1554129908
dbplot,"Leverages 'dplyr' to process the calculations of a plot inside a database. 
    This package provides helper functions that abstract the work at three levels:
    outputs a 'ggplot', outputs the calculations, outputs the formula
    needed to calculate bins.",2019-03-03,Edgar Ruiz,https://github.com/edgararuiz/dbplot,TRUE,https://github.com/edgararuiz/dbplot,11497,106,1551570375
dbplyr,"A 'dplyr' back end for databases that allows you to
    work with remote database tables as if they are in-memory data frames.
    Basic features works with any database that has a 'DBI' back end; more
    advanced features require 'SQL' translation to be provided by the
    package author.",2019-01-09,Hadley Wickham,https://github.com/tidyverse/dbplyr,TRUE,https://github.com/tidyverse/dbplyr,2913183,169,1552764558
dbscan,"A fast reimplementation of several density-based algorithms of
    the DBSCAN family for spatial data. Includes the DBSCAN (density-based spatial
    clustering of applications with noise) and OPTICS (ordering points to identify
    the clustering structure) clustering algorithms HDBSCAN (hierarchical DBSCAN) and the LOF (local outlier
    factor) algorithm. The implementations use the kd-tree data structure (from
    library ANN) for faster k-nearest neighbor search. An R interface to fast kNN
    and fixed-radius NN search is also provided.",2018-11-13,Michael Hahsler,NA,TRUE,https://github.com/mhahsler/dbscan,159215,85,1548344819
dbx,"Provides select, insert, update, upsert, and delete database operations. Supports 'PostgreSQL', 'MySQL', 'SQLite', and more, and plays nicely with the 'DBI' package.",2019-01-03,Andrew Kane,https://github.com/ankane/dbx,TRUE,https://github.com/ankane/dbx,6551,104,1552078108
dclone,"Low level functions for implementing
    maximum likelihood estimating procedures for
    complex models using data cloning and Bayesian
    Markov chain Monte Carlo methods
    as described in Solymos 2010 (R Journal 2(2):29--37).
    Sequential and parallel MCMC support
    for 'JAGS', 'WinBUGS', 'OpenBUGS', and 'Stan'.",2019-03-22,Peter Solymos,"https://groups.google.com/forum/#!forum/dclone-users,
http://datacloning.org",TRUE,https://github.com/datacloning/dclone,40086,1,1553228117
dcmodify,"Data cleaning scripts typically contain a lot of 'if this change that'
    type of statements. Such statements are typically condensed expert knowledge.
    With this package, such 'data modifying rules' are taken out of the code and
    become in stead parameters to the work flow. This allows one to maintain, document,
    and reason about data modification rules as separate entities.",2018-07-30,Mark van der Loo,https://github.com/data-cleaning/dcmodify,TRUE,https://github.com/data-cleaning/dcmodify,4416,3,1532961646
dcurver,"A Davidian curve defines a seminonparametric density, whose shape and flexibility can be tuned by
  easy to estimate parameters. Since a special case of a Davidian curve is the standard normal density,
  Davidian curves can be used for relaxing normality assumption in statistical applications (Zhang & Davidian, 2001)
  <doi:10.1111/j.0006-341X.2001.00795.x>. This package provides the density function, the gradient of
  the loglikelihood and a random generator for Davidian curves.",2018-04-23,Oğuzhan Öğreden,https://github.com/oguzhanogreden/dcurver,TRUE,https://github.com/oguzhanogreden/dcurver,35036,0,1524464066
DDoutlier,"Outlier detection in multidimensional domains. Implementation of notable distance and density-based outlier algorithms. Allows users to identify local outliers by comparing observations to their nearest neighbors, reverse nearest neighbors, shared neighbors or natural neighbors. For distance-based approaches, see Knorr, M., & Ng, R. T. (1997) <doi:10.1145/782010.782021>, Angiulli, F., & Pizzuti, C. (2002) <doi:10.1007/3-540-45681-3_2>, Hautamaki, V., & Ismo, K. (2004) <doi:10.1109/ICPR.2004.1334558> and Zhang, K., Hutter, M. & Jin, H. (2009) <doi:10.1007/978-3-642-01307-2_84>. For density-based approaches, see Tang, J., Chen, Z., Fu, A. W. C., & Cheung, D. W. (2002) <doi:10.1007/3-540-47887-6_53>, Jin, W., Tung, A. K. H., Han, J., & Wang, W. (2006) <doi:10.1007/11731139_68>, Schubert, E., Zimek, A. & Kriegel, H-P. (2014) <doi:10.1137/1.9781611973440.63>, Latecki, L., Lazarevic, A. & Prokrajac, D. (2007) <doi:10.1007/978-3-540-73499-4_6>, Papadimitriou, S., Gibbons, P. B., & Faloutsos, C. (2003) <doi:10.1109/ICDE.2003.1260802>, Breunig, M. M., Kriegel, H.-P., Ng, R. T., & Sander, J. (2000) <doi:10.1145/342009.335388>, Kriegel, H.-P., Kröger, P., Schubert, E., & Zimek, A. (2009) <doi:10.1145/1645953.1646195>, Zhu, Q., Feng, Ji. & Huang, J. (2016) <doi:10.1016/j.patrec.2016.05.007>, Huang, J., Zhu, Q., Yang, L. & Feng, J. (2015) <doi:10.1016/j.knosys.2015.10.014>, Tang, B. & Haibo, He. (2017) <doi:10.1016/j.neucom.2017.02.039> and Gao, J., Hu, W., Zhang, X. & Wu, Ou. (2011) <doi:10.1007/978-3-642-20847-8_23>.",2018-05-30,Jacob H. Madsen <jacob.madsen1@mail.com>,https://github.com/jhmadsen/DDoutlier,TRUE,https://github.com/jhmadsen/ddoutlier,7790,6,1527629033
ddpcr,"An interface to explore, analyze, and visualize droplet digital PCR
    (ddPCR) data in R. This is the first non-proprietary software for analyzing
    two-channel ddPCR data. An interactive tool was also created and is available
    online to facilitate this analysis for anyone who is not comfortable with
    using R.",2019-01-03,Dean Attali,https://github.com/daattali/ddpcr,TRUE,https://github.com/daattali/ddpcr,12334,29,1546630150
deBInfer,"A Bayesian framework for parameter inference in differential equations.
    This approach offers a rigorous methodology for parameter inference as well as
    modeling the link between unobservable model states and parameters, and
    observable quantities. Provides templates for the DE model, the
    observation model and data likelihood, and the model parameters and their prior
    distributions. A Markov chain Monte Carlo (MCMC) procedure processes these inputs
    to estimate the posterior distributions of the parameters and any derived
    quantities, including the model trajectories. Further functionality is provided
    to facilitate MCMC diagnostics and the visualisation of the posterior distributions
    of model parameters and trajectories.",2018-04-18,"Philipp H Boersch-Supan 
    (<https://orcid.org/0000-0001-6723-6833>)",https://github.com/pboesu/debinfer,TRUE,https://github.com/pboesu/debinfer,7538,3,1540390091
debugr,"Tool to print out the value of R objects/expressions while running
  an R script. Outputs can be made dependent on user-defined conditions/criteria. 
  Debug messages only appear when a global option for debugging is set. 
  This way, 'debugr' code can even remain in the debugged code for later use 
  without any negative effects during normal runtime.",2018-07-30,Joachim Zuckarelli,https://github.com/jsugarelli/debugr/,TRUE,https://github.com/jsugarelli/debugr,1961,11,1532548132
decido,"Provides constrained triangulation of polygons. Ear cutting (or 
 ear clipping) applies constrained triangulation by successively 'cutting'
 triangles from a polygon defined by path/s. Holes are supported by introducing
 a bridge segment between polygon paths. This package wraps the 'header-only' 
 library 'earcut.hpp' <https://github.com/mapbox/earcut.hpp.git> which includes
 a reference to the method used by Held, M. (2001) <doi:10.1007/s00453-001-0028-4>. ",2018-08-21,Michael Sumner,https://hypertidy.github.io/decido,TRUE,https://github.com/hypertidy/decido,3466,7,1546984403
DecisionAnalysis,"Aides in the multi objective decision analysis process by simplifying 
  the creation of value hierarchy tree plots, calculating and plotting single and 
  multi attribute value function scores, and conducting sensitivity analysis. Linear, 
  exponential, and categorical single attribute value functions are supported. For 
  details see Parnell (2013, ISBN:978-1-118-17313-8) Kirkwood (1997, ISBN:0-534-51692-0).",2018-07-30,Josh Deehr,NA,TRUE,https://github.com/afit-r/decisionanalysis,2513,4,1532959013
deckgl,"Makes 'deck.gl' <https://deck.gl/>, a WebGL-powered open-source JavaScript framework
  for visual exploratory data analysis of large datasets, available within R via the 'htmlwidgets' package.
  Furthermore, it supports basemaps from 'mapbox' <https://www.mapbox.com/> via
  'mapbox-gl-js' <https://github.com/mapbox/mapbox-gl-js>.",2018-11-19,Stefan Kuethe,"https://github.com/crazycapivara/deckgl/,
https://crazycapivara.github.io/deckgl/",TRUE,https://github.com/crazycapivara/deckgl,1415,18,1543684939
DeclareDesign,"Researchers can characterize and learn about the properties of
    research designs before implementation using `DeclareDesign`. Ex ante
    declaration and diagnosis of designs can help researchers clarify the 
    strengths and limitations of their designs and to improve their 
    properties, and can help readers evaluate a research strategy prior
    to implementation and without access to results. It can also make it
    easier for designs to be shared, replicated, and critiqued.",2019-01-26,Graeme Blair  (<https://orcid.org/0000-0001-9164-2102>),"https://declaredesign.org,
https://github.com/DeclareDesign/DeclareDesign",TRUE,https://github.com/declaredesign/declaredesign,5354,58,1551719624
deconstructSigs,"Takes sample information in the form of the fraction of mutations
    in each of 96 trinucleotide contexts and identifies the weighted combination
    of published signatures that, when summed, most closely reconstructs the
    mutational profile.",2016-07-29,Rachel Rosenthal,https://github.com/raerose01/deconstructSigs,TRUE,https://github.com/raerose01/deconstructsigs,12434,64,1532362521
deconvolveR,"Empirical Bayes methods for learning prior distributions from data.
    An unknown prior distribution (g) has yielded (unobservable) parameters, each of
    which produces a data point from a parametric exponential family (f). The goal
    is to estimate the unknown prior (""g-modeling"") by deconvolution and Empirical
    Bayes methods.",2019-02-08,Balasubramanian Narasimhan,https://bnaras.github.io/deconvolveR,TRUE,https://github.com/bnaras/deconvolver,5795,3,1549663927
deepgmm,"Deep Gaussian mixture models as proposed by Viroli and McLachlan (2019) 
    <doi:10.1007/s11222-017-9793-z> provide a generalization of classical Gaussian mixtures 
    to multiple layers. Each layer contains a set of latent variables that follow 
    a mixture of Gaussian distributions. To avoid overparameterized solutions, dimension 
    reduction is applied at each layer by way of factor models.",2019-02-22,Cinzia Viroli,https://github.com/suren-rathnayake/deepgmm,TRUE,https://github.com/suren-rathnayake/deepgmm,444,0,1551657781
deeplr,"A wrapper for the 'DeepL' API, a web service for translating texts between different languages. 
    Access to the official API (see <https://www.deepl.com/translator>) is subject to a monthly fee.
    No authentication key is required for the undocumented DeepL JSON-RPC API. The package provides functions
    for both types of API calls.",2018-05-28,David Zumbach,<https://www.deepl.com/translator,TRUE,https://github.com/zumbov2/deeplr,4607,1,1544218428
deflateBR,Simple functions to deflate nominal Brazilian Reais using several popular price indexes downloaded from the Brazilian Institute for Applied Economic Research.,2018-09-28,Fernando Meireles,https://github.com/meirelesff/deflatebr/,TRUE,https://github.com/meirelesff/deflatebr,1931,7,1537191617
deisotoper,"Provides a low-level interface for a deisotoper container 
  implemented in the 'Java' programming language and means of S3 helper 
  functions for plotting and debugging isotopes of mass spectrometric data. 
  The deisotoper algorithm detects and aggregates peaks which belong to the 
  same isotopic cluster of a given mass spectrum. ",2017-12-19,Christian Panse  (0000-0003-1975-3064),https://github.com/protViz/deisotoper/,TRUE,https://github.com/protviz/deisotoper,4619,0,1524461148
DemoDecomp,"Two general demographic decomposition methods are offered: Pseudo-continuous decomposition proposed by Horiuchi, Wilmoth, and Pletcher (2008) <doi:10.1353/dem.0.0033> and stepwise replacement decomposition proposed by Andreev, Shkolnikov and Begun (2002) <doi:10.4054/DemRes.2002.7.14>.",2018-08-14,Tim Riffe,NA,TRUE,https://github.com/timriffe/demodecomp,2276,0,1549636878
demography,"Functions for demographic analysis including lifetable
        calculations; Lee-Carter modelling; functional data analysis of
        mortality rates, fertility rates, net migration numbers; and
        stochastic population forecasting.",2019-01-18,Rob J Hyndman with contributions from Heather Booth,https://github.com/robjhyndman/demography,TRUE,https://github.com/robjhyndman/demography,49344,25,1551817308
dendextend,"Offers a set of functions for extending
    'dendrogram' objects in R, letting you visualize and compare trees of
    'hierarchical clusterings'. You can (1) Adjust a tree's graphical parameters
    - the color, size, type, etc of its branches, nodes and labels. (2)
    Visually and statistically compare different 'dendrograms' to one another.",2019-03-15,Tal Galili,"https://github.com/talgalili/dendextend/,
https://cran.r-project.org/package=dendextend,
https://www.r-statistics.com/tag/dendextend/,
https://academic.oup.com/bioinformatics/article/31/22/3718/240978/dendextend-an-R-package-for-visualizing-adjusting",TRUE,https://github.com/talgalili/dendextend,1204711,99,1552935640
dendroTools,"Provides novel dendroclimatological methods, primarily used by the
    Tree-ring research community. There are two core functions. The first one is 
    daily_response(), which finds the optimal sequence of days that are related 
    to one or more tree-ring proxy records. The second one is compare_methods(), 
    which effectively compares several linear and nonlinear regression algorithms.  ",2019-03-28,Jernej Jevsenak,http://github.com/jernejjevsenak/dendroTools,TRUE,https://github.com/jernejjevsenak/dendrotools,11352,2,1553779499
DEploid,"Traditional phasing programs are limited to diploid organisms.
 Our method modifies Li and Stephens algorithm with Markov chain Monte Carlo
 (MCMC) approaches, and builds a generic framework that allows haplotype searches
 in a multiple infection setting. This package is primarily developed as part of
 the Pf3k project, which is a global collaboration using the latest
 sequencing technologies to provide a high-resolution view of natural variation
 in the malaria parasite Plasmodium falciparum. Parasite DNA are extracted from
 patient blood sample, which often contains more than one parasite strain, with
 unknown proportions. This package is used for deconvoluting mixed haplotypes,
 and reporting the mixture proportions from each sample.",2018-10-23,Joe Zhu,https://github.com/mcveanlab/DEploid-r,TRUE,https://github.com/mcveanlab/deploid-r,11257,0,1540065272
dequer,"Queues, stacks, and 'deques' are list-like, abstract data types. 
    These are meant to be very cheap to ""grow"", or insert new objects into.
    A typical use case involves storing data in a list in a streaming fashion,
    when you do not necessarily know how may elements need to be stored.
    Unlike R's lists, the new data structures provided here are not
    necessarily stored contiguously, making insertions and deletions at the
    front/end of the structure much faster.  The underlying implementation
    is new and uses a head/tail doubly linked list; thus, we do not rely on R's
    environments or hashing.  To avoid unnecessary data copying, most operations
    on these data structures are performed via side-effects.",2017-11-16,Drew Schmidt,https://github.com/wrathematics/dequer,TRUE,https://github.com/wrathematics/dequer,9892,19,1542059678
Deriv,"R-based solution for symbolic differentiation. It admits
    user-defined function as well as function substitution
    in arguments of functions to be differentiated. Some symbolic
    simplification is part of the work.",2018-06-11,Serguei Sokol,NA,TRUE,https://github.com/sgsokol/deriv,126444,15,1528729432
DescribeDisplay,"Produce publication quality graphics from output of 'GGobi'
    describe display plugin.",2018-09-23,Di Cook,https://github.com/ggobi/DescribeDisplay,TRUE,https://github.com/ggobi/describedisplay,20910,0,1537737963
DescriptiveStats.OBeu,"Estimate and return the needed parameters for visualizations designed for 'OpenBudgets.eu' <http://openbudgets.eu/> datasets. Calculate descriptive statistical measures in budget data of municipalities across Europe, according to the 'OpenBudgets.eu' data model. There are functions for measuring central tendency and dispersion of amount variables along with their distributions and correlations and the frequencies of categorical variables for a given dataset. Also, can be used generally to extract visualization parameters, convert them to 'JSON' format and use them as input in a different graphical interface. ",2019-01-20,Kleanthis Koupidis,https://github.com/okgreece/DescriptiveStats.OBeu,TRUE,https://github.com/okgreece/descriptivestats.obeu,6976,1,1551877195
descriptr,"Generate descriptive statistics such as measures of location,
    dispersion, frequency tables, cross tables, group summaries and multiple
    one/two way tables. ",2019-01-22,Aravind Hebbali  (<https://orcid.org/0000-0001-9220-9669>),"https://descriptr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/descriptr",TRUE,https://github.com/rsquaredacademy/descriptr,15073,25,1551096751
desctable,"Easily create descriptive and comparative tables.
    It makes use and integrates directly with the tidyverse family of packages, and pipes.
    Tables are produced as data frames/lists of data frames for easy manipulation after creation,
    and ready to be saved as csv, or piped to DT::datatable() or pander::pander() to integrate into reports.",2019-04-01,Maxime Wack,https://github.com/maximewack/desctable,TRUE,https://github.com/maximewack/desctable,9447,39,1554136762
DesignLibrary,"
    A simple interface to build designs using the package 'DeclareDesign'. 
    In one line of code, users can specify the parameters of individual 
    designs and diagnose their properties. The designers can also be used 
    to compare performance of a given design across a range of combinations 
    of parameters, such as effect size, sample size, and assignment probabilities.",2018-11-12,Jasper Cooper,"https://declaredesign.org/library/,
https://github.com/DeclareDesign/DesignLibrary",TRUE,https://github.com/declaredesign/designlibrary,6426,20,1553105849
desplot,"A function for plotting maps of agricultural field experiments that
    are laid out in grids.",2019-04-03,Kevin Wright  (<https://orcid.org/0000-0002-0617-8673>),https://github.com/kwstat/desplot,TRUE,https://github.com/kwstat/desplot,14374,9,1554299364
detect,"Models for analyzing site occupancy and count data models
  with detection error, including single-visit based models,
  conditional distance sampling and time-removal models.
  Package development was supported by the
  Alberta Biodiversity Monitoring Institute (www.abmi.ca)
  and the Boreal Avian Modelling Project (borealbirds.ca).",2018-08-30,Peter Solymos,https://github.com/psolymos/detect,TRUE,https://github.com/psolymos/detect,19179,2,1539127600
detzrcr,"Compare detrital zircon suites by uploading univariate,
      U-Pb age, or bivariate, U-Pb age and Lu-Hf data, in a 'shiny'-based
      user-interface. Outputs publication quality figures using 'ggplot2', and
      tables of statistics currently in use in the detrital zircon geochronology
      community.",2019-03-27,Magnus Kristoffersen,https://github.com/magnuskristoffersen/detzrcr,TRUE,https://github.com/magnuskristoffersen/detzrcr,14011,3,1553680485
devRate,"A set of functions to quantify the relationship between development
    rate and temperature and to build phenological models. The package comprises 
    a set of models and estimated parameters borrowed from a literature review 
    in ectotherms. The methods and literature review are described in Rebaudo 
    et al. (2018) <doi:10.1111/2041-210X.12935> and Rebaudo and Rabhi (2018) 
    <doi:10.1111/eea.12693>. An example can be found in Rebaudo et al. (2017) 
    <doi:10.1007/s13355-017-0480-5>.",2018-10-08,Francois Rebaudo  (2016-2018),https://github.com/frareb/devRate/,TRUE,https://github.com/frareb/devrate,13895,1,1538996468
devtools,Collection of package development tools.,2018-10-26,Jim Hester,https://github.com/r-lib/devtools,TRUE,https://github.com/r-lib/devtools,8585097,1792,1554386729
dexter,"A system for the management, assessment, and psychometric analysis of data from educational and psychological tests. 
    Developed at Cito, The Netherlands, with subsidy from the Dutch Ministry of Education, Culture, and Science.",2019-01-02,Gunter Maris,http://dexterities.netlify.com,TRUE,https://github.com/jessekps/dexter,17476,3,1537277716
dextergui,"Classical Test and Item analysis, 
  Item Response analysis and data management for educational and psychological tests.",2019-03-06,jesse koops,NA,TRUE,https://github.com/jessekps/dexter,5037,3,1537277716
dexterMST,"Conditional Maximum Likelihood Calibration and data management of multistage tests. 
  Functions for calibration of the Extended Nominal Response and the Interaction models, DIF and profile analysis.
  See Robert J. Zwitser and Gunter Maris (2015)<doi:10.1007/s11336-013-9369-6>.",2018-10-29,Timo Bechger,http://dexterities.netlify.com,TRUE,https://github.com/jessekps/dexter,3099,3,1537277716
dfpk,"Statistical methods involving PK measures are provided, in the dose allocation process during a Phase I clinical trials. These methods, proposed by Ursino et al, (2017) <doi:10.1002/bimj.201600084>, enter pharmacokinetics (PK) in the dose finding designs in different ways, including covariates models, dependent variable or hierarchical models. This package provides functions to generate data from several scenarios and functions to run simulations which their objective is to determine the maximum tolerated dose (MTD).",2018-11-09,Artemis Toumazi,http://github.com/artemis-toumazi/dfpk,TRUE,https://github.com/artemis-toumazi/dfpk,18785,3,1541624460
dggridR,"Spatial analyses involving binning require that every bin have the same area, but this is impossible using a rectangular grid laid over the Earth or over any projection of the Earth. Discrete global grids use hexagons, triangles, and diamonds to overcome this issue, overlaying the Earth with equally-sized bins. This package provides utilities for working with discrete global grids, along with utilities to aid in plotting such data.",2018-04-06,Richard Barnes,https://github.com/r-barnes/dggridR/,TRUE,https://github.com/r-barnes/dggridr,12212,70,1532738141
dgo,"Fit dynamic group-level item response theory (IRT) and multilevel
    regression and poststratification (MRP) models from item response data. dgo
    models latent traits at the level of demographic and geographic groups,
    rather than individuals, in a Bayesian group-level IRT approach developed by
    Caughey and Warshaw (2015) <doi:10.1093/pan/mpu021>. The package also
    estimates subpopulations' average responses to single survey items with a
    dynamic MRP model proposed by Park, Gelman, and Bafumi (2004)
    <doi:10.11126/stanford/9780804753005.003.0011>.",2018-07-17,James Dunham,https://jdunham.io/dgo/,TRUE,https://github.com/jamesdunham/dgo,16180,7,1531827260
DHARMa,"The 'DHARMa' package uses a simulation-based approach to create
    readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed
    models. Currently supported are linear and generalized linear (mixed) models from 'lme4' 
    (classes 'lmerMod', 'glmerMod'), 'glmmTMB' and 'spaMM', generalized additive models ('gam' from 
    'mgcv'), 'glm' (including 'negbin' from 'MASS', but excluding quasi-distributions) and 'lm' model
    classes. Moreover, externally created simulations, e.g. posterior predictive simulations 
    from Bayesian software such as 'JAGS', 'STAN', or 'BUGS' can be processed as well. 
    The resulting residuals are standardized to values between 0 and 1 and can be interpreted 
    as intuitively as residuals from a linear regression. The package also provides a number of 
    plot and test functions for typical model misspecification problems, such as 
    over/underdispersion, zero-inflation, and residual spatial and temporal autocorrelation.",2019-03-06,Florian Hartig  (Theoretical Ecology,http://florianhartig.github.io/DHARMa/,TRUE,https://github.com/florianhartig/dharma,36978,55,1551806052
diagmeta,Provides methods by Steinhauser et al. (2016) <DOI:10.1186/s12874-016-0196-1> for meta-analysis of diagnostic accuracy studies with several cutpoints.,2018-12-11,Guido Schwarzer,https://github.com/guido-s/diagmeta,TRUE,https://github.com/guido-s/diagmeta,3817,1,1547061028
DiagrammeR,"
    Build graph/network structures using functions for stepwise addition and
    deletion of nodes and edges. Work with data available in tables for bulk
    addition of nodes, edges, and associated metadata. Use graph selections
    and traversals to apply changes to specific nodes or edges. A wide
    selection of graph algorithms allow for the analysis of graphs. Visualize
    the graphs and take advantage of any aesthetic properties assigned to
    nodes and edges.",2018-03-01,Richard Iannone,https://github.com/rich-iannone/DiagrammeR,TRUE,https://github.com/rich-iannone/diagrammer,600591,1147,1552456590
dials,"Many models contain tuning parameters (i.e. parameters that cannot be directly estimated from the data). These tools can be used to define objects for creating, simulating, or validating values for such parameters. ",2018-12-09,Max Kuhn,https://tidymodels.github.io/dials,TRUE,https://github.com/tidymodels/dials,7729,33,1547926392
diceR,"Performs cluster analysis using an ensemble
    clustering framework, Chiu & Talhouk (2018)
    <doi:10.1186/s12859-017-1996-y>.  Results from a diverse set of
    algorithms are pooled together using methods such as majority voting,
    K-Modes, LinkCluE, and CSPA. There are options to compare cluster
    assignments across algorithms using internal and external indices,
    visualizations such as heatmaps, and significance testing for the
    existence of clusters.",2019-03-08,Derek Chiu,"https://github.com/AlineTalhouk/diceR,
https://alinetalhouk.github.io/diceR",TRUE,https://github.com/alinetalhouk/dicer,10210,15,1552602853
dief,"An implementation of the metrics dief@t and dief@k to measure the diefficiency (or continuous efficiency) of incremental approaches, see Acosta, M., Vidal, M. E., & Sure-Vetter, Y. (2017) <doi:10.1007/978-3-319-68204-4_1>. The metrics dief@t and dief@k allow for measuring the diefficiency during an elapsed time period t or while k answers are produced, respectively. dief@t and dief@k rely on the computation of the area under the curve of answer traces, and thus capturing the answer rate concentration over a time interval.    ",2019-02-28,Maribel Acosta,https://github.com/maribelacosta/dief,TRUE,https://github.com/maribelacosta/dief,4159,4,1551647341
diffdf,"Functions for comparing two data.frames against 
    each other. The core functionality is to provide a detailed breakdown of any differences 
    between two data.frames as well as providing utility functions to help narrow down the 
    source of problems and differences.",2019-03-12,Craig Gower,https://github.com/gowerc/diffdf,TRUE,https://github.com/gowerc/diffdf,5098,5,1553592056
diffee,"This is an R implementation of Fast and Scalable Learning of Sparse Changes in High-Dimensional Gaussian Graphical Model Structure (DIFFEE). The DIFFEE algorithm can be used to fast estimate the differential network between two related datasets. For instance, it can identify differential gene network from datasets of case and control. By performing data-driven network inference from two high-dimensional data sets, this tool can help users effectively translate two aggregated data blocks into knowledge of the changes among entities between two Gaussian Graphical Model. Please run demo(diffeeDemo) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Arshdeep Sekhon, Yanjun Qi (2018) <arXiv:1710.11223>.",2018-07-03,Beilun Wang,https://github.com/QData/DIFFEE,TRUE,https://github.com/qdata/diffee,3089,0,1539358019
diffeqr,"An interface to 'DifferentialEquations.jl' <http://docs.juliadiffeq.org/latest/> from the R programming language.
  It has unique high performance methods for solving ordinary differential equations (ODE), stochastic differential equations (SDE),
  delay differential equations (DDE), differential-algebraic equations (DAE), and more. Much of the functionality,
  including features like adaptive time stepping in SDEs, are unique and allow for multiple orders of magnitude speedup over more common methods.
  'diffeqr' attaches an R interface onto the package, allowing seamless use of this tooling by R users.",2018-04-27,Christopher Rackauckas,https://github.com/JuliaDiffEq/diffeqr,TRUE,https://github.com/juliadiffeq/diffeqr,3104,37,1550061278
diffeR,Metrics of difference for comparing pairs of variables or pairs of maps representing real or categorical variables at original and multiple resolutions.,2019-01-22,Robert Gilmore Pontius Jr. <rpontius@clarku.edu>,"http://amsantac.co/software.html,
https://github.com/amsantac/diffeR",TRUE,https://github.com/amsantac/differ,13562,0,1548124154
ICAOD,"Finds optimal designs for nonlinear models using a metaheuristic algorithm called imperialist competitive algorithm ICA. See, for details, Masoudi et al. (2017) <doi:10.1016/j.csda.2016.06.014>.",2019-01-14,Ehsan Masoudi,https://github.com/ehsan66/ICAOD,TRUE,https://github.com/ehsan66/icaod,8310,0,1547482276
ICC,Assist in the estimation of the Intraclass Correlation Coefficient (ICC) from variance components of a one-way analysis of variance and also estimate the number of individuals or groups necessary to obtain an ICC estimate with a desired confidence interval width.,2015-06-17,Matthew Wolak,http://github.com/matthewwolak/ICC,TRUE,https://github.com/matthewwolak/icc,46156,5,1540492038
iccbeta,"A function and vignettes for computing an intraclass correlation
    described in Aguinis & Culpepper (2015) <doi:10.1177/1094428114563618>.
    This package quantifies the share of variance in a dependent variable that
    is attributed to group heterogeneity in slopes.",2019-01-28,Steven Andrew Culpepper,https://github.com/tmsalab/iccbeta,TRUE,https://github.com/tmsalab/iccbeta,11788,1,1548707609
ICCbin,"Assists in generating binary clustered data, estimates of Intracluster Correlation coefficient (ICC) for binary response in 16 different methods, and 5 different types of confidence intervals.",2017-11-14,Akhtar Hossain,https://cran.r-project.org/package=ICCbin,TRUE,https://github.com/akhtarh/iccbin,6685,3,1551505600
icd,"Calculate comorbidities, Charlson and van Walraven
    scores, perform fast and accurate validation, conversion,
    manipulation, filtering and comparison of ICD-9 and ICD-10 codes. This
    package enables a work flow from raw lists of ICD codes in hospital
    databases to comorbidities.  ICD-9 and ICD-10 comorbidity mappings
    from Quan (Deyo and Elixhauser versions), Elixhauser and AHRQ
    included.  Common ambiguities and code formats are handled.",2018-11-18,Jack O. Wasey,https://jackwasey.github.io/icd/,TRUE,https://github.com/jackwasey/icd,20214,123,1554129333
ICD10gm,"Provides convenient access to the German modification of the International Classification of Diagnoses, 10th revision (ICD-10-GM). It provides functionality to aid in the identification, specification and historisation of ICD-10 codes. Its intended use is the analysis of routinely collected data in the context of epidemiology, medical research and health services research. The underlying metadata are released by the German Institute for Medical Documentation and Information <https://www.dimdi.de>, and are redistributed in accordance with their license.",2019-02-12,Ewan Donnachie  (<https://orcid.org/0000-0002-0668-0049>),"https://github.com/edonnachie/ICD10gm,
https://doi.org/10.5281/zenodo.2542833",TRUE,https://github.com/edonnachie/icd10gm,472,1,1550045172
icesVocab,"R interface to access the RECO POX web services of the ICES 
  (International Council for the Exploration of the Sea) Vocabularies database 
  <https://vocab.ices.dk/services/POX.aspx>.",2019-03-12,Colin Millar,https://vocab.ices.dk/services/POX.aspx,TRUE,https://github.com/ices-tools-prod/icesvocab,5844,3,1552341661
icr,"Provides functions to compute and plot Krippendorff's inter-coder 
    reliability coefficient alpha and bootstrapped uncertainty estimates 
    (Krippendorff 2004, ISBN:0761915443). The bootstrap routines are set up to
    make use of parallel threads where supported.",2019-02-14,Alexander Staudt,https://github.com/staudtlex/icr,TRUE,https://github.com/staudtlex/icr,7651,1,1550168440
IDE,"The Integro-Difference Equation model is a linear, dynamical model used to model
   phenomena that evolve in space and in time; see, for example, Cressie and Wikle (2011,
   ISBN:978-0-471-69274-4) or Dewar et al. (2009) <doi:10.1109/TSP.2008.2005091>. At the
   heart of the model is the kernel, which dictates how the process evolves from one time
   point to the next. Both process and parameter reduction are used to facilitate computation,
   and spatially-varying kernels are allowed. Data used to estimate the parameters are assumed
   to be readings of the process corrupted by Gaussian measurement error. Parameters are fitted
   by maximum likelihood, and estimation is carried out using an evolution algorithm. ",2018-08-07,Andrew Zammit-Mangion,NA,TRUE,https://github.com/andrewzm/ide,2948,0,1533595703
idealstan,"Offers item-response theory (IRT) ideal-point estimation for binary, ordinal, counts and continuous responses with time-varying and missing-data inference. Full and approximate Bayesian sampling with 'Stan' (<https://mc-stan.org/>). ",2019-02-19,Robert Kubinec,NA,TRUE,https://github.com/saudiwin/idealstan,4968,23,1550674787
idefix,"Generates efficient designs for discrete choice experiments based on the multinomial logit model, and individually adapted designs for the mixed multinomial logit model. The generated designs can be presented on screen and choice data can be gathered using a shiny application. Crabbe M, Akinc D and Vandebroek M (2014) <doi:10.1016/j.trb.2013.11.008>.",2018-11-09,Frits Traets,https://github.com/traets/idefix,TRUE,https://github.com/traets/idefix,6567,3,1541508971
ideq,"In contrast to other methods of modeling spatio-temporal data,
  dynamic spatio-temporal models (DSTMs) directly model the dynamic
  data-generating process.
  'ideq' supports two main classes of DSTMs:
  (1) empirical orthogonal function (EOF) models and
  (2) integrodifference equation (IDE) models.
  EOF models do not directly use any spatial information;
  instead, they make use of observed relationships in the data
  (the principal components) to model the underlying process.
  In contrast, IDE models are based on diffusion dynamics and the process
  evolution is governed by a (typically Gaussian) redistribution kernel.
  Both types have a variety of options for specifying the model components,
  including the process matrix, process error, and observation error.
  The classic reference for DSTMs is
  Noel Cressie and Christopher K. Wikle (2011, ISBN:978-0471692744).
  For IDE models specifically, see
  Christopher K. Wikle and Noel Cressie (1999, <https://www.jstor.org/stable/2673587>)
  and 
  Christopher K. Wikle (2002, <doi:10.1191/1471082x02st036oa>).",2019-03-22,Easton Huch,NA,TRUE,https://github.com/eastonhuch/ideq,157,2,1553011968
idx2r,"Convert files to and from IDX format to vectors, matrices and arrays.
    IDX is a very simple file format designed for storing vectors and multidimensional matrices in
    binary format. The format is described on the website from Yann LeCun
    <http://yann.lecun.com/exdb/mnist/>. ",2018-02-20,Erik Doffagne,https://github.com/edoffagne/idx2r,TRUE,https://github.com/edoffagne/idx2r,2560,0,1524630859
ifaTools,"Tools, tutorials, and demos of Item Factor Analysis using 'OpenMx'.",2019-03-09,Joshua N. Pritikin,https://github.com/jpritikin/ifaTools,TRUE,https://github.com/jpritikin/ifatools,13452,1,1530240979
IGP,"Creates a Gaussian process model using the specified package. 
    Makes it easy to try different packages in same code, only the
    package argument needs to be changed.
    It is essentially a wrapper for the other Gaussian process
    software packages.",2017-09-19,Collin Erickson,https://github.com/CollinErickson/IGP,TRUE,https://github.com/collinerickson/igp,3384,0,1544301858
igraph,"Routines for simple graphs and network analysis. It can
  handle large graphs very well and provides functions for generating random
  and regular graphs, graph visualization, centrality methods and much more.",2019-02-13,See AUTHORS file.,http://igraph.org,TRUE,https://github.com/igraph/igraph,4454537,814,1552991575
iheatmapr,"Make complex, interactive heatmaps. 'iheatmapr' includes a modular 
    system for iteratively building up complex heatmaps, as well as the 
    iheatmap() function for making relatively standard heatmaps.",2019-03-16,Alicia Schep  (<https://orcid.org/0000-0002-3915-0618>),https://github.com/ropensci/iheatmapr,TRUE,https://github.com/ropensci/iheatmapr,6847,177,1552620947
imager,"Fast image processing for images in up to 4 dimensions (two spatial
    dimensions, one time/depth dimension, one colour dimension). Provides most
    traditional image processing tools (filtering, morphology, transformations,
    etc.) as well as various functions for easily analysing image data using R. The
    package wraps 'CImg', <http://cimg.eu>, a simple, modern C++ library for image
    processing.",2019-01-23,Simon Barthelme,"http://dahtah.github.io/imager, https://github.com/dahtah/imager",TRUE,https://github.com/dahtah/imager,167464,138,1549286722
imagerExtra,Provides advanced functions for image processing based on the package 'imager'.,2019-01-25,Shota Ochi,https://github.com/ShotaOchi/imagerExtra,TRUE,https://github.com/shotaochi/imagerextra,5188,7,1550797748
imageviewer,"Display a 2D-matrix data as a interactive zoomable gray-scale image viewer, providing tools for manual data inspection. The viewer window shows cursor guiding lines and a corresponding data slices for both axes at the current cursor position. A tool-bar allows adjusting image display brightness/contrast through WebGL filters and performing basic high-pass/low-pass filtering.",2019-02-18,Iakov Pustilnik,https://github.com/yapus/imageviewer,TRUE,https://github.com/yapus/imageviewer,632,4,1550603642
imagine,"Provides fast application of image filters to data matrices,
    using R and C++ algorithms.",2018-05-06,Wencheng Lau-Medrano,https://github.com/LuisLauM/imagine,TRUE,https://github.com/luislaum/imagine,7632,0,1525620469
ImaginR,"The pearl oyster, Pinctada margaritifera (Linnaeus, 1758), represents the second economic resource of French Polynesia. It is one of the only bivalves expressing a large varied range of inner shell color, & by correlation, of pearl color. This phenotypic variability is partly under genetic control, but also under environmental influence. With ImaginR, it's now possible to delimit the color phenotype of the pearl oyster's inner shell and to characterize their color variations (by the HSV color code system) with pictures.",2017-05-31,Pierre-Louis Stenger <Pierre.Louis.Stenger@ifremer.fr>,NA,TRUE,https://github.com/plstenger/imaginr,3924,0,1551200530
imbalance,"Class imbalance usually damages the performance of classifiers. Thus, it is
             important to treat data before applying a classifier algorithm. This package
             includes recent resampling algorithms in the literature: (Barua et al. 2014)
             <doi:10.1109/tkde.2012.232>; (Das et al. 2015) <doi:10.1109/tkde.2014.2324567>,
             (Zhang et al. 2014) <doi:10.1016/j.inffus.2013.12.003>; (Gao et al. 2014)
             <doi:10.1016/j.neucom.2014.02.006>; (Almogahed et al. 2014)
             <doi:10.1007/s00500-014-1484-5>. It also includes an useful interface to
             perform oversampling.",2018-02-18,Ignacio Cordón,http://github.com/ncordon/imbalance,TRUE,https://github.com/ncordon/imbalance,4889,22,1546836859
IMFData,"Search, extract and formulate IMF's datasets.",2016-10-29,Ming-Jer Lee,https://github.com/mingjerli/IMFData,TRUE,https://github.com/mingjerli/imfdata,7966,23,1551924772
imfr,"Explore and download data from the International Monetary Fund's
    data API <http://data.imf.org/>.",2019-03-31,Christopher Gandrud,https://CRAN.R-project.org/package=imfr,TRUE,https://github.com/christophergandrud/imfr,9356,15,1554043907
imguR,"A complete API client for the image hosting service Imgur.com, including the an imgur graphics device, enabling the easy upload and sharing of plots.",2016-03-29,Thomas J. Leeper,https://github.com/leeper/imguR,TRUE,https://github.com/leeper/imgur,19594,16,1524385140
IMIFA,"Provides flexible Bayesian estimation of Infinite Mixtures of Infinite Factor Analysers and related models, for nonparametrically clustering high-dimensional data, introduced by Murphy et al. (2018) <arXiv:1701.07010v4>. The IMIFA model conducts Bayesian nonparametric model-based clustering with factor analytic covariance structures without recourse to model selection criteria to choose the number of clusters or cluster-specific latent factors, mostly via efficient Gibbs updates. Model-specific diagnostic tools are also provided, as well as many options for plotting results, conducting posterior inference on parameters of interest, posterior predictive checking, and quantifying uncertainty.",2019-02-04,Keefe Murphy,https://cran.r-project.org/package=IMIFA,TRUE,https://github.com/keefe-murphy/imifa,7891,2,1549287120
iml,"Interpretability methods to analyze the behavior and predictions of
 any machine learning model.
 Implemented methods are:
 Feature importance described by Fisher et al. (2018) <arXiv:1801.01489>,
 accumulated local effects plots described by Apley (2018) <arXiv:1612.08468>,
 partial dependence plots described by Friedman (2001) <http://www.jstor.org/stable/2699986>,
 individual conditional expectation ('ice') plots described by Goldstein et al. (2013) <doi:10.1080/10618600.2014.907095>,
 local models (variant of 'lime') described by Ribeiro et. al (2016) <arXiv:1602.04938>,
 the Shapley Value described by Strumbelj et. al (2014) <doi:10.1007/s10115-013-0679-x>, 
 feature interactions described by Friedman et. al <doi:10.1214/07-AOAS148> and
 tree surrogate models.",2019-02-05,Christoph Molnar,https://github.com/christophM/iml,TRUE,https://github.com/christophm/iml,24436,216,1553080696
immer,"
    Implements some item response models for multiple
    ratings, including the hierarchical rater model, 
    conditional maximum likelihood estimation of linear 
    logistic partial credit model and a wrapper function
    to the commercial FACETS program. See Robitzsch and
    Steinfeld (2018) for a description of the functionality
    of the package. 
    See Wang, Su & Qiu (2014; <doi:10.1111/jedm.12045>)
    for an overview of modeling alternatives.",2018-12-10,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/immer,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/immer,12735,2,1551211662
Immigrate,"Based on large margin principle, this package performs feature selection methods: ""IM4E""(Iterative Margin-Maximization under Max-Min Entropy Algorithm); ""imIM4E""(imbalance Iterative Margin-Maximization under Max-Min Entropy Algorithm); ""Immigrate""(Iterative Max-Min Entropy Margin-Maximization with Interaction Terms Algorithm); ""BIM""(Boosted version of IMMIGRATE algorithm); ""Simba""(Iterative Search Margin Based Algorithm); ""LFE""(Local Feature Extraction Algorithm). This package also performs prediction for the above feature selection methods. See Zhao et al. (2018) <arXiv:1810.02658> for more details.",2019-01-21,Ruzhang Zhao,"https://CRAN.R-project.org/package=Immigrate,
https://github.com/RuzhangZhao/Immigrate/,
https://arxiv.org/abs/1810.02658",TRUE,https://github.com/ruzhangzhao/immigrate,1805,1,1548082326
implyr,"'SQL' back-end to 'dplyr' for Apache Impala, the massively
    parallel processing query engine for Apache 'Hadoop'. Impala enables
    low-latency 'SQL' queries on data stored in the 'Hadoop' Distributed
    File System '(HDFS)', Apache 'HBase', Apache 'Kudu', Amazon Simple 
    Storage Service '(S3)', Microsoft Azure Data Lake Store '(ADLS)', 
    and Dell 'EMC' 'Isilon'. See <https://impala.apache.org> for more
    information about Impala.",2018-05-17,Ian Cook,https://github.com/ianmcook/implyr,TRUE,https://github.com/ianmcook/implyr,10591,53,1552585795
imputeR,"Multivariate Expectation-Maximization (EM) based imputation framework that offers several different algorithms. These include regularisation methods like Lasso and Ridge regression, tree-based models and dimensionality reduction methods like PCA and PLS.",2018-10-14,Steffen Moritz  (<https://orcid.org/0000-0002-0085-1804>),http://github.com/SteffenMoritz/imputeR,TRUE,https://github.com/steffenmoritz/imputer,14427,4,1544530004
imputeTS,"Imputation (replacement) of missing values 
             in univariate time series. 
             Offers several imputation functions
             and missing data plots. 
             Available imputation algorithms include: 
            'Mean', 'LOCF', 'Interpolation', 
            'Moving Average', 'Seasonal Decomposition', 
            'Kalman Smoothing on Structural Time Series models',
            'Kalman Smoothing on ARIMA models'.",2018-06-20,Steffen Moritz,https://github.com/SteffenMoritz/imputeTS,TRUE,https://github.com/steffenmoritz/imputets,111610,43,1553784222
imsig,Estimate the relative abundance of tissue-infiltrating immune subpopulations abundances using gene expression data. ,2018-07-10,Ajit Johnson Nirmal,https://github.com/ajitjohnson/imsig/,TRUE,https://github.com/ajitjohnson/imsig,2031,8,1541778816
incidence,"Provides functions and classes to compute, handle and visualise incidence from dated events for a defined time interval. Dates can be provided in various standard formats. The class 'incidence' is used to store computed incidence and can be easily manipulated, subsetted, and plotted. In addition, log-linear models can be fitted to 'incidence' objects using 'fit'. This package is part of the RECON (<http://www.repidemicsconsortium.org/>) toolkit for outbreak analysis.",2019-03-14,Zhian N. Kamvar  (<https://orcid.org/0000-0003-1458-7108>),http://www.repidemicsconsortium.org/incidence/,TRUE,https://github.com/reconhub/incidence,19384,30,1552581488
inctools,"Tools for estimating incidence from biomarker data in cross-
    sectional surveys, and for calibrating tests for recent infection. 
    Implements and extends the method of Kassanjee et al. (2012)
    <doi:10.1097/EDE.0b013e3182576c07>.",2018-09-21,Eduard Grebe,http://www.incidence-estimation.org/page/inctools,TRUE,https://github.com/sacema/inctools,7450,5,1544087337
IndianTaxCalc,"Calculate Indian Income Tax liability for Financial years of Individual resident aged below 60 years,Senior Citizen,Super Senior Citizen, Firm, Local Authority, Any Non Resident Individual / Hindu Undivided Family / Association of Persons /Body of Individuals / Artificial Judicial Person, Co-operative Society.",2017-05-08,Sulthan <contact@iamsulthan.in>,https://github.com/iamsulthan/IndianTaxCalc,TRUE,https://github.com/iamsulthan/indiantaxcalc,4680,5,1533046786
INDperform,"An implementation of the 7-step approach suggested by Otto et al. 
    (2018) <doi:10.1016/j.ecolind.2017.05.045> to validate ecological state indicators
    and to select a suite of complimentary and well performing indicators. 
    This suite can be then used to assess the current state of the system 
    in comparison to a reference period. However, the tools in this package 
    are very generic and can be used to test any type of indicator (e.g. social 
    or economic indicators).",2019-02-10,Saskia A. Otto,https://github.com/saskiaotto/INDperform,TRUE,https://github.com/saskiaotto/indperform,3075,1,1554563340
iNEXT,"Provides simple functions to compute and plot two
    types (sample-size- and coverage-based) rarefaction and extrapolation of species
    diversity (Hill numbers) for individual-based (abundance) data or sampling-unit-
    based (incidence) data.",2019-01-24,T. C. Hsieh,http://chao.stat.nthu.edu.tw/blog/software-download/,TRUE,https://github.com/johnsonhsieh/inext,30819,24,1548319078
infer,The objective of this package is to perform inference using an expressive statistical grammar that coheres with the tidy design framework. ,2018-11-15,Andrew Bray,https://github.com/tidymodels/infer,TRUE,https://github.com/tidymodels/infer,26546,338,1553537614
inferr,"Select set of parametric and non-parametric statistical tests. 'inferr' builds upon the solid set of
    statistical tests provided in 'stats' package by including additional data types as inputs, expanding and
    restructuring the test results. The tests included are t tests, variance tests, proportion tests, chi square tests, Levene's test, McNemar Test, Cochran's Q test and Runs test.",2018-02-13,Aravind Hebbali,"https://rsquaredacademy.github.io/inferr/,
https://github.com/rsquaredacademy/inferr",TRUE,https://github.com/rsquaredacademy/inferr,7053,18,1548498926
infix,Contains a number of infix binary operators that may be useful in day to day practices.,2018-12-25,Ernest Benedito,http://github.com/ebeneditos/infix,TRUE,https://github.com/ebeneditos/infix,2042,0,1544980916
infoDecompuTE,"The main purpose of this package is to generate the structure of the analysis of variance 
            (ANOVA) table of the two-phase experiments. The user only need to input the design and the 
              relationships of the random and fixed factors using the Wilkinson-Rogers' syntax, 
              this package can then quickly generate the structure of the ANOVA table with the 
              coefficients of the variance components for the expected mean squares.
              Thus, the balanced incomplete block design and provides the efficiency
              factors of the fixed effects can also be studied and compared much easily.",2018-05-29,Kevin Chang,https://github.com/kcha193/infoDecompuTE,TRUE,https://github.com/kcha193/infodecompute,14591,0,1527479399
ini,"Parse simple '.ini' configuration files to an structured list. Users
  can manipulate this resulting list with lapply() functions. This same
  structured list can be used to write back to file after modifications.",2018-05-20,David Valentim Dias,https://github.com/dvdscripter/ini,TRUE,https://github.com/dvdscripter/ini,1061970,1,1526771905
inlabru,"Facilitates spatial modeling using integrated nested Laplace approximation via the 
  INLA package (<http://www.r-inla.org>). Additionally, implements a log Gaussian Cox process likelihood for 
  modeling univariate and spatial point processes based on ecological survey data. See Yuan Yuan, 
  Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Havard Rue, 
  Tim Gerrodette (2017), <arXiv:1604.06013>.",2018-07-24,Fabian E. Bachl  (Fabian Bachl wrote the main code),"http://www.inlabru.org,",TRUE,https://github.com/fbachl/inlabru,5370,14,1554017723
inline,"Functionality to dynamically define R functions and S4 methods
 with 'inlined' C, C++ or Fortran code supporting the .C and .Call calling
 conventions.",2018-05-18,Oleg Sklyar,NA,TRUE,https://github.com/eddelbuettel/inline,598202,21,1535893381
inlmisc,"A collection of functions for creating high-level graphics,
    performing raster-based analysis, processing MODFLOW-based models,
    selecting subsets using a genetic algorithm, creating interactive web maps,
    accessing color palettes, etc. Used to support packages and scripts written
    by researchers at the United States Geological Survey (USGS)
    Idaho National Laboratory (INL) Project Office.",2019-02-09,Jason C. Fisher  (<https://orcid.org/0000-0001-9032-8912>),https://github.com/USGS-R/inlmisc,TRUE,https://github.com/usgs-r/inlmisc,30833,9,1551681759
inpdfr,"A set of functions to analyse and compare texts, using classical 
  text mining	functions, as well as those from theoretical ecology.",2018-10-24,Rebaudo Francois (IRD,https://github.com/frareb/inpdfr/,TRUE,https://github.com/frareb/inpdfr,9180,1,1540371846
inplace,"It provides in-place operators for R 
    that are equivalent to '+=', '-=', '*=', '/=' in C++. 
    Those can be applied on integer|double vectors|matrices.
    You have also access to sweep operations (in-place).",2018-06-10,Florian Privé,https://github.com/privefl/inplace,TRUE,https://github.com/privefl/inplace,1829,7,1529338559
insect,Provides tools for probabilistic taxon assignment with informatic sequence classification trees. See Wilkinson et al (2018) <doi:10.7287/peerj.preprints.26812v1>.,2018-11-25,Shaun Wilkinson,http://github.com/shaunpwilkinson/insect,TRUE,https://github.com/shaunpwilkinson/insect,3390,7,1551247457
insight,"A tool to provide an easy, intuitive and consistent access to 
   information contained in various R models, like model formulas, model terms, 
   information about random effects, data that was used to fit the model or 
   data from response variables. 'insight' mainly revolves around two types 
   of functions: Functions that find (the names of) information, starting with 
   'find_', and functions that get the underlying data, starting with 'get_'. 
   The package has a consistent syntax and works with many different model 
   objects, where otherwise functions to access these information are missing.",2019-03-29,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>),https://easystats.github.io/insight/,TRUE,https://github.com/easystats/insight,20404,17,1554196923
InSilicoVA,"Computes individual causes of death and population cause-specific mortality fractions using the 'InSilicoVA' algorithm from McCormick et al. (2016) <DOI:10.1080/01621459.2016.1152191>. It uses data derived from verbal autopsy (VA) interviews, in a format similar to the input of the widely used 'InterVA4' method. This package provides general model fitting and customization for 'InSilicoVA' algorithm and basic graphical visualization of the output.",2018-10-29,Zehang Li,https://github.com/verbal-autopsy-software/InSilicoVA,TRUE,https://github.com/verbal-autopsy-software/insilicova,18186,2,1554262131
installr,"R is great for installing software.  Through the 'installr'
    package you can automate the updating of R (on Windows, using updateR())
    and install new software. Software installation is initiated through a
    GUI (just run installr()), or through functions such as: install.Rtools(),
    install.pandoc(), install.git(), and many more. The updateR() command
    performs the following: finding the latest R version, downloading it,
    running the installer, deleting the installation file, copy and updating
    old packages to the new R installation.",2018-10-06,Tal Galili,"https://github.com/talgalili/installr/,
http://www.r-statistics.com/tag/installr/",TRUE,https://github.com/talgalili/installr,883107,162,1550252695
interactions,"A suite of functions for conducting and interpreting analysis 
  of statistical interaction in regression models that was formerly part of the 
  'jtools' package. Functionality includes visualization of two- and three-way
  interactions among continuous and/or categorical variables as well as 
  calculation of ""simple slopes"" and Johnson-Neyman intervals. These
  capabilities are implemented for generalized linear models in addition to the 
  standard linear regression context.",2019-02-18,Jacob A. Long  (<https://orcid.org/0000-0002-1582-6214>),https://interactions.jacob-long.com,TRUE,https://github.com/jacob-long/interactions,2113,44,1552096037
interep,"Extensive penalized variable selection methods have been developed in the past two decades for analyzing high dimensional omics data, such as gene expressions, single nucleotide polymorphisms (SNPs), copy number variations (CNVs) and others. However, lipidomics data have been rarely investigated by using high dimensional variable selection methods. This package incorporates our recently developed penalization procedures to conduct interaction analysis for high dimensional lipidomics data with repeated measurements. The core module of this package is developed in C++. The development of this software package and the associated statistical methods have been partially supported by an Innovative Research Award from Johnson Cancer Research Center, Kansas State University.",2018-11-10,Fei Zhou,https://github.com/feizhoustat/interep,TRUE,https://github.com/feizhoustat/interep,3375,1,1547111716
interlineaR,"Interlinearized glossed texts (IGT) are used in descriptive linguistics for
 representing a morphological analysis of a text through a morpheme-by-morpheme gloss.
 'InterlineaR' provide a set of functions that targets several popular formats of IGT
 ('SIL Toolbox', 'EMELD XML') and that turns an IGT into a set of data frames following
 a relational model (the tables represent the different linguistic units: texts,
 sentences, word, morphems).
 The same pieces of software ('SIL FLEX', 'SIL Toolbox') typically produce dictionaries
 of the morphemes used in the glosses. 'InterlineaR' provide a function for turning
 the LIFT XML dictionary format into a set of data frames following a relational model
 in order to represent the dictionary entries, the sense(s) attached to the entries,
 the example(s) attached to senses, etc.",2018-05-22,Sylvain Loiseau,https://github.com/sylvainloiseau/interlineaR,TRUE,https://github.com/sylvainloiseau/interlinear,1987,1,1526992667
internetarchive,"Search the Internet Archive, retrieve metadata, and download
    files.",2016-12-08,Lincoln Mullen,https://github.com/ropensci/internetarchive,TRUE,https://github.com/ropensci/internetarchive,10770,37,1523997066
interplot,"Plots the conditional coefficients (""marginal effects"") of
    variables included in multiplicative interaction terms.",2018-06-30,Yue Hu,NA,TRUE,https://github.com/sammo3182/interplot,50012,9,1552444906
IntrinioStockAPI,"Download financial data from the free 'Intrinio Stock API' (<https://intrinio.com/>).
    'Intrinio' offers a REST API which provides financial markets data 
    including intra-day stock prices, historical stock prices, technical indicators, company fundamentals, and more. 
    Complete documentation for the 'Intrinio Stock API' is available here: 
    <https://intrinio.com/documentation/api/>. To access the 'Intrinio Stock API',
    simply create a free account <https://intrinio.com/>.",2018-10-08,Intrinio,https://github.com/intrinio/r-sdk,TRUE,https://github.com/intrinio/r-sdk,1363,0,1538410685
intrval,"Evaluating if values 
  of vectors are within different open/closed intervals
  (`x %[]% c(a, b)`), or if two closed
  intervals overlap (`c(a1, b1) %[]o[]% c(a2, b2)`).
  Operators for negation and directional relations also implemented.",2017-01-22,Peter Solymos,https://github.com/psolymos/intrval,TRUE,https://github.com/psolymos/intrval,5639,35,1538599522
intsvy,"
  Provides tools for importing, merging, and analysing data from 
  international assessment studies (TIMSS, PIRLS, PISA, ICILS, and PIAAC).",2018-10-09,Daniel Caro <dcarov@gmail.com>,"http://danielcaro.net/r-intsvy/,
https://github.com/eldafani/intsvy",TRUE,https://github.com/eldafani/intsvy,48467,7,1539104802
invctr,"Vector operations between grapes: An infix-only package! The 'invctr' functions perform common and less common operations on vectors, data frames matrices and list objects:
    - Extracting a value (range), or, finding the indices of a value (range).
    - Trimming, or padding a vector with a value of your choice.
    - Simple polynomial regression.
    - Set and membership operations.
    - General check & replace function for NAs, Inf and other values.",2019-03-07,Fred Hasselman  (<https://orcid.org/0000-0003-1384-8361>),https://github.com/FredHasselman/invctr,TRUE,https://github.com/fredhasselman/invctr,290,0,1551888510
investr,"Functions to facilitate inverse estimation (e.g., calibration) in
    linear, generalized linear, nonlinear, and (linear) mixed-effects models. A
    generic function is also provided for plotting fitted regression models with
    or without confidence/prediction bands that may be of use to the general
    user.",2016-04-09,Brandon M. Greenwell,https://github.com/bgreenwell/investr,TRUE,https://github.com/bgreenwell/investr,24240,10,1542129110
iotables,"Pre-processing and basic analytical tasks related to working with Eurostat's symmetric input-output
    tables and provide basic input-output economics calculations. The package is 
    a part of rOpenGov <http://ropengov.github.io/> to open source open government initiatives.",2019-01-18,Daniel Antal  (<https://orcid.org/0000-0001-7513-6760>),http://iotables.ceemid.eu/,TRUE,https://github.com/ropengov/iotables,8166,2,1547810000
ipc,"Provides tools for passing messages between R processes. 
    Shiny Examples are provided showing how to perform useful tasks such as: 
    updating reactive values from within a future, progress bars for long running 
    async tasks, and interrupting async tasks based on user input.",2019-01-11,Ian E. Fellows,https://github.com/fellstat/ipc,TRUE,https://github.com/fellstat/ipc,2311,27,1548202277
ipeadatar,"Allows directly access to the macroeconomic, 
             financial and regional database maintained by 
             Brazilian Institute for Applied Economic Research ('Ipea').
             This R package uses the 'Ipeadata' API. For more information, 
             see <http://www.ipeadata.gov.br/>.",2019-02-22,Luiz Eduardo S. Gomes,http://github.com/gomesleduardo/ipeadatar,TRUE,https://github.com/gomesleduardo/ipeadatar,366,0,1552487660
iprior,"Provides methods to perform and analyse I-prior regression models.
    Estimation is done either via direct optimisation of the log-likelihood or 
    an EM algorithm.",2019-03-20,Haziq Jamil,https://github.com/haziqj/iprior,TRUE,https://github.com/haziqj/iprior,10394,2,1553065239
iptmnetr,"Provides an R interface to the 'iPTMnet' database REST API, which can be used to retrieve 
    Post Translational Modification (PTM) data in systems biology context. This package handles all the aspects
    of communicating with the API, which involve sending the request, checking the error codes and parsing the
    response in a format that is ready to integrate into existing workflows.",2018-09-27,Sachin Gavali,"https://research.bioinformatics.udel.edu/iptmnet/,
https://github.com/udel-cbcb/iptmnetr",TRUE,https://github.com/udel-cbcb/iptmnetr,2493,1,1537464974
iptools,"A toolkit for manipulating, validating and testing 'IP' addresses and
    ranges, along with datasets relating to 'IP' addresses. Tools are also provided
    to map 'IPv4' blocks to country codes. While it primarily has support for the 'IPv4'
    address space, more extensive 'IPv6' support is intended.",2018-12-09,Bob Rudis <bob@rud.is>,https://github.com/hrbrmstr/iptools,TRUE,https://github.com/hrbrmstr/iptools,16643,38,1539531022
ipumsr,"An easy way to import census, survey and geographic data provided by 'IPUMS'
    into R plus tools to help use the associated metadata to make analysis easier. 'IPUMS'
    data describing 1.4 billion individuals drawn from over 750 censuses and surveys is
    available free of charge from our website <https://ipums.org>.",2019-03-08,Greg Freedman Ellis,"https://www.ipums.org, https://github.com/mnpopcenter/ipumsr",TRUE,https://github.com/mnpopcenter/ipumsr,13698,38,1553178706
IQCC,"Builds statistical control charts with exact limits for
        univariate and multivariate cases.",2017-11-15,Flavio Barros,https://flaviobarros.github.io/IQCC,TRUE,https://github.com/flaviobarros/iqcc,16649,0,1527625058
ircor,"Provides implementation of various correlation coefficients of common use in
  Information Retrieval. In particular, it includes Kendall (1970, isbn:0852641990) tau coefficient
  as well as tau_a and tau_b for the treatment of ties. It also includes Yilmaz et al. (2008)
  <doi:10.1145/1390334.1390435> tauAP correlation coefficient, and versions tauAP_a and tauAP_b
  developed by Urbano and Marrero (2017) <doi:10.1145/3121050.3121106> to cope with ties.",2017-08-21,Julián Urbano,https://github.com/julian-urbano/ircor/,TRUE,https://github.com/julian-urbano/ircor,3212,3,1532005123
irlba,"Fast and memory efficient methods for truncated singular value
    decomposition and principal components analysis of large sparse and dense
    matrices.",2019-02-05,B. W. Lewis,NA,TRUE,https://github.com/bwlewis/irlba,2130059,65,1549481355
isdparser,"Tools for parsing 'NOAA' Integrated Surface Data ('ISD') files,
    described at <https://www.ncdc.noaa.gov/isd>. Data includes for example,
    wind speed and direction, temperature, cloud data, sea level pressure,
    and more. Includes data from approximately 35,000 stations worldwide,
    though best coverage is in North America/Europe/Australia. Data is stored
    as variable length ASCII character strings, with most fields optional.
    Included are tools for parsing entire files, or individual lines of data.",2018-10-23,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/isdparser,TRUE,https://github.com/ropensci/isdparser,78214,5,1540251959
isoband,"A fast C++ implementation to generate contour lines (isolines) and
  contour polygons (isobands) from regularly spaced grids containing elevation data.",2019-02-03,Claus Wilke,https://github.com/clauswilke/isoband,TRUE,https://github.com/clauswilke/isoband,744,64,1554502172
IsoriX,"Building isoscapes using mixed models and inferring the geographic
  origin of samples based on their isotopic ratios. This package is essentially a
  simplified interface to several other packages which implements a new
  statistical framework based on mixed models. It uses 'spaMM' for fitting and
  predicting isoscapes, and assigning an organism's origin depending on its
  isotopic ratio. 'IsoriX' also relies heavily on the package 'rasterVis' for
  plotting the maps produced with 'raster' using 'lattice'.",2018-08-29,Alexandre Courtiol  (<https://orcid.org/0000-0003-0637-2959>),https://github.com/courtiol/IsoriX/,TRUE,https://github.com/courtiol/isorix,8890,3,1553462048
itunesr,"To enable 'iOS' App Developers to access iTunes App Store Ratings and Reviews using R to extract Basic App Information and Reviews submitted by their App users, Since Apple Store does not provide this straightforward. ",2018-10-11,AbdulMajedRaja RS,http://github.com/amrrs/itunesr,TRUE,https://github.com/amrrs/itunesr,6296,16,1539265082
jaatha,"An estimation method that can use computer simulations to
    approximate maximum-likelihood estimates even when the likelihood function can not
    be evaluated directly. It can be applied whenever it is feasible to conduct many
    simulations, but works best when the data is approximately Poisson distributed.
    It was originally designed for demographic inference in evolutionary
    biology. It has optional support for conducting coalescent simulation using
    the 'coala' package.",2016-05-13,Paul Staab,https://github.com/statgenlmu/jaatha,TRUE,https://github.com/statgenlmu/jaatha,22542,3,1551123391
jagsUI,"A set of wrappers around 'rjags' functions to run Bayesian analyses in 'JAGS' (specifically, via 'libjags').  A single function call can control adaptive, burn-in, and sampling MCMC phases, with MCMC chains run in sequence or in parallel. Posterior distributions are automatically summarized (with the ability to exclude some monitored nodes if desired) and functions are available to generate figures based on the posteriors (e.g., predictive check plots, traceplots). Function inputs, argument syntax, and output format are nearly identical to the 'R2WinBUGS'/'R2OpenBUGS' packages to allow easy switching between MCMC samplers. ",2018-09-12,Ken Kellner <contact@kenkellner.com>,https://github.com/kenkellner/jagsUI,TRUE,https://github.com/kenkellner/jagsui,45768,15,1550762526
janeaustenr,"Full texts for Jane Austen's 6 completed novels, ready for text
    analysis. These novels are ""Sense and Sensibility"", ""Pride and Prejudice"",
    ""Mansfield Park"", ""Emma"", ""Northanger Abbey"", and ""Persuasion"".",2017-06-10,Julia Silge,https://github.com/juliasilge/janeaustenr,TRUE,https://github.com/juliasilge/janeaustenr,360012,72,1527625957
janitor,"The main janitor functions can: perfectly format data.frame column
    names; provide quick counts of variable combinations (i.e., frequency
    tables and crosstabs); and isolate duplicate records. Other janitor functions
    nicely format the tabulation results. These tabulate-and-report functions
    approximate popular features of SPSS and Microsoft Excel. This package
    follows the principles of the ""tidyverse"" and works well with the pipe function
    %>%. janitor was built with beginning-to-intermediate R users in mind and is
    optimized for user-friendliness. Advanced R users can already do everything
    covered here, but with janitor they can do it faster and save their thinking for
    the fun stuff.",2018-07-31,Sam Firke,https://github.com/sfirke/janitor,TRUE,https://github.com/sfirke/janitor,112069,607,1552658872
jaod,"Client for the Directory of Open Access Journals ('DOAJ')
    (<https://doaj.org/>). 'API' documentation at
    <https://doaj.org/api/v1/docs>. Methods included for working with
    all 'DOAJ' 'API' routes: fetch article information by identifier,
    search for articles, fetch journal information by identifier,
    and search for journals.",2017-09-01,Scott Chamberlain,https://github.com/ropenscilabs/jaod,TRUE,https://github.com/ropenscilabs/jaod,3157,8,1541631922
jcolors,Contains a selection of color palettes and 'ggplot2' themes designed by the package author.,2018-08-09,Jared Huling,https://jaredhuling.github.io/jcolors/,TRUE,https://github.com/jaredhuling/jcolors,12936,9,1540081424
jeek,"Provides a fast and scalable joint estimator for integrating additional knowledge in learning multiple related sparse Gaussian Graphical Models (JEEK). The JEEK algorithm can be used to fast estimate multiple related precision matrices in a large-scale. For instance, it can identify multiple gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogeneous data sets, this tool can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(jeek) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Arshdeep Sekhon, Yanjun Qi ""A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models"" (ICML 2018) <arXiv:1806.00548>.",2018-07-07,Beilun Wang,https://github.com/QData/jeek,TRUE,https://github.com/qdata/jeek,2006,0,1547746762
jetpack,"Manage project dependencies from your DESCRIPTION file. Create a reproducible virtual environment with minimal additional files in your project. Provides tools to add, remove, and update dependencies as well as install existing dependencies with a single function.",2019-02-12,Andrew Kane,https://github.com/ankane/jetpack,TRUE,https://github.com/ankane/jetpack,3635,157,1551650865
jiebaR,"Chinese text segmentation, keyword extraction and speech tagging
    For R.",2019-03-12,Qin Wenfeng,https://github.com/qinwf/jiebaR/,TRUE,https://github.com/qinwf/jiebar,76199,250,1552293298
jipApprox,"Approximate joint-inclusion probabilities in Unequal Probability Sampling, or compute Monte Carlo approximations of the first and second-order inclusion probabilities of a general sampling design as in Fattorini (2006) <doi:10.1093/biomet/93.2.269>.",2019-02-09,Roberto Sichera,NA,TRUE,https://github.com/rhobis/jipapprox,1438,0,1548589732
JMbayes,Shared parameter models for the joint modeling of longitudinal and time-to-event data using MCMC; Dimitris Rizopoulos (2016) <doi:10.18637/jss.v072.i07>. ,2019-03-25,Dimitris Rizopoulos <d.rizopoulos@erasmusmc.nl>,https://github.com/drizopoulos/JMbayes,TRUE,https://github.com/drizopoulos/jmbayes,37771,15,1554403268
jmcm,"Fit joint mean-covariance models for longitudinal data. The models
    and their components are represented using S4 classes and methods. The core
    computational algorithms are implemented using the 'Armadillo' C++ library
    for numerical linear algebra and 'RcppArmadillo' glue.",2018-11-10,Jianxin Pan,https://github.com/ypan1988/jmcm/,TRUE,https://github.com/ypan1988/jmcm,10663,2,1541803107
jmotif,"Implements time series z-normalization, SAX, HOT-SAX, VSM, SAX-VSM, RePair, and RRA
    algorithms facilitating time series motif (i.e., recurrent pattern), discord (i.e., anomaly),
    and characteristic pattern discovery along with interpretable time series classification.",2018-02-07,Pavel Senin,https://github.com/jMotif/jmotif-R,TRUE,https://github.com/jmotif/jmotif-r,13723,40,1537968810
jmvcore,"A framework for creating rich interactive analyses for the jamovi
    platform (see <https://www.jamovi.org> for more information).",2019-03-28,Jonathon Love,https://www.jamovi.org,TRUE,https://github.com/jamovi/jmvcore,50290,2,1554514672
joineR,"Analysis of repeated measurements and time-to-event data via random
    effects joint models. Fits the joint models proposed by Henderson and colleagues
    <doi:10.1093/biostatistics/1.4.465> (single event time) and by Williamson and
    colleagues (2008) <doi:10.1002/sim.3451> (competing risks events time) to a
    single continuous repeated measure. The time-to-event data is modelled using a 
    (cause-specific) Cox proportional hazards regression model with time-varying 
    covariates. The longitudinal outcome is modelled using a linear mixed effects
    model. The association is captured by a latent Gaussian process. The model is 
    estimated using am Expectation Maximization algorithm. Some plotting functions 
    and the variogram are also included. This project is funded by the Medical 
    Research Council (Grant numbers G0400615 and MR/M013227/1).",2018-05-18,Pete Philipson  (<https://orcid.org/0000-0001-7846-0208>),https://github.com/graemeleehickey/joineR/,TRUE,https://github.com/graemeleehickey/joiner,28518,7,1527585627
joineRmeta,"Fits joint models of the type proposed by Henderson and colleagues 
    (2000) <doi:10.1093/biostatistics/1.4.465>, but extends to the multi-study, 
    meta-analytic case. Functions for meta-analysis of a single longitudinal and 
    a single  time-to-event outcome from multiple studies using joint models.  
    Options to produce plots for multi study joint data, to pool joint model 
    fits from 'JM' and 'joineR' packages in a two stage meta-analysis, and to 
    model multi-study joint data in a one stage meta-analysis.",2018-03-09,Maria Sudell  (<https://orcid.org/0000-0002-7919-4981>),https://github.com/mesudell/joineRmeta/,TRUE,https://github.com/mesudell/joinermeta,2739,1,1529432428
joineRML,"Fits the joint model proposed by Henderson and colleagues (2000) 
    <doi:10.1093/biostatistics/1.4.465>, but extended to the case of multiple 
    continuous longitudinal measures. The time-to-event data is modelled using a 
    Cox proportional hazards regression model with time-varying covariates. The 
    multiple longitudinal outcomes are modelled using a multivariate version of the 
    Laird and Ware linear mixed model. The association is captured by a multivariate
    latent Gaussian process. The model is estimated using a Monte Carlo Expectation 
    Maximization algorithm. This project is funded by the Medical Research Council 
    (Grant number MR/M013227/1).",2018-05-28,Graeme L. Hickey (<https://orcid.org/0000-0002-4989-0054>),https://github.com/petephilipson/joineRML,TRUE,https://github.com/petephilipson/joinerml,22931,0,1533068952
JointAI,"Provides joint analysis and imputation of (generalized) 
    linear and cumulative logit regression models, (generalized) linear and 
    cumulative logit mixed models and parametric (Weibull) as well as Cox
    proportional hazards survival models with incomplete (covariate) data in 
    the Bayesian framework.
    The package performs some preprocessing of the data and creates a 'JAGS'
    model, which will then automatically be passed to 'JAGS' 
    <http://mcmc-jags.sourceforge.net> with the help of 
    the package 'rjags'.
    It also provides summary and plotting functions for the output and allows 
    to export imputed values.",2019-03-08,Nicole S. Erler  (<https://orcid.org/0000-0002-9370-6832>),https://nerler.github.io/JointAI,TRUE,https://github.com/nerler/jointai,4408,2,1552579342
JointNets,"A set of tools for performing sparse Gaussian graphical model (joint, multiple and difference) estimation from high dimensional dataset. It contains a general purpose visualization function as well as a specialized function for 3d brain network. Simulation and evaluation modules are available. It also contains a simple GUI built in shiny for easy graph visualization. Methods include SIMULE (Wang B et al. (2017) <doi:10.1007/s10994-017-5635-7>), WSIMULE (Singh C et al. (2017) <arXiv:1709.04090v2>), DIFFEE (Wang B et al. (2018) <arXiv:1710.11223>), FASJEM (Wang B et al. (2018) <arXiv:1702.02715v3>), JEEK (Wang B et al. (2018) <arXiv:1806.00548>) and DIFFEEK (Wang B et al, under final review for publication).",2018-12-25,Zhaoyang Wang,https://github.com/QData/JointNets,TRUE,https://github.com/qdata/jointnets,1425,0,1545786411
jointseg,"Methods for fast segmentation of multivariate
    signals into piecewise constant profiles and for generating realistic
    copy-number profiles. A typical application is the joint segmentation of total
    DNA copy numbers and allelic ratios obtained from Single Nucleotide Polymorphism
    (SNP) microarrays in cancer studies. The methods are described in Pierre-Jean, 
    Rigaill and Neuvial (2015) <doi:10.1093/bib/bbu026>.",2019-01-11,Morgane Pierre-Jean,https://github.com/mpierrejean/jointseg,TRUE,https://github.com/mpierrejean/jointseg,4408,4,1546858725
jqr,"Client for 'jq', a 'JSON' processor (<https://stedolan.github.io/jq/>), 
    written in C. 'jq' allows the following with 'JSON' data: index into, parse, 
    do calculations, cut up and filter, change key names and values, perform 
    conditionals and comparisons, and more.",2018-10-22,Scott Chamberlain,https://github.com/ropensci/jqr,TRUE,https://github.com/ropensci/jqr,141377,95,1551957611
jrc,An 'httpuv' based bridge between R and 'JavaScript'. Provides an easy way to exchange commands and data between a web page and a currently running R session. ,2019-03-31,Svetlana Ovchinnikova,https://github.com/anders-biostat/jrc,TRUE,https://github.com/anders-biostat/jrc,101,7,1554123225
jrvFinance,"Implements the basic financial analysis
    functions similar to (but not identical to) what
    is available in most spreadsheet software. This
    includes finding the IRR and NPV of regularly
    spaced cash flows and annuities. Bond pricing and
    YTM calculations are included. In addition, Black
    Scholes option pricing and Greeks are also
    provided.",2019-03-15,Jayanth Varma,http://github.com/jrvarma/jrvFinance,TRUE,https://github.com/jrvarma/jrvfinance,11788,3,1552654766
js,"A set of utilities for working with JavaScript syntax in R.
    Includes tools to parse, tokenize, compile, validate, reformat, optimize 
    and analyze JavaScript code.",2017-07-28,Jeroen Ooms,https://github.com/jeroen/js,TRUE,https://github.com/jeroen/js,14876,44,1524914890
jskm,The function 'jskm()' creates publication quality Kaplan-Meier plot with at risk tables below. 'svyjskm()' provides plot for weighted Kaplan-Meier estimator. ,2019-03-12,Jinseob Kim  (<https://orcid.org/0000-0002-9403-605X>),https://github.com/jinseob2kim/jskm,TRUE,https://github.com/jinseob2kim/jskm,1036,0,1552393655
jsmodule,"'RStudio' addins and 'Shiny' modules for descriptive statistics, regression and survival analysis.",2019-03-08,Jinseob Kim  (<https://orcid.org/0000-0002-9403-605X>),https://github.com/jinseob2kim/jsmodule,TRUE,https://github.com/jinseob2kim/jsmodule,289,1,1552399714
jsonlite,"A fast JSON parser and generator optimized for statistical data
    and the web. Started out as a fork of 'RJSONIO', but has been completely
    rewritten in recent versions. The package offers flexible, robust, high
    performance tools for working with JSON in R and is particularly powerful
    for building pipelines and interacting with a web API. The implementation is
    based on the mapping described in the vignette (Ooms, 2014). In addition to
    converting JSON data from/to R objects, 'jsonlite' contains functions to
    stream, validate, and prettify JSON data. The unit tests included with the
    package verify that all edge cases are encoded and decoded consistently for
    use with dynamic data in systems and applications.",2018-12-07,Jeroen Ooms,"https://arxiv.org/abs/1403.2805,
https://www.opencpu.org/posts/jsonlite-a-smarter-json-encoder",TRUE,https://github.com/jeroen/jsonlite,13237430,209,1552052520
jsonvalidate,"Uses the node library 'is-my-json-valid' to validate 'JSON' against
    a 'JSON' schema.",2016-06-13,Rich FitzJohn,https://github.com/ropenscilabs/jsonvalidate,TRUE,https://github.com/ropenscilabs/jsonvalidate,96083,24,1529068292
jsr223,"Provides a high-level integration for the 'Java' platform that makes 'Java' objects easy to use from within 'R'; provides a unified interface to integrate 'R' with several programming languages; and features extensive data exchange between 'R' and 'Java'. The 'jsr223'-supported programming languages include 'Groovy', 'JavaScript', 'JRuby' ('Ruby'), 'Jython' ('Python'), and 'Kotlin'. Any of these languages can use and extend 'Java' classes in natural syntax. Furthermore, solutions developed in any of the 'jsr223'-supported languages are also accessible to 'R' developers. The 'jsr223' package also features callbacks, script compiling, and string interpolation. In all, 'jsr223' significantly extends the computing capabilities of the 'R' software environment.",2018-12-12,Floid R. Gilbert,https://github.com/floidgilbert/jsr223,TRUE,https://github.com/floidgilbert/jsr223,3192,5,1544655917
jstable,"Create regression tables from generalized linear model(GLM), generalized estimating equation(GEE), generalized linear mixed-effects model(GLMM), Cox proportional hazards model, survey-weighted generalized linear model(svyglm) and survey-weighted Cox model results for publication.",2019-03-07,Jinseob Kim  (<https://orcid.org/0000-0002-9403-605X>),https://github.com/jinseob2kim/jstable,TRUE,https://github.com/jinseob2kim/jstable,1710,1,1552393685
jstor,"Functions and helpers to import metadata, ngrams and full-texts 
    delivered by Data for Research by JSTOR. ",2018-12-12,Thomas Klebel  (<https://orcid.org/0000-0002-7331-4751>),"https://github.com/ropensci/jstor,
https://ropensci.github.io/jstor/",TRUE,https://github.com/ropensci/jstor,3527,29,1544629304
jsTree,"Create and customize interactive trees using the 'jQuery' 'jsTree' <https://www.jstree.com/>
    plugin library and the 'htmlwidgets' package. These trees can be used
    directly from the R console, from 'RStudio', in Shiny apps and R Markdown documents.",2017-10-24,Jonathan Sidi,https://github.com/metrumresearchgroup/jsTree,TRUE,https://github.com/metrumresearchgroup/jstree,3429,20,1525958622
jtools,"This is a collection of tools that the author (Jacob) has written
  for the purpose of more efficiently understanding and sharing the results of
  (primarily) regression analyses. There are also a number of miscellaneous
  functions for statistical and programming purposes. Just about everything 
  supports models from the survey package.",2019-02-08,Jacob A. Long  (<https://orcid.org/0000-0002-1582-6214>),https://github.com/jacob-long/jtools,TRUE,https://github.com/jacob-long/jtools,51882,52,1552263606
JuliaCall,"Provides an R interface to 'Julia',
    which is a high-level, high-performance dynamic programming language
    for numerical computing, see <https://julialang.org/> for more information.
    It provides a high-level interface as well as a low-level interface.
    Using the high level interface, you could call any 'Julia' function just like
    any R function with automatic type conversion. Using the low level interface,
    you could deal with C-level SEXP directly while enjoying the convenience of
    using a high-level programming language like 'Julia'.",2019-03-22,Changcheng Li,https://github.com/Non-Contradiction/JuliaCall,TRUE,https://github.com/non-contradiction/juliacall,58724,69,1553204883
JuniperKernel,"Provides a full implementation of the 'Jupyter' <http://jupyter.org/> messaging protocol in C++ by leveraging 'Rcpp' and 'Xeus' <https://github.com/QuantStack/xeus>.
             'Jupyter' supplies an interactive computing environment and a messaging protocol defined over 'ZeroMQ' for multiple programming languages. This package implements
             the 'Jupyter' kernel interface so that 'R' is exposed to this interactive computing environment. 'ZeroMQ' functionality is provided by the 'pbdZMQ' package.
             'Xeus' is a C++ library that facilitates the implementation of kernels for 'Jupyter'. Additionally, 'Xeus' provides an interface to libraries that exist in the 'Jupyter' ecosystem for building widgets,
             plotting, and more <https://blog.jupyter.org/interactive-workflows-for-c-with-jupyter-fe9b54227d92>. 'JuniperKernel' uses 'Xeus' as a library for the 'Jupyter' messaging protocol.",2018-07-09,Spencer Aiello,https://github.com/JuniperKernel/JuniperKernel,TRUE,https://github.com/juniperkernel/juniperkernel,6974,43,1544394923
junr,"
    The 'Junar' API is a commercial platform to organize and publish data
    <http://www.junar.com>. It has been used in a number of national and local
    government Open Data initiatives in Latin America and the USA. This package
    is a wrapper to make it easier to access data made public through the 'Junar'
    API.",2017-12-11,Frans van Dunné,https://github.com/fvd/junr,TRUE,https://github.com/fvd/junr,6614,1,1553991832
jvcoords,"
  Provides functions to standardize and whiten data, and to perform
  Principal Component Analysis (PCA).  The main advantage of this
  package over alternatives like prcomp() is, that jvcoords makes it
  easy to convert (additional) data between the original and the
  transformed coordinates.  The package also provides a class coords,
  which can represent affine coordinate transformations.  This class
  forms the basis of the transformations provided by the package, but
  can also be used independently.  The implementation has been
  optimized to be of comparable speed (and sometimes even faster) than
  existing alternatives.",2018-12-17,Jochen Voss  (<https://orcid.org/0000-0002-2323-3814>),https://github.com/seehuhn/jvcoords,TRUE,https://github.com/seehuhn/jvcoords,947,0,1544380504
JWileymisc,"A collection of miscellaneous tools and functions,
    such as tools to generate descriptive statistics tables,
    format output, visualize relations among variables or check
    distributions.",2018-09-15,Joshua F. Wiley <jwiley.psych@gmail.com>,https://github.com/JWiley/JWileymisc,TRUE,https://github.com/jwiley/jwileymisc,6870,2,1551402261
jwutil,"This is a set of simple utilities for various data manipulation and testing tasks.
    The goal is to use core R tools well, without bringing in many
    dependencies. Main areas of interest are semi-automated data frame manipulation, such as
    converting factors in multiple binary indicator columns. There are testing
    functions which provide 'testthat' expectations to permute arguments to
    function calls. There are functions and data to test extreme numbers, dates,
    and bad input of various kinds which should allow testing failure and corner
    cases, which can be used for fuzzing your functions. The test suite has many examples of usage.",2018-06-11,Jack O. Wasey,https://github.com/jackwasey/jwutil,TRUE,https://github.com/jackwasey/jwutil,5796,0,1543789823
kableExtra,"Build complex HTML or 'LaTeX' tables using 'kable()' from 'knitr' 
    and the piping syntax from 'magrittr'. Function 'kable()' is a light weight 
    table generator coming from 'knitr'. This package simplifies the way to 
    manipulate the HTML or 'LaTeX' codes generated by 'kable()' and allows 
    users to construct complex tables and customize styles using a readable 
    syntax. ",2019-03-16,Hao Zhu  (<https://orcid.org/0000-0002-3386-6076>),"http://haozhu233.github.io/kableExtra/,
https://github.com/haozhu233/kableExtra",TRUE,https://github.com/haozhu233/kableextra,338167,304,1554443468
kamila,"Implements methods for clustering mixed-type data,
  specifically combinations of continuous and nominal data. Special attention
  is paid to the often-overlooked problem of equitably balancing the
  contribution of the continuous and categorical variables. This package
  implements KAMILA clustering, a novel method for clustering
  mixed-type data in the spirit of k-means clustering. It does not require
  dummy coding of variables, and is efficient enough to scale to rather large
  data sets. Also implemented is Modha-Spangler clustering, which uses a
  brute-force strategy to maximize the cluster separation simultaneously in the
  continuous and categorical variables. For more information, see Foss, Markatou,
  Ray, & Heching (2016) <doi:10.1007/s10994-016-5575-7> and Foss & Markatou
  (2018) <doi:10.18637/jss.v083.i13>.",2019-03-16,Alexander Foss,https://github.com/ahfoss/kamila,TRUE,https://github.com/ahfoss/kamila,7074,3,1552708181
kayadata,"Provides data for Kaya identity variables (population, gross 
             domestic product, primary energy consumption, and energy-related 
             CO2 emissions) for the world and for individual nations, and 
             utility functions for looking up data,  plotting trends of 
             Kaya variables, and plotting the fuel mix for a given country
             or region. The Kaya identity (Yoichi Kaya and Keiichi Yokobori, 
             ""Environment, Energy, and Economy: Strategies for Sustainability"" 
             (United Nations University Press, 1998) and 
             <https://en.wikipedia.org/wiki/Kaya_identity>) expresses a nation's 
             or region's greenhouse gas emissions in terms of its population, 
             per-capita Gross Domestic Product, the energy intensity of its 
             economy, and the carbon-intensity of its energy supply.",2019-03-22,Jonathan Gilligan  (<https://orcid.org/0000-0003-1375-6686>),https://github.com/jonathan-g/kayadata,TRUE,https://github.com/jonathan-g/kayadata,120,0,1553279921
kde1d,"Provides an efficient implementation of univariate local polynomial
    kernel density estimators that can handle bounded and discrete data. See 
    Geenens (2014) <arXiv:1303.4121>, 
    Geenens and Wang (2018) <arXiv:1602.04862>, 
    Nagler (2018a) <arXiv:1704.07457>, 
    Nagler (2018b) <arXiv:1705.05431>.",2018-05-28,Thomas Nagler,https://github.com/tnagler/kde1d,TRUE,https://github.com/tnagler/kde1d,5137,4,1538590346
kdevine,"Implements the vine copula based kernel density estimator of
    Nagler and Czado (2016) <doi:10.1016/j.jmva.2016.07.003>. The estimator does
    not suffer from the curse of dimensionality and is therefore well suited for
    high-dimensional applications.",2018-12-17,Thomas Nagler,https://github.com/tnagler/kdevine,TRUE,https://github.com/tnagler/kdevine,6010,7,1545243700
kdtools,"Provides various tools for working with multidimensional
  data in R and C++, including extremely fast nearest-neighbor- and range-
  queries without the overhead of linked tree nodes.",2018-04-26,Timothy Keitt,https://github.com/thk686/kdtools,TRUE,https://github.com/thk686/kdtools,2880,5,1550607552
kehra,"Collection of utility functions used in the KEHRA project (see http://www.brunel.ac.uk/ife/britishcouncil). It refers to the multidimensional analysis of air pollution, weather and health data.",2016-06-10,Claudia Vitolo,https://github.com/kehraProject/r_kehra,TRUE,https://github.com/kehraproject/r_kehra,5119,1,1550564305
keras,"Interface to 'Keras' <https://keras.io>, a high-level neural
  networks 'API'. 'Keras' was developed with a focus on enabling fast experimentation,
  supports both convolution based networks and recurrent networks (as well as
  combinations of the two), and runs seamlessly on both 'CPU' and 'GPU' devices.",2019-04-05,Daniel Falbel [ctb,https://keras.rstudio.com,TRUE,https://github.com/rstudio/keras,217517,530,1554515559
kerasformula,"Adds a high-level interface for 'keras' neural nets. kms() fits neural net and accepts R formulas to aid data munging and hyperparameter selection. kms() can optionally accept a compiled keras_sequential_model() from 'keras'. 
    kms() accepts a number of parameters (like loss and optimizer) and splits the data into (optionally sparse) test and training matrices. kms() facilitates setting advanced hyperparameters (e.g., regularization). kms() returns a single object with predictions, a confusion matrix, and function call details.",2018-08-23,Pete Mohanty,https://github.com/rdrr1990/kerasformula,TRUE,https://github.com/rdrr1990/kerasformula,5716,52,1536521476
kernelboot,"Smoothed bootstrap and functions for random generation from
             univariate and multivariate kernel densities. It does not
             estimate kernel densities.",2018-07-04,Tymoteusz Wolodzko,https://github.com/twolodzko/kernelboot,TRUE,https://github.com/twolodzko/kernelboot,8019,0,1540117094
KernelKnn,Extends the simple k-nearest neighbors algorithm by incorporating numerous kernel functions and a variety of distance metrics. The package takes advantage of 'RcppArmadillo' to speed up the calculation of distances between observations.,2018-01-16,Lampros Mouselimis <mouselimislampros@gmail.com>,https://github.com/mlampros/KernelKnn,TRUE,https://github.com/mlampros/kernelknn,15617,7,1551865880
KeyboardSimulator,Control your keyboard and mouse with R code by simulating key presses and mouse clicks. The input simulation is implemented with the Windows API.,2019-01-10,Jim Chen,https://github.com/ChiHangChen/KeyboardSimulator,TRUE,https://github.com/chihangchen/keyboardsimulator,9400,5,1547169899
keyholder,"Tools for keeping track of information, named ""keys"", about rows of
    data frame like objects. This is done by creating special attribute ""keys""
    which is updated after every change in rows (subsetting, ordering, etc.).
    This package is designed to work tightly with 'dplyr' package.",2018-12-01,Evgeni Chasnovski,"https://echasnovski.github.io/keyholder/,
https://github.com/echasnovski/keyholder/",TRUE,https://github.com/echasnovski/keyholder,3949,2,1543768974
keypress,"Wait for a single key press at the 'R' prompt.
    This works in terminals, but does not currently work
    in the 'Windows' 'GUI', the 'OS X' 'GUI' ('R.app'),
    in 'Emacs' 'ESS', in an 'Emacs' shell buffer or in
    'R Studio'. In these cases 'keypress' stops with an
    error message.",2017-03-02,Gábor Csárdi,https://github.com/gaborcsardi/keypress,TRUE,https://github.com/gaborcsardi/keypress,8655,12,1553680661
KFAS,"State space modelling is an efficient and flexible framework for 
    statistical inference of a broad class of time series and other data. KFAS 
    includes computationally efficient functions for Kalman filtering, smoothing, 
    forecasting, and simulation of multivariate exponential family state space models, 
    with observations from Gaussian, Poisson, binomial, negative binomial, and gamma 
    distributions. See the paper by Helske (2017) <doi:10.18637/jss.v078.i10> for details.",2019-02-03,Jouni Helske  (<https://orcid.org/0000-0001-7130-793X>),NA,TRUE,https://github.com/helske/kfas,124166,20,1549013059
khroma,"Colour schemes for archaeological data visualization. This package 
    provides Paul Tol's colour schemes and several thematic palettes (geologic 
    timescale, FAO soils, etc.) with scales for 'ggplot2'.",2019-02-24,Nicolas Frerebeau  (<https://orcid.org/0000-0001-5759-4944>),https://cran.r-project.org/package=khroma,TRUE,https://github.com/nfrerebeau/khroma,1786,3,1554034073
kitagawa,"Provides tools to calculate the theoretical hydrodynamic response
    of an aquifer undergoing harmonic straining or pressurization, or analyze
    measured responses. There are
    two classes of models here: (1) for sealed wells, based on the model of 
    Kitagawa et al (2011, <doi:10.1029/2010JB007794>), 
    and (2) for open wells, based on the models of
    Cooper et al (1965, <doi:10.1029/JZ070i016p03915>), 
    Hsieh et al (1987, <doi:10.1029/WR023i010p01824>), 
    Rojstaczer (1988, <doi:10.1029/JB093iB11p13619>), and 
    Liu et al (1989, <doi:10.1029/JB094iB07p09453>). These models treat 
    strain (or aquifer head) as an input to the
    physical system, and fluid-pressure (or water height) as the output. The
    applicable frequency band of these models is characteristic of seismic
    waves, atmospheric pressure fluctuations, and solid earth tides.",2018-09-14,Andrew J Barbour,https://github.com/abarbour/kitagawa,TRUE,https://github.com/abarbour/kitagawa,13136,2,1552078316
kiwisR,"A wrapper for querying 'WISKI' databases via the 'KiWIS' 'REST' API. 'WISKI' is an 'SQL' relational database 
  used for the collection and storage of water data developed by KISTERS and 'KiWIS' is a 'REST' service that provides
  access to 'WISKI' databases via HTTP requests (<https://water.kisters.de/en/technology-trends/kisters-and-open-data/>). 
  Contains a list of default databases (called 'hubs') and also allows users to provide their own 'KiWIS' URL. 
  Supports the entire query process- from metadata to specific time series values. All data is returned as tidy tibbles.",2019-03-10,Ryan Whaley,https://github.com/rywhale/kiwisR,TRUE,https://github.com/rywhale/kiwisr,264,3,1552305701
kknn,"Weighted k-Nearest Neighbors for Classification, Regression and Clustering.",2016-03-26,Klaus Schliep,https://github.com/KlausVigo/kknn,TRUE,https://github.com/klausvigo/kknn,190394,13,1553107233
kmer,"Contains tools for rapidly computing distance matrices 
    and clustering large sequence datasets using fast alignment-free 
    k-mer counting and recursive k-means partitioning. 
    See Vinga and Almeida (2003) <doi:10.1093/bioinformatics/btg005> 
    for a review of k-mer counting methods and applications for 
    biological sequence analysis.",2019-03-15,Shaun Wilkinson,http://github.com/shaunpwilkinson/kmer,TRUE,https://github.com/shaunpwilkinson/kmer,7602,6,1552617626
kmeRs,"Contains tools to calculate similarity score matrix for DNA k-mers. The pairwise
            similarity score is calculated using PAM or BLOSUM substitution matrix. The 
            results are evaluated by similarity score calculated by Needleman-Wunsch 
            (1970) <doi:10.1016/0022-2836(70)90057-4> global or Smith-Waterman 
            (1981) <doi:10.1016/0022-2836(81)90087-5> local alignment. Higher similarity
            score indicates more similar sequences for BLOSUM and less similar sequences
            for PAM matrix; 30, 40, 70, 120, 250 and 62, 45, 50, 62, 80, 100 matrix 
            versions are available for PAM and BLOSUM, respectively. ",2018-11-03,Rafal Urniaz  (<https://orcid.org/0000-0003-0192-2165>),https://rafalurniaz.github.io/kmeRs/,TRUE,https://github.com/rafalurniaz/kmers,1356,0,1552860062
kmi,"Performs a Kaplan-Meier multiple imputation to recover the missing potential censoring information from competing risks events, so that standard right-censored methods could be applied to the imputed data sets to perform analyses of the cumulative incidence functions (Allignol and Beyersmann, 2010 <doi:10.1093/biostatistics/kxq018>).",2018-05-22,Arthur Allignol <arthur.allignol@gmail.com>,https://github.com/aallignol/kmi,TRUE,https://github.com/aallignol/kmi,25897,1,1527016121
knitr,"Provides a general-purpose tool for dynamic report generation in R
    using Literate Programming techniques.",2019-03-08,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://yihui.name/knitr/,TRUE,https://github.com/yihui/knitr,11039074,1755,1554329283
knnp,"Two main functionalities are provided. One of them is predicting values with 
    k-nearest neighbors algorithm and the other is optimizing the parameters k and d of the algorithm.
    These are carried out in parallel using multiple threads.",2018-07-01,Javier Berdecio Trigueros,https://github.com/Dani-Basta/TFG,TRUE,https://github.com/dani-basta/tfg,2205,3,1551691979
Knoema,"Using this package, users can access to the largest collection of public data and statistics on the Internet featuring about 2.5 billion time series from thousands of sources collected in 'Knoema' repository and use rich R calculations in order to analyze the data. Because data in 'Knoema' is time series data, 'Knoema' function offers data in a number of formats usable in R such as 'ts', 'xts' or 'zoo'. For more information about 'Knoema' API go to <https://knoema.com/dev/docs>.",2018-05-11,Pavel Pimenov,https://github.com/Knoema/knoema-r-driver,TRUE,https://github.com/knoema/knoema-r-driver,6049,1,1534310679
knor,The k-means 'NUMA' Optimized Routine library or 'knor' is a highly optimized and fast library for computing k-means in parallel with accelerations for Non-Uniform Memory Access ('NUMA') architectures.,2018-09-13,Disa Mhembere,https://github.com/neurodata/knorR,TRUE,https://github.com/neurodata/knorr,7500,6,1550642303
komadown,"R Markdown templates based on the 'KOMA-Script' classes for
  LaTeX, additionally offering cross-referencing via the 'bookdown' package.",2018-04-23,Johan Larsson  (<https://orcid.org/0000-0002-4029-5945>),https://github.com/jolars/komadown,TRUE,https://github.com/jolars/komadown,3423,2,1553379749
komaletter,"An R Markdown template for writing beautiful yet versatile letters,
  using the 'KOMA-Script' letter class 'scrlttr2' and an adaptation of the
  'pandoc-letter' template. 'scrlttr2' provides layouts for many different
  window envelope types and the possibility to define your own.",2018-10-12,Robert Nuske  (<https://orcid.org/0000-0001-9773-2061>),https://github.com/rnuske/komaletter,TRUE,https://github.com/rnuske/komaletter,2935,8,1554120119
konfound,"Statistical methods that quantify the conditions necessary to alter
    inferences, also known as sensitivity analysis, are becoming increasingly
    important to a variety of quantitative sciences. A series of recent works,
    including Frank (2000) <doi:10.1177/0049124100029002001> and Frank et al.
    (2013) <doi:10.3102/0162373713493129> extend previous sensitivity analyses
    by considering the characteristics of omitted variables or unobserved cases
    that would change an inference if such variables or cases were observed. These
    analyses generate statements such as ""an omitted variable would have to be
    correlated at xx with the predictor of interest (e.g., treatment) and outcome
    to invalidate an inference of a treatment effect"". Or ""one would have to replace
    pp percent of the observed data with null hypothesis cases to invalidate the
    inference"". We implement these recent developments of sensitivity analysis and
    provide modules to calculate these two robustness indices and generate such
    statements in R. In particular, the functions konfound(), pkonfound() and 
    mkonfound() allow users to calculate the robustness of inferences for a user's 
    own model, a single published study and multiple studies respectively.",2019-01-21,Joshua M Rosenberg,https://github.com/jrosen48/konfound,TRUE,https://github.com/jrosen48/konfound,2666,1,1553801470
KoNLP,"POS Tagger and Morphological Analyzer for Korean text based research. It provides tools for corpus linguistics research such as Keystroke converter, Hangul automata, Concordance, and Mutual Information. It also provides a convenient interface for users to apply, edit and add morphological dictionary selectively. ",2016-12-15,Heewon Jeon,https://github.com/haven-jeon/KoNLP,TRUE,https://github.com/haven-jeon/konlp,405168,116,1531443478
koRpus,"A set of tools to analyze texts. Includes, amongst others,
        functions for automatic language detection, hyphenation,
        several indices of lexical diversity (e.g., type token ratio,
        HD-D/vocd-D, MTLD) and readability (e.g., Flesch, SMOG, LIX,
        Dale-Chall). Basic import functions for language corpora are
        also provided, to enable frequency analyses (supports Celex and
        Leipzig Corpora Collection file formats) and measures like
        tf-idf. Note: For full functionality a local installation of
        TreeTagger is recommended. It is also recommended to not load
        this package directly, but by loading one of the available
        language support packages from the 'l10n' repository
        <https://undocumeantit.github.io/repos/l10n>. 'koRpus' also
        includes a plugin for the R GUI and IDE RKWard, providing
        graphical dialogs for its basic features. The respective R
        package 'rkward' cannot be installed directly from a
        repository, as it is a part of RKWard. To make full use of this
        feature, please install RKWard from <https://rkward.kde.org>
        (plugins are detected automatically). Due to some restrictions
        on CRAN, the full package sources are only available from the
        project homepage. To ask for help, report bugs, request
        features, or discuss the development of the package, please
        subscribe to the koRpus-dev mailing list
        (<http://korpusml.reaktanz.de>).",2018-10-28,Meik Michalke,https://reaktanz.de/?c=hacking&s=koRpus,TRUE,https://github.com/undocumeantit/korpus,108401,23,1540724245
KRIG,"Implements different methods for spatial statistics, in particular focused in
    Kriging based models. We count with different implemented models, simple, ordinary and 
    universal forms of Kriging, co-Kriging and regression Kriging models. Includes, multivariate 
    sensitivity analysis under an approximation designed over reproducing kernel Hilbert spaces and 
    computation of Sobol indexes under this framework.",2018-01-30,Pedro Guarderas,https://github.com/pedroguarderas/KRIG,TRUE,https://github.com/pedroguarderas/krig,2601,0,1536068905
KScorrect,"Implements the Lilliefors-corrected Kolmogorov-Smirnov test for use
    in goodness-of-fit tests, suitable when population parameters are unknown and
    must be estimated by sample statistics. P-values are estimated by simulation.
    Can be used with a variety of continuous distributions, including normal,
    lognormal, univariate mixtures of normals, uniform, loguniform, exponential,
    gamma, and Weibull distributions. Functions to generate random numbers and
    calculate density, distribution, and quantile functions are provided for use
    with the log uniform and mixture distributions.",2018-08-14,Phil Novack-Gottshall,https://github.com/pnovack-gottshall/KScorrect,TRUE,https://github.com/pnovack-gottshall/kscorrect,9350,2,1546697018
KSgeneral,"Computes a p-value of the one-sample two-sided (or one-sided, as a special case) Kolmogorov-Smirnov (KS) statistic, for any fixed critical level, and an arbitrary, possibly large sample size for a pre-specified purely discrete, mixed or continuous cumulative distribution function (cdf) under the null hypothesis. If a data sample is supplied, 'KSgeneral' computes the p-value corresponding to the value of the KS test statistic computed based on the user provided data sample. The package 'KSgeneral' implements a novel, accurate and efficient method named Exact-KS-FFT, expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using Fast Fourier Transform (FFT). The package can also be used to compute and plot the complementary cdf of the KS statistic which is known to depend on the hypothesized distribution when the latter is discontinuous (i.e. purely discrete or mixed). ",2018-05-14,Dimitrina S. Dimitrova <D.Dimitrova@city.ac.uk>,https://github.com/raymondtsr/KSgeneral,TRUE,https://github.com/raymondtsr/ksgeneral,2869,0,1526469738
kvh,"The format KVH is a lightweight format that can be read/written both by humans and machines.
   It can be useful in situations where XML or alike formats seem to be an overkill.
   We provide an ability to parse KVH files in R pretty fast due to 'Rcpp' use.",2018-06-15,Serguei Sokol,http://serguei.sokol.free.fr/kvh-format/,TRUE,https://github.com/sgsokol/kvh,3514,0,1529068813
kwb.hantush,"Calculation groundwater mounding beneath an infiltration basin based on the Hantush (1967) equation (http://doi.org/10.1029/WR003i001p00227). The correct implementation is shown with a verification example based on a USGS report (page 25, http://pubs.usgs.gov/sir/2010/5102/support/sir2010-5102.pdf).",2015-06-03,Michael Rustler,http://kwb-r.github.io/kwb.hantush/,TRUE,https://github.com/kwb-r/kwb.hantush,8276,0,1544020633
labelled,"Work with labelled data imported from 'SPSS'
    or 'Stata' with 'haven' or 'foreign'. This package
    provides useful functions to deal with ""haven_labelled"" and
    ""haven_labelled_spss"" classes introduced by 'haven' package.",2019-02-25,Joseph Larmarange  (<https://orcid.org/0000-0001-7097-700X>),https://github.com/larmarange/labelled,TRUE,https://github.com/larmarange/labelled,399668,21,1552925272
LaF,"Methods for fast access to large ASCII files.  Currently the
    following file formats are supported: comma separated format (CSV) and fixed
    width format. It is assumed that the files are too large to fit into memory,
    although the package can also be used to efficiently access files that do
    fit into memory. Methods are provided to access and process files blockwise.
    Furthermore, an opened file can be accessed as one would an ordinary
    data.frame. The LaF vignette gives an overview of the functionality
    provided.",2017-11-20,Jan van der Laan,https://github.com/djvanderlaan/LaF,TRUE,https://github.com/djvanderlaan/laf,78680,43,1539843149
LAGOSNE,"Client for programmatic access to the Lake
    Multi-scaled Geospatial and Temporal database <https://lagoslakes.org>, with functions
    for accessing lake water quality and ecological context data for the US.",2019-01-22,Joseph Stachelek  (<https://orcid.org/0000-0002-5924-2464>),https://github.com/cont-limno/LAGOSNE,TRUE,https://github.com/cont-limno/lagosne,4269,5,1552338106
lakemorpho,"Lake morphometry metrics are used by limnologists to understand,
    among other things, the ecological processes in a lake. Traditionally, these
    metrics are calculated by hand, with planimeters, and increasingly with
    commercial GIS products. All of these methods work; however, they are either
    outdated, difficult to reproduce, or require expensive licenses to use. The
    'lakemorpho' package provides the tools to calculate a typical suite
    of these metrics from an input elevation model and lake polygon. The metrics
    currently supported are: fetch, major axis, minor axis, major/minor axis 
    ratio, maximum length, maximum width, mean width, maximum depth, mean depth, 
    shoreline development, shoreline length, surface area, and volume.",2018-02-11,Jeffrey W. Hollister,http://www.github.com/jhollist/lakemorpho,TRUE,https://github.com/jhollist/lakemorpho,11684,3,1541598628
LAM,"
    Includes some procedures for latent variable modeling with a 
    particular focus on multilevel data.
    The 'LAM' package contains mean and covariance structure modelling
    for multivariate normally distributed data (mlnormal(); Longford, 1987;
    <doi:10.1093/biomet/74.4.817>), a general Metropolis-Hastings algorithm 
    (amh(); Roberts & Rosenthal, 2001, <doi:10.1214/ss/1015346320>) and 
    penalized maximum likelihood estimation (pmle(); Cole, Chu & Greenland, 
    2014; <doi:10.1093/aje/kwt245>).",2018-06-07,Alexander Robitzsch,https://github.com/alexanderrobitzsch/LAM,TRUE,https://github.com/alexanderrobitzsch/lam,4865,2,1542979801
landscapemetrics,"Calculates landscape metrics for categorical landscape patterns in 
    a tidy workflow. 'landscapemetrics' reimplements the most common metrics from
    'FRAGSTATS' (<https://www.umass.edu/landeco/research/fragstats/fragstats.html>) 
    and new ones from the current literature on landscape metrics.
    This package supports 'raster' spatial objects and takes 
    RasterLayer, RasterStacks, RasterBricks or lists of RasterLayer from the
    'raster' package as input arguments. It further provides utility functions
    to visualize patches, select metrics and building blocks to develop new 
    metrics.",2019-03-15,"Maximillian H.K. Hesselbarth 
    (<https://orcid.org/0000-0003-1125-9918>)",https://r-spatialecology.github.io/landscapemetrics/,TRUE,https://github.com/r-spatialecology/landscapemetrics,5619,85,1554215303
landscapetools,"Provides utility functions for some of the less-glamorous tasks involved
    in landscape analysis. It includes functions to coerce raster data to the
    common tibble format and vice versa, it helps with flexible reclassification
    tasks of raster data and it provides a function to merge multiple raster.
    Furthermore, 'landscapetools' helps landscape scientists to visualize their
    data by providing optional themes and utility functions to plot single
    landscapes, rasterstacks, -bricks and lists of raster.",2019-02-25,Marco Sciaini  (<https://orcid.org/0000-0002-3042-5435>),https://ropensci.github.io/landscapetools/,TRUE,https://github.com/ropensci/landscapetools,4150,37,1551131901
languagelayeR,"Improve your text analysis with languagelayer
        <https://languagelayer.com>, a powerful language detection
        API.",2019-02-12,Colin FAY,https://github.com/ColinFay/languagelayer,TRUE,https://github.com/colinfay/languagelayer,6216,5,1549959202
languageserver,An implementation of the Language Server Protocol for R. The Language Server protocol is used by an editor client to integrate features like auto completion. See <https://microsoft.github.io/language-server-protocol> for details.,2019-03-28,Randy Lai,https://github.com/REditorSupport/languageserver,TRUE,https://github.com/reditorsupport/languageserver,29317,105,1553745216
LaplacesDemon,Provides a complete environment for Bayesian inference using a variety of different samplers (see ?LaplacesDemon for an overview). The README describes the history of the package development process.,2018-06-30,Henrik Singmann,https://github.com/LaplacesDemonR/LaplacesDemon,TRUE,https://github.com/laplacesdemonr/laplacesdemon,63157,36,1529753400
latentnet,Fit and simulate latent position and cluster models for statistical networks. ,2018-08-25,Pavel N. Krivitsky  (<https://orcid.org/0000-0002-9101-3362>),http://www.statnet.org,TRUE,https://github.com/statnet/latentnet,101395,9,1535204809
later,"Executes arbitrary R or C functions some time after the current
    time, after the R execution stack has emptied.",2019-02-11,Joe Cheng,https://github.com/r-lib/later,TRUE,https://github.com/r-lib/later,3280013,64,1549923236
latex2exp,"Parses and converts LaTeX math formulas to R's plotmath
    expressions, used to enter mathematical formulas and symbols to be rendered as
    text, axis labels, etc. throughout R's plotting system.",2015-11-30,Stefano Meschiari,http://github.com/stefano-meschiari/latex2exp,TRUE,https://github.com/stefano-meschiari/latex2exp,75484,124,1540151958
latte,"Back-end connections to 'LattE' (<https://www.math.ucdavis.edu/~latte>) 
	for counting lattice points and integration inside convex polytopes and 
	'4ti2' (<http://www.4ti2.de/>) for algebraic, geometric, and combinatorial 
	problems on linear spaces and front-end tools facilitating their use in the 
	'R' ecosystem.",2019-03-25,David Kahle,https://github.com/dkahle/latte,TRUE,https://github.com/dkahle/latte,204,1,1554313082
lattice,"A powerful and elegant high-level data visualization
  system inspired by Trellis graphics, with an emphasis on
  multivariate data. Lattice is sufficient for typical graphics needs,
  and is also flexible enough to handle most nonstandard requirements.
  See ?Lattice for an introduction.",2018-11-04,Deepayan Sarkar <deepayan.sarkar@r-project.org>,http://lattice.r-forge.r-project.org/,TRUE,https://github.com/deepayan/lattice,2825504,22,1541410692
lava,"A general implementation of Structural Equation Models
	with latent variables (MLE, 2SLS, and composite likelihood
	estimators) with both continuous, censored, and ordinal
	outcomes (Holst and Budtz-Joergensen (2013) <doi:10.1007/s00180-012-0344-y>).
	Mixture latent variable models and non-linear latent variable models
	(Holst and Budtz-Joergensen (2019) <doi:10.1093/biostatistics/kxy082>).
	The package also provides methods for graph exploration (d-separation,
	back-door criterion), simulation of general non-linear latent variable
	models, and estimation of influence functions for a broad range of
	statistical models. ",2019-02-12,Klaus K. Holst,https://github.com/kkholst/lava,TRUE,https://github.com/kkholst/lava,1566303,24,1549954438
lavaanPlot,"Plots path diagrams from models in lavaan using the plotting
    functionality from the DiagrammeR package. DiagrammeR provides nice path diagrams 
    via Graphviz, and these functions make it easy to generate these diagrams from a
    lavaan path model without having to write the DOT language graph specification.",2018-04-25,Alex Lishinski,https://github.com/alishinski/lavaanPlot,TRUE,https://github.com/alishinski/lavaanplot,8092,13,1546963995
lavaSearch2,"Tools for model specification in the latent variable framework
    (add-on to the 'lava' package). The package contains three main functionalities:
    Wald tests/F-tests with improved control of the type 1 error in small samples,
    adjustment for multiple comparisons when searching for local dependencies,
    and adjustment for multiple comparisons when doing inference for multiple latent variable models. ",2019-03-18,Brice Ozenne  (<https://orcid.org/0000-0001-9694-2956>),https://github.com/bozenne/lavaSearch2,TRUE,https://github.com/bozenne/lavasearch2,5858,0,1554387363
lawn,"Client for 'Turfjs' (<http://turfjs.org>) for
    'geospatial' analysis. The package revolves around using 'GeoJSON'
    data. Functions are included for creating 'GeoJSON' data objects,
    measuring aspects of 'GeoJSON', and combining, transforming,
    and creating random 'GeoJSON' data objects.",2019-02-01,Scott Chamberlain,https://github.com/ropensci/lawn,TRUE,https://github.com/ropensci/lawn,19115,57,1549042160
lazyrmd,"An R Markdown html document format that provides the ability to lazily
    load plot outputs as the user scrolls over them.  This is useful for large R
    Markdown documents with many plots, as it allows for a fast initial page load and
    defers loading of individual graphics to the time that the user navigates near them.",2018-08-19,Ryan Hafen,http://github.com/hafen/lazyrmd,TRUE,https://github.com/hafen/lazyrmd,24473,38,1534807596
LBSPR,"Simulate expected equilibrium length composition, yield-per-recruit, and
    the spawning potential ratio (SPR) using the length-based SPR (LBSPR) model. Fit the LBSPR
    model to length data to estimate  selectivity, relative apical fishing mortality, and
    the spawning potential ratio for data-limited fisheries.
    See Hordyk et al (2016) <doi:10.1139/cjfas-2015-0422> for more information about the
    LBSPR assessment method.",2019-03-12,Adrian Hordyk,https://github.com/AdrianHordyk/LBSPR,TRUE,https://github.com/adrianhordyk/lbspr,7901,2,1552347189
lconnect,"Provides functions to upload vectorial data and derive landscape
    connectivity metrics in habitat or matrix systems. Additionally, includes an 
    approach to assess individual patch contribution to the overall landscape 
    connectivity, enabling the prioritization of habitat patches. The computation
    of landscape connectivity and patch importance are very useful in Landscape 
    Ecology research. The metrics available are: number of components, number of 
    links, size of the largest component, mean size of components, class coincidence
    probability, landscape coincidence probability, characteristic path length, 
    expected cluster size, area-weighted flux and integral index of connectivity.
    Pascual-Hortal, L., and Saura, S. (2006) <doi:10.1007/s10980-006-0013-z>
    Urban, D., and Keitt, T. (2001) <doi:10.2307/2679983>
    Laita, A., Kotiaho, J., Monkkonen, M. (2011) <doi:10.1007/s10980-011-9620-4>.",2019-04-05,Frederico Mestre,NA,TRUE,https://github.com/fmestre1/lconnect,0,0,1554190536
ldatuning,"For this first version only metrics to estimate the best fitting
    number of topics are implemented.",2016-10-24,Murzintcev Nikita,https://github.com/nikita-moor/ldatuning,TRUE,https://github.com/nikita-moor/ldatuning,20830,28,1548678195
LDAvis,"Tools to create an interactive web-based visualization of a
    topic model that has been fit to a corpus of text data using
    Latent Dirichlet Allocation (LDA). Given the estimated parameters of
    the topic model, it computes various summary statistics as input to
    an interactive visualization built with D3.js that is accessed via
    a browser. The goal is to help users interpret the topics in their
    LDA topic model.",2015-10-24,Carson Sievert,https://github.com/cpsievert/LDAvis,TRUE,https://github.com/cpsievert/ldavis,45094,366,1524679979
leaflet,"Create and customize interactive maps using the 'Leaflet'
    JavaScript library and the 'htmlwidgets' package. These maps can be used
    directly from the R console, from 'RStudio', in Shiny applications and R Markdown
    documents.",2018-08-27,Joe Cheng,http://rstudio.github.io/leaflet/,TRUE,https://github.com/rstudio/leaflet,819175,526,1554144832
leaflet.esri,"An add-on package to the 'leaflet' package, which provides bindings for 'ESRI' services. This package allows a user to add 'ESRI' provided services such as 'MapService', 'ImageMapService', 'TiledMapService' etc. to a 'leaflet' map.",2018-04-23,Bhaskar Karambelkar,"https://github.com/bhaskarvk/leaflet.esri,https://bhaskarvk.github.io/leaflet.esri/",TRUE,https://github.com/bhaskarvk/leaflet.esri,6334,25,1524492222
leaflet.extras,"The 'leaflet' JavaScript library provides many plugins some of which
    are available in the core 'leaflet' package, but there are many more. It is not
    possible to support them all in the core 'leaflet' package. This package serves
    as an add-on to the 'leaflet' package by providing extra functionality via 'leaflet'
    plugins.",2018-04-21,Bhaskar Karambelkar,"https://github.com/bhaskarvk/leaflet.extras,
https://bhaskarvk.github.io/leaflet.extras/",TRUE,https://github.com/bhaskarvk/leaflet.extras,51638,146,1524492501
leaflet.opacity,"
    Extends the 'leaflet' R package with the 'Leaflet.OpacityControls' JavaScript 
    plugin. Adds controls to the leaflet map for adjusting the 
    opacity of a layer.",2018-11-29,Marc Becker  (R interface),NA,TRUE,https://github.com/be-marc/leaflet.opacity,1100,3,1542636089
leafletR,Display your spatial data on interactive web-maps using the open-source JavaScript library Leaflet. 'leafletR' provides basic web-mapping functionality to combine vector data and online map tiles from different sources. See <http://leafletjs.com> for more information on Leaflet.,2016-04-01,Christian Graul,https://github.com/chgrl/leafletR,TRUE,https://github.com/chgrl/leafletr,51815,56,1532424517
leafpm,"A collection of tools for interactive manipulation of (spatial) data 
    layers on leaflet web maps. Tools include editing of existing layers, creation 
    of new layers through drawing of shapes (points, lines, polygons), deletion 
    of shapes as well as cutting holes into existing shapes. Provides control over 
    options to e.g. prevent self-intersection of polygons and lines or to enable/disable 
    snapping to align shapes.",2019-03-13,Kenton Russell,https://github.com/r-spatial/leafpm,TRUE,https://github.com/r-spatial/leafpm,1606,5,1552141123
leafsync,"Create small multiples of several leaflet web maps with (optional) 
    synchronised panning and zooming control. When syncing is enabled all maps 
    respond to mouse actions on one map. This allows side-by-side comparisons
    of different attributes of the same geometries. Syncing can be adjusted
    so that any combination of maps can be synchronised.",2019-03-05,Tim Appelhans,https://github.com/r-spatial/leafsync,TRUE,https://github.com/r-spatial/leafsync,398,7,1551986766
leanpubr,"Provides access to the 'Leanpub' API
    <https://leanpub.com/help/api> for gathering information about 
    publications and submissions to the 'Leanpub' platform.",2018-08-16,John Muschelli,https://github.com/muschellij2/leanpubr,TRUE,https://github.com/muschellij2/leanpubr,1763,0,1540929565
learnPopGen,"Conducts various numerical analyses and simulations in population genetics and evolutionary theory, primarily for the purpose of teaching (and learning about) key concepts in population & quantitative genetics, and evolutionary theory.",2018-10-12,Liam J. Revell,http://github.com/liamrevell/PopGen,TRUE,https://github.com/liamrevell/popgen,1709,8,1550702755
learnr,"Create interactive tutorials using R Markdown. Use a combination 
  of narrative, figures, videos, exercises, and quizzes to create self-paced
  tutorials for learning about R and R packages.",2018-06-29,Barret Schloerke,https://rstudio.github.io/learnr/,TRUE,https://github.com/rstudio/learnr,33975,245,1554488290
ledger,"Utilities for querying plain text accounting files from 'Ledger', 'HLedger', and 'Beancount'.",2019-03-22,Trevor L Davis,https://github.com/trevorld/r-ledger,TRUE,https://github.com/trevorld/r-ledger,1847,11,1553279438
legocolors,"Provides a dataset containing several color naming conventions established by multiple sources, along with associated color metadata.
    The package also provides related helper functions for mapping among the different Lego color naming conventions and between Lego colors, hex colors, and 'R' color names.
    The functions include nearest color matching based on Euclidean distance in RGB space. 
    Naming conventions for color mapping include those from 'BrickLink' (<https://www.bricklink.com>), 'The Lego Group' (<https://www.lego.com>), 'LDraw' (<https://www.ldraw.org/>), and 'Peeron' (<http://www.peeron.com/>).",2019-03-24,Matthew Leonawicz,https://github.com/leonawicz/legocolors,TRUE,https://github.com/leonawicz/legocolors,254,0,1553530548
leiden,"Implements the 'Python leidenalg' module to be called in R.
    Enables clustering using the leiden algorithm for partition a graph into communities.
    See the 'Python' repository for more details: <https://github.com/vtraag/leidenalg>
    Traag et al (2018) From Louvain to Leiden: guaranteeing well-connected communities. <arXiv:1810.08473>.",2019-02-11,Tom Kelly <tom.kelly@riken.jp>,https://github.com/TomKellyGenetics/leiden,TRUE,https://github.com/tomkellygenetics/leiden,526,8,1552635855
lemon,"Functions for working with legends and axis lines of 'ggplot2',
    facets that repeat axis lines on all panels, and some 'knitr' extensions.",2019-01-08,Stefan McKinnon Edwards,https://github.com/stefanedwards/lemon,TRUE,https://github.com/stefanedwards/lemon,16729,89,1546414630
LendingClub,"Functions to access Lending Club's API and assist the investor manage 
	their account. Lending Club is a peer-to-peer lending service where loans are 
	broken up into $25 notes that investors buy with the expectation of earning a 
	return on the interest. You can learn more about the API here:
	<http://www.lendingclub.com/developers/lc-api.action>.",2018-06-05,Ryan Kuhn  (<https://orcid.org/0000-0001-6827-3492>),https://github.com/kuhnrl30/LendingClub,TRUE,https://github.com/kuhnrl30/lendingclub,9179,3,1534225065
lenses,"Provides tools for creating and using lenses to simplify data manipulation. Lenses are composable getter/setter pairs for working with data in a purely functional way. Inspired by the 'Haskell' library 'lens' (Kmett, 2012) <https://hackage.haskell.org/package/lens>. For a fairly comprehensive (and highly technical) history of lenses please see the 'lens' wiki <https://github.com/ekmett/lens/wiki/History-of-Lenses>.",2019-03-06,Chris Hammill,"http://cfhammill.github.io/lenses,
https://github.com/cfhammill/lenses",TRUE,https://github.com/cfhammill/lenses,286,12,1553107500
letsR,"R functions for handling, processing, and analyzing geographic
    data on species' distributions and environmental variables.",2018-01-24,Bruno Vilela & Fabricio Villalobos,"http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12401/abstract,
https://github.com/macroecology/letsR",TRUE,https://github.com/macroecology/letsr,17791,11,1554458667
lexicon,"A collection of lexical hash tables, dictionaries, and word lists.",2019-03-21,Tyler Rinker,https://github.com/trinker/lexicon,TRUE,https://github.com/trinker/lexicon,85225,50,1553100601
LexisNexisTools,"My PhD supervisor once told me that everyone doing newspaper
    analysis starts by writing code to read in files from the 'LexisNexis' newspaper
    archive (retrieved e.g., from <http://www.nexis.com/> or any of the partner
    sites). However, while this is a nice exercise I do recommend, not everyone has
    the time. This package takes TXT files downloaded from the newspaper archive of
    'LexisNexis', reads them into R and offers functions for further processing.",2019-01-27,Johannes Gruber,https://github.com/JBGruber/LexisNexisTools,TRUE,https://github.com/jbgruber/lexisnexistools,3321,25,1552995581
lexRankr,An R implementation of the LexRank algorithm described by G. Erkan and D. R. Radev (2004) <DOI:10.1613/jair.1523>.,2019-03-17,Adam Spannbauer,https://github.com/AdamSpannbauer/lexRankr/,TRUE,https://github.com/adamspannbauer/lexrankr,9614,15,1552855119
lfe,"Transforms away factors with many levels prior to doing an OLS. 
  Useful for estimating linear models with multiple group fixed effects, and for
  estimating linear models which uses factors with many levels as pure control variables.
  Includes support for instrumental variables, conditional F statistics for weak instruments,
  robust and multi-way clustered standard errors, as well as limited mobility bias correction.",2019-03-27,Simen Gaure  (<https://orcid.org/0000-0001-7251-8747>),https://github.com/sgaure/lfe,TRUE,https://github.com/sgaure/lfe,140763,10,1553860827
lfstat,"The ""Manual on Low-flow Estimation and Prediction"", published by
    the World Meteorological Organisation (WMO), gives a comprehensive summary on
    how to analyse stream flow data focusing on low-flows. This packages provides
    functions to compute the described statistics and produces plots similar to the
    ones in the manual.",2016-08-24,Daniel Koffler,NA,TRUE,https://github.com/mundl/lfstat,26526,4,1530006096
lgr,"A flexible, feature-rich yet light-weight logging
    framework based on 'R6' classes. It supports hierarchical loggers,
    custom log levels, arbitrary data fields in log events, logging to
    plaintext, 'JSON', memory buffers, and databases, as well as email and
    push notifications. For a full list of features with examples please
    refer to the package vignette.",2019-03-25,Stefan Fleck  (<https://orcid.org/0000-0003-3344-9851>),https://github.com/s-fleck/lgr,TRUE,https://github.com/s-fleck/lgr,689,24,1554468828
lhs,Provides a number of methods for creating and augmenting Latin Hypercube Samples.,2019-02-03,Rob Carnell,https://github.com/bertcarnell/lhs,TRUE,https://github.com/bertcarnell/lhs,155618,1,1551291561
liayson,"Given an RNA-seq derived cell-by-gene matrix and an DNA-seq derived copy number segmentation, LIAYSON predicts the number of clones present in a tumor, their size, the copy number profile of each clone and the clone membership of each single cell.",2018-12-21,Noemi Andor,"https://github.com/noemiandor/liayson,
https://groups.google.com/d/forum/liayson",TRUE,https://github.com/noemiandor/liayson,865,1,1544575086
librarian,"Automatically install, update, and load 'CRAN', 'GitHub', and 'Bioconductor' 
    packages in a single function call. By accepting bare unquoted names for packages, 
    it's easy to add or remove packages from the list.",2019-03-13,Desi Quintans,https://github.com/DesiQuintans/librarian,TRUE,https://github.com/desiquintans/librarian,2977,20,1554530100
lidR,"Airborne LiDAR (Light Detection and Ranging) interface for data
    manipulation and visualization. Read/write 'las' and 'laz' files, computation
    of metrics in area based approach, point filtering, artificial point reduction,
    classification from geographic data, normalization, individual tree segmentation
    and other manipulations.",2019-03-03,Jean-Romain Roussel,https://github.com/Jean-Romain/lidR,TRUE,https://github.com/jean-romain/lidr,27872,143,1554551219
lifecontingencies,"Classes and methods that allow the user to manage life table,
    actuarial tables (also multiple decrements tables). Moreover, functions to easily
    perform demographic, financial and actuarial mathematics on life contingencies
    insurances calculations are contained therein.",2019-03-05,"Giorgio Alfredo Spedicato 
    (<https://orcid.org/0000-0002-0315-8888>)",http://github.com/spedygiorgio/lifecontingencies,TRUE,https://github.com/spedygiorgio/lifecontingencies,52486,22,1551825637
liftr,Persistent reproducible reporting by containerization of R Markdown documents.,2018-05-14,Nan Xiao  (<https://orcid.org/0000-0002-0250-5673>),"https://nanx.me/liftr/, https://github.com/road2stat/liftr",TRUE,https://github.com/road2stat/liftr,16265,124,1552879082
liger,"Gene Set Enrichment Analysis (GSEA) is a computational method that determines whether an a priori defined set of genes shows statistically significant, concordant differences between two biological states. The original algorithm is detailed in Subramanian et al. with 'Java' implementations available through the Broad Institute (Subramanian et al. 2005 <doi:10.1073/pnas.0506580102>). The 'liger' package provides a lightweight R implementation of this enrichment test on a list of values (Fan et al., 2017 <doi:10.5281/zenodo.887386>). Given a list of values, such as p-values or log-fold changes derived from differential expression analysis or other analyses comparing biological states, this package enables you to test a priori defined set of genes for enrichment to enable interpretability of highly significant or high fold-change genes.",2019-01-03,Jean Fan  (<https://orcid.org/0000-0002-0212-5451>),https://github.com/JEFworks/liger,TRUE,https://github.com/jefworks/liger,2394,29,1553797112
likert,"An approach to analyzing Likert response items, with an emphasis on visualizations. 
    The stacked bar plot is the preferred method for presenting Likert results. Tabular results
    are also implemented along with density plots to assist researchers in determining whether 
    Likert responses can be used quantitatively instead of qualitatively. See the likert(), 
    summary.likert(), and plot.likert() functions to get started.",2016-12-31,Jason Bryer <jason@bryer.org>,"http://jason.bryer.org/likert, http://github.com/jbryer/likert",TRUE,https://github.com/jbryer/likert,87593,160,1554297794
lilikoi,"Computes the pathway deregulation score for a given set of metabolites, selects the pathways with the highest mutual information and then uses them to build a classifier. F. Alakwaa, S. Huang, and L. Garmire (2018) <doi:10.1101/283408>.",2018-07-30,Fadhl Alakwaa,https://github.com/lanagarmire/lilikoi,TRUE,https://github.com/lanagarmire/lilikoi,1832,3,1535591759
lime,"When building complex models, it is often difficult to explain why
    the model should be trusted. While global measures such as accuracy are
    useful, they cannot be used for explaining why a model made a specific
    prediction. 'lime' (a port of the 'lime' 'Python' package) is a method for
    explaining the outcome of black box models by fitting a local model around
    the point in question an perturbations of this point. The approach is
    described in more detail in the article by Ribeiro et al. (2016) 
    <arXiv:1602.04938>.",2018-11-21,Thomas Lin Pedersen,https://github.com/thomasp85/lime,TRUE,https://github.com/thomasp85/lime,31155,346,1542800738
LindenmayeR,"L-systems or Lindenmayer systems are parallel rewriting systems which can
    be used to simulate biological forms and certain kinds of fractals.
    Briefly, in an L-system a series of symbols in a string are replaced
    iteratively according to rules to give a more complex string. Eventually,
    the symbols are translated into turtle graphics for plotting. Wikipedia has
    a very good introduction: en.wikipedia.org/wiki/L-system This package
    provides basic functions for exploring L-systems.",2017-07-31,Bryan Hanson,NA,TRUE,https://github.com/bryanhanson/lindenmayer,12017,4,1539349139
lineup,"Tools for detecting and correcting sample mix-ups between two sets
    of measurements, such as between gene expression data on two tissues.",2019-03-06,Karl W Broman <broman@wisc.edu>,https://github.com/kbroman/lineup,TRUE,https://github.com/kbroman/lineup,13546,1,1552252123
lingtypology,"Provides R with the Glottolog database <http://glottolog.org> and some more abilities for purposes of linguistic mapping. The Glottolog database contains the catalogue of languages of the world. This package helps researchers to make a linguistic maps, using philosophy of the Cross-Linguistic Linked Data project <http://clld.org/>, which allows for while at the same time facilitating uniform access to the data across publications. A tutorial for this package is available on GitHub pages <https://ropensci.github.io/lingtypology/> and package vignette. Maps created by this package can be used both for the investigation and linguistic teaching. In addition, package provides an ability to download data from typological databases such as WALS, AUTOTYP and some others and to create your own database website.",2018-06-14,George Moroz,"https://CRAN.R-project.org/package=lingtypology,
https://github.com/ropensci/lingtypology/",TRUE,https://github.com/ropensci/lingtypology,15279,27,1539525604
linguisticsdown,"Provides 'Shiny gadgets' to search, type, and insert IPA symbols
    into documents or scripts, requiring only knowledge about phonetics or 
    'X-SAMPA'. Also provides functions to facilitate the rendering of IPA
    symbols in 'LaTeX' and PDF format, making IPA symbols properly rendered
    in all output formats. A minimal R Markdown template for authoring 
    Linguistics related documents is also bundled with the package. Some
    helper functions to facilitate authoring with R Markdown is also provided.",2019-03-01,Yongfu Liao,"https://liao961120.github.io/linguisticsdown/,
https://github.com/liao961120/linguisticsdown",TRUE,https://github.com/liao961120/linguisticsdown,1833,8,1551405357
LinkedMatrix,"A class that links matrix-like objects (nodes) by rows or by
    columns while behaving similarly to a base R matrix. Very large matrices
    are supported if the nodes are memory-mapped objects.",2018-08-06,Alexander Grueneberg,https://github.com/QuantGen/LinkedMatrix,TRUE,https://github.com/quantgen/linkedmatrix,9026,2,1533827139
linkprediction,"Implementations of most of the existing proximity-based methods of 
  link prediction in graphs. Among the 20 implemented methods are e.g.:
  Adamic L. and Adar E. (2003) <doi:10.1016/S0378-8733(03)00009-1>,
  Leicht E., Holme P., Newman M. (2006) <doi:10.1103/PhysRevE.73.026120>,
  Zhou T. and Zhang Y (2009) <doi:10.1140/epjb/e2009-00335-8>, and
  Fouss F., Pirotte A., Renders J., and Saerens M. (2007) <doi:10.1109/TKDE.2007.46>.",2018-10-19,Michal Bojanowski,https://github.com/recon-icm/linkprediction,TRUE,https://github.com/recon-icm/linkprediction,1366,5,1542723852
linl,"A 'LaTeX' Letter class for 'rmarkdown', using the
 'pandoc-letter' template adapted for use with 'markdown'.",2018-12-15,Dirk Eddelbuettel and Aaron Wolen,http://dirk.eddelbuettel.com/code/linl.html,TRUE,https://github.com/eddelbuettel/linl,4829,69,1547303690
lintools,"Variable elimination (Gaussian elimination, Fourier-Motzkin elimination), 
    Moore-Penrose pseudoinverse, reduction to reduced row echelon form, value substitution,  
    projecting a vector on the convex polytope described by a system of (in)equations, 
    simplify systems by removing spurious columns and rows and collapse implied equalities, 
    test if a matrix is totally unimodular, compute variable ranges implied by linear
    (in)equalities.",2018-07-30,Mark van der Loo,https://github.com/data-cleaning/lintools,TRUE,https://github.com/data-cleaning/lintools,9042,0,1532414079
lintr,"Checks adherence to a given style, syntax errors and possible
    semantic issues.  Supports on the fly checking of R code edited with 'RStudio IDE', 'Emacs',
    'Vim', 'Sublime Text' and 'Atom'.",2018-11-08,Jim Hester,https://github.com/jimhester/lintr,TRUE,https://github.com/jimhester/lintr,477343,558,1549978106
liquidSVM,"Support vector machines (SVMs) and related kernel-based learning
    algorithms are a well-known class of machine learning algorithms, for
    non-parametric classification and regression.
    liquidSVM is an implementation of SVMs whose key features are:
    fully integrated hyper-parameter selection,
    extreme speed on both small and large data sets,
    full flexibility for experts, and
    inclusion of a variety of different learning scenarios:
    multi-class classification, ROC, and Neyman-Pearson learning, and
    least-squares, quantile, and expectile regression.",2019-03-02,Ingo Steinwart,https://github.com/liquidSVM/liquidSVM,TRUE,https://github.com/liquidsvm/liquidsvm,7876,24,1547148484
lisa,"Contains 128 palettes from Color Lisa. All palettes are based on masterpieces from the worlds greatest artists. For more information, see <http://colorlisa.com/>.",2019-04-01,Tyler Littlefield,https://github.com/tyluRp/lisa,TRUE,https://github.com/tylurp/lisa,208,17,1554482806
listarrays,"A toolbox for R arrays. Flexibly split, bind, reshape, modify, 
    subset and name arrays.",2019-03-24,Tomasz Kalinowski,"https://github.com/t-kalinowski/listarrays,
https://t-kalinowski.github.io/listarrays/",TRUE,https://github.com/t-kalinowski/listarrays,2498,6,1553465764
listviewer,"R lists, especially nested lists, can be very difficult to
    visualize or represent. Sometimes 'str()' is not enough, so this suite of
    htmlwidgets is designed to help see, understand, and maybe even modify your R
    lists.  The function 'reactjson()' requires a package
    'reactR' that can be installed from CRAN or <https://github.com/timelyportfolio/reactR>.",2018-10-07,Jos de Jong,https://github.com/timelyportfolio/listviewer,TRUE,https://github.com/timelyportfolio/listviewer,114521,118,1538879495
littler,"A scripting and command-line front-end
 is provided by 'r' (aka 'littler') as a lightweight binary wrapper around
 the GNU R language and environment for statistical computing and graphics.
 While R can be used in batch mode, the r binary adds full support for
 both 'shebang'-style scripting (i.e. using a  hash-mark-exclamation-path
 expression as the first line in scripts) as well as command-line use in
 standard Unix pipelines. In other words, r provides the R language without
 the environment.",2019-03-15,Dirk Eddelbuettel and Jeff Horner,http://dirk.eddelbuettel.com/code/littler.html,TRUE,https://github.com/eddelbuettel/littler,42753,168,1553378191
live,"Interpretability of complex machine learning models is a growing concern.
    This package helps to understand key factors that drive the 
    decision made by complicated predictive model (so called black box model). 
    This is achieved through local approximations that are either based on 
    additive regression like model or CART like model that allows for 
    higher interactions. The methodology is based on Tulio Ribeiro, Singh, Guestrin (2016) <doi:10.1145/2939672.2939778>.
    More details can be found in Staniak, Biecek (2018) <arXiv:1804.01955>.",2019-02-28,Mateusz Staniak,https://github.com/MI2DataLab/live,TRUE,https://github.com/mi2datalab/live,5142,24,1554234420
LLSR,"Originally design to characterise Aqueous Two Phase Systems, LLSR provide a simple way to analyse experimental data and obtain phase diagram parameters, among other properties, systematically. The package will include (every other update) new functions in order to comprise useful tools in liquid-liquid extraction research.",2019-03-05,Diego F Coelho <diegofcoelho@gmail.com>,https://CRAN.R-project.org/package=LLSR,TRUE,https://github.com/diegofcoelho/llsr,13044,0,1551358882
lme4,"Fit linear and generalized linear mixed-effects models.
    The models and their components are represented using S4 classes and
    methods.  The core computational algorithms are implemented using the
    'Eigen' C++ library for numerical linear algebra and 'RcppEigen' ""glue"".",2019-03-05,Douglas Bates (<https://orcid.org/0000-0001-8316-9503>),https://github.com/lme4/lme4/,TRUE,https://github.com/lme4/lme4,6509555,326,1553284687
lmerTest,"Provides p-values in type I, II or III anova and summary tables
    for lmer model fits (cf. lme4) via Satterthwaite's degrees of freedom method. A
    Kenward-Roger method is also available via the pbkrtest package. Model selection
    methods include step, drop1 and anova-like tables for random effects (ranova).
    Methods for Least-Square means (LS-means) and tests of linear contrasts of fixed
    effects are also available.",2019-02-11,Alexandra Kuznetsova,https://github.com/runehaubo/lmerTestR,TRUE,https://github.com/runehaubo/lmertestr,495466,9,1549402341
LMfilteR,"We present a method based on filtering algorithms to estimate the parameters of linear regressions, i.e. the coefficients and the variance of the error term. The proposed algorithms make use of Particle Filters following Ristic, B., Arulampalam, S., Gordon, N. (2004, ISBN: 158053631X) resampling methods.",2018-08-14,Christian Llano Robayo,NA,TRUE,https://github.com/chrisscod/lmfilter,3905,0,1533098343
lmm,"It implements Expectation/Conditional Maximization Either (ECME)
             and rapidly converging algorithms as well as
             Bayesian inference for linear mixed models, 
             which is described in Schafer, J.L. (1998)
             ""Some improved procedures for linear mixed models"".
             Dept. of Statistics, The Pennsylvania State University.",2018-06-30,Original by Joseph L. Schafer,https://github.com/jinghuazhao/R,TRUE,https://github.com/jinghuazhao/r,23520,0,1552649197
lmPerm,Linear model functions using permutation tests.,2016-08-02,Bob Wheeler <bwheelerg@gmail.com>,https://github.com/mtorchiano/lmPerm,TRUE,https://github.com/mtorchiano/lmperm,27668,7,1541785917
lmQCM,"Implementation based on Zhang, Jie & Huang, Kun (2014) <doi:10.4137/CIN.S14021> Normalized ImQCM: An Algorithm for Detecting Weak Quasi-Cliques in Weighted Graph with Applications in Gene Co-Expression Module Discovery in Cancers. Cancer informatics, 13, CIN-S14021.",2019-03-12,Zhi Huang,http://github.com/huangzhii/lmQCM,TRUE,https://github.com/huangzhii/lmqcm,3519,0,1553556640
lmSubsets,"Exact and approximation algorithms for variable-subset
  selection in ordinary linear regression models.  Either compute all
  submodels with the lowest residual sum of squares, or determine the
  single-best submodel according to a pre-determined statistical
  criterion.  Hofmann, Gatu, Kontoghiorghes, Colubi, Zeileis (2018,
  submitted).",2019-03-07,Marc Hofmann,https://github.com/marc-hofmann/lmSubsets.R,TRUE,https://github.com/marc-hofmann/lmsubsets.r,2398,0,1552130813
lobstr,"A set of tools for inspecting and understanding R data
    structures inspired by str(). Includes ast() for visualizing abstract 
    syntax trees, ref() for showing shared references, cst() for showing 
    call stack trees, and obj_size() for computing object sizes.",2018-12-21,Hadley Wickham,https://github.com/r-lib/lobstr,TRUE,https://github.com/r-lib/lobstr,4305,183,1548515745
localICE,"Local Individual Conditional Expectation is as an extension to Individual Conditional Expectation (ICE) and provides three-dimensional local explanations for particular data instances. The three dimension are two features at the horizontal and vertical axes as well as the target that is represented by different colors. The approach is applicable for classification and regression problems to explain interactions of two features towards the target. The plot for discrete targets looks similar to plots of cluster algorithms like k-means, where different clusters represent different predictions. Reference to the ICE approach: Alex Goldstein, Adam Kapelner, Justin Bleich, Emil Pitkin (2013) <arXiv:1309.6392>. ",2019-02-01,Martin Walter,https://github.com/viadee/localICE,TRUE,https://github.com/viadee/localice,569,7,1549501982
localIV,"In the generalized Roy model, the marginal treatment effect (MTE) can be used as
  a building block for constructing conventional causal parameters such as the average treatment
  effect (ATE) and the average treatment effect on the treated (ATT) (Heckman, Urzua, and Vytlacil 2006
  <doi:10.1162/rest.88.3.389>). Given a treatment selection model and an outcome model, the function mte()
  estimates the MTE via local instrumental variables (or via a normal selection model) and also the
  projection of MTE onto the 2-dimensional space of the propensity score and a latent variable representing
  unobserved resistance to treatment (Zhou and Xie 2018 <https://scholar.harvard.edu/files/xzhou/files/zhou-xie_mte2.pdf>).
  The object returned by mte() can be used to estimate conventional parameters such as ATE and ATT
  (via average()) or marginal policy-relevant treatment effects (via mprte()).",2018-08-05,Xiang Zhou,https://github.com/xiangzhou09/localIV,TRUE,https://github.com/xiangzhou09/localiv,1833,1,1533416359
loder,"Read and write access to PNG image files using the LodePNG
    library. The package has no external dependencies.",2018-06-15,Jon Clayden,https://github.com/jonclayden/loder,TRUE,https://github.com/jonclayden/loder,4831,3,1529075633
log4r,"logr4 provides an object-oriented logging system that uses an API
    roughly equivalent to log4j and its related variants.",2014-09-29,John Myles White,https://github.com/johnmyleswhite/log4r,TRUE,https://github.com/johnmyleswhite/log4r,35032,44,1553704959
logbin,"Methods for fitting log-link GLMs and GAMs to binomial data,
    including EM-type algorithms with more stable convergence properties than standard methods.",2018-08-31,Mark W. Donoghoe,https://github.com/mdonoghoe/logbin,TRUE,https://github.com/mdonoghoe/logbin,12532,8,1535682868
logger,"Inspired by the the 'futile.logger' R package and 'logging' Python module, this utility provides a flexible and extensible way of formatting and delivering log messages with low overhead.",2019-01-02,Gergely Daróczi  (<https://orcid.org/0000-0003-3149-8537>),https://github.com/daroczig/logger,TRUE,https://github.com/daroczig/logger,1386,53,1553885765
logging,"Pure R implementation of the ubiquitous log4j package. It offers hierarchic 
  loggers, multiple handlers per logger, level based filtering, space handling in messages 
  and custom formatting.",2019-02-10,Walerian Sokolowski,https://github.com/WLOGSolutions/r-logging,TRUE,https://github.com/wlogsolutions/r-logging,190632,3,1551081166
loggit,"
    A very simple and easy-to-use set of suspiciously-familiar functions. 'loggit'
    provides a set of wrappings for base R's message(), warning(), and stop()
    functions that maintain identical functionality, but also log the handler
    message to a 'JSON' log file. While mostly automatic, powerful custom logging
    is available via these handlers' logging function, loggit(), which is also
    exported for use. No change in existing code is necessary to use this
    package.",2018-04-09,Ryan Price,https://github.com/ryapric/loggit,TRUE,https://github.com/ryapric/loggit,3627,17,1554083669
loggle,"Provides a set of methods that learn time-varying graphical models based on data measured over a temporal grid. The underlying statistical model is motivated by the needs to describe and understand evolving interacting relationships among a set of random variables in many real applications, for instance the study of how stocks interact with each other and how such interactions change over time. The time-varying graphical models are estimated under the assumption that the graph topology changes gradually over time. For more details on estimating time-varying graphical models, please refer to: Yang, J. & Peng, J. (2018) <arXiv:1804.03811>.",2018-04-16,Jilei Yang,https://github.com/jlyang1990/loggle,TRUE,https://github.com/jlyang1990/loggle,2115,6,1545991423
logisticRR,"Adjusted odds ratio conditional on potential confounders can be directly obtained from logistic regression. However, those adjusted odds ratios have been widely incorrectly interpreted as a relative risk. As relative risk is often of interest in public health, we provide a simple code to return adjusted relative risks from logistic regression model under potential confounders. ",2018-10-31,Youjin Lee,https://github.com/youjin1207/logisticRR,TRUE,https://github.com/youjin1207/logisticrr,2109,0,1541017889
logmult,"Functions to fit log-multiplicative models using 'gnm', with
  support for convenient printing, plots, and jackknife/bootstrap
  standard errors. For complex survey data, models can be fitted from
  design objects from the 'survey' package. Currently supported models
  include UNIDIFF (Erikson & Goldthorpe), a.k.a. log-multiplicative
  layer effect model (Xie), and several association models: Goodman's
  row-column association models of the RC(M) and RC(M)-L families
  with one or several dimensions; two skew-symmetric association
  models proposed by Yamaguchi and by van der Heijden & Mooijaart.
  Functions allow computing the intrinsic association coefficient
  (and therefore the Altham index), including via the Bayes shrinkage
  estimator proposed by Zhou; and the RAS/IPF/Deming-Stephan algorithm.",2019-02-13,Milan Bouchet-Valat,https://github.com/nalimilan/logmult,TRUE,https://github.com/nalimilan/logmult,19076,2,1550080069
lognorm,"The lognormal distribution  
  (Limpert et al. (2001) <doi:10.1641/0006-3568(2001)051[0341:lndats]2.0.co;2>)
  can characterize uncertainty that is bounded by zero.
  This package provides estimation of distribution parameters, computation of
  moments and other basic statistics, and an approximation of the distribution
  of the sum of several correlated lognormally distributed variables 
  (Lo 2013 <doi:10.12988/ams.2013.39511>).",2019-03-13,Thomas Wutzler,https://github.com/bgctw/lognorm,TRUE,https://github.com/bgctw/lognorm,2576,2,1552466071
lolog,"Estimation of Latent Order Logistic (LOLOG) Models for Networks.
    LOLOGs are a flexible and fully general class of statistical graph models. 
    This package provides functions for performing MOM, GMM and variational 
    inference. Visual diagnostics and goodness of fit metrics are provided. 
    See Fellows (2018) <arXiv:1804.04583> for a detailed description of the methods.",2019-01-12,Ian E. Fellows,https://github.com/statnet/lolog,TRUE,https://github.com/statnet/lolog,2760,2,1547139285
lolR,"Supervised learning techniques designed for the situation when the dimensionality exceeds the sample size have a tendency to overfit as the dimensionality of the data increases. To remedy this High dimensionality; low sample size (HDLSS) situation, we attempt to learn a lower-dimensional representation of the data before learning a classifier. That is, we project the data to a situation where the dimensionality is more manageable, and then are able to better apply standard classification or clustering techniques since we will have fewer dimensions to overfit. A number of previous works have focused on how to strategically reduce dimensionality in the unsupervised case, yet in the supervised HDLSS regime, few works have attempted to devise dimensionality reduction techniques that leverage the labels associated with the data. In this package and the associated manuscript Vogelstein et al. (2017) <arXiv:1709.01233>, we provide several methods for feature extraction, some utilizing labels and some not, along with easily extensible utilities to simplify cross-validative efforts to identify the best feature extraction method. Additionally, we include a series of adaptable benchmark simulations to serve as a standard for future investigative efforts into supervised HDLSS. Finally, we produce a comprehensive comparison of the included algorithms across a range of benchmark simulations and real data applications.",2018-04-13,Eric Bridgeford,https://github.com/neurodata/lol,TRUE,https://github.com/neurodata/lol,2604,7,1539616257
longpower,"Compute power and sample size for linear models of longitudinal
    data. Supported models include mixed-effects models and models fit by
    generalized least squares and generalized estimating equations. Relevant
    formulas are derived by Liu and Liang (1997) <DOI:10.2307/2533554>, 
    Diggle et al (2002) <ISBN:9780199676750>, and Lu, Luo, and Chen (2008)
    <DOI:10.2202/1557-4679.1098>.",2019-03-07,Michael C. Donohue,https://github.com/mcdonohue/longpower,TRUE,https://github.com/mcdonohue/longpower,22037,0,1551976793
loo,"Efficient approximate leave-one-out cross-validation (LOO)
    for Bayesian models fit using Markov chain Monte Carlo. The approximation
    uses Pareto smoothed importance sampling (PSIS), a new procedure for
    regularizing importance weights. As a byproduct of the calculations, we also
    obtain approximate standard errors for estimated predictive errors and for
    the comparison of predictive errors between models. The package also 
    provides methods for using stacking and other model weighting techniques 
    to average Bayesian predictive distributions.",2019-03-13,Jonah Gabry,"https://mc-stan.org/loo, https://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/loo,310108,59,1554148533
loon,An extendable toolkit for interactive data visualization and exploration.,2019-03-23,Adrian Waddell,http://waddella.github.io/loon/,TRUE,https://github.com/waddella/loon,6374,23,1553377434
lorentz,"The Lorentz transform in special relativity; also the gyrogroup structure of three-velocities following Ungar (2006)
  <doi:10.1088/0143-0807/27/3/L02>.  For general relativity, see the
  'schwarzschild' package.",2019-03-21,Robin K. S. Hankin  (<https://orcid.org/0000-0001-5982-0415>),https://github.com/RobinHankin/lorentz.git,TRUE,https://github.com/robinhankin/lorentz,1748,2,1553455770
lpirfs,"Provides functions to estimate and plot linear as well as nonlinear impulse 
             responses based on local projections by Jordà (2005) <doi:10.1257/0002828053828518>.",2018-12-11,Philipp Adämmer  (<https://orcid.org/0000-0003-3770-0097>),NA,TRUE,https://github.com/adaemmerp/lpirfs,4111,2,1554459529
lplyr,"Provides 'dplyr' verbs for lists and other useful 
    verbs for manipulation of data frames. In particular, it includes a 
    mutate_which() function that mutates columns for a specific subset of 
    rows defined by a condition, and fuse() which is a more flexible version 
    of 'tidyr' unite() function. ",2017-11-05,Paul Poncet,https://github.com/paulponcet/lplyr,TRUE,https://github.com/paulponcet/lplyr,6029,30,1542326293
LPS,"An implementation of the Linear Predictor Score approach, as initiated by Radmacher et al. (J Comput Biol 2001) and enhanced by Wright et al. (PNAS 2003) for gene expression signatures. Several tools for unsupervised clustering of gene expression data are also provided.",2015-02-16,Sylvain Mareschal,http://bioinformatics.ovsa.fr/LPS,TRUE,https://github.com/maressyl/r.lps,12651,0,1552570936
LPWC,"Computes a time series distance measure for clustering based on weighted correlation and introduction of lags. The lags capture delayed responses in a time series dataset. The timepoints must be specified. T. Chandereng, A. Gitter (2018) <doi:10.1101/292615>.",2019-03-12,Thevaa Chandereng,https://github.com/gitter-lab/LPWC,TRUE,https://github.com/gitter-lab/lpwc,4499,7,1552852640
lrgs,"Implements a Gibbs sampler to do linear regression with multiple covariates, multiple responses, Gaussian measurement errors on covariates and responses, Gaussian intrinsic scatter, and a covariate prior distribution which is given by either a Gaussian mixture of specified size or a Dirichlet process with a Gaussian base distribution.",2017-12-01,Adam Mantz,https://github.com/abmantz/lrgs,TRUE,https://github.com/abmantz/lrgs,7946,11,1545341870
lsm,"When the values of the outcome variable Y are either 0 or 1, the function lsm() calculates the estimation of the log likelihood in the saturated model. This model is characterized by Llinas (2006, ISSN:2389-8976) in section 2.3 through the assumptions 1 and 2. The function LogLik() works (almost perfectly) when the number of independent variables K is high, but for small K it calculates wrong values in some cases. For this reason, when Y is dichotomous and the data are grouped in J populations, it is recommended to use the function lsm() because it works very well for all K.",2018-08-30,Jorge Villalba,https://github.com/jlvia1191/lsm,TRUE,https://github.com/jlvia1191/lsm,2605,0,1535604674
lspls,"Implements the LS-PLS (least squares - partial least squares)
  method described in for instance Jørgensen, K., Segtnan, V. H., Thyholt, K.,
  Næs, T. (2004)  ""A Comparison of Methods for Analysing Regression Models with
  Both Spectral and Designed Variables""
  Journal of Chemometrics, 18(10), 451--464, <doi:10.1002/cem.890>.",2018-07-26,Bjørn-Helge Mevik,"http://mevik.net/work/software/lspls.html,
https://github.com/bhmevik/lspls",TRUE,https://github.com/bhmevik/lspls,14692,0,1532625252
ltm,"Analysis of multivariate dichotomous and polytomous data using latent trait models under the Item Response Theory approach. It includes the Rasch, the Two-Parameter Logistic, the Birnbaum's Three-Parameter, the Graded Response, and the Generalized Partial Credit Models.",2018-04-17,Dimitris Rizopoulos <d.rizopoulos@erasmusmc.nl>,https://github.com/drizopoulos/ltm,TRUE,https://github.com/drizopoulos/ltm,145892,16,1551212166
ltmle,"Targeted Maximum Likelihood Estimation (TMLE) of
    treatment/censoring specific mean outcome or marginal structural model for
    point-treatment and longitudinal data.",2018-08-20,Joshua Schwab,https://github.com/joshuaschwab/ltmle,TRUE,https://github.com/joshuaschwab/ltmle,18965,11,1551126295
lubridate,"Functions to work with date-times and time-spans: fast and user
    friendly parsing of date-time data, extraction and updating of components of
    a date-time (years, months, days, hours, minutes, and seconds), algebraic
    manipulation on date-time and time-span objects. The 'lubridate' package has
    a consistent and memorable syntax that makes working with dates easy and
    fun.
    Parts of the 'CCTZ' source code, released under the Apache 2.0 License,
    are included in this package. See <https://github.com/google/cctz> for more
    details.",2018-04-11,Vitalie Spinu,"http://lubridate.tidyverse.org,
https://github.com/tidyverse/lubridate",TRUE,https://github.com/tidyverse/lubridate,6538381,419,1552220728
lucid,"Print vectors (and data frames) of floating point numbers
    using a non-scientific format optimized for human readers.  Vectors
    of numbers are rounded using significant digits, aligned at the
    decimal point, and all zeros trailing the decimal point are dropped.
    See: Wright (2016). Lucid: An R Package for Pretty-Printing Floating Point
    Numbers. In JSM Proceedings, Statistical Computing Section. Alexandria,
    VA: American Statistical Association. 2270-2279.",2019-02-06,Kevin Wright  (<https://orcid.org/0000-0002-0617-8673>),https://github.com/kwstat/lucid,TRUE,https://github.com/kwstat/lucid,14088,23,1549467450
LUCIDus,An implementation for the 'LUCID' method to jointly estimate latent unknown clusters/subgroups with integrated data. An EM algorithm is used to obtain the latent cluster assignment and model parameter estimates. Feature selection is achieved by applying the regularization method.,2018-12-21,Cheng Peng,https://github.com/USCbiostats/LUCIDus,TRUE,https://github.com/uscbiostats/lucidus,853,3,1545441532
lumberjack,"A function composition ('pipe') operator and extensible 
    framework that allows for easy logging of changes in data.",2018-07-20,Mark van der Loo,https://github.com/markvanderloo/lumberjack,TRUE,https://github.com/markvanderloo/lumberjack,4228,21,1552906214
Luminescence,"A collection of various R functions for the purpose of Luminescence
    dating data analysis. This includes, amongst others, data import, export,
    application of age models, curve deconvolution, sequence analysis and
    plotting of equivalent dose distributions.",2018-10-05,Sebastian Kreutzer,https://CRAN.R-project.org/package=Luminescence,TRUE,https://github.com/r-lum/luminescence,39922,6,1552736512
lutz,"Input latitude and longitude values or an 'sf/sfc' POINT 
    object and get back the timezone in which they exist. Two methods are implemented. 
    One is very fast and uses the 'V8' package to access the 'tz-lookup.js' 'Javascript' library
    (<https://github.com/darkskyapp/tz-lookup/>). This method also works outside of countries' 
    borders and in international waters, however speed comes at the cost of accuracy - near time 
    zone borders away from populated centres there is a chance that it will return the incorrect
    time zone. The other method is slower but more accurate - it uses the sf package to intersect 
    points with a detailed map of time zones from here: 
    <https://github.com/evansiroky/timezone-boundary-builder/>.",2018-06-24,Andy Teucher,https://github.com/ateucher/lutz,TRUE,https://github.com/ateucher/lutz,13598,18,1529855525
lvec,"Core functionality for working with vectors (numeric, integer,
    logical and character) that are too large to keep in memory. The vectors are
    kept (partially) on disk using memory mapping. This package contains the
    basic functionality for working with these memory mapped vectors (e.g.
    creating, indexing, ordering and sorting) and provides C++ headers which can
    be used by other packages to extend the functionality provided in this
    package.",2018-05-24,Jan van der Laan,https://github.com/djvanderlaan/lvec,TRUE,https://github.com/djvanderlaan/lvec,4745,6,1527091384
lvm4net,"Latent variable models for network data using fast inferential
    procedures.",2018-10-07,Isabella Gollini,http://github.com/igollini/lvm4net,TRUE,https://github.com/igollini/lvm4net,11365,5,1554392771
lvmcomp,"Provides stochastic EM algorithms for latent variable models
    with a high-dimensional latent space. So far, we provide functions for confirmatory item
    factor analysis based on the multidimensional two parameter logistic (M2PL) model and the 
    generalized multidimensional partial credit model. These functions scale well for problems
    with many latent traits (e.g., thirty or even more) and are virtually tuning-free.
    The computation is facilitated by multiprocessing 'OpenMP' API.
    For more information, please refer to:
    Zhang, S., Chen, Y., & Liu, Y. (2018). An Improved Stochastic EM Algorithm for Large-scale
    Full-information Item Factor Analysis. British Journal of Mathematical and Statistical
    Psychology. <doi:10.1111/bmsp.12153>.",2018-12-30,Siliang Zhang,https://github.com/slzhang-fd/lvmcomp,TRUE,https://github.com/slzhang-fd/lvmcomp,1151,2,1546323409
lwgeom,"Access to selected functions found in 'liblwgeom' <https://github.com/postgis/postgis/tree/svn-trunk/liblwgeom>, the light-weight geometry library used by 'PostGIS' <http://postgis.net/>.",2019-02-18,Edzer Pebesma  (<https://orcid.org/0000-0001-8049-7069>),https://github.com/r-spatial/lwgeom/,TRUE,https://github.com/r-spatial/lwgeom,123497,24,1552216082
MachineShop,"Meta-package for statistical and machine learning with a common interface for model fitting, prediction, performance assessment, and presentation of results.  Supports predictive modeling of numerical, categorical, and censored time-to-event outcomes and resample (bootstrap and cross-validation) estimation of model performance.",2019-02-15,Brian J Smith,https://brian-j-smith.github.io/MachineShop/,TRUE,https://github.com/brian-j-smith/machineshop,4081,43,1552841777
macleish,"Download data from the Ada and Archibald MacLeish Field 
    Station in Whately, MA. The Ada 
    and Archibald MacLeish Field Station is a 260-acre patchwork of 
    forest and farmland located in West Whately, MA that provides opportunities 
    for faculty and students to pursue environmental research, outdoor 
    education, and low-impact recreation 
    (see <http://www.smith.edu/ceeds/macleish.php> for more information). 
    This package contains 
    weather data over several years, and spatial data on various man-made and 
    natural structures.",2018-01-03,Benjamin S. Baumer,http://github.com/beanumber/macleish,TRUE,https://github.com/beanumber/macleish,7723,2,1553106764
maditr,"Package provides pipe-style interface for 'data.table'. It preserves all
    'data.table' features without significant impact on performance. 'let'
    and 'take' functions are simplified interfaces for most common data manipulation
    tasks. For example, you can write 'mtcars %>% take(mean(mpg), by = am)' for 
    aggregation or 'mtcars %>% let(hp_wt = hp/wt, hp_wt_mpg = hp_wt/mpg)' for modification.
    Use 'take_if/let_if' for conditional aggregation/modification. 'query_if' function
    translates its arguments one-to-one to '[.data.table' method. Additionally there are
    some conveniences such as automatic 'data.frame' conversion to 'data.table'.",2019-01-03,Gregory Demin,https://github.com/gdemin/maditr,TRUE,https://github.com/gdemin/maditr,4591,27,1546476049
madness,"An object that supports automatic differentiation
    of matrix- and multidimensional-valued functions with 
    respect to multidimensional independent variables. 
    Automatic differentiation is via 'forward accumulation'.",2018-08-29,Steven E. Pav  (<https://orcid.org/0000-0002-4197-6195>),https://github.com/shabbychef/madness,TRUE,https://github.com/shabbychef/madness,11357,12,1535434323
magic,"A collection of efficient, vectorized algorithms for the
 creation and investigation of magic squares and hypercubes, including
 a variety of functions for the manipulation and analysis of
 arbitrarily dimensioned arrays.  The package includes methods for
 creating normal magic squares of any order greater than 2.  The
 ultimate intention is for the package to be a computerized embodiment
 all magic square knowledge, including direct numerical verification
 of properties of magic squares (such as recent results on the
 determinant of odd-ordered semimagic squares).  Some antimagic
 functionality is included.  The package also
 serves as a rebuttal to the often-heard comment ""I thought R
 was just for statistics"".",2018-09-17,Robin K. S. Hankin,https://github.com/RobinHankin/magic.git,TRUE,https://github.com/robinhankin/magic,746293,1,1551034726
magickGUI,Enables us to use the functions of the package 'magick' interactively.,2019-03-13,Shota Ochi,https://github.com/ShotaOchi/magickGUI,TRUE,https://github.com/shotaochi/magickgui,251,5,1553366561
magicLamp,"Set of utility functions to interact with 'WeMo Switch', a smart 
    plug that can be remotely controlled via wifi. The provided functions make 
    it possible to turn one or more 'WeMo Switch' plugs on and off in a 
    scriptable fashion. More information about 'WeMo Switch' can be found at 
    <http://www.belkin.com/us/p/P-F7C027/>. ",2017-09-21,Simon Garnier,https://github.com/swarm-lab/magicLamp,TRUE,https://github.com/swarm-lab/magiclamp,3078,2,1540407517
makedummies,"Create dummy variables from categorical data.
    This package can convert categorical data (factor and ordered) into
    dummy variables and handle multiple columns simultaneously.
    This package enables to select whether a dummy variable for base group
    is included (for principal component analysis/factor analysis) or
    excluded (for regression analysis) by an option.
    'makedummies' function accepts 'data.frame', 'matrix', and
    'tbl' (tibble) class (by 'tibble' package).
    'matrix' class data is automatically converted to 'data.frame' class.",2019-03-03,Toshiaki Ara,https://github.com/toshi-ara/makedummies,TRUE,https://github.com/toshi-ara/makedummies,8085,6,1551653694
makeParallel,"
    Writing parallel R code can be difficult, particularly for code
    that is not ""embarrassingly parallel"".
    This experimental package automates the transformation of serial R code
    into more efficient parallel versions. It identifies task parallelism by
    statically analyzing entire scripts to detect dependencies between
    statements. It implements an extensible system for scheduling
    and generating new code. It includes a reference implementation of the
    'List Scheduling' approach to the general task scheduling problem of scheduling 
    statements on multiple processors.",2018-07-31,Clark Fitzgerald  (<https://orcid.org/0000-0003-3446-6389>),https://github.com/clarkfitzg/makeParallel,TRUE,https://github.com/clarkfitzg/makeparallel,1923,9,1554515104
malariaAtlas,"A suite of tools to allow you to download all 
  publicly available parasite rate survey points, mosquito occurrence points and raster surfaces from 
  the 'Malaria Atlas Project' <https://map.ox.ac.uk/> servers as well as utility functions for plotting
  the downloaded data.",2018-10-30,Daniel Pfeffer (<https://orcid.org/0000-0002-2204-3488>),https://github.com/malaria-atlas-project/malariaAtlas,TRUE,https://github.com/malaria-atlas-project/malariaatlas,3102,16,1553966814
manifestoR,"Provides access to coded election programmes from the Manifesto
    Corpus and to the Manifesto Project's Main Dataset and routines to analyse this
    data. The Manifesto Project <https://manifesto-project.wzb.eu> collects and
    analyses election programmes across time and space to measure the political
    preferences of parties. The Manifesto Corpus contains the collected and
    annotated election programmes in the Corpus format of the package 'tm' to enable
    easy use of text processing and text mining functionality. Specific functions
    for scaling of coded political texts are included.",2018-05-28,Jirka Lewandowski,"https://github.com/ManifestoProject/manifestoR,
https://manifesto-project.wzb.eu/",TRUE,https://github.com/manifestoproject/manifestor,15635,33,1527066133
manipulateWidget,"Like package 'manipulate' does for static graphics, this package
    helps to easily add controls like sliders, pickers, checkboxes, etc. that 
    can be used to modify the input data or the parameters of an interactive 
    chart created with package 'htmlwidgets'.",2018-06-11,Jalal-Edine ZAWAM,https://github.com/rte-antares-rpackage/manipulateWidget,TRUE,https://github.com/rte-antares-rpackage/manipulatewidget,602790,89,1528726435
MANOVA.RM,"Implemented are various tests for semi-parametric repeated measures
    and general MANOVA designs that do neither assume multivariate normality nor
    covariance homogeneity, i.e., the procedures are applicable for a wide range
    of general multivariate factorial designs. Furthermore, post-hoc comparisons 
    are provided for the multivariate analyses.
    Friedrich, S., Konietschke, F. and Pauly, M. (2018) <arXiv:1801.08002>.",2018-08-14,Sarah Friedrich,http://github.com/smn74/MANOVA.RM,TRUE,https://github.com/smn74/manova.rm,10181,1,1554466828
manymodelr,"Frequently one needs a convenient way to build and tune,
             several models in one go.The goal is to provide a number of convenience functions useful in machine learning 
             applications. It provides the ability to build,tune and obtain predictions of 
             several models in one function. The models are built using 'caret' functions with
             easier to read syntax.
             Kuhn(2014)<arXiv:1405.6974v14>.
             Kuhn(2008)<doi10.18637/jss.v028.i05>.
             Chambers,J.M.(1992)<doi:10.1371/journal.pone.0053143>.
             Wilkinson,G.N. and Rogers, C. E. (1973)<doi:10.2307/2346786>.",2019-03-02,Nelson Gonzabato,https://github.com/Nelson-Gon/manymodelr,TRUE,https://github.com/nelson-gon/manymodelr,528,2,1554346049
mapdeck,"Provides a mechanism to plot an interactive map using 'Mapbox GL' 
		(<https://www.mapbox.com/mapbox-gl-js/api/>), a javascript library for interactive maps,
		and 'Deck.gl' (<http://deck.gl/#/>), a javascript library which uses 'WebGL' for 
		visualising large data sets.",2019-01-22,David Cooley,https://symbolixau.github.io/mapdeck/articles/mapdeck.html,TRUE,https://github.com/symbolixau/mapdeck,3594,147,1554533232
mapedit,"Suite of interactive functions and helpers for selecting and editing
    geospatial data.",2019-03-16,Tim Appelhans,https://github.com/r-spatial/mapedit,TRUE,https://github.com/r-spatial/mapedit,24888,126,1552769818
mapr,"Utilities for visualizing species occurrence data. Includes
    functions to visualize occurrence data from 'spocc', 'rgbif',
    and other packages. Mapping options included for base R plots, 'ggplot2',
    'ggmap', 'leaflet' and 'GitHub' 'gists'.",2018-03-21,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/mapr,TRUE,https://github.com/ropensci/mapr,11194,34,1547492603
mapsapi,"Interface to the 'Google Maps' APIs: (1) routing directions based on the 'Directions' API, returned as 'sf' objects, either as single feature per alternative route, or a single feature per segment per alternative route; (2) travel distance or time matrices based on the 'Distance Matrix' API; (3) geocoded locations based on the 'Geocode' API, returned as 'sf' objects, either points or bounds.",2019-04-06,Michael Dorman,https://github.com/michaeldorman/mapsapi/,TRUE,https://github.com/michaeldorman/mapsapi,11856,22,1554557558
mapview,"Quickly and conveniently create interactive
    visualisations of spatial data with or without background maps.
    Attributes of displayed features are fully queryable via pop-up
    windows. Additional functionality includes methods to visualise true-
    and false-color raster images, bounding boxes, small multiples and 3D
    raster data cubes.",2018-12-19,Tim Appelhans,https://github.com/r-spatial/mapview,TRUE,https://github.com/r-spatial/mapview,265031,229,1554494041
mar1s,"Multiplicative AR(1) with Seasonal is a stochastic
  process model built on top of AR(1). The package provides the
  following procedures for MAR(1)S processes: fit, compose, decompose,
  advanced simulate and predict.",2018-08-18,Andrey Paramonov,https://github.com/aparamon/mar1s,TRUE,https://github.com/aparamon/mar1s,18992,0,1534584175
marcher,"A set of tools for likelihood-based estimation, model selection and testing of two- and three-range shift and migration models for animal movement data as described in Gurarie et al. (2017) <doi: 10.1111/1365-2656.12674>.  Provided movement data (X, Y and Time), including irregularly sampled data, functions estimate the time, duration and location of one or two range shifts, as well as the ranging area and auto-correlation structure of the movment.  Tests assess, for example, whether the shift was ""significant"", and whether a two-shift migration was a true return migration.",2017-04-12,Eliezer Gurarie,NA,TRUE,https://github.com/eligurarie/marcher,3707,2,1529672498
margins,"An R port of Stata's 'margins' command, which can be used to
    calculate marginal (or partial) effects from model objects.",2018-05-22,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/leeper/margins,TRUE,https://github.com/leeper/margins,45581,178,1548156690
markdown,"Provides R bindings to the 'Sundown' 'Markdown' rendering library
    (<https://github.com/vmg/sundown>). 'Markdown' is a plain-text formatting
    syntax that can be converted to 'XHTML' or other formats. See
    <http://en.wikipedia.org/wiki/Markdown> for more information about 'Markdown'.",2018-12-07,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/rstudio/markdown,TRUE,https://github.com/rstudio/markdown,9200271,51,1544146693
markovchain,"Functions and S4 methods to create and manage discrete time Markov
    chains more easily. In addition functions to perform statistical (fitting
    and drawing random variates) and probabilistic (analysis of their structural
    proprieties) analysis are provided.",2019-01-21,"Giorgio Alfredo Spedicato 
    (<https://orcid.org/0000-0002-0315-8888>)",http://github.com/spedygiorgio/markovchain/,TRUE,https://github.com/spedygiorgio/markovchain,123493,60,1549268425
MarkowitzR,"A collection of tools for analyzing significance of 
    Markowitz portfolios.",2018-05-26,Steven E. Pav  (<https://orcid.org/0000-0002-4197-6195>),https://github.com/shabbychef/MarkowitzR,TRUE,https://github.com/shabbychef/markowitzr,21103,3,1527308893
marmap,"Import xyz data from the NOAA (National Oceanic and Atmospheric Administration, <http://www.noaa.gov>), GEBCO (General Bathymetric Chart of the Oceans, <http://www.gebco.net>) and other sources, plot xyz data to prepare publication-ready figures, analyze xyz data to extract transects, get depth / altitude based on geographical coordinates, or calculate z-constrained least-cost paths.",2018-10-15,Eric Pante,https://github.com/ericpante/marmap,TRUE,https://github.com/ericpante/marmap,55145,6,1539623275
MARSS,"The MARSS package provides maximum-likelihood parameter estimation for constrained and unconstrained linear multivariate autoregressive state-space (MARSS) models fit to multivariate time-series data.  Fitting is primarily via an Expectation-Maximization (EM) algorithm, although fitting via the BFGS algorithm (using the optim function) is also provided.  MARSS models are a class of dynamic linear model (DLM) and vector autoregressive model (VAR) model.  Functions are provided for parametric and innovations bootstrapping, Kalman filtering and smoothing, bootstrap model selection criteria (AICb), confidences intervals via the Hessian approximation and via bootstrapping and calculation of auxiliary residuals for detecting outliers and shocks.  The user guide shows examples of using MARSS for parameter estimation for a variety of applications, model selection, dynamic factor analysis, outlier and shock detection, and addition of covariates.  Type RShowDoc(""UserGuide"", package=""MARSS"") at the R command line to open the MARSS user guide.  Online workshops (lectures and computer labs) at <https://nwfsc-timeseries.github.io/>  See the NEWS file for update information.",2018-11-02,Eli Holmes,https://nwfsc-timeseries.github.io/MARSS,TRUE,https://github.com/nwfsc-timeseries/marss,41350,11,1553022466
maSAE,"An S4 implementation of the unbiased extension of the model-
    assisted synthetic-regression estimator proposed by 
    Mandallaz (2013) <DOI:10.1139/cjfr-2012-0381>, 
    Mandallaz et al. (2013) <DOI:10.1139/cjfr-2013-0181> and 
    Mandallaz (2014) <DOI:10.1139/cjfr-2013-0449>. 
    It yields smaller variances than the standard bias correction, 
    the generalised regression estimator.",2016-05-31,Andreas Dominik Cullmann,https://github.com/fvafrCU/maSAE,TRUE,https://github.com/fvafrcu/masae,11544,0,1537358690
mason,"Use a consistent syntax to create data structures of common
    statistical techniques that can be continued in a pipe chain.
    Design the analysis, add settings and variables, construct the results, and
    polish the final structure. Rinse and repeat for any number of statistical
    techniques.",2018-07-05,Luke Johnston,https://github.com/lwjohnst86/mason,TRUE,https://github.com/lwjohnst86/mason,5226,1,1538227715
matchingMarkets,"Implements structural estimators to correct for
    the sample selection bias from observed outcomes in matching
    markets. This includes one-sided matching of agents into
    groups as well as two-sided matching of students to schools.
    The package also contains algorithms to find stable matchings
    in the three most common matching problems: the stable roommates
    problem, the college admissions problem, and the house
    allocation problem.",2019-02-04,Thilo Klein,"http://matchingMarkets.org, http://klein.uk",TRUE,https://github.com/thiloklein/matchingmarkets,39470,22,1549316956
matchingR,"Computes matching algorithms quickly using Rcpp.
    Implements the Gale-Shapley Algorithm to compute the stable
    matching for two-sided markets, such as the stable marriage
    problem and the college-admissions problem. Implements Irving's
    Algorithm for the stable roommate problem. Implements the top
    trading cycle algorithm for the indivisible goods trading problem.",2018-01-26,Jan Tilly,https://github.com/jtilly/matchingR/,TRUE,https://github.com/jtilly/matchingr,13511,31,1548270288
mateable,"Tools to simulate, manage, visualize, and analyze
    spatially and temporally explicit datasets of mating potential.
    Implements methods to calculate synchrony, proximity, and compatibility.",2016-04-09,Stuart Wagenius,https://github.com/stuartWagenius/mateable,TRUE,https://github.com/stuartwagenius/mateable,5689,0,1540820098
mathpix,"Given an image of a formula (typeset or handwritten) this package
    provides calls to the 'Mathpix' service to produce the 'LaTeX' code which should
    generate that image, and pastes it into a (e.g. an 'rmarkdown') document. 
    See <https://docs.mathpix.com/> for full details. 'Mathpix' is an external service 
    and use of the API is subject to their terms and conditions.",2018-04-27,Jonathan Carroll  (<https://orcid.org/0000-0002-1404-5264>),https://github.com/jonocarroll/mathpix,TRUE,https://github.com/jonocarroll/mathpix,5008,159,1524835438
matlabr,"Provides users to call MATLAB from using the ""system"" command.
    Allows users to submit lines of code or MATLAB m files.
    This is in comparison to 'R.matlab', which creates a MATLAB server.",2018-08-13,John Muschelli,NA,TRUE,https://github.com/muschellij2/matlabr,14526,6,1534175719
matlib,"A collection of matrix functions for teaching and learning matrix
    linear algebra as used in multivariate statistical methods. These functions are
    mainly for tutorial purposes in learning matrix algebra ideas using R. In some
    cases, functions are provided for concepts available elsewhere in R, but where
    the function call or name is not obvious. In other cases, functions are provided
    to show or demonstrate an algorithm. In addition, a collection of functions are
    provided for drawing vector diagrams in 2D and 3D.",2018-04-04,Michael Friendly,https://github.com/friendly/matlib,TRUE,https://github.com/friendly/matlib,54843,24,1549639012
matR,"An analysis platform for metagenomics combining 
 specialized tools and workflows, easy handling of the BIOM 
 format, and transparent access to MG-RAST resources.  Integrates 
 easily with other R packages and non-R software.",2018-05-04,William L. Trimble,https://github.com/MG-RAST/matR/,TRUE,https://github.com/mg-rast/matr,11001,16,1525693397
Matrix.utils,"Implements data manipulation methods such as cast, aggregate, and merge/join for Matrix and matrix-like objects.",2018-04-19,Craig Varrichio <canthony427@gmail.com>,https://github.com/cvarrichio/Matrix.utils,TRUE,https://github.com/cvarrichio/matrix.utils,17711,2,1524150561
MatrixEQTL,"Matrix eQTL is designed for fast eQTL analysis on large datasets.
        Matrix eQTL can test for association between genotype 
        and gene expression using linear regression 
        with either additive or ANOVA genotype effects.
        The models can include covariates to account for factors 
        as population stratification, gender, and clinical variables. 
        It also supports models with heteroscedastic and/or correlated errors,
        false discovery rate estimation and 
        separate treatment of local (cis) and distant (trans) eQTLs.",2018-01-13,Andrey A Shabalin  (0000-0003-0309-6821),http://www.bios.unc.edu/research/genomic_software/Matrix_eQTL/,TRUE,https://github.com/andreyshabalin/matrixeqtl,27554,16,1550594174
matrixpls,"Partial Least Squares Path Modeling
    algorithm and related algorithms. The algorithm implementations aim for
    computational efficiency using matrix algebra and covariance data. The
    package is designed toward Monte Carlo simulations and includes functions
    to perform simple Monte Carlo simulations.",2017-05-03,Mikko Rönkkö,https://github.com/mronkko/matrixpls,TRUE,https://github.com/mronkko/matrixpls,18126,5,1552908790
matrixProfile,"A simple and the early stage package for matrix profile based on the paper of Chin-Chia Michael Yeh, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Hoang Anh Dau, Diego Furtado Silva, Abdullah Mueen, and Eamonn Keogh (2016) <DOI:10.1109/ICDM.2016.0179>. This package calculates all-pairs-similarity for a given window size for time series data.",2018-08-17,Donghwan Kim,https://github.com/ainsuotain/matrixprofile,TRUE,https://github.com/ainsuotain/matrixprofile,1719,0,1530605507
matrixStats,"High-performing functions operating on rows and columns of matrices, e.g. col / rowMedians(), col / rowRanks(), and col / rowSds().  Functions optimized per data type and for subsetted calculations such that both memory usage and processing time is minimized.  There are also optimized vector-based methods, e.g. binMeans(), madDiff() and weightedMedian().",2018-07-23,Henrik Bengtsson,https://github.com/HenrikBengtsson/matrixStats,TRUE,https://github.com/henrikbengtsson/matrixstats,1583295,106,1532380477
matrixTests,"Functions to perform fast statistical hypothesis tests on rows/columns of matrices.
  The main goals are: 1) speed via vectorization, 2) output that is detailed and easy to use,
  3) compatibility with tests implemented in R (like those available in the 'stats' package).",2019-04-05,Karolis Koncevičius,https://github.com/KKPMW/matrixTests,TRUE,https://github.com/kkpmw/matrixtests,2986,5,1554500719
matsbyname,"An implementation of matrix mathematics wherein operations are performed ""by name.""",2019-02-16,Matthew Heun  (<https://orcid.org/0000-0002-7438-214X>),https://github.com/MatthewHeun/matsbyname,TRUE,https://github.com/matthewheun/matsbyname,1266,0,1550362349
matsindf,"Provides functions to collapse a tidy data frame into matrices in a data frame
    and expand a data frame of matrices into a tidy data frame.",2019-02-11,Matthew Heun  (<https://orcid.org/0000-0002-7438-214X>),https://github.com/MatthewHeun/matsindf,TRUE,https://github.com/matthewheun/matsindf,523,0,1550169798
mau,"Provides functions for the creation, evaluation and test of decision models based in
    Multi Attribute Utility Theory (MAUT). Can process and evaluate local risk aversion utilities
    for a set of indexes, compute utilities and weights for the whole decision tree defining the
    decision model and simulate weights employing Dirichlet distributions under addition constraints 
    in weights.",2018-01-17,Pedro Guarderas,https://github.com/pedroguarderas/mau,TRUE,https://github.com/pedroguarderas/mau,3763,1,1531370751
MaxMC,"An implementation of the Monte Carlo techniques described in details by Dufour (2006) <doi:10.1016/j.jeconom.2005.06.007> and Dufour and Khalaf (2007) <doi:10.1002/9780470996249.ch24>. The two main features available are the Monte Carlo method with tie-breaker, mc(), for discrete statistics, and the Maximized Monte Carlo, mmc(), for statistics with nuisance parameters.",2019-03-24,Julien Neves,https://github.com/julienneves/MaxMC,TRUE,https://github.com/julienneves/maxmc,392,0,1553414558
MazamaCoreUtils,"A suite of utility functions providing functionality commonly
    needed for production level projects such as logging, error handling,
    and cache management.",2018-12-03,Jonathan Callahan,https://github.com/MazamaScience/MazamaCoreUtils,TRUE,https://github.com/mazamascience/mazamacoreutils,1439,1,1543857783
MazamaSpatialUtils,"A suite of conversion scripts to create internally standardized
    spatial polygons data frames. Utility scripts use these data sets to return
    values such as country, state, timezone, watershed, etc. associated with a
    set of longitude/latitude pairs. (They also make cool maps.)",2019-01-30,Jonathan Callahan,https://github.com/MazamaScience/MazamaSpatialUtils,TRUE,https://github.com/mazamascience/mazamaspatialutils,17825,0,1554161138
MazamaWebUtils,"A suite of utility functions providing standardized functionality
    often needed in web services including: logging, cache management
    and parsing of http request headers.",2018-09-29,Jonathan Callahan,https://github.com/MazamaScience/MazamaWebUtils,TRUE,https://github.com/mazamascience/mazamawebutils,3545,0,1538077650
mbbefd,"Distributions that are typically used for exposure rating in
             general insurance, in particular to price reinsurance contracts.
             The vignettes show code snippets to fit the distribution to
             empirical data.",2019-01-02,Giorgio Spedicato  (<https://orcid.org/0000-0002-0315-8888>),http://github.com/spedygiorgio/mbbefd,TRUE,https://github.com/spedygiorgio/mbbefd,20555,7,1544433661
mbest,"Fast moment-based hierarchical model fitting. Implements
    methods from the papers
    ""Fast Moment-Based Estimation for Hierarchical Models,"" by Perry (2017)
    and
    ""Fitting a Deeply Nested Hierarchical Model to a Large Book Review
    Dataset Using a Moment-Based Estimator,"" by Zhang, Schmaus, and Perry
    (2018).",2018-05-25,Patrick O. Perry,https://github.com/patperry/r-mbest,TRUE,https://github.com/patperry/r-mbest,78995,15,1527193458
mboost,"Functional gradient descent algorithm
  (boosting) for optimizing general risk functions utilizing
  component-wise (penalised) least squares estimates or regression
  trees as base-learners for fitting generalized linear, additive
  and interaction models to potentially high-dimensional data.",2018-08-22,Benjamin Hofner  (<https://orcid.org/0000-0003-2810-3186>),https://github.com/boost-R/mboost,TRUE,https://github.com/boost-r/mboost,217217,41,1553263504
mboxr,Importing and converting an mbox file into a tibble object.,2019-02-24,JooYoung Seo,https://github.com/jooyoungseo/mboxr,TRUE,https://github.com/jooyoungseo/mboxr,1413,2,1551382807
MBTAr,"Access to the MBTA's performance API for R. Creates an easy-to-use
  bundle of functions to work with all the built-in calls to the MBTA performance 
  API, and some to work with the GTFS-compatible API V3 which replaced some 
  functionality from the old performance API. Allows users to download realtime 
  tracking data in dataframe format that is manipulable in standard R analytics 
  functions. Pulls performance statistics in both realtime and for historical 
  dates and trips (after July 2015).",2018-11-12,Justin de Benedictis-Kessner,NA,TRUE,https://github.com/justindbk/mbtar,7090,0,1542062734
mcca,"It contains six common multi-category classification accuracy evaluation measures:
 Hypervolume Under Manifold (HUM), described in
 Li and Fine (2008) <doi:10.1093/biostatistics/kxm050>.
 Correct Classification Percentage (CCP), Integrated Discrimination Improvement (IDI), Net Reclassification Improvement (NRI), R-Squared Value (RSQ), described in
 Li, Jiang and Fine (2013) <doi:10.1093/biostatistics/kxs047>.
 Polytomous Discrimination Index (PDI), described in
 Van Calster et al. (2012) <doi:10.1007/s10654-012-9733-3>.
 Li et al. (2018) <doi:10.1177/0962280217692830>.
 We described all these above measures and our mcca package in
 Li, Gao and D'Agostino (2019) <doi:10.1002/sim.8103>.",2019-02-05,Ming Gao,https://github.com/gaoming96/mcca,TRUE,https://github.com/gaoming96/mcca,4078,3,1549343759
mclogit,"Specification and estimation of conditional logit models of binary
    responses and multinomial counts is provided, with or without
    random effects. The current implementation of the estimator for random
    effects variances uses a Laplace approximation (or PQL) approach and thus should
    be used only if groups sizes are large.",2018-09-27,Martin Elff,"http://www.elff.eu/software/mclogit/,http://github.com/melff/mclogit/",TRUE,https://github.com/melff/mclogit,22827,6,1549275550
MCMCprecision,"Estimates the precision of transdimensional Markov chain Monte Carlo 
    (MCMC) output, which is often used for Bayesian analysis of models with different 
    dimensionality (e.g., model selection). Transdimensional MCMC (e.g., reversible 
    jump MCMC) relies on sampling a discrete model-indicator variable to estimate 
    the posterior model probabilities. If only few switches occur between the models, 
    precision may be low and assessment based on the assumption of independent 
    samples misleading. Based on the observed transition matrix of the indicator 
    variable, the method of Heck, Overstall, Gronau, & Wagenmakers (2018, 
    Statistics & Computing) <doi:10.1007/s11222-018-9828-0> draws posterior samples 
    of the stationary distribution to (a) assess the uncertainty in the estimated 
    posterior model probabilities and (b) estimate the effective sample size of 
    the MCMC output.",2018-08-10,Daniel W. Heck,https://github.com/danheck/MCMCprecision,TRUE,https://github.com/danheck/mcmcprecision,5859,0,1533904342
mcmcr,"Functions and classes to store, manipulate and summarise 
   Monte Carlo Markov Chain (MCMC) samples.",2018-11-24,Joe Thorley  (<https://orcid.org/0000-0002-7683-4592>),https://github.com/poissonconsulting/mcmcr,TRUE,https://github.com/poissonconsulting/mcmcr,2879,3,1550891938
MCMCvis,"Performs key functions for MCMC analysis using minimal code - visualizes, manipulates, and summarizes MCMC output. Functions support simple and straightforward subsetting of model parameters within the calls, and produce presentable and 'publication-ready' output. MCMC output may be derived from Bayesian model output fit with JAGS, Stan, or other MCMC samplers.",2019-02-24,Casey Youngflesh  (<https://orcid.org/0000-0001-6343-3311>),http://github.com/caseyyoungflesh/MCMCvis,TRUE,https://github.com/caseyyoungflesh/mcmcvis,14601,22,1553987228
mcMST,"Algorithms to approximate the Pareto-front of multi-criteria minimum spanning tree problems. Additionally, a modular toolbox for the generation of multi-objective benchmark graph problems is included.",2017-09-18,Jakob Bossek,https://github.com/jakobbossek/mcMST,TRUE,https://github.com/jakobbossek/mcmst,3814,2,1525857094
Mcomp,"
  The 1001 time series from the M-competition (Makridakis et al. 1982) <DOI:10.1002/for.3980010202> and the 3003 time series from the IJF-M3 competition (Makridakis and Hibon, 2000) <DOI:10.1016/S0169-2070(00)00057-1>.",2018-06-19,Rob Hyndman,"http://pkg.robjhyndman.com/Mcomp/,
https://github.com/robjhyndman/Mcomp",TRUE,https://github.com/robjhyndman/mcomp,52022,5,1535620596
mdir.logrank,"Implemented are the one-sided and two-sided 
  multiple-direction logrank test for two-sample right 
  censored data. In addition to the statistics p-values are calculated: 
  1. For the one-sided testing problem one p-value based on a
   wild bootstrap approach is determined. 2. In the two-sided case
   one p-value based on a chi-squared approximation and 
   a second p-values based on a permutation approach are calculated.
 Ditzhaus, M. and Friedrich, S. (2018) <arXiv:1807.05504>.
 Ditzhaus, M. and Pauly, M. (2018) <arXiv:1808.05627>.",2018-09-29,Marc Ditzhaus and Sarah Friedrich,NA,TRUE,https://github.com/marcdii/mdir.logrank,2195,0,1538143203
mdmb,"
    Contains model-based treatment of missing data for regression 
    models with missing values in covariates or the dependent 
    variable using maximum likelihood or Bayesian estimation 
    (Ibrahim et al., 2005; <doi:10.1198/016214504000001844>).
    The regression model can be nonlinear (e.g., interaction 
    effects, quadratic effects or B-spline functions). 
    Multilevel models with missing data in predictors are
    available for Bayesian estimation. Substantive-model compatible 
    multiple imputation can be also conducted.",2019-01-11,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/mdmb,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/mdmb,11057,2,1554482724
mdsr,"A complement to *Modern Data
    Science with R* (ISBN: 978-1498724487, publisher URL: 
    <https://www.crcpress.com/Modern-Data-Science-with-R/Baumer-Kaplan-Horton/p/book/9781498724487>). 
    This package contains all of the data and code necessary to
    complete exercises and reproduce examples from the text. It also 
    facilitates connections to the SQL database server used in the book.",2018-06-18,Ben Baumer,http://github.com/beanumber/mdsr,TRUE,https://github.com/beanumber/mdsr,17793,20,1544728139
meanr,"Sentiment analysis is a popular technique in text mining.  Roughly
    speaking, the technique is an attempt to determine the overall emotional
    attitude of a piece of text (i.e., positive or negative).  We provide a new
    implementation of a common method for computing sentiment, whereby words are
    scored as positive or negative according to a ""dictionary"", and then an
    sum of those scores for the document is produced.  We use the 'Hu' and 'Liu'
    sentiment dictionary for determining sentiment.  The scoring function is
    'vectorized' by document, and scores for multiple documents are computed in
    parallel via 'OpenMP'.",2017-10-26,Drew Schmidt,https://github.com/wrathematics/meanr,TRUE,https://github.com/wrathematics/meanr,4706,12,1552613805
meanShiftR,"Performs mean shift classification using linear and 
  k-d tree based nearest neighbor implementations for the Gaussian,
  Epanechnikov, and biweight product kernels. ",2018-12-03,Jonathan Lisic,http://meanmean.me/meanshift/r/cran/2016/08/28/meanShiftR.html,TRUE,https://github.com/jlisic/meanshiftr,6304,2,1551113426
medflex,"Run flexible mediation analyses using natural effect models as described in 
  Lange, Vansteelandt and Bekaert (2012) <DOI:10.1093/aje/kwr525>, 
  Vansteelandt, Bekaert and Lange (2012) <DOI:10.1515/2161-962X.1014> 
  and Loeys, Moerkerke, De Smet, Buysse, Steen and Vansteelandt (2013) <DOI:10.1080/00273171.2013.832132>.",2018-09-03,Johan Steen,https://github.com/jmpsteen/medflex,TRUE,https://github.com/jmpsteen/medflex,22390,1,1550014794
Mediana,"Provides a general framework for clinical trial simulations based
    on the Clinical Scenario Evaluation (CSE) approach. The package supports a
    broad class of data models (including clinical trials with continuous, binary,
    survival-type and count-type endpoints as well as multivariate outcomes that are
    based on combinations of different endpoints), analysis strategies and commonly
    used evaluation criteria.",2018-07-16,Gautier Paux,http://gpaux.github.io/Mediana/,TRUE,https://github.com/gpaux/mediana,11892,8,1552423532
meditations,Prints a random quote from Marcus Aurelius' book Meditations.,2019-01-16,Jacob Kaplan,https://github.com/jacobkap/meditations,TRUE,https://github.com/jacobkap/meditations,1196,1,1548166767
meetupapi,"Allows management of 'Meetup' groups via the <https:www.meetup.com/meetup_api/>.
    Provided are a set of functions that enable fetching information of joined meetups, attendance,
    and members. This package requires the use of an API key.",2018-02-20,Zac Davies <zaclavis@gmail.com>,https://github.com/zacdav/meetupapi,TRUE,https://github.com/zacdav/meetupapi,2324,0,1526280138
mefa4,"An S4 update of the 'mefa' package
  using sparse matrices for enhanced efficiency.
  Sparse array-like objects are supported via
  lists of sparse matrices.",2018-03-25,Peter Solymos,https://github.com/psolymos/mefa4,TRUE,https://github.com/psolymos/mefa4,17654,0,1530908237
MEGENA,"Co-Expression Network Analysis by adopting network embedding technique. Song W.-M., Zhang B. (2015) Multiscale Embedded Gene Co-expression Network Analysis. PLoS Comput Biol 11(11): e1004574. <doi: 10.1371/journal.pcbi.1004574>.",2018-09-10,Won-Min Song,https://github.com/songw01/MEGENA,TRUE,https://github.com/songw01/megena,6453,2,1536892850
mem,"The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week.",2018-11-08,Jose E. Lozano,https://github.com/lozalojo/mem,TRUE,https://github.com/lozalojo/mem,18445,1,1554467254
memapp,"The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week. 'memapp' is a web application created in the Shiny framework for the 'mem' R package.",2019-01-29,Jose E. Lozano,https://github.com/lozalojo/memapp,TRUE,https://github.com/lozalojo/memapp,12557,2,1553863976
meme,"The word 'Meme' was originated from the book, 'The Selfish Gene', authored by Richard Dawkins (1976).
             It is a unit of culture that is passed from one generation to another and correlates to the gene, the unit of physical heredity.
             The internet memes are captioned photos that are intended to be funny, ridiculous.
             Memes behave like infectious viruses and travel from person to person quickly through social media.
             The 'meme' package allows users to make custom memes.",2018-09-27,Guangchuang Yu  (<https://orcid.org/0000-0002-6485-8781>),https://github.com/GuangchuangYu/meme/,TRUE,https://github.com/guangchuangyu/meme,6903,17,1537946268
memery,"Generates internet memes that optionally include a superimposed inset plot and other atypical features, 
    combining the visual impact of an attention-grabbing meme with graphic results of data analysis.
    The package differs from related packages that focus on imitating and reproducing standard memes.
    Some packages do this by interfacing with online meme generators whereas others achieve this natively.
    This package takes the latter approach. It does not interface with online meme generators or require any authentication with external websites.
    It reads images directly from local files or via URL and meme generation is done by the package.
    While this is similar to the 'meme' package available on CRAN, it differs in that the focus is on 
    allowing for non-standard meme layouts and hybrids of memes mixed with graphs.
    While this package can be used to make basic memes like an online meme generator would produce, 
    it caters primarily to hybrid graph-meme plots where the meme presentation can be seen as a backdrop highlighting 
    foreground graphs of data analysis results.
    The package also provides support for an arbitrary number of meme text labels with arbitrary size, position and other attributes 
    rather than restricting to the standard top and/or bottom text placement. 
    This is useful for proper aesthetic interleaving of plots of data between meme image backgrounds and overlain text labels.
    The package offers a selection of templates for graph placement and appearance with respect to the underlying meme.
    Graph templates also permit additional template-specific customization.
    Animated gif support is provided but this is optional and functional only if the 'magick' package is installed. 
    'magick' is not required unless gif functionality is desired.",2018-05-17,Matthew Leonawicz,https://github.com/leonawicz/memery,TRUE,https://github.com/leonawicz/memery,5099,12,1552251034
memisc,"An infrastructure for the management of survey data including
        value labels, definable missing values, recoding of variables,
        production of code books, and import of (subsets of) 'SPSS' and
        'Stata' files is provided. Further, the package allows to produce
        tables and data frames of arbitrary descriptive statistics and
        (almost) publication-ready tables of regression model
        estimates, which can be exported to 'LaTeX' and HTML.",2019-03-18,Martin Elff (with contributions from Christopher N. Lawrence,"http://www.elff.eu/software/memisc/,http://github.com/melff/memisc/",TRUE,https://github.com/melff/memisc,316501,24,1554493744
memoise,"Cache the results of a function so that when you call it
    again with the same arguments it returns the pre-computed value.",2017-04-21,Jim Hester,https://github.com/hadley/memoise,TRUE,https://github.com/hadley/memoise,5746995,160,1541499671
memor,"A 'rmarkdown' template that supports company logo, contact info, 
    watermarks and more. Currently restricted to 'Latex'/'Markdown'; a similar 
    'HTML' theme will be added in the future. ",2019-01-16,Hao Zhu  (<https://orcid.org/0000-0002-3386-6076>),https://github.com/hebrewseniorlife/memor,TRUE,https://github.com/hebrewseniorlife/memor,2341,47,1553272596
memuse,"How much ram do you need to store a 100,000 by 100,000 matrix?
    How much ram is your current R session using? How much ram do you even have?
    Learn the scintillating answer to these and many more such questions with
    the 'memuse' package.",2017-11-10,Drew Schmidt,https://github.com/shinra-dev/memuse,TRUE,https://github.com/shinra-dev/memuse,40732,34,1539821061
mephas,"The web-based statistical fundamentals, tests, and models, aiming to facilitate researchers to analyze medical, pharmaceutical and genomic data.",2019-02-04,Yi Zhou  (<https://orcid.org/0000-0001-9254-324>),https://github.com/mephas/mephas,TRUE,https://github.com/mephas/mephas,647,0,1554478880
MESS,"A mixed collection of useful and semi-useful diverse
    statistical functions, some of which may even be referenced in
    The R Primer book.",2019-01-14,Claus Thorn Ekstrøm,https://github.com/ekstroem/MESS,TRUE,https://github.com/ekstroem/mess,48607,0,1551304145
messaging,"Provides tools for creating and issuing nicely-formatted
    text within R diagnostic messages and those messages given during
    warnings and errors. The formatting of the messages can be
    customized using templating features. Issues with singular and
    plural forms can be handled through specialized syntax.",2018-05-27,Richard Iannone  (<https://orcid.org/0000-0003-3925-190X>),https://github.com/rich-iannone/messaging,TRUE,https://github.com/rich-iannone/messaging,1963,9,1527448817
meta,"User-friendly general package providing standard methods for meta-analysis and supporting Schwarzer, Carpenter, and Rücker <DOI:10.1007/978-3-319-21416-0>, ""Meta-Analysis with R"" (2015):
 - fixed effect and random effects meta-analysis;
 - several plots (forest, funnel, Galbraith / radial, L'Abbe, Baujat, bubble);
 - statistical tests and trim-and-fill method to evaluate bias in meta-analysis;
 - import data from 'RevMan 5';
 - prediction interval, Hartung-Knapp and Paule-Mandel method for random effects model;
 - cumulative meta-analysis and leave-one-out meta-analysis;
 - meta-regression (if R package 'metafor' is installed);
 - generalised linear mixed models (if R packages 'metafor', 'lme4', 'numDeriv', and 'BiasedUrn' are installed);
 - produce forest plot summarising several (subgroup) meta-analyses.",2019-01-03,Guido Schwarzer,https://github.com/guido-s/meta http://meta-analysis-with-r.org,TRUE,https://github.com/guido-s/meta,168212,16,1554196719
metaBMA,"Computes the posterior model probabilities for four meta-analysis models 
    (null model vs. alternative model assuming either fixed- or random-effects, respectively).
    These posterior probabilities are used to estimate the overall mean effect size 
    as the weighted average of the mean effect size estimates of the random- and 
    fixed-effect model as proposed by Gronau, Van Erp, Heck, Cesario, Jonas, & 
    Wagenmakers (2017, <doi:10.1080/23743603.2017.1326760>). The user can define 
    a wide range of noninformative or informative priors for the mean effect size 
    and the heterogeneity coefficient. Funding for this research was provided by 
    the Berkeley Initiative for Transparency in the Social Sciences, a program of 
    the Center for Effective Global Action (CEGA), with support from the Laura and 
    John Arnold Foundation.",2017-08-04,Daniel W. Heck,https://github.com/danheck/metaBMA,TRUE,https://github.com/danheck/metabma,4197,2,1523030366
MetabolicSurv,"An approach to identifies metabolic biomarker signature for metabolic data by discovering predictive metabolite for predicting survival and classifying patients into risk groups. 
 Classifiers are constructed as a linear combination of predictive/important metabolites, prognostic factors and treatment effects if necessary. 
 Several methods were implemented to reduce the metabolomics matrix such as the  principle component analysis of Wold Svante et al. (1987) <doi:10.1016/0169-7439(87)80084-9> , 
 the LASSO method by Robert Tibshirani (1998) <doi:10.1002/(SICI)1097-0258(19970228)16:4%3C385::AID-SIM380%3E3.0.CO;2-3>, the 
 elastic net approach by Hui Zou and Trevor Hastie (2005) <doi:10.1111/j.1467-9868.2005.00503.x>. 
 Sensitivity analysis on the quantile used for the classification can also be accessed to check the deviation of the classification group based on the quantile specified. 
 Large scale cross validation can be performed in  order to investigate the mostly selected predictive metabolites and for internal validation. During the evaluation process, validation is accessed using the hazard ratios (HR) distribution of the test set and inference is mainly based on resampling and permutations technique.",2019-01-30,Olajumoke Evangelina Owokotomo,https://github.com/OlajumokeEvangelina/MetabolicSurv,TRUE,https://github.com/olajumokeevangelina/metabolicsurv,526,0,1548060846
metacoder,"A set of tools for parsing, manipulating, and graphing data
    classified by a hierarchy (e.g. a taxonomy).",2019-01-04,Zachary Foster,https://grunwaldlab.github.io/metacoder_documentation/,TRUE,https://github.com/grunwaldlab/metacoder,12449,61,1554445298
metacom,"Functions to analyze coherence, boundary clumping, and turnover
    following the pattern-based metacommunity analysis of Leibold and Mikkelson
    2002  <doi:10.1034/j.1600-0706.2002.970210.x>. The package also includes 
		functions to visualize ecological networks, and to calculate modularity 
		as a replacement to boundary clumping.",2018-08-17,Tad Dallas,https://cran.r-project.org/package=metacom,TRUE,https://github.com/taddallas/metacom,22652,5,1534510318
MetaComp,"Implements routines for metagenome sample taxonomy assignments collection, 
    aggregation, and visualization. Accepts the EDGE-formatted output from GOTTCHA/GOTTCHA2, 
    BWA, Kraken, MetaPhlAn, DIAMOND, and Pangia. Produces SVG and PDF heatmap-like plots 
    comparing taxa abundances across projects. ",2018-06-18,Pavel Senin,https://github.com/seninp-bioinfo/MetaComp,TRUE,https://github.com/seninp-bioinfo/metacomp,4767,2,1529348781
metaDigitise,"High-throughput, flexible and reproducible extraction of data from figures in primary research papers. metaDigitise() can extract data and / or automatically calculate summary statistics for users from box plots, bar plots (e.g., mean and errors), scatter plots and histograms.",2018-07-29,Daniel Noble,NA,TRUE,https://github.com/daniel1noble/metadigitise,2066,46,1547484551
MetaLonDA,Identify time intervals of differentially abundant metagenomics features in longitudinal studies.,2018-05-26,Ahmed Metwally,https://github.com/aametwally/MetaLonDA,TRUE,https://github.com/aametwally/metalonda,5407,1,1552358766
metamedian,"Implements several methods to meta-analyze studies that report the 
    sample median of the outcome. When the primary studies are one-group 
    studies, the methods of McGrath et al. (2019) <doi:10.1002/sim.8013> can 
    be applied to estimate the pooled median. In the two-group context, the 
    methods of McGrath et al. (2018) <arXiv:1809.01278> can be applied to 
    estimate the pooled raw difference of medians across groups.",2019-03-09,Sean McGrath  (<https://orcid.org/0000-0002-7281-3516>),https://github.com/stmcg/metamedian,TRUE,https://github.com/stmcg/metamedian,2862,0,1552086991
metaRMST,"R implementation of a multivariate meta-analysis of randomized controlled trials (RCT) with the difference in restricted mean survival times (RMSTD). Use this package with individual patient level data from an RCT for a time-to-event outcome to determine combined effect estimates according to 4 methods: 1)  a univariate meta-analysis using observed treatment effects, 2) a univariate meta-analysis using effects predicted by fitted Royston-Parmar flexible parametric models, 3) multivariate meta-analysis with analytically derived covariance, 4) multivariate meta-analysis with bootstrap derived covariance. This package computes all combined effects and provides an RMSTD curve with combined effect estimates and their confidence intervals.",2018-12-18,Isabelle Weir,https://github.com/iweir/metaRMST,TRUE,https://github.com/iweir/metarmst,875,0,1551189872
metaSEM,"A collection of functions for conducting meta-analysis using a
             structural equation modeling (SEM) approach via the 'OpenMx' and
             'lavaan' packages. It also implements various procedures to
			 perform meta-analytic structural equation modeling on the
             correlation and covariance matrices.",2018-10-18,Mike W.-L. Cheung <mikewlcheung@nus.edu.sg>,https://github.com/mikewlcheung/metasem,TRUE,https://github.com/mikewlcheung/metasem,22934,11,1552827589
MetaStan,"Performs Bayesian meta-analysis using 'Stan'. 
             Includes binomial-normal hierarchical models and option to use weakly informative priors for the
             heterogeneity parameter and the treatment effect parameter which are described in 
             Guenhan, Roever, and Friede (2018) <arXiv:1809.04407>.",2019-01-19,"Burak Kuersad Guenhan 
    (<https://orcid.org/0000-0002-7454-8680>)",http://github.com/gunhanb/MetaStan,TRUE,https://github.com/gunhanb/metastan,2103,3,1546640481
metaviz,"A compilation of functions to create visually appealing and information-rich 
    plots of meta-analytic data using 'ggplot2'. Currently allows to create forest plots, 
    funnel plots, and many of their variants, such as rainforest plots, thick forest plots, 
    additional evidence contour funnel plots, and sunset funnel plots. In addition, functionalities 
    for visual inference with the funnel plot in the context of meta-analysis are provided.",2019-01-14,Michael Kossmeier,https://github.com/Mkossmeier/metaviz,TRUE,https://github.com/mkossmeier/metaviz,6642,3,1548337051
meteoForecast,"Access to several Numerical Weather Prediction services both in raster format and as a time series for a location. Currently it works with GFS, MeteoGalicia, NAM, and RAP.",2018-11-20,Oscar Perpinan Lamigueiro,http://github.com/oscarperpinan/meteoForecast,TRUE,https://github.com/oscarperpinan/meteoforecast,17908,39,1542669980
meteR,"Fit and plot macroecological patterns predicted by the Maximum
    Entropy Theory of Ecology (METE).",2016-06-27,Andy Rominger,https://github.com/cmerow/meteR,TRUE,https://github.com/cmerow/meter,6758,8,1552583937
metR,"Many useful functions and extensions for dealing
    with meteorological data in the tidy data framework. Extends 'ggplot2'
    for better plotting of scalar and vector fields and provides commonly
    used analysis methods in the atmospheric sciences.",2019-03-12,Elio Campitelli  (<https://orcid.org/0000-0002-7742-9230>),https://github.com/eliocamp/metR,TRUE,https://github.com/eliocamp/metr,1719,47,1552525597
Metrics,"An implementation of evaluation metrics in R that are commonly
             used in supervised machine learning. It implements metrics for
             regression, time series, binary classification, classification,
             and information retrieval problems. It has zero dependencies and
             a consistent, simple interface for all functions.",2018-07-09,Michael Frasco,https://github.com/mfrasco/Metrics,TRUE,https://github.com/mfrasco/metrics,188253,67,1539829419
mets,"Implementation of various statistical models for multivariate
    event history data <doi:10.1007/s10985-013-9244-x>. Including multivariate
    cumulative incidence models <doi:10.1002/sim.6016>, and  bivariate random
    effects probit models (Liability models) <doi:10.1016/j.csda.2015.01.014>.
    Also contains two-stage binomial modelling that can do pairwise odds-ratio
    dependence modelling based marginal logistic regression models. This is an
    alternative to the alternating logistic regression approach (ALR).",2018-11-20,Klaus K. Holst and Thomas Scheike,https://github.com/kkholst/mets,TRUE,https://github.com/kkholst/mets,82152,3,1554198522
metScanR,"A tool for locating, mapping, and gathering environmental data and metadata, worldwide.  Users can search for and filter metadata from > 157,000 environmental monitoring stations among 219 countries/territories and >20 networks/organizations via elevation, location, active dates, elements measured (e.g., temperature, precipitation), country, network, and/or known identifier. Future updates to the package will allow the user to obtain datasets from stations within the database.",2019-02-02,Josh Roberti,https://github.com/jaroberti/metScanR,TRUE,https://github.com/jaroberti/metscanr,7884,6,1549063288
metsyn,"Provides an interface with the Meteo France Synop data API 
    (see <https://donneespubliques.meteofrance.fr/?fond=produit&id_produit=90&id_rubrique=32> 
    for more information). 
    The Meteo France Synop data are made of meteorological data recorded 
    every three hours on 62 French meteorological stations. ",2018-11-14,Paul Poncet,https://github.com/paulponcet/metsyn,TRUE,https://github.com/paulponcet/metsyn,1038,0,1542326238
mev,Exact simulation from max-stable processes and multivariate extreme value distributions for various parametric models. Threshold selection methods.,2018-02-22,Leo Belzile,https://github.com/lbelzile/mev/,TRUE,https://github.com/lbelzile/mev,14286,0,1551280387
mfbvar,"Estimation of mixed-frequency Bayesian vector autoregressive (VAR) models with Minnesota or steady-state priors. The package implements a state space-based VAR model that handles mixed frequencies of the data. The model is estimated using Markov Chain Monte Carlo to numerically approximate the posterior distribution, where the prior can be either the Minnesota prior, as used by Schorfheide and Song (2015) <doi:10.1080/07350015.2014.954707>, or the steady-state prior, as advocated by Ankargren, Unosson and Yang (2018) <http://uu.diva-portal.org/smash/get/diva2:1260262/FULLTEXT01.pdf>.",2018-12-27,"Sebastian Ankargren 
    (<https://orcid.org/0000-0003-4415-8734>)",https://github.com/ankargren/mfbvar,TRUE,https://github.com/ankargren/mfbvar,823,8,1546205094
mfe,"Extracts meta-features from datasets to support the design of 
  recommendation systems based on Meta-Learning. The meta-features, also called 
  characterization measures, are able to characterize the complexity of datasets
  and to provide estimates of algorithm performance. The package contains not 
  only the standard characterization measures, but also more recent 
  characterization measures. By making available a large set of meta-feature 
  extraction functions, tasks like comprehensive data characterization, deep 
  data exploration and large number of Meta-Learning based data analysis can be
  performed. These concepts are described in the paper: Fabio Pinto, Carlos 
  Soares, and Joao Mendes-Moreira. Towards automatic generation of metafeatures.
  In Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 
  pages 215 - 226, 2016, <doi:10.1007/978-3-319-31753-3_18>.",2018-06-29,Adriano Rivolli,https://github.com/rivolli/mfe,TRUE,https://github.com/rivolli/mfe,4421,11,1553615089
mfGARCH,"Estimating GARCH-MIDAS (MIxed-DAta-Sampling) models (Engle, Ghysels, Sohn, 2013, <doi:10.1162/REST_a_00300>) and related statistical inference, accompanying the paper ""Two are better than one: volatility forecasting using multiplicative component GARCH models"" by Conrad and Kleen (2018, <doi:10.2139/ssrn.2752354>). The GARCH-MIDAS model decomposes the conditional variance of (daily) stock returns into a short- and long-term component, where the latter may depend on an exogenous covariate sampled at a lower frequency. ",2018-08-06,Onno Kleen,https://github.com/onnokleen/mfGARCH/,TRUE,https://github.com/onnokleen/mfgarch,3401,10,1551690964
MFPCA,"Calculate a multivariate functional principal component analysis
    for data observed on different dimensional domains. The estimation algorithm
    relies on univariate basis expansions for each element of the multivariate
    functional data  (Happ & Greven, 2018) <doi:10.1080/01621459.2016.1273115>. Multivariate and univariate functional data objects are
    represented by S4 classes for this type of data implemented in the package
    'funData'. For more details on the general concepts of both packages and a case study, see Happ (2018) <arXiv:1707.02129>.",2019-03-20,Clara Happ  (<https://orcid.org/0000-0003-4737-3835>),https://github.com/ClaraHapp/MFPCA,TRUE,https://github.com/clarahapp/mfpca,8261,9,1553029917
mgc,"Multiscale Graph Correlation (MGC) is a framework developed by Shen et al. (2017) <arXiv:1609.05148> that extends global correlation procedures to be multiscale; consequently, MGC tests typically require far fewer samples than existing methods for a wide variety of dependence structures and dimensionalities, while maintaining computational efficiency. Moreover, MGC provides a simple and elegant multiscale characterization of the potentially complex latent geometry underlying the relationship. ",2018-04-13,Eric Bridgeford,https://github.com/neurodata/mgc,TRUE,https://github.com/neurodata/mgc,2132,8,1553476657
mgcViz,"Extension of the 'mgcv' package, providing visual tools for Generalized Additive Models that exploit the additive structure of such models, scale to large data sets and can be used in conjunction with a wide range of response distributions. The focus is providing visual methods for better understanding the model output and for aiding model checking and development beyond simple exponential family regression. The graphical framework is based on the layering system provided by 'ggplot2'.",2019-01-23,Matteo Fasiolo,https://github.com/mfasiolo/mgcViz,TRUE,https://github.com/mfasiolo/mgcviz,3769,49,1554114851
mgm,Estimation of k-Order time-varying Mixed Graphical Models and mixed VAR(p) models via elastic-net regularized neighborhood regression. For details see linked paper.,2019-03-14,Jonas Haslbeck,https://arxiv.org/abs/1510.06871,TRUE,https://github.com/jmbh/mgm,23493,15,1553785237
mhsmm,"Parameter estimation and prediction for hidden Markov and semi-Markov models for data with multiple observation sequences.  Suitable for equidistant time series data, with multivariate and/or missing data. Allows user defined emission distributions.",2017-01-15,Jared OConnell <jaredoconnell@gmail.com>,https://github.com/jaredo/mhsmm,TRUE,https://github.com/jaredo/mhsmm,27553,7,1553721588
MHTdiscrete,"A comprehensive tool for almost all existing multiple testing
    methods for discrete data. The package also provides some novel multiple testing
    procedures controlling FWER/FDR for discrete data. Given discrete p-values
    and their domains, the [method].p.adjust function returns adjusted p-values,
    which can be used to compare with the nominal significant level alpha and make
    decisions. For users' convenience, the functions also provide the output option 
    for printing decision rules.",2018-12-15,Yalin Zhu,https://allen.shinyapps.io/MTPs/,TRUE,https://github.com/allenzhuaz/mhtdiscrete,6505,0,1543113600
MIAmaxent,"Tools for training, selecting, and evaluating maximum entropy
    (and standard logistic regression) distribution models. This package 
    provides tools for user-controlled transformation of explanatory variables, 
    selection of variables by nested model comparison, and flexible model 
    evaluation and projection. It follows principles based on the maximum-
    likelihood interpretation of maximum entropy modeling, and uses infinitely-
    weighted logistic regression for model fitting.",2018-11-13,Julien Vollering,https://github.com/julienvollering/MIAmaxent,TRUE,https://github.com/julienvollering/miamaxent,6134,8,1552386339
micar,"'Mica' is a server application used to create data web portals for 
    large-scale epidemiological studies or multiple-study consortia. 'Mica' helps
    studies to provide scientifically robust data visibility and web presence 
    without significant information technology effort. 'Mica' provides a 
    structured description of consortia, studies, annotated and searchable data
    dictionaries, and data access request management. This 'Mica' client allows
    to perform data extraction for reporting purposes.",2019-02-22,Yannick Marcon  (<https://orcid.org/0000-0003-0138-2023>),"https://www.obiba.org/ https://www.obiba.org/pages/products/mica/
https://doi.org/10.1093/ije/dyx180",TRUE,https://github.com/obiba/micar,356,0,1552340106
mice,"Multiple imputation using Fully Conditional Specification (FCS)
    implemented by the MICE algorithm as described in Van Buuren and
    Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>. Each variable has
    its own imputation model. Built-in imputation models are provided for
    continuous data (predictive mean matching, normal), binary data (logistic
    regression), unordered categorical data (polytomous logistic regression)
    and ordered categorical data (proportional odds). MICE can also impute
    continuous two-level data (normal model, pan, second-level variables).
    Passive imputation can be used to maintain consistency between variables.
    Various diagnostic plots are available to inspect the quality of the
    imputations.",2019-03-07,Stef van Buuren,"http://stefvanbuuren.github.io/mice/ ,
http://www.stefvanbuuren.name ,
http://www.stefvanbuuren.name/fimd/",TRUE,https://github.com/stefvanbuuren/mice,1172833,100,1554481880
miceadds,"
    Contains functions for multiple imputation which
    complements existing functionality in R.
    In particular, several imputation methods for the
    mice package (van Buuren & Groothuis-Oudshoorn, 2011,
    <doi:10.18637/jss.v045.i03>) are included.
    Main features of the miceadds package include
    plausible value imputation (Mislevy, 1991,
    <doi:10.1007/BF02294457>), multilevel imputation for
    variables at any level or with any number of hierarchical
    and non-hierarchical levels (Grund, Luedtke & Robitzsch,
    2018, <doi:10.1177/1094428117703686>; van Buuren, 2018, 
    Ch.7, <doi:10.1201/9780429492259>), imputation using 
    partial least squares (PLS) for high dimensional 
    predictors (Robitzsch, Pham & Yanagida, 2016), 
    and nested multiple imputation (Rubin, 2003, 
    <doi:10.1111/1467-9574.00217>).",2019-03-18,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/miceadds,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/miceadds,340921,5,1554482653
miceExt,"Extends and builds on the 'mice' package by
	adding a functionality to perform multivariate predictive mean matching on
	imputed data as well as new functionalities to perform predictive mean
	matching on factor variables.",2018-03-05,Tobias Schumacher,http://github.com/tobiasschumacher/miceExt,TRUE,https://github.com/tobiasschumacher/miceext,2584,0,1523018574
miceFast,"
  Fast imputations under the object-oriented programming paradigm.
	There was used quantitative models with a closed-form solution. Thus package is based on linear algebra operations.
	The biggest improvement in time performance could be achieve for a calculation where a grouping variable have to be used.
	A single evaluation of a quantitative model for the multiple imputations is another major enhancement.
	Moreover there are offered a few functions built to work with popular R packages such as 'data.table'.",2018-05-06,Maciej Nasinski,https://github.com/Polkas/miceFast,TRUE,https://github.com/polkas/micefast,2813,1,1525634895
microbenchmark,"Provides infrastructure to accurately measure and compare
        the execution time of R expressions.",2018-10-18,Joshua M. Ulrich,https://github.com/joshuaulrich/microbenchmark/,TRUE,https://github.com/joshuaulrich/microbenchmark,581993,26,1547392282
microdemic,"The 'Microsoft Academic Knowledge' API provides programmatic access
	to scholarly articles in the 'Microsoft Academic Graph'
	(<https://academic.microsoft.com/>). Includes methods matching all 'Microsoft
	Academic' API routes, including search, graph search, text similarity, and
	interpret natural language query string.",2018-10-25,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/microdemic,TRUE,https://github.com/ropensci/microdemic,10702,9,1547667611
microsynth,"A generalization of the 'Synth' package that is designed
 for data at a more granular level (e.g., micro-level). Provides
 functions to construct weights (including propensity score-type
 weights) and run analyses for synthetic control methods with
 micro- and meso-level data; see Robbins, Saunders, and Kilmer 
 (2017) <doi:10.1080/01621459.2016.1213634>.",2018-05-16,Michael Robbins,https://github.com/ssdavenport/microsynth,TRUE,https://github.com/ssdavenport/microsynth,2094,0,1554492106
midasr,"Methods and tools for mixed frequency time series data analysis.
    Allows estimation, model selection and forecasting for MIDAS regressions.",2019-03-05,Virmantas Kvedaras <virmantas.kvedaras@ec.europa.eu>,http://mpiktas.github.io/midasr/,TRUE,https://github.com/mpiktas/midasr,27686,25,1551881607
migest,"Indirect methods for estimating bilateral migration flows in the presence of partial or missing data, including the estimation of bilateral migration flows from changes in bilateral migrant stock tables (e.g. Abel (2013) <doi:10.4054/DemRes.2013.28.18>).",2019-02-24,Guy J. Abel  (<https://orcid.org/0000-0002-4893-5687>),https://github.com/gjabel/migest/,TRUE,https://github.com/gjabel/migest,23245,9,1551082124
mime,"Guesses the MIME type from a filename extension using the data
    derived from /etc/mime.types in UNIX-type systems.",2018-10-05,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/yihui/mime,TRUE,https://github.com/yihui/mime,11211707,17,1538773076
mimsy,"Calculate dissolved gas concentrations from raw MIMS 
	(Membrane Inlet Mass Spectrometer, Bay Instruments) signal data. 
	Use mimsy() on a formatted CSV file to return dissolved gas 
	concentrations (mg and microMole) and ratios of N2, O2, Ar based on 
	gas solubility at temperature, pressure, and salinity. See references 
	Benson and Krause (1984) <DOI:10.4319/lo.1992.37.6.1307>, Garcia and 
	Gordon (1992) <DOI:10.4319/lo.1984.29.3.0620>, Stull (1947) 
	<DOI:10.1021/ie50448a022>, and Hamme and Emerson (2004) 
	<DOI:10.1016/j.dsr.2004.06.009> for more information. Easily save the 
	output to a nicely-formatted multi-tab 'Excel' workbook with mimsy.save(). 
	Supports dual-temperature standard calibration for dual-bath MIMS setups.",2019-03-10,Michelle C. Kelly,"https://github.com/michelleckelly/mimsy,
https://michelleckelly.github.io/mimsy/",TRUE,https://github.com/michelleckelly/mimsy,239,0,1552515417
mindr,"Convert Markdown ('.md') or Rmarkdown ('.Rmd') files into mindmap widgets or files ('.mm'), and vice versa. FreeMind mindmap ('.mm') files can be opened by or imported to common mindmap software such as 'FreeMind' (<http://freemind.sourceforge.net/wiki/index.php/Main_Page>) and 'XMind' (<http://www.xmind.net>).",2019-02-28,Peng Zhao,https://github.com/pzhaonet/mindr,TRUE,https://github.com/pzhaonet/mindr,7494,420,1551350004
miniCRAN,"Makes it possible to create an internally consistent
    repository consisting of selected packages from CRAN-like repositories.
    The user specifies a set of desired packages, and 'miniCRAN' recursively
    reads the dependency tree for these packages, then downloads only this
    subset. The user can then install packages from this repository directly,
    rather than from CRAN.  This is useful in production settings, e.g. server
    behind a firewall, or remote locations with slow (or zero) Internet access.",2018-01-15,Andrie de Vries,https://github.com/andrie/miniCRAN,TRUE,https://github.com/andrie/minicran,63699,90,1529679523
minval,"For a given set of stoichiometric reactions, this package
    evaluates the mass and charge balance, extracts all reactants, products, orphan
    metabolites, metabolite names and compartments. Also are included some options
    to characterize and write models in TSV and SBML formats.",2018-04-12,Daniel Osorio,https://github.com/gibbslab/minval,TRUE,https://github.com/gibbslab/minval,9007,2,1550715714
mipfp,"An implementation of the iterative proportional fitting (IPFP), 
    maximum likelihood, minimum chi-square and weighted least squares procedures
    for updating a N-dimensional array with respect to given target marginal 
    distributions (which, in turn can be multidimensional). The package also
    provides an application of the IPFP to simulate multivariate Bernoulli
    distributions.",2018-08-29,Johan Barthelemy,https://github.com/jojo-/mipfp,TRUE,https://github.com/jojo-/mipfp,19797,7,1528203254
mirt,"Analysis of dichotomous and polytomous response data using
    unidimensional and multidimensional latent trait models under the Item
    Response Theory paradigm (Chalmers (2012) <doi:10.18637/jss.v048.i06>). 
    Exploratory and confirmatory models can be estimated with quadrature (EM) 
    or stochastic (MHRM) methods. Confirmatory
    bi-factor and two-tier analyses are available for modeling item testlets.
    Multiple group analysis and mixed effects designs also are available for
    detecting differential item and test functioning as well as modeling
    item and person covariates. Finally, latent class models such as the DINA,
    DINO, multidimensional latent class, and several other discrete latent
    variable models, including mixture and zero-inflated response models, 
    are supported.",2019-01-29,Phil Chalmers,"https://github.com/philchalmers/mirt,
https://github.com/philchalmers/mirt/wiki,
https://groups.google.com/forum/#!forum/mirt-package",TRUE,https://github.com/philchalmers/mirt,182460,86,1554251571
mirtCAT,"Provides tools to generate an HTML interface for creating adaptive
    and non-adaptive educational and psychological tests using the shiny
    package (Chalmers (2016) <doi:10.18637/jss.v071.i05>). 
    Suitable for applying unidimensional and multidimensional
    computerized adaptive tests (CAT) using item response theory methodology and for
    creating simple questionnaires forms to collect response data directly in R.
    Additionally, optimal test designs (e.g., ""shadow testing"") are supported
    for tests which contain a large number of item selection constraints.
    Finally, package contains tools useful for performing Monte Carlo simulations 
    for studying the behavior of computerized adaptive test banks.",2018-10-22,Phil Chalmers,"https://github.com/philchalmers/mirtCAT,
https://github.com/philchalmers/mirtCAT/wiki,
https://groups.google.com/forum/#!forum/mirt-package",TRUE,https://github.com/philchalmers/mirtcat,55975,41,1547955454
mirtjml,"Provides constrained joint maximum likelihood estimation
    algorithms for item factor analysis (IFA) based on multidimensional item response theory
    models. So far, we provide functions for exploratory and confirmatory IFA based on the 
    multidimensional two parameter logistic (M2PL) model for binary response data. Comparing 
    with traditional estimation methods for IFA, the methods implemented in this package scale
    better to data with large numbers of respondents, items, and latent factors. The computation
    is facilitated by multiprocessing 'OpenMP' API. For more information, please refer to:
    1. Chen, Y., Li, X., & Zhang, S. (2018). Joint Maximum Likelihood Estimation for 
    High-Dimensional Exploratory Item Factor Analysis. Psychometrika, 1-23. 
    <doi:10.1007/s11336-018-9646-5>;
    2. Chen, Y., Li, X., & Zhang, S. (2017). Structured Latent Factor Analysis for Large-scale Data: 
    Identifiability, Estimability, and Their Implications. arXiv preprint <arXiv:1712.08966>.",2018-12-21,Siliang Zhang,https://github.com/slzhang-fd/mirtjml,TRUE,https://github.com/slzhang-fd/mirtjml,977,1,1552893717
misaem,"Estimate parameters of logistic regression with missing data and perform model selection, using algorithm Stochastic Approximation EM.",2019-01-15,Wei Jiang,https://github.com/wjiang94/misaem.git,TRUE,https://github.com/wjiang94/misaem,1034,0,1547554232
missCompare,"Offers a convenient pipeline to test and compare various missing data
  imputation algorithms on simulated and real data. The central assumption behind missCompare is that structurally
  different datasets (e.g. larger datasets with a large number of correlated variables vs. smaller datasets
  with non correlated variables) will benefit differently from different missing data imputation algorithms.
  missCompare takes measurements of your dataset and sets up a sandbox to try a curated list of standard and 
  sophisticated missing data imputation algorithms and compares them assuming custom missingness patterns.
  missCompare will also impute your real-life dataset for you after the selection of the best performing algorithm
  in the simulations. The package also provides various post-imputation diagnostics and visualizations to help you 
  assess imputation performance.    ",2019-02-05,Tibor V. Varga  (<https://orcid.org/0000-0002-2383-699X>),NA,TRUE,https://github.com/tirgit/misscompare,489,3,1550825769
mitml,"Provides tools for multiple imputation of missing data in multilevel
 modeling. Includes a user-friendly interface to the packages 'pan' and 'jomo',
 and several functions for visualization, data management and the analysis 
 of multiply imputed data sets.",2019-01-07,Simon Grund,NA,TRUE,https://github.com/simongrund1/mitml,510020,6,1546426586
MittagLeffleR,"Implements the Mittag-Leffler function, distribution,
  random variate generation, and estimation. Based on the Laplace-Inversion
  algorithm by Garrappa, R. (2015) <doi:10.1137/140971191>.",2018-04-25,Peter Straka,https://strakaps.github.io/MittagLeffleR/,TRUE,https://github.com/strakaps/mittagleffler,5492,2,1536714314
miWQS,"Consider a set/mixture of continuous, correlated, and censored components/chemicals that are reasonable to combine in an index and share a common outcome. These components are also interval-censored between zero and upper thresholds, or detection limits, that may be different among the components. The `miWQS` package applies the multiple imputation (MI) procedure to the weighted quantile sum regression (WQS) methodology for continuous, binary, or count outcomes.  In summary, MI consists of three stages: (1) imputation, (2) analysis, and (3) pooling. First,  the missing values are imputed by bootstrapping (Lubin et.al (2004) <doi:10.1289/ehp.7199>), Bayesian imputation, or placing the below the detection limits in the first quantile (BDLQ1) (Ward et.al. (2014) <doi:10.1289/ehp.1307602>). Second, the estimate.wqs() function implements WQS regression if the components are complete, imputed, or missing (Carrico et.al. (2014) <doi:10.1007/s13253-014-0180-3>) . If the data is missing, BDLQ1 is automatically implemented.  Lastly, the pool.mi() function calculates the pooled statistics according to Rubin's rules (Rubin 1987). ",2018-12-23,Paul M. Hargarten,NA,TRUE,https://github.com/phargarten2/miwqs,1551,0,1535655103
mixchar,"Deconvolution of thermal decay curves allows you to quantify proportions 
    of biomass components in plant litter. Thermal decay curves derived from 
    thermogravimetric analysis (TGA) are imported, modified, and then modelled in a 
    three- or four- part  mixture model using the Fraser-Suzuki function. The output 
    is estimates for weights of pseudo-components corresponding to hemicellulose, 
    cellulose, and lignin. For more information see: Müller-Hagedorn, M. and Bockhorn, 
    H. (2007) <doi:10.1016/j.jaap.2006.12.008>, Órfão, J. J. M. and Figueiredo, J. L. 
    (2001) <doi:10.1016/S0040-6031(01)00634-7>, and Yang, H. and Yan, R. and 
    Chen, H. and Zheng, C. and Lee, D. H. and Liang, D. T. (2006) <doi:10.1021/ef0580117>.",2018-08-16,Saras Windecker,http://github.com/smwindecker/mixchar,TRUE,https://github.com/smwindecker/mixchar,1683,6,1538503940
mixdir,"Scalable Bayesian clustering of categorical datasets. The package implements a hierarchical Dirichlet 
    (Process) mixture  of multinomial distributions. It is thus a probabilistic latent class model (LCM) and can be used
    to reduce the  dimensionality of hierarchical data and cluster individuals into latent classes. It can automatically
    infer an appropriate number of latent classes or find k classes, as defined by the user.  The model is based on a
    paper by Dunson and Xing (2009) <doi:10.1198/jasa.2009.tm08439>, but implements a scalable variational inference algorithm so that it is
    applicable to large datasets. It is described and tested in the accompanying paper by 
    Ahlmann-Eltze and Yau (2018) <doi:10.1109/DSAA.2018.00068>.",2019-03-11,Constantin Ahlmann-Eltze,https://github.com/const-ae/mixdir,TRUE,https://github.com/const-ae/mixdir,1921,5,1552399004
MixfMRI,"Utilizing model-based clustering (unsupervised)
        for functional magnetic resonance imaging (fMRI) data.
        The developed methods (Chen and Maitra (2018, manuscript)) include
        2D and 3D clustering analyses (for p-values with voxel locations) and
        segmentation analyses (for p-values alone) for fMRI data where p-values
        indicate significant level of activation responding to stimulate
        of interesting. The analyses are mainly identifying active
        voxel/signal associated with normal brain behaviors.
        Analysis pipelines (R scripts) utilizing this package
        (see examples in 'inst/workflow/') is also implemented with high
        performance techniques.",2018-04-26,Wei-Chen Chen,https://github.com/snoweye/MixfMRI,TRUE,https://github.com/snoweye/mixfmri,2001,1,1533932629
mixggm,"Mixtures of Gaussian graphical models for model-based clustering with sparse covariance and concentration matrices. See Fop, Murphy, and Scrucca (2018) <doi:10.1007/s11222-018-9838-y>.",2018-11-14,Michael Fop  (<https://orcid.org/0000-0003-3936-2757>),https://github.com/michaelfop/mixggm,TRUE,https://github.com/michaelfop/mixggm,1046,0,1546865428
MixSIAR,"Creates and runs Bayesian mixing models to analyze
    biological tracer data (i.e. stable isotopes, fatty acids), which estimate the
    proportions of source (prey) contributions to a mixture (consumer). 'MixSIAR'
    is not one model, but a framework that allows a user to create a mixing model
    based on their data structure and research questions, via options for fixed/
    random effects, source data types, priors, and error terms. 'MixSIAR' incorporates
    several years of advances since 'MixSIR' and 'SIAR', and includes both GUI
    (graphical user interface) and script versions.",2018-04-13,Brian Stock,https://github.com/brianstock/MixSIAR,TRUE,https://github.com/brianstock/mixsiar,10574,29,1549896883
mixsqp,"Provides optimization algorithms based on sequential
  quadratic programming (SQP) for maximum likelihood estimation of the
  mixture proportions in a finite mixture model where the component
  densities are known. The algorithms are expected to obtain solutions
  that are at least as accurate as the state-of-the-art MOSEK
  interior-point solver (called by function ""KWDual"" in the 'REBayes'
  package), and they are expected to arrive at solutions more quickly
  in large data sets. The algorithms are described in Y. Kim,
  P. Carbonetto, M. Stephens & M. Anitescu (2012) <arXiv:1806.01412>.",2019-02-18,Peter Carbonetto,https://github.com/stephenslab/mixsqp,TRUE,https://github.com/stephenslab/mixsqp,2433,2,1554393589
mize,"Optimization algorithms implemented in R, including
    conjugate gradient (CG), Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the
    limited memory BFGS (L-BFGS) methods. Most internal parameters can be set 
    through the call interface. The solvers hold up quite well for 
    higher-dimensional problems.",2018-09-14,James Melville,http://github.com/jlmelville/mize,TRUE,https://github.com/jlmelville/mize,4459,3,1553618454
mkin,"Calculation routines based on the FOCUS Kinetics Report (2006,
  2014).  Includes a function for conveniently defining differential equation
  models, model solution based on eigenvalues if possible or using numerical
  solvers and a choice of the optimisation methods made available by the 'FME'
  package.  If a C compiler (on windows: 'Rtools') is installed, differential
  equation models are solved using compiled C functions.  Please note that no
  warranty is implied for correctness of results or fitness for a particular
  purpose.",2019-03-04,Johannes Ranke,https://cgit.jrwb.de/mkin/about,TRUE,https://github.com/jranke/mkin,37739,5,1553007660
mknapsack,"Package solves multiple knapsack optimisation problem. 
    Given a set of items, each with volume and value, 
    it will allocate them to knapsacks of a given size in a way that
    value of top N knapsacks is as large as possible.",2018-04-10,Bulat Yapparov,https://github.com/madedotcom/mknapsack,TRUE,https://github.com/madedotcom/mknapsack,2364,0,1530137332
MlBayesOpt,"Hyper parameter tuning using Bayesian
    optimization (Shahriari et al. <doi:10.1109/JPROC.2015.2494218>) for support vector machine,
    random forest, and extreme gradient boosting (Chen & Guestrin (2016) <doi:10.1145/2939672.2939785>). 
    Unlike already existing packages (e.g. 'mlr', 'rBayesianOptimization', or 'xgboost'), there is no need to change in accordance with the package or method of machine learning.
    You just prepare a data frame with feature vectors and the label column that has any class ('character', 'factor', 'integer').
    Moreover, to write a optimization function, you have only to specify the data and the column name of the label to classify.",2019-03-20,Yuya Matsumura,https://github.com/ymattu/MlBayesOpt,TRUE,https://github.com/ymattu/mlbayesopt,4143,33,1553065418
mlbgameday,Multi-core processing of data from Major League Baseball Advanced Media <http://gd2.mlb.com/components/game/mlb/>. Additional tools to parallel process large data sets and write them to a database. ,2019-04-02,Kris Eberwein,https://github.com/keberwein/mlbgameday,TRUE,https://github.com/keberwein/mlbgameday,4747,20,1554226877
mldr,"Exploratory data analysis and manipulation functions for multi-
    label data sets along with an interactive Shiny application to ease their use.",2019-01-28,David Charte  (<https://orcid.org/0000-0002-4830-9512>),https://github.com/fcharte/mldr,TRUE,https://github.com/fcharte/mldr,32336,11,1551871049
mldr.datasets,"Large collection of multilabel datasets along with the functions
    needed to export them to several formats, to make partitions, and to obtain
    bibliographic information.",2019-01-17,David Charte  (<https://orcid.org/0000-0002-4830-9512>),https://github.com/fcharte/mldr.datasets,TRUE,https://github.com/fcharte/mldr.datasets,18087,3,1552411948
mleap,"A 'sparklyr' <https://spark.rstudio.com> extension that provides
  an interface to 'MLeap' <https://github.com/combust/mleap>, an open source library
  that enables exporting and serving of 'Apache Spark' pipelines.",2018-11-01,Kevin Kuo  (<https://orcid.org/0000-0001-7803-7901>),https://github.com/rstudio/mleap,TRUE,https://github.com/rstudio/mleap,4203,15,1541029627
mlflow,"R interface to 'MLflow', open source platform for the complete machine
  learning life cycle, see <https://mlflow.org/>. This package supports installing
  'MLflow', tracking experiments, creating and running projects, and saving and
  serving models.",2019-03-28,Matei Zaharia,https://github.com/mlflow/mlflow,TRUE,https://github.com/mlflow/mlflow,10694,3416,1554410831
MLML2R,"Maximum likelihood estimates (MLE) of the proportions
    of 5-mC and 5-hmC in the DNA using information from BS-conversion,
    TAB-conversion, and oxBS-conversion methods. One can use information from all three methods 
    or any combination of two of them. Estimates are based on Binomial model by
    Qu et al. (2013) <doi:10.1093/bioinformatics/btt459> and
    Kiihl et al. (2019) <doi:10.1515/sagmb-2018-0031>.",2019-04-06,Samara Kiihl,https://github.com/samarafk/MLML2R,TRUE,https://github.com/samarafk/mlml2r,3745,1,1554559382
mlr,"Interface to a large number of classification and regression
    techniques, including machine-readable parameter descriptions. There is
    also an experimental extension for survival analysis, clustering and
    general, example-specific cost-sensitive learning. Generic resampling,
    including cross-validation, bootstrapping and subsampling. Hyperparameter
    tuning with modern optimization techniques, for single- and multi-objective
    problems. Filter and wrapper methods for feature selection. Extension of
    basic learners with additional operations common in machine learning, also
    allowing for easy nested resampling. Most operations can be parallelized.",2018-08-28,Bernd Bischl  (<https://orcid.org/0000-0001-6002-6980>),https://github.com/mlr-org/mlr,TRUE,https://github.com/mlr-org/mlr,230530,1210,1554476763
mlrCPO,"Toolset that enriches 'mlr' with a diverse set of preprocessing
    operators. Composable Preprocessing Operators (""CPO""s) are first-class
    R objects that can be applied to data.frames and 'mlr' ""Task""s to modify
    data, can be attached to 'mlr' ""Learner""s to add preprocessing to machine
    learning algorithms, and can be composed to form preprocessing pipelines.",2019-01-10,Martin Binder,https://github.com/mlr-org/mlrCPO,TRUE,https://github.com/mlr-org/mlrcpo,3827,29,1553631571
mlrMBO,"Flexible and comprehensive R toolbox for model-based optimization
    ('MBO'), also known as Bayesian optimization. It implements the Efficient
    Global Optimization Algorithm and is designed for both single- and multi-
    objective optimization with mixed continuous, categorical and conditional
    parameters. The machine learning toolbox 'mlr' provide dozens of regression
    learners to model the performance of the target algorithm with respect to
    the parameter settings. It provides many different infill criteria to guide
    the search process. Additional features include multi-point batch proposal,
    parallel execution as well as visualization and sophisticated logging
    mechanisms, which is especially useful for teaching and understanding of
    algorithm behavior. 'mlrMBO' is implemented in a modular fashion, such that
    single components can be easily replaced or adapted by the user for specific
    use cases.",2018-06-21,Bernd Bischl (<https://orcid.org/0000-0001-6002-6980>),https://github.com/mlr-org/mlrMBO,TRUE,https://github.com/mlr-org/mlrmbo,27339,128,1551780668
mltools,"A collection of machine learning helper functions, particularly assisting in the Exploratory Data Analysis phase. Makes heavy use of the 'data.table' package for optimal speed and memory efficiency. Highlights include a versatile bin_data() function, sparsify() for converting a data.table to sparse matrix format with one-hot encoding, fast evaluation metrics, and empirical_cdf() for calculating empirical Multivariate Cumulative Distribution Functions.",2018-05-12,Ben Gorman,https://github.com/ben519/mltools,TRUE,https://github.com/ben519/mltools,20353,55,1551215566
mlxR,"Simulation and visualization of complex
    models for longitudinal data. The models are encoded using the model coding
    language 'Mlxtran', automatically converted into C++ codes, compiled on the
    fly and linked to R using the 'Rcpp' package. That allows one to implement
    very easily complex ODE-based models and complex statistical models,
    including mixed effects models, for continuous, count, categorical, and
    time-to-event data.",2018-02-20,Marc Lavielle,http://simulx.webpopix.org,TRUE,https://github.com/marclavielle/mlxr,17230,9,1549044953
mmand,"Provides tools for performing mathematical morphology operations,
    such as erosion and dilation, on data of arbitrary dimensionality. Can also
    be used for finding connected components, resampling, filtering, smoothing
    and other image processing-style operations.",2019-03-17,Jon Clayden,https://github.com/jonclayden/mmand,TRUE,https://github.com/jonclayden/mmand,26996,19,1552857755
mmapcharr,"Uses memory-mapping to enable the random access of elements of
  a text file of characters separated by characters as if it were a simple
  R(cpp) matrix.",2019-02-26,Florian Privé,https://github.com/privefl/mmapcharr,TRUE,https://github.com/privefl/mmapcharr,4885,5,1551172315
MMeM,"Analyzing data under multivariate mixed effects model using multivariate REML and multivariate Henderson3 methods. 
  See Meyer (1985) <doi:10.2307/2530651> and Wesolowska Janczarek (1984) <doi:10.1002/bimj.4710260613>.",2019-02-03,Luyao Peng,NA,TRUE,https://github.com/pengluyaoyao/mmem,519,1,1549341614
mmpf,Marginalizes prediction functions using Monte-Carlo integration and computes permutation importance.,2018-10-24,Zachary Jones,NA,TRUE,https://github.com/zmjones/mmpf,25932,7,1540338840
mnis,An API package for the Members' Name Information Service operated by the UK parliament. Documentation for the API itself can be found here: <http://data.parliament.uk/membersdataplatform/default.aspx>.,2017-07-03,Evan Odell,http://docs.evanodell.com/mnis,TRUE,https://github.com/evanodell/mnis,6279,2,1550576849
mnlfa,"
    Conducts moderated nonlinear factor analysis (e.g., Curran et al., 2014,
    <doi:10.1080/00273171.2014.889594>). 
    Regularization methods are implemented for assessing non-invariant items. 
    Currently, the package includes dichotomous items and unidimensional
    item response models. Extensions will be included in future package
    versions.",2019-04-05,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/mnlfa,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/mnlfa,0,0,1554465062
MNP,"Fits the Bayesian multinomial probit model via Markov chain
 Monte Carlo.  The multinomial probit model is often used to analyze 
 the discrete choices made by individuals recorded in survey data. 
 Examples where the multinomial probit model may be useful include the 
 analysis of product choice by consumers in market research and the 
 analysis of candidate or party choice by voters in electoral studies.  
 The MNP package can also fit the model with different choice sets for 
 each individual, and complete or partial individual choice orderings 
 of the available alternatives from the choice set. The estimation is
 based on the efficient marginal data augmentation algorithm that is 
 developed by Imai and van Dyk (2005). ``A Bayesian Analysis of the 
 Multinomial Probit Model Using the Data Augmentation,'' Journal of 
 Econometrics, Vol. 124, No. 2 (February), pp. 311-334. 
 <DOI:10.1016/j.jeconom.2004.02.002>  Detailed examples are given in 
 Imai and van Dyk (2005). ``MNP: R Package for Fitting the Multinomial 
 Probit Model.''  Journal of Statistical Software, Vol. 14, No. 3 (May), 
 pp. 1-32. <DOI:10.18637/jss.v014.i03>.",2017-09-27,Kosuke Imai,http://imai.princeton.edu/software/MNP.html,TRUE,https://github.com/kosukeimai/mnp,48498,5,1541388222
mockery,"
    The two main functionalities of this package are creating mock
    objects (functions) and selectively intercepting calls to a given
    function that originate in some other function. It can be used
    with any testing framework available for R. Mock objects can
    be injected with either this package's own stub() function or a
    similar with_mock() facility present in the testthat package. ",2018-08-19,Noam Finkelstein,https://github.com/n-s-f/mockery,TRUE,https://github.com/n-s-f/mockery,132986,42,1552320151
modeest,"Provides estimators of the mode of univariate
    data or univariate distributions. ",2019-03-13,Paul Poncet,https://github.com/paulponcet/modeest,TRUE,https://github.com/paulponcet/modeest,187992,5,1552510903
modeldb,Uses 'dplyr' and 'tidyeval' to fit statistical models inside the database. It currently supports KMeans and linear regression models.,2019-03-02,Edgar Ruiz,https://github.com/edgararuiz/modeldb,TRUE,https://github.com/edgararuiz/modeldb,2550,40,1551625004
modelgrid,"A minimalistic but flexible framework that facilitates the creation,
    management and training of multiple 'caret' models. A model grid consists of
    two components: (1) a set of settings that is shared by all models by 
    default, and (2) specifications that apply only to the individual models.
    When the model grid is trained, model and training specifications are first 
    consolidated from the shared and the model specific settings into complete
    'caret' model configurations. These models are then trained with the 'train' 
    function from the 'caret' package.",2018-11-04,Lars Kjeldgaard,https://github.com/smaakage85/modelgrid,TRUE,https://github.com/smaakage85/modelgrid,2650,17,1541317661
modelr,"Functions for modelling that help you seamlessly
    integrate modelling into a pipeline of data manipulation and
    visualisation.",2019-02-18,Hadley Wickham,"https://modelr.tidyverse.org, https://github.com/tidyverse/modelr",TRUE,https://github.com/tidyverse/modelr,2388627,325,1550497654
moderndive,"Datasets and wrapper functions for tidyverse-friendly introductory linear regression, used in ModernDive: An Introduction to Statistical and Data Sciences via R available at <http://moderndive.com/> and DataCamp's Modeling with Data in the Tidyverse available at <https://www.datacamp.com/courses/modeling-with-data-in-the-tidyverse>.",2018-07-06,Albert Y. Kim,https://github.com/ModernDive/moderndive_package,TRUE,https://github.com/moderndive/moderndive_package,9149,31,1552693756
modi,"Algorithms for multivariate outlier detection when missing values occur.
    Algorithms are based on Mahalanobis distance or data depth. Imputation is based
    on the multivariate normal model or uses nearest neighbour donors. The algorithms 
    take sample designs, in particular weighting, into account. The methods are 
    described in Bill and Hulliger (2016) <doi:10.17713/ajs.v45i1.86>.",2018-11-20,Martin Sterchi,https://github.com/martinSter/modi,TRUE,https://github.com/martinster/modi,905,1,1543412039
MODIS,"Download and processing functionalities for the Moderate Resolution
    Imaging Spectroradiometer (MODIS). The package provides automated access to the
    global online data archives LP DAAC (<https://lpdaac.usgs.gov/>), LAADS 
    (<https://ladsweb.modaps.eosdis.nasa.gov/>) and NSIDC (<https://nsidc.org/>) 
    as well as processing capabilities such as file conversion, mosaicking, 
    subsetting and time series filtering.",2019-03-08,Florian Detsch,https://github.com/MatMatt/MODIS,TRUE,https://github.com/matmatt/modis,17573,22,1552053038
MODISTools,"Programmatic interface to the 'MODIS Land Products Subsets'
    web services (<https://modis.ornl.gov/data/modis_webservice.html>).
    Allows for easy downloads of 'MODIS' time series directly to your R 
    workspace or your computer.",2019-03-01,Hufkens Koen  (<https://orcid.org/0000-0002-5070-8109>),https://github.com/khufkens/MODISTools,TRUE,https://github.com/khufkens/modistools,22554,7,1552587750
MODIStsp,"Allows automating the creation of time series of rasters derived
    from MODIS Satellite Land Products data. It performs several typical
    preprocessing steps such as download, mosaicking, reprojection and resize
    of data acquired on a specified time period. All processing parameters
    can be set using a user-friendly GUI. Users can select which layers of
    the original MODIS HDF files they want to process, which additional
    Quality Indicators should be extracted from aggregated MODIS Quality
    Assurance layers and, in the case of Surface Reflectance products
    , which Spectral Indexes should be computed from the original reflectance
    bands. For each output layer, outputs are saved as single-band raster
    files corresponding to each available acquisition date. Virtual files
    allowing access to the entire time series as a single file are also created.
    Command-line execution exploiting a previously saved processing options
    file is also possible, allowing to automatically update time series
    related to a MODIS product whenever a new image is available.",2019-03-08,Lorenzo Busetto  (<https://orcid.org/0000-0001-9634-6038>),https://github.com/ropensci/MODIStsp,TRUE,https://github.com/ropensci/modistsp,12440,75,1553077111
modules,"Provides modules as an organizational unit for source code. Modules
    enforce to be more rigorous when defining dependencies and have
    a local search path. They can be used as a sub unit within packages
    or in scripts.",2019-02-10,Sebastian Warnholz,http://wahani.github.io/modules,TRUE,https://github.com/wahani/modules,13851,28,1549795351
MOEADr,"Modular implementation of Multiobjective Evolutionary Algorithms 
              based on Decomposition (MOEA/D) [Zhang and Li (2007), 
              <DOI:10.1109/TEVC.2007.892759>] for quick assembling and 
              testing of new algorithmic components, as well as easy 
              replication of published MOEA/D proposals.",2017-10-24,Felipe Campelo,https://github.com/fcampelo/MOEADr,TRUE,https://github.com/fcampelo/moeadr,4401,9,1542633323
MoEClust,Clustering via parsimonious Gaussian Mixtures of Experts using the MoEClust models introduced by Murphy and Murphy (2017) <arXiv:1711.05632>. This package fits finite Gaussian mixture models with a formula interface for supplying gating and/or expert network covariates using a range of parsimonious covariance parameterisations via the EM/CEM algorithm. Visualisation of the results of such models using generalised pairs plots is also facilitated.,2018-12-11,Keefe Murphy,https://cran.r-project.org/package=MoEClust,TRUE,https://github.com/keefe-murphy/moeclust,3976,2,1550168419
Momocs,"The goal of Momocs is to provide a complete, convenient, 
       reproducible and open-source toolkit for 2D morphometrics.
       It includes most common 2D morphometrics approaches on outlines, open outlines, configurations of landmarks, traditional morphometrics, and facilities for data preparation, manipulation and visualization with a consistent grammar throughout.
       It allows reproducible, complex morphometric analyses and other morphometrics approaches should be easy to plug in, or develop from, on top of this canvas.",2018-03-22,Vincent Bonhomme,https://github.com/MomX/Momocs/,TRUE,https://github.com/momx/momocs,24764,31,1540902732
MonetDBLite,"An in-process version of 'MonetDB', a SQL database designed for analytical tasks. Similar to 'SQLite', the database runs entirely inside the 'R' shell.",2018-07-27,Hannes Mühleisen  (<https://orcid.org/0000-0001-8552-0029>),https://github.com/hannesmuehleisen/MonetDBLite-R,TRUE,https://github.com/hannesmuehleisen/monetdblite-r,25513,50,1544080458
mongolite,"High-performance MongoDB client based on 'mongo-c-driver' and 'jsonlite'.
    Includes support for aggregation, indexing, map-reduce, streaming, encryption,
    enterprise authentication, and GridFS. The online user manual provides an overview 
    of the available methods in the package: <https://jeroen.github.io/mongolite/>.",2019-03-05,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),"https://github.com/jeroen/mongolite/ (devel)
https://jeroen.github.io/mongolite/ (user manual)
http://mongoc.org/ (upstream)",TRUE,https://github.com/jeroen/mongolite,131180,205,1552052651
monkeylearn,"Allows using some services of Monkeylearn <http://monkeylearn.com/> which is
    a Machine Learning platform on the cloud for text analysis (classification and extraction).",2018-04-13,Maëlle Salmon  (<https://orcid.org/0000-0002-2815-0399>),"http://github.com/ropensci/monkeylearn,
http://ropensci.github.io/monkeylearn/",TRUE,https://github.com/ropensci/monkeylearn,8924,86,1530115672
monotonicity,"Test for monotonicity in financial variables sorted by portfolios. It is conventional practice in empirical research to form portfolios of assets ranked by a certain sort variable. A t-test is then used to consider the mean return spread between the portfolios with the highest and lowest values of the sort variable. Yet comparing only the average returns on the top and bottom portfolios does not provide a sufficient way to test for a monotonic relation between expected returns and the sort variable. This package provides nonparametric tests for the full set of monotonic patterns by Patton, A. and Timmermann, A. (2010) <doi:10.1016/j.jfineco.2010.06.006> and compares the proposed results with extant alternatives such as t-tests, Bonferroni bounds, and multivariate inequality tests through empirical applications and simulations.",2019-02-14,Siegfried Köstlmeier,https://github.com/skoestlmeier/monotonicity,TRUE,https://github.com/skoestlmeier/monotonicity,3320,0,1550748646
MonteCarlo,"Simplifies Monte Carlo simulation studies by automatically 
             setting up loops to run over parameter grids and parallelising
             the Monte Carlo repetitions. It also generates LaTeX tables.",2019-01-31,Christian Hendrik Leschinski,http://github.com/FunWithR/MonteCarlo,TRUE,https://github.com/funwithr/montecarlo,14921,17,1548927939
moonBook,"Several analysis-related functions for the book entitled ""R
    statistics and graph for medical articles"" (written in Korean), version 1,
    by Keon-Woong Moon with Korean demographic data with several plot
    functions.",2018-07-23,Keon-Woong Moon,https://github.com/cardiomoon/moonBook,TRUE,https://github.com/cardiomoon/moonbook,61389,11,1532322645
Morpho,"A toolset for Geometric Morphometrics and mesh processing. This
    includes (among other stuff) mesh deformations based on reference points,
    permutation tests, detection of outliers, processing of sliding
    semi-landmarks and semi-automated surface landmark placement.",2018-04-24,Stefan Schlager,https://github.com/zarquon42b/Morpho,TRUE,https://github.com/zarquon42b/morpho,31771,19,1550153162
MortalityGaps,"Life expectancy is highly correlated over time among countries and 
  between males and females. These associations can be used to improve forecasts. 
  Here we have implemented a method for forecasting female life expectancy based on 
  analysis of the gap between female life expectancy in a country compared with
  the record level of female life expectancy in the world. Second, to forecast 
  male life expectancy, the gap between male life expectancy and female life 
  expectancy in a country is analysed. We named this method the Double-Gap model.
  For a detailed description of the method see Pascariu et al. (2017). 
  <doi:10.1016/j.insmatheco.2017.09.011>.",2018-07-20,Marius D. Pascariu,https://github.com/mpascariu/MortalityGaps,TRUE,https://github.com/mpascariu/mortalitygaps,1689,0,1536509593
MortalityLaws,"Fit the most popular human mortality 'laws', and construct 
  full and abridge life tables given various input indices. A mortality
  law is a parametric function that describes the dying-out process of 
  individuals in a population during a significant portion of their 
  life spans. For a comprehensive review of the most important mortality 
  laws see Tabeau (2001) <doi:10.1007/0-306-47562-6_1>. 
  An elegant function for downloading data from Human Mortality 
  Database <https://www.mortality.org> is provided as well.  ",2018-11-06,Marius D. Pascariu,https://github.com/mpascariu/MortalityLaws,TRUE,https://github.com/mpascariu/mortalitylaws,8033,4,1543936183
mosaic,"Data sets and utilities from Project MOSAIC (<http://mosaic-web.org>) used
    to teach mathematics, statistics, computation and modeling.  Funded by the
    NSF, Project MOSAIC is a community of educators working to tie together
    aspects of quantitative work that students in science, technology,
    engineering and mathematics will need in their professional lives, but
    which are usually taught in isolation, if at all.",2019-01-12,Randall Pruim,"https://github.com/ProjectMOSAIC/mosaic,
https://projectmosaic.github.io/mosaic/",TRUE,https://github.com/projectmosaic/mosaic,593744,75,1553826320
mosaicCore,"Common utilities used in other MOSAIC-family packages are 
    collected here.",2018-06-24,Randall Pruim <rpruim@calvin.edu>,https://github.com/ProjectMOSAIC/mosaicCore,TRUE,https://github.com/projectmosaic/mosaiccore,215690,2,1549431694
motoRneuron,"The temporal relationship between motor neurons can offer 
    explanations for neural strategies. We combined functions to reduce neuron 
    action potential discharge data and analyze it for short-term, time-domain 
    synchronization. Even more so, motoRneuron combines most available methods 
    for the determining cross correlation histogram peaks and most available 
    indices for calculating synchronization into simple functions. See 
    Nordstrom, Fuglevand, and Enoka (1992) <doi:10.1113/jphysiol.1992.sp019244> 
    for a more thorough introduction.",2019-02-26,Andrew Tweedell,http://github.com/tweedell/motoRneuron,TRUE,https://github.com/tweedell/motorneuron,387,0,1550242864
mountainplot,"Lattice functions for drawing folded empirical cumulative
    distribution plots, or mountain plots. A mountain plot is similar
    to an empirical CDF plot, except that the curve increases from
    0 to 0.5, then decreases from 0.5 to 1 using an inverted scale at
    the right side.",2017-07-13,Kevin Wright,https://github.com/kwstat/mountainplot,TRUE,https://github.com/kwstat/mountainplot,9809,1,1527186379
mousetrap,"Mouse-tracking, the analysis of mouse movements in computerized
    experiments, is a method that is becoming increasingly popular in the
    cognitive sciences. The mousetrap package offers functions for importing,
    preprocessing, analyzing, aggregating, and visualizing mouse-tracking data.",2019-02-02,Pascal J. Kieslich  (<https://orcid.org/0000-0002-0853-9364>),https://github.com/pascalkieslich/mousetrap,TRUE,https://github.com/pascalkieslich/mousetrap,10576,13,1551951063
moveHMM,"Provides tools for animal movement modelling using hidden Markov
    models. These include processing of tracking data, fitting hidden Markov models
    to movement data, visualization of data and fitted model, decoding of the state
    process...",2018-06-07,Theo Michelot,"https://github.com/TheoMichelot/moveHMM,
https://cran.r-project.org/package=moveHMM",TRUE,https://github.com/theomichelot/movehmm,15771,10,1554306894
moveVis,Tools to visualize movement data (e.g. from GPS tracking) and temporal changes of environmental data (e.g. from remote sensing) by creating video animations.,2019-03-20,Jakob Schwalb-Willmann,http://movevis.org,TRUE,https://github.com/16eagle/movevis,8355,40,1554285593
mpcmp,"A collection of functions for estimation, testing and diagnostic checking for the mean-parametrized Conway-Maxwell Poisson (COM-Poisson) regression model of Huang (2017) <doi:10.1177/1471082X17697749>.",2019-03-04,Thomas Fung,https://github.com/thomas-fung/mpcmp,TRUE,https://github.com/thomas-fung/mpcmp,306,1,1553589159
mplot,"Model stability and variable inclusion plots [Mueller and Welsh
    (2010, <doi:10.1111/j.1751-5823.2010.00108.x>); Murray, Heritier and Mueller
    (2013, <doi:10.1002/sim.5855>)] as well as the adaptive fence [Jiang et al.
    (2008, <doi:10.1214/07-AOS517>); Jiang et al. 
    (2009, <doi:10.1016/j.spl.2008.10.014>)] for linear and generalised linear models.",2019-01-22,Garth Tarr,"http://garthtarr.github.io/mplot,
https://github.com/garthtarr/mplot",TRUE,https://github.com/garthtarr/mplot,26529,6,1548132426
MplusAutomation,"Leverages the R language to automate latent variable model estimation
	and interpretation using 'Mplus', a powerful latent variable modeling program
	developed by Muthen and Muthen (<http://www.statmodel.com>). Specifically, this package
    provides routines for creating related groups of models, running batches of
    models, and extracting and tabulating model parameters and fit statistics.",2018-11-25,Michael Hallquist,https://github.com/michaelhallquist/MplusAutomation,TRUE,https://github.com/michaelhallquist/mplusautomation,72147,27,1554385556
mpoly,Symbolic computing with multivariate polynomials in R.,2019-01-31,David Kahle,https://github.com/dkahle/mpoly,TRUE,https://github.com/dkahle/mpoly,24287,2,1553906296
mppR,"Analysis of experimental multi-parent populations to detect
             regions of the genome (called quantitative trait loci, QTLs)
             influencing phenotypic traits. The population must be composed of crosses
             between a set of at least three parents (e.g. factorial design,
             'diallel', or nested association mapping). The functions cover data
             processing, QTL detection, and results visualization. The implemented
             methodology is described by Garin, Wimmer, Mezmouk, Malosetti and
             van Eeuwijk (2017) <doi:10.1007/s00122-017-2923-3>.",2018-07-01,Vincent Garin,https://github.com/vincentgarin/mppR,TRUE,https://github.com/vincentgarin/mppr,1932,1,1530696981
MPTmultiverse,"
    Statistical or cognitive modeling usually requires a number of more or less 
    arbitrary choices creating one specific path through a 'garden of forking paths'. 
    The multiverse approach (Steegen, Tuerlinckx, Gelman, & Vanpaemel, 2016, 
    <doi:10.1177/1745691616658637>) offers a principled alternative in which results 
    for all possible combinations of reasonable modeling choices are reported. 
    MPTmultiverse performs a multiverse analysis for multinomial processing tree 
    (MPT, Riefer & Batchelder, 1988, <doi:10.1037/0033-295X.95.3.318>) models combining 
    maximum-likelihood/frequentist and Bayesian estimation approaches with 
    different levels of pooling (i.e., data aggregation). For the 
    frequentist approaches, no pooling (with and without parametric or nonparametric 
    bootstrap) and complete pooling are implemented using 
    MPTinR <https://cran.r-project.org/package=MPTinR>. 
    For the Bayesian approaches, no pooling, complete pooling, and three different 
    variants of partial pooling are implemented using 
    TreeBUGS <https://cran.r-project.org/package=TreeBUGS>. The main function is 
    fit_mpt() who performs the multiverse analysis in one call.",2019-03-11,Henrik Singmann  (<https://orcid.org/0000-0002-4842-3657>),https://github.com/mpt-network/MPTmultiverse,TRUE,https://github.com/mpt-network/mptmultiverse,1160,0,1553333530
mrds,"Animal abundance estimation via conventional, multiple covariate
    and mark-recapture distance sampling (CDS/MCDS/MRDS). Detection function
    fitting is performed via maximum likelihood. Also included are diagnostics
    and plotting for fitted detection functions. Abundance estimation is via a
    Horvitz-Thompson-like estimator.",2018-06-27,Jeff Laake <jeff.laake@noaa.gov>,NA,TRUE,https://github.com/distancedevelopment/mrds,33661,0,1554282583
mregions,"Tools to get marine regions data from
    <http://www.marineregions.org/>. Includes tools to get region metadata,
    as well as data in 'GeoJSON' format, as well as Shape files. Use cases
    include using data downstream to visualize 'geospatial' data by marine
    region, mapping variation among different regions, and more.",2017-10-17,Scott Chamberlain,https://github.com/ropenscilabs/mregions,TRUE,https://github.com/ropenscilabs/mregions,7023,13,1539710369
MRFcov,"Approximate node interaction parameters of Markov Random Fields 
    graphical networks. Models can incorporate additional covariates, allowing users to estimate
    how interactions between nodes in the graph are predicted to change across
    covariate gradients. The general methods implemented in this package are described 
    in Clark et al. (2018) <doi:10.1002/ecy.2221>.",2018-11-26,Nicholas J Clark,https://github.com/nicholasjclark/MRFcov,TRUE,https://github.com/nicholasjclark/mrfcov,1964,15,1543979877
mrfDepth,"Tools to compute depth measures and implementations of related 
             tasks such as outlier detection, data exploration and 
            classification of multivariate, regression and functional data.",2018-10-12,Jakob Raymaekers,https://github.com/PSegaert/mrfDepth,TRUE,https://github.com/psegaert/mrfdepth,9004,1,1539334547
mrgsolve,"Fast simulation from ordinary differential equation (ODE) based 
    models typically employed in quantitative pharmacology and systems biology.  ",2019-01-23,Kyle T Baron  (<https://orcid.org/0000-0001-7252-5656>),https://github.com/metrumresearchgroup/mrgsolve,TRUE,https://github.com/metrumresearchgroup/mrgsolve,11136,45,1548760897
msaenet,"Multi-step adaptive elastic-net (MSAENet) algorithm for
    feature selection in high-dimensional regressions proposed in
    Xiao and Xu (2015) <DOI:10.1080/00949655.2015.1016944>,
    with support for multi-step adaptive MCP-net (MSAMNet) and
    multi-step adaptive SCAD-net (MSASNet) methods.",2018-12-14,Nan Xiao  (<https://orcid.org/0000-0002-0250-5673>),"https://nanx.me/msaenet/, https://github.com/road2stat/msaenet",TRUE,https://github.com/road2stat/msaenet,14608,7,1552877416
MSbox,"Common mass spectrometry tools described in John Roboz (2013) <doi:10.1201/b15436>. It allows checking element
 isotopes, calculating (isotope labelled) exact monoisitopic mass, m/z values and mass accuracy, and inspecting possible contaminant mass peaks,
 examining possible adducts in electrospray ionization (ESI) and matrix-assisted laser desorption ionization (MALDI)
 ion sources. ",2019-02-24,Yonghui Dong,https://github.com/YonghuiDong/MSbox,TRUE,https://github.com/yonghuidong/msbox,4097,0,1554564217
mschart,"Create native charts for 'Microsoft PowerPoint' and 'Microsoft Word' documents. 
 These can then be edited and annotated. Functions are provided to let users create charts, modify 
 and format their content. The chart's underlying data is automatically saved within the 
 'Word' document or 'PowerPoint' presentation. It extends package 'officer' that does 
 not contain any feature for 'Microsoft' native charts production. ",2018-04-19,David Gohel,https://ardata-fr.github.io/mschart/,TRUE,https://github.com/ardata-fr/mschart,6716,59,1538474102
mscstts,"R Client for the Microsoft Cognitive Services 
  'Text-to-Speech' REST API, including voice synthesis. A valid account 
  must be registered at the Microsoft Cognitive Services website 
  <https://www.microsoft.com/cognitive-services/> in order to 
  obtain a (free) API key. Without an API key, this package will not 
  work properly.",2018-11-19,John Muschelli  (<https://orcid.org/0000-0001-6469-1750>),https://github.com/muschellij2/mscstts,TRUE,https://github.com/muschellij2/mscstts,2073,4,1545850723
MSEtool,"Simulation tools for management strategy evaluation are provided for the 'DLMtool' operating model to inform data-rich fisheries. 
  'MSEtool' provides complementary assessment models of varying complexity with standardized reporting, diagnostic tools for evaluating 
  assessment models within closed-loop simulation, and helper functions for building more complex operating models and management procedures.",2018-10-17,Tom Carruthers,http://www.datalimitedtoolkit.org,TRUE,https://github.com/tcarruth/msetool,2627,0,1553738550
MSGARCH,"Fit (by Maximum Likelihood or MCMC/Bayesian), simulate, and forecast various Markov-Switching GARCH models as described in Ardia et al. (2017) <https://ssrn.com/abstract=2845809>.",2018-05-16,Keven Bluteau,https://github.com/keblu/MSGARCH,TRUE,https://github.com/keblu/msgarch,14144,28,1542689568
msgl,"Multinomial logistic regression with sparse group lasso
        penalty. Simultaneous feature selection and parameter
        estimation for classification. Suitable for high dimensional
        multiclass classification with many classes. The algorithm
        computes the sparse group lasso penalized maximum likelihood
        estimate. Use of parallel computing for cross validation and
        subsampling is supported through the 'foreach' and 'doParallel'
        packages. Development version is on GitHub, please report
        package issues on GitHub.",2019-01-04,Martin Vincent,"http://www.sciencedirect.com/science/article/pii/S0167947313002168,
https://github.com/nielsrhansen/msgl",TRUE,https://github.com/nielsrhansen/msgl,22179,1,1546466493
msigdbr,"Provides the 'Molecular Signatures Database' (MSigDB) gene sets
    typically used with the 'Gene Set Enrichment Analysis' (GSEA) software
    (Subramanian et al. 2005 <doi:10.1073/pnas.0506580102>, Liberzon et al. 2015
    <doi:10.1016/j.cels.2015.12.004>) in a standard R data frame with key-value
    pairs. Included are the original human gene symbols and Entrez IDs as well
    as the equivalents for various frequently studied model organisms such as
    mouse, rat, pig, fly, and yeast.",2018-10-09,Igor Dolgalev,https://github.com/igordot/msigdbr,TRUE,https://github.com/igordot/msigdbr,3698,11,1539193033
msm,"Functions for fitting continuous-time Markov and hidden
    Markov multi-state models to longitudinal data.  Designed for
    processes observed at arbitrary times in continuous time (panel data)
    but some other observation schemes are supported. Both Markov
    transition rates and the hidden Markov output process can be modelled
    in terms of covariates, which may be constant or piecewise-constant
    in time.",2019-03-18,Christopher Jackson <chris.jackson@mrc-bsu.cam.ac.uk>,https://github.com/chjackson/msm,TRUE,https://github.com/chjackson/msm,448756,10,1552915896
MTA,Build multiscalar territorial analysis based on various contexts.,2018-05-14,Timothée Giraud,https://github.com/riatelab/MTA/,TRUE,https://github.com/riatelab/mta,4626,2,1526300292
MTLR,"An implementation of Multi-Task Logistic Regression (MTLR) for R. 
  This package is based on the method proposed by Yu et al. (2011) which utilized MTLR for generating individual survival curves
  by learning feature weights which vary across time. This model was further extended to account for left and interval censored data.",2019-03-09,Humza Haider,https://github.com/haiderstats/MTLR,TRUE,https://github.com/haiderstats/mtlr,1262,5,1552153530
MTSYS,"Mahalanobis-Taguchi (MT) system is a collection of multivariate
    analysis methods developed for the field of quality engineering. MT system
    consists of two families depending on their purpose. One is a family of
    Mahalanobis-Taguchi (MT) methods (in the broad sense) for diagnosis (see
    Woodall, W. H., Koudelik, R., Tsui, K. L., Kim, S. B., Stoumbos, Z. G., and
    Carvounis, C. P. (2003) <doi:10.1198/004017002188618626>) and the other is a
    family of Taguchi (T) methods for forecasting (see Kawada, H., and Nagata, Y.
    (2015) <doi:10.17929/tqs.1.12>). The MT package contains three basic methods
    for the family of MT methods and one basic method for the family of T
    methods. The MT method (in the narrow sense), the Mahalanobis-Taguchi
    Adjoint (MTA) methods, and the Recognition-Taguchi (RT) method are for the
    MT method and the two-sided Taguchi (T1) method is for the family of T
    methods. In addition, the Ta and Tb methods, which are the improved versions
    of the T1 method, are included.",2017-09-10,Akifumi Okayama,https://github.com/okayaa/MTSYS,TRUE,https://github.com/okayaa/mtsys,3698,0,1524111685
mudata2,"Formatting and structuring multi-parameter spatiotemporal data
  is often a time-consuming task. This package offers functions and data structures 
  designed to easily organize and visualize these data for applications in geology, 
  paleolimnology, dendrochronology, and paleoclimate. See Dunnington and Spooner (2018)
  <doi:10.1139/facets-2017-0026>.",2019-03-16,Dewey Dunnington  (<https://orcid.org/0000-0002-9415-4582>),https://github.com/paleolimbot/mudata,TRUE,https://github.com/paleolimbot/mudata,6914,15,1552750068
mudfold,"Nonparametric unfolding item response theory (IRT) model for dichotomous data (see W.H. Van Schuur (1984). Structure in Political Beliefs: A New Model for Stochastic Unfolding with Application to European Party Activists, and W.J.Post (1992). Nonparametric Unfolding Models: A Latent Structure Approach). The package implements MUDFOLD (Multiple UniDimensional unFOLDing), an iterative item selection algorithm that constructs unfolding scales from dichotomous preferential-choice data without explicitly assuming a parametric form of the item response functions. Scale diagnostics from Post(1992) and estimates for the person locations proposed by Johnson(2006) and Van Schuur(1984) are also available. This model can be seen as the unfolding variant of Mokken(1971) scaling method.",2018-12-10,Spyros Balafas,https://github.com/cran/mudfold,TRUE,https://github.com/cran/mudfold,4785,1,1544428203
mulset,"Computes efficient data distributions from highly inconsistent datasets with many missing values using multi-set intersections. Based upon hash functions, 'mulset' can quickly identify intersections from very large matrices of input vectors across columns and rows and thus provides scalable solution for dealing with missing values. Tomic et al. (2019) <doi:10.1101/545186>.",2019-03-08,Ivan Tomic,https://github.com/LogIN-/mulset,TRUE,https://github.com/login-/mulset,232,0,1551990281
multicmp,"A toolkit containing statistical analysis models motivated by multivariate forms of the Conway-Maxwell-Poisson (COM-Poisson) distribution for flexible modeling of multivariate count data, especially in the presence of data dispersion. Currently the package only supports bivariate data, via the bivariate COM-Poisson distribution described in Sellers et al. (2016) <doi:10.1016/j.jmva.2016.04.007>. Future development will extend the package to higher-dimensional data.",2018-06-29,Diag Davenport,http://dx.doi.org/10.1016/j.jmva.2016.04.007,TRUE,https://github.com/diagdavenport/multicmp,5057,0,1530272515
multicolor,Add multiple colors to text that is printed to the console.,2019-03-18,Amanda Dobbyn,http://github.com/aedobbyn/multicolor/,TRUE,https://github.com/aedobbyn/multicolor,2644,35,1554390184
multifwf,"Read a table of fixed width formatted data of different types into
    a data.frame for each type.",2015-12-24,Panos Rontogiannis,https://github.com/prontog/multifwf,TRUE,https://github.com/prontog/multifwf,5869,0,1549960368
multigraph,"Functions to plot and manipulate multigraphs, signed and weighted multigraphs, bipartite graphs, and Cayley graphs with different layout options (devel version).",2018-09-25,Antonio Rivero Ostoic,http://github.com/mplex/multigraph/,TRUE,https://github.com/mplex/multigraph,9201,12,1542049994
multinets,"Analyze multilevel networks as described in Lazega et al (2008)
    <doi:10.1016/j.socnet.2008.02.001> and in Lazega and Snijders 
    (2016, ISBN:978-3-319-24520-1). The package was developed essentially as an 
    extension to 'igraph'.",2018-07-07,Neylson Crepalde,https://github.com/neylsoncrepalde/multinets,TRUE,https://github.com/neylsoncrepalde/multinets,2690,8,1547033745
multiplex,"Algebraic procedures for the analysis of multiple social networks are delivered with 
	    this package. Among other things, it makes possible to create and manipulate multivariate 
	    network data with different formats, and there are effective ways available to treat multiple 
	    networks with routines that combine algebraic systems like the partially ordered semigroup or 
	    the semiring structure together with the relational bundles occurring in different types of 
	    multivariate network data sets. It also provides an algebraic approach for two-mode networks 
	    through Galois derivations between families of the pairs of subsets in the two domains.",2018-09-21,Antonio Rivero Ostoic,http://github.com/mplex/multiplex/,TRUE,https://github.com/mplex/multiplex,28418,7,1537556893
multistateutils,"Provides functions for working with multi-state modelling, 
    such as efficient simulation routines for estimating transition probabilities and length of stay.
    It is designed as an extension to multi-state modelling capabilities provided with the 'flexsurv' 
    package (see Jackson (2016) <doi:10.18637/jss.v070.i08>).",2019-02-04,Stuart Lacy,https://github.com/stulacy/multistateutils,TRUE,https://github.com/stulacy/multistateutils,2727,1,1549289821
mumm,"Fit multiplicative mixed models using maximum likelihood estimation via the Template
  Model Builder (TMB), Kristensen K, Nielsen A, Berg CW, Skaug H, Bell BM (2016) <doi:10.18637/jss.v070.i05>.
  One version of the multiplicative mixed model is applied in Piepho (1999) <doi:10.1111/j.0006-341X.1999.01120.x>.
  The package provides functions for calculating confidence intervals for the model parameters
  and for performing likelihood ratio tests.",2018-08-15,Sofie Poedenphant,http://github.com/sofpj/mumm,TRUE,https://github.com/sofpj/mumm,2305,6,1549793930
munsell,"Provides easy access to, and manipulation of, the Munsell 
    colours. Provides a mapping between Munsell's 
    original notation (e.g. ""5R 5/10"") and hexadecimal strings suitable 
    for use directly in R graphics. Also provides utilities 
    to explore slices through the Munsell colour tree, to transform 
    Munsell colours and display colour palettes.",2018-06-12,Charlotte Wickham <cwickham@gmail.com>,"https://cran.r-project.org/package=munsell,
https://github.com/cwickham/munsell/",TRUE,https://github.com/cwickham/munsell,11355921,43,1533152035
muRty,Calculates k-best solutions and costs for an assignment problem following the method outlined in Murty (1968) <doi:10.1287/opre.16.3.682>.,2019-04-04,Aljaz Jelenko <aljaz.jelenko@amis.net>,https://github.com/arg0naut91/muRty,TRUE,https://github.com/arg0naut91/murty,12,0,1554448830
MUS,Sampling and evaluation methods to apply Monetary Unit Sampling (or in older literature Dollar Unit Sampling) during an audit of financial statements.,2019-03-20,Henning Prömpers,NA,TRUE,https://github.com/alsguimaraes/mus,3693,1,1554490924
music,"An aid for learning and using music theory. You can build chords, scales, and chord progressions using 12-note equal temperament tuning (12-ET) or user-defined tuning. Includes functions to visualize notes on a piano using ASCII plots in the console and to plot waveforms using base graphics. It allows simple playback of notes and chords using the 'audio' package.",2019-02-20,Efstathios D. Gennatas,https://github.com/egenn/music,TRUE,https://github.com/egenn/music,586,5,1554499345
mvinfluence,"Computes regression deletion diagnostics for multivariate linear models and provides some associated
	diagnostic plots.  The diagnostic measures include hat-values (leverages), generalized Cook's distance, and
	generalized squared 'studentized' residuals.  Several types of plots to detect influential observations are
	provided.",2018-05-17,Michael Friendly,https://github.com/friendly/mvinfluence,TRUE,https://github.com/friendly/mvinfluence,59275,0,1526559937
mvMISE,"Offers a general framework of multivariate mixed-effects
        models for the joint analysis of multiple correlated outcomes with clustered 
        data structures and potential missingness proposed by Wang et al. (2018) <doi:10.1093/biostatistics/kxy022>. The missingness of outcome values may 
        depend on the values themselves (missing not at random and non-ignorable), 
        or may depend on only the covariates (missing at random and ignorable), or both.
        This package provides functions for two models: 1) mvMISE_b() 
        allows correlated outcome-specific random intercepts with a factor-analytic 
        structure, and 2) mvMISE_e() allows the correlated outcome-specific 
        error terms with a graphical lasso penalty on the error precision matrix. Both functions 
        are motivated by the multivariate data analysis on data with clustered structures 
        from labelling-based quantitative proteomic studies. These models and functions 
        can also be applied to univariate and multivariate analyses of clustered data 
        with balanced or unbalanced design and no missingness.",2018-06-10,Jiebiao Wang and Lin S. Chen,https://github.com/randel/mvMISE,TRUE,https://github.com/randel/mvmise,1747,0,1530927105
mvMORPH,"Fits multivariate (Brownian Motion, Early Burst, ACDC, Ornstein-Uhlenbeck and Shifts) models of continuous traits evolution on trees and time series. 'mvMORPH' also proposes high-dimensional multivariate comparative tools (linear models using Generalized Least Squares) based on penalized likelihood.  See
    Clavel et al. (2015) <DOI:10.1111/2041-210X.12420> and Clavel et al. (2018) <DOI:10.1093/sysbio/syy045>.",2018-08-04,Julien Clavel,https://github.com/JClavel/mvMORPH,TRUE,https://github.com/jclavel/mvmorph,28306,9,1549986900
MVNBayesian,"Tools of Bayesian analysis framework using the method
  suggested by Berger (1985) <doi:10.1007/978-1-4757-4286-2> for
  multivariate normal (MVN) distribution and multivariate normal
  mixture (MixMVN) distribution:
  a) calculating Bayesian posteriori of (Mix)MVN distribution;
  b) generating random vectors of (Mix)MVN distribution;
  c) Markov chain Monte Carlo (MCMC) for (Mix)MVN distribution.",2018-08-16,ZHANG Chen,https://github.com/CubicZebra/MVNBayesian,TRUE,https://github.com/cubiczebra/mvnbayesian,1699,0,1537776125
mvnfast,"Provides computationally efficient tools related to
    the multivariate normal and Student's t distributions. The main functionalities are:
    simulating multivariate random vectors, evaluating multivariate
    normal or Student's t densities and Mahalanobis distances. These tools are very efficient
    thanks to the use of C++ code and of the OpenMP API.",2018-01-31,Matteo Fasiolo,"https://github.com/mfasiolo/mvnfast, www.sitmo.com",TRUE,https://github.com/mfasiolo/mvnfast,45279,16,1529515856
mvp,"Fast manipulation of symbolic multivariate polynomials
  using the 'Map' class of the Standard Template Library.  The package
  uses print and coercion methods from the 'mpoly' package (Kahle 2013,
  ""Multivariate polynomials in R"".  The R Journal, 5(1):162), but offers
  speed improvements.  It is comparable in speed to the 'spray' package
  for sparse arrays, but retains the symbolic benefits of 'mpoly'.",2019-02-04,Robin K. S. Hankin  (<https://orcid.org/0000-0001-5982-0415>),https://github.com/RobinHankin/mvp.git,TRUE,https://github.com/robinhankin/mvp,1843,0,1554517565
mvPot,"Tools for high-dimensional peaks-over-threshold inference and simulation
  of spatial extremal processes.",2018-04-09,Raphael de Fondeville,http://github.com/r-fndv/mvPot,TRUE,https://github.com/r-fndv/mvpot,6137,0,1542361435
MVR,"This is a non-parametric method for joint adaptive mean-variance regularization and variance stabilization of high-dimensional data. It is suited for handling difficult problems posed by high-dimensional multivariate datasets (p >> n paradigm). Among those are that the variance is often a function of the mean, variable-specific estimators of variances are not reliable, and tests statistics have low powers due to a lack of degrees of freedom. Key features include:
            (i) Normalization and/or variance stabilization of the data,
            (ii) Computation of mean-variance-regularized t-statistics (F-statistics to follow),
            (iii) Generation of diverse diagnostic plots,
            (iv) Computationally efficient implementation using C/C++ interfacing and an option for parallel computing to enjoy a faster and easier experience in the R environment.",2018-09-10,Jean-Eudes Dazard,https://github.com/jedazard/MVR,TRUE,https://github.com/jedazard/mvr,17966,0,1551991036
mvtboost,"Fits a multivariate model of decision trees for multiple, continuous outcome variables. A model for each outcome variable is fit separately, selecting predictors that explain covariance in the outcomes.  Built on top of 'gbm', which fits an ensemble of decision trees to univariate outcomes.",2016-12-05,Patrick Miller,https://github.com/patr1ckm/mvtboost,TRUE,https://github.com/patr1ckm/mvtboost,8735,16,1526335464
mwaved,"Computes the Wavelet deconvolution estimate of a common signal
    present in multiple channels that have possible different levels of blur
    and long memory additive error.",2019-03-22,Justin Rory Wishart,https://github.com/jrwishart/mwaved,TRUE,https://github.com/jrwishart/mwaved,11716,0,1553471549
mycor,"Perform correlation and linear regression test
    among the numeric fields in a data.frame automatically
    and make plots using pairs or lattice::parallelplot.",2018-04-10,Keon-Woong Moon,https://github.com/cardiomoon/mycor,TRUE,https://github.com/cardiomoon/mycor,30070,0,1523364356
myTAI,Investigate the evolution of biological processes by capturing evolutionary signatures in transcriptomes (Drost et al. (2017) <doi:10.1093/bioinformatics/btx835>). The aim of this tool is to provide a transcriptome analysis environment for answering questions regarding the evolution of biological processes (Drost et al. (2016) <doi:10.1101/051565>).,2019-03-10,Hajk-Georg Drost  (<https://orcid.org/0000-0002-1567-306X>>>),https://github.com/HajkD/myTAI,TRUE,https://github.com/hajkd/mytai,14367,12,1553951986
n1qn1,"Provides 'Scilab' 'n1qn1', or Quasi-Newton BFGS
      ""qn"" without constraints and 'qnbd' or Quasi-Newton BFGS with constraints.
       This takes more memory than traditional L-BFGS.  The n1qn1 routine is useful since it allows prespecification of a Hessian.
       If the Hessian is near enough the truth in optimization it can speed up the optimization problem. Both algorithms are described in the
       'Scilab' optimization documentation located at 
       <http://www.scilab.org/content/download/250/1714/file/optimization_in_scilab.pdf>.",2018-09-17,Matthew Fidler,https://github.com/nlmixrdevelopment/n1qn1,TRUE,https://github.com/nlmixrdevelopment/n1qn1,6074,0,1537151599
na.tools,"
    This comprehensive toolkit provide a consistent and 
    extensible framework for working with missing values in vectors. The 
    companion package 'tidyimpute' provides similar functionality for list-like 
    and table-like structures).
    Functions exist for detection, removal, replacement, imputation, 
    recollection, etc. of 'NAs'.",2018-06-25,Christopher Brown,https://github.com/decisionpatterns/na.tools,TRUE,https://github.com/decisionpatterns/na.tools,4510,2,1544139344
nadiv,"Constructs (non)additive genetic relationship matrices, and their
    inverses, from a pedigree to be used in linear mixed effect models (A.K.A.
    the 'animal model'). Also includes other functions to facilitate the use of
    animal models. Some functions have been created to be used in conjunction
    with the R package 'asreml' for the 'ASReml' software, which can be
    obtained upon purchase from 'VSN' international 
    (<http://www.vsni.co.uk/software/asreml>).",2018-05-10,Matthew Wolak,http://github.com/matthewwolak/nadiv,TRUE,https://github.com/matthewwolak/nadiv,25148,5,1544460407
naivebayes,High performance implementation of the Naive Bayes algorithm.,2019-03-17,Michal Majka,http://github.com/majkamichal/naivebayes,TRUE,https://github.com/majkamichal/naivebayes,49864,8,1554045053
namer,It names the 'R Markdown' chunks of files based on the filename.,2019-03-26,Steph Locke,https://github.com/lockedata/namer,TRUE,https://github.com/lockedata/namer,1373,50,1554383248
nandb,"Calculation of molecular number and brightness from 
    fluorescence microscopy image series. The software was published in a 2016
    paper <doi:10.1093/bioinformatics/btx434>. The seminal paper for the 
    technique is Digman et al. 2008 <doi:10.1529/biophysj.107.114645>. A review
    of the technique was published in 2017 <doi:10.1016/j.ymeth.2017.12.001>.",2018-11-11,Rory Nolan,https://github.com/rorynolan/nandb,TRUE,https://github.com/rorynolan/nandb,4043,2,1541964219
naniar,"Missing values are ubiquitous in data and need to be explored and
    handled in the initial stages of analysis. 'naniar' provides data structures 
    and functions that facilitate the plotting of missing values and examination 
    of imputations. This allows missing data dependencies to be explored with 
    minimal deviation from the common work patterns of 'ggplot2' and tidy data. ",2019-02-15,Nicholas Tierney  (<https://orcid.org/0000-0003-1460-8722>),https://github.com/njtierney/naniar,TRUE,https://github.com/njtierney/naniar,47200,362,1553741453
nanostringr,"Provides quality control (QC), normalization, and
    batch effect correction operations for 'NanoString nCounter' data,
    Talhouk et al. (2016) <doi:10.1371/journal.pone.0153844>.  Various
    metrics are used to determine which samples passed or failed QC.  Gene
    expression should first be normalized to housekeeping genes, before a
    reference-based approach is used to adjust for batch effects.  Raw
    NanoString data can be imported in the form of Reporter Code Count
    (RCC) files.",2019-04-03,Derek Chiu,"https://github.com/OVCARE/nanostringr,
https://ovcare.github.io/nanostringr",TRUE,https://github.com/ovcare/nanostringr,189,1,1554397325
naptime,"Provides a near drop-in replacement for base::Sys.sleep() that allows more types of input
    to produce delays in the execution of code and can silence/prevent typical sources of error.",2017-02-23,Russell S. Pierce,URL: https://github.com/drknexus/naptime,TRUE,https://github.com/drknexus/naptime,6109,6,1542895890
nardl,"Computes the nonlinear cointegrating autoregressive distributed lag model with p lags of the dependent variables and q lags of independent variables proposed by (Shin, Yu & Greenwood-Nimmo, 2014 <doi:10.1007/978-1-4899-8008-3_9>).",2018-05-07,Taha Zaghdoudi,https://github.com/zedtaha/nardl,TRUE,https://github.com/zedtaha/nardl,5917,1,1525711417
narray,"Stacking arrays according to dimension names, subset-aware
    splitting and mapping of functions, intersecting along arbitrary
    dimensions, converting to and from data.frames, and many other helper
    functions.",2018-08-18,Michael Schubert <mschu.dev@gmail.com>,https://github.com/mschubert/narray,TRUE,https://github.com/mschubert/narray,9926,18,1534621745
nasapower,"Client for 'NASA' 'POWER' global meteorology, surface solar
    energy and climatology data 'API'.  'POWER' (Prediction Of Worldwide Energy
    Resource) data are freely available global meteorology and surface solar
    energy climatology data for download with a resolution of 1/2 by 1/2 arc
    degree longitude and latitude and are funded through the 'NASA' Earth
    Science Directorate Applied Science Program.  For more on the data
    themselves, a web-based data viewer and web access, please see
    <https://power.larc.nasa.gov/>.",2019-02-17,Adam H. Sparks  (<https://orcid.org/0000-0002-0061-8359>),"https://github.com/ropensci/nasapower,
https://ropensci.github.io/nasapower/",TRUE,https://github.com/ropensci/nasapower,2940,28,1550394462
nat,"NeuroAnatomy Toolbox (nat) enables analysis and visualisation of 3D
    biological image data, especially traced neurons. Reads and writes 3D images
    in NRRD and 'Amira' AmiraMesh formats and reads surfaces in 'Amira' hxsurf
    format. Traced neurons can be imported from and written to SWC and 'Amira'
    LineSet and SkeletonGraph formats. These data can then be visualised in 3D
    via 'rgl', manipulated including applying calculated registrations, e.g.
    using the 'CMTK' registration suite, and analysed. There is also a simple
    representation for neurons that have been subjected to 3D skeletonisation
    but not formally traced; this allows morphological comparison between
    neurons including searches and clustering (via the 'nat.nblast' extension
    package).",2017-11-12,Gregory Jefferis,"https://github.com/jefferis/nat, http://jefferislab.org",TRUE,https://github.com/jefferis/nat,18180,25,1549476946
nat.templatebrains,"Extends package 'nat' (NeuroAnatomy Toolbox) by providing objects
    and functions for handling template brains.",2018-06-24,Gregory Jefferis  (<https://orcid.org/0000-0002-0587-9355>),https://github.com/jefferislab/nat.templatebrains,TRUE,https://github.com/jefferislab/nat.templatebrains,11510,2,1544641690
natserv,"Interface to 'NatureServe' (<http://www.natureserve.org>).
    Includes methods to get data, image metadata, search taxonomic names,
    and make maps.",2019-01-23,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/natserv,TRUE,https://github.com/ropensci/natserv,55598,8,1548213090
NatureSounds,Collection of example animal sounds for bioacoustic analysis.,2019-01-07,Marcelo Araya-Salas,https://github.com/maRce10/NatureSounds,TRUE,https://github.com/marce10/naturesounds,5580,0,1546881773
ncf,"R functions for analyzing spatial (cross-)covariance: the
        nonparametric (cross-)covariance function, the spline correlogram, the
        nonparametric phase coherence function, local indicators of spatial 
        association (LISA), (Mantel) correlogram, (Partial) Mantel test.",2019-03-22,Ottar N. Bjornstad,http://ento.psu.edu/directory/onb1,TRUE,https://github.com/objornstad/ncf,47038,2,1553287907
ncmeta,"Extract metadata from 'NetCDF' data sources, these can be files, file handles or
 servers. This package leverages and extends the lower level functions of the 'RNetCDF' package 
 providing a consistent set of functions that all return data frames. We introduce named concepts 
 of 'grid', 'axis' and 'source' which are all meaningful entities without formal definition in the 
 'NetCDF' library <https://www.unidata.ucar.edu/software/netcdf/>. 'RNetCDF' matches the library 
 itself with only the named concepts of 'variables', 'dimensions' and 'attributes'. 'ncmeta'
 provides a required framework for the in-development 'tidync' project <https://github.com/hypertidy/tidync>.",2018-10-26,Michael Sumner,https://github.com/hypertidy/ncmeta,TRUE,https://github.com/hypertidy/ncmeta,31599,4,1553054210
ncpen,"An efficient unified nonconvex penalized estimation algorithm for
    Gaussian (linear), binomial Logit (logistic), Poisson, multinomial Logit,
    and Cox proportional hazard regression models.
    The unified algorithm is implemented based on the convex concave procedure and
    the algorithm can be applied to most of the existing nonconvex penalties.
    The algorithm also supports convex penalty:
    least absolute shrinkage and selection operator (LASSO).
    Supported nonconvex penalties include
    smoothly clipped absolute deviation (SCAD),
    minimax concave penalty (MCP), truncated LASSO penalty (TLP),
    clipped LASSO (CLASSO), sparse ridge (SRIDGE),
    modified bridge (MBRIDGE) and modified log (MLOG).
    For high-dimensional data (data set with many variables),
    the algorithm selects relevant variables producing a parsimonious regression model.
    Kim, D., Lee, S. and Kwon, S. (2018) <arXiv:1811.05061>,
    Lee, S., Kwon, S. and Kim, Y. (2016) <doi:10.1016/j.csda.2015.08.019>,
    Kwon, S., Lee, S. and Kim, Y. (2015) <doi:10.1016/j.csda.2015.07.001>.
    (This research is funded by Julian Virtue Professorship from Center for Applied Research at Pepperdine
    Graziadio Business School and the National Research Foundation of Korea.)",2018-11-17,Dongshin Kim,https://github.com/zeemkr/ncpen,TRUE,https://github.com/zeemkr/ncpen,3057,0,1542586849
ncvreg,"Fits regularization paths for linear regression, GLM, and Cox
  regression models using lasso or nonconvex penalties, in particular the
  minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD)
  penalty, with options for additional L2 penalties (the ""elastic net"" idea).
  Utilities for carrying out cross-validation as well as post-fitting
  visualization, summarization, inference, and prediction are also provided.",2019-02-26,Patrick Breheny  (<https://orcid.org/000-0002-0650-1119>),"http://pbreheny.github.io/ncvreg,
https://github.com/pbreheny/ncvreg",TRUE,https://github.com/pbreheny/ncvreg,66752,20,1552687272
ndtv,"Renders dynamic network data from 'networkDynamic' objects as movies, interactive animations, or other representations of changing relational structures and attributes.",2018-10-08,Skye Bender-deMoll,https://github.com/statnet/ndtv,TRUE,https://github.com/statnet/ndtv,88216,23,1538972983
neatmaps,"Simplify the exploratory data analysis process for multiple network
             data sets with the help of hierarchical clustering, consensus 
             clustering and heatmaps. Multiple network data consists of multiple
             disjoint networks that have common variables (e.g. ego networks). 
             This package contains the necessary tools for exploring such data,
             from the data pre-processing stage to the creation of dynamic
             visualizations.",2019-03-15,Philippe Boileau,https://github.com/PhilBoileau/neatmaps,TRUE,https://github.com/philboileau/neatmaps,3783,3,1552667316
negenes,"Estimating the number of essential genes in a genome on the basis of data from a random transposon mutagenesis experiment, through the use of a Gibbs sampler.",2018-04-02,Karl W Broman <kbroman@biostat.wisc.edu>,https://github.com/kbroman/negenes,TRUE,https://github.com/kbroman/negenes,15150,1,1552340196
neo4r,"A Modern and Flexible 'Neo4J' Driver, allowing you to query 
    data on a 'Neo4J' server and handle the results in R. It's modern in 
    the sense it provides a driver 
    that can be easily integrated in a data analysis workflow, especially by 
    providing an API working smoothly with other data analysis and graph 
    packages. It's flexible in the  way it returns the results, by 
    trying to stay as close as 
    possible to the way 'Neo4J' returns data. That way, you have the control 
    over the way you will compute the results. At the same time, the result 
    is not too complex, so that the ""heavy lifting"" of data wrangling is not 
    left to the user. ",2019-02-15,Colin Fay  (<https://orcid.org/0000-0001-7343-1846>),https://github.com/neo4j-rstats/neo4r,TRUE,https://github.com/neo4j-rstats/neo4r,963,37,1551622045
neonUtilities,"NEON data packages can be accessed through the NEON Data Portal <http://data.neonscience.org>
    or through the NEON Data API (see <http://data.neonscience.org/data-api> for documentation). Data delivered from
    the Data Portal are provided as monthly zip files packaged within a parent zip file, while individual files
    can be accessed from the API. This package provides tools that aid in discovering, downloading, and reformatting 
    data prior to use in analyses. This includes downloading data via the API, merging data tables by type, and 
    converting formats. For more information, see the readme file at <https://github.com/NEONScience/NEON-utilities>.",2019-03-06,Christine Laney <claney@battelleecology.org>,https://github.com/NEONScience/NEON-utilities,TRUE,https://github.com/neonscience/neon-utilities,2284,17,1553028905
neotoma,"Access paleoecological datasets from the Neotoma Paleoecological
    Database using the published API (<http://api.neotomadb.org/>).  The functions
    in this package access various pre-built API functions and attempt to return
    the results from Neotoma in a usable format for researchers and the public.",2019-01-05,Simon J. Goring,https://github.com/ropensci/neotoma,TRUE,https://github.com/ropensci/neotoma,18815,20,1549654185
nesRdata,Serves data from the United States Environmental Protection Agency (USEPA) National Eutrophication Survey <https://www.epa.gov/national-aquatic-resource-surveys>.,2018-09-10,Joseph Stachelek  (<https://orcid.org/0000-0002-5924-2464>),https://github.com/jsta/nesRdata,TRUE,https://github.com/jsta/nesrdata,2880,2,1545919222
nestfs,"Implementation of forward selection based on cross-validated
             linear and logistic regression.",2018-12-16,Marco Colombo  (<https://orcid.org/0000-0001-6672-0623>),https://github.com/mcol/nestfs,TRUE,https://github.com/mcol/nestfs,2969,0,1544986016
netdiffuseR,"Empirical statistical analysis, visualization and simulation of
    diffusion and contagion processes on networks. The package implements algorithms
    for calculating network diffusion statistics such as transmission rate, hazard
    rates, exposure models, network threshold levels, infectiousness (contagion),
    and susceptibility. The package is inspired by work published in Valente,
    et al., (2015) <DOI:10.1016/j.socscimed.2015.10.001>; Valente (1995) <ISBN:
    9781881303213>, Myers (2000) <DOI:10.1086/303110>, Iyengar and others (2011)
    <DOI:10.1287/mksc.1100.0566>, Burt (1987) <DOI:10.1086/228667>; among others.",2019-03-26,George Vega Yon  (<https://orcid.org/0000-0002-3171-0844>,"https://github.com/USCCANA/netdiffuseR,
https://USCCANA.github.io/netdiffuseR",TRUE,https://github.com/usccana/netdiffuser,10140,39,1553581305
netgsa,"Carry out Network-based Gene Set Analysis by incorporating external information about interactions among genes, as well as novel interactions learned from data.",2019-03-27,Jing Ma,https://github.com/drjingma/netgsa,TRUE,https://github.com/drjingma/netgsa,10212,0,1553045389
NetLogoR,"Build and run spatially explicit
    agent-based models using only the R platform. 'NetLogoR' follows the same
    framework as the 'NetLogo' software
    (Wilensky, 1999 <http://ccl.northwestern.edu/netlogo/>) and is a translation
    in R of the structure and functions of 'NetLogo'.
    'NetLogoR' provides new R classes to define model agents and functions to
    implement spatially explicit agent-based models in the R environment.
    This package allows benefiting of the fast and easy coding phase from the
    highly developed 'NetLogo' framework, coupled with the versatility, power
    and massive resources of the R software.
    Examples of three models (Ants <http://ccl.northwestern.edu/netlogo/models/Ants>,
    Butterfly (Railsback and Grimm, 2012) and Wolf-Sheep-Predation
    <http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation>) written using
    'NetLogoR' are available. The 'NetLogo' code of the original version of these
    models is provided alongside.
    A programming guide inspired from the 'NetLogo' Programming Guide
    (<https://ccl.northwestern.edu/netlogo/docs/programming.html>) and a dictionary
    of 'NetLogo' primitives (<https://ccl.northwestern.edu/netlogo/docs/dictionary.html>)
    equivalences are also available.
    NOTE: To increment 'time', these functions can use a for loop or can be
    integrated with a discrete event simulator, such as 'SpaDES'
    (<https://cran.r-project.org/package=SpaDES>).
    The suggested package 'fastshp' can be installed with
    'install.packages(""fastshp"", repos = ""https://rforge.net"", type = ""source"")'.",2019-01-25,Sarah Bauduin  (<https://orcid.org/0000-0002-3252-5894>),"http://netlogor.predictiveecology.org,
https://github.com/PredictiveEcology/NetLogoR/",TRUE,https://github.com/predictiveecology/netlogor,4052,18,1548433372
netmeta,"A comprehensive set of functions providing frequentist methods for network meta-analysis and supporting Schwarzer et al. (2015) <DOI:10.1007/978-3-319-21416-0>, Chapter 8 ""Network Meta-Analysis"":
 - frequentist network meta-analysis following Rücker (2012) <DOI:10.1002/jrsm.1058>;
 - net heat plot and design-based decomposition of Cochran's Q according to Krahn et al. (2013) <DOI:10.1186/1471-2288-13-35>;
 - measures characterizing the flow of evidence between two treatments by König et al. (2013) <DOI:10.1002/sim.6001>;
 - ranking of treatments (frequentist analogue of SUCRA) according to Rücker & Schwarzer (2015) <DOI:10.1186/s12874-015-0060-8>;
 - partial order of treatment rankings ('poset') and Hasse diagram for 'poset' (Carlsen & Bruggemann, 2014) <DOI:10.1002/cem.2569>; (Rücker & Schwarzer, 2017) <DOI:10.1002/jrsm.1270>;
 - split direct and indirect evidence to check consistency (Dias et al., 2010) <DOI:10.1002/sim.3767>;
 - league table with network meta-analysis results;
 - additive network meta-analysis for combinations of treatments;
 - network meta-analysis of binary data using the Mantel-Haenszel or non-central hypergeometric distribution method;
 - 'comparison-adjusted' funnel plot (Chaimani & Salanti, 2012) <DOI:10.1002/jrsm.57>;
 - automated drawing of network graphs described in Rücker & Schwarzer (2016) <DOI:10.1002/jrsm.1143>.",2019-01-02,Guido Schwarzer,https://github.com/guido-s/netmeta http://meta-analysis-with-r.org,TRUE,https://github.com/guido-s/netmeta,35233,0,1554462081
netrankr,"Implements methods for centrality related analyses of networks. 
    While the package includes the possibility to build more than 20 indices, 
    its main focus lies on index-free assessment of centrality via partial 
    rankings obtained by neighborhood-inclusion or positional dominance. These 
    partial rankings can be analyzed with different methods, including 
    probabilistic methods like computing expected node ranks and relative 
    rank probabilities (how likely is it that a node is more central than another?).
    The methodology is described in depth in the vignettes and in
    Schoch (2018) <doi:10.1016/j.socnet.2017.12.003>.",2018-09-18,David Schoch,https://schochastics.github.io/netrankr,TRUE,https://github.com/schochastics/netrankr,3984,23,1537201395
NetRep,"Functions for assessing the replication/preservation of a network 
  module's topology across datasets through permutation testing.",2018-06-12,Scott Ritchie,NA,TRUE,https://github.com/inouyelab/netrep,5593,8,1528800995
NetWeaver,Implements various simple function utilities and flexible pipelines to generate circular images for visualizing complex genomic and network data analysis features.,2019-02-26,Minghui Wang,https://github.com/mw201608/NetWeaver/,TRUE,https://github.com/mw201608/netweaver,4977,1,1553806545
networkABC,"We developed an inference tool based on approximate Bayesian computation to decipher network data and assess the strength of the inferred links between network's actors. It is a new multi-level approximate Bayesian computation (ABC) approach. At the first level, the method captures the global properties of the network, such as scale-freeness and clustering coefficients, whereas the second level is targeted to capture local properties, including the probability of each couple of genes being linked. Up to now, Approximate Bayesian Computation (ABC) algorithms have been scarcely used in that setting and, due to the computational overhead, their application was limited to a small number of genes. On the contrary, our algorithm was made to cope with that issue and has low computational cost. It can be used, for instance, for elucidating gene regulatory network, which is an important step towards understanding the normal cell physiology and complex pathological phenotype. Reverse-engineering consists in using gene expressions over time or over different experimental conditions to discover the structure of the gene network in a targeted cellular process. The fact that gene expression data are usually noisy, highly correlated, and have high dimensionality explains the need for specific statistical methods to reverse engineer the underlying network. ",2019-03-06,Frederic Bertrand  (<https://orcid.org/0000-0002-0837-8281>),"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/networkABC",TRUE,https://github.com/fbertran/networkabc,255,1,1551436048
NetworkDistance,"Network is a prevalent form of data structure in many fields. As an object of analysis, many distance or metric measures have been proposed to define the concept of similarity between two networks. We provide a number of distance measures for networks. See Jurman et al (2011) <doi:10.3233/978-1-60750-692-8-227> for an overview on spectral class of inter-graph distance measures.",2018-12-12,Kisung You  (<https://orcid.org/0000-0002-8584-459X>),http://github.com/kisungyou/NetworkDistance,TRUE,https://github.com/kisungyou/networkdistance,4250,1,1547928753
NetworkInference,"This is an R implementation of the netinf algorithm (Gomez Rodriguez, Leskovec, and Krause, 2010)<doi:10.1145/1835804.1835933>. Given a set of events that spread between a set of nodes the algorithm infers the most likely stable diffusion network that is underlying the diffusion process.",2019-02-28,Fridolin Linder,NA,TRUE,https://github.com/desmarais-lab/networkinference,6844,14,1551377283
networktools,"Includes assorted tools for network analysis. Bridge centrality, impact, & goldbricker.",2018-06-05,Payton Jones,https://CRAN.R-project.org/package=networktools,TRUE,https://github.com/paytonjjones/networktools,7658,3,1550685307
networktree,Methods to create tree models with correlation-based network models (multivariate normal distributions). ,2019-03-09,Payton Jones  (<https://orcid.org/0000-0001-6513-8498>),NA,TRUE,https://github.com/paytonjjones/networktree,1678,0,1554206404
neuralnet,"Training of neural networks using backpropagation,
    resilient backpropagation with (Riedmiller, 1994) or without
    weight backtracking (Riedmiller and Braun, 1993) or the
    modified globally convergent version by Anastasiadis et al.
    (2005). The package allows flexible settings through
    custom-choice of error and activation function. Furthermore,
    the calculation of generalized weights (Intrator O & Intrator
    N, 1993) is implemented.",2019-02-07,Marvin N. Wright,https://github.com/bips-hb/neuralnet,TRUE,https://github.com/bips-hb/neuralnet,500322,4,1552299929
NeuralNetTools,"Visualization and analysis tools to aid in the interpretation of
    neural network models.  Functions are available for plotting,
    quantifying variable importance, conducting a sensitivity analysis, and
    obtaining a simple list of model weights.",2018-07-26,Marcus W. Beck,NA,TRUE,https://github.com/fawda123/neuralnettools,81180,49,1539277302
neurobase,"Base package for 'Neuroconductor', which includes many helper 
    functions that interact with objects of class 'nifti', implemented by
    package 'oro.nifti', for reading/writing and also other manipulation 
    functions.",2018-11-20,John Muschelli,NA,TRUE,https://github.com/muschellij2/neurobase,14525,4,1553628374
neurohcp,"Downloads and reads data from Human 'Connectome' Project 
    <https://db.humanconnectome.org> using Amazon Web Services ('AWS') 
    'S3' buckets.",2018-05-24,John Muschelli,https://db.humanconnectome.org,TRUE,https://github.com/muschellij2/neurohcp,4168,3,1527184649
neutralitytestr,Package takes frequencies of mutations as reported by high throughput sequencing data from cancer and fits a theoretical neutral model of tumour evolution. Package outputs summary statistics and contains code for plotting the data and model fits. See Williams et al 2016 <doi:10.1038/ng.3489> and Williams et al 2017 <doi:10.1101/096305> for further details of the method.,2018-05-21,Marc Williams,https://github.com/marcjwilliams1/neutralitytestr,TRUE,https://github.com/marcjwilliams1/neutralitytestr,2160,2,1531301158
neverhpfilter,"In the working paper titled ""Why You Should Never Use the Hodrick-Prescott 
   Filter"", James D. Hamilton proposes an interesting new alternative to economic 
   time series filtering. The neverhpfilter package provides functions for implementing 
   his solution. Hamilton (2017) <doi:10.3386/w23429>.",2018-01-24,Justin M. Shea,https://justinmshea.github.io/neverhpfilter/,TRUE,https://github.com/justinmshea/neverhpfilter,2552,6,1529610722
newsanchor,"Interface to gather news from the 'News API', based on a multilevel query <https://newsapi.org/>. A personal API key is required. ",2019-03-05,Buhl Yannik,NA,TRUE,https://github.com/correlaid/newsanchor,285,18,1551729864
newsmap,"Semi-supervised model for geographical document classification (Watanabe 2018) <doi:10.1080/21670811.2017.1293487>. 
    This package currently contains seed dictionaries in English, German, French, Spanish, Japanese, Russian and Chinese (Simplified and Traditional).",2019-02-24,Kohei Watanabe,https://github.com/koheiw/newsmap,TRUE,https://github.com/koheiw/newsmap,3535,16,1552300774
NFP,"An implementation of the network fingerprint framework that introduced 
  in paper ""Network fingerprint: a knowledge-based characterization of biomedical 
  networks"" (Cui, 2015) <doi:10.1038/srep13286>. This method worked by making 
  systematic comparisons to a set of well-studied ""basic networks"", measuring 
  both the functional and topological similarity.  A biological could be
  characterized as a spectrum-like vector consisting of similarities to basic 
  networks. It shows great potential in biological network study.",2016-11-21,Yang Cao,https://github.com/yiluheihei/NFP,TRUE,https://github.com/yiluheihei/nfp,5226,2,1551352962
ngram,"An n-gram is a sequence of n ""words"" taken, in order, from a
    body of text.  This is a collection of utilities for creating,
    displaying, summarizing, and ""babbling"" n-grams.  The
    'tokenization' and ""babbling"" are handled by very efficient C
    code, which can even be built as its own standalone library.
    The babbler is a simple Markov chain.  The package also offers
    a vignette with complete example 'workflows' and information about
    the utilities offered in the package.",2017-11-21,Drew Schmidt,https://github.com/wrathematics/ngram,TRUE,https://github.com/wrathematics/ngram,44810,48,1548624013
ngstk,"
    Can be used to facilitate the analysis of NGS data, such as visualization, conversion of data format for WEB service input and other purpose.",2018-11-22,Jianfeng Li  (<https://orcid.org/0000-0003-2349-208X>),https://github.com/JhuangLab/ngstk,TRUE,https://github.com/jhuanglab/ngstk,5056,11,1542724851
nhanesA,"Utility to retrieve data from the National Health and Nutrition 
	Examination Survey (NHANES) website <https://www.cdc.gov/nchs/nhanes/index.htm>.",2018-10-17,Christopher J. Endres,https://cran.r-project.org/package=nhanesA,TRUE,https://github.com/cjendres1/nhanes,14667,7,1539741644
nhdR,"Tools for working with the National Hydrography Dataset, with 
    functions for querying, downloading, and networking both the NHD 
    <https://www.usgs.gov/core-science-systems/ngp/national-hydrography> 
    and NHDPlus <http://www.horizon-systems.com/nhdplus> datasets. ",2019-02-19,Joseph Stachelek  (<https://orcid.org/0000-0002-5924-2464>),https://github.com/jsta/nhdR,TRUE,https://github.com/jsta/nhdr,634,14,1553875119
nhds,"The National Hospital Discharge Survey (2010)
    summarizes the state of patients at the end of their hospital
    admissions. The US CDC publishes the data in the public domain, and
    describes it as follows: The National Hospital Discharge Survey (NHDS)
    is a continuing nationwide sample survey of short-stay hospitals in
    the United States. The scope of NHDS encompasses patients discharged
    from noninstitutional hospitals, exclusive of military and Department
    of Veterans Affairs hospitals, located in the 50 States and the
    District of Columbia. Only hospitals having six or more beds for
    in-patient use are included in the survey. See
    <https://www.cdc.gov/nchs/nhds> for more information.",2019-03-31,Jack Wasey,https://github.com/jackwasey/nhds,TRUE,https://github.com/jackwasey/nhds,135,1,1554383047
nima,"Miscellaneous R functions developed over the course of statistical
    research and scientific computing. These include, for example, utilities
    that supplement existing idiosyncrasies of the R language, extend existing
    plotting functionality and aesthetics, provide alternative presentations of
    matrix decompositions, and extend access to command line tools and
    systems-level information.",2018-05-21,Nima Hejazi,https://github.com/nhejazi/nima,TRUE,https://github.com/nhejazi/nima,6139,1,1548623319
nipals,Principal Components Analysis of a matrix using Non-linear Iterative Partial Least Squares with Gram-Schmidt orthogonalization of the scores and loadings. Optimized for speed. See Andrecut (2009) <doi:10.1089/cmb.2008.0221>.,2018-10-24,Kevin Wright  (<https://orcid.org/0000-0002-0617-8673>),https://github.com/kwstat/nipals,TRUE,https://github.com/kwstat/nipals,6219,5,1551625963
nitrcbot,Parses and downloads images from various 'NeuroImaging Tools and Resources Collaboratory' <https://www.nitrc.org> sets.,2018-06-01,Adi Gherman,https://www.nitrc.org,TRUE,https://github.com/adigherman/nitrcbot,2185,0,1540322317
NitrogenUptake2016,"Contains data, code, and figures from Hill et al. 2018a (Journal of Experimental Marine Biology and Ecology; <DOI: 10.1016/j.jembe.2018.07.006>) and Hill et al. 2018b (Data In Brief <DOI: 10.1016/j.dib.2018.09.133>). Datasets document plant allometry, stem heights, nutrient and stable isotope content, and sediment denitrification enzyme assays. The data and analysis offer an examination of nitrogen uptake and allocation in two salt marsh plant species.",2018-10-28,Troy D. Hill,https://github.com/troyhill/NitrogenUptake2016,TRUE,https://github.com/troyhill/nitrogenuptake2016,2545,0,1540747234
nlaR,"Client for programmatic access to the 2007 and 2012 National 
  Lakes Assessment database <https://www.epa.gov/national-aquatic-resource-surveys/nla> 
  containing data for hundreds of lakes in the lower 48 states of the contiguous US.",2019-01-22,Joseph Stachelek,https://github.com/jsta/nlaR,TRUE,https://github.com/jsta/nlar,1799,2,1548900782
nlgeocoder,"R interface to the open location server API of 'Publieke Diensten Op de Kaart' (<http://www.pdok.nl>). It offers geocoding, address suggestions and lookup of geographical objects. Included is an utility function for displaying leaflet tiles restricted to the Netherlands.",2018-10-08,Edwin de Jonge,https://github.com/uRos2018/nlgeocoder,TRUE,https://github.com/uros2018/nlgeocoder,1313,2,1549037189
nlmixr,"Fit and compare nonlinear mixed-effects models in differential
    equations with flexible dosing information commonly seen in pharmacokinetics
    and pharmacodynamics (Almquist, Leander, and Jirstrand 2015 
    <doi:10.1007/s10928-015-9409-1>). Differential equation solving is 
    by compiled C code provided in the 'RxODE' package
    (Wang, Hallow, and James 2015 <doi:10.1002/psp4.12052>).",2018-09-23,Wenping Wang,https://github.com/nlmixrdevelopment/nlmixr,TRUE,https://github.com/nlmixrdevelopment/nlmixr,6243,34,1554521819
NLMR,"Provides neutral landscape models (<doi:10.1007/BF02275262>,
    <http://sci-hub.tw/10.1007/bf02275262>).  
    Neutral landscape models range from ""hard"" 
    neutral models (completely random distributed), to ""soft"" neutral models 
    (definable spatial characteristics) and generate landscape patterns that are 
    independent of ecological processes.
    Thus, these patterns can be used as null models in landscape ecology. 'nlmr' 
    combines a large number of algorithms from other published software for 
    simulating neutral landscapes. The simulation results are obtained in a
    geospatial data format (raster* objects from the 'raster' package) and can,
    therefore, be used in any sort of raster data operation that is performed 
    with standard observation data.                                                                                                  ",2019-02-27,Marco Sciaini  (<https://orcid.org/0000-0002-3042-5435>),https://ropensci.github.io/NLMR/,TRUE,https://github.com/ropensci/nlmr,7252,43,1551922516
nlrx,"The purpose of this package is to provide tools to setup, run and analyze 'NetLogo' (<https://ccl.northwestern.edu/netlogo/>) model simulations in 'R'.
    'nlrx' experiments use a similar structure as 'NetLogos' Behavior Space experiments. 
    However, 'nlrx' offers more flexibility and additional tools for running and analyzing complex simulation designs and sensitivity analyses.
    The user defines all information that is needed in an intuitive framework, using class objects.
    Experiments are submitted from 'R' to 'NetLogo' via 'XML' files that are dynamically written, based on specifications defined by the user.
    By nesting model calls in future environments, large simulation design with many runs can be executed in parallel.
    This also enables simulating 'NetLogo' experiments on remote HPC machines.
    In order to use this package, 'Java' and 'NetLogo' (>= 5.3.1) need to be available on the executing system.",2019-03-28,Jan Salecker  (<https://orcid.org/0000-0002-9000-4229>),https://github.com/nldoc/nlrx/,TRUE,https://github.com/nldoc/nlrx,315,22,1553776496
nlstimedist,"Fit biologically meaningful distribution functions to
  time-sequence data (phenology), estimate parameters to draw the cumulative
  distribution function and probability density function and calculate standard
  statistical moments and percentiles.",2018-10-28,Nathan Eastwood,https://github.com/nathaneastwood/nlstimedist,TRUE,https://github.com/nathaneastwood/nlstimedist,5322,0,1540656799
NlsyLinks,"Utilities and kinship information for behavior genetics and
    developmental research using the National Longitudinal Survey of Youth
    (NLSY; <http://www.bls.gov/nls/>).",2016-04-19,Will Beasley,"http://liveoak.github.io/NlsyLinks,
https://github.com/LiveOak/NlsyLinks,
https://r-forge.r-project.org/projects/nlsylinks",TRUE,https://github.com/liveoak/nlsylinks,14102,1,1552624883
nLTT,"Provides functions to calculate the normalised Lineage-Through-
    Time (nLTT) statistic, given two phylogenetic trees. The nLTT statistic measures
    the difference between two Lineage-Through-Time curves, where each curve is
    normalised both in time and in number of lineages.",2018-04-18,Thijs Janzen,https://github.com/richelbilderbeek/nLTT,TRUE,https://github.com/richelbilderbeek/nltt,14233,3,1536578243
nmaINLA,Performs network meta-analysis using integrated nested Laplace approximations ('INLA'). Includes methods to assess the heterogeneity and inconsistency in the network. Contains more than ten different network meta-analysis data. 'INLA' package can be obtained from <http://www.r-inla.org>. We recommend the testing version.,2018-07-23,Burak Kuersad Guenhan,http://github.com/gunhanb/nmaINLA,TRUE,https://github.com/gunhanb/nmainla,3929,2,1532356253
NMAoutlier,"A set of functions providing the forward search algorithm for detecting outlying studies (i.e., studies with extreme findings) in network meta-analysis:
               - provides the length of the initial subset for forward search algorithm;
               - iterations of forward search algorithm;
               - basic set of studies in each step of forward search algorithm;
               - summary estimates and their confidence intervals in each step of forward search algorithm;
               - outlying case diagnostics measures; 
               - ranking measures;
               - heterogeneity and inconsistency measures;
               - forward plot for summary estimates and their confidence intervals;
               - forward plots for monitored measures: outlying case diagnostics measures, ranking measures, heterogeneity, and inconsistency measures.",2019-02-01,Maria Petropoulou  (<https://orcid.org/0000-0002-7147-3644>),https://github.com/petropouloumaria/NMAoutlier,TRUE,https://github.com/petropouloumaria/nmaoutlier,507,1,1551188200
nmfem,"Provides a version of the Expectation-Maximization algorithm for
    mix-models, reducing the numbers of parameters to estimate using
    Non-negative Matrix Factorization methods.
    For more explanations, see pre-print of Carel and Alquier (2017) <arXiv:1709.03346>.",2019-04-02,Lena Carel,https://github.com/LenaCarel/nmfem,TRUE,https://github.com/lenacarel/nmfem,3333,0,1554127350
Nmisc,"Contains functions useful for debugging, set operations on vectors,
    and 'UTC' date and time functionality. It adds a few vector manipulation 
    verbs to 'purrr' and 'dplyr' packages. It can also generate an R file to 
    install and update packages to simplify deployment into production. The 
    functions were developed at the data science firm 'Numeract LLC' and are 
    used in several packages and projects.",2018-11-07,Mike Badescu,https://github.com/numeract/Nmisc,TRUE,https://github.com/numeract/nmisc,2473,0,1541598534
nmixgof,"Provides residuals and overdispersion metrics to assess the fit of N-mixture models obtained using the package 'unmarked'. 
    Details on the methods are given in Knape et al. (2017) <doi:10.1101/194340>.",2018-07-05,Jonas Knape  (<https://orcid.org/0000-0002-8012-5131>),https://github.com/jknape/nmixgof,TRUE,https://github.com/jknape/nmixgof,1662,0,1531229704
nmslibR,"A Non-Metric Space Library ('NMSLIB' <https://github.com/searchivarius/nmslib>) wrapper, which according to the authors ""is an efficient cross-platform similarity search library and a toolkit for evaluation of similarity search methods. The goal of the 'NMSLIB' <https://github.com/searchivarius/nmslib> Library is to create an effective and comprehensive toolkit for searching in generic non-metric spaces. Being comprehensive is important, because no single method is likely to be sufficient in all cases. Also note that exact solutions are hardly efficient in high dimensions and/or non-metric spaces. Hence, the main focus is on approximate methods"". The wrapper also includes Approximate Kernel k-Nearest-Neighbor functions based on the 'NMSLIB' <https://github.com/searchivarius/nmslib> 'Python' Library.",2018-07-21,Lampros Mouselimis,https://github.com/mlampros/nmslibR,TRUE,https://github.com/mlampros/nmslibr,3950,7,1551867555
nnfor,"Automatic time series modelling with neural networks. 
    Allows fully automatic, semi-manual or fully manual specification of networks. For details of the
	specification methodology see: (i) Crone and Kourentzes (2010) <doi:10.1016/j.neucom.2010.01.017>;
	and (ii) Kourentzes et al. (2014) <doi:10.1016/j.eswa.2013.12.011>.",2019-01-16,Nikolaos Kourentzes,http://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/,TRUE,https://github.com/trnnick/nnfor,11044,16,1547717169
nngeo,"K-nearest neighbor search for projected and non-projected 'sf' spatial layers. Nearest neighbor search uses (1) C implementation of the Vincenty Formula for lon-lat point layers, (2) function nn2() from package 'RANN' for projected point layers, or (3) function st_distance() from package 'sf' for line or polygon layers.",2019-03-12,Michael Dorman,BugReports: https://github.com/michaeldorman/nngeo/,TRUE,https://github.com/michaeldorman/nngeo,6301,25,1549105336
nnTensor,"Some functions for performing non-negative matrix factorization, non-negative CANDECOMP/PARAFAC (CP) decomposition, non-negative Tucker decomposition, and generating toy model data. See Andrzej Cichock et al (2009) <doi:10.1002/9780470747278> and the reference section of GitHub README.md <https://github.com/rikenbit/nnTensor>, for details of the methods.",2018-09-16,Koki Tsuyuzaki,https://github.com/rikenbit/nnTensor,TRUE,https://github.com/rikenbit/nntensor,2229,1,1536970570
nodbi,"Simplified document database manipulation and analysis,
    including support for many 'NoSQL' databases, including document 
    databases ('Elasticsearch', 'CouchDB', 'MongoDB'), 
    'key-value' databases ('Redis'), and other 'NoSQL' types ('etcd').",2018-08-01,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/nodbi,TRUE,https://github.com/ropensci/nodbi,1665,44,1533148516
nodiv,"An implementation of the nodiv algorithm, see Borregaard, M.K., Rahbek, C., Fjeldsaa, J., Parra, J.L., Whittaker, R.J. & Graham, C.H. 2014. Node-based analysis of species distributions. Methods in Ecology and Evolution 5(11): 1225-1235. <DOI:10.1111/2041-210X.12283>. Package for phylogenetic analysis of species distributions. The main function goes through each node in the phylogeny, compares the distributions of the two descendant nodes, and compares the result to a null model. This highlights nodes where major distributional divergence have occurred. The distributional divergence for these nodes is mapped using the SOS statistic.",2018-11-07,Michael Krabbe Borregaard,https://github.com/mkborregaard/nodiv,TRUE,https://github.com/mkborregaard/nodiv,14881,2,1541447693
nofrills,"Provides a compact variation of the usual syntax of function
  declaration, in order to support tidyverse-style quasiquotation of a
  function's arguments and body.",2018-01-21,Eugene Ha,https://github.com/egnha/nofrills,TRUE,https://github.com/egnha/nofrills,4878,35,1535537623
nomisr,"Access UK official statistics from the 'Nomis' database. 
    'Nomis' includes data from the Census, the Labour Force Survey, DWP benefit 
    statistics and other economic and demographic data from the Office for 
    National Statistics, based around statistical geographies. See 
    <https://www.nomisweb.co.uk/api/v01/help> for full API documentation.",2019-01-09,Evan Odell  (<https://orcid.org/0000-0003-1845-808X>),"https://github.com/ropensci/nomisr,
https://docs.evanodell.com/nomisr",TRUE,https://github.com/ropensci/nomisr,3571,19,1547044804
nonet,"It provides ensemble capabilities to supervised and unsupervised learning models predictions without using training labels. It decides the relative weights of the different models predictions by using best models predictions as response variable and rest of the mo. User can decide the best model, therefore, It provides freedom to user to ensemble models based on their design solutions.",2019-01-15,Aviral Vijay,https://open.gslab.com/nonet/,TRUE,https://github.com/gslabdev/nonet,1161,1,1546514762
nonlinearICP,"Performs 'nonlinear Invariant Causal Prediction' to estimate the 
    causal parents of a given target variable from data collected in
    different experimental or environmental conditions, extending
    'Invariant Causal Prediction' from Peters, Buehlmann and Meinshausen (2016), 
    <arXiv:1501.01332>, to nonlinear settings. For more details, see C. Heinze-Deml, 
    J. Peters and N. Meinshausen: 'Invariant Causal Prediction for Nonlinear Models', 
    <arXiv:1706.08576>.",2017-07-31,Christina Heinze-Deml <heinzedeml@stat.math.ethz.ch>,https://github.com/christinaheinze/nonlinearICP-and-CondIndTests,TRUE,https://github.com/christinaheinze/nonlinearicp-and-condindtests,3432,5,1525356604
nonlinearTseries,"Functions for nonlinear time series analysis. This package permits
    the computation of the  most-used nonlinear statistics/algorithms
    including generalized correlation dimension, information dimension,
    largest Lyapunov exponent, sample entropy and Recurrence
    Quantification Analysis (RQA), among others. Basic routines
    for surrogate data testing are also included. Part of this work
    was based on the  book ""Nonlinear time series analysis"" by
    Holger Kantz and Thomas Schreiber (ISBN: 9780521529020).",2019-02-21,Constantino A. Garcia,https://github.com/constantino-garcia/nonlinearTseries,TRUE,https://github.com/constantino-garcia/nonlineartseries,36945,7,1550651791
normalr,"The robustness of many of the statistical techniques, such as factor analysis, applied in 
          the social sciences rests upon the assumption of item-level normality. However, when dealing 
          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)
          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for 
          large datasets of continuous variables, its application in current software programs is cumbersome
          with analysts having to take several steps to normalise each variable. We present an R package 
          'normalr' that enables researchers to make convenient optimal transformations of multiple variables
          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their 
          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, 
          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their 
          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, 
          kurtosis, and other inferential assessments of normality.",2018-03-30,Kevin Chang,https://github.com/kcha193/normalr,TRUE,https://github.com/kcha193/normalr,6524,2,1533510538
nos,"Calculate NOS (node overlap and segregation) and
    the associated metrics described in Strona and Veech (2015)
    <DOI:10.1111/2041-210X.12395> and Strona et al. (2017, In Press).
    The functions provided in the package enable assessment of
    structural patterns ranging from complete node segregation to perfect
    nestedness in a variety of network types. In addition, they provide a
    measure of network modularity.  ",2017-09-11,Thomas J. Matthews and Giovanni Strona,https://github.com/txm676/nos,TRUE,https://github.com/txm676/nos,3361,0,1553779684
noteMD,"When building a 'shiny' app to generate reports (pdf or 'word'), we can insert a comment box in front-end side for user to write down them notes and use this package to document those notes in reports.",2019-03-06,Jiena McLellan,https://github.com/jienagu/noteMD,TRUE,https://github.com/jienagu/notemd,253,54,1553214342
nowcasting,"It contains the tools to implement dynamic factor models to forecast economic variables. The user will be able to construct pseudo real time vintages, use information criteria for determining the number of factors and shocks, estimate the model, and visualize results among other things.",2018-11-27,Daiane Marcolino de Mattos,https://github.com/nmecsys/nowcasting,TRUE,https://github.com/nmecsys/nowcasting,4966,9,1554495871
np,"Nonparametric (and semiparametric) kernel methods that seamlessly handle a mix of continuous, unordered, and ordered factor data types. We would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC, <http://www.nserc-crsng.gc.ca>), the Social Sciences and Humanities Research Council of Canada (SSHRC, <http://www.sshrc-crsh.gc.ca>), and the Shared Hierarchical Academic Research Computing Network (SHARCNET, <http://www.sharcnet.ca>).",2018-10-25,Jeffrey S. Racine,https://github.com/JeffreyRacine/R-Package-np,TRUE,https://github.com/jeffreyracine/r-package-np,246253,24,1540402733
npExact,"Provides several novel exact hypothesis tests with minimal assumptions on the errors. The tests are exact, meaning that their p-values are correct for the given sample sizes (the p-values are not derived from asymptotic analysis). The test for stochastic inequality is for ordinal comparisons based on two independent samples and requires no assumptions on the errors. The other tests include tests for the mean and variance of a single sample and comparing means in independent samples. All these tests only require that the data has known bounds (such as percentages that lie in [0,100]. These bounds are part of the input.",2018-12-03,Oliver Reiter  (<https://orcid.org/0000-0001-6338-5428>),https://github.com/zauster/npExact,TRUE,https://github.com/zauster/npexact,904,0,1545245379
NPflow,"Dirichlet process mixture of multivariate normal, skew normal or skew t-distributions
             modeling oriented towards flow-cytometry data preprocessing applications.",2017-08-02,Boris P. Hejblum,NA,TRUE,https://github.com/borishejblum/npflow,6651,0,1523913500
npmlda,"Support the book: Wu CO and Tian X (2018). Nonparametric Models for Longitudinal Data. 
             Chapman & Hall/CRC (to appear); and provide fit for using global and local smoothing methods
             for the conditional-mean and conditional-distribution based models with longitudinal Data.",2018-02-12,Xin Tian,https://github.com/npmldabook/npmlda/,TRUE,https://github.com/npmldabook/npmlda,2280,0,1552938940
npregfast,"A method for obtaining nonparametric estimates of regression models
    with or without factor-by-curve interactions using local polynomial kernel
    smoothers or splines. Additionally, a parametric model (allometric model) can be
    estimated.",2017-11-30,Marta Sestelo  (0000-0003-4284-6509),NA,TRUE,https://github.com/sestelo/npregfast,8777,0,1527505928
nsapi,"Access the NS api and download current departure times, 
    disruptions and engineering work, the station list, and
    travel recommendations from station to station. All results will be 
    returned as a 'data.frame'. 
    NS (Nederlandse Spoorwegen; Dutch Railways) is the largest train travel
    provider in the Netherlands. for more information about the API itself
    see <https://www.ns.nl/en/travel-information/ns-api>.
    To use the API, and this package, you will need to obtain a username
    and password. More information about authentication and the use of the functions
    are described in the vignette. ",2018-08-11,Roel M. Hogervorst  (<https://orcid.org/0000-0001-7509-0328>),"https://github.com/RMHogervorst/nsapi ,
https://rmhogervorst.nl/nsapi/",TRUE,https://github.com/rmhogervorst/nsapi,2184,1,1535194103
nse,Collection of functions designed to calculate numerical standard error (NSE) of univariate time series as described in Ardia et al. (2018) <doi:10.2139/ssrn.2741587> and Ardia and Bluteau (2017) <doi:10.21105/joss.00172>.,2018-09-13,Keven Bluteau,https://github.com/keblu/nse,TRUE,https://github.com/keblu/nse,5909,0,1539901444
NSO1212,National Statistical Office of Mongolia (NSO) is the national statistical service and an organization of Mongolian government. NSO provides open access and official data via its web site <http://www.1212.mn/> and API <http://opendata.1212.mn/en/doc>. The package NSO1212 has functions for accessing the API service. The functions are compatible with the API v2.0 and get data sets and its detailed informations from the API.,2019-02-05,Makhgal Ganbold,https://github.com/galaamn/NSO1212,TRUE,https://github.com/galaamn/nso1212,397,1,1549678337
nsprcomp,"Two methods for performing a constrained principal
        component analysis (PCA), where non-negativity and/or sparsity
        constraints are enforced on the principal axes (PAs). The
        function 'nsprcomp' computes one principal component (PC) after
        the other. Each PA is optimized such that the corresponding PC
        has maximum additional variance not explained by the previous
        components. In contrast, the function 'nscumcomp' jointly
        computes all PCs such that the cumulative variance is maximal.
        Both functions have the same interface as the 'prcomp' function
        from the 'stats' package (plus some extra parameters), and both
        return the result of the analysis as an object of class
        'nsprcomp', which inherits from 'prcomp'. See
        <https://sigg-iten.ch/learningbits/2013/05/27/nsprcomp-is-on-cran/>
        and Sigg et al. (2008) <doi:10.1145/1390156.1390277> for more
        details.",2018-06-05,Christian Sigg  (<https://orcid.org/0000-0003-1067-9224>),https://sigg-iten.ch/research/,TRUE,https://github.com/chrsigg/nsprcomp,18239,6,1528181042
nsrr,"Allows users to access data from the National Sleep
    Research Resource ('NSRR') <https://sleepdata.org/>.",2019-02-22,John Muschelli  (<https://orcid.org/0000-0001-6469-1750>),https://github.com/muschellij2/nsrr,TRUE,https://github.com/muschellij2/nsrr,355,0,1551398275
nucim,Tools for 4D nucleome imaging. Quantitative analysis of the 3D nuclear landscape recorded with super-resolved fluorescence microscopy.,2018-10-09,Volker Schmid,https://github.com/bioimaginggroup/nucim,TRUE,https://github.com/bioimaginggroup/nucim,5393,2,1547583991
NUCOMBog,"Modelling the vegetation, carbon, nitrogen and water dynamics of undisturbed open bog ecosystems in a temperate to sub-boreal climate. The executable of the model can downloaded from <https://github.com/jeroenpullens/NUCOMBog>.",2018-05-20,J.W.M. Pullens,https://github.com/jeroenpullens/NUCOMBog/,TRUE,https://github.com/jeroenpullens/nucombog,7516,0,1526829328
nullabor,"Tools for visual inference. Generate null data sets
    and null plots using permutation and simulation. Calculate distance metrics
    for a lineup, and examine the distributions of metrics.",2018-09-23,Di Cook,http://github.com/dicook/nullabor,TRUE,https://github.com/dicook/nullabor,16766,33,1552458609
nvctr,"The n-vector framework uses the normal vector to the Earth ellipsoid
  (called n-vector) as a non-singular position representation that turns out to
  be very convenient for practical position calculations.
  The n-vector is simple to use and gives exact answers for all global positions,
  and all distances, for both ellipsoidal and spherical Earth models.
  This package is a translation of the 'Matlab' library from FFI,
  the Norwegian Defence Research Establishment, as described in Gade (2010)
  <doi:10.1017/S0373463309990415>.",2019-03-07,Enrico Spinielli  (<https://orcid.org/0000-0001-8584-9131>),https://github.com/euctrl-pru/nvctr,TRUE,https://github.com/euctrl-pru/nvctr,264,2,1553612859
nycflights13,"Airline on-time data for all flights departing NYC in 2013.
    Also includes useful 'metadata' on airlines, airports, weather, and planes.",2018-06-26,Hadley Wickham,http://github.com/hadley/nycflights13,TRUE,https://github.com/hadley/nycflights13,745027,66,1530044236
nzilbb.labbcat,"'LaBB-CAT' is a web-based language corpus management
 system developed by the New Zealand Institute of Language, Brain
 and Behaviour (NZILBB) - see <https://labbcat.canterbury.ac.nz>.
 This package defines functions for accessing corpus data in a 'LaBB-CAT'
 instance.
 For more information about 'LaBB-CAT', see
 Robert Fromont and Jennifer Hay (2008) <doi:10.3366/E1749503208000142>
 or 
 Robert Fromont (2017) <doi:10.1016/j.csl.2017.01.004>.",2019-03-21,Robert Fromont,"https://github.com/nzilbb/labbcat-R,
https://labbcat.canterbury.ac.nz",TRUE,https://github.com/nzilbb/labbcat-r,202,0,1553179930
nzpullover,"Datasets of driving offences and fines in New Zealand between 2009 and 2017.
    Originally published by the New Zealand Police at
    <http://www.police.govt.nz/about-us/publication/road-policing-driver-offence-data-january-2009-december-2017>.",2018-02-25,Duncan Garmonsway,https://github.com/nacnudus/nzpullover,TRUE,https://github.com/nacnudus/nzpullover,4500,1,1538989631
oai,"A general purpose client to work with any 'OAI-PMH'
    (Open Archives Initiative Protocol for 'Metadata' Harvesting) service.
    The 'OAI-PMH' protocol is described at
    <http://www.openarchives.org/OAI/openarchivesprotocol.html>.
    Functions are provided to work with the 'OAI-PMH' verbs: 'GetRecord',
    'Identify', 'ListIdentifiers', 'ListMetadataFormats', 'ListRecords', and
    'ListSets'.",2016-11-24,Scott Chamberlain,https://github.com/ropensci/oai,TRUE,https://github.com/ropensci/oai,56859,6,1542655321
oak,Functions and classes to create and manipulate trees and nodes.,2018-11-06,Paul Poncet,https://github.com/paulponcet/oak,TRUE,https://github.com/paulponcet/oak,1124,1,1542326312
obAnalytics,"Data processing, visualisation and analysis of Limit Order Book
    event data.",2016-11-11,Philip Stubbings,https://github.com/phil8192/ob-analytics,TRUE,https://github.com/phil8192/ob-analytics,9942,83,1551618455
objectremover,"An 'RStudio' addin to assist with removing objects from the global environment. Features include removing objects according to name patterns and object type. During the course of an analysis, temporary objects are often created and this tool assists with removing them quickly. This can be useful when memory management within 'R' is important.",2019-03-06,Alan Yeung  (<https://orcid.org/0000-0001-5226-3695>),https://github.com/alan-y/objectremover,TRUE,https://github.com/alan-y/objectremover,261,0,1551734021
Observation,"Two-part system for first collecting then managing direct
    observation data, as described by Hibbing PR, Ellingson LD,
    Dixon PM, & Welk GJ (2018) <doi:10.1249/MSS.0000000000001486>.",2018-05-11,Paul R. Hibbing,https://github.com/paulhibbing/Observation,TRUE,https://github.com/paulhibbing/observation,1906,0,1526051547
oce,"Supports the analysis of Oceanographic data, including 'ADCP'
    measurements, measurements made with 'argo' floats, 'CTD' measurements,
    sectional data, sea-level time series, coastline and topographic data, etc.
    Provides specialized functions for calculating seawater properties such as
    potential temperature in either the 'UNESCO' or 'TEOS-10' equation of state.
    Produces graphical displays that conform to the conventions of the Oceanographic
    literature.",2018-10-04,Dan Kelley  (<https://orcid.org/0000-0001-7808-5911>),https://dankelley.github.io/oce,TRUE,https://github.com/dankelley/oce,67845,65,1553702154
ocedata,"Several important and Oceanographic data sets are provided. These
    are particularly useful to the 'oce' package, but can also be helpful in a
    general context.",2018-12-19,Dan Kelley  (<https://orcid.org/0000-0001-7808-5911>),https://dankelley.github.io/ocedata,TRUE,https://github.com/dankelley/ocedata,14564,4,1545233133
odbc,A DBI-compatible interface to ODBC databases.,2018-06-09,Jim Hester,https://github.com/r-dbi/odbc,TRUE,https://github.com/r-dbi/odbc,309949,206,1544205650
oddsratio,"Simplified odds ratio calculation of GAM(M)s & GLM(M)s. 
    Provides structured output (data frame) of all predictors and their corresponding odds ratios and confident intervals for further analyses. 
    It helps to avoid false references of predictors and increments by specifying these parameters in a list instead of using 'exp(coef(model))' (standard approach of odds ratio calculation for GLMs) which just returns a plain numeric output. 
    For GAM(M)s, odds ratio calculation is highly simplified with this package since it takes care of the multiple 'predict()' calls of the chosen predictor while holding other predictors constant.
    Also, this package allows odds ratio calculation of percentage steps across the whole predictor distribution range for GAM(M)s. 
    In both cases, confident intervals are returned additionally.
    Calculated odds ratio of GAM(M)s can be inserted into the smooth function plot. ",2018-07-25,Patrick Schratz  (<https://orcid.org/0000-0003-0748-6624>),https://github.com/pat-s/oddsratio,TRUE,https://github.com/pat-s/oddsratio,18182,20,1536590362
ODEnetwork,"Simulates a network of ordinary differential equations of order
    two. The package provides an easy interface to construct networks. In addition
    you are able to define different external triggers to manipulate the trajectory.
    The method is described by Surmann, Ligges, and Weihs (2014) <doi:10.1109/ENERGYCON.2014.6850482>.",2018-05-22,Dirk Surmann  (<https://orcid.org/0000-0003-0873-137X>),https://github.com/surmann/ODEnetwork,TRUE,https://github.com/surmann/odenetwork,2069,2,1526996026
ODEsensitivity,"Performs sensitivity analysis in ordinary differential equation (ode) models.
    The package utilize the ode interface from 'deSolve' and connects it with the 
    sensitivity analysis from 'sensitivity'. Additionally we add a method to
    run the sensitivity analysis on variables with class 'ODEnetwork'. A detailed
    plotting function provides outputs on the calculations.
    The method is described by Weber, Theers, Surmann, Ligges, and Weihs (2018) <doi:10.17877/DE290R-18874>.",2019-01-09,Frank Weber,https://github.com/surmann/ODEsensitivity,TRUE,https://github.com/surmann/odesensitivity,2393,2,1547023750
ODS,"Outcome-dependent sampling (ODS) schemes are cost-effective ways to enhance study efficiency. 
    In ODS designs, one observes the exposure/covariates with a probability that depends on the outcome 
    variable. Popular ODS designs include case-control for binary outcome, case-cohort for time-to-event 
    outcome, and continuous outcome ODS design (Zhou et al. 2002) <doi: 10.1111/j.0006-341X.2002.00413.x>. 
    Because ODS data has biased sampling nature, standard statistical analysis such as linear regression 
    will lead to biases estimates of the population parameters. This package implements four statistical 
    methods related to ODS designs: (1) An empirical likelihood method analyzing the primary continuous 
    outcome with respect to exposure variables in continuous ODS design (Zhou et al., 2002). (2) A partial 
    linear model analyzing the primary outcome in continuous ODS design (Zhou, Qin and Longnecker, 2011) 
    <doi: 10.1111/j.1541-0420.2010.01500.x>. (3) Analyze a secondary outcome in continuous ODS design 
    (Pan et al. 2018) <doi: 10.1002/sim.7672>. (4) An estimated likelihood method analyzing a secondary 
    outcome in case-cohort data (Pan et al. 2017) <doi: 10.1111/biom.12838>.",2018-11-19,Yinghao Pan,https://github.com/Yinghao-Pan/ODS,TRUE,https://github.com/yinghao-pan/ods,837,0,1543153147
oec,Access The Observatory of Economic Complexity API from R to download international trade data.,2018-05-11,Mauricio Vargas S.,https://CRAN.R-project.org/package=oec,TRUE,https://github.com/pachamaltese/oec-r,8784,9,1535419894
oem,"Solves penalized least squares problems for big tall data
    using the orthogonalizing EM algorithm of Xiong et al. (2016) 
    <doi:10.1080/00401706.2015.1054436>. The main fitting function is oem() and the
    functions cv.oem() and xval.oem() are for cross validation, the latter being an
    accelerated cross validation function for linear models. The big.oem() function
    allows for out of memory fitting.",2018-10-30,Jared Huling  (<https://orcid.org/0000-0003-0670-4845>),"https://arxiv.org/abs/1801.09661,
https://github.com/jaredhuling/oem,
https://jaredhuling.github.io/oem",TRUE,https://github.com/jaredhuling/oem,21835,13,1549895430
officer,"Access and manipulate 'Microsoft Word' and 'Microsoft PowerPoint' documents from R. 
  The package focuses on tabular and graphical reporting from R; it also provides two functions
  that let users get document content into data objects. A set of functions 
  lets add and remove images, tables and paragraphs of text in new or existing documents. 
  When working with 'PowerPoint' presentations, slides can be added or removed; shapes inside 
  slides can also be added or removed. When working with 'Word' documents, a cursor can be 
  used to help insert or delete content at a specific location in the document. The package 
  does not require any installation of Microsoft products to be able to write Microsoft files.",2019-03-01,David Gohel,https://davidgohel.github.io/officer,TRUE,https://github.com/davidgohel/officer,193733,273,1553611944
ofGEM,"Offers a gene-based meta-analysis test with filtering to detect gene-environment interactions (GxE) with association data, proposed by Wang et al. (2018) <doi:10.1002/gepi.22115>. It first conducts a meta-filtering test to filter out unpromising SNPs by combining all samples in the consortia data. It then runs a test of omnibus-filtering-based GxE meta-analysis (ofGEM) that combines the strengths of the fixed- and random-effects meta-analysis with meta-filtering. It can also analyze data from multiple ethnic groups. ",2018-07-13,Jiebiao Wang,https://github.com/randel/ofGEM,TRUE,https://github.com/randel/ofgem,1725,0,1530927419
OHPL,"Ordered homogeneity pursuit lasso (OHPL)
    algorithm for group variable selection proposed in Lin et al. (2017)
    <DOI:10.1016/j.chemolab.2017.07.004>. The OHPL method exploits the
    homogeneity structure in high-dimensional data and enjoys the
    grouping effect to select groups of important variables
    automatically. This feature makes it particularly useful for
    high-dimensional datasets with strongly correlated variables,
    such as spectroscopic data.",2017-08-08,Nan Xiao,"https://ohpl.io, https://github.com/road2stat/OHPL",TRUE,https://github.com/road2stat/ohpl,3921,1,1552882287
ohtadstats,"Calculate's Tomoka Ohta's partitioning of linkage disequilibrium,
 deemed D-statistics, for pairs of loci. Beissinger et al. (2016) <doi:10.1038/hdy.2015.81>.",2019-03-18,Paul F. Petrowski <pfpetrowski@mail.missouri.edu> & Timothy M. Beissinger <timbeissinger@gmail.com>,https://github.com/pfpetrowski/OhtaDStats,TRUE,https://github.com/pfpetrowski/ohtadstats,2768,1,1553058236
olsrr,"Tools designed to make it easier for users, particularly beginner/intermediate R users 
    to build ordinary least squares regression models. Includes comprehensive regression output, 
    heteroskedasticity tests, collinearity diagnostics, residual diagnostics, measures of influence, 
    model fit assessment and variable selection procedures.",2018-11-22,Aravind Hebbali,"https://olsrr.rsquaredacademy.com/,
https://github.com/rsquaredacademy/olsrr",TRUE,https://github.com/rsquaredacademy/olsrr,58073,69,1548498002
ompr,"Model mixed integer linear programs in an algebraic way directly in R.
             The model is solver-independent and thus offers the possibility
             to solve a model with different solvers. It currently only supports
             linear constraints and objective functions. See the 'ompr'
             website <https://dirkschumacher.github.io/ompr> for more information, 
             documentation and examples.",2018-06-11,Dirk Schumacher,https://github.com/dirkschumacher/ompr,TRUE,https://github.com/dirkschumacher/ompr,10058,159,1548702934
ompr.roi,"A solver for 'ompr' based on the R Optimization Infrastructure ('ROI').
  The package makes all solvers in 'ROI' available to solve 'ompr' models. Please see the
  'ompr' website <https://dirkschumacher.github.io/ompr> and package docs for more information
  and examples on how to use it.",2018-06-11,Dirk Schumacher,https://github.com/dirkschumacher/ompr.roi,TRUE,https://github.com/dirkschumacher/ompr.roi,8882,6,1528747054
omu,"Facilitates the creation of intuitive figures to describe metabolomics data by utilizing Kyoto Encyclopedia of Genes and Genomes (KEGG) hierarchy data, and gathers functional orthology and gene data using the package 'KEGGREST' to access the 'KEGG' API.",2018-08-02,Connor Tiffany,"https://github.com/connor-reid-tiffany/Omu,
https://www.kegg.jp/kegg/rest/keggapi.html",TRUE,https://github.com/connor-reid-tiffany/omu,1731,0,1532393899
onemap,"Analysis of molecular marker data from model (backcrosses,
    F2 and recombinant inbred lines) and non-model systems (i. e.
    outcrossing species). For the later, it allows statistical
    analysis by simultaneously estimating linkage and linkage
    phases (genetic map construction) according to Wu et al. (2002)
    <doi:10.1006/tpbi.2002.1577>. All analysis are based on multipoint 
    approaches using hidden Markov models.",2017-10-18,Gabriel Margarido,https://github.com/augusto-garcia/onemap,TRUE,https://github.com/augusto-garcia/onemap,18845,15,1529518953
OneR,"Implements the One Rule (OneR) Machine Learning classification algorithm (Holte, R.C. (1993) <doi:10.1023/A:1022631118932>) with enhancements for sophisticated handling of numeric data and missing values together with extensive diagnostic functions. It is useful as a baseline for machine learning models and the rules are often helpful heuristics.",2017-05-05,Holger von Jouanne-Diedrich,https://github.com/vonjd/OneR,TRUE,https://github.com/vonjd/oner,21057,23,1528132176
onnx,"R Interface to 'ONNX' - Open Neural Network Exchange <https://onnx.ai/>. 
             'ONNX' provides an open source format for machine learning models. 
             It defines an extensible computation graph model, as well as definitions
             of built-in operators and standard data types.",2018-04-25,Yuan Tang  (<https://orcid.org/0000-0001-5243-233X>),https://github.com/onnx/onnx-r,TRUE,https://github.com/onnx/onnx-r,2412,16,1524687155
OOBCurve,"Provides functions to calculate the out-of-bag learning curve for random forests for any measure that is available in the 'mlr' package. Supported random forest packages are 'randomForest' and 'ranger' and trained models of these packages with the train function of 'mlr'. The main function is OOBCurve() that calculates the out-of-bag curve depending on the number of trees. With the OOBCurvePars() function out-of-bag curves can also be calculated for 'mtry', 'sample.fraction' and 'min.node.size' for the 'ranger' package.",2018-08-30,Philipp Probst,https://github.com/PhilippPro/OOBCurve,TRUE,https://github.com/philipppro/oobcurve,4448,9,1535641111
opalr,"Data integration Web application for biobanks by 'OBiBa'. 'Opal' is
    the core database application for biobanks. Participant data, once
    collected from any data source, must be integrated and stored in a central
    data repository under a uniform model. 'Opal' is such a central repository.
    It can import, process, validate, query, analyze, report, and export data.
    'Opal' is typically used in a research center to analyze the data acquired at
    assessment centres. Its ultimate purpose is to achieve seamless
    data-sharing among biobanks. This 'Opal' client allows to interact with 'Opal'
    web services and to perform operations on the R server side. 'DataSHIELD'
    administration tools are also provided.",2019-03-21,Yannick Marcon  (<https://orcid.org/0000-0003-0138-2023>),"https://www.obiba.org/ https://www.obiba.org/pages/products/opal/
https://doi.org/10.1093/ije/dyx180 http://www.datashield.ac.uk/",TRUE,https://github.com/obiba/opalr,860,0,1553269782
openadds,"'Openaddresses' (<https://openaddresses.io/>) client. Search,
    fetch data, and combine 'datasets'. Outputs are easy to visualize
    with base plots, 'ggplot2', or 'leaflet'.",2017-01-03,Scott Chamberlain,https://github.com/sckott/openadds,TRUE,https://github.com/sckott/openadds,6202,7,1543961938
openair,"Tools to analyse, interpret and understand air
    pollution data. Data are typically hourly time series
    and both monitoring data and dispersion model output
    can be analysed.  Many functions can also be applied to
    other data, including meteorological and traffic data.",2019-03-28,David Carslaw,http://davidcarslaw.github.io/openair/,TRUE,https://github.com/davidcarslaw/openair,138795,111,1554446902
opencage,"Tool for accessing the OpenCage API, which provides forward
    geocoding (from placename to longitude and latitude) and reverse geocoding (from
    longitude and latitude to placename).",2018-01-16,Maëlle Salmon,http://github.com/ropensci/opencage,TRUE,https://github.com/ropensci/opencage,8350,53,1549379441
opencv,"Experimenting with computer vision and machine learning in R. This 
    package exposes some of the available 'OpenCV' vision algorithms, such as edge, 
    body or face detection. These can either be applied to analyze static images,
    or to filter live video footage from a camera device.",2019-04-01,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),https://github.com/ropensci/opencv,TRUE,https://github.com/ropensci/opencv,64,58,1554496158
OpenImageR,"Incorporates functions for image preprocessing, filtering and image recognition. The package takes advantage of 'RcppArmadillo' to speed up computationally intensive functions. The histogram of oriented gradients descriptor is a modification of the 'findHOGFeatures' function of the 'SimpleCV' computer vision platform, the average_hash(), dhash() and phash() functions are based on the 'ImageHash' python library. The Gabor Feature Extraction functions are based on 'Matlab' code of the paper, ""CloudID: Trustworthy cloud-based and cross-enterprise biometric identification"" by M. Haghighat, S. Zonouz, M. Abdel-Mottaleb, Expert Systems with Applications, vol. 42, no. 21, pp. 7905-7916, 2015, <doi:10.1016/j.eswa.2015.06.025>. The 'SLIC' and 'SLICO' superpixel algorithms were explained in detail in (i) ""SLIC Superpixels Compared to State-of-the-art Superpixel Methods"", Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Suesstrunk, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, num. 11, p. 2274-2282, May 2012, <doi:10.1109/TPAMI.2012.120> and (ii) ""SLIC Superpixels"", Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Suesstrunk, EPFL Technical Report no. 149300, June 2010.",2019-02-10,Lampros Mouselimis,https://github.com/mlampros/OpenImageR,TRUE,https://github.com/mlampros/openimager,46933,32,1551862168
OpenML,"We provide an R interface to 'OpenML.org' which is an online machine learning platform where researchers can access open data, download and upload data sets, share their machine learning tasks and experiments and organize them online to work and collaborate with other researchers. 
    The R interface allows to query for data sets with specific properties, and allows the downloading and uploading of data sets, tasks, flows and runs. 
    See <https://www.openml.org/guide/api> for more information.",2018-03-02,Giuseppe Casalicchio <giuseppe.casalicchio@stat.uni-muenchen.de>,https://github.com/openml/openml-r,TRUE,https://github.com/openml/openml-r,11599,69,1551821851
OpenMx,"Facilitates treatment of statistical model specifications
    as things that can be generated and manipulated programmatically.
    Structural equation models may be specified with reticular action model matrices or paths,
    linear structural relations matrices or paths, or
    directly in matrix algebra.
    Fit functions include full information maximum likelihood,
    maximum likelihood, and weighted least squares.
    Example models include confirmatory factor, multiple group, mixture
    distribution, categorical threshold, modern test theory, differential
    equations, state space, and many others.  MacOS users can download the most up-to-date 
    package binaries from <http://openmx.ssri.psu.edu>.
    See Neale, Hunter, Pritikin, Zahery, Brick,
    Kirkpatrick, Estabrook, Bates, Maes, & Boker (2016) <doi:10.1007/s11336-014-9435-8>.",2019-02-08,Joshua N. Pritikin,"http://openmx.ssri.psu.edu, https://github.com/OpenMx/OpenMx",TRUE,https://github.com/openmx/openmx,262145,28,1554562968
OpenRepGrid,"Analyze repertory grids, a qualitative-quantitative 
    data collection technique devised by George A. Kelly in the 1950s. Today, grids are used across 
    various domains ranging from clinical psychology to marketing. The package contains
    functions to quantitatively analyze and visualize repertory grid data 
    (see e.g. Bell, 2005, <doi:10.1002/0470013370.ch9>; 
    Fransella, Bell, & Bannister, 2004, ISBN: 978-0-470-09080-0).",2018-05-31,Mark Heckmann,"http://openrepgrid.org,
https://github.com/markheckmann/OpenRepGrid",TRUE,https://github.com/markheckmann/openrepgrid,16540,10,1545509808
opensensmapr,"Download environmental measurements and sensor station metadata
    from the API of open data sensor web platform <https://opensensemap.org> for
    analysis in R.
    This platform provides real time data of more than 1500 low-cost sensor
    stations for PM10, PM2.5, temperature, humidity, UV-A intensity and more
    phenomena.
    The package aims to be compatible with 'sf' and the 'Tidyverse', and provides
    several helper functions for data exploration and transformation.",2019-03-10,Norwin Roosen,http://github.com/sensebox/opensensmapR,TRUE,https://github.com/sensebox/opensensmapr,1613,3,1549748959
openSTARS,"An open source implementation of the 'STARS' toolbox
    (Peterson & Ver Hoef, 2014, <doi:10.18637/jss.v056.i02>) using 'R' and 'GRASS GIS'.
    It prepares the *.ssn object needed for the 'SSN' package.
    A Digital Elevation Model (DEM) is used to derive stream networks 
    (in contrast to 'STARS' that can clean an existing stream network).",2018-05-11,Mira Kattwinkel,https://github.com/MiKatt/openSTARS,TRUE,https://github.com/mikatt/openstars,3417,14,1532354892
openVA,Implements multiple existing open-source algorithms for coding cause of death from verbal autopsies. It also provides tools for data manipulation tasks commonly used in Verbal Autopsy analysis and implements easy graphical visualization of individual and population level statistics.,2019-02-18,Zehang Li,https://github.com/verbal-autopsy-software/openVA,TRUE,https://github.com/verbal-autopsy-software/openva,9383,0,1550593675
openxlsx,"Simplifies the creation of Excel .xlsx files by providing a high
    level interface to writing, styling and editing worksheets. Through the use of
    'Rcpp', read/write times are comparable to the 'xlsx' and 'XLConnect' packages
    with the added benefit of removing the dependency on Java.",2018-05-26,Alexander Walker,https://github.com/awalker89/openxlsx,TRUE,https://github.com/awalker89/openxlsx,2112111,281,1534548058
oppr,"A decision support tool for prioritizing conservation projects.
    Prioritizations can be developed by maximizing expected feature richness,
    expected phylogenetic diversity, the number of features that meet
    persistence targets, or identifying a set of projects that meet persistence
    targets for minimal cost. Constraints (e.g. lock in specific actions) and
    feature weights can also be specified to further customize prioritizations.
    After defining a project prioritization problem, solutions can be obtained
    using exact algorithms, heuristic algorithms, or random processes. In
    particular, it is recommended to install the 'Gurobi' optimizer  (available
    from <https://www.gurobi.com>) because it can identify optimal solutions
    very quickly. Finally, methods are provided for comparing different
    prioritizations and evaluating their benefits.",2019-03-20,Jeffrey O Hanson,"https://prioritizr.github.io/oppr,
https://github.com/prioritizr/oppr",TRUE,https://github.com/prioritizr/oppr,171,2,1553093303
opticut,"Likelihood based optimal partitioning and indicator
  species analysis. Finding the best binary partition for each species
  based on model selection, with the possibility to take into account
  modifying/confounding variables as described
  in Kemencei et al. (2014) <doi:10.1556/ComEc.15.2014.2.6>.
  The package implements binary and multi-level response models,
  various measures of uncertainty, Lorenz-curve based thresholding,
  with native support for parallel computations.",2018-02-01,Peter Solymos,https://github.com/psolymos/opticut,TRUE,https://github.com/psolymos/opticut,4883,0,1524972828
optigrab,"Parse options from the command-line using a simple, clean syntax. 
    It requires little or no specification and supports short and long options,
    GNU-, Java- or Microsoft- style syntaxes, verb commands and more. ",2019-01-07,Christopher Brown,https://github.com/decisionpatterns/optigrab,TRUE,https://github.com/decisionpatterns/optigrab,6958,4,1546708461
OptimClassifier,"Patterns searching and binary classification in economic and financial data is a
              large field of research. There are a large part of the data
              that the target variable is binary. Nowadays, many methodologies
              are used, this package collects most popular and compare different
              configuration options for Linear Models (LM), Generalized Linear Models (GLM), 
              Linear Mixed Models (LMM), Discriminant Analysis (DA), 
              Classification And Regression Trees (CART), Neural Networks (NN) and Support Vector Machines (SVM).",2018-04-09,Agustín Pérez-Martín (<https://orcid.org/0000-0003-4994-3176>),https://economistgame.github.io/OptimClassifier,TRUE,https://github.com/economistgame/optimclassifier,4284,1,1523286938
optimus,"Assessment and diagnostics for comparing competing
    clustering solutions, using predictive models. The main intended
    use is for comparing clustering/classification solutions of
    ecological data (e.g. presence/absence, counts, ordinal scores) to
    1) find an optimal partitioning solution, 2) identify
    characteristic species and 3) refine a classification by merging
    clusters that increase predictive performance. However, in a more
    general sense, this package can do the above for any set of
    clustering solutions for i observations of j variables.",2018-01-16,Mitchell Lyons,https://github.com/mitchest/optimus/,TRUE,https://github.com/mitchest/optimus,3861,1,1529460060
optiRum,"This fills the gaps credit analysts and loan modellers at
    Optimum Credit identify in the existing R code body.
    It allows for the production of documentation with less coding,
    replicates a number of Microsoft Excel functions useful for
    modelling loans (without rounding), and other helpful functions
    for producing charts and tables.  It also has some additional scales for
    use, including a GBP scale.",2018-07-03,Steph Locke,"https://github.com/lockedata/optiRum,
https://itsalocke.com/optirum/",TRUE,https://github.com/lockedata/optirum,17346,8,1548250352
optmatch,"Distance based bipartite matching using the RELAX-IV minimum cost flow solver,
    oriented to matching of treatment and control groups in observational
    studies. Routines are provided to generate distances from generalised linear models (propensity
    score matching), formulas giving variables on which to limit matched distances, stratified or
    exact matching directives, or calipers, alone or in combination.",2018-07-12,Ben B. Hansen <ben.hansen@umich.edu>,"https://www.r-project.org,
https://github.com/markmfredrickson/optmatch",TRUE,https://github.com/markmfredrickson/optmatch,117667,21,1546627682
optparse,"A command line parser inspired by Python's 'optparse' library to
    be used with Rscript to write ""#!"" shebang scripts that accept short and
    long flag/options.",2019-04-02,Trevor L Davis,https://github.com/trevorld/r-optparse,TRUE,https://github.com/trevorld/r-optparse,243090,71,1554312485
Orcs,"I tend to repeat the same code chunks over and over again. At
    first, this was fine for me and I paid little attention to such redundancies.
    A little later, when I got tired of manually replacing Linux filepaths with
    the referring Windows versions, and vice versa, I started to stuff some very
    frequently used work-steps into functions and, even later, into a proper R
    package. And that's what this package is - a hodgepodge of various R functions
    meant to simplify (my) everyday-life coding work without, at the same time,
    being devoted to a particular scope of application.",2019-02-28,Florian Detsch,https://github.com/fdetsch/Orcs,TRUE,https://github.com/fdetsch/orcs,2094,2,1551368865
ordering,"Functions to test/check/verify/investigate the ordering of vectors. 
    The 'is_[strictly_]*' family of functions test vectors for 
    'sorted', 'monotonic', 'increasing', 'decreasing' order; 'is_constant' 
    and 'is_incremental' test for the degree of ordering. `ordering` 
    provides a numeric indication of ordering -2 (strictly decreasing) to 
    2 (strictly increasing).",2018-11-19,Christopher Brown,https://github.com/decisionpatterns/ordering,TRUE,https://github.com/decisionpatterns/ordering,982,0,1546703019
ordinal,"Implementation of cumulative link (mixed) models also known
    as ordered regression models, proportional odds models, proportional
    hazards models for grouped survival times and ordered logit/probit/...
    models. Estimation is via maximum likelihood and mixed models are fitted
    with the Laplace approximation and adaptive Gauss-Hermite quadrature.
    Multiple random effect terms are allowed and they may be nested, crossed or
    partially nested/crossed. Restrictions of symmetry and equidistance can be
    imposed on the thresholds (cut-points/intercepts). Standard model
    methods are available (summary, anova, drop-methods, step,
    confint, predict etc.) in addition to profile methods and slice
    methods for visualizing the likelihood function and checking
    convergence.",2019-03-09,Rune Haubo Bojesen Christensen,https://github.com/runehaubo/ordinal,TRUE,https://github.com/runehaubo/ordinal,419644,4,1552133245
ore,"Provides an alternative to R's built-in functionality for handling
    regular expressions, based on the Onigmo library. Offers first-class
    compiled regex objects, partial matching and function-based substitutions,
    amongst other features.",2018-08-30,Jon Clayden,https://github.com/jonclayden/ore,TRUE,https://github.com/jonclayden/ore,67984,51,1536159636
origami,"Provides a general framework for the application of
    cross-validation schemes to particular functions. By allowing arbitrary
    lists of results, origami accommodates a range of cross-validation
    applications.",2018-03-06,Jeremy Coyle,http://origami.tlverse.org,TRUE,https://github.com/tlverse/origami,4836,15,1550363107
originr,"Get species origin data (whether species is native/invasive) from the
    following sources on the web: Encyclopedia of Life (<http://eol.org>), Flora
    'Europaea' (<http://rbg-web2.rbge.org.uk/FE/fe.html>), Global Invasive Species
    Database (<http://www.iucngisd.org/gisd>), the Native Species Resolver
    (<http://bien.nceas.ucsb.edu/bien/tools/nsr/nsr-ws/>), Integrated Taxonomic
    Information Service (<http://www.itis.gov/>), and Global Register of
    Introduced and Invasive Species (<http://www.griis.org/>).",2018-04-30,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/originr,TRUE,https://github.com/ropensci/originr,6496,12,1546631186
osmdata,"Download and import of 'OpenStreetMap' ('OSM') data as 'sf' or 'sp'
    objects.  'OSM' data are extracted from the 'Overpass' web server and
    processed with very fast 'C++' routines for return to 'R'.",2019-03-21,Mark Padgham,https://github.com/ropensci/osmdata,TRUE,https://github.com/ropensci/osmdata,42371,109,1553589535
osmose,"The multispecies and individual-based model (IBM) 'OSMOSE'
  (Shin and Curry (2001) <doi:10.1016/S0990-7440(01)01106-8> and Shin and Curry (2004) <doi:10.1139/f03-154>)
  focuses on fish species. This model assumes opportunistic predation based on spatial co-occurrence and size
  adequacy between a predator and its prey (size-based opportunistic predation). It
  represents fish individuals grouped into schools, which are characterized by their
  size, weight, age, taxonomy and geographical location (2D model), and which undergo
  major processes of fish life cycle (growth, explicit predation, natural and starvation
  mortalities, reproduction and migration) and fishing exploitation. The model needs
  basic biological parameters that are often available for a wide range of species, and
  which can be found in 'FishBase' for instance (see <http://www.fishbase.org/search.php>), and fish spatial distribution data. This
  package provides tools to build and run simulations using the 'OSMOSE' model.",2018-01-09,Nicolas Barrier,http://www.osmose-model.org/,TRUE,https://github.com/osmose-model/osmose,2635,1,1544623613
osmplotr,"Bespoke images of 'OpenStreetMap' ('OSM') data and data
    visualisation using 'OSM' objects.",2018-12-19,Mark Padgham,https://github.com/ropensci/osmplotr,TRUE,https://github.com/ropensci/osmplotr,10171,107,1549547070
OSMscale,"Functionality to handle and project lat-long coordinates, easily download background maps
    and add a correct scale bar to 'OpenStreetMap' plots in any map projection.",2017-04-12,Berry Boessenkool,https://github.com/brry/OSMscale,TRUE,https://github.com/brry/osmscale,6575,1,1553942708
osrm,"An interface between R and the OSRM API. OSRM is a routing
    service based on OpenStreetMap data. See <http://project-osrm.org/> for more
    information. This package allows to compute distances (travel time and 
    kilometric distance) between points and travel time matrices.",2019-01-24,Timothée Giraud,https://github.com/rCarto/osrm,TRUE,https://github.com/rcarto/osrm,19590,78,1548340833
otsad,"Implements a set of online fault detectors for time-series, called: PEWMA see M. Carter
             et al. (2012) <doi:10.1109/SSP.2012.6319708>, SD-EWMA and TSSD-EWMA see H. Raza et al. 
             (2015) <doi:10.1016/j.patcog.2014.07.028>, KNN-CAD see E. Burnaev et al. (2016)
             <arXiv:1608.04585>, KNN-LDCD see V. Ishimtsev et al. (2017) <arXiv:1706.03412> and 
             CAD-OSE see M. Smirnov (2018) <https://github.com/smirmik/CAD>. The first three 
             algorithms belong to prediction-based techniques and the last three belong to 
             window-based techniques. In addition, the SD-EWMA and PEWMA algorithms are algorithms 
             designed to work in stationary environments, while the other four 
             are algorithms designed to work in non-stationary environments.",2019-04-01,Alaiñe Iturria,https://github.com/alaineiturria/otsad,TRUE,https://github.com/alaineiturria/otsad,49,3,1553754780
otuSummary,"Summarizes the taxonomic composition, diversity contribution of the rare and abundant community by using OTU (operational taxonomic unit) table which was generated by analyzing pipeline of 'QIIME' or 'mothur'. The rare biosphere in this package is subset by the relative abundance threshold (for details about rare biosphere please see Lynch and Neufeld (2015) <doi:10.1038/nrmicro3400>).",2018-06-19,Sizhong Yang,https://github.com/camel315/otuSummary,TRUE,https://github.com/camel315/otusummary,1792,0,1527253933
otvPlots,"Enables automated visualization of variable 
    distribution and changes over time for predictive model building.
    It efficiently computes summary statistics aggregated by time for 
    large datasets, and create plots for variable level monitoring.  ",2018-06-26,Yingbo Li,https://github.com/capitalone/otvPlots,TRUE,https://github.com/capitalone/otvplots,3195,6,1529983557
outbreaks,"Empirical or simulated disease outbreak data, provided either as
    RData or as text files.",2019-01-21,Finlay Campbell,https://github.com/reconhub/outbreaks,TRUE,https://github.com/reconhub/outbreaks,10752,24,1551096018
outcomerate,"Standardized survey outcome rate functions, including the response rate, contact rate, cooperation rate, and refusal rate. These outcome rates allow survey researchers to measure the quality of survey data using definitions published by the American Association of Public Opinion Research (AAPOR). For details on these standards, see AAPOR (2016) <https://www.aapor.org/Standards-Ethics/Standard-Definitions-(1).aspx>. ",2018-10-06,"Rafael Pilliard Hellwig 
    (<https://orcid.org/0000-0002-3092-3493>)",https://github.com/ropensci/outcomerate,TRUE,https://github.com/ropensci/outcomerate,1276,5,1539753712
overture,"Simplifies MCMC setup by automatically looping through sampling 
    functions and saving the results.  Reduces the memory footprint of running 
    MCMC and saves samples to disk as the chain runs.  Allows samples from the 
    chain to be analyzed while the MCMC is still running.  Provides functions 
    for commonly performed operations such as calculating Metropolis acceptance 
    ratios and creating adaptive Metropolis samplers.  References: Roberts and 
    Rosenthal (2009) <doi:10.1198/jcgs.2009.06134>.",2019-03-15,Kurtis Shuler,https://github.com/kurtis-s/overture,TRUE,https://github.com/kurtis-s/overture,713,0,1552602954
owmr,"Accesses OpenWeatherMap's (owm) <https://openweathermap.org/> API.
   'owm' itself is a service providing weather data in the past, in the future and now.
   Furthermore, 'owm' serves weather map layers usable in frameworks like 'leaflet'.
   In order to access the API, you need to sign up for an API key. There are free and paid plans.
   Beside functions for fetching weather data from 'owm', 'owmr' supplies
   tools to tidy up fetched data (for fast and simple access) and to show it on leaflet maps.",2018-11-03,Stefan Kuethe,"https://github.com/crazycapivara/owmr/,
https://crazycapivara.github.io/owmr/",TRUE,https://github.com/crazycapivara/owmr,5739,15,1542908713
ows4R,"Provides an Interface to Web-Services defined as standards by the Open Geospatial Consortium (OGC), including Web Feature Service
 (WFS) for vector data, Catalogue Service (CSW) for ISO/OGC metadata and associated standards such as the common web-service specification (OWS) and
 OGC Filter Encoding. The long-term purpose is to add support for additional OGC service standards such as Web Coverage Service (WCS) and
 Web Processing Service (WPS).",2018-08-31,Emmanuel Blondel  (<https://orcid.org/0000-0002-5870-5762>),"https://github.com/eblondel/ows4R,
http://www.opengeospatial.org/standards",TRUE,https://github.com/eblondel/ows4r,2287,3,1551104291
oXim,Tools for oxycline depth calculation from echogram matrices.,2018-05-07,Wencheng Lau-Medrano,https://github.com/LuisLauM/oXim,TRUE,https://github.com/luislaum/oxim,6959,0,1525706805
packagefinder,"Search for R packages on CRAN directly from the R console, based on the packages' titles, short and long descriptions, or other fields. Combine multiple keywords with logical operators ('and', 'or'), view detailed information on any package and keep track of the latest package contributions to CRAN.",2019-04-02,Joachim Zuckarelli  (<https://orcid.org/0000-0002-9280-3016>),https://github.com/jsugarelli/packagefinder/,TRUE,https://github.com/jsugarelli/packagefinder,3038,22,1554233855
packcircles,Simple algorithms for circle packing.,2018-09-18,Michael Bedward,https://github.com/mbedward/packcircles,TRUE,https://github.com/mbedward/packcircles,28251,24,1537250680
packrat,"Manage the R packages your project depends
    on in an isolated, portable, and reproducible way.",2018-11-14,Kevin Ushey,https://github.com/rstudio/packrat/,TRUE,https://github.com/rstudio/packrat,1548985,301,1553287182
pacman,"Tools to more conveniently perform tasks associated with
        add-on packages. pacman conveniently wraps library and package
        related functions and names them in an intuitive and consistent
        fashion.  It seeks to combine functionality from lower level
        functions which can speed up workflow.",2019-03-11,Tyler Rinker,https://github.com/trinker/pacman,TRUE,https://github.com/trinker/pacman,261386,131,1553220760
pacotest,"Routines for two different test types, the Constant Conditional Correlation (CCC) test and the Vectorial Independence (VI) test are provided (Kurz and Spanhel (2017) <arXiv:1706.02338>). The tests can be applied to check whether a conditional copula coincides with its partial copula. Functions to test whether a regular vine copula satisfies the so-called simplifying assumption or to test a single copula within a regular vine copula to be a (j-1)-th order partial copula are available. The CCC test comes with a decision tree approach to allow testing in high-dimensional settings.",2019-03-11,Malte S. Kurz,NA,TRUE,https://github.com/maltekurz/pacotest,5344,1,1552297866
padr,"Transforms datetime data into a format ready for analysis.
    It offers two core functionalities; aggregating data to a higher level interval
    (thicken) and imputing records where observations were absent (pad). ",2018-06-26,Edwin Thoen,https://github.com/EdwinTh/padr,TRUE,https://github.com/edwinth/padr,169407,92,1554317026
PAFit,Statistical methods for estimating preferential attachment and node fitness generative mechanisms in temporal complex networks are provided. Thong Pham et al. (2015) <doi:10.1371/journal.pone.0137796>. Thong Pham et al.(2016) <doi:10.1038/srep32558>.  ,2018-09-19,Thong Pham,https://github.com/thongphamthe/PAFit,TRUE,https://github.com/thongphamthe/pafit,19984,5,1554439033
pagedown,"Use the paged media properties in CSS and the JavaScript
  library 'paged.js' to split the content of an HTML document into discrete
  pages. Each page can have its page size, page numbers, margin boxes, and
  running headers, etc. Applications of this package include books, letters,
  reports, papers, business cards, resumes, and posters.",2019-03-06,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/rstudio/pagedown,TRUE,https://github.com/rstudio/pagedown,2533,282,1553891147
pagenum,A simple way to add page numbers to base/ggplot/lattice graphics.,2017-07-13,Kevin Wright,https://github.com/kwstat/pagenum,TRUE,https://github.com/kwstat/pagenum,7152,0,1527186535
pak,"The goal of 'pak' is to make package installation faster and
    more reliable. In particular, it performs all HTTP operations in parallel,
    so metadata resolution and package downloads are fast. Metadata and package
    files are cached on the local disk as well. 'pak' has a dependency solver,
    so it finds version conflicts before performing the installation. This
    version of 'pak' supports CRAN, 'Bioconductor' and 'GitHub' packages as well.",2019-02-19,Gábor Csárdi,https://pak.r-lib.org/,TRUE,https://github.com/r-lib/pak,773,132,1552621212
PakPC2017,Provides data sets and functions for exploration of Pakistan Population Census 2017 (<http://www.pbscensus.gov.pk/>).,2018-02-16,Muhammad Yaseen,https://github.com/MYaseen208/PakPC2017,TRUE,https://github.com/myaseen208/pakpc2017,9143,5,1525670135
PakPMICS2014Ch,"Provides data set and functions for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Child questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).",2017-09-07,Muhammad Yaseen,https://github.com/MYaseen208/PakPMICS2014Ch,TRUE,https://github.com/myaseen208/pakpmics2014ch,2867,1,1525707095
PakPMICS2014HH,"Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Household questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).",2017-09-07,Muhammad Yaseen,https://github.com/MYaseen208/PakPMICS2014HH,TRUE,https://github.com/myaseen208/pakpmics2014hh,2829,0,1525679970
PakPMICS2014HL,"Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Household Listing questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).",2017-09-07,Muhammad Yaseen,https://github.com/MYaseen208/PakPMICS2014HL,TRUE,https://github.com/myaseen208/pakpmics2014hl,2855,0,1525680063
PakPMICS2014Wm,"Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Women (age 15-49 years) questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).",2017-09-07,Muhammad Yaseen,https://github.com/MYaseen208/PakPMICS2014Wm,TRUE,https://github.com/myaseen208/pakpmics2014wm,2823,0,1525680182
palasso,"Implements sparse regression with paired covariates (Rauschenberger et al. 2019). For the optional shrinkage, install ashr (<https://github.com/stephens999/ashr>) and CorShrink (<https://github.com/kkdey/CorShrink>) from GitHub (see README).",2019-03-08,Armin Rauschenberger,https://github.com/rauschenberger/palasso,TRUE,https://github.com/rauschenberger/palasso,3489,0,1553933625
paleobioDB,"Includes 19 functions to wrap each endpoint of
    the PaleobioDB API, plus 8 functions to visualize and process the fossil
    data. The API documentation for the Paleobiology Database can be found in
    <http://paleobiodb.org/data1.1/>.",2019-02-26,Sara Varela,https://github.com/ropensci/paleobioDB,TRUE,https://github.com/ropensci/paleobiodb,14706,28,1551184303
paleotree,"Provides tools for transforming, a posteriori time-scaling, and
    modifying phylogenies containing extinct (i.e. fossil) lineages. In particular,
    most users are interested in the functions timePaleoPhy(), bin_timePaleoPhy(),
    cal3TimePaleoPhy() and bin_cal3TimePaleoPhy(), which date cladograms of
    fossil taxa using stratigraphic data. This package also contains a large number
    of likelihood functions for estimating sampling and diversification rates from
    different types of data available from the fossil record (e.g. range data,
    occurrence data, etc). paleotree users can also simulate diversification and
    sampling in the fossil record using the function simFossilRecord(), which is a
    detailed simulator for branching birth-death-sampling processes composed of
    discrete taxonomic units arranged in ancestor-descendant relationships. Users
    can use simFossilRecord() to simulate diversification in incompletely sampled
    fossil records, under various models of morphological differentiation (i.e.
    the various patterns by which morphotaxa originate from one another), and
    with time-dependent, longevity-dependent and/or diversity-dependent rates of
    diversification, extinction and sampling. Additional functions allow users to
    translate simulated ancestor-descendant data from simFossilRecord() into standard
    time-scaled phylogenies or unscaled cladograms that reflect the relationships
    among taxon units.",2018-10-02,David W. Bapst,https://github.com/dwbapst/paleotree,TRUE,https://github.com/dwbapst/paleotree,38555,10,1550262966
paletteer,"The choices of color palettes in R can be quite overwhelming with 
    palettes spread over many packages with many different API's. This packages
    aims to collect all color palettes across the R ecosystem under the same
    package with a streamlined API.",2019-02-13,See AUTHORS file.,https://github.com/EmilHvitfeldt/paletteer,TRUE,https://github.com/emilhvitfeldt/paletteer,9929,216,1554076216
palettesForR,"A set of palettes imported from 'Gimp' distributed 
  under GPL3 (<https://www.gimp.org/about/COPYING>), and 'Inkscape' 
  distributed under GPL2 (<https://inkscape.org/about/license/>).",2019-01-18,Francois Rebaudo,https://github.com/frareb/palettesForR,TRUE,https://github.com/frareb/palettesforr,667,1,1547794008
palm,"Functions to fit point process models using the Palm likelihood. First proposed by Tanaka, Ogata, and Stoyan (2008) <DOI:10.1002/bimj.200610339>, maximisation of the Palm likelihood can provide computationally efficient parameter estimation for point process models in situations where the full likelihood is intractable. This package is chiefly focused on Neyman-Scott point processes, but can also fit the void processes proposed by Jones-Todd et al. (in press) <DOI:10.1002/sim.8046>. The development of this package was motivated by the analysis of capture-recapture surveys on which individuals cannot be identified---the data from which can conceptually be seen as a clustered point process (Stevenson, Borchers, and Fewster, in press <DOI:10.1111/biom.12983>). As such, some of the functions in this package are specifically for the estimation of cetacean density from two-camera aerial surveys.",2018-12-08,Ben Stevenson <ben.stevenson@auckland.ac.nz>,https://github.com/b-steve/palm,TRUE,https://github.com/b-steve/palm,5798,1,1545514713
pals,"A comprehensive collection of color palettes, colormaps, and tools to evaluate them.",2018-01-22,Kevin Wright,https://github.com/kwstat/pals,TRUE,https://github.com/kwstat/pals,18215,38,1536273019
pammtools,"The Piece-wise exponential (Additive Mixed) Model
    (PAMM; Bender and Scheipl (2018) <doi: 10.1177/1471082X17748083>) is a
    powerful model class for survival analysis, based on Generalized Additive
    (Mixed) Models (GA(M)Ms). It offers intuitive specification and robust
    estimation of complex survival models with stratified baseline hazards,
    random effects, time-varying effects, time-dependent covariates and
    cumulative effects (Bender et. al. (2018) <doi:10.1093/biostatistics/kxy003>.
    pammtools provides tidy workflow for survival analysis with PAMMs,
    including data transformation and other pre- and post-processing
    functions as well as visualization.",2019-03-14,Andreas Bender  (<https://orcid.org/0000-0001-5628-8611>),https://github.com/adibender/pammtools,TRUE,https://github.com/adibender/pammtools,1539,9,1553968475
pander,"Contains some functions catching all messages, 'stdout' and other
    useful information while evaluating R code and other helpers to return user
    specified text elements (like: header, paragraph, table, image, lists etc.)
    in 'pandoc' markdown or several type of R objects similarly automatically
    transformed to markdown format. Also capable of exporting/converting (the
    resulting) complex 'pandoc' documents to e.g. HTML, 'PDF', 'docx' or 'odt'. This
    latter reporting feature is supported in brew syntax or with a custom reference
    class with a smarty caching 'backend'.",2018-11-06,Gergely Daróczi  (<https://orcid.org/0000-0003-3149-8537>),http://rapporter.github.io/pander,TRUE,https://github.com/rapporter/pander,662967,234,1548141080
pandocfilters,"The document converter 'pandoc' <http://pandoc.org/> is widely used
    in the R community. One feature of 'pandoc' is that it can produce and consume
    JSON-formatted abstract syntax trees (AST). This allows to transform a given
    source document into JSON-formatted AST, alter it by so called filters and pass
    the altered JSON-formatted AST back to 'pandoc'. This package provides functions
    which allow to write such filters in native R code. 
    Although this package is inspired by the Python package 'pandocfilters' 
    <https://github.com/jgm/pandocfilters/>, it provides additional convenience functions which make it simple to use the 'pandocfilters' package as a 
    report generator. Since 'pandocfilters' inherits most of it's functionality
    from 'pandoc' it can create documents in many formats 
    (for more information see <http://pandoc.org/>) but is also bound to the same
    limitations as 'pandoc'.",2016-04-27,Florian Schwendinger,"http://pandoc.org/, https://github.com/jgm/pandocfilters/",TRUE,https://github.com/jgm/pandocfilters,14920,275,1550594959
pangaear,"Tools to interact with the 'Pangaea' Database
    (<https://www.pangaea.de>), including functions for searching for data,
    fetching 'datasets' by 'dataset' 'ID', and working with the 'Pangaea'
    'OAI-PMH' service.",2018-01-03,Scott Chamberlain,https://github.com/ropensci/pangaear,TRUE,https://github.com/ropensci/pangaear,8475,9,1533231491
papayar,"Users pass images and objects of class 'nifti' from the 'oro.nifti'
    package to a Papaya, an interactive lightweight JavaScript viewer.
    Although many packages can view individual slices or projections of
    image and matrix data, this package allows for quick and easy
    interactive browsing of images.  The viewer is based off of the
    Mango software, which is a lightweight medical image viewer.",2016-09-28,John Muschelli,https://github.com/rii-mango/Papaya/,TRUE,https://github.com/rii-mango/papaya,5979,295,1552170309
papeR,"A toolbox for writing 'knitr', 'Sweave' or other 'LaTeX'- or 'markdown'-based
	     reports and to prettify the output of various estimated models.",2019-01-03,Benjamin Hofner,http://github.com/hofnerb/papeR,TRUE,https://github.com/hofnerb/paper,27470,15,1546519699
parallelDist,"A fast parallelized alternative to R's native 'dist' function to
    calculate distance matrices for continuous, binary, and multi-dimensional
    input matrices, which supports a broad variety of 41 predefined distance
    functions from the 'stats', 'proxy' and 'dtw' R packages, as well as user-
    defined functions written in C++. For ease of use, the 'parDist' function
    extends the signature of the 'dist' function and uses the same parameter
    naming conventions as distance methods of existing R packages. The package
    is mainly implemented in C++ and leverages the 'RcppParallel' package to
    parallelize the distance computations with the help of the 'TinyThread'
    library. Furthermore, the 'Armadillo' linear algebra library is used for
    optimized matrix operations during distance calculations. The curiously
    recurring template pattern (CRTP) technique is applied to avoid virtual
    functions, which improves the Dynamic Time Warping calculations while
    the implementation stays flexible enough to support different DTW step
    patterns and normalization methods.",2018-12-12,Alexander Eckert,"https://github.com/alexeckert/parallelDist,
https://www.alexandereckert.com/R",TRUE,https://github.com/alexeckert/paralleldist,14555,20,1550438594
ParallelLogger,"Support for parallel computation with progress bar, and option to stop or proceed on errors. Also provides logging to console and disk, 
  and the logging persists in the parallel threads. Additional functions support function call automation with delayed execution (e.g. for executing functions in
  parallel).",2019-01-21,Martijn Schuemie,"https://ohdsi.github.io/ParallelLogger,
https://github.com/OHDSI/ParallelLogger",TRUE,https://github.com/ohdsi/parallellogger,3769,2,1548042901
parallelMap,"Unified parallelization framework for multiple back-end,
  designed for internal package and interactive usage.
    The main operation is a parallel ""map"" over lists.
    Supports local, multicore, mpi and BatchJobs mode.
    Allows ""tagging"" of the parallel operation
    with a level name that can be later selected by the user to
    switch on parallel execution for exactly this operation.",2015-06-10,Bernd Bischl <bernd_bischl@gmx.net>,https://github.com/berndbischl/parallelMap,TRUE,https://github.com/berndbischl/parallelmap,178270,51,1534231226
ParamHelpers,"Functions for parameter descriptions and operations in black-box
    optimization, tuning and machine learning. Parameters can be described
    (type, constraints, defaults, etc.), combined to parameter sets and can in
    general be programmed on. A useful OptPath object (archive) to log function
    evaluations is also provided.",2019-01-18,Jakob Richter,https://github.com/berndbischl/ParamHelpers,TRUE,https://github.com/berndbischl/paramhelpers,196107,24,1548076046
ParBayesianOptimization,"Fast, flexible framework for implementing Bayesian optimization of model 
	hyperparameters according to the methods described in Snoek et al. <arXiv:1206.2944>.
	The package allows the user to run scoring function in parallel, save intermediary 
	results, and tweak other aspects of the process to fully utilize the computing resources
	available to the user.",2019-03-10,Samuel Wilson,https://github.com/AnotherSamWilson/ParBayesianOptimization,TRUE,https://github.com/anothersamwilson/parbayesianoptimization,1081,14,1552608174
parlitools,"Provides various tools for analysing UK political data, 
    including creating political cartograms and retrieving data.",2019-03-22,Evan Odell  (<https://orcid.org/0000-0003-1845-808X>),"https://docs.evanodell.com/parlitools,
https://github.com/EvanOdell/parlitools/",TRUE,https://github.com/evanodell/parlitools,6132,15,1553776083
parmsurvfit,"Executes simple parametric models for right-censored 
    survival data.  Functionality emulates capabilities in 'Minitab', including
    fitting right-censored data, assessing fit, plotting survival functions,
    and summary statistics and probabilities.",2018-12-07,Ashley Jacobson,https://github.com/apjacobson/parmsurvfit,TRUE,https://github.com/apjacobson/parmsurvfit,1383,0,1544155922
parsetools,"Tools and utilities for dealing with parse data. 
    Parse data represents the parse tree as data with location and type
    information.  This package provides functions for navigating the  
    parse tree as a data frame.",2019-01-04,Andrew Redd,https://github.com/RDocTaskForce/parsetools,TRUE,https://github.com/rdoctaskforce/parsetools,777,9,1546476072
parsnip,"A common interface is provided to allow users to specify a model without having to remember the different argument names across different functions or computational engines (e.g. 'R', 'Spark', 'Stan', etc). ",2019-03-22,Max Kuhn,https://tidymodels.github.io/parsnip,TRUE,https://github.com/tidymodels/parsnip,7072,186,1554406523
particles,"Simulating particle movement in 2D space has many application. The
    'particles' package implements a particle simulator based on the ideas 
    behind the 'd3-force' 'JavaScript' library. 'particles' implements all 
    forces defined in 'd3-force' as well as others such as vector fields, traps, 
    and attractors.",2019-01-14,Thomas Lin Pedersen,https://github.com/thomasp85/particles,TRUE,https://github.com/thomasp85/particles,2880,82,1547456193
partitionComparison,"Provides several measures ((dis)similarity, distance/metric,
    correlation, entropy) for comparing two partitions of the same set of
    objects. The different measures can be assigned to three different
    classes: Pair comparison (containing the famous Jaccard and Rand
    indices), set based, and information theory based.
    Many of the implemented measures can be found in
    Albatineh AN, Niewiadomska-Bugaj M and Mihalko D (2006)
    <doi:10.1007/s00357-006-0017-z> and
    Meila M (2007) <doi:10.1016/j.jmva.2006.11.013>.
    Partitions are represented by vectors of class labels which allow a
    straightforward integration with existing clustering algorithms
    (e.g. kmeans()). The package is mostly based on the S4 object system.",2019-03-07,Fabian Ball,https://github.com/KIT-IISM-EM/partitionComparison,TRUE,https://github.com/kit-iism-em/partitioncomparison,4280,0,1551956318
partools,"Miscellaneous utilities for parallelizing large
   computations.  Alternative to MapReduce.
   File splitting and distributed operations such as sort and aggregate.
   ""Software Alchemy"" method for parallelizing most statistical methods,
   presented in N. Matloff, Parallel Computation for Data Science,
   Chapman and Hall, 2015.  Includes a debugging aid.",2017-04-10,Norm Matloff <normmatloff@gmail.com>,https://github.com/matloff/partools,TRUE,https://github.com/matloff/partools,11173,35,1531850815
patentsview,"Provides functions to simplify the 'PatentsView' API
    (<http://www.patentsview.org/api/doc.html>) query language,
    send GET and POST requests to the API's seven endpoints, and parse the data
    that comes back.",2019-01-28,Christopher Baker,https://ropensci.github.io/patentsview/index.html,TRUE,https://github.com/ropensci/patentsview,6148,10,1549297256
pathfindR,"Pathway enrichment analysis enables researchers to uncover mechanisms 
    underlying the phenotype. pathfindR is a tool for pathway enrichment analysis 
    utilizing active subnetworks. It identifies active subnetworks in a 
    protein-protein interaction network using user-provided a list of genes. 
    It performs pathway enrichment analyses on the identified subnetworks. 
    pathfindR also offers functionalities to cluster enriched pathways and identify 
    representative pathways and to score the pathways per sample. The method is
    described in detail in Ulgen E, Ozisik O, Sezerman OU. 2018. pathfindR: An R
    Package for Pathway Enrichment Analysis Utilizing Active Subnetworks. bioRxiv. 
    <doi:10.1101/272450>.",2018-11-20,Ege Ulgen,https://github.com/egeulgen/pathfindR,TRUE,https://github.com/egeulgen/pathfindr,5247,28,1553590233
patternize,"Quantification of variation in organismal color patterns as
    obtained from image data. Patternize defines homology between pattern positions
    across images either through fixed landmarks or image registration. Pattern
    identification is performed by categorizing the distribution of colors using RGB
    thresholds or image segmentation.",2018-11-23,Steven Van Belleghem,https://github.com/StevenVB12/patternize,TRUE,https://github.com/stevenvb12/patternize,4937,7,1554222655
PAutilities,"A collection of utilities that are useful for a broad range of
    tasks that are common in physical activity research, including the
    following: creation of Bland-Altman plots, formatted descriptive
    statistics, metabolic calculations (e.g. basal metabolic rate predictions)
    and conversions, demographic calculations (age and age-for-body-mass-index
    percentile), bout analysis of moderate-to-vigorous intensity physical
    activity, and analysis of bout detection algorithm performance.",2019-03-06,Paul R. Hibbing,https://github.com/paulhibbing/PAutilities,TRUE,https://github.com/paulhibbing/pautilities,284,0,1551769612
pavo,"A cohesive framework for parsing, analyzing and organizing color
    from spectral data.",2019-03-06,Rafael Maia  (<https://orcid.org/0000-0002-7563-9795>),"http://rafaelmaia.net/pavo/, https://github.com/rmaia/pavo/",TRUE,https://github.com/rmaia/pavo,34370,11,1553603607
pbapply,"A lightweight package that adds
  progress bar to vectorized R functions
  ('*apply'). The implementation can easily be added
  to functions where showing the progress is
  useful (e.g. bootstrap). The type and style of the
  progress bar (with percentages or remaining time)
  can be set through options.
  Supports several parallel processing backends.",2019-02-05,Peter Solymos,https://github.com/psolymos/pbapply,TRUE,https://github.com/psolymos/pbapply,535512,52,1549400770
pbdMPI,"An efficient interface to MPI by utilizing S4
        classes and methods with a focus on Single Program/Multiple Data
        ('SPMD')
        parallel programming style, which is intended for batch parallel
        execution.",2018-08-07,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdmpi,43212,2,1554516768
pbdRPC,"A very light implementation yet secure for remote procedure calls
        with unified interface via ssh (OpenSSH) or plink/plink.exe (PuTTY).",2018-05-05,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdrpc,5913,4,1535503083
pbdSLAP,"Utilizing scalable linear algebra packages mainly
        including 'BLACS', 'PBLAS', and 'ScaLAPACK' in double precision via
        'pbdMPI' based on 'ScaLAPACK' version 2.0.2.",2018-04-05,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdslap,28002,0,1554516559
pbdZMQ,"'ZeroMQ' is a well-known library for high-performance
    asynchronous messaging in scalable, distributed applications.  This
    package provides high level R wrapper functions to easily utilize
    'ZeroMQ'. We mainly focus on interactive client/server programming
    frameworks. For convenience, a minimal 'ZeroMQ' library (4.2.2)
    is shipped with 'pbdZMQ', which can be used if no system installation
    of 'ZeroMQ' is available.  A few wrapper functions compatible with
    'rzmq' are also provided.",2018-05-05,Wei-Chen Chen,http://r-pbd.org/,TRUE,https://github.com/snoweye/pbdzmq,219223,12,1552623733
pbmcapply,"A light-weight package helps you track and visualize
  the progress of parallel version of vectorized R functions (mc*apply).
  Parallelization (mc.core > 1) works only on *nix (Linux, Unix such as macOS) system due to
  the lack of fork() functionality, which is essential for mc*apply, on Windows.",2019-04-01,Kevin Kuang (aut),https://github.com/kvnkuang/pbmcapply,TRUE,https://github.com/kvnkuang/pbmcapply,45707,19,1554144765
PBSadmb,"A collection of software provides R support for 'ADMB'
             (Automatic Differentiation Model Builder) and a 'GUI'
             interface facilitates the conversion of 'ADMB' template
             code to 'C code' followed by compilation to a binary executable.
             Stand-alone functions can also be run by users
             not interested in clicking a 'GUI'.",2019-03-19,Rowan Haigh,"https://github.com/pbs-software/pbs-admb,
https://github.com/pbs-software/pbs-modelling",TRUE,https://github.com/pbs-software/pbs-admb,14172,0,1553265911
PBSddesolve,"Routines for solving systems of delay differential equations by
   interfacing numerical routines written by Simon N. Wood , with contributions
   by Benjamin J. Cairns. These numerical routines first appeared in Simon
   Wood's 'solv95' program. This package includes a vignette and a complete
   user's guide. 'PBSddesolve' originally appeared on CRAN under the name
   'ddesolve'. That version is no longer supported. The current name emphasizes
   a close association with other PBS packages, particularly 'PBSmodelling'.",2019-03-12,Rowan Haigh,https://github.com/pbs-software/pbs-ddesolve,TRUE,https://github.com/pbs-software/pbs-ddesolve,19365,0,1552422863
PBSmapping,"This software has evolved from fisheries research conducted at the
   Pacific Biological Station (PBS) in 'Nanaimo', British Columbia, Canada. It
   extends the R language to include two-dimensional plotting features similar
   to those commonly available in a Geographic Information System (GIS).
   Embedded C code speeds algorithms from computational geometry, such as
   finding polygons that contain specified point events or converting between
   longitude-latitude and Universal Transverse Mercator (UTM) coordinates.
   Additionally, we include 'C++' code developed by Angus Johnson for the
   'Clipper' library, data for a global shoreline, and other data sets in the
   public domain. Under the user's R library directory '.libPaths()',
   specifically in './PBSmapping/doc', a complete user's guide is offered and
   should be consulted to use package functions effectively.",2019-03-15,Rowan Haigh,"https://github.com/pbs-software/pbs-mapping,
https://github.com/pbs-software/pbs-mapx,
http://www.angusj.com/delphi/clipper.php",TRUE,https://github.com/pbs-software/pbs-mapping,188847,5,1552685636
PBSmodelling,"Provides software to facilitate the design, testing, and operation
   of computer models. It focuses particularly on tools that make it easy to
   construct and edit a customized graphical user interface ('GUI'). Although our
   simplified 'GUI' language depends heavily on the R interface to the 'Tcl/Tk'
   package, a user does not need to know 'Tcl/Tk'. Examples illustrate models
   built with other R packages, including 'PBSmapping', 'PBSddesolve', and 'BRugs'. 
   A complete user's guide 'PBSmodelling-UG.pdf' shows how to use this package
   effectively.",2019-03-14,Rowan Haigh,https://github.com/pbs-software/pbs-modelling,TRUE,https://github.com/pbs-software/pbs-modelling,63017,0,1552589307
pbv,"
    Computes probabilities of the bivariate normal distribution
    in a vectorized R function (Drezner & Wesolowsky, 1990, 
    <doi:10.1080/00949659008811236>).",2018-11-06,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/pbv,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/pbv,1169,0,1544021009
PCADSC,"A suite of non-parametric, visual tools for assessing differences in data structures
    for two datasets that contain different observations of the same variables. These tools are all 
    based on Principal Component Analysis (PCA) and thus effectively address differences in the structures
    of the covariance matrices of the two datasets. The PCASDC tools consist of easy-to-use, 
    intuitive plots that each focus on different aspects of the PCA decompositions. The cumulative eigenvalue
    (CE) plot describes differences in the variance components (eigenvalues) of the deconstructed covariance matrices. The
    angle plot presents the information loss when moving from the PCA decomposition of one dataset to the 
    PCA decomposition of the other. The chroma plot describes the loading patterns of the two datasets, thereby
    presenting the relative weighting and importance of the variables from the original dataset. ",2017-04-19,Anne H. Petersen,https://github.com/annepetersen1/PCADSC,TRUE,https://github.com/annepetersen1/pcadsc,3549,0,1548925852
pccc,"An implementation of the pediatric complex chronic conditions (CCC)
    classification system using R and C++.",2018-07-02,Seth Russell,https://github.com/CUD2V/pccc,TRUE,https://github.com/cud2v/pccc,3117,1,1530556853
pcev,"Principal component of explained variance (PCEV) is a statistical
    tool for the analysis of a multivariate response vector. It is a dimension-
    reduction technique, similar to Principal component analysis (PCA), that seeks
    to maximize the proportion of variance (in the response vector) being explained
    by a set of covariates.",2018-02-03,Maxime Turgeon,http://github.com/GreenwoodLab/pcev,TRUE,https://github.com/greenwoodlab/pcev,7269,3,1544979068
pcIRT,"Estimates the multidimensional polytomous Rasch model
    (Rasch, 1961) and the Continuous Rating Scale model (Mueller, 1987).",2018-04-30,Christine Hohensinn,https://github.com/christinehohensinn/pcIRT,TRUE,https://github.com/christinehohensinn/pcirt,16124,2,1525034208
PCMBase,"Phylogenetic comparative methods represent models of continuous trait 
  data associated with the tips of a phylogenetic tree. Examples of such models 
  are Gaussian continuous time branching stochastic processes such as Brownian 
  motion (BM) and Ornstein-Uhlenbeck (OU) processes, which regard the data at the 
  tips of the tree as an observed (final) state of a Markov process starting from 
  an initial state at the root and evolving along the branches of the tree. The 
  PCMBase R package provides a general framework for manipulating such models. 
  This framework consists of an application programming interface for specifying 
  data and model parameters, and efficient algorithms for simulating trait evolution 
  under a model and calculating the likelihood of model parameters for an assumed
  model and trait data. The package implements a growing collection of models, 
  which currently includes BM, OU, BM/OU with jumps, two-speed OU as well as mixed 
  Gaussian models, in which different types of the above models can be associated 
  with different branches of the tree. The PCMBase package is limited to 
  trait-simulation and likelihood calculation of (mixed) Gaussian phylogenetic 
  models. The PCMFit package provides functionality for ML and Bayesian fit of 
  these models to tree and trait data. The package web-site 
  <https://venelin.github.io/PCMBase/>
  provides access to the documentation and other resources. ",2019-03-15,Venelin Mitov,"https://venelin.github.io/PCMBase/,
https://github.com/venelin/PCMBase",TRUE,https://github.com/venelin/pcmbase,1268,0,1554126405
pcr,"Calculates the amplification efficiency and curves from real-time 
  quantitative PCR (Polymerase Chain Reaction) data. Estimates the relative 
  expression from PCR data using the double delta CT and the standard curve 
  methods Livak & Schmittgen (2001) <doi:10.1006/meth.2001.1262>. Tests for 
  statistical significance using two-group tests and linear regression 
  Yuan et al. (2006) <doi: 10.1186/1471-2105-7-85>.",2018-07-24,Mahmoud Ahmed,https://github.com/MahShaaban/pcr,TRUE,https://github.com/mahshaaban/pcr,7079,5,1554372849
PCRedux,"Extracts features from amplification curve data of quantitative Polymerase Chain Reactions (qPCR) (Pabinger, Stephan, Stefan Roediger, Albert Kriegner, Klemens Vierlinger, and Andreas Weinhauusel (2014) <doi:10.1016/j.bdq.2014.08.002>) for machine learning purposes. Helper functions prepare the amplification curve data for processing as functional data (e.g., Hausdorff distance) or enable the plotting of amplification curve classes (negative, ambiguous, positive). The hookreg() and hookregNL() functions can be used to predict amplification curves with an hook effect-like curvature. The pcrfit_single() function can be used to extract features from an amplification curve.",2018-10-28,Stefan Roediger  (<https://orcid.org/0000-0002-1441-6512>),https://CRAN.R-project.org/package=PCRedux,TRUE,https://github.com/devsjr/pcredux,3629,3,1540731258
pct,"Functions and example data to teach and
  increase the reproducibility of the methods and code underlying 
  the Propensity to Cycle Tool (PCT), a research project and web application 
  hosted at <https://www.pct.bike/>. 
  For an academic paper on the methods,
  see Lovelace et al (2017) <doi:10.5198/jtlu.2016.862>.",2019-03-29,Robin Lovelace  (<https://orcid.org/0000-0001-5679-6536>),"http://www.pct.bike/, https://itsleeds.github.io/pct/",TRUE,https://github.com/itsleeds/pct,59,5,1554529483
pdfsearch,"Includes functions for keyword search of pdf files. There is
    also a wrapper that includes searching of all files within a single
    directory.",2019-01-09,Brandon LeBeau,https://github.com/lebebr01/pdfsearch,TRUE,https://github.com/lebebr01/pdfsearch,6343,14,1546981016
pdp,"A general framework for constructing partial dependence (i.e., 
  marginal effect) plots from various types machine learning models in R.",2018-08-27,Brandon Greenwell  (<https://orcid.org/0000-0002-8120-0084>),"https://bgreenwell.github.io/pdp/index.html,
https://github.com/bgreenwell/pdp",TRUE,https://github.com/bgreenwell/pdp,45269,58,1549551593
pdSpecEst,"An implementation of data analysis tools for samples of symmetric or 
  Hermitian positive definite matrices, such as collections of covariance matrices 
  or spectral density matrices. The tools in this package can be used to perform: (i) 
  intrinsic wavelet transforms for curves (1D) or surfaces (2D) of Hermitian positive 
  definite matrices with applications to dimension reduction, denoising and clustering in the 
  space of Hermitian positive definite matrices; and (ii) exploratory data analysis and inference 
  for samples of positive definite matrices by means of intrinsic data depth functions and 
  rank-based hypothesis tests in the space of Hermitian positive definite matrices.",2018-10-06,Joris Chau,"https://github.com/JorisChau/pdSpecEst,
https://jchau.shinyapps.io/pdSpecEst/",TRUE,https://github.com/jorischau/pdspecest,7048,0,1553460277
pedigreeTools,"Tools to sort, edit and prune pedigrees and to extract the inbreeding coefficients
    and the relationship matrix (includes code for pedigrees from self-pollinated species). 
    The use of pedigree data is central to genetics research within the animal and plant breeding communities to predict 
    breeding values. The relationship matrix between the individuals can be derived from pedigree structure following
    the algorithms described for example in Vazquez et al., 2010 <doi:10.2527/jas.2009-1952>.",2018-12-09,Ana Ines Vazquez,https://github.com/Rpedigree/pedigreeTools/,TRUE,https://github.com/rpedigree/pedigreetools,955,1,1551921756
pedometrics,"Functions to employ many of the tools and techniques used in the 
    field of pedometrics.",2015-12-03,Alessandro Samuel-Rosa,https://github.com/samuel-rosa/pedometrics,TRUE,https://github.com/samuel-rosa/pedometrics,14274,3,1548955088
pedquant,"
    Provides an interface to access public economic and financial data for 
    economic research and quantitative analysis. The data sources including 
    NBS, FRED, Yahoo Finance, 163 Finance, Sina Finance and etc. ",2019-03-15,Shichen Xie,https://github.com/ShichenXie/pedquant,TRUE,https://github.com/shichenxie/pedquant,182,3,1553607543
PeerPerformance,"Provides functions to perform the peer performance
    analysis of funds' returns as described in Ardia and Boudt (2018) <doi:10.1016/j.jbankfin.2017.10.014>.",2018-08-30,David Ardia,https://github.com/ArdiaD/PeerPerformance,TRUE,https://github.com/ardiad/peerperformance,6013,3,1535645419
Peptides,Includes functions to calculate several physicochemical properties and indices for amino-acid sequences as well as to read and plot 'XVG' output files from the 'GROMACS' molecular dynamics package.,2018-06-08,Daniel Osorio,https://github.com/dosorio/Peptides/,TRUE,https://github.com/dosorio/peptides,25445,17,1528491212
PerformanceAnalytics,"Collection of econometric functions for
    performance and risk analysis. This package aims to aid
    practitioners and researchers in utilizing the latest
    research in analysis of non-normal return streams.  In
    general, it is most tested on return (rather than
    price) data on a regular scale, but most functions will
    work with irregular return data as well, and increasing
    numbers of functions will work with P&L or price data
    where possible.",2018-03-02,Brian G. Peterson,https://github.com/braverock/PerformanceAnalytics,TRUE,https://github.com/braverock/performanceanalytics,612680,59,1551380191
peRiodiCS,"
    Functions for generating variants of curves:
    restricted cubic spline, periodic restricted cubic spline,
    periodic cubic spline. Periodic splines can be used to model data
    that has periodic nature / seasonality.",2018-07-05,Crt Ahlin,NA,TRUE,https://github.com/crtahlin/periodics,1661,0,1531339046
periscope,"An enterprise-targeted scalable and UI-standardized 'shiny' framework 
    including a variety of developer convenience functions with the goal of both 
    streamlining robust application development while assisting with creating a 
    consistent user experience regardless of application or developer.",2019-03-06,Constance Brett,"https://github.com/cb4ds/periscope.git, http://canvasxpress.org",TRUE,https://github.com/cb4ds/periscope,315,2,1551977105
permDep,"Implementations of permutation approach to hypothesis testing for quasi-independence of truncation time and failure time. The implemented approaches are powerful against non-monotone alternatives and thereby offer protection against erroneous assumptions of quasi-independence. The proposed tests use either a conditional or an unconditional method to evaluate the permutation p-value. The conditional method was first developed in Tsai (1980) <doi:10.2307/2336059> and Efron and Petrosian (1992) <doi:10.1086/171931>. The unconditional method provides a valid approximation to the conditional method, yet computationally simpler and does not hold fixed the size of each risk sets. Users also have an option to carry out the proposed permutation tests in a parallel computing fashion.",2018-07-05,Sy Han (Steven) Chiou,http://github.com/stc04003/permDep,TRUE,https://github.com/stc04003/permdep,3711,0,1534362355
permute,"A set of restricted permutation designs for freely exchangeable, line transects (time series), and spatial grid designs plus permutation of blocks (groups of samples) is provided. 'permute' also allows split-plot designs, in which the whole-plots or split-plots or both can be freely-exchangeable or one of the restricted designs. The 'permute' package is modelled after the permutation schemes of 'Canoco 3.1' (and later) by Cajo ter Braak.",2019-03-12,Gavin L. Simpson,https://github.com/gavinsimpson/permute,TRUE,https://github.com/gavinsimpson/permute,925401,10,1552244182
permutes,"Helps you determine the analysis window to use when analyzing densely-sampled
    time-series data, such as EEG data, using permutation testing (Maris & Oostenveld 2007)
    <doi:10.1016/j.jneumeth.2007.03.024>. These permutation tests can help identify the timepoints
    where significance of an effects begins and ends, and the results can be plotted in various
    types of heatmap for reporting.",2018-05-18,Cesko Voeten,NA,TRUE,https://github.com/cvoeten/permutes,1858,2,1526727386
personalized,"Provides functions for fitting and validation of models for subgroup
    identification and personalized medicine / precision medicine under the general subgroup
    identification framework of Chen et al. (2017) <doi:10.1111/biom.12676>.
    This package is intended for use for both randomized controlled trials and
    observational studies.",2019-02-07,Jared Huling  (<https://orcid.org/0000-0003-0670-4845>),"https://jaredhuling.github.io/personalized/,
https://arxiv.org/abs/1809.07905",TRUE,https://github.com/jaredhuling/personalized,7933,6,1549583318
petrinetR,"Functions for the construction of Petri Nets. Petri Nets can be replayed by firing enabled transitions.
     Silent transitions will be hidden by the execution handler. Also includes functionalities for the visualization of Petri Nets and
     export of Petri Nets to PNML (Petri Net Markup Language) files.",2019-03-08,Gert Janssenswillen,https://www.bupar.net,TRUE,https://github.com/gertjanssenswillen/petrinetr,8234,1,1552040581
petro.One,"Application that retrieves papers metadata from the OnePetro website.
    Thousands of papers on oil and gas live in OnePetro. By retrieving metadata 
    from the search queries, a summary of papers that match the
    query words, can be retrieved for further analysis and text mining. There 
    are some statistics and data mining provided such as word cloud plots, keywords 
    frequency, conversion to corpus document, and removal of common usage words.
    OnePetro link: <https://www.onepetro.org/>.",2019-01-13,Alfonso R. Reyes,https://github.com/f0nzie/petro.One,TRUE,https://github.com/f0nzie/petro.one,2979,2,1547361059
PGRdup,"Provides functions to aid the identification of probable/possible
    duplicates in Plant Genetic Resources (PGR) collections using
    'passport databases' comprising of information records of each constituent
    sample. These include methods for cleaning the data, creation of a
    searchable Key Word in Context (KWIC) index of keywords associated with
    sample records and the identification of nearly identical records with
    similar information by fuzzy, phonetic and semantic matching of keywords.",2018-01-13,J. Aravind  (0000-0002-4791-442X),"https://cran.r-project.org/package=PGRdup,
https://github.com/aravind-j/PGRdup,
https://doi.org/10.5281/zenodo.841963,
https://aravind-j.github.io/PGRdup/,
https://www.rdocumentation.org/packages/PGRdup",TRUE,https://github.com/aravind-j/pgrdup,11495,1,1534355913
pgsc,"Computes the generalized synthetic control estimator described in
    Powell (2017) <doi:10.7249/WR1142>.  Provides both point estimates, and hypothesis testing.",2018-10-28,Philip Barrett,https://github.com/philipbarrett/pgsc,TRUE,https://github.com/philipbarrett/pgsc,1093,1,1548436190
phangorn,"Package contains methods for estimation of phylogenetic trees and
    networks using Maximum Likelihood, Maximum Parsimony, distance methods and
    Hadamard conjugation. Allows to compare trees, models selection and offers
    visualizations for trees and split networks. ",2019-03-23,Klaus Schliep  (<https://orcid.org/0000-0003-2941-0161>),https://github.com/KlausVigo/phangorn,TRUE,https://github.com/klausvigo/phangorn,261049,78,1553987147
phaseR,"Performs a qualitative analysis
   of one and two dimensional autonomous ODE systems, using phase
   plane methods. Programs are available to identify and classify
   equilibrium points, plot the direction field, and plot trajectories
   for multiple initial conditions. In the one dimensional case, a 
   program is also available to plot the phase portrait. Whilst in the
   two dimensional case, programs are additionally available to plot 
   nullclines and stable/unstable manifolds of saddle points. Many 
   example systems are provided for the user.",2018-08-20,Michael J. Grayling,https://github.com/mjg211/phaseR,TRUE,https://github.com/mjg211/phaser,19848,2,1536005449
PHEindicatormethods,"Functions to calculate commonly used public health statistics and 
    their confidence intervals using methods approved for use in the production  
    of Public Health England indicators such as those presented via Fingertips 
    (<http://fingertips.phe.org.uk/>). It provides functions for the generation 
    of proportions, crude rates, means, directly standardised rates, indirectly 
    standardised rates and standardised mortality ratios. Statistical methods 
    are referenced in the following publications. 
    Breslow NE, Day NE (1987) <doi:10.1002/sim.4780080614>.
    Dobson et al (1991) <doi:10.1002/sim.4780100317>. 
    Armitage P, Berry G (2002) <doi:10.1002/9780470773666>.
    Wilson EB. (1927) <doi:10.1080/01621459.1927.10502953>.
    Altman DG et al (2000, ISBN: 978-0-727-91375-3).",2018-07-30,Anderson Georgina,NA,TRUE,https://github.com/publichealthengland/pheindicatormethods,1959,3,1553191237
phenocamapi,A bundle to facilitate working with PhenoCam timeseries and data.   The user would be able to obtain phenological time-series and site metadata from the PhenoCam network <https://phenocam.sr.unh.edu/webcam/>.,2019-03-19,Bijan Seyednasrollah,https://github.com/bnasr/phenocamapi/,TRUE,https://github.com/bnasr/phenocamapi,1307,1,1552969097
phenoCDM,"Using the Bayesian state-space approach, we developed a continuous development model to quantify dynamic incremental changes in the response variable. While the model was originally developed for daily changes in forest green-up, the model can be used to predict any similar process. The CDM can capture both timing and rate of nonlinear processes. Unlike statics methods, which aggregate variations into a single metric, our dynamic model tracks the changing impacts over time. The CDM accommodates nonlinear responses to variation in predictors, which changes throughout development. ",2018-05-02,Bijan Seyednasrollah,NA,TRUE,https://github.com/bnasr/phenocdm,2517,0,1541436983
phenofit,"
    The merits of 'TIMESAT' and 'phenopix' are adopted. Besides, a simple and 
    growing season dividing method and a practical snow elimination method 
    based on Whittaker were proposed. 7 curve fitting methods and 4 phenology 
    extraction methods were provided. Parameters boundary are considered for 
    every curve fitting methods according to their ecological meaning. 
    And 'optimx' is used to select best optimization method for different 
    curve fitting methods.",2019-02-18,Dongdong Kong,https://github.com/kongdd/phenofit,TRUE,https://github.com/kongdd/phenofit,360,8,1552447669
PhenotypeSimulator,"Simulation is a critical part of method development and assessment
    in quantitative genetics. 'PhenotypeSimulator' allows for the flexible 
    simulation of phenotypes under different models, including genetic variant 
    and  infinitesimal genetic effects (reflecting population structure) as well 
    as non-genetic covariate effects, observational noise and additional 
    correlation effects. The different phenotype components are combined into a 
    final phenotype while controlling for the proportion of variance explained 
    by each of the components. For each effect component, the number of 
    variables, their distribution and the design of their effect across traits 
    can be customised. For the simulation of the genetic effects, external 
    genotype data from a number of standard software ('plink', 'hapgen2'/
    'impute2', 'genome', 'bimbam', simple text files) can be imported. The final 
    simulated phenotypes and its components can be automatically saved into .rds 
    or .csv files. In addition, they can be saved in formats compatible with 
    commonly used genetic association software ('gemma', 'bimbam', 'plink', 
    'snptest', 'LiMMBo'). ",2018-10-25,Hannah Meyer  (<https://orcid.org/0000-0003-4564-0899>),https://github.com/HannahVMeyer/PhenotypeSimulator,TRUE,https://github.com/hannahvmeyer/phenotypesimulator,6548,9,1553605789
philentropy,"Computes 46 optimized distance and similarity measures for comparing probability functions (Drost (2018) <doi:10.21105/joss.00765>). These comparisons between probability functions have their foundations in a broad range of scientific disciplines from mathematics to ecology. The aim of this package is to provide a core framework for clustering, classification, statistical inference, goodness-of-fit, non-parametric statistics, information theory, and machine learning tasks that are based on comparing univariate or multivariate probability functions.",2019-02-13,Hajk-Georg Drost  (<https://orcid.org/0000-0002-1567-306X>),https://github.com/HajkD/philentropy,TRUE,https://github.com/hajkd/philentropy,14285,34,1550063345
phmm,"Fits proportional hazards model incorporating random effects using
    an EM algorithm using Markov Chain Monte Carlo at E-step. Vaida and Xu (2000)
    <DOI:10.1002/1097-0258(20001230)19:24%3C3309::AID-SIM825%3E3.0.CO;2-9>.",2019-03-08,Michael Donohue,https://github.com/mcdonohue/phmm,TRUE,https://github.com/mcdonohue/phmm,13878,0,1552409977
phonics,"Provides a collection of phonetic algorithms including
    Soundex, Metaphone, NYSIIS, Caverphone, and others.",2019-03-01,James P. Howard,"https://jameshoward.us/software/phonics/,
https://github.com/howardjp/phonics",TRUE,https://github.com/howardjp/phonics,12503,16,1551467936
phonR,"Tools for phoneticians and phonologists, including functions for normalization and plotting of vowels.",2016-08-25,Daniel R. McCloy,http://drammock.github.io/phonR/,TRUE,https://github.com/drammock/phonr,16799,14,1543976134
phyclust,"Phylogenetic clustering (phyloclustering) is an evolutionary
        Continuous Time Markov Chain model-based approach to identify
        population structure from molecular data without assuming
        linkage equilibrium. The package phyclust (Chen 2011) provides a
        convenient implementation of phyloclustering for DNA and SNP data,
        capable of clustering individuals into subpopulations and identifying
        molecular sequences representative of those subpopulations. It is
        designed in C for performance, interfaced with R for visualization,
        and incorporates other popular open source programs including
        ms (Hudson 2002) <doi:10.1093/bioinformatics/18.2.337>,
        seq-gen (Rambaut and Grassly 1997)
        <doi:10.1093/bioinformatics/13.3.235>,
        Hap-Clustering (Tzeng 2005) <doi:10.1002/gepi.20063> and
        PAML baseml (Yang 1997, 2007) <doi:10.1093/bioinformatics/13.5.555>,
        <doi:10.1093/molbev/msm088>,
        for simulating data, additional analyses, and searching the best tree.
        See the phyclust website for more information, documentations and
        examples.",2019-03-27,Wei-Chen Chen,http://snoweye.github.io/phyclust/,TRUE,https://github.com/snoweye/phyclust,42310,4,1553475125
phylin,"The spatial interpolation of genetic distances between
	     samples is based on a modified kriging method that
	     accepts a genetic distance matrix and generates a map of
	     probability of lineage presence. This package also offers
	     tools to generate a map of  potential contact zones
	     between groups with user-defined thresholds in the tree
	     to account for old and recent divergence. Additionally,
	     it has functions for IDW interpolation using genetic data
	     and midpoints.",2019-03-13,Pedro Tarroso,"https://www.r-project.org, https://github.com/ptarroso/phylin",TRUE,https://github.com/ptarroso/phylin,11917,0,1552412219
phylobase,"Provides a base S4 class for comparative methods, incorporating
    one or more trees and trait data.",2019-02-02,R Hackathon et al. (alphabetically: Ben Bolker,https://github.com/fmichonneau/phylobase,TRUE,https://github.com/fmichonneau/phylobase,94060,8,1549121901
phylocomr,"Interface to 'Phylocom' (<http://phylodiversity.net/phylocom/>),
    a library for analysis of 'phylogenetic' community structure and
    character evolution. Includes low level methods for interacting with
    the three executables, as well as higher level interfaces for methods
    like 'aot', 'ecovolve', 'bladj', 'phylomatic', and more.",2018-11-29,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/phylocomr,TRUE,https://github.com/ropensci/phylocomr,2734,14,1543517009
PhylogeneticEM,"
    Implementation of the automatic shift detection method for
    Brownian Motion (BM) or Ornstein–Uhlenbeck (OU) models of trait evolution on
    phylogenies. Some tools to handle equivalent shifts configurations are also
    available. See Bastide et al. (2017) <doi:10.1111/rssb.12206> and
    Bastide et al. (2018) <doi:10.1093/sysbio/syy005>.",2018-09-11,Paul Bastide,https://github.com/pbastide/PhylogeneticEM,TRUE,https://github.com/pbastide/phylogeneticem,5095,6,1536651107
phylogram,"Contains functions for developing phylogenetic trees as
    deeply-nested lists (""dendrogram"" objects).
    Enables bi-directional conversion between dendrogram and
    ""phylo"" objects
    (see Paradis et al (2004) <doi:10.1093/bioinformatics/btg412>),
    and features several tools for command-line tree
    manipulation and import/export via Newick parenthetic text.",2018-06-25,Shaun Wilkinson  (<https://orcid.org/0000-0002-7332-7931>),http://github.com/ropensci/phylogram,TRUE,https://github.com/ropensci/phylogram,8026,8,1529989572
phylopath,"A comprehensive and easy to use R implementation of confirmatory
    phylogenetic path analysis as described by Von Hardenberg and Gonzalez-Voyer
    (2012) <doi:10.1111/j.1558-5646.2012.01790.x>.",2019-01-02,Wouter van der Bijl,http://Ax3man.github.io/phylopath/,TRUE,https://github.com/ax3man/phylopath,7637,4,1553640135
phyloseqGraphTest,"Provides functions for graph-based multiple-sample
    testing and visualization of microbiome data, in particular data
    stored in 'phyloseq' objects. The tests are based on those
    described in Friedman and Rafsky (1979)
    <http://www.jstor.org/stable/2958919>, and the tests are described
    in more detail in Callahan et al. (2016)
    <doi:10.12688/f1000research.8986.1>.",2018-06-27,Julia Fukuyama,https://github.com/jfukuyama/phyloseqGraphTest,TRUE,https://github.com/jfukuyama/phyloseqgraphtest,4501,2,1527264927
phylotools,"A collection of tools for building RAxML supermatrix using
             PHYLIP or aligned FASTA files. These functions will be
             useful for building large phylogenies using multiple markers.",2017-12-10,Jinlong Zhang,https://github.com/helixcn/phylotools,TRUE,https://github.com/helixcn/phylotools,25966,2,1534930607
physiology,"A variety of formulae are provided for estimation
    of physiologic characteristics of infants, children, and adults.
    Calculations include: body surface area, ideal weight, airway
    dead-space, the alveolar gas equation, and GFR.  Each formula is
    referenced to the original publication. Future functions will cover
    more material with a focus on anaesthesia, critical care and
    peri-operative medicine.",2018-11-28,Jack O. Wasey,https://jackwasey.github.io/physiology/,TRUE,https://github.com/jackwasey/physiology,9465,5,1543661658
phytools,"A wide range of functions for phylogenetic analysis. Functionality is concentrated in phylogenetic comparative biology, but also includes a diverse array of methods for visualizing, manipulating, reading or writing, and even inferring phylogenetic trees and data. Included among the functions in phylogenetic comparative biology are various for ancestral state reconstruction, model-fitting, simulation of phylogenies and data, and multivariate analysis. There are a broad range of plotting methods for phylogenies and comparative data which include, but are not restricted to, methods for mapping trait evolution on trees, for projecting trees into phenotypic space or a geographic map, and for visualizing correlated speciation between trees. Finally, there are a number of functions for reading, writing, analyzing, inferring, simulating, and manipulating phylogenetic trees and comparative data not covered by other packages. For instance, there are functions for randomly or non-randomly attaching species or clades to a phylogeny, for estimating supertrees or consensus phylogenies from a set, for simulating trees and phylogenetic data under a range of models, and for a wide variety of other manipulations and analyses that phylogenetic biologists might find useful in their research.",2018-09-28,Liam J. Revell,http://github.com/liamrevell/phytools,TRUE,https://github.com/liamrevell/phytools,164677,55,1553264196
piggyback,"Because larger (> 50 MB) data files cannot easily be committed to git,
  a different approach is required to manage data associated with an analysis in a 
  GitHub repository.  This package provides a simple work-around by allowing larger
  (up to 2 GB) data files to piggyback on a repository as assets attached to individual
  GitHub releases.  These files are not handled by git in any way, but instead are
  uploaded, downloaded, or edited directly by calls through the GitHub API. These
  data files can be versioned manually by creating different releases.  This approach
  works equally well with public or private repositories.  Data can be uploaded
  and downloaded programmatically from scripts. No authentication is required to
  download data from public repositories.",2019-02-07,Carl Boettiger,https://github.com/ropensci/piggyback,TRUE,https://github.com/ropensci/piggyback,2219,92,1549557901
pillar,"Provides a 'pillar' generic designed for formatting columns
   of data using the full range of colours provided by modern terminals.",2018-12-15,Kirill Müller,https://github.com/r-lib/pillar,TRUE,https://github.com/r-lib/pillar,7813435,77,1547905718
pinbasic,"Utilities for fast and stable estimation of the probability of 
 informed trading (PIN) in the model introduced by Easley et al. (2002) 
 <DOI:10.1111/1540-6261.00493> are implemented. Since the basic model developed 
 by Easley et al. (1996) <DOI:10.1111/j.1540-6261.1996.tb04074.x> is nested in the 
 former due to equating the intensity of uninformed buys and sells, functions 
 can also be applied to this simpler model structure, if needed. 
 State-of-the-art factorization of the model likelihood function as well as 
 most recent algorithms for generating initial values for optimization routines are implemented. 
 In total, two likelihood factorizations and three methodologies for 
 starting values are included. 
 Furthermore, functions for simulating datasets of daily aggregated buys and sells, 
 calculating confidence intervals for the probability of informed trading and posterior probabilities 
 of trading days' conditions are available. ",2018-11-18,Andreas Recktenwald,https://github.com/anre005/pinbasic/,TRUE,https://github.com/anre005/pinbasic,9864,7,1542538712
pingers,"To assist you with troubleshooting internet connection issues and
    assist in isolating packet loss on your network. It does this by allowing you to 
    retrieve the top trace route destinations your internet provider uses, and recursively 
    ping each server in series while capturing the results and writing them to a log file. 
    Each iteration it queries the destinations again, before shuffling the sequence of 
    destinations to ensure the analysis is unbiased and consistent across each trace route.",2018-10-26,Jesse Vent,https://github.com/JesseVent/pingers,TRUE,https://github.com/jessevent/pingers,1108,4,1540987501
pinp,"A 'PNAS'-alike style for 'rmarkdown', derived from the
 'Proceedings of the National Academy of Sciences of the United States
 of America' ('PNAS', see <https://www.pnas.org>) 'LaTeX' style, and
 adapted for use with 'markdown' and 'pandoc'.",2019-01-11,Dirk Eddelbuettel and James Balamuta,http://dirk.eddelbuettel.com/code/pinp.html,TRUE,https://github.com/eddelbuettel/pinp,64759,90,1547303557
pinyin,"Convert Chinese characters into Pinyin (the official romanization system for Standard Chinese in mainland China, Malaysia, Singapore, and Taiwan. See <https://en.wikipedia.org/wiki/Pinyin> for details), Sijiao (four or five numerical digits per character. See <https://en.wikipedia.org/wiki/Four-Corner_Method>.), Wubi (an input method with five strokes. See <https://en.wikipedia.org/wiki/Wubi_method>) or user-defined codes.",2018-12-17,Peng Zhao,https://github.com/pzhaonet/pinyin,TRUE,https://github.com/pzhaonet/pinyin,3466,18,1545037610
pivmet,"Collection of pivotal algorithms 
             for: relabelling the MCMC chains in order to undo the label 
             switching problem in Bayesian mixture models,
             as proposed in Egidi, Pappadà, Pauli and Torelli (2018a)<doi:10.1007/s11222-017-9774-2>;
             initializing the centers of the classical k-means algorithm 
             in order to obtain a better clustering solution. For further details see
             Egidi, Pappadà, Pauli and Torelli (2018b)<ISBN:9788891910233>.",2019-02-26,Leonardo Egidi,https://github.com/leoegidi/pivmet,TRUE,https://github.com/leoegidi/pivmet,865,1,1552063711
pivotaltrackR,"'Pivotal Tracker' <https://www.pivotaltracker.com> is a project
    management software-as-a-service that provides a REST API. This package
    provides an R interface to that API, allowing you to query it and work with
    its responses.",2018-01-19,Neal Richardson,"http://enpiar.com/r/pivotaltrackR,
https://github.com/nealrichardson/pivotaltrackR",TRUE,https://github.com/nealrichardson/pivotaltrackr,2537,0,1541607887
pivottabler,"Create regular pivot tables with just a few lines of R.  
    More complex pivot tables can also be created, e.g. pivot tables
    with irregular layouts, multiple calculations and/or derived 
    calculations based on multiple data frames.  Pivot tables are
    constructed using R only and can be written to a range of
    output formats (plain text, 'HTML', 'Latex' and 'Excel'), 
    including with styling/formatting.",2019-03-20,Christopher Bailiss,https://github.com/cbailiss/pivottabler,TRUE,https://github.com/cbailiss/pivottabler,11058,49,1553151422
pixiedust,"The introduction of the 'broom' package has made converting model
    objects into data frames as simple as a single function. While the 'broom'
    package focuses on providing tidy data frames that can be used in advanced
    analysis, it deliberately stops short of providing functionality for reporting
    models in publication-ready tables. 'pixiedust' provides this functionality with
    a programming interface intended to be similar to 'ggplot2's system of layers
    with fine tuned control over each cell of the table. Options for output include
    printing to the console and to the common markdown formats (markdown, HTML, and
    LaTeX). With a little 'pixiedust' (and happy thoughts) tables can really fly.",2019-01-11,Benjamin Nutter,https://github.com/nutterb/pixiedust,TRUE,https://github.com/nutterb/pixiedust,20871,144,1531749270
pkgbuild,"Provides functions used to build R packages. Locates compilers
  needed to build R packages on various platforms and ensures the PATH is
  configured appropriately so R can use them.",2019-03-20,Jim Hester,https://github.com/r-lib/pkgbuild,TRUE,https://github.com/r-lib/pkgbuild,1273170,29,1553526078
pkgcond,"This provides utilities for creating classed error and warning
  conditions based on where the error originated.",2018-12-03,Andrew Redd,https://github.com/RDocTaskForce/pkgcond,TRUE,https://github.com/rdoctaskforce/pkgcond,809,2,1543944464
pkgdown,"Generate an attractive and useful website from a source package.
    'pkgdown' converts your documentation, vignettes, 'README', and more to 
    'HTML' making it easy to share information about your package online.",2018-12-07,Hadley Wickham  (<https://orcid.org/0000-0003-4757-117X>),"https://pkgdown.r-lib.org, https://github.com/r-lib/pkgdown",TRUE,https://github.com/r-lib/pkgdown,87743,403,1553346991
pkggraph,Interactively explore various dependencies of a package(s) (on the Comprehensive R Archive Network Like repositories) and perform analysis using tidy philosophy. Most of the functions return a 'tibble' object (enhancement of 'dataframe') which can be used for further analysis. The package offers functions to produce 'network' and 'igraph' dependency graphs. The 'plot' method produces a static plot based on 'ggnetwork' and 'plotd3' function produces an interactive D3 plot based on 'networkD3'.,2018-11-15,KS Srikanth,https://github.com/talegari/pkggraph,TRUE,https://github.com/talegari/pkggraph,3611,4,1542403493
pkgload,"Simulates the process of installing a package
    and then attaching it. This is a key part of the 'devtools' package as it
    allows you to rapidly iterate while developing a package.",2018-10-29,Jim Hester,https://github.com/r-lib/pkgload,TRUE,https://github.com/r-lib/pkgload,1102750,24,1540840847
pkgmaker,"Provides some low-level utilities to use for package
    development. It currently provides managers for multiple package specific
    options and registries, vignette, unit test and bibtex related utilities.
    It serves as a base package for packages like NMF, RcppOctave, doRNG, and
    as an incubator package for other general purposes utilities, that will
    eventually be packaged separately.
    It is still under heavy development and changes in the interface(s) are
    more than likely to happen.",2018-05-25,Renaud Gaujoux,https://renozao.github.io/pkgmaker,TRUE,https://github.com/renozao/pkgmaker,1364149,4,1527284776
pkgnet,"Tools from the domain of graph theory can be used to quantify the complexity
             and vulnerability to failure of a software package. That is the guiding philosophy
             of this package. 'pkgnet' provides tools to analyze the dependencies between functions
             in an R package and between its imported packages.",2019-04-05,Brian Burns,"https://github.com/UptakeOpenSource/pkgnet,
https://uptakeopensource.github.io/pkgnet/",TRUE,https://github.com/uptakeopensource/pkgnet,5793,42,1554515701
pkgverse,"Build your own universe of packages similar to the 'tidyverse'
    package <https://tidyverse.org/> with this meta-package creator. Create a
    package-verse, or meta package, by supplying a custom name for the
    collection of packages and the vector of desired package names to include–
    and optionally supply a destination directory, an indicator of whether to
    keep the created package directory, and/or a vector of verbs implement via
    the 'usethis' <http://usethis.r-lib.org/> package.",2018-11-14,"Michael Wayne Kearney 
    (<https://orcid.org/0000-0002-0730-4694>)",https://pkgverse.mikewk.com,TRUE,https://github.com/mkearney/pkgverse,1035,95,1541121402
PKNCA,"Compute standard Non-Compartmental Analysis (NCA)
    parameters and summarize them.  In addition to this core work, it
    also provides standardized plotting routines, basic assessments
    for biocomparison or drug interaction, and model-based estimation
    routines for calculating doses to reach specific values of AUC or
    Cmax.",2018-06-13,Bill Denney,https://github.com/billdenney/pknca,TRUE,https://github.com/billdenney/pknca,13544,13,1554154150
PKPDmisc,"A toolbox for data management common to pharmacokinetic and
  pharmacokinetic modeling and simulation, such as resampling,
  area-under-the-curve calculation, data chunking, custom csv
  output, and project scaffolding.",2017-12-17,Devin Pastoor,https://github.com/dpastoor/PKPDmisc,TRUE,https://github.com/dpastoor/pkpdmisc,4364,9,1526394549
pksensi,"Applying the global sensitivity analysis workflow to investigate the parameter uncertainty and sensitivity in pharmacokinetic (PK) models, especially the physiologically-based pharmacokinetic (PBPK) model with multivariate outputs. The package also provide some functions to check the sensitivity measures and its convergence of model parameters.   ",2019-01-29,Nan-Hung Hsieh  (<https://orcid.org/0000-0003-0163-2766>),"https://github.com/nanhung/pksensi,
https://nanhung.rbind.io/pksensi",TRUE,https://github.com/nanhung/pksensi,1361,0,1552860109
plac,"A semi-parametric estimation method for the Cox model
    with left-truncated data using augmented information
    from the marginal of truncation times.",2016-04-30,Fan Wu,https://github.com/942kid/plac,TRUE,https://github.com/942kid/plac,5564,2,1526093424
PlackettLuce,"Functions to prepare rankings data and fit the Plackett-Luce model
    jointly attributed to Plackett (1975) <doi:10.2307/2346567> and Luce
    (1959, ISBN:0486441369). The standard Plackett-Luce model is generalized
    to accommodate ties of any order in the ranking. Partial rankings, in which
    only a subset of items are ranked in each ranking, are also accommodated in
    the implementation. Disconnected/weakly connected networks implied by the
    rankings may be handled by adding pseudo-rankings with a hypothetical item.
    Optionally, a multivariate normal prior may be set on the log-worth
    parameters and ranker reliabilities may be incorporated as proposed by
    Raman and Joachims (2014) <doi:10.1145/2623330.2623654>. Maximum a
    posteriori estimation is used when priors are set. Methods are provided to
    estimate standard errors or quasi-standard errors for inference as well as
    to fit Plackett-Luce trees. See the package website or vignette for further
    details.",2019-04-01,Heather Turner  (<https://orcid.org/0000-0002-1256-3375>),https://hturner.github.io/PlackettLuce/,TRUE,https://github.com/hturner/plackettluce,3406,5,1554112110
plan,Supports the creation of 'burndown' charts and 'gantt' diagrams.,2018-05-30,Dan Kelley <Dan.Kelley@Dal.Ca>,http://github.com/dankelley/plan,TRUE,https://github.com/dankelley/plan,15204,14,1527686928
plater,"Tools for interacting with data from experiments done in microtiter
    plates. Easily read in plate-shaped data and convert it to tidy format, 
    combine plate-shaped data with tidy data, and view tidy data in plate shape.  ",2017-06-26,Sean Hughes,https://github.com/ropenscilabs/plater,TRUE,https://github.com/ropenscilabs/plater,5443,13,1533334798
platetools,"Collection of functions for working with multi-well microtitre
    plates, mainly 96, 384 and 1536 well plates.",2018-06-25,Scott Warchal,https://github.com/swarchal/platetools,TRUE,https://github.com/swarchal/platetools,6794,20,1554362827
plinkQC,"Genotyping arrays enable the direct measurement of an individuals
    genotype at thousands of markers. 'plinkQC' facilitates genotype quality
    control for genetic association studies as described by Anderson and
    colleagues (2010) <doi:10.1038/nprot.2010.116>. It makes 'PLINK' basic
    statistics (e.g. missing genotyping rates per individual, allele frequencies
    per genetic marker) and relationship functions accessible from 'R' and
    generates a per-individual and per-marker quality control report.
    Individuals and markers that fail the quality control can subsequently be
    removed to generate a new, clean dataset. Removal of individuals based on
    relationship status is optimised to retain as many individuals as possible
    in the study.",2019-03-01,Hannah Meyer  (<https://orcid.org/0000-0003-4564-0899>),https://github.com/HannahVMeyer/plinkQC,TRUE,https://github.com/hannahvmeyer/plinkqc,1612,6,1551477737
plot3logit,"An implementation of the ternary plot for interpreting regression
    coefficients of trinomial regression models, as proposed in Santi, Dickson
    and Espa (2018) <doi:10.1080/00031305.2018.1442368>. Ternary plots can be
    drawn using either 'ggtern' package (based on 'ggplot2') or 'Ternary'
    package (based on standard graphics).",2019-02-20,Flavio Santi  (<https://orcid.org/0000-0002-2014-1981>),https://www.flaviosanti.it/software/plot3logit,TRUE,https://github.com/f-santi/plot3logit,799,0,1550677104
plotlyGeoAssets,Includes 'JavaScript' files that allow 'plotly' maps to render without an internet connection.,2019-01-08,Carson Sievert  (<https://orcid.org/0000-0002-4958-2844>),https://github.com/cpsievert/plotlyGeoAssets,TRUE,https://github.com/cpsievert/plotlygeoassets,26673,2,1546963464
plotMElm,"Plot marginal effects for interactions estimated
    from linear models.",2018-05-28,Christopher Gandrud,NA,TRUE,https://github.com/christophergandrud/plotmelm,5806,6,1527519130
plotROC,"Most ROC curve plots obscure the cutoff values and inhibit
    interpretation and comparison of multiple curves. This attempts to address
    those shortcomings by providing plotting and interactive tools. Functions
    are provided to generate an interactive ROC curve plot for web use, and
    print versions. A Shiny application implementing the functions is also
    included.",2018-06-23,Michael C. Sachs,http://sachsmc.github.io/plotROC,TRUE,https://github.com/sachsmc/plotroc,45489,56,1538589658
pls,"Multivariate regression methods
	Partial Least Squares Regression (PLSR), Principal Component
	Regression (PCR) and Canonical Powered Partial Least Squares (CPPLS).",2019-03-23,Bjørn-Helge Mevik,"http://mevik.net/work/software/pls.html,
https://github.com/bhmevik/pls",TRUE,https://github.com/bhmevik/pls,1028749,8,1553361742
plsdof,"The plsdof package provides Degrees of Freedom estimates
        for Partial Least Squares (PLS) Regression. Model selection for
        PLS is based on various information criteria (aic, bic, gmdl)
        or on cross-validation. Estimates for the mean and covariance
        of the PLS regression coefficients are available. They allow
        the construction of approximate confidence intervals and the
        application of test procedures. Further, cross-validation
        procedures for Ridge Regression and Principal Components
        Regression are available.",2019-01-31,Nicole Kraemer,https://github.com/fbertran/plsdof,TRUE,https://github.com/fbertran/plsdof,16770,1,1549746694
plsRbeta,"Provides Partial least squares Regression for (weighted) beta regression models (Bertrand 2013,  <http://journal-sfds.fr/article/view/215>) and k-fold cross-validation of such models using various criteria. It allows for missing data in the explanatory variables. Bootstrap confidence intervals constructions are also available.",2019-02-01,Frederic Bertrand  (<https://orcid.org/0000-0002-0837-8281>),"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/plsRbeta",TRUE,https://github.com/fbertran/plsrbeta,13616,1,1551185757
plsRcox,"Provides Partial least squares Regression and various regular, sparse or kernel, techniques for fitting Cox models in high dimensional settings <doi:10.1093/bioinformatics/btu660>, Bastien, P., Bertrand, F., Meyer N., Maumy-Bertrand, M. (2015), Deviance residuals-based sparse PLS and sparse kernel PLS regression for censored data, Bioinformatics, 31(3):397-404. Cross validation criteria were studied in <arXiv:1810.02962>, Bertrand, F., Bastien, Ph. and Maumy-Bertrand, M. (2018), Cross validating extensions of kernel, sparse or regular partial least squares regression models to censored data.",2019-02-03,Frederic Bertrand  (<https://orcid.org/0000-0002-0837-8281>),"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/plsRcox",TRUE,https://github.com/fbertran/plsrcox,18813,1,1549746674
plsRglm,Provides (weighted) Partial least squares Regression for generalized linear models and repeated k-fold cross-validation of such models using various criteria. It allows for missing data in the explanatory variables. Bootstrap confidence intervals constructions are also available.,2019-02-02,Frederic Bertrand  (<https://orcid.org/0000-0002-0837-8281>),"http://www-irma.u-strasbg.fr/~fbertran/,
https://github.com/fbertran/plsRglm",TRUE,https://github.com/fbertran/plsrglm,29309,3,1549746798
plyr,"A set of tools that solves a common set of problems: you
    need to break a big problem down into manageable pieces, operate on each
    piece and then put all the pieces back together.  For example, you might
    want to fit a model to each spatial location or time point in your study,
    summarise data by panels or collapse high-dimensional arrays to simpler
    summary statistics. The development of 'plyr' has been generously supported
    by 'Becton Dickinson'.",2016-06-08,Hadley Wickham,"http://had.co.nz/plyr, https://github.com/hadley/plyr",TRUE,https://github.com/hadley/plyr,14208549,474,1544024669
pm4py,"Interface to 'PM4py' <http://pm4py.org>, a process mining library 
    in 'Python'. This package uses the 'reticulate' package to act as a bridge 
    between 'PM4Py' and the 'R' package 'bupaR'. It provides several process 
    discovery algorithms, evaluation measures, and alignments. ",2019-03-10,Felix Mannhardt,https://github.com/fmannhardt/pm4py,TRUE,https://github.com/fmannhardt/pm4py,371,5,1552236559
pmc,"Monte Carlo based model choice for applied phylogenetics of
    continuous traits. Method described in  Carl Boettiger, Graham Coop,
    Peter Ralph (2012) Is your phylogeny informative? Measuring
    the power of comparative methods, Evolution 66 (7)
    2240-51. doi:10.1111/j.1558-5646.2011.01574.x.",2018-05-17,Carl Boettiger,https://github.com/cboettig/pmc,TRUE,https://github.com/cboettig/pmc,14825,2,1526585777
pmd,"Paired mass distance (PMD) analysis proposed in Yu, Olkowicz and Pawliszyn (2018) <doi:10.1016/j.aca.2018.10.062> for gas/liquid chromatography–mass spectrometry (GC/LC-MS) based non-targeted analysis. PMD analysis including GlobalStd algorithm and structure/reaction directed analysis. GlobalStd algorithm could found independent peaks in m/z-retention time profiles based on retention time hierarchical cluster analysis and frequency analysis of paired mass distances within retention time groups. Structure directed analysis could be used to find potential relationship among those independent peaks in different retention time groups based on frequency of paired mass distances. A GUI for PMD analysis is also included as a 'shiny' application.",2018-12-02,Miao YU  (<https://orcid.org/0000-0002-2804-6014>),https://yufree.github.io/pmd,TRUE,https://github.com/yufree/pmd,1013,2,1552449277
pmhtutorial,"Routines for state estimate in a linear
    Gaussian state space model and a simple stochastic volatility model using
    particle filtering. Parameter inference is also carried out in these models
    using the particle Metropolis-Hastings algorithm that includes the particle
    filter to provided an unbiased estimator of the likelihood. This package is
    a collection of minimal working examples of these algorithms and is only
    meant for educational use and as a start for learning to them on your own.",2019-03-22,Johan Dahlin,https://github.com/compops/pmh-tutorial-rpkg,TRUE,https://github.com/compops/pmh-tutorial-rpkg,6748,2,1554100971
pmpp,"Dynamic panel modelling framework based on an empirical-Bayes approach.
             Contains tools for computing point forecasts and bootstrapping prediction intervals.
             Reference: Liu et al. (2016) <doi:10.2139/ssrn.2889000>.",2018-10-12,Michal Oleszak,https://github.com/veneficusnl/pmpp,TRUE,https://github.com/veneficusnl/pmpp,1212,1,1538418665
pointblank,"Validate data in data frames,
    'tibble' objects, in 'CSV' and 'TSV' files,
    and in database tables ('PostgreSQL' and 'MySQL').
    Validation pipelines can be made using
    easily-readable, consecutive validation steps
    and such pipelines allow for switching of the
    data table context. Upon execution of the
    validation plan, several reporting options are
    available. User-defined thresholds for failure
    rates allow for the determination of appropriate
    reporting actions.",2018-05-02,Richard Iannone  (<https://orcid.org/0000-0003-3925-190X>),https://github.com/rich-iannone/pointblank,TRUE,https://github.com/rich-iannone/pointblank,3292,121,1536557728
pointdexter,"Labels longitudinal and latitudinal coordinates located inside a polygon.
    For a singular polygon, the label is a logical vector of TRUE and FALSE values. For multiple polygons, the label is a character vector based on the names of each polygon. 
    The package is designed to work with both sf and SpatialPolygonsDataFrame objects.",2019-03-17,Cristian E. Nuno,"https://cenuno.github.io/pointdexter/,
https://github.com/cenuno/pointdexter",TRUE,https://github.com/cenuno/pointdexter,869,2,1552803998
politicaldata,"Provides useful functions for obtaining commonly-used data
    in political analysis and political science, including from sources
    such as the Comparative Agendas Project <https://www.comparativeagendas.net>,
    which provides data on politics and policy from 20+ countries, the
    MIT Election and Data Science Lab <https://www.electionlab.mit.edu>,
    and FiveThirtyEight <https://www.FiveThirtyEight.com>.",2019-03-13,G. Elliott Morris,NA,TRUE,https://github.com/elliottmorris/politicaldata,603,69,1553111021
pollen,"Supports analysis of aerobiological data. 
    Available features include determination of pollen season limits, 
    replacement of outliers (Kasprzyk and Walanus (2014) <doi:10.1007/s10453-014-9332-8>),
    and calculation of growing degree days.",2018-10-07,Jakub Nowosad  (<https://orcid.org/0000-0002-1057-3721>),https://github.com/Nowosad/pollen,TRUE,https://github.com/nowosad/pollen,6798,2,1550344550
polmineR,"Library for corpus analysis using the Corpus Workbench as an
    efficient back end for indexing and querying large corpora. The package offers
    functionality to flexibly create partitions and to carry out basic statistical
    operations (count, co-occurrences etc.). The original full text of documents
    can be reconstructed and inspected at any time. Beyond that, the package is
    intended to serve as an interface to packages implementing advanced statistical
    procedures. Respective data structures (document term matrices, term co-
    occurrence matrices etc.) can be created based on the indexed corpora.",2019-01-08,Andreas Blaette  (<https://orcid.org/0000-0001-8970-8010>),https://www.github.com/PolMine/polmineR,TRUE,https://github.com/polmine/polminer,10378,23,1547912917
polyclip,"R port of Angus Johnson's open source library Clipper. Performs polygon clipping operations (intersection, union, set minus, set difference) for polygonal regions of arbitrary complexity, including holes. Computes offset polygons (spatial buffer zones, morphological dilations, Minkowski dilations) for polygonal regions and polygonal lines. Computes Minkowski Sum of general polygons. There is a function for removing self-intersections from polygon data.",2019-03-14,Angus Johnson (C++ original,"http://www.angusj.com/delphi/clipper.php,
https://sourceforge.net/projects/polyclipping,
https://github.com/baddstats/polyclip",TRUE,https://github.com/baddstats/polyclip,486277,7,1552469074
polyCub,"Numerical integration of continuously differentiable
    functions f(x,y) over simple closed polygonal domains.
    The following cubature methods are implemented:
    product Gauss cubature (Sommariva and Vianello, 2007,
    <doi:10.1007/s10543-007-0131-2>),
    the simple two-dimensional midpoint rule
    (wrapping 'spatstat' functions),
    adaptive cubature for radially symmetric functions via line
    integrate() along the polygon boundary (Meyer and Held, 2014,
    <doi:10.1214/14-AOAS743>, Supplement B),
    and integration of the bivariate Gaussian density based on
    polygon triangulation.
    For simple integration along the axes, the 'cubature' package
    is more appropriate.",2019-02-07,Sebastian Meyer,https://github.com/bastistician/polyCub,TRUE,https://github.com/bastistician/polycub,35859,2,1549534686
polyglot,Use the R console as an interactive learning environment to memorize any two columns dataset.,2018-11-01,Félix Luginbuhl,https://github.com/lgnbhl/polyglot,TRUE,https://github.com/lgnbhl/polyglot,2785,0,1542981651
polylabelr,"A wrapper around the C++ library 
    'polylabel' from 'Mapbox', providing an efficient routine for
    finding the approximate pole of inaccessibility of a polygon, which
    usually serves as an excellent candidate for labeling of a polygon.",2018-11-02,Johan Larsson,https://github.com/jolars/polylabelr,TRUE,https://github.com/jolars/polylabelr,4560,8,1541965062
polyRAD,"Read depth data from genotyping-by-sequencing (GBS) or restriction 
  site-associated DNA sequencing (RAD-seq) are imported and used to make Bayesian
  probability estimates of genotypes in polyploids or diploids.  The genotype 
  probabilities, or genotypes sampled from those probabilties, can then be exported
  for downstream analysis.  'polyRAD' is described by Clark et al. (2018)
  <doi:10.1101/380899>.",2018-11-19,Lindsay V. Clark  (<https://orcid.org/0000-0002-3881-9252>),https://github.com/lvclark/polyRAD,TRUE,https://github.com/lvclark/polyrad,1872,6,1553538793
polywog,"Routines for flexible functional form estimation via basis
    regression, with model selection via the adaptive LASSO or SCAD to prevent
    overfitting.",2018-04-20,Brenton Kenkel and Curtis S. Signorino,https://github.com/brentonk/polywog-package,TRUE,https://github.com/brentonk/polywog-package,12605,0,1524252645
pomp,"Tools for working with partially observed Markov process (POMP) models (also known as stochastic dynamical systems, hidden Markov models, and nonlinear, non-Gaussian, state-space models).  The package provides facilities for implementing POMP models, simulating them, and fitting them to time series data by a variety of frequentist and Bayesian methods.  It is also a versatile platform for implementation of inference methods for general POMP models.",2018-12-13,Aaron A. King,https://kingaa.github.io/pomp/,TRUE,https://github.com/kingaa/pomp,61959,51,1553539576
pool,"Enables the creation of object pools, which make it less
    computationally expensive to fetch a new object. Currently the
    only supported pooled objects are 'DBI' connections.",2019-01-07,Joe Cheng,https://github.com/rstudio/pool,TRUE,https://github.com/rstudio/pool,44455,137,1546570991
PopED,"Optimal experimental designs for both population and individual
    studies based on nonlinear mixed-effect models. Often this is based on a
    computation of the Fisher Information Matrix. This package was developed
    for pharmacometric problems, and examples and predefined models are available
    for these types of systems. The methods are described in Nyberg et al. 
    (2012) <doi:10.1016/j.cmpb.2012.05.005>, and Foracchia et al. (2004) 
    <doi:10.1016/S0169-2607(03)00073-7>.",2018-09-10,Andrew C. Hooker,http://poped.sourceforge.net,TRUE,https://github.com/andrewhooker/poped,17640,13,1554194853
popEpi,"Enables computation of epidemiological statistics, including those 
    where counts or mortality rates of the reference population are used. 
    Currently supported: excess hazard models, rates, mean survival times, 
    relative survival, and standardized incidence and mortality ratios 
    (SIRs/SMRs), all of which can be easily adjusted for by covariates such as 
    age. Fast splitting and aggregation of 'Lexis' objects (from package 'Epi') 
    and other computations achieved using 'data.table'. ",2019-03-18,Joonas Miettinen,https://github.com/WetRobot/popEpi,TRUE,https://github.com/wetrobot/popepi,31987,1,1553347140
PopGenReport,"Provides beginner friendly framework to analyse population genetic
    data. Based on 'adegenet' objects it uses 'knitr' to create comprehensive reports on spatial genetic data. 
    For detailed information how to use the package refer to the comprehensive
    tutorials or visit <http://www.popgenreport.org/>.",2019-02-04,Bernd Gruber,https://github.com/green-striped-gecko/PopGenReport,TRUE,https://github.com/green-striped-gecko/popgenreport,23841,4,1542590713
popkin,"Provides functions to estimate the kinship matrix of individuals from a large set of biallelic SNPs, and extract inbreeding coefficients and the generalized FST (Wright's fixation index).  Method described in Ochoa and Storey (2016) <doi:10.1101/083923>.",2019-02-14,Alejandro Ochoa,https://github.com/StoreyLab/popkin/,TRUE,https://github.com/storeylab/popkin,3362,10,1550191491
poplite,Provides objects and accompanying methods which facilitates populating and querying SQLite databases.    ,2019-02-18,Daniel Bottomly,https://github.com/dbottomly/poplite,TRUE,https://github.com/dbottomly/poplite,9867,0,1550518261
poppr,"Population genetic analyses for hierarchical analysis of partially
    clonal populations built upon the architecture of the 'adegenet' package.",2019-03-11,Zhian N. Kamvar  (<https://orcid.org/0000-0003-1458-7108>),"https://github.com/grunwaldlab/poppr,
https://grunwaldlab.github.io/poppr,
https://grunwaldlab.github.io/Population_Genetics_in_R/",TRUE,https://github.com/grunwaldlab/poppr,63197,32,1552840401
popprxl,"GenAlEx is a popular Excel macro for genetic analysis and the
    'poppr' R package allows import of GenAlEx formatted CSV data for genetic
    data analysis in R. This package allows for the import of GenAlEx formatted
    Excel files, serving as a small 'poppr' add on for those who have trouble or
    simply do not want to export their data into CSV format. ",2018-05-17,Zhian N. Kamvar  (<https://orcid.org/0000-0003-1458-7108>),https://github.com/zkamvar/popprxl,TRUE,https://github.com/zkamvar/popprxl,8596,1,1526562435
portalr,"Download and generate summaries for the rodent, plant, ant, and 
    weather data from the Portal Project. Portal is a long-term (and ongoing) 
    experimental monitoring site in the Chihuahua desert. The raw data files 
    can be found at <https://github.com/weecology/portaldata>.",2019-02-20,Glenda M. Yenni  (<https://orcid.org/0000-0001-6969-1848>),"https://weecology.github.io/portalr/,
https://github.com/weecology/portalr",TRUE,https://github.com/weecology/portalr,1513,6,1553019600
PortfolioAnalytics,Portfolio optimization and analysis routines and graphics.,2018-05-17,Brian G. Peterson,https://github.com/braverock/PortfolioAnalytics,TRUE,https://github.com/braverock/portfolioanalytics,69296,24,1526598238
postal,"An interface to the United States Postal Service Post Calc and Zone Calc APIs <https://postcalc.usps.com/>, postal
  allows users to find the postage price, delivery day, and other information for packages and envelopes, 
  as well as to find the postal zone for an origin and a destination zip code pair.",2019-02-02,Amanda Dobbyn,https://github.com/aedobbyn/postal/,TRUE,https://github.com/aedobbyn/postal,2049,19,1549128181
postlogic,"Provides adds postfix and infix logic operators for
    if, then, unless, and otherwise.",2018-11-26,Andrew Redd  (<https://orcid.org/000-0002-6149-2438>),https://github.com/RDocTaskForce/postlogic,TRUE,https://github.com/rdoctaskforce/postlogic,1007,0,1546451901
POUMM,"The Phylogenetic Ornstein-Uhlenbeck Mixed Model (POUMM) allows to 
    estimate the phylogenetic heritability of continuous traits, to test 
    hypotheses of neutral evolution versus stabilizing selection, to quantify 
    the strength of stabilizing selection, to estimate measurement error and to
    make predictions about the evolution of a phenotype and phenotypic variation 
    in a population. The package implements combined maximum likelihood and 
    Bayesian inference of the univariate Phylogenetic Ornstein-Uhlenbeck Mixed 
    Model, fast parallel likelihood calculation, maximum likelihood 
    inference of the genotypic values at the tips, functions for summarizing and
    plotting traces and posterior samples, functions for simulation of a univariate 
    continuous trait evolution model along a phylogenetic tree. So far, the 
    package has been used for estimating the heritability of quantitative traits
    in macroevolutionary and epidemiological studies, see e.g. 
    Bertels et al. (2017) <doi:10.1093/molbev/msx246> and 
    Mitov and Stadler (2018) <doi:10.1093/molbev/msx328>. The algorithm for 
    parallel POUMM likelihood calculation has been published in 
    Mitov and Stadler (2019) <doi:10.1111/2041-210X.13136>.",2019-03-27,Venelin Mitov,"https://venelin.github.io/POUMM/index.html,
https://github.com/venelin/POUMM",TRUE,https://github.com/venelin/poumm,4106,0,1553683111
powdR,"Full pattern summation of X-ray powder diffraction data as
  described in Chipera and Bish (2002) <doi:10.1107/S0021889802017405>.
  Derives quantitative estimates of crystalline and amorphous phase
  concentrations in complex mixtures.",2018-11-15,Benjamin Butler,http://github.com/benmbutler/powdR,TRUE,https://github.com/benmbutler/powdr,1552,2,1554390469
Power2Stage,"Contains functions to obtain the operational characteristics of 
    bioequivalence studies with 2-stage designs (TSD) via simulations.",2018-04-03,Detlew Labes,https://github.com/Detlew/Power2Stage,TRUE,https://github.com/detlew/power2stage,16074,0,1554181679
poweRlaw,"An implementation of maximum likelihood estimators for a variety
    of heavy tailed distributions, including both the discrete and continuous
    power law distributions. Additionally, a goodness-of-fit based approach is
    used to estimate the lower cut-off for the scaling region.",2019-01-10,Colin Gillespie,https://github.com/csgillespie/poweRlaw,TRUE,https://github.com/csgillespie/powerlaw,57175,69,1552425783
powerlmm,"Calculate power for the 'time x treatment' effect
    in two- and three-level multilevel longitudinal studies with missing data.
    Both the third-level factor (e.g. therapists, schools, or physicians),
    and the second-level factor (e.g. subjects), can be assigned random slopes.
    Studies with partially nested designs, unequal cluster sizes,
    unequal allocation to treatment arms, and different dropout patterns
    per treatment are supported. For all designs power can be
    calculated both analytically and via simulations. The analytical
    calculations extends the method described in Galbraith et al. (2002)
    <doi:10.1016/S0197-2456(02)00205-2>, to three-level models.
    Additionally, the simulation tools provides flexible ways to investigate
    bias, Type I errors and the consequences of model misspecification.",2018-08-14,Kristoffer Magnusson,https://github.com/rpsychologist/powerlmm,TRUE,https://github.com/rpsychologist/powerlmm,5289,47,1534269779
PowerTOST,"Contains functions to calculate power and sample size for
    various study designs used for bioequivalence studies. 
    See function known.designs() for study designs covered. 
    Moreover the package contains functions for power and sample size 
    based on 'expected' power in case of uncertain (estimated) variability 
    and/or uncertain theta0.
    -----
    Added are functions for the power and sample size for the ratio of 
    two means with normally distributed data on the original scale 
    (based on Fieller's confidence ('fiducial') interval).
    -----
    Contains further functions for power and sample size calculations based on
    non-inferiority t-test. This is not a TOST procedure but eventually useful 
    if the question of 'non-superiority' must be evaluated.
    The power and sample size calculations based on non-inferiority test may 
    also performed via 'expected' power in case of uncertain (estimated) 
    variability and/or uncertain theta0.
    -----
    Contains functions power.scABEL() and sampleN.scABEL() to calculate power 
    and sample size for the BE decision via scaled (widened) BE acceptance 
    limits (EMA recommended) based on simulations.
    Contains also functions scABEL.ad() and sampleN.scABEL.ad() to iteratively
    adjust alpha in order to maintain the overall consumer risk in ABEL studies
    and adapt the sample size for the loss in power.
    Contains further functions power.RSABE() and sampleN.RSABE() to calculate 
    power and sample size for the BE decision via reference scaled ABE criterion 
    according to the FDA procedure based on simulations.
    Contains further functions power.NTIDFDA() and sampleN.NTIDFDA() to calculate 
    power and sample size for the BE decision via the FDA procedure for NTID's 
    based on simulations.
    Contains further functions power.HVNTID() and sampleN.HVNTID() to calculate 
    power and sample size for the BE decision via the FDA procedure for 
    highly variable NTID's (see FDA Dabigatran / rivaroxaban guidances)
    -----
    Contains functions for power analysis of a sample size plan for ABE 
    (pa.ABE()), scaled ABE (pa.scABE()) and scaled ABE for NTID's (pa.NTIDFDA())
    analysing power if deviating from assumptions of the plan.
    -----
    Contains further functions for power calculations / sample size estimation
    for dose proportionality studies using the Power model.",2018-04-12,Detlew Labes,http://github.com/Detlew/PowerTOST,TRUE,https://github.com/detlew/powertost,36432,3,1543244373
ppcSpatial,Spatial Analysis for exploration of Pakistan Population Census 2017 (<http://www.pbscensus.gov.pk/>). It uses data from R package 'PakPC2017'.,2018-03-07,Muhammad Yaseen,https://github.com/MYaseen208/ppcSpatial,TRUE,https://github.com/myaseen208/ppcspatial,2685,0,1525670742
PPforest,Implements projection pursuit forest algorithm for supervised classification.,2018-06-11,Natalia da Silva,https://github.com/natydasilva/PPforest,TRUE,https://github.com/natydasilva/ppforest,2896,12,1530536223
ppgmmga,Projection Pursuit (PP) algorithm for dimension reduction based on Gaussian Mixture Models (GMMs) for density estimation using Genetic Algorithms (GAs) to maximise an approximated negentropy index.,2018-10-15,Alessio Serafini  (<https://orcid.org/0000-0002-8579-5695>),https://github.com/luca-scr/ppgmmga,TRUE,https://github.com/luca-scr/ppgmmga,1268,1,1546878374
ppitables,"The Poverty Probability Index (PPI) is a poverty measurement tool 
    for organizations and businesses with a mission to serve the poor. The PPI 
    is statistically-sound, yet simple to use: the answers to 10 questions about 
    a household’s characteristics and asset ownership are scored to compute the 
    likelihood that the household is living below the poverty line – or above by 
    only a narrow margin. This package contains country-specific lookup data tables
    used as reference to determine the poverty likelihood of a household based
    on their score from the country-specific PPI questionnaire. These lookup 
    tables have been extracted from documentation of the PPI found at 
    <https://www.povertyindex.org> and managed by Innovations for Poverty Action 
    <https://www.poverty-action.org>.",2019-01-02,Ernest Guevarra  (<https://orcid.org/0000-0002-4887-4415>),https://github.com/validmeasures/ppitables,TRUE,https://github.com/validmeasures/ppitables,3163,3,1546796817
prais,"The Prais-Winsten estimator (Prais & Winsten, 1954) takes into account AR(1) serial correlation of the errors in a linear regression model. The procedure recursively estimates the coefficients and the error autocorrelation of the specified model until sufficient convergence of the AR(1) coefficient is attained.",2019-03-10,Franz X. Mohr,https://github.com/franzmohr/prais,TRUE,https://github.com/franzmohr/prais,16052,0,1552216177
praznik,"A collection of feature selection filters performing greedy optimisation of mutual information-based usefulness criteria, inspired by the overview by Brown, Pocock, Zhao and Lujan (2012) <http://www.jmlr.org/papers/v13/brown12a.html>.
 Implements, among other, minimum redundancy maximal relevancy ('mRMR') method by Peng, Long and Ding (2005) <doi:10.1109/TPAMI.2005.159>; joint mutual information ('JMI') method by Yang and Moody (1999) <http://papers.nips.cc/paper/1779-data-visualization-and-feature-selection-new-algorithms-for-nongaussian-data>; double input symmetrical relevance ('DISR') method by Meyer and Bontempi  (2006) <doi:10.1007/11732242_9> as well as joint mutual information maximisation ('JMIM') method by Bennasar, Hicks and Setchi (2015) <doi:10.1016/j.eswa.2015.07.007>.",2018-05-08,Miron B. Kursa  (<https://orcid.org/0000-0001-7672-648X>),https://github.com/mbq/praznik,TRUE,https://github.com/mbq/praznik,4046,7,1525796051
prcbench,A testing workbench for evaluating precision-recall curves under various conditions.,2019-03-05,Takaya Saito,"http://takayasaito.github.io/prcbench/,
https://github.com/takayasaito/prcbench",TRUE,https://github.com/takayasaito/prcbench,7933,5,1551781485
pre,"Derives prediction rule ensembles (PREs). Largely follows the
    procedure for deriving PREs as described in Friedman & Popescu (2008; 
    <DOI:10.1214/07-AOAS148>), with adjustments and improvements. The 
    main function pre() derives prediction rule ensembles consisting of 
    rules and/or linear terms for continuous, binary, count, multinomial, 
    and multivariate continuous responses. Function gpe() derives 
    generalized prediction ensembles, consisting of rules, hinge and linear 
    functions of the predictor variables.",2019-04-01,Marjolein Fokkema,https://github.com/marjoleinF/pre,TRUE,https://github.com/marjoleinf/pre,18720,21,1554119795
precrec,"Accurate calculations and visualization of precision-recall and ROC (Receiver Operator Characteristics)
    curves.",2019-03-05,Takaya Saito,"http://takayasaito.github.io/precrec,
https://github.com/takayasaito/precrec",TRUE,https://github.com/takayasaito/precrec,14244,20,1551707224
predict3d,"Draw 2 dimensional and three dimensional plot for multiple regression models using package 'ggplot2' and 'rgl'.
   Supports linear models (lm), generalized linear models (glm) and local polynomial regression fittings (loess).  ",2019-03-06,Keon-Woong Moon,https://github.com/cardiomoon/predict3d,TRUE,https://github.com/cardiomoon/predict3d,417,2,1554276219
prediction,"A one-function package containing 'prediction()', a type-safe alternative to 'predict()' that always returns a data frame. The package currently supports common model types (e.g., ""lm"", ""glm"") from the 'stats' package, as well as numerous other model classes from other add-on packages. See the README or main package documentation page for a complete listing.",2019-01-31,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/leeper/prediction,TRUE,https://github.com/leeper/prediction,215245,63,1549035488
predtoolsTS,"Makes the time series prediction easier by automatizing this process
  using four main functions: prep(), modl(), pred() and postp(). Features different
  preprocessing methods to homogenize variance and to remove trend and seasonality.
  Also has the potential to bring together different predictive models to make comparatives.
  Features ARIMA and Data Mining Regression models (using caret).",2018-04-29,Alberto Vico Moreno,https://github.com/avm00016/predtoolsTS,TRUE,https://github.com/avm00016/predtoolsts,3489,0,1529438232
preference,"Design and analyze two-stage randomized trials with a continuous
    outcome measure. The package contains functions to compute the required 
    sample size needed to detect a given preference, treatment, and selection 
    effect; alternatively, the package contains functions that can report the 
    study power given a fixed sample size. Finally, analysis functions are 
    provided to test each effect using either summary data (i.e. means, 
    variances) or raw study data.",2018-11-29,Michael Kane,https://github.com/kaneplusplus/preference,TRUE,https://github.com/kaneplusplus/preference,3844,1,1543515428
prepdat,"Prepares data for statistical analysis (e.g., analysis of variance
  ;ANOVA) by enabling the user to easily and quickly merge (using the
  file_merge() function) raw data files into one merged table and then
  aggregate the merged table (using the prep() function) into a finalized
  table while keeping track and summarizing every step of the preparation.
  The finalized table contains several possibilities for dependent measures of
  the dependent variable. Most suitable when measuring variables in an
  interval or ratio scale (e.g., reaction-times) and/or discrete values such
  as accuracy. Main functions included are file_merge() and prep(). The
  file_merge() function vertically merges individual data files (in a long
  format) in which each line is a single observation to one single dataset.
  The prep() function aggregates the single dataset according to any
  combination of grouping variables (i.e., between-subjects and
  within-subjects independent variables, respectively), and returns a data
  frame with a number of dependent measures for further analysis for each cell
  according to the combination of provided grouping variables. Dependent
  measures for each cell include among others means before and after rejecting
  all values according to a flexible standard deviation criteria, number of
  rejected values according to the flexible standard deviation criteria,
  proportions of rejected values according to the flexible standard deviation
  criteria, number of values before rejection, means after rejecting values
  according to procedures described in Van Selst & Jolicoeur (1994; suitable
  when measuring reaction-times), standard deviations, medians, means according
  to any percentile (e.g., 0.05, 0.25, 0.75, 0.95) and harmonic means. The data
  frame prep() returns can also be exported as a txt file to be used for
  statistical analysis in other statistical programs.",2016-09-23,Ayala S. Allon,http://github.com/ayalaallon/prepdat,TRUE,https://github.com/ayalaallon/prepdat,8561,14,1551404525
prereg,Provides a collection of templates to author preregistration documents for scientific studies in PDF format.,2019-01-09,Frederik Aust  (<https://orcid.org/0000-0003-4900-788X>),https://github.com/crsh/prereg,TRUE,https://github.com/crsh/prereg,6340,25,1547051912
prettydoc,"Creating tiny yet beautiful documents and vignettes from R
    Markdown. The package provides the 'html_pretty' output format as an
    alternative to the 'html_document' and 'html_vignette' engines that
    convert R Markdown into HTML pages. Various themes and syntax highlight
    styles are supported.",2018-01-16,Yixuan Qiu,https://github.com/yixuan/prettydoc,TRUE,https://github.com/yixuan/prettydoc,66891,196,1529360087
prettyGraphs,"Simple and crisp publication-quality graphics for the ExPosition family of packages.
  See An ExPosition of the Singular Value Decomposition in R (Beaton et al 2014) <doi:10.1016/j.csda.2013.11.006>.",2018-12-18,Derek Beaton,NA,TRUE,https://github.com/derekbeaton/exposition-family_old,30814,3,1545106817
prettymapr,"Automates the process of creating a scale bar and north arrow in
    any package that uses base graphics to plot in R. Bounding box tools help find
    and manipulate extents. Finally, there is a function to automate the process
    of setting margins, plotting the map, scale bar, and north arrow, and resetting
    graphic parameters upon completion.",2017-09-20,Dewey Dunnington <dewey@fishandwhistle.net>,https://github.com/paleolimbot/prettymapr,TRUE,https://github.com/paleolimbot/prettymapr,39275,16,1534071162
prettyunits,"Pretty, human readable formatting of quantities.
    Time intervals: 1337000 -> 15d 11h 23m 20s.
    Vague time intervals: 2674000 -> about a month ago.
    Bytes: 1337 -> 1.34 kB.",2015-07-13,Gabor Csardi,https://github.com/gaborcsardi/prettyunits,TRUE,https://github.com/gaborcsardi/prettyunits,2757207,45,1553680755
pricesensitivitymeter,"An implementation of the van Westendorp Price
    Sensitivity Meter in R, which is a survey-based approach
	to analyze consumer price preferences and sensitivity
    (van Westendorp 1976, isbn:9789283100386).",2018-10-21,Max Alletsee,https://github.com/alletsee/pricesensitivitymeter,TRUE,https://github.com/alletsee/pricesensitivitymeter,3017,2,1552822579
primefactr,"Use Prime Factorization for simplifying computations,
    for instance for ratios of large factorials.",2018-05-19,Florian Privé,https://github.com/privefl/primefactr,TRUE,https://github.com/privefl/primefactr,4863,0,1526717095
PRIMME,"
    R interface to PRIMME, a C library for computing a few
    eigenvalues and their corresponding eigenvectors of a real symmetric or complex
    Hermitian matrix.  It can also compute singular values and vectors of a square
    or rectangular matrix.  It can find largest, smallest, or interior
    singular/eigenvalues and can use preconditioning to accelerate convergence. ",2018-01-12,Eloy Romero,https://github.com/primme/primme,TRUE,https://github.com/primme/primme,3993,48,1554140854
PRIMsrc,"Performs a unified treatment of Bump Hunting by Patient Rule Induction Method (PRIM) in Survival, Regression and Classification settings (SRC). The current version is a development release that only implements the case of a survival response.",2018-10-04,Jean-Eudes Dazard,"https://github.com/jedazard/PRIMsrc, https://www.primsrc.com",TRUE,https://github.com/jedazard/primsrc,13543,3,1551994748
princurve,Fitting a principal curve to a data matrix in arbitrary dimensions.,2018-10-08,Kurt Hornik (<https://orcid.org/0000-0003-4198-9911>),https://github.com/dynverse/princurve,TRUE,https://github.com/dynverse/princurve,51700,15,1536138081
prioritizr,"Conservation prioritization using integer
    programming techniques. To solve large-scale problems, users
    should install the 'gurobi' optimizer
    (available from <http://www.gurobi.com/>).",2018-06-28,Richard Schuster,"https://prioritizr.net, https://github.com/prioritizr/prioritizr",TRUE,https://github.com/prioritizr/prioritizr,4903,28,1554555624
prioritizrdata,Conservation planning data sets for learning how to use the 'prioritizr' package <https://CRAN.R-project.org/package=prioritizr>.,2018-05-22,Richard Schuster,"https://prioritizr.github.io/prioritizrdata,
https://github.com/prioritizr/prioritizrdata",TRUE,https://github.com/prioritizr/prioritizrdata,3194,1,1546949949
prism,"Allows users to access the Oregon State Prism climate data. Using
    the web service API data can easily downloaded in bulk and loaded into R for
    spatial analysis. Some user friendly visualizations are also provided.",2018-12-10,Hart Edmund,http://github.com/ropensci/prism,TRUE,https://github.com/ropensci/prism,8687,33,1544482983
PRISM.forecast,Implements Penalized Regression with Inferred Seasonality Module (PRISM) to generate forecast estimation of weekly unemployment initial claims using 'Google Trends' data. It includes required data and tools for backtesting the performance in 2007-2016.,2018-07-01,Dingdong Yi,https://github.com/ryanddyi/prism,TRUE,https://github.com/ryanddyi/prism,1642,0,1530514770
PRISMAstatement,"Plot a PRISMA <http://prisma-statement.org/> flow
    chart describing the identification, screening, eligibility and
    inclusion or studies in systematic reviews. PRISMA is an
    evidence-based minimum set of items for reporting in systematic
    reviews and meta-analyses. PRISMA focuses on the reporting of reviews
    evaluating randomized trials, but can also be used as a basis for
    reporting systematic reviews of other types of research, particularly
    evaluations of interventions.",2018-08-08,Jack O. Wasey,https://github.com/jackwasey/PRISMAstatement,TRUE,https://github.com/jackwasey/prismastatement,6357,4,1543143439
probably,"Models can be improved by post-processing class probabilities, by: recalibration, conversion to hard probabilities, assessment of equivocal zones, and other activities. 'probably' contains tools for conducting these operations. ",2019-03-07,Max Kuhn,https://github.com/tidymodels/probably/,TRUE,https://github.com/tidymodels/probably,1106,38,1553273131
pROC,"Tools for visualizing, smoothing and comparing receiver operating characteristic (ROC curves). (Partial) area under the curve (AUC) can be compared with statistical tests based on U-statistics or bootstrap. Confidence intervals can be computed for (p)AUC or ROC curves.",2019-03-12,Xavier Robin  (<https://orcid.org/0000-0002-6813-3200>),http://expasy.org/tools/pROC/,TRUE,https://github.com/xrobin/proc,1074519,56,1554047085
processanimateR,"Token replay animation for process maps created with 
  'processmapR' by using SVG animations ('SMIL') and the 'htmlwidget' package.",2018-11-27,Felix Mannhardt,https://github.com/fmannhardt/processanimateR/,TRUE,https://github.com/fmannhardt/processanimater,3880,17,1553718070
processR,"Perform moderation, mediation, moderated mediation and moderated moderation. 
   Inspired from famous 'PROCESS' macro for 'SPSS' and 'SAS' created by Andrew Hayes. ",2019-03-07,Keon-Woong Moon,https://github.com/cardiomoon/processR,TRUE,https://github.com/cardiomoon/processr,480,3,1554550034
prodigenr,"Create a project directory structure, along with typical files
    for that project.  This allows projects to be quickly and easily created,
    as well as for them to be standardized. Designed specifically with scientists
    in mind (mainly bio-medical researchers, but likely applies to other fields).",2018-05-23,Luke Johnston  (<https://orcid.org/0000-0003-4169-2616>),https://github.com/lwjohnst86/prodigenr,TRUE,https://github.com/lwjohnst86/prodigenr,5562,18,1536570166
profile,"Defines a data structure for profiler data, and methods to read and
    write from the 'Rprof' and 'pprof' file formats.",2018-01-05,Kirill Müller,"https://github.com/r-prof/profile,
https://r-prof.github.io/profile",TRUE,https://github.com/r-prof/profile,2535,6,1527166600
profileModel,"Provides tools that can be used to calculate, evaluate, plot and use for inference the profiles of *arbitrary* inference functions for *arbitrary* 'glm'-like fitted models with linear predictors. More information on the methods that are implemented can be found in Kosmidis (2008) <https://www.r-project.org/doc/Rnews/Rnews_2008-2.pdf>.",2019-04-03,Ioannis Kosmidis  (<https://orcid.org/0000-0003-1556-0302>),https://github.com/ikosmidis/profileModel,TRUE,https://github.com/ikosmidis/profilemodel,349431,0,1554217314
ProFit,Get data / Define model / ??? / Profit! 'ProFit' is a Bayesian galaxy fitting tool that uses a fast 'C++' image generation library and a flexible interface to a large number of likelihood samplers.,2019-04-04,Aaron Robotham  (<https://orcid.org/0000-0003-0429-3579>),https://github.com/ICRAR/ProFit,TRUE,https://github.com/icrar/profit,8035,13,1554370581
profr,"An alternative data structure and visual rendering
    for the profiling information generated by Rprof.",2018-12-05,Hadley Wickham,https://github.com/hadley/profr,TRUE,https://github.com/hadley/profr,42442,30,1544103715
projections,"Provides functions and graphics for projecting daily incidence based on past incidence, and estimates of the serial interval and reproduction number. Projections are based on a branching process using a Poisson-distributed number of new cases per day, similar to the model used for estimating R0 in 'EpiEstim' or in 'earlyR', and described by Nouvellet et al. (2017) <doi:10.1016/j.epidem.2017.02.012>.",2018-08-27,Thibaut Jombart,http://www.repidemicsconsortium.org/projections,TRUE,https://github.com/reconhub/projections,3880,3,1552829100
projector,"Display dense vector representation of texts on a 2D plan to better
  understand embeddings by observing the neighbors of a selected text.
  It also includes an interactive application to change dynamically the pivot text.",2018-02-27,Michaël Benesty,https://github.com/pommedeterresautee/projector,TRUE,https://github.com/pommedeterresautee/projector,2862,14,1551944803
ProjectTemplate,"Provides functions to
    automatically build a directory structure for a new R
    project. Using this structure, 'ProjectTemplate'
    automates data loading, preprocessing, library
    importing and unit testing.",2019-02-26,Aleksandar Blagotic [ctb,http://projecttemplate.net,TRUE,https://github.com/johnmyleswhite/projecttemplate,50699,540,1551207456
projpred,"
    Performs projection predictive feature selection for generalized linear models
    (see, Piironen, Paasiniemi and Vehtari, 2018, <arXiv:1810.02406>).
    The package is compatible with the 'rstanarm' and 'brms' packages, but other 
    reference models can also be used. See the package vignette for more 
    information and examples.",2019-03-12,Juho Piironen,"http://mc-stan.org/projpred, http://discourse.mc-stan.org/",TRUE,https://github.com/stan-dev/projpred,4331,36,1552229598
promises,"Provides fundamental abstractions for doing asynchronous programming
    in R using promises. Asynchronous programming is useful for allowing a single
    R process to orchestrate multiple tasks in the background while also attending
    to something else. Semantics are similar to 'JavaScript' promises, but with a
    syntax that is idiomatic R.",2018-04-13,Joe Cheng,"https://rstudio.github.io/promises,
https://github.com/rstudio/promises",TRUE,https://github.com/rstudio/promises,2762468,133,1543528547
promote,"Deploy, maintain, and invoke predictive models using the 'Alteryx
    Promote' REST API.  'Alteryx Promote' is available at the URL:
    <https://www.alteryx.com/products/alteryx-promote>.",2019-02-06,Paul E. Promote <promotedev@alteryx.com>,https://github.com/alteryx/promote-r-client,TRUE,https://github.com/alteryx/promote-r-client,3581,3,1549405368
PropCIs,"Computes two-sample confidence intervals for single, paired and independent proportions.",2018-02-23,Ralph Scherer,https://github.com/shearer/PropCIs,TRUE,https://github.com/shearer/propcis,32076,3,1535050880
prophet,"Implements a procedure for forecasting time series data based on
    an additive model where non-linear trends are fit with yearly, weekly, and
    daily seasonality, plus holiday effects. It works best with time series
    that have strong seasonal effects and several seasons of historical data.
    Prophet is robust to missing data and shifts in the trend, and typically
    handles outliers well.",2018-12-21,Sean Taylor,https://github.com/facebook/prophet,TRUE,https://github.com/facebook/prophet,148955,8022,1553793341
propr,"The bioinformatic evaluation of gene co-expression often begins with
    correlation-based analyses. However, correlation lacks validity when
    applied to relative data, including count data generated by next-generation
    sequencing. This package implements several metrics for proportionality, including
    phi [Lovell et al (2015) <DOI:10.1371/journal.pcbi.1004075>] and
    rho [Erb and Notredame (2016) <DOI:10.1007/s12064-015-0220-8>]. This package also
    implements several metrics for differential proportionality. Unlike correlation,
    these measures give the same result for both relative and absolute data.",2018-11-19,Thomas Quinn,http://github.com/tpq/propr,TRUE,https://github.com/tpq/propr,16436,22,1553298671
ProPublicaR,"Provides wrapper functions to access the ProPublica's Congress and Campaign Finance APIs.
    The Congress API provides near real-time access to legislative data from the House of 
    Representatives, the Senate and the Library of Congress.
    The Campaign Finance API provides data from United States Federal Election Commission 
    filings and other sources. The API covers summary information for candidates and 
    committees, as well as certain types of itemized data.
    For more information about these APIs go to: <https://www.propublica.org/datastore/apis>.",2019-04-06,Aleksander Dietrichson,NA,TRUE,https://github.com/dietrichson/propublicar,0,0,1554157115
protr,"Comprehensive toolkit for generating various numerical
    features of protein sequences described in Xiao et al. (2015)
    <DOI:10.1093/bioinformatics/btv042>. For full functionality,
    the software 'ncbi-blast+' is needed, see
    <https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download>
    for more information.",2019-02-24,Nan Xiao  (<https://orcid.org/0000-0002-0250-5673>),"https://nanx.me/protr/, https://github.com/road2stat/protr,
http://protr.org",TRUE,https://github.com/road2stat/protr,27531,18,1552898136
protViz,"Helps with quality checks, visualizations 
    and analysis of mass spectrometry data, coming from proteomics 
    experiments. The package is developed, tested and used at the Functional 
    Genomics Center Zurich. We use this package mainly for prototyping, 
    teaching, and having fun with proteomics data. But it can also be 
    used to do data analysis for small scale data sets.",2019-01-04,Christian Panse  (<https://orcid.org/0000-0003-1975-3064>),https://github.com/protViz/protViz/,TRUE,https://github.com/protviz/protviz,20119,3,1551257950
proustr,"Tools for Natural Language Processing in French and texts from Marcel Proust's collection 
  ""A La Recherche Du Temps Perdu"". The novels contained in this collection are 
  ""Du cote de chez Swann "", ""A l'ombre des jeunes filles en fleurs"",""Le Cote de Guermantes"", 
  ""Sodome et Gomorrhe I et II"", ""La Prisonniere"", ""Albertine disparue"", and ""Le Temps retrouve"".",2019-02-05,Colin Fay  (<https://orcid.org/0000-0001-7343-1846>),https://github.com/ColinFay/proustr,TRUE,https://github.com/colinfay/proustr,5162,18,1549372622
proxyC,"
    Computes proximity between rows or columns of large matrices efficiently in C++.
    Functions are optimized for large sparse matrices using the Armadillo and Intel TBB libraries.
    Among several built-in similarity/distance measures, computation of correlation,
    cosine similarity and Euclidean distance is particularly fast.",2018-12-31,Kohei Watanabe,NA,TRUE,https://github.com/koheiw/proxyc,1252,3,1546476539
prozor,"Determine minimal protein set explaining
    peptide spectrum matches. Utility functions for creating fasta amino acid databases with decoys and contaminants.
    Peptide false discovery rate estimation for target decoy search results on psm, precursor, peptide and protein
    level.",2018-07-26,Witold Wolski,https://github.com/protviz/prozor,TRUE,https://github.com/protviz/prozor,7466,3,1540480147
PSCBS,Segmentation of allele-specific DNA copy number data and detection of regions with abnormal copy number within each parental chromosome.  Both tumor-normal paired and tumor-only analyses are supported.,2018-08-12,Henrik Bengtsson,https://github.com/HenrikBengtsson/PSCBS,TRUE,https://github.com/henrikbengtsson/pscbs,72946,5,1534109444
psd,"Produces power spectral density estimates through iterative
    refinement of the optimal number of sine-tapers at each frequency. This
    optimization procedure is based on the method of Riedel and Sidorenko
    (1995), which minimizes the Mean Square Error (sum of variance and bias)
    at each frequency, but modified for computational stability.",2019-03-20,Andrew J. Barbour  (<https://orcid.org/0000-0001-6473-5493>),"https://github.com/abarbour/psd, Barbour and Parker (2014):
https://doi.org/10.1016/j.cageo.2013.09.015, Riedel and
Sidorenko (1995): https://doi.org/10.1109/78.365298",TRUE,https://github.com/abarbour/psd,26380,2,1553205292
pseudorank,"Efficient calculation of pseudo-ranks and (pseudo)-rank based test statistics. In case of equal sample sizes, pseudo-ranks and mid-ranks are equal. When used for inference mid-ranks may lead to paradoxical results. Pseudo-ranks are in general not affected by such a problem. For details, see Brunner, E., Bathke A. C. and Konietschke, F: Rank- and Pseudo-Rank Procedures in Factorial Designs - Using R and SAS, Springer Verlag, to appear.",2018-11-27,Martin Happ  (<https://orcid.org/0000-0003-0009-2665>),http://github.com/happma/pseudorank,TRUE,https://github.com/happma/pseudorank,4656,1,1543267584
psidR,"Makes it easy to build panel data in wide format from Panel Survey
    of Income Dynamics ('PSID') delivered raw data. Downloads data directly from
    the PSID server using the 'SAScii' package. 'psidR' takes care of merging
    data from each wave onto a cross-period index file, so that individuals can be
    followed over time. The user must specify which years they are interested in,
    and the 'PSID' variable names (e.g. ER21003) for each year (they differ in each
    year). The package offers helper functions to retrieve variable names from different
    waves. There are different panel data designs and sample subsetting criteria
    implemented (""SRC"", ""SEO"", ""immigrant"" and ""latino"" samples).",2018-10-18,Florian Oswald,https://github.com/floswald/psidR,TRUE,https://github.com/floswald/psidr,21904,26,1539852415
PSLM2015,Data and statistics of Pakistan Social and Living Standards Measurement (PSLM) survey 2014-15 from Pakistan Bureau of Statistics (<http://www.pbs.gov.pk/>).,2017-12-06,Muhammad Yaseen,https://github.com/MYaseen208/PSLM2015,TRUE,https://github.com/myaseen208/pslm2015,2601,0,1525670889
pssmooth,"Implements estimation and testing procedures for evaluating an intermediate biomarker response as a principal surrogate of a clinical response to treatment (i.e., principal stratification effect modification analysis), as described in Juraska M, Huang Y, and Gilbert PB (2018), Inference on treatment effect modification by biomarker response in a three-phase sampling design, Biostatistics, kxy074 <doi:10.1093/biostatistics/kxy074>. The methods avoid the restrictive 'placebo structural risk' modeling assumption common to past methods and further improve robustness by the use of nonparametric kernel smoothing for biomarker density estimation. A randomized controlled two-group clinical efficacy trial is assumed with an ordered categorical or continuous univariate biomarker response measured at a fixed timepoint post-randomization and with a univariate baseline surrogate measure allowed to be observed in only a subset of trial participants with an observed biomarker response (see the flexible three-phase sampling design in the paper for details). Bootstrap-based procedures are available for pointwise and simultaneous confidence intervals and testing of four relevant hypotheses. Summary and plotting functions are provided for estimation results.",2019-01-22,Michal Juraska,https://github.com/mjuraska/pssmooth,TRUE,https://github.com/mjuraska/pssmooth,1938,0,1548186012
PSTR,"Provides the Panel Smooth Transition Regression (PSTR) modelling.
    The modelling procedure consists of three stages: Specification, Estimation and Evaluation.
    The package offers sharp tools helping the package user(s) to conduct model specification tests,
    to do PSTR model estimation, and to do model evaluation.
    The tests implemented in the package allow for cluster-dependency and are heteroskedasticity-consistent.
    The wild bootstrap and wild cluster bootstrap tests are also implemented.
    Parallel computation (as an option) is implemented in some functions, especially the bootstrap tests.
    The package suits tasks running many cores on super-computation servers.",2018-12-09,Yukai Yang,https://github.com/yukai-yang/PSTR,TRUE,https://github.com/yukai-yang/pstr,5111,4,1546555318
psychmeta,"Tools for computing bare-bones and psychometric meta-analyses and for generating psychometric data for use in meta-analysis simulations. Supports bare-bones, individual-correction, and artifact-distribution methods for meta-analyzing correlations and d values. Includes tools for converting effect sizes, computing sporadic artifact corrections, reshaping meta-analytic databases, computing multivariate corrections for range variation, and more. Bugs can be reported to <https://github.com/psychmeta/psychmeta/issues> or <issues@psychmeta.com>.",2019-02-26,Jeffrey A. Dahlke,NA,TRUE,https://github.com/psychmeta/psychmeta,12595,10,1551213231
psycho,"The main goal of the psycho package is to provide tools for psychologists, neuropsychologists and neuroscientists, 
   to facilitate and speed up the time spent on data analysis. It aims at supporting best practices and tools to format the output 
   of statistical methods to directly paste them into a manuscript, ensuring statistical reporting standardization and conformity.",2019-03-31,Dominique Makowski,https://github.com/neuropsychology/psycho.R,TRUE,https://github.com/neuropsychology/psycho.r,15288,52,1547790357
psymonitor,"Apply the popular real-time monitoring strategy
    proposed by Phillips, Shi and Yu (2015a,b;PSY) <doi:10.1111/iere.12132>, <doi:10.1111/iere.12131>, along with a new
    bootstrap procedure designed to mitigate the potential impact of
    heteroskedasticity and to effect family-wise size control in recursive
    testing algorithms (Phillips and Shi, forthcoming).",2019-03-20,Itamar Caspi,https://github.com/itamarcaspi/psymonitor,TRUE,https://github.com/itamarcaspi/psymonitor,1437,6,1553436121
ptstem,"Wraps a collection of stemming algorithms for the Portuguese
    Language.",2019-01-02,Daniel Falbel,https://github.com/dfalbel/ptstem,TRUE,https://github.com/dfalbel/ptstem,5978,12,1546439286
PTXQC,"Generates Proteomics (PTX) quality control (QC) reports for shotgun LC-MS data analyzed with the 
             MaxQuant software suite.
             Reports are customizable (target thresholds, subsetting) and available in HTML or PDF format.
             Published in J. Proteome Res., Proteomics Quality Control: Quality Control Software for MaxQuant Results (2015) 'doi:10.1021/acs.jproteome.5b00780'.",2019-03-15,Chris Bielow <chris.bielow@fu-berlin.de>,https://github.com/cbielow/PTXQC,TRUE,https://github.com/cbielow/ptxqc,7883,14,1552637012
pubchunks,"Get chunks of XML scholarly articles without 
    having to know how to work with XML. Custom mappers
    for each publisher and for each article section pull 
    out the information you want. Works with outputs from 
    package 'fulltext', 'xml2' package documents, and file paths to 
    XML documents.",2019-01-21,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/pubchunks,TRUE,https://github.com/ropensci/pubchunks,1483,7,1548293718
pubh,"A toolbox for making R functions and capabilities more
    accessible to students and professionals from Epidemiology and
    Public Health related disciplines. Includes a function to report 
    coefficients and confidence intervals from models using robust
    standard errors (when available), functions that expand lattice
    plots and functions relevant for introductory papers in Epidemiology 
    or Public Health. Please note that use of the 
    provided data sets is for educational purposes only.",2018-11-02,Josie Athens,https://github.com/josie-athens/pubh,TRUE,https://github.com/josie-athens/pubh,4695,0,1541018657
PUlasso,"Efficient algorithm for solving PU (Positive and Unlabeled) problem in low or high dimensional setting with lasso or group lasso penalty. The algorithm uses Maximization-Minorization and (block) coordinate descent. Sparse calculation and parallel computing are supported for the computational speed-up. See Hyebin Song, Garvesh Raskutti (2018) <arXiv:1711.08129>.",2019-02-28,Hyebin Song,https://arxiv.org/abs/1711.08129,TRUE,https://github.com/hsong1/pulasso,5056,2,1551369737
pulsar,"Model selection for penalized graphical models using the Stability Approach to Regularization Selection ('StARS'), with options for speed-ups including Bounded StARS (B-StARS), batch computing, and other stability metrics (e.g., graphlet stability G-StARS). Christian L. Müller, Richard Bonneau, Zachary Kurtz (2016) <arXiv:1605.07072>.",2019-03-07,Zachary Kurtz,"http://github.com/zdk123/pulsar, http://arxiv.org/abs/1605.07072",TRUE,https://github.com/zdk123/pulsar,7905,4,1551931548
purrr,A complete and consistent functional programming toolkit for R.,2019-03-15,Lionel Henry,"http://purrr.tidyverse.org, https://github.com/tidyverse/purrr",TRUE,https://github.com/tidyverse/purrr,7139661,755,1552673702
purrrlyr,"Some functions at the intersection of 'dplyr' and 'purrr' that 
  formerly lived in 'purrr'.",2019-03-15,Lionel Henry,https://github.com/hadley/purrrlyr,TRUE,https://github.com/hadley/purrrlyr,42914,97,1552673380
pushbar,"Create sliders from left, right, top and bottom which may include any html or 'Shiny' input or output.",2019-03-15,John Coene,https://github.com/JohnCoene/pushbar,TRUE,https://github.com/johncoene/pushbar,187,23,1552909574
PWFSLSmoke,"Utilities for working with air quality monitoring data
    with a focus on small particulates (PM2.5) generated by wildfire
    smoke. Functions are provided for downloading available data from
    the United States 'EPA' <https://www.epa.gov/outdoor-air-quality-data> and
    it's 'AirNow' air quality site <https://www.airnow.gov>.
    Additional sources of PM2.5 data made accessible by the package include:
    'AIRSIS' (password protected) <https://www.oceaneering.com/data-management/>
    and 'WRCC' <https://wrcc.dri.edu/cgi-bin/smoke.pl>.
    Data compilations are provided by 'PWFSL'
    <https://www.fs.fed.us/pnw/pwfsl/>.",2019-04-04,Jonathan Callahan,https://github.com/MazamaScience/PWFSLSmoke,TRUE,https://github.com/mazamascience/pwfslsmoke,6182,4,1554399893
pxweb,"Generic interface for the PX-Web/PC-Axis API. The PX-Web/PC-Axis
    API is used by organizations such as Statistics Sweden and Statistics
    Finland to disseminate data. The R package can interact with all
    PX-Web/PC-Axis APIs to fetch information about the data hierarchy, extract
    metadata and extract and parse statistics to R data.frame format. PX-Web is
    a solution to disseminate PC-Axis data files in dynamic tables on the web.
    Since 2013 PX-Web contains an API to disseminate PC-Axis files.",2019-01-07,Mans Magnusson,https://github.com/rOpenGov/pxweb/,TRUE,https://github.com/ropengov/pxweb,17669,27,1550314277
pyinit,"Deterministic Pena-Yohai initial estimator for robust S estimators
    of regression. The procedure is described in detail in
    Pena, D., & Yohai, V. (1999) <doi:10.2307/2670164>.",2018-03-14,David Kepplinger,https://github.com/dakep/pyinit,TRUE,https://github.com/dakep/pyinit,2171,1,1552347113
pzfx,Read and write 'GraphPad Prism' '.pzfx' files in R.,2019-01-08,Yue Jiang  (<https://orcid.org/0000-0002-9798-5517>),https://github.com/Yue-Jiang/pzfx,TRUE,https://github.com/yue-jiang/pzfx,1970,2,1547066555
QAIG,"A tool for automatic generation of sibling items from a parent item model defined by
           the user. It is an implementation of the process automatic item generation (AIG) focused
           on generating quantitative multiple-choice type of items (see Embretson, Kingston
           (2018) <doi:10.1111/jedm.12166>).",2019-03-17,Subhabrata Patra (Shubh),https://github.com/shubh-b/QAIG,TRUE,https://github.com/shubh-b/qaig,166,0,1553434683
qCBA,CBA postprocessing algorithm that creates smaller models for datasets containing quantitative (numerical) attributes. Article describing QCBA is published in Tomas Kliegr (2017) <arXiv:1711.10166>.,2018-01-12,Tomas Kliegr,https://github.com/kliegr/QCBA,TRUE,https://github.com/kliegr/qcba,2953,2,1535625434
qcc,"Shewhart quality control charts for continuous, attribute and count data. Cusum and EWMA charts. Operating characteristic curves. Process capability analysis. Pareto chart and cause-and-effect chart. Multivariate control charts.",2017-07-11,Luca Scrucca,https://github.com/luca-scr/qcc,TRUE,https://github.com/luca-scr/qcc,198069,11,1551959932
qccrs,"Functions to calculate Average Sample Numbers (ASN), Average Run Length (ARL1) and value of k, k1 and k2 for quality control charts under repetitive sampling as given in Aslam et al. (2014) (<DOI:10.7232/iems.2014.13.1.101>).",2018-12-03,Muhammad Yaseen,"https://github.com/myaseen208/qccrs,
https://myaseen208.github.io/qccrs/",TRUE,https://github.com/myaseen208/qccrs,951,0,1543496112
qdap,"Automates many of the tasks associated with quantitative discourse analysis of transcripts containing discourse
              including frequency counts of sentence types, words, sentences, turns of talk, syllables and other assorted
              analysis tasks. The package provides parsing tools for preparing transcript data. Many functions enable the user
              to aggregate data by any number of grouping variables, providing analysis and seamless integration with other R
              packages that undertake higher level analysis and visualization of text. This affords the user a more efficient
              and targeted analysis. 'qdap' is designed for transcript analysis, however, many functions are applicable to other
              areas of Text Mining/ Natural Language Processing.",2019-01-02,Tyler Rinker,http://trinker.github.com/qdap/,TRUE,https://github.com/trinker/qdap,1734444,121,1546434950
QGglmm,"Compute various quantitative genetics parameters from a Generalised Linear Mixed Model (GLMM) estimates. Especially, it yields the observed phenotypic mean, phenotypic variance and additive genetic variance.",2018-11-12,Pierre de Villemereuil <bonamy@horus.ens.fr>,NA,TRUE,https://github.com/devillemereuil/qgglmm,6389,4,1542038919
qgraph,"Weighted network visualization and analysis, as well as Gaussian graphical model computation. See Epskamp et al. (2012) <doi:10.18637/jss.v048.i04>.",2019-02-13,Sacha Epskamp,http://sachaepskamp.com/qgraph,TRUE,https://github.com/sachaepskamp/qgraph,296834,35,1553268334
qicharts2,"Functions for making run charts, Shewhart control charts and
    Pareto charts for continuous quality improvement. Included control charts are:
    I, MR, Xbar, S, T, C, U, U', P, P', and G charts. Non-random variation in the
    form of minor to moderate persistent shifts in data over time is identified by
    the Anhoej rules for unusually long runs and unusually few crossing 
    [Anhoej, Olesen (2014) <doi:10.1371/journal.pone.0113825>].
    Non-random variation in the form of larger, possibly transient, shifts is
    identified by Shewhart's 3-sigma rule [Mohammed, Worthington, Woodall (2008)
    <doi:10.1136/qshc.2004.012047>].",2019-03-16,Jacob Anhoej,https://github.com/anhoej/qicharts2,TRUE,https://github.com/anhoej/qicharts2,12364,19,1554555828
qmethod,"Analysis of Q methodology, used to identify distinct perspectives existing within a group.
  This methodology is used across social, health and environmental sciences to understand diversity of attitudes, discourses, or decision-making styles (for more information, see <http://qmethod.org>).
  A single function runs the full analysis. Each step can be run separately using the corresponding functions: for automatic flagging of Q-sorts (manual flagging is optional), for statement scores, for distinguishing and consensus statements, and for general characteristics of the factors.
  Additional functions are available to import and export data, to print and plot, to import raw data from individual *.CSV files, and to make printable cards.
  The package also offers functions to print Q cards and to generate Q distributions for study administration.
  The package uses principal components and it allows manual or automatic flagging, a number of mathematical methods for rotation, and a number of correlation coefficients for the initial correlation matrix.
  See further details in the package documentation, and in the web pages below, which include a cookbook, guidelines for more advanced analysis (how to perform manual flagging or change the sign of factors), data management, and a beta graphical user interface for online and offline use.",2018-05-22,Aiora Zabala  (Main author,"https://github.com/aiorazabala/qmethod,
https://github.com/aiorazabala/qmethod/wiki",TRUE,https://github.com/aiorazabala/qmethod,15781,27,1526928581
qoma.smuggler,"Transport data and commands across the 'FAME' <https://fame.sungard.com/support.html> / 'R' border.
    A set of utilities for: reading 'FAME' databases into 'R'; writing
    'R' data into 'FAME' databases; executing 'FAME' commands in 'R' environment; and, executing
    'R' commands from the 'FAME' environment.",2018-08-30,Kevin Keane,https://github.com/qomaio/r-smuggler/,TRUE,https://github.com/qomaio/r-smuggler,1227,0,1535735692
qqplotr,Extensions of 'ggplot2' Q-Q plot functionalities.,2018-07-18,Alexandre Almeida,https://github.com/aloy/qqplotr,TRUE,https://github.com/aloy/qqplotr,14983,28,1532625844
qrencoder,"Quick Response codes (QR codes) are a type of matrix bar code and can be
    used to authenticate transactions, provide access to multi-factor authentication
    services and enable general data transfer in an image. QR codes use four standardized 
    encoding modes (numeric, alphanumeric, byte/binary, and kanji) to efficiently store 
    data. Matrix barcode generation is performed efficiently in C via the included
    'libqrencoder' library created by Kentaro Fukuchi.",2016-09-16,Bob Rudis,http://github.com/hrbrmstr/qrencoder,TRUE,https://github.com/hrbrmstr/qrencoder,5018,33,1541960158
qs,Provides functions for quickly writing and reading any R object to and from disk.  ,2019-03-02,Travers Ching,https://github.com/traversc/qs,TRUE,https://github.com/traversc/qs,582,62,1554482098
qsub,"Run lapply() calls in parallel by submitting them to 
    'gridengine' clusters using the 'qsub' command.",2019-02-13,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,http://github.com/rcannood/qsub,TRUE,https://github.com/rcannood/qsub,2320,1,1550068705
qtl,"Analysis of experimental crosses to identify genes
  (called quantitative trait loci, QTLs) contributing to variation in
  quantitative traits.",2019-01-22,Karl W Broman <broman@wisc.edu> and Hao Wu,"http://rqtl.org, https://github.com/kbroman/qtl",TRUE,https://github.com/kbroman/qtl,115294,48,1553104433
qtlcharts,"Web-based interactive charts (using D3.js) for the analysis of
    experimental crosses to identify genetic loci (quantitative trait
    loci, QTL) contributing to variation in quantitative traits.",2019-02-05,Karl W Broman,"https://kbroman.org/qtlcharts,
https://github.com/kbroman/qtlcharts",TRUE,https://github.com/kbroman/qtlcharts,13763,76,1552309036
quadmesh,"Create surface forms from matrix or 'raster' data for flexible plotting and
 conversion to other mesh types. The functions 'quadmesh' or 'triangmesh'
 produce a continuous surface as a 'mesh3d' object as used by the 'rgl'
 package. This is used for plotting raster data in 3D (optionally with
 texture), and allows the application of a map projection without data loss and 
 many processing applications that are restricted by inflexible regular grid rasters.
 There are discrete forms of these continuous surfaces available with
 'dquadmesh' and 'dtriangmesh' functions.",2019-04-06,Michael D. Sumner,https://github.com/hypertidy/quadmesh,TRUE,https://github.com/hypertidy/quadmesh,9484,14,1554511334
qualmap,"Provides a set of functions for taking qualitative GIS data, hand drawn on a map, and 
   converting it to a simple features object. These tools are focused on data that are drawn on a map
   that contains some type of polygon features. For each area identified on the map, the id numbers
   of these polygons can be entered as vectors and transformed using qualmap.",2018-09-12,Christopher Prener  (<https://orcid.org/0000-0002-4310-9888>),https://github.com/slu-openGIS/qualmap,TRUE,https://github.com/slu-opengis/qualmap,2789,11,1536771419
qualpalr,"Automatic generation of distinct qualitative color palettes,
    optionally adapted to color deficiency. It takes a subspace of the HSL color
    space as input and projects it to the DIN99d color space where it selects
    and return colors that are maximally distinct.",2018-10-29,Johan Larsson  (<https://orcid.org/0000-0002-4029-5945>),https://jolars.github.io/qualpalr/,TRUE,https://github.com/jolars/qualpalr,7824,10,1540845176
Quandl,"Functions for interacting directly with the Quandl API to offer data in a number of formats usable in R, downloading a zip with all data from a Quandl database, and the ability to search. This R package uses the Quandl API. For more information go to <https://www.quandl.com/docs/api>. For more help on the package itself go to <https://www.quandl.com/help/r>.",2018-08-14,Raymond McTaggart,https://github.com/quandl/quandl-r,TRUE,https://github.com/quandl/quandl-r,264843,97,1534274562
quantable,"Methods which streamline the descriptive analysis of quantitative
    matrices. Matrix columns are samples while rows are features i.e. proteins, genes.
    Includes methods for visualization (e.g. Heatmaps, Volcanos, pairwise QQ, Bland-Altman plot),
    summary statistics (e.g. CV), data normalization methods (e.g. robustscale). Read function for Progenesis.  ",2018-05-15,Witold Wolski <wewolski@gmail.com>,https://github.com/protViz/quantable,TRUE,https://github.com/protviz/quantable,9499,7,1543832224
quanteda,"A fast, flexible, and comprehensive framework for 
    quantitative text analysis in R.  Provides functionality for corpus management,
    creating and manipulating tokens and ngrams, exploring keywords in context, 
    forming and manipulating sparse matrices
    of documents by features and feature co-occurrences, analyzing keywords, computing feature similarities and
    distances, applying content dictionaries, applying supervised and unsupervised machine learning, 
    visually representing text and text analyses, and more. ",2019-04-01,Kenneth Benoit,https://quanteda.io,TRUE,https://github.com/quanteda/quanteda,263330,485,1554261136
quantities,"Integration of the 'units' and 'errors' packages for a complete quantity
    calculus system for R vectors, matrices and arrays, with automatic propagation,
    conversion, derivation and simplification of magnitudes and uncertainties.",2018-12-05,Iñaki Ucar,https://github.com/r-quantities/quantities,TRUE,https://github.com/r-quantities/quantities,1571,12,1551102712
quantmod,"Specify, build, trade, and analyse quantitative financial trading strategies.",2019-03-24,Joshua M. Ulrich,http://www.quantmod.com https://github.com/joshuaulrich/quantmod,TRUE,https://github.com/joshuaulrich/quantmod,3077693,398,1553352064
QuantNorm,"Modifies the distance matrix obtained from data with batch effects, so as to improve the performance of sample pattern detection, such as clustering, dimension reduction, and construction of networks between subjects. The method has been published in Bioinformatics (Fei et al, 2018, <doi:10.1093/bioinformatics/bty117>). Also available on 'GitHub' <https://github.com/tengfei-emory/QuantNorm>.",2019-02-01,Teng Fei,NA,TRUE,https://github.com/tengfei-emory/quantnorm,2163,8,1550705057
quantregRanger,This is the implementation of quantile regression forests for the fast random forest package 'ranger'.,2017-12-15,Philipp Probst,https://github.com/PhilippPro/quantregRanger,TRUE,https://github.com/philipppro/quantregranger,2542,7,1524057129
QuantumClone,"Using HTS data, clusters mutations in order to recreate putative
    clones from the data provided. It requires genotype at the location of the
    variant as well as the depth of coverage and number of reads supporting the
    mutation. Additional information may be provided, such as the contamination
    in the tumor sample. This package also provides a function QuantumCat() which
    simulates data obtained from tumor sequencing.",2017-11-13,Paul Deveau,https://github.com/DeveauP/QuantumClone,TRUE,https://github.com/deveaup/quantumclone,8957,7,1552838234
Quartet,"Calculates the number of four-taxon subtrees consistent with a pair
  of cladograms, calculating the symmetric quartet distance of Bandelt & Dress (1986),
  Reconstructing the shape of a tree from observed dissimilarity data,
  Advances in Applied Mathematics, 7, 309-343 <doi:10.1016/0196-8858(86)90038-2>, 
  and using the tqDist algorithm of Sand et al. (2014), tqDist: a library for
  computing the quartet and triplet distances between binary or general trees,
  Bioinformatics, 30, 2079–2080 <doi:10.1093/bioinformatics/btu157>
  for pairs of bifurcating trees.",2019-03-06,Martin R. Smith,https://github.com/ms609/Quartet,TRUE,https://github.com/ms609/quartet,858,1,1551872893
questionr,"Set of functions to make the processing and analysis of
    surveys easier : interactive shiny apps and addins for data recoding,
    contingency tables, dataset metadata handling, and several convenience
    functions.",2018-11-26,Julien Barnier,https://juba.github.io/questionr/,TRUE,https://github.com/juba/questionr,409944,46,1550603101
queuecomputer,"Implementation of a computationally efficient method for
    simulating queues with arbitrary arrival and service times.",2018-10-16,Anthony Ebert  (<https://orcid.org/0000-0003-3002-6300>),https://github.com/AnthonyEbert/queuecomputer,TRUE,https://github.com/anthonyebert/queuecomputer,6404,17,1539715192
quickblock,"
    Provides functions for assigning treatments in randomized experiments using
    near-optimal threshold blocking. The package is made with large data sets in
    mind and derives blocks more than an order of magnitude quicker than other
    methods.",2018-08-21,Fredrik Savje,https://github.com/fsavje/quickblock,TRUE,https://github.com/fsavje/quickblock,3695,2,1535138194
quickmapr,"While analyzing geospatial data, easy visualization is often
    needed that allows for quick plotting, and simple, but easy interactivity.
    Additionally, visualizing geospatial data in projected coordinates is also
    desirable. The 'quickmapr' package provides a simple method to visualize 
    'sp', 'sf' (via coercion to 'sp'), and 'raster' objects, allows for basic 
    zooming, panning, identifying,labeling, selecting, and measuring spatial 
    objects.  Importantly, it does not require that the data be in geographic 
    coordinates.",2018-06-03,Jeffrey W. Hollister,https://www.github.com/jhollist/quickmapr,TRUE,https://github.com/jhollist/quickmapr,12118,54,1528030793
quickmatch,"
    Provides functions for constructing near-optimal generalized full matching.
    Generalized full matching is an extension of the original full matching method
    to situations with more intricate study designs. The package is made with
    large data sets in mind and derives matches more than an order of magnitude
    quicker than other methods.",2018-08-24,Fredrik Savje,https://github.com/fsavje/quickmatch,TRUE,https://github.com/fsavje/quickmatch,4017,8,1535145010
quickPlot,"A high-level plotting system, built using 'grid' graphics, that is
    optimized for speed and modularity. This has great utility for quick
    visualizations when testing code, with the key benefit that visualizations
    are updated independently of one another.",2018-11-09,Eliot J B McIntire  (<https://orcid.org/0000-0002-6914-8316>),"http://quickplot.predictiveecology.org,
https://github.com/PredictiveEcology/quickPlot",TRUE,https://github.com/predictiveecology/quickplot,23438,4,1541715966
quokar,"Diagnostics methods for quantile regression models for detecting influential observations:
  robust distance methods for general quantile regression models; generalized Cook's distance and 
  Q-function distance method for quantile regression models using aymmetric Laplace distribution. Reference
  of this method can be found in Luis E. Benites, Víctor H. Lachos, Filidor E. Vilca (2015) <arXiv:1509.05099v1>; 
  mean posterior probability and Kullback–Leibler divergence methods for Bayes quantile regression model.
  Reference of this method is Bruno Santos, Heleno Bolfarine (2016) <arXiv:1601.07344v1>.",2017-11-10,Wenjing Wang <wenjingwangr@gmail.com>,https://github.com/wenjingwang/quokar,TRUE,https://github.com/wenjingwang/quokar,2727,5,1550670351
quRan,"Full text, in data frames containing one row per verse, of the 
    Qur'an in Arabic (with and without vowels) and in English (the Yusuf Ali 
    and Saheeh International translations), formatted to be convenient for 
    text analysis.",2019-01-17,Andrew Heiss,https://github.com/andrewheiss/quRan,TRUE,https://github.com/andrewheiss/quran,635,17,1547192243
qwraps2,"A collection of (wrapper) functions the creator found useful
    for quickly placing data summaries and formatted regression results into
    '.Rnw' or '.Rmd' files. Functions for generating commonly used graphics,
    such as receiver operating curves or Bland-Altman plots, are also provided
    by 'qwraps2'.  'qwraps2' is a updated version of a package 'qwraps'. The
    original version 'qwraps' was never submitted to CRAN but can be found at
    <https://github.com/dewittpe/qwraps/>. The implementation and limited scope
    of the functions within 'qwraps2' <https://github.com/dewittpe/qwraps2/> is
    fundamentally different from 'qwraps'.",2019-03-15,Peter DeWitt,https://github.com/dewittpe/qwraps2/,TRUE,https://github.com/dewittpe/qwraps2,26307,17,1553279022
R.devices,"Functions for creating plots and image files in a unified way
    regardless of output format (EPS, PDF, PNG, SVG, TIFF, WMF, etc.). Default
    device options as well as scales and aspect ratios are controlled in a uniform
    way across all device types. Switching output format requires minimal changes
    in code. This package is ideal for large-scale batch processing, because it
    will never leave open graphics devices or incomplete image files behind, even on
    errors or user interrupts.",2018-07-21,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.devices,TRUE,https://github.com/henrikbengtsson/r.devices,119635,14,1532186733
R.filesets,"A file set refers to a set of files located in one or more directories on the file system.  This package provides classes and methods to locate, setup, subset, navigate and iterate such sets.  The API is designed such that these classes can be extended via inheritance to provide a richer API for special file formats.  Moreover, a specific name format is defined such that filenames and directories can be considered to have full names which consists of a name followed by comma-separated tags.  This adds additional flexibility to identify file sets and individual files.  NOTE: This package's API should be considered to be in an beta stage.  Its main purpose is currently to support the aroma.* packages, where it is one of the main core components; if you decide to build on top of this package, please contact the author first.",2018-04-09,Henrik Bengtsson,"https://github.com/HenrikBengtsson/R.filesets,
http://www.aroma-project.org/",TRUE,https://github.com/henrikbengtsson/r.filesets,56078,0,1523293800
R.matlab,"Methods readMat() and writeMat() for reading and writing MAT files.  For user with MATLAB v6 or newer installed (either locally or on a remote host), the package also provides methods for controlling MATLAB (trademark) via R and sending and retrieving data between R and MATLAB.",2018-09-27,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.matlab,TRUE,https://github.com/henrikbengtsson/r.matlab,241969,57,1538055844
R.oo,Methods and classes for object-oriented programming in R with or without references.  Large effort has been made on making definition of methods as simple as possible with a minimum of maintenance for package developers.  The package has been developed since 2001 and is now considered very stable.  This is a cross-platform package implemented in pure R that defines standard S3 classes without any tricks.,2018-04-22,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.oo,TRUE,https://github.com/henrikbengtsson/r.oo,1297165,12,1524367701
R.rsp,"The RSP markup language makes any text-based document come alive.  RSP provides a powerful markup for controlling the content and output of LaTeX, HTML, Markdown, AsciiDoc, Sweave and knitr documents (and more), e.g. 'Today's date is <%=Sys.Date()%>'.  Contrary to many other literate programming languages, with RSP it is straightforward to loop over mixtures of code and text sections, e.g. in month-by-month summaries.  RSP has also several preprocessing directives for incorporating static and dynamic contents of external files (local or online) among other things.  Functions rstring() and rcat() make it easy to process RSP strings, rsource() sources an RSP file as it was an R script, while rfile() compiles it (even online) into its final output format, e.g. rfile('report.tex.rsp') generates 'report.pdf' and rfile('report.md.rsp') generates 'report.html'.  RSP is ideal for self-contained scientific reports and R package vignettes.  It's easy to use - if you know how to write an R script, you'll be up and running within minutes.",2019-02-05,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.rsp,TRUE,https://github.com/henrikbengtsson/r.rsp,261054,20,1549407491
R.utils,Utility functions useful when programming and developing R packages.,2019-02-14,Henrik Bengtsson,https://github.com/HenrikBengtsson/R.utils,TRUE,https://github.com/henrikbengtsson/r.utils,1425495,31,1550181063
r2d3,"Suite of tools for using 'D3', a library for producing dynamic, interactive data
  visualizations. Supports translating objects into 'D3' friendly data structures, rendering
  'D3' scripts, publishing 'D3' visualizations, incorporating 'D3' in R Markdown, creating
  interactive 'D3' applications with Shiny, and distributing 'D3' based 'htmlwidgets' in R
  packages.",2018-12-18,Javier Luraschi,https://github.com/rstudio/r2d3,TRUE,https://github.com/rstudio/r2d3,664427,343,1553084339
R2GUESS,"Wrapper functions for GUESS, a GPU-accelerated
    sparse Bayesian variable selection method for linear regression based
    analysis of multivariate, correlated outcomes.",2018-12-20,Gianluca Campanella,https://github.com/ImperialCollegeLondon/R2GUESS,TRUE,https://github.com/imperialcollegelondon/r2guess,12954,0,1545488479
R2ucare,Performs goodness-of-fit tests for capture-recapture models. Also contains several functions to process capture-recapture data.,2017-04-13,Olivier Gimenez,https://github.com/oliviergimenez/R2ucare,TRUE,https://github.com/oliviergimenez/r2ucare,4286,1,1524302375
R6,"Creates classes with reference semantics, similar to R's built-in
    reference classes. Compared to reference classes, R6 classes are simpler
    and lighter-weight, and they are not built on S4 classes so they do not
    require the methods package. These classes allow public and private
    members, and they support inheritance, even when the classes are defined in
    different packages.",2019-02-14,Winston Chang,"https://r6.r-lib.org, https://github.com/r-lib/R6/",TRUE,https://github.com/r-lib/r6,14819637,254,1550245191
r6extended,"Useful methods and data fields to extend the
             bare bones 'R6' class provided by the 'R6' package - ls-method, 
             hashes, warning- and message-method, general get-method and a 
             debug-method that assigns self and private to the global environment.",2019-02-12,Peter Meissner,https://github.com/petermeissner/r6extended,TRUE,https://github.com/petermeissner/r6extended,2978,2,1549917200
radarchart,"Create interactive radar charts using the 'Chart.js' 'JavaScript' library
    and the 'htmlwidgets' package. 'Chart.js' <http://www.chartjs.org/> is a 
    lightweight library that supports several types of simple chart using the 'HTML5' 
    canvas element. This package provides an R interface specifically to the 
    radar chart, sometimes called a spider chart, for visualising multivariate data.",2016-12-20,Doug Ashton,https://github.com/mangothecat/radarchart,TRUE,https://github.com/mangothecat/radarchart,19499,55,1548151100
RadData,"Nuclear Decay Data for Dosimetric Calculations from the 
    International Commission on Radiological Protection from ICRP 
    Publication 107. Ann. ICRP 38 (3). Eckerman, Keith and Endo, Akira 2008 
    <doi:10.1016/j.icrp.2008.10.004> 
    <http://www.icrp.org/publication.asp?id=ICRP%20Publication%20107>. 
    This is a database of the physical data needed in calculations of 
    radionuclide-specific protection and operational quantities. The 
    data is prescribed by the ICRP, the international authority on 
    radiation dose standards, for estimating dose from the intake of or 
    exposure to radionuclides in the workplace and the environment. 
    The database contains information on the half-lives, decay chains, 
    and yields and energies of radiations emitted in nuclear transformations 
    of 1252 radionuclides of 97 elements. ",2019-04-05,Mark Hogue,https://github.com/markhogue/RadData,TRUE,https://github.com/markhogue/raddata,0,0,1554432527
radiant,"A platform-independent browser-based interface for business
    analytics in R, based on the shiny package. The application combines the
    functionality of radiant.data, radiant.design, radiant.basics,
    radiant.model, and radiant.multivariate.",2019-03-10,Vincent Nijs,https://github.com/radiant-rstats/radiant,TRUE,https://github.com/radiant-rstats/radiant,21938,184,1553195572
radiant.basics,"The Radiant Basics menu includes interfaces for probability 
    calculation, central limit theorem simulation, comparing means and proportions, 
    goodness-of-fit testing, cross-tabs, and correlation. The application extends 
    the functionality in radiant.data.",2019-03-06,Vincent Nijs,"https://github.com/radiant-rstats/radiant.basics,
https://radiant-rstats.github.io/radiant.basics,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.basics,17055,2,1551769006
radiant.data,"The Radiant Data menu includes interfaces for loading, saving,
    viewing, visualizing, summarizing, transforming, and combining data. It also
    contains functionality to generate reproducible reports of the analyses
    conducted in the application.",2019-03-04,Vincent Nijs,"https://github.com/radiant-rstats/radiant.data,
https://radiant-rstats.github.io/radiant.data,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.data,20795,29,1553190754
radiant.design,"The Radiant Design menu includes interfaces for design of
    experiments, sampling, and sample size calculation. The application extends
    the functionality in radiant.data.",2019-03-06,Vincent Nijs,"https://github.com/radiant-rstats/radiant.design,
https://radiant-rstats.github.io/radiant.design,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.design,16650,3,1551768968
radiant.model,"The Radiant Model menu includes interfaces for linear and logistic
    regression, naive Bayes, neural networks, classification and regression trees,
    model evaluation, collaborative filtering, decision analysis, and simulation. 
    The application extends the functionality in radiant.data.",2019-03-05,Vincent Nijs,"https://github.com/radiant-rstats/radiant.model,
https://radiant-rstats.github.io/radiant.model,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.model,17415,7,1553305470
radiant.multivariate,"The Radiant Multivariate menu includes interfaces for perceptual
    mapping, factor analysis, cluster analysis, and conjoint analysis. The
    application extends the functionality in radiant.data.",2019-03-05,Vincent Nijs,"https://github.com/radiant-rstats/radiant.multivariate,
https://radiant-rstats.github.io/radiant.multivariate,
https://radiant-rstats.github.io/docs",TRUE,https://github.com/radiant-rstats/radiant.multivariate,16505,2,1553640983
radix,"Scientific and technical article format for the web. 'Radix' articles 
    feature attractive, reader-friendly typography, flexible layout options
    for visualizations, and full support for footnotes and citations.",2018-12-09,JJ Allaire,https://github.com/rstudio/radix,TRUE,https://github.com/rstudio/radix,5199,0,1551982353
radsafer,"Provides functions for radiation safety, also known as ""radiation protection"" and ""radiological control"". The science of radiation protection is called ""health physics"" and its engineering functions are called ""radiological engineering"". Functions in this package cover many of the computations needed by radiation safety professionals. Examples include: obtaining updated calibration and source check values for radiation monitors to account for radioactive decay in a reference source, simulating instrument readings to better understand measurement uncertainty, correcting instrument readings for geometry and ambient atmospheric conditions. Many of these functions are described in Johnson and Kirby (2011, ISBN-13:  978-1609134198). Utilities are also included for developing inputs and processing outputs with radiation transport codes, such as MCNP, a general-purpose Monte Carlo N-Particle code that can be used for neutron, photon, electron, or coupled neutron/photon/electron transport (Werner et. al. (2018) <doi:10.2172/1419730>).",2019-04-04,Mark Hogue <mark.hogue.chp@gmail.com>,https://github.com/markhogue/radsafer,TRUE,https://github.com/markhogue/radsafer,3,0,1554170542
RAdwords,"Aims at loading Google Adwords data into R. Adwords is an online
    advertising service that enables advertisers to display advertising copy to web
    users (see <https://developers.google.com/adwords/> for more information). 
    Therefore the package implements three main features. First, the package
    provides an authentication process for R with the Google Adwords API (see 
    <https://developers.google.com/adwords/api/> for more information) via OAUTH2.
    Second, the package offers an interface to apply the Adwords query language in
    R and query the Adwords API with ad-hoc reports. Third, the received data are
    transformed into suitable data formats for further data processing and data
    analysis.",2019-01-28,Johannes Burkhardt <johannes.burkhardt@gmail.com>,"https://github.com/jburkhardt/RAdwords,
https://developers.google.com/adwords,
https://developers.google.com/adwords/api/",TRUE,https://github.com/jburkhardt/radwords,26489,89,1548668942
RagGrid,"Data objects in 'R' can be rendered as 'HTML' tables using the
    'JavaScript' library 'ag-grid' (typically via 'R Markdown' or 'Shiny'). The
    'ag-grid' library has been included in this 'R' package. The package name
    'RagGrid' is an abbreviation of 'R agGrid'.",2018-08-12,Srikkanth M,https://github.com/no-types/RagGrid/,TRUE,https://github.com/no-types/raggrid,2515,16,1538975488
rags2ridges,"Proper L2-penalized ML estimators for the
  precision matrix as well as supporting functions to employ these estimators
  in a graphical modeling setting.",2019-03-19,Carel F.W. Peeters,https://github.com/CFWP/rags2ridges,TRUE,https://github.com/cfwp/rags2ridges,14748,4,1552994831
ragt2ridges,"The ragt2ridges-package provides ridge maximum likelihood estimation of vector auto-regressive processes: the VAR(1), VAR(2) and VARX(1) model (more to be added). Prior knowledge may be incorporated in the estimation through a) specification of the edges believed to be absent in the time series chain graph, and b) a shrinkage target towards which the parameter estimate is shrunken for large penalty parameter values. Estimation functionality is accompanied by methodology for penalty parameter selection. In addition, the package offers supporting functionality for the exploitation of estimated models. Among others, i) a procedure to infer the support of the non-sparse ridge estimate (and thereby of the time series chain graph) is implemented, ii) a table of node-wise network summary statistics, iii) mutual information analysis, and iv) impulse response analysis. Cf. Miok et al. (2017) <DOI:10.1002/bimj.201500269> and Miok et al. (2018) <DOI:10.1002/bimj.201700195> for details on the implemented methods.",2018-12-20,Wessel N. van Wieringen <w.vanwieringen@vumc.nl>,https://github.com/wvanwie/ragt2ridges,TRUE,https://github.com/wvanwie/ragt2ridges,8450,1,1545310695
railtrails,"Rail trail data from the excellent 'TrailLink' website, sponsored by the 
    Rails-to-Trails Conservancy <https://www.traillink.com/>. Includes information 
    (such as name, length, surface, reviews, and trailhead latitude and longitude) on
    3,846 trails and 24,413 reviews in every state in the United States. Data can be 
    used to better understand recreational trail use in the United States and for
    examples / teaching, particularly examples and teaching involving hierarchical
    or repeated measures data.",2018-06-09,Joshua Rosenberg,https://github.com/jrosen48/railtrails,TRUE,https://github.com/jrosen48/railtrails,4589,5,1528516839
rakeR,"Functions for performing spatial microsimulation ('raking')
    in R.",2017-10-10,Phil Mike Jones  (0000-0001-5173-3245),https://philmikejones.github.io/rakeR/,TRUE,https://github.com/philmikejones/raker,4636,5,1553636925
rAltmetric,"Provides a programmatic interface to the citation information and alternate metrics provided by 'Altmetric'. Data from Altmetric allows researchers to immediately track the impact of their published work, without having to wait for citations. This allows for faster engagement with the audience interested in your work. For more information, visit <https://www.altmetric.com/>.",2017-04-19,Karthik Ram,https://github.com/ropensci/rAltmetric,TRUE,https://github.com/ropensci/raltmetric,14629,28,1527814798
rAmCharts,"Provides an R interface for using 'AmCharts' Library. Based on
    'htmlwidgets', it provides a global architecture to generate 'JavaScript' source
    code for charts. Most of classes in the library have their equivalent in R
    with S4 classes; for those classes, not all properties have been referenced but
    can easily be added in the constructors. Complex properties (e.g. 'JavaScript'
    object) can be passed as named list. See examples at <http://datastorm-
    open.github.io/introduction_ramcharts/> and <http://www.amcharts.com/> for
    more information about the library. The package includes the free version
    of 'AmCharts' Library. Its only limitation is a small link to the web site
    displayed on your charts. If you enjoy this library, do not hesitate to refer
    to this page <http://www.amcharts.com/online-store/> to purchase a licence,
    and thus support its creators and get a period of Priority Support. See also
    <http://www.amcharts.com/about/> for more information about 'AmCharts' company.",2019-02-12,Benoit Thieurmel,http://datastorm-open.github.io/introduction_ramcharts/,TRUE,https://github.com/datastorm-open/ramcharts,25831,36,1549959477
RAMClustR,"A feature clustering algorithm for non-targeted mass spectrometric metabolomics data. This method is compatible with gas and liquid chromatography coupled mass spectrometry, including indiscriminant tandem mass spectromery <DOI: 10.1021/ac501530d> data. ",2019-02-13,Corey D. Broeckling,https://github.com/cbroeckl/RAMClustR,TRUE,https://github.com/cbroeckl/ramclustr,744,4,1554220135
ramcmc,"Function for adapting the shape of the random walk Metropolis proposal
    as specified by robust adaptive Metropolis algorithm by Vihola (2012) <DOI:10.1007/s11222-011-9269-5>. 
    Package also includes fast functions for rank-one Cholesky update and downdate.
    These functions can be used directly from R or the corresponding C++ header files 
    can be easily linked to other R packages.",2018-05-29,Jouni Helske,NA,TRUE,https://github.com/helske/ramcmc,5844,1,1534324639
randgeo,"Generate random positions (latitude/longitude), 
    Well-known text ('WKT') points or polygons, or 'GeoJSON' points or 
    polygons. ",2018-05-18,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/randgeo,TRUE,https://github.com/ropensci/randgeo,4444,10,1526677301
randomizr,"Generates random assignments for common experimental designs and 
	    random samples for common sampling designs.",2018-07-11,Alexander Coppock,"https://declaredesign.org/r/randomizr/,
https://github.com/DeclareDesign/randomizr",TRUE,https://github.com/declaredesign/randomizr,25276,18,1543948743
randomNames,Function for generating random gender and ethnicity correct first and/or last names. Names are chosen proportionally based upon their probability of appearing in a large scale data base of real names.,2019-03-07,Damian W. Betebenner,"https://CenterForAssessment.github.io/randomNames,
https://github.com/CenterForAssessment/randomNames,
https://cran.r-project.org/package=randomNames",TRUE,https://github.com/centerforassessment/randomnames,28432,7,1552001819
randomsearch,Simple Random Search function for the 'smoof' and 'ParamHelpers' ecosystem with termination criteria and parallelization.,2019-01-17,Jakob Richter  (<https://orcid.org/0000-0003-4481-5554>),https://github.com/jakob-r/randomsearch,TRUE,https://github.com/jakob-r/randomsearch,1975,2,1547720183
randquotes,"Connects to the site <http://quotesondesign.com/> 
            that uses the 'WordPress' JSON REST API 
            to provide a way for you to grab quotes.",2018-05-11,AbdulMajedRaja RS,https://github.com/amrrs/randquotes,TRUE,https://github.com/amrrs/randquotes,1863,7,1536556155
rangeBuilder,"Provides tools for filtering occurrence records, generating alpha-hull-derived range polygons and mapping species distributions. ",2017-05-31,Pascal Title,https://github.com/ptitle/rangeBuilder,TRUE,https://github.com/ptitle/rangebuilder,7527,4,1532474002
rangeMapper,"Tools for easy generation of (life-history) traits maps based on
    species range (extent-of-occurrence) maps.",2019-03-26,Mihai Valcu,https://github.com/valcu/rangeMapper,TRUE,https://github.com/valcu/rangemapper,24153,3,1553615958
ranger,"A fast implementation of Random Forests, particularly suited for high
          dimensional data. Ensembles of classification, regression, survival and
          probability prediction trees are supported. Data from genome-wide association
          studies can be analyzed efficiently. In addition to data frames, datasets of
          class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') 
          can be directly analyzed.",2019-03-07,Marvin N. Wright,https://github.com/imbs-hl/ranger,TRUE,https://github.com/imbs-hl/ranger,349603,410,1554290906
RANN,"Finds the k nearest neighbours for every point in a given dataset
    in O(N log N) time using Arya and Mount's ANN library (v1.1.3). There is
    support for approximate as well as exact searches, fixed radius searches
    and 'bd' as well as 'kd' trees. The distance is computed using the L2
    (Euclidean) metric. Please see package 'RANN.L1' for the same
    functionality using the L1 (Manhattan, taxicab) metric.",2019-01-08,Sunil Arya and David Mount (for ANN),https://github.com/jefferis/RANN,TRUE,https://github.com/jefferis/rann,453993,17,1546975297
rapiclient,"Access services specified in OpenAPI (formerly Swagger) format.
  It is not a code generator. Client is generated dynamically as a list of R 
  functions.",2017-02-14,Darko Bergant,https://github.com/bergant/rapiclient,TRUE,https://github.com/bergant/rapiclient,4385,20,1551863628
rapidraker,"A 'Java' implementation of the RAKE algorithm (Rose, S., Engel, D., 
  Cramer, N. and Cowley, W. (2010) <doi:10.1002/9780470689646.ch1>), which can 
  be used to extract keywords from documents without any training data.",2018-01-05,Christopher Baker,https://crew102.github.io/slowraker/articles/rapidraker.html,TRUE,https://github.com/crew102/rapidraker,2580,1,1532709078
raptr,"Biodiversity is in crisis. The overarching aim of conservation
    is to preserve biodiversity patterns and processes. To this end, protected
    areas are established to buffer species and preserve biodiversity processes.
    But resources are limited and so protected areas must be cost-effective.
    This package contains tools to generate plans for protected areas
    (prioritizations), using spatially explicit targets for biodiversity
    patterns and processes. To obtain solutions in a feasible amount  of time,
    this package uses the commercial 'Gurobi' software package (obtained from
    <http://www.gurobi.com/>). For more information on using
    this package, see Hanson et al. (2017) <doi:10.1111/2041-210X.12862>.",2018-11-26,Jeffrey O Hanson,"https://jeffrey-hanson.com/raptr,
https://github.com/jeffreyhanson/raptr",TRUE,https://github.com/jeffreyhanson/raptr,6609,2,1543272989
rasciidoc,"Inspired by Karl Broman`s reader on using 'knitr'
    with 'asciidoc'
    (<http://kbroman.org/knitr_knutshell/pages/asciidoc.html>), this is
    merely a wrapper to 'knitr' and 'asciidoc'.",2019-03-03,Andreas Dominik Cullmann,https://github.com/fvafrcu/rasciidoc,TRUE,https://github.com/fvafrcu/rasciidoc,416,0,1537358707
rasterize,"Provides R functions to selectively rasterize components
             of 'grid' output.  ",2019-03-06,Paul Murrell,"https://github.com/pmur002/rasterize,
https://stattech.wordpress.fos.auckland.ac.nz/2018/05/25/2018-05-selective-raster-graphics/",TRUE,https://github.com/pmur002/rasterize,304,1,1551667364
rasterVis,"Methods for enhanced visualization and interaction with raster data. It implements visualization methods for quantitative data and categorical data, both for univariate and multivariate rasters. It also provides methods to display spatiotemporal rasters, and vector fields. See the website for examples.",2018-06-02,"Oscar Perpinan Lamigueiro 
    (<https://orcid.org/0000-0002-4134-7196>)",http://oscarperpinan.github.io/rastervis,TRUE,https://github.com/oscarperpinan/rastervis,264306,46,1543487460
ratelimitr,Allows to limit the rate at which one or more functions can be called.,2018-10-07,Tarak Shah,https://github.com/tarakc02/ratelimitr,TRUE,https://github.com/tarakc02/ratelimitr,11467,31,1538939582
ratematrix,"Estimates the evolutionary rate matrix (R) using Markov chain Monte Carlo (MCMC) as described in Caetano and Harmon (2017) <doi:10.1111/2041-210X.12826>. The package has functions to run MCMC chains, plot results, evaluate convergence, and summarize posterior distributions.",2018-10-30,Daniel Caetano,https://github.com/Caetanods/ratematrix,TRUE,https://github.com/caetanods/ratematrix,3190,4,1554233794
RATest,"A collection of randomization tests, data sets and examples. The current version focuses on three testing problems and their implementation in empirical work. First, it facilitates the empirical researcher to test for particular hypotheses, such as comparisons of means, medians, and variances from k populations using robust permutation tests, which asymptotic validity holds under very weak assumptions, while retaining the exact rejection probability in finite samples when the underlying distributions are identical. Second, the description and implementation of a permutation test for testing the continuity assumption of the baseline covariates in the sharp regression discontinuity design (RDD) as in Canay and Kamat (2017) <https://goo.gl/UZFqt7>. More specifically, it allows the user to select a set of covariates and test the aforementioned hypothesis using a permutation test based on the Cramer-von Miss test statistic. Graphical inspection of the empirical CDF and histograms for the variables of interest is also supported in the package. Third, it provides the practitioner with an effortless implementation of a permutation test based on the martingale decomposition of the empirical process for the goodness-of-fit testing problem with an estimated nuisance parameter. An application of this testing problem is the one of testing for heterogeneous treatment effects in a randomized control trial.",2018-11-30,Mauricio Olivares-Gonzalez,NA,TRUE,https://github.com/ignaciomsarmiento/ratest,5504,2,1544037107
raustats,"Functions for downloading Australian economic statistics
  from the Australian Bureau of Statistics (ABS) (see <https://www.abs.gov.au/>) and
  Reserve Bank of Australia (RBA) (see <https://www.rba.gov.au/>) websites.",2019-03-13,David Mitchell,https://github.com/mitcda/raustats,TRUE,https://github.com/mitcda/raustats,216,0,1552729539
rayshader,"Uses a combination of raytracing, spherical texture mapping, lambertian reflectance, and ambient occlusion to produce hillshades of elevation matrices. Includes water detection and layering functions, programmable color palette generation, several built-in textures, 2D and 3D plotting options, and the ability to export 3D maps to a 3D printable format.",2019-02-20,Tyler Morgan-Wall,https://github.com/tylermorganwall/rayshader,TRUE,https://github.com/tylermorganwall/rayshader,5182,589,1554521815
rbgm,"Facilities for working with Atlantis box-geometry model (BGM) 
 files. Atlantis is a deterministic, biogeochemical, whole-of-ecosystem model. 
 Functions are provided to read from BGM files directly, preserving their 
 internal topology, as well as helper functions to generate 'Spatial' objects.
 This functionality aims to simplify the creation and modification of box 
 and geometry as well as the ability to integrate with other data sources. ",2018-05-18,Michael D. Sumner,https://research.csiro.au/atlantis/,TRUE,https://github.com/australianantarcticdivision/rbgm,5115,2,1550027451
rbhl,"Interface to 'Biodiversity' 'Heritage' Library ('BHL')
    (<http://www.biodiversitylibrary.org/>) 'API'
    (<http://www.biodiversitylibrary.org/api2/docs/docs.html>). 'BHL' is a
    repository of 'digitized' literature on 'biodiversity'
    studies, including 'floras', research papers, and more.",2017-04-12,Scott Chamberlain,https://github.com/ropensci/rbhl,TRUE,https://github.com/ropensci/rbhl,14169,13,1540396865
rbi,"Provides a complete R interface to LibBi, a library for Bayesian inference (see <http://libbi.org> and <doi:10.18637/jss.v067.i10> for more information). This includes functions for manipulating LibBi models, for reading and writing LibBi input/output files, for converting LibBi output to provide traces for use with the coda package, and for running LibBi from R.",2019-01-08,Sebastian Funk,https://github.com/libbi/RBi,TRUE,https://github.com/libbi/rbi,6527,13,1553088885
rbi.helpers,"Contains a collection of helper functions to use with 'RBi', the R interface to 'LibBi', described in Murray et al. (2015) <doi:10.18637/jss.v067.i10>. It contains functions to adapt the proposal distribution and number of particles in particle Markov-Chain Monte Carlo, as well as calculating the Deviance Information Criterion (DIC) and converting between times in 'LibBi' results and R time/dates.",2019-02-22,Sebastian Funk <sebastian.funk@lshtm.ac.uk>,"http://libbi.org, https://github.com/sbfnk/RBi,
https://github.com/sbfnk/RBi.helpers",TRUE,https://github.com/sbfnk/rbi,345,13,1553088885
rbin,"Manually bin data using weight of evidence and information value. Includes other binning 
    methods such as equal length, quantile and winsorized. Options for combining levels of categorical
    data are also available. Dummy variables can be generated based on the bins created using any of 
    the available binning methods. References: Siddiqi, N. (2006) <doi:10.1002/9781119201731.biblio>.",2019-01-04,Aravind Hebbali,"https://github.com/rsquaredacademy/rbin,
https://rbin.rsquaredacademy.com",TRUE,https://github.com/rsquaredacademy/rbin,878,6,1548497288
rbison,"Interface to the 'USGS' 'BISON' (<https://bison.usgs.gov/>)
    API, a 'database' for species occurrence data. Data comes from
    species in the United States from participating data providers. You can get
    data via 'taxonomic' and location based queries. A simple function
    is provided to help visualize data.",2018-10-25,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rbison,TRUE,https://github.com/ropensci/rbison,38028,8,1547145845
RBitmoji,"An R wrapper to the overly complicated 'Bitmoji' API allowing users 
  to access and plot various comic strips using their personalized 'Bitstrips'
  avatar (<https://www.bitmoji.com/>).",2018-09-30,Brandon Greenwell  (<https://orcid.org/0000-0002-8120-0084>),https://github.com/bgreenwell/RBitmoji,TRUE,https://github.com/bgreenwell/rbitmoji,1329,22,1543418487
RblDataLicense,"Download prices, market data, and master data with 
    the 'Bloomberg Data License' service from 
    <https://www.bloomberg.com/professional/product/data-license/>. 
    As a prerequisite, you need a valid license from 'Bloomberg'. 
    This software and its author are in no way affiliated, 
    endorsed, or approved by 'Bloomberg' or any of its affiliates.
    'Bloomberg' is a registered trademark.",2019-03-15,Emanuele Guidotti,https://github.com/emanuele-guidotti/RblDataLicense,TRUE,https://github.com/emanuele-guidotti/rbldatalicense,185,1,1553432278
Rblpapi,An R Interface to 'Bloomberg' is provided via the 'Blp API'.,2019-02-21,Whit Armstrong,"http://dirk.eddelbuettel.com/code/rblpapi.html,
https://github.com/Rblp/Rblpapi",TRUE,https://github.com/rblp/rblpapi,56714,108,1553611068
rblt,"An R-shiny application to plot datalogger time series at a microsecond precision as Acceleration, Temperature, 
  Pressure, Light intensity from CATS, AXY-TREK and WACU bio-loggers. It is possible to link behavioral labels extracted
  from 'BORIS' software <http://www.boris.unito.it> or manually written in a csv file.
  CATS bio-logger are manufactured by <http://www.cats.is>, AXY-TREK are manufactured by <http://www.technosmart.eu> and 
  WACU are manufactured by <http://www.iphc.cnrs.fr/-MIBE-.html>.",2019-02-03,Sebastien Geiger,https://github.com/sg4r/rblt,TRUE,https://github.com/sg4r/rblt,472,0,1554467101
Rborist,"Scalable implementation of classification and regression forests, as described by Breiman (2001), <DOI:10.1023/A:1010933404324>.",2019-03-19,Mark Seligman,"http://www.suiji.org/arborist, https://github.com/suiji/Arborist",TRUE,https://github.com/suiji/arborist,26532,61,1554228263
rbraries,"Interface to the 'Libraries.io' API (<https://libraries.io/api>).
    'Libraries.io' indexes data from 36 different package managers for 
    programming languages.",2018-04-18,Scott Chamberlain,https://github.com/ropenscilabs/rbraries,TRUE,https://github.com/ropenscilabs/rbraries,2010,14,1533677710
Rcan,"Tools for basic and advance cancer statistics and graphics.
    Calculates age-specific rate, age-standardized rate, estimated annual
    percentage rate with standards error. Creates graphics across variable and
    time, such as age-specific trends and period-cohort trends.",2018-12-17,Mathieu Laversanne,https://github.com/timat35/Rcan,TRUE,https://github.com/timat35/rcan,2253,3,1548173106
rcartocolor,"Provides color schemes for maps and other graphics
        designed by 'CARTO' as described at <https://carto.com/carto-colors/>.
        It includes four types of palettes: aggregation, diverging, qualitative, 
        and quantitative.",2019-03-08,Jakub Nowosad  (<https://orcid.org/0000-0002-1057-3721>),https://github.com/Nowosad/rcartocolor,TRUE,https://github.com/nowosad/rcartocolor,8629,26,1553013660
rCBA,"Provides implementations of a classifier based on the
    ""Classification Based on Associations"" (CBA). It can be used for building
    classification models from association rules. Rules are pruned in the order of
    precedence given by the sort criteria and a default rule is added. The final
    classifier labels provided instances. CBA was originally proposed by Liu,
    B. Hsu, W. and Ma, Y. Integrating Classification and Association Rule
    Mining. Proceedings KDD-98, New York, 27-31 August. AAAI. pp80-86 (1998, ISBN:1-57735-070-7).",2018-05-16,Jaroslav Kuchar,https://github.com/jaroslav-kuchar/rCBA,TRUE,https://github.com/jaroslav-kuchar/rcba,9226,5,1526500218
rcheology,Provides a dataset of functions in all base packages of R versions 1.0.1 onwards.,2019-03-12,David Hugh-Jones,https://github.com/hughjonesd/rcheology,TRUE,https://github.com/hughjonesd/rcheology,2283,22,1553103148
rchess,"R package for chess validations, pieces movements and check
    detection. Also integrates functions to plot chess boards given a
    Forsyth Edwards and Portable Game notations.",2015-11-05,Joshua Kunst <jbkunst@gmail.com>,https://github.com/jbkunst/rchess,TRUE,https://github.com/jbkunst/rchess,7785,56,1544675719
rchie,"Parses the 'ArchieML' format from the New York Times <http://archieml.org>.
  Also provides utilities for retrieving Google Drive documents for parsing.",2018-11-28,Noam Ross  (<https://orcid.org/0000-0002-2136-0000>),"https://github.com/noamross/rchie,
https://github.com/newsdev/archieml-js",TRUE,https://github.com/noamross/rchie,979,15,1543504780
rcites,A programmatic interface to the Species+ <https://speciesplus.net/> database via the Species+/CITES Checklist API <https://api.speciesplus.net/>.,2018-11-18,Jonas Geschke (<https://orcid.org/0000-0002-5654-9313>),"https://ropensci.github.io/rcites/,
https://github.com/ropensci/rcites",TRUE,https://github.com/ropensci/rcites,2220,10,1554323199
rcitoid,"Client for 'Citoid' (<https://www.mediawiki.org/wiki/Citoid>),
    an API for getting citations for various scholarly work identifiers
    found on 'Wikipedia'.",2019-02-12,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropenscilabs/rcitoid,TRUE,https://github.com/ropenscilabs/rcitoid,419,3,1550186612
Rclean,"To create clearer, more concise code provides this
	     toolbox helps coders to isolate the essential parts of a script that
	     produces a chosen result, such as an object, tables and figures
	     written to disk and even warnings and errors. This work
	     was funded by US National Science Foundation grant
	     SSI-1450277 for applications of End-to-End Data Provenance.",2018-03-23,Matthew K. Lau,https://github.com/ProvTools/Rclean,TRUE,https://github.com/provtools/rclean,2071,7,1549750330
RClickhouse,"'Yandex Clickhouse' (<https://clickhouse.yandex/>) is a high-performance relational column-store database to enable
    big data exploration and 'analytics' scaling to petabytes of data. Methods are
    provided that enable working with 'Yandex Clickhouse' databases via
    'DBI' methods and using 'dplyr'/'dbplyr' idioms.",2018-01-20,Christian Hotz-Behofsits,https://github.com/IMSMWU/RClickhouse,TRUE,https://github.com/imsmwu/rclickhouse,3826,31,1549454946
rclimateca,"The Environment Canada climate archives <http://climate.weather.gc.ca/>
  are an important source of data for climate researchers in Canada and world wide.
  The repository contains temperature, precipitation, and wind data for more than
  8,000 locations. The functions in this package simplify the process of downloading,
  subsetting, and manipulating these data for the purposes of more efficient workflows
  in climate research.",2018-06-11,Dewey Dunnington <dewey@fishandwhistle.net>,https://github.com/paleolimbot/rclimateca,TRUE,https://github.com/paleolimbot/rclimateca,6377,8,1548691828
rclipboard,"Leverages the functionality of 'clipboard.js', a JavaScript library
    for HMTL5-based copy to clipboard from web pages (see <https://clipboardjs.com>
    for more information), and provides a reactive copy-to-clipboard UI button 
    component, called 'rclipButton', for 'shiny' R applications.",2019-03-15,Sebastien Bihorel,http://github.com/sbihorel/rclipboard,TRUE,https://github.com/sbihorel/rclipboard,5322,23,1552612056
RcmdrPlugin.temis,"An 'R Commander' plug-in providing an integrated solution to perform
    a series of text mining tasks such as importing and cleaning a corpus, and
    analyses like terms and documents counts, vocabulary tables, terms
    co-occurrences and documents similarity measures, time series analysis,
    correspondence analysis and hierarchical clustering. Corpora can be imported
    from spreadsheet-like files, directories of raw text files, 'Twitter' queries,
    as well as from 'Dow Jones Factiva', 'LexisNexis', 'Europresse' and 'Alceste' files.",2018-06-22,Milan Bouchet-Valat,https://github.com/nalimilan/R.TeMiS,TRUE,https://github.com/nalimilan/r.temis,41010,11,1546954506
RColetum,"Get your data (forms, structures, answers) from Coletum 
    <https://coletum.com> to handle and analyse.",2018-10-29,André Smaniotto,https://github.com/geo-sapiens/RColetum,TRUE,https://github.com/geo-sapiens/rcoletum,2316,6,1540899167
rcongresso,"Provides propositions, votings, deputies and parties data from 
    Brazilian lower house <https://dadosabertos.camara.leg.br> in data frames.",2018-05-25,Paulo Vinícius Soares,https://github.com/analytics-ufcg/rcongresso,TRUE,https://github.com/analytics-ufcg/rcongresso,3609,29,1553880629
rcoreoa,"Client for the CORE API (<https://core.ac.uk/docs/>).
    CORE (<https://core.ac.uk>) aggregates open access research
    outputs from repositories and journals worldwide and make them
    available to the public.",2018-09-20,Scott Chamberlain,https://github.com/ropensci/rcoreoa,TRUE,https://github.com/ropensci/rcoreoa,3828,12,1537479733
rcorpora,"A collection of small text corpora of interesting data.
    It contains all data sets from 'dariusk/corpora'. Some examples:
    names of animals: birds, dinosaurs, dogs; foods: beer categories,
    pizza toppings; geography: English towns, rivers, oceans;
    humans: authors, US presidents, occupations; science: elements,
    planets; words: adjectives, verbs, proverbs, US president quotes.",2018-07-17,Darius Kazemi,https://github.com/gaborcsardi/rcorpora,TRUE,https://github.com/gaborcsardi/rcorpora,12416,25,1531869557
rcosmo,"Handling and Analysing Spherical, 
      HEALPix and Cosmic Microwave Background data on a HEALPix grid.",2018-11-19,Daniel Fryer  (<https://orcid.org/0000-0001-6032-0522>),https://github.com/VidaliLama/rcosmo,TRUE,https://github.com/vidalilama/rcosmo,1081,7,1554093391
Rcpp,"The 'Rcpp' package provides R functions as well as C++ classes which
 offer a seamless integration of R and C++. Many R data types and objects can be
 mapped back and forth to C++ equivalents which facilitates both writing of new
 code as well as easier integration of third-party libraries. Documentation
 about 'Rcpp' is provided by several vignettes included in this package, via the
 'Rcpp Gallery' site at <http://gallery.rcpp.org>, the paper by Eddelbuettel and
 Francois (2011, <doi:10.18637/jss.v040.i08>), the book by Eddelbuettel (2013,
 <doi:10.1007/978-1-4614-6868-4>) and the paper by Eddelbuettel and Balamuta (2018,
 <doi:10.1080/00031305.2017.1375990>); see 'citation(""Rcpp"")' for details.",2019-03-17,Dirk Eddelbuettel,"http://www.rcpp.org, http://dirk.eddelbuettel.com/code/rcpp.html,
https://github.com/RcppCore/Rcpp",TRUE,https://github.com/rcppcore/rcpp,23564474,442,1553431627
RcppAlgos,"Provides optimized functions implemented in C++ with 'Rcpp'
    for solving problems in combinatorics and computational mathematics.
    Utilizes parallel programming via 'RcppThread' for maximal performance.
    Also makes use of the RMatrix class from the 'RcppParallel' library.
    There are combination/permutation functions with constraint parameters
    that allow for generation of all combinations/permutations of a vector
    meeting specific criteria (e.g. finding all combinations such
    that the sum is between two bounds). Capable of generating specific
    combinations/permutations (e.g. retrieve only the nth lexicographical
    result) which sets up nicely for parallelization as well as random
    sampling. Gmp support permits exploration where the total number of
    results is large (e.g. comboSample(10000, 500, n = 4)). Additionally,
    there are several high performance number theoretic functions that
    are useful for problems common in computational mathematics. Some of
    these functions make use of the fast integer division library
    'libdivide' by <http://ridiculousfish.com>. The primeSieve function
    is based on the segmented sieve of Eratosthenes implementation by
    Kim Walisch. It is also efficient for large numbers by using the
    cache friendly improvements originally developed by Tomás Oliveira.
    Finally, there is a prime counting function that implements Legendre's
    formula based on the algorithm by Kim Walisch.",2019-03-21,Joseph Wood,"https://github.com/jwood000/RcppAlgos, https://gmplib.org/,
http://primesieve.org/,
https://github.com/kimwalisch/primesieve,
https://github.com/kimwalisch/primecount,
http://libdivide.com/,
http://sweet.ua.pt/tos/software/prime_sieve.html",TRUE,https://github.com/jwood000/rcppalgos,10581,11,1553454828
RcppArmadillo,"'Armadillo' is a templated C++ linear algebra library (by Conrad
 Sanderson) that aims towards a good balance between speed and ease of use. Integer,
 floating point and complex numbers are supported, as well as a subset of
 trigonometric and statistics functions. Various matrix decompositions are
 provided through optional integration with LAPACK and ATLAS libraries.
 The 'RcppArmadillo' package includes the header files from the templated
 'Armadillo' library. Thus users do not need to install 'Armadillo' itself in
 order to use 'RcppArmadillo'. From release 7.800.0 on, 'Armadillo' is
 licensed under Apache License 2; previous releases were under licensed as
 MPL 2.0 from version 3.800.0 onwards and LGPL-3 prior to that;
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to Armadillo) is licensed under
 the GNU GPL version 2 or later, as is the rest of 'Rcpp'. Note that
 Armadillo requires a fairly recent compiler; for the g++ family at least
 version 4.6.* is required. ",2019-03-22,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.armadillo.html,TRUE,https://github.com/rcppcore/rcpparmadillo,5811876,88,1553260806
RcppCCTZ,"'Rcpp' Access to the 'CCTZ' timezone library is provided. 'CCTZ' is
 a C++ library for translating between absolute and civil times using the rules
 of a time zone. The 'CCTZ' source code, released under the Apache 2.0 License,
 is included in this package. See <https://github.com/google/cctz> for more
 details.",2018-10-14,Dirk Eddelbuettel,https://github.com/eddelbuettel/rcppcctz,TRUE,https://github.com/eddelbuettel/rcppcctz,150769,15,1539527850
RcppCNPy,"The 'cnpy' library written by Carl Rogers provides read and write
 facilities for files created with (or for) the 'NumPy' extension for 'Python'.
 Vectors and matrices of numeric types can be read or written to and from
 files as well as compressed files. Support for integer files is available if
 the package has been built with -std=c++11 which should be the default on
 all platforms since the release of R 3.3.0.",2018-07-29,Dirk Eddelbuettel and Wush Wu,http://dirk.eddelbuettel.com/code/rcpp.cnpy.html,TRUE,https://github.com/eddelbuettel/rcppcnpy,22086,19,1554516863
RcppCWB,"'Rcpp' Bindings for the C code of the 'Corpus Workbench' ('CWB'), an indexing and query 
  engine to efficiently analyze large corpora (<http://cwb.sourceforge.net>). 'RcppCWB' is licensed
  under the GNU GPL-3, in line with the GPL-3 license of the 'CWB' (<https://www.r-project.org/
  Licenses/GPL-3>). The 'CWB' relies on 'pcre' (BSD license, see <https://www.pcre.org/
  licence.txt>) and 'GLib' (LGPL license, see <https://www.gnu.org/licenses/lgpl-3.0.en.
  html>). See the file LICENSE.note for further information. The package includes modified code of the
  'rcqp' package (GPL-2, see <https://cran.r-project.org/package=rcqp>). The original work of the authors
  of the 'rcqp' package is acknowledged with great respect, and they are listed as authors of this
  package. To achieve cross-platform portability (including Windows), using 'Rcpp' for wrapper code
  is the approach used by 'RcppCWB'.",2019-02-21,Andreas Blaette,https://www.github.com/PolMine/RcppCWB,TRUE,https://github.com/polmine/rcppcwb,5664,1,1547624408
RcppDist,"The 'Rcpp' package provides a C++ library to make it easier
    to use C++ with R. R and 'Rcpp' provide functions for a variety of
    statistical distributions. Several R packages make functions
    available to R for additional statistical distributions. However,
    to access these functions from C++ code, a costly call to the R
    functions must be made. 'RcppDist' provides a header-only C++ library
    with functions for additional statistical distributions that can be
    called from C++ when writing code using 'Rcpp' or 'RcppArmadillo'.
    Functions are available that return a 'NumericVector' as well as
    doubles, and for multivariate or matrix distributions, 'Armadillo'
    vectors and matrices. 'RcppDist' provides functions for the following
    distributions: the four parameter beta distribution; the location-
    scale t distribution; the truncated normal distribution; the
    truncated t distribution; a truncated location-scale t distribution;
    the triangle distribution; the multivariate normal distribution*;
    the multivariate t distribution*; the Wishart distribution*; and
    the inverse Wishart distribution*. Distributions marked with an
    asterisk rely on 'RcppArmadillo'.",2018-10-28,JB Duck-Mayr  (<https://orcid.org/0000-0002-2231-1294>),https://github.com/duckmayr/RcppDist,TRUE,https://github.com/duckmayr/rcppdist,1199,2,1551960500
RcppDynProg,Dynamic Programming implemented in 'Rcpp'.  Includes example partition and out of sample fitting applications.  Also supplies additional custom coders for the 'vtreat' package.,2019-03-31,John Mount,"https://github.com/WinVector/RcppDynProg/,
https://winvector.github.io/RcppDynProg/",TRUE,https://github.com/winvector/rcppdynprog,1154,7,1554060312
RcppEigen,"R and 'Eigen' integration using 'Rcpp'.
 'Eigen' is a C++ template library for linear algebra: matrices, vectors,
 numerical solvers and related algorithms.  It supports dense and sparse
 matrices on integer, floating point and complex numbers, decompositions of
 such matrices, and solutions of linear systems. Its performance on many
 algorithms is comparable with some of the best implementations based on
 'Lapack' and level-3 'BLAS'. The 'RcppEigen' package includes the header
 files from the 'Eigen' C++ template library (currently version 3.3.4). Thus
 users do not need to install 'Eigen' itself in order to use 'RcppEigen'.
 Since version 3.1.1, 'Eigen' is licensed under the Mozilla Public License
 (version 2); earlier version were licensed under the GNU LGPL version 3 or
 later. 'RcppEigen' (the 'Rcpp' bindings/bridge to 'Eigen') is licensed under
 the GNU GPL version 2 or later, as is the rest of 'Rcpp'.",2018-11-24,Douglas Bates,http://dirk.eddelbuettel.com/code/rcpp.eigen.html,TRUE,https://github.com/rcppcore/rcppeigen,5935105,47,1553887569
RcppEnsmallen,"'Ensmallen' is a templated C++ mathematical optimization library 
 (by the 'MLPACK' team) that provides a simple set of abstractions for writing an
 objective function to optimize. Provided within are various standard and
 cutting-edge optimizers that include full-batch gradient descent techniques, 
 small-batch techniques, gradient-free optimizers, and constrained optimization.
 The 'RcppEnsmallen' package includes the header files from the 'Ensmallen' library
 and pairs the appropriate header files from 'armadillo' through the 
 'RcppArmadillo' package. Therefore, users do not need to install 'Ensmallen' nor
 'Armadillo' to use 'RcppEnsmallen'. Note that 'Ensmallen' is licensed under 
 3-Clause BSD, 'Armadillo' starting from 7.800.0 is licensed under Apache License 2,
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to 'Armadillo') is licensed under 
 the GNU GPL version 2 or later. Thus, 'RcppEnsmallen' is also licensed under
 similar terms. Note that 'Ensmallen' requires a compiler that supports 
 'C++11' and 'Armadillo' 6.500 or later.",2019-03-10,James Joseph Balamuta,"https://github.com/coatless/rcppensmallen,
https://github.com/mlpack/ensmallen, http://ensmallen.org/",TRUE,https://github.com/coatless/rcppensmallen,1740,13,1552195460
RcppExamples,"Examples for Seamless R and C++ integration
 The 'Rcpp' package contains a C++ library that facilitates the integration of
 R and C++ in various ways. This package provides some usage examples.

   Note that the documentation in this package currently does not cover all the
 features in the package. It is not even close. On the other hand, the site
 <http://gallery.rcpp.org> is regrouping a large number of examples for 'Rcpp'.",2016-11-24,Dirk Eddelbuettel and Romain Francois,http://dirk.eddelbuettel.com/code/rcpp.html,TRUE,https://github.com/eddelbuettel/rcppexamples,18094,20,1537645884
RcppGetconf,"The 'getconf' command-line tool provided by 'libc' allows
 querying of a large number of system variables. This package provides
 similar functionality.",2018-11-16,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.getconf.html,TRUE,https://github.com/eddelbuettel/rcppgetconf,2086,1,1545606564
RcppMeCab,"R package based on 'Rcpp' for 'MeCab': Yet Another Part-of-Speech and Morphological Analyzer. 
	The purpose of this package is providing a seamless developing and analyzing environment for CJK texts.
	This package utilizes parallel programming for providing highly efficient text preprocessing 'posParallel()' function.
	For installation, please refer to README.md file.",2018-07-04,Junhewk Kim,NA,TRUE,https://github.com/junhewk/rcppmecab,2069,11,1530742763
RcppMsgPack,"'MsgPack' header files are provided for use by R packages, along 
 with the ability to access, create and alter 'MsgPack' objects directly from R.
 'MsgPack' is an efficient binary serialization format. It lets you exchange
 data among multiple languages like 'JSON' but it is faster and smaller.
 Small integers are encoded into a single byte, and typical short strings
 require only one extra byte in addition to the strings themselves. This
 package provides headers from the 'msgpack-c' implementation for C and
 C++(11) for use by R, particularly 'Rcpp'. The included 'msgpack-c' headers
 are licensed under the Boost Software License (Version 1.0); the code added
 by this package as well the R integration are licensed under the GPL (>= 2).
 See the files 'COPYRIGHTS' and 'AUTHORS' for a full list of  copyright holders
 and contributors to 'msgpack-c'.  ",2018-11-18,Travers Ching and Dirk Eddelbuettel; the authors and contributors of MsgPack,NA,TRUE,https://github.com/eddelbuettel/rcppmsgpack,4426,8,1542583253
RcppParallel,"High level functions for parallel programming with 'Rcpp'.
    For example, the 'parallelFor()' function can be used to convert the work of
    a standard serial ""for"" loop into a parallel one and the 'parallelReduce()'
    function can be used for accumulating aggregate or other values.",2018-12-11,Kevin Ushey,"http://rcppcore.github.io/RcppParallel,
https://github.com/RcppCore/RcppParallel",TRUE,https://github.com/rcppcore/rcppparallel,462797,107,1549166748
RcppProgress,"Allows to display a progress bar in the R
    console for long running computations taking place in c++ code,
    and support for interrupting those computations even in multithreaded
    code, typically using OpenMP.",2018-05-11,Karl Forner <karl.forner@gmail.com>,https://github.com/kforner/rcpp_progress,TRUE,https://github.com/kforner/rcpp_progress,215753,19,1526044434
RcppStreams,"The 'Streamulus' (template, header-only) library by
 Irit Katriel (at <https://github.com/iritkatriel/streamulus>)
 provides a very powerful yet convenient framework for stream
 processing. This package connects 'Streamulus' to R by providing 
 both the header files and all examples.",2019-02-25,Dirk Eddelbuettel <edd@debian.org>,http://dirk.eddelbuettel.com/code/rcpp.streams.html,TRUE,https://github.com/eddelbuettel/rcppstreams,10125,14,1546745562
RcppThread,"Provides a C++11-style thread class and thread pool that can safely
    be interrupted from R; see, Nagler (2018) <arXiv:1811.00450>.",2018-11-23,Thomas Nagler,https://github.com/tnagler/RcppThread,TRUE,https://github.com/tnagler/rcppthread,11664,18,1543928068
RcppTOML,"The configuration format defined by 'TOML' (which expands to
 ""Tom's Obvious Markup Language"") specifies an excellent format (described at
 <https://github.com/toml-lang/toml>) suitable for both human editing as well
 as the common uses of a machine-readable format. This package uses 'Rcpp' to
 connect the 'cpptoml' parser written by Chase Geigle (in modern C++11) to R.",2018-10-31,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rcpp.toml.html,TRUE,https://github.com/eddelbuettel/rcpptoml,22552,16,1548522735
RcppXPtrUtils,"Provides the means to compile user-supplied C++ functions with
  'Rcpp' and retrieve an 'XPtr' that can be passed to other C++ components.",2019-01-21,Iñaki Ucar,https://github.com/Enchufa2/RcppXPtrUtils,TRUE,https://github.com/enchufa2/rcppxptrutils,3953,13,1548087641
Rcrawler,"Performs parallel web crawling and web scraping. It is designed to crawl, parse and store web pages to produce data that can be directly used for analysis application. For details see Khalil and Fakir (2017) <DOI:10.1016/j.softx.2017.04.004>.",2018-11-11,Salim Khalil  (<https://orcid.org/0000-0002-7804-4041>),https://github.com/salimk/Rcrawler/,TRUE,https://github.com/salimk/rcrawler,16927,169,1549122215
rcrossref,"Client for various 'CrossRef' 'APIs', including 'metadata' search
    with their old and newer search 'APIs', get 'citations' in various formats
    (including 'bibtex', 'citeproc-json', 'rdf-xml', etc.), convert 'DOIs'
    to 'PMIDs', and 'vice versa', get citations for 'DOIs', and get links to
    full text of articles when available.",2019-01-14,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rcrossref,TRUE,https://github.com/ropensci/rcrossref,29838,84,1553001003
rcrtan,"Contains methods for criterion-referenced test analyses as 
    described in Brown & Hudson (2002). This includes cut-score item discrimination 
    analyses and measures of dependability.",2018-12-19,Geoffrey T. LaFlair,https://github.com/gtlaflair/rcrtan,TRUE,https://github.com/gtlaflair/rcrtan,1959,2,1545196869
rcv,"A collection of ranked choice voting data and functions to 
    manipulate, run elections with, and visualize this data and others. 
    It can bring in raw data, transform it into a ballot you can read, 
    and return election results for an RCV contest.",2017-08-11,Matthew Yancheff,https://github.com/ds-elections/rcv,TRUE,https://github.com/ds-elections/rcv,3586,5,1554487369
RCzechia,"Administrative regions, rivers and water bodies of the Czech Republic.",2019-04-05,Jindra Lacko,https://github.com/jlacko/RCzechia,TRUE,https://github.com/jlacko/rczechia,3562,8,1554460046
Rd,"Creation and manipulation of R documentation (Rd) as 
    R objects.  Also contains functions for checking consistency 
    of Rd and S4 generics and methods for converting  
    objects to Rd formatted output.",2019-01-17,Andrew Redd,https://github.com/RDocTaskForce/Rd,TRUE,https://github.com/rdoctaskforce/rd,614,3,1548460069
Rd2roxygen,"Functions to convert Rd to 'roxygen' documentation. It can parse an
    Rd file to a list, create the 'roxygen' documentation and update the original
    R script (e.g. the one containing the definition of the function)
    accordingly. This package also provides utilities that can help developers
    build packages using 'roxygen' more easily. The 'formatR' package can be used
    to reformat the R code in the examples sections so that the code will be
    more readable.",2019-03-05,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/yihui/Rd2roxygen,TRUE,https://github.com/yihui/rd2roxygen,22627,19,1551802880
rdatacite,"Client for the web service methods provided
    by 'DataCite' (<https://www.datacite.org/>), including functions to interface with
    their 'OAI-PMH' 'metadata' service, and a 'RESTful' search API. The API
    is backed by 'SOLR', allowing expressive queries, including faceting,
    statistics on variables, and 'more-like-this' queries.",2018-05-27,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rdatacite,TRUE,https://github.com/ropensci/rdatacite,8084,18,1548972386
rdataretriever,"Provides an R interface to the Data Retriever
    <http://data-retriever.org/> via the Data Retriever's
    command line interface. The Data Retriever automates the
    tasks of finding, downloading, and cleaning public datasets,
    and then stores them in a local database.",2017-03-11,Daniel McGlinn,https://github.com/ropensci/rdataretriever/,TRUE,https://github.com/ropensci/rdataretriever,4699,22,1553022016
rdbnomics,"R access to hundreds of millions data series from DBnomics API
    (<https://db.nomics.world/>).",2019-03-19,Sebastien Galais,https://github.com/dbnomics/rdbnomics,TRUE,https://github.com/dbnomics/rdbnomics,1898,8,1552838027
rde,"Allows caching of raw data directly in R code. This allows R
  scripts and R Notebooks to be shared and re-run on a machine without access
  to the original data. Cached data is encoded into an ASCII string that can
  be pasted into R code. When the code is run, the data is automatically
  loaded from the cached version if the original data file is unavailable.
  Works best for small datasets (a few hundred observations).",2018-07-02,Stefan Kloppenborg,https://github.com/kloppen/rde,TRUE,https://github.com/kloppen/rde,1708,1,1530531556
rdefra,Get data from DEFRA's UK-AIR website <https://uk-air.defra.gov.uk/>. It basically scrapes the HTML content.,2019-03-18,Claudia Vitolo  (<https://orcid.org/0000-0002-4252-1176>),https://github.com/ropensci/rdefra,TRUE,https://github.com/ropensci/rdefra,5838,9,1534348070
rdflib,"The Resource Description Framework, or 'RDF' is a widely used
             data representation model that forms the cornerstone of the 
             Semantic Web. 'RDF' represents data as a graph rather than 
             the familiar data table or rectangle of relational databases.
             The 'rdflib' package provides a friendly and concise user interface
             for performing common tasks on 'RDF' data, such as reading, writing
             and converting between the various serializations of 'RDF' data,
             including 'rdfxml', 'turtle', 'nquads', 'ntriples', and 'json-ld';
             creating new 'RDF' graphs, and performing graph queries using 'SPARQL'.
             This package wraps the low level 'redland' R package which
             provides direct bindings to the 'redland' C library.  Additionally,
             the package supports the newer and more developer friendly
             'JSON-LD' format through the 'jsonld' package. The package
             interface takes inspiration from the Python 'rdflib' library.",2019-01-15,Carl Boettiger,https://github.com/ropensci/rdflib,TRUE,https://github.com/ropensci/rdflib,5376,13,1547598428
rdfp,"An implementation of Google's 'DoubleClick for Publishers' (DFP) API 
    <https://developers.google.com/ad-manager/api/start> (recently renamed to 
    'Google Ad Manager'). This package is automatically compiled from the API WSDLs 
    (Web Service Description Language) files to dictate how the API is structured. 
    Theoretically, all API actions are possible using this package; however, care 
    must be taken to format the inputs correctly and parse the outputs correctly 
    as well. Please see Google's DFP API reference and this package's website 
    <https://stevenmmortimer.github.io/rdfp/> for more information, documentation, 
    and examples.",2019-01-07,Steven M. Mortimer,https://github.com/StevenMMortimer/rdfp,TRUE,https://github.com/stevenmmortimer/rdfp,2376,13,1546097679
rdhs,"Provides a client for (1) querying the DHS API for survey indicators
  and metadata (<https://api.dhsprogram.com/#/index.html>), (2) identifying surveys
  and datasets for analysis, (3) downloading survey datasets from the DHS website,
  (4) loading datasets and associate metadata into R, and (5) extracting variables
  and combining datasets for pooled analysis.",2019-03-19,OJ Watson  (<https://orcid.org/0000-0003-2374-0741>),https://ropensci.github.io/rdhs/,TRUE,https://github.com/ropensci/rdhs,1199,15,1553006971
RDieHarder,"The 'RDieHarder' package provides an R interface to 
 the 'DieHarder' suite of random number generators and tests that 
 was developed by Robert G. Brown and David Bauer, extending 
 earlier work by George Marsaglia and others. The 'DieHarder'
 library is included, but if a version is already installed
 it will be used instead.",2018-12-21,Dirk Eddelbuettel <edd@debian.org>,https://github.com/eddelbuettel/rdieharder,TRUE,https://github.com/eddelbuettel/rdieharder,8984,3,1545394261
Rdimtools,"We provide linear and nonlinear dimension reduction techniques.
	Intrinsic dimension estimation methods for exploratory analysis are also provided.
    For more details on dimensionality techniques, see the paper by
    Ma and Zhu (2013) <doi:10.1111/j.1751-5823.2012.00182.x> if you are interested in
    statistical approach, or Engel, Huttenberger, and Hamann (2012)
    <doi:10.4230/OASIcs.VLUDS.2011.135> for a broader multi-disciplinary overview.",2018-12-21,Kisung You  (<https://orcid.org/0000-0002-8584-459X>),http://github.com/kisungyou/Rdimtools,TRUE,https://github.com/kisungyou/rdimtools,7955,2,1553543018
rdist,A common framework for calculating distance matrices.,2018-05-18,Nello Blaser,https://github.com/blasern/rdist,TRUE,https://github.com/blasern/rdist,9730,10,1531244924
rdiversity,"Provides a framework for the measurement and partitioning of
    the (similarity-sensitive) biodiversity of a metacommunity and its
    constituent subcommunities. Richard Reeve, et al. (2016) 
    <arXiv:1404.6520v3>.",2018-06-19,Sonia Mitchell  (<https://orcid.org/0000-0003-1536-2066>),https://github.com/boydorr/rdiversity,TRUE,https://github.com/boydorr/rdiversity,3635,2,1550757974
RDML,"Imports real-time thermo cycler (qPCR) data from Real-time PCR
    Data Markup Language (RDML) and transforms to the appropriate formats of
    the 'qpcR' and 'chipPCR' packages. Contains a dendrogram visualization 
    for the structure of RDML object and GUI for RDML editing.",2017-09-25,Konstantin A. Blagodatskikh,https://github.com/kablag/RDML,TRUE,https://github.com/kablag/rdml,14071,13,1553789389
rdnb,"A wrapper for the 'Deutsche Nationalbibliothek (German National
    Library) API', available at <http://www.dnb.de>. The German National Library is
    the German central archival library, collecting, archiving, bibliographically
    classifying all German and German-language publications, foreign
    publications about Germany, translations of German works, and the works of
    German-speaking emigrants published abroad between 1933 and 1945. A personal
    access token is required for usage.",2018-09-15,Christian Graul,https://github.com/chgrl/rdnb,TRUE,https://github.com/chgrl/rdnb,5621,1,1554497190
RDocumentation,"Wraps around the default help functionality in R. Instead of plain documentation files, documentation will show up as it does on <https://www.rdocumentation.org>, a platform that shows R documentation from 'CRAN', 'GitHub' and 'Bioconductor', together with informative stats to assess the package quality.",2018-01-23,Ludovic Vannoorenberghe,"https://www.rdocumentation.org, https://www.datacamp.com",TRUE,https://github.com/datacamp/rdocumentation,11587,147,1527862409
rdoxygen,"Create doxygen documentation for source code in R packages. 
  Includes a RStudio Addin, that allows to trigger the doxygenize process.",2017-05-25,Clemens Schmid,https://github.com/nevrome/rdoxygen,TRUE,https://github.com/nevrome/rdoxygen,3011,1,1552419417
Rdpack,"Functions for manipulation of R documentation objects,
    including functions reprompt() and ereprompt() for updating 'Rd'
    documentation for functions, methods and classes; 'Rd' macros for
    citations and import of references from 'bibtex' files for use in
    'Rd' files and 'roxygen2' comments; 'Rd' macros for evaluating and
    inserting snippets of 'R' code and the results of its evaluation or
    creating graphics on the fly; and many functions for manipulation of
    references and Rd files.",2018-10-04,Georgi N. Boshnakov,https://github.com/GeoBosh/Rdpack,TRUE,https://github.com/geobosh/rdpack,101048,3,1554477711
rdrop2,"Provides full programmatic access to the 'Dropbox' file hosting platform <https://dropbox.com>, including support for all standard file operations.",2017-09-29,Karthik Ram,NA,TRUE,https://github.com/karthik/rdrop2,30482,178,1550524825
rdryad,"Interface to the Dryad ""Solr"" API, their ""OAI-PMH"" service, and
    fetch datasets. Dryad (<http://datadryad.org/>) is a curated host of
    data underlying scientific publications.",2018-06-18,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rdryad,TRUE,https://github.com/ropensci/rdryad,21659,18,1539795793
rdtLite,"Defines functions that can be used to collect provenance as
  an R script executes or during a console session. The output is a text 
  file in PROV-JSON format.",2018-11-30,Barbara Lerner,https://github.com/End-to-end-provenance/rdtLite,TRUE,https://github.com/end-to-end-provenance/rdtlite,894,1,1544590818
rdwd,"Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see 
             <https://www.dwd.de/EN/climate_environment/cdc/cdc.html> for more information).
             Choose files with 'selectDWD()', download and process data sets with 'dataDWD()' and 'readDWD()'.",2019-03-17,Berry Boessenkool,https://github.com/brry/rdwd,TRUE,https://github.com/brry/rdwd,7110,15,1554509666
reactlog,"Building interactive web applications with R is incredibly easy
  with 'shiny'. Behind the scenes, 'shiny' builds a reactive graph that can
  quickly become intertwined and difficult to debug. 'reactlog' 
  (Schloerke 2019) <doi:10.5281/zenodo.2591517> provides a visual insight into
  that black box of 'shiny' reactivity by constructing a directed dependency
  graph of the application's reactive state at any time point in a reactive
  recording.",2019-03-22,Barret Schloerke  (<https://orcid.org/0000-0001-9986-114X>),"https://rstudio.github.io/reactlog/,
https://github.com/rstudio/reactlog,
https://community.rstudio.com/tags/reactlog",TRUE,https://github.com/rstudio/reactlog,189,29,1553884141
reactR,"Make it easy to use 'React' in R with 'htmlwidget' scaffolds,
              helper dependency functions, an embedded 'Babel' 'transpiler',
              and examples.",2019-01-15,Facebook Inc,https://github.com/react-R/reactR,TRUE,https://github.com/react-r/reactr,8374,106,1550604671
readabs,"Downloads, imports, and tidies time series data from the 
    Australian Bureau of Statistics <https://www.abs.gov.au/>.",2019-02-01,Matt Cowgill,https://github.com/mattcowgill/readabs,TRUE,https://github.com/mattcowgill/readabs,2492,14,1549082456
readbitmap,"Identifies and reads Windows BMP, JPEG, PNG, and TIFF format bitmap
    images. Identification defaults to the use of the magic number embedded in
    the file rather than the file extension. Reading of JPEG and PNG image
    depends on libjpg and libpng libraries. See file INSTALL for details if
    necessary.",2018-06-27,Gregory Jefferis  (<https://orcid.org/0000-0002-0587-9355>),https://github.com/jefferis/readbitmap,TRUE,https://github.com/jefferis/readbitmap,136704,4,1530100121
readbulk,"Combine multiple data files from a common directory.
    The data files will be read into R and bound together, creating a
    single large data.frame. A general function is provided along with
    a specific function for data that was collected using the open-source
    experiment builder 'OpenSesame' <http://osdoc.cogsci.nl/>.",2019-02-02,Pascal J. Kieslich  (<https://orcid.org/0000-0002-0853-9364>),https://github.com/pascalkieslich/readbulk,TRUE,https://github.com/pascalkieslich/readbulk,11123,4,1551951222
readJDX,"Import data written in the JCAMP-DX format. This is an instrument-independent format used in the field of spectroscopy. Examples include IR, NMR, and Raman spectroscopy. See the vignette for background and supported formats.  The official JCAMP-DX site is <http://www.jcamp-dx.org/>.",2018-10-15,Bryan A. Hanson  (ORCID 0000-0003-3536-8246),https://github.com/bryanhanson/readJDX,TRUE,https://github.com/bryanhanson/readjdx,5169,1,1539627560
readobj,"Wraps 'tiny_obj_loader' C++ library for reading the 'Wavefront' OBJ
    3D file format including both mesh objects and materials files. The
    resultant R objects are either structured to match the 'tiny_obj_loader'
    internal data representation or in a form directly compatible with the 'rgl'
    package.",2019-03-11,Gregory Jefferis,https://github.com/jefferis/readobj,TRUE,https://github.com/jefferis/readobj,3431,5,1552303692
readr,"The goal of 'readr' is to provide a fast and friendly way to read
    rectangular data (like 'csv', 'tsv', and 'fwf'). It is designed to flexibly
    parse many types of data found in the wild, while still cleanly failing when
    data unexpectedly changes.",2018-12-21,Jim Hester,"http://readr.tidyverse.org, https://github.com/tidyverse/readr",TRUE,https://github.com/tidyverse/readr,7158461,688,1550764450
readsdmx,"Read Statistical Data and Metadata Exchange (SDMX) XML data. 
    This the main transmission format used in official statistics. Data can be imported from
    local SDMX-ML files or a SDMX web-service and will be read in 'as is' into a dataframe object.
    The 'RapidXML' C++ library <http://rapidxml.sourceforge.net> is used to parse the XML data.",2019-02-01,Matthew de Queljoe,https://github.com/mdequeljoe/readsdmx,TRUE,https://github.com/mdequeljoe/readsdmx,553,1,1550735066
readstata13,Function to read and write the 'Stata' file format.,2018-05-26,"Sebastian Jeworutzki 
    (<https://orcid.org/0000-0002-2671-5253>)",https://github.com/sjewo/readstata13,TRUE,https://github.com/sjewo/readstata13,453450,31,1531043703
readtext,"Functions for importing and handling text files and formatted text
    files with additional meta-data, such including '.csv', '.tab', '.json', '.xml',
    '.html', '.pdf', '.doc', '.docx', '.xls', '.xlsx', and others.",2018-05-10,Kenneth Benoit,http://github.com/quanteda/readtext,TRUE,https://github.com/quanteda/readtext,84777,65,1545905753
readxl,"Import excel files into R. Supports '.xls' via the
    embedded 'libxls' C library <https://github.com/libxls/libxls> and
    '.xlsx' via the embedded 'RapidXML' C++ library
    <http://rapidxml.sourceforge.net>.  Works on Windows, Mac and Linux
    without external dependencies.",2019-03-13,Hadley Wickham (<https://orcid.org/0000-0003-4757-117X>),"https://readxl.tidyverse.org, https://github.com/tidyverse/readxl",TRUE,https://github.com/tidyverse/readxl,6305585,499,1552495173
rebird,"A programmatic client for the eBird database, including functions
    for searching for bird observations by geographic location (latitude,
    longitude), eBird hotspots, location identifiers, by notable sightings, by
    region, and by taxonomic name.",2018-09-27,Sebastian Pardo  (<https://orcid.org/0000-0002-4147-5796>),http://github.com/ropensci/rebird,TRUE,https://github.com/ropensci/rebird,36850,39,1553445291
RECA,"Relevant Component Analysis (RCA) tries to find a linear
    transformation of the feature space such that the effect of irrelevant
    variability is reduced in the transformed space.",2018-05-16,Nan Xiao  (<https://orcid.org/0000-0002-0250-5673>),"https://nanx.me/RECA/, https://github.com/road2stat/RECA",TRUE,https://github.com/road2stat/reca,11073,5,1552883295
recexcavAAR,A toolset for 3D reconstruction and analysis of excavations. It provides methods to reconstruct natural and artificial surfaces based on field measurements. This allows to spatially contextualize documented subunits and features. Intended to be part of a 3D visualization workflow.,2017-02-25,Clemens Schmid,https://github.com/ISAAKiel/recexcavAAR,TRUE,https://github.com/isaakiel/recexcavaar,4817,7,1544777384
recipes,"An extensible framework to create and preprocess 
    design matrices. Recipes consist of one or more data manipulation 
    and analysis ""steps"". Statistical parameters for the steps can 
    be estimated from an initial data set and then applied to 
    other data sets. The resulting design matrices can then be used 
    as inputs into statistical or machine learning models. ",2019-03-21,Max Kuhn,https://github.com/tidymodels/recipes,TRUE,https://github.com/tidymodels/recipes,1363047,225,1553216733
reclin,"Functions to assist in performing probabilistic record linkage and
    deduplication: generating pairs, comparing records, em-algorithm for
    estimating m- and u-probabilities, forcing one-to-one matching. Can also be
    used for pre- and post-processing for machine learning methods for record
    linkage.",2018-08-09,Jan van der Laan,https://github.com/djvanderlaan/reclin,TRUE,https://github.com/djvanderlaan/reclin,2006,9,1533823569
recmap,"Provides an interface and a C++ implementation of the RecMap MP2
  construction heuristic (see 'citation(""recmap"")' for details). This algorithm
  draws maps according to a given statistical value (e.g., election results,
  population or epidemiological data). The basic idea of the RecMap algorithm is
  that each map region (e.g., different countries) is represented by a
  rectangle. The area of each rectangle represents the statistical value given
  as input (maintain zero cartographic error). Documentation about RecMap is
  provided by a vignette included in this package.",2019-03-07,Christian Panse  (<https://orcid.org/0000-0003-1975-3064>),NA,TRUE,https://github.com/cpanse/recmap,17478,12,1552134339
recommenderlab,"Provides a research infrastructure to test and develop
    recommender algorithms including UBCF, IBCF, FunkSVD and association
    rule-based algorithms.",2019-03-23,Michael Hahsler,https://github.com/mhahsler/recommenderlab,TRUE,https://github.com/mhahsler/recommenderlab,100622,128,1554412497
reconstructr,"Functions to reconstruct sessions from web log or other user trace data
             and calculate various metrics around them, producing tabular,
             output that is compatible with 'dplyr' or 'data.table' centered processes.",2018-07-26,Oliver Keyes,https://github.com/Ironholds/reconstructr,TRUE,https://github.com/ironholds/reconstructr,9673,25,1533157445
REDCapR,"Encapsulates functions to streamline calls from R to the REDCap
    API.  REDCap (Research Electronic Data CAPture) is a web application for
    building and managing online surveys and databases developed at Vanderbilt
    University.  The Application Programming Interface (API) offers an avenue
    to access and modify data programmatically, improving the capacity for
    literate and reproducible programming.",2017-05-18,Will Beasley,"https://github.com/OuhscBbmc/REDCapR, http://ouhsc.edu/bbmc/,
http://project-redcap.org",TRUE,https://github.com/ouhscbbmc/redcapr,14920,37,1549519286
REddyProc,"Standard and extensible Eddy-Covariance data post-processing 
  (Wutzler et al. (2018) <doi:10.5194/bg-15-5015-2018>)
  includes  
  uStar-filtering, gap-filling, and flux-partitioning.
  The Eddy-Covariance (EC)  micrometeorological technique quantifies continuous 
  exchange fluxes of gases, energy, and momentum between an ecosystem and the atmosphere.
  It is important for understanding ecosystem dynamics and upscaling exchange fluxes.
  (Aubinet et al. (2012) <doi:10.1007/978-94-007-2351-1>).
  This package inputs pre-processed (half-)hourly data and supports further processing. 
  First, a quality-check and filtering is performed based on the relationship between 
  measured flux and friction
  velocity (uStar) to discard biased data 
  (Papale et al. (2006) <doi:10.5194/bg-3-571-2006>).
  Second, gaps in the data are filled based on information from environmental conditions
  (Reichstein et al. (2005) <doi:10.1111/j.1365-2486.2005.001002.x>).
  Third, the net flux of carbon dioxide is partitioned
  into its gross fluxes in and out of the ecosystem by night-time 
  based and day-time based approaches
  (Lasslop et al. (2010) <doi:10.1111/j.1365-2486.2009.02041.x>).",2019-03-30,Thomas Wutzler,"https://www.bgc-jena.mpg.de/bgi/index.php/Services/REddyProcWeb,
https://github.com/bgctw/REddyProc",TRUE,https://github.com/bgctw/reddyproc,5891,15,1554225055
REddyProcNCDF,Extension to 'REddyProc' that allows reading data from netCDF files.,2018-05-11,Thomas Wutzler,https://github.com/bgctw/REddyProcNCDF,TRUE,https://github.com/bgctw/reddyprocncdf,1793,0,1525866935
redist,"Enables researchers to sample redistricting plans from a pre-
    specified target distribution using a Markov Chain Monte Carlo algorithm.
    The package allows for the implementation of various constraints in the
    redistricting process such as geographic compactness and population parity
    requirements. The algorithm also can be used in combination with efficient
    simulation methods such as simulated and parallel tempering algorithms. Tools
    for analysis such as inverse probability reweighting and plotting functionality
    are included. The package implements methods described in Fifield, Higgins, Imai
    and Tarr (2016) ``A New Automated Redistricting Simulator Using Markov Chain
    Monte Carlo,'' working paper available at
    <https://imai.fas.harvard.edu/research/files/redist.pdf>.",2018-12-15,Ben Fifield <bfifield@princeton.edu>,NA,TRUE,https://github.com/kosukeimai/redist,10373,8,1548942788
redlistr,"A toolbox created by members of the International Union for
    Conservation of Nature (IUCN) Red List of Ecosystems Committee for
    Scientific Standards. Primarily, it is a set of tools suitable
    for calculating the metrics required for making assessments of species and
    ecosystems against the IUCN Red List of Threatened Species and the IUCN Red
    List of Ecosystems categories and criteria. See the IUCN website for
    detailed guidelines, the criteria, publications and other information.",2018-11-02,Calvin Lee  (<https://orcid.org/0000-0001-8277-8614>),https://github.com/red-list-ecosystem/redlistr,TRUE,https://github.com/red-list-ecosystem/redlistr,4063,13,1551167058
redux,"A 'hiredis' wrapper that includes support for
    transactions, pipelining, blocking subscription, serialisation of
    all keys and values, 'Redis' error handling with R errors.
    Includes an automatically generated 'R6' interface to the full
    'hiredis' 'API'.  Generated functions are faithful to the
    'hiredis' documentation while attempting to match R's argument
    semantics.  Serialisation must be explicitly done by the user, but
    both binary and text-mode serialisation is supported.",2018-05-31,Rich FitzJohn,https://github.com/richfitz/redux,TRUE,https://github.com/richfitz/redux,8520,41,1550830740
refimpact,"Provides wrapper functions around the UK Research
    Excellence Framework 2014 Impact Case Studies Database API
    <http://impact.ref.ac.uk/>. The database contains relevant publication and
    research metadata about each case study as well as several paragraphs of
    text from the case study submissions. Case studies in the database are
    licenced under a CC-BY 4.0 licence
    <http://creativecommons.org/licenses/by/4.0/legalcode>.",2017-07-19,Perry Stephenson,https://github.com/ropensci/refimpact,TRUE,https://github.com/ropensci/refimpact,4664,3,1526385890
refinr,"These functions take a character vector as input, identify and 
  cluster similar values, and then merge clusters together so their values 
  become identical. The functions are an implementation of the key collision 
  and ngram fingerprint algorithms from the open source tool Open Refine 
  <http://openrefine.org/>. More info on key collision and ngram fingerprint 
  can be found here <https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth>.",2018-06-17,Chris Muir,https://github.com/ChrisMuir/refinr,TRUE,https://github.com/chrismuir/refinr,3394,71,1536895546
RefManageR,"Provides tools for importing and working with bibliographic
    references. It greatly enhances the 'bibentry' class by providing a class
    'BibEntry' which stores 'BibTeX' and 'BibLaTeX' references, supports 'UTF-8'
    encoding, and can be easily searched by any field, by date ranges, and by
    various formats for name lists (author by last names, translator by full names,
    etc.). Entries can be updated, combined, sorted, printed in a number of styles,
    and exported. 'BibTeX' and 'BibLaTeX' '.bib' files can be read into 'R' and
    converted to 'BibEntry' objects. Interfaces to 'NCBI Entrez', 'CrossRef', and
    'Zotero' are provided for importing references and references can be created
    from locally stored 'PDF' files using 'Poppler'. Includes functions for citing
    and generating a bibliography with hyperlinks for documents prepared with
    'RMarkdown' or 'RHTML'.",2019-04-03,Mathew W. McLean  (<https://orcid.org/0000-0002-7891-9645>),https://github.com/ropensci/RefManageR/,TRUE,https://github.com/ropensci/refmanager,109213,61,1554352060
refuge,"Access the 'Refuge' API, a web-application for locating trans and 
    intersex-friendly restrooms, including unisex and accessible restrooms. 
    Includes data on the location of restrooms, along with directions, 
    comments, user ratings and amenities. Coverage is global, but data is 
    most comprehensive in the United States.
    See <https://www.refugerestrooms.org/api/docs/> for full API documentation.",2018-12-03,Evan Odell  (<https://orcid.org/0000-0003-1845-808X>),https://docs.evanodell.com/refuge,TRUE,https://github.com/evanodell/refuge,2793,1,1543868988
regnet,"Network-based regularization has achieved success in variable selection for 
    high-dimensional biological data due to its ability to incorporate correlations 
    among genomic features. This package provides procedures of network-based variable 
    selection for generalized linear models. Two recent additions are the robust network 
    regularization for the survival response and the network regularization for continuous 
    response. Functions for other regularization methods will be included in the forthcoming 
    upgraded versions. ",2018-05-22,Jie Ren,https://github.com/jrhub/regnet,TRUE,https://github.com/jrhub/regnet,4532,2,1539547837
RegSDC,"Implementation of the methods described in the paper with the above title: Langsrud, Ø. (2019) <doi:10.1007/s11222-018-9848-9>. Open view-only version at <https://rdcu.be/bfeWQ>. The package can be used to generate synthetic or hybrid continuous microdata, and the relationship to the original data can be controlled in several ways. A function for replacing suppressed tabular cell frequencies with decimal numbers is included.",2019-02-27,Øyvind Langsrud,https://github.com/olangsrud/RegSDC,TRUE,https://github.com/olangsrud/regsdc,725,0,1551287547
rehydratoR,"Facilitates replication of Twitter-based research by handling
    common programming tasks needed when downloading tweets.  Specifically, it ensures a 
    user does not exceed Twitter’s rate limits, and it saves tweets in moderately sized files.  
    While a user could perform these tasks in their own code, doing so may be beyond the 
    capabilities of many users.  ",2019-02-08,Kevin Coakley,https://kevincoakley.github.io/rehydratoR/,TRUE,https://github.com/kevincoakley/rehydrator,795,1,1549584241
reinforcedPred,"Traditional risk prediction only utilizes baseline factors known 
    to be associated with the disease. Given that longitudinal information are
    routinely measured and documented for patients, it is worthwhile to make
    full use of these data. The available longitudinal biomarker data will 
    likely improve prediction. However, repeated biomarker collection could be 
    costly and inconvenient, and risk prediction for patients at a later time 
    could delay necessary medical decisions. Thus, there is a trade-off between
    high quality prediction and cost. This package implements a cost-effective 
    statistical procedure that recursively incorporates comprehensive 
    longitudinal information into the risk prediction model, taking into 
    account the cost of delaying the decision to a follow-up time when more 
    information is available. The statistical methods are described in the 
    following paper: Pan, Y., Laber, E., Smith, M., Zhao, Y. (2018). Reinforced 
    risk prediction with budget constraint: application to electronic health 
    records data. Manuscript submitted for publication. ",2018-10-31,Yinghao Pan,https://github.com/Yinghao-Pan/reinforcedPred,TRUE,https://github.com/yinghao-pan/reinforcedpred,1374,0,1540945324
reinforcelearn,"Implements reinforcement learning environments and algorithms as described in Sutton & Barto (1998, ISBN:0262193981).
    The Q-Learning algorithm can be used with function approximation, 
    eligibility traces (Singh & Sutton (1996) <doi:10.1007/BF00114726>) 
    and experience replay (Mnih et al. (2013) <arXiv:1312.5602>).",2019-03-20,Markus Dumke,http://markusdumke.github.io/reinforcelearn,TRUE,https://github.com/markusdumke/reinforcelearn,2668,25,1552940432
ReIns,"Functions from the book ""Reinsurance: Actuarial and Statistical Aspects"" (2017) by Hansjoerg Albrecher, Jan Beirlant and Jef Teugels <http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470772689.html>.",2018-09-18,Tom Reynkens  (<https://orcid.org/0000-0002-5516-5107>),"http://www.hec.unil.ch/halbrech_files/reinsurance.html,
https://github.com/TReynkens/ReIns",TRUE,https://github.com/treynkens/reins,12128,4,1540050772
remedy,"An 'RStudio' addin providing shortcuts for writing in 'Markdown'. This package provides a series of 
             functions that allow the user to be more efficient when using 'Markdown'. For example, you can select 
             a word, and put it in bold or in italics, or change the alignment of elements inside you Rmd. The idea
             is to map all the functionalities from 'remedy' on keyboard shortcuts, so that it provides an interface 
             close to what you can find in any other text editor. ",2018-12-03,Colin Fay  (<https://orcid.org/0000-0001-7343-1846>),https://github.com/ThinkR-open/remedy,TRUE,https://github.com/thinkr-open/remedy,2300,278,1551531627
remoter,"A set of utilities for client/server computing with R, controlling
    a remote R session (the server) from a local one (the client).  Simply set
    up a server (see package vignette for more details) and connect to it from
    your local R session ('RStudio', terminal, etc).  The client/server
    framework is a custom 'REPL' and runs entirely in your R session without the
    need for installing a custom environment on your system.  Network
    communication is handled by the 'ZeroMQ' library by way of the 'pbdZMQ'
    package.",2018-01-05,Drew Schmidt,https://github.com/RBigData/remoter,TRUE,https://github.com/rbigdata/remoter,7994,53,1554215263
REndo,"Fits linear models with endogenous regressor using latent instrumental variable approaches. 
    The methods included in the package are Lewbel's (1997) <doi:10.2307/2171884> higher moments approach as well as 
    Lewbel's (2012) <doi:10.1080/07350015.2012.643126> heteroscedasticity approach, Park and Gupta's (2012) <doi:10.1287/mksc.1120.0718> joint estimation method 
    that uses Gaussian copula and Kim and Frees's (2007) <doi:10.1007/s11336-007-9008-1> multilevel generalized
    method of moment approach that deals with endogeneity in a multilevel setting.
    These are statistical techniques to address the endogeneity problem where no external instrumental variables are needed.
    Note that with version 2.0.0 sweeping changes were introduced which greatly improve functionality and usability but break backwards compatibility.",2019-01-16,Raluca Gui,https://github.com/mmeierer/REndo,TRUE,https://github.com/mmeierer/rendo,11353,1,1547755597
rentrez,"Provides an R interface to the NCBI's 'EUtils' API, 
    allowing users to search databases like 'GenBank' 
    <https://www.ncbi.nlm.nih.gov/genbank/> and 'PubMed' 
    <https://www.ncbi.nlm.nih.gov/pubmed/>, process the 
    results of those searches and pull data into their R sessions.",2018-03-05,David Winter  (<https://orcid.org/0000-0002-6165-0029>),http://github.com/ropensci/rentrez,TRUE,https://github.com/ropensci/rentrez,122237,109,1543480333
repeated,"Various functions to fit models for non-normal repeated
    measurements.",2019-02-05,Bruce Swihart,http://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/repeated,4962,0,1549388062
repec,"Utilities for accessing RePEc (Research Papers in Economics)
    through a RESTful API. You can request a code and get detailed
    information at the following page: <https://ideas.repec.org/api.html>.",2018-08-31,"Christian Alexander Mongeau Ospina 
    (<https://orcid.org/0000-0002-4047-3924>)",https://github.com/chrMongeau/repec,TRUE,https://github.com/chrmongeau/repec,1505,2,1535793966
REPLesentR,"Create presentations and display them inside the R 'REPL'
    (Read-Eval-Print loop), aka the R console. Presentations can be written in
    'RMarkdown' or any other text format. A set of convenient navigation options
    as well as code evaluation during a presentation is provided. It is great
    for tech talks with live coding examples and tutorials. While this is not a
    replacement for standard presentation formats, it's old-school looks might
    just be what sets it apart. This project has been inspired by the
    'REPLesent' project for presentations in the 'Scala' 'REPL'.",2018-10-30,Sebastian Warnholz,NA,TRUE,https://github.com/wahani/replesentr,1203,3,1551454330
replyr,"Patches to use 'dplyr' on remote data sources ('SQL' databases,
   'Spark' 2.0.0 and above) in a reliable ""generic"" fashion (generic meaning
   user code works similarly on all such sources, without needing per-source
   adaption).  Due to the fluctuating nature of 'dplyr'/'dbplyr'/'rlang' 'APIs' this package
   is going into maintenance mode.  Most of the 'replyr' functions are already 
   done better by one of the non-monolithic replacement packages: 'wrapr', 'seplyr', 'rquery',
   or 'cdata'.",2019-03-31,John Mount,"https://github.com/WinVector/replyr/,
https://winvector.github.io/replyr/",TRUE,https://github.com/winvector/replyr,56308,65,1554054387
RepoGenerator,"Generates a project and repo for easy initialization of a GitHub repo for R workshops. The repo includes a README with instructions to ensure that all users have the needed packages, an 'RStudio' project with the right directories and the proper data. The repo can then be used for hosting code taught during the workshop.",2018-06-19,Jared P. Lander,https://github.com/jaredlander/RepoGenerator,TRUE,https://github.com/jaredlander/repogenerator,1723,1,1536435143
reportr,"Provides a system for reporting messages, which provides certain useful features over the standard R system, such as the incorporation of output consolidation, message filtering, assertions, expression substitution, automatic generation of stack traces for debugging, and conditional reporting based on the current ""output level"".",2018-10-26,Jon Clayden,https://github.com/jonclayden/reportr,TRUE,https://github.com/jonclayden/reportr,38264,4,1540563597
reproducible,"Collection of high-level, robust, machine- and OS-independent tools
    for making deeply reproducible and reusable content in R.
    This includes light weight package management (similar to 'packrat' and
    'checkpoint', but more flexible, lightweight and simpler than both), tools
    for caching, downloading and verifying or writing checksums, post-processing 
    of common spatial datasets, and accessing GitHub repositories. 
    Some features are still under active development.",2019-03-18,Eliot J B McIntire  (<https://orcid.org/0000-0002-6914-8316>),"http://reproducible.predictiveecology.org,
https://github.com/PredictiveEcology/reproducible",TRUE,https://github.com/predictiveecology/reproducible,16480,20,1553005700
REPTILE,Predicting regulatory DNA elements based on epigenomic signatures. This package is more of a set of building blocks than a direct solution. REPTILE regulatory prediction pipeline is built on this R package. See <https://github.com/yupenghe/REPTILE> for more information.,2016-06-21,Yupeng He,https://github.com/yupenghe/REPTILE,TRUE,https://github.com/yupenghe/reptile,4677,16,1531799194
repurrrsive,"Recursive lists in the form of R objects, 'JSON', and 'XML', for use in
    teaching and examples. Examples include color palettes, Game of Thrones
    characters, 'GitHub' users and repositories, and entities from the Star Wars
    universe. Data from the 'gapminder' package is also included, as a simple data
    frame and in nested and split forms.",2017-09-08,Jennifer Bryan,https://github.com/jennybc/repurrrsive,TRUE,https://github.com/jennybc/repurrrsive,10594,75,1548379634
request,"High level and easy 'HTTP' client for 'R'. Provides functions for
    building 'HTTP' queries, including query parameters, body requests, headers,
    authentication, and more.",2016-01-03,Scott Chamberlain,https://github.com/sckott/request,TRUE,https://github.com/sckott/request,8720,31,1533670236
rerddap,"General purpose R client for 'ERDDAP' servers. Includes
    functions to search for 'datasets', get summary information on
    'datasets', and fetch 'datasets', in either 'csv' or 'netCDF' format.
    'ERDDAP' information: 
    <https://upwell.pfeg.noaa.gov/erddap/information.html>.",2019-02-01,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rerddap,TRUE,https://github.com/ropensci/rerddap,11304,28,1554501106
reReg,"A collection of regression models for recurrent event process and failure time data. Available methods include these from Xu et al. (2017) <doi:10.1080/01621459.2016.1173557>, Lin et al. (2000) <doi:10.1111/1467-9868.00259>, Wang et al. (2001) <doi:10.1198/016214501753209031>, Ghosh and Lin (2003) <doi:10.1111/j.0006-341X.2003.00102.x>, and Huang and Wang (2004) <doi:10.1198/016214504000001033>.",2018-10-22,Sy Han (Steven) Chiou,http://github.com/stc04003/reReg,TRUE,https://github.com/stc04003/rereg,11614,2,1553899895
rerf,"R-RerF (aka Randomer Forest (RerF) or Random Projection
  Forests) is an algorithm developed by Tomita (2016) <arXiv:1506.03410v2>
  which is similar to Random Forest - Random Combination (Forest-RC)
  developed by Breiman (2001) <doi:10.1023/A:1010933404324>.  Random
  Forests create axis-parallel, or orthogonal trees. That is, the feature
  space is recursively split along directions parallel to the axes of the
  feature space. Thus, in cases in which the classes seem inseparable
  along any single dimension, Random Forests may be suboptimal.  To
  address this, Breiman also proposed and characterized Forest-RC, which
  uses linear combinations of coordinates rather than individual
  coordinates, to split along.  This package, 'rerf', implements RerF
  which is similar to Forest-RC.  The difference between the two
  algorithms is where the random linear combinations occur: Forest-RC
  combines features at the per tree level whereas RerF takes linear
  combinations of coordinates at every node in the tree.",2019-03-15,Jesse Patsolic [ctb,https://github.com/neurodata/R-RerF,TRUE,https://github.com/neurodata/r-rerf,5448,36,1553543829
resampledata,"Package of data sets from ""Mathematical Statistics
    with Resampling in R"" (1st Ed. 2011, 2nd Ed. 2018) by Laura Chihara and Tim Hesterberg.",2018-08-04,Albert Y. Kim,https://github.com/rudeboybert/resampledata,TRUE,https://github.com/rudeboybert/resampledata,9332,6,1533361517
resemble,"Implementation of functions for spectral similarity/dissimilarity
    analysis and memory-based learning (MBL) for non-linear modeling
    in complex spectral datasets. In chemometrics MBL is also known as local modeling.",2016-03-04,Leonardo Ramirez-Lopez,http://l-ramirez-lopez.github.io/resemble/,TRUE,https://github.com/l-ramirez-lopez/resemble,12438,4,1553601096
ResistorArray,Electrical properties of resistor networks using matrix methods.,2019-01-29,Robin K. S. Hankin  (<https://orcid.org/0000-0001-5982-0415>),https://github.com/RobinHankin/ResistorArray.git,TRUE,https://github.com/robinhankin/resistorarray,14635,0,1548794688
ResourceSelection,"Resource Selection (Probability) Functions
  for use-availability wildlife data
  based on weighted distributions as described in
  Lele and Keim (2006) <doi:10.1890/0012-9658(2006)87[3021:WDAEOR]2.0.CO;2>,
  Lele (2009) <doi:10.2193/2007-535>,
  and Solymos & Lele (2016) <doi:10.1111/2041-210X.12432>.",2019-01-08,Peter Solymos  (<https://orcid.org/0000-0001-7337-1740>),https://github.com/psolymos/ResourceSelection,TRUE,https://github.com/psolymos/resourceselection,117249,1,1546930557
restorepoint,"Debugging with restore points instead of break points. A restore
    point stores all local variables when called inside a function. The stored
    values can later be retrieved and evaluated in a modified R console that
    replicates the function's environment. To debug step by step, one can simply
    copy & paste the function body from the R script. Particularly convenient
    in combination with ""RStudio"". See the ""Github"" page inst/vignettes for a
    tutorial.",2019-01-02,Sebastian Kranz,https://github.com/skranz/restorepoint,TRUE,https://github.com/skranz/restorepoint,9151,12,1546540444
reticulate,"Interface to 'Python' modules, classes, and functions. When calling
    into 'Python', R data types are automatically converted to their equivalent 'Python'
    types. When values are returned from 'Python' to R they are converted back to R
    types. Compatible with all versions of 'Python' >= 2.7.",2019-03-06,JJ Allaire,https://github.com/rstudio/reticulate,TRUE,https://github.com/rstudio/reticulate,589866,860,1552606697
retistruct,"Reconstructs retinae by morphing a flat surface with cuts (a
    dissected flat-mount retina) onto a curvilinear surface (the standard retinal
    shape). It can estimate the position of a point on the intact adult retina
    to within 8 degrees of arc (3.6% of nasotemporal axis). The coordinates in
    reconstructed retinae can be transformed to visuotopic coordinates.",2017-08-09,David C. Sterratt,http://davidcsterratt.github.io/retistruct/,TRUE,https://github.com/davidcsterratt/retistruct,10472,4,1534853558
retrodesign,"Provides tools for working with Type S (Sign) and
    Type M (Magnitude) errors, as proposed in Gelman and Tuerlinckx (2000)
    <doi.org/10.1007/s001800000040> and
    Gelman & Carlin (2014) <doi.org/10.1177/1745691614551642>.
    In addition to simply calculating the probability of
    Type S/M error, the package includes functions for calculating these errors
    across a variety of effect sizes for comparison, and recommended sample size
    given ""tolerances"" for Type S/M errors. To improve the speed of these
    calculations, closed forms solutions for the probability of a Type S/M error
    from Lu, Qiu, and Deng (2018) <doi.org/10.1111/bmsp.12132>
    are implemented. As of 1.0.0, this includes
    support only for simple research designs. See the
    package vignette for a fuller exposition on how Type S/M errors arise in
    research, and how to analyze them using the type of design analysis proposed
    in the above papers.",2019-03-08,Andrew Timm,https://github.com/andytimm/retrodesign,TRUE,https://github.com/andytimm/retrodesign,302,1,1552319217
reutils,"An interface to NCBI databases such as PubMed, GenBank, or GEO
    powered by the Entrez Programming Utilities (EUtils). The nine EUtils
    provide programmatic access to the NCBI Entrez query and database
    system for searching and retrieving biological data.",2016-09-03,Gerhard Schöfl <gerhard.schofl@gmail.com>,https://github.com/gschofl/reutils,TRUE,https://github.com/gschofl/reutils,16475,8,1544280693
revdbayes,"Provides functions for the Bayesian analysis of extreme value
    models.  The 'rust' package <https://cran.r-project.org/package=rust> is
    used to simulate a random sample from the required posterior distribution.
    The functionality of 'revdbayes' is similar to the 'evdbayes' package
    <https://cran.r-project.org/package=evdbayes>, which uses Markov Chain
    Monte Carlo ('MCMC') methods for posterior simulation.  Also provided
    are functions for making inferences about the extremal index, using 
    the K-gaps model of Suveges and Davison (2010) <doi:10.1214/09-AOAS292>.
    Also provided are d,p,q,r functions for the Generalised Extreme Value 
    ('GEV') and Generalised Pareto ('GP') distributions that deal 
    appropriately with cases where the shape parameter is very close to zero.",2019-03-08,Paul J. Northrop,http://github.com/paulnorthrop/revdbayes,TRUE,https://github.com/paulnorthrop/revdbayes,9859,2,1552073447
revealjs,"R Markdown format for 'reveal.js' presentations, a framework 
  for easily creating beautiful presentations using HTML.",2017-03-13,Hakim El Hattab,https://github.com/rstudio/revealjs,TRUE,https://github.com/rstudio/revealjs,31989,191,1547045232
revengc,"Decoupled (e.g. separate averages) and censored (e.g. > 100 species) variables are continually reported by many well-established organizations (e.g. World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), World Bank, and various national censuses).  The challenge therefore is to infer what the original data could have been given summarized information.  We present an R package that reverse engineers decoupled and/or censored count data with two main functions.  The cnbinom.pars function estimates the average and dispersion parameter of a censored univariate frequency table.  The rec function reverse engineers summarized data into an uncensored bivariate table of probabilities.",2019-01-08,Samantha Duchscherer,https://github.com/GIST-ORNL/revengc,TRUE,https://github.com/gist-ornl/revengc,3673,2,1546444234
revtools,"Researchers commonly need to summarize scientific information, a process known as 'evidence synthesis'. The first stage of a synthesis process (such as a systematic review or meta-analysis) is to download a list of references from academic search engines such as 'Web of Knowledge' or 'Scopus'. The traditional approach to systematic review is then to sort these data manually, first by locating and removing duplicated entries, and then screening to remove irrelevant content by viewing titles and abstracts (in that order). 'revtools' provides interfaces for each of these tasks. An alternative approach, however, is to draw on tools from machine learning to visualise patterns in the corpus. In this case, you can use 'revtools' to render ordinations of text drawn from article titles, keywords and abstracts, and interactively select or exclude individual references, words or topics.",2018-11-29,Martin J. Westgate,https://revtools.net,TRUE,https://github.com/mjwestgate/revtools,3269,9,1550796664
Rfacebook,Provides an interface to the Facebook API.,2017-05-25,Pablo Barbera <pbarbera@usc.edu>,https://github.com/pablobarbera/Rfacebook,TRUE,https://github.com/pablobarbera/rfacebook,139333,330,1532795230
rfacebookstat,"Load data by campaigns, ads, ad sets and insights, ad account and 
    business manager from Facebook Marketing API into R. For more details see official documents by Facebook Marketing API <https://developers.facebook.com/docs/marketing-apis/>.",2018-08-14,Alexey Seleznev <selesnow@gmail.com>,http://selesnow.github.io/rfacebookstat,TRUE,https://github.com/selesnow/rfacebookstat,2001,13,1553768442
rfbCNPJ,"Downloads and parses data from official site on Department
    of Federal Revenue in Brazil (Receita Federal do Brasil, RFB). Data are 
    collected from RFB site (<http://idg.receita.fazenda.gov.br>). Latest update 
    was in December 15, 2017. There are more than 9 million companies IDs and 
    17 million partner information.",2018-05-17,Julio Trecenti,https://github.com/jtrecenti/rfbCNPJ,TRUE,https://github.com/jtrecenti/rfbcnpj,1945,9,1542984799
rfigshare,"An interface to 'figshare' (http://figshare.com), a scientific repository to archive and assign 'DOIs' to data, software, figures, and more.",2015-06-15,Carl Boettiger,https://github.com/ropensci/rfigshare,TRUE,https://github.com/ropensci/rfigshare,21891,36,1549660995
rfishbase,"A programmatic interface to <http://www.fishbase.org>, re-written
    based on an accompanying 'RESTful' API. Access tables describing over 30,000
    species of fish, their biology, ecology, morphology, and more. This package also
    supports experimental access to <http://www.sealifebase.org> data, which contains
    nearly 200,000 species records for all types of aquatic life not covered by
    'FishBase.'",2019-03-12,Carl Boettiger  (<https://orcid.org/0000-0002-1642-628X>),https://github.com/ropensci/rfishbase,TRUE,https://github.com/ropensci/rfishbase,24519,49,1552429386
RFishBC,"Helps fisheries scientists collect measurements from calcified
    structures and back-calculate estimated lengths at previous ages using
    standard procedures and models. This is intended to replace much of the
    functionality provided by the now out-dated 'fishBC' software.",2018-12-18,Derek Ogle  (<https://orcid.org/0000-0002-0370-9299>),http://derekogle.com/RFishBC,TRUE,https://github.com/droglenc/rfishbc,1183,3,1548991604
rfm,"Tools for RFM (recency, frequency and monetary value) analysis. 
    Generate RFM score from both transaction and customer level data. Visualize the
    relationship between recency, frequency and monetary value using heatmap, 
    histograms, bar charts and scatter plots. Includes a 'shiny' app for 
    interactive segmentation. References:
    i. Blattberg R.C., Kim BD., Neslin S.A (2008) <doi:10.1007/978-0-387-72579-6_12>.",2019-01-14,Aravind Hebbali  (<https://orcid.org/0000-0001-9220-9669>),"https://github.com/rsquaredacademy/rfm,
https://rfm.rsquaredacademy.com/",TRUE,https://github.com/rsquaredacademy/rfm,6359,12,1550137430
rfoaas,R access to the 'FOAAS' (F... Off As A Service) web service is provided.,2018-08-20,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rfoaas.html,TRUE,https://github.com/eddelbuettel/rfoaas,13337,24,1534772673
rfordummies,"Contains all the code examples in the book ""R for Dummies"" (2nd
    edition) by Andrie de Vries and Joris Meys. You can view the table of 
    contents as well as the sample code for each chapter.",2019-03-19,Andrie de Vries,"https://rfordummies.com, http://andrie.github.io/rfordummies/",TRUE,https://github.com/andrie/rfordummies,13378,1,1553012812
rfPermute,"Estimate significance of importance metrics
    for a Random Forest model by permuting the response
    variable. Produces null distribution of importance
    metrics for each predictor variable and p-value of
    observed. Provides summary and visualization functions for 'randomForest' 
    results.",2018-07-07,Eric Archer,https://github.com/EricArcher/rfPermute,TRUE,https://github.com/ericarcher/rfpermute,17734,9,1550690452
Rfssa,"Methods and tools for implementing functional singular spectrum analysis for functional time series
    as described in Haghbin H., Najibi, S.M., Mahmoudvand R., Maadooliat M. (2019). Functional singular spectrum Analysis. Manuscript submitted for publication. ",2019-02-11,Hossein Haghbin,https://github.com/haghbinh/Rfssa.git,TRUE,https://github.com/haghbinh/rfssa,445,1,1551650194
rgabriel,"This package was created to analyze multi-level one-way
        experimental designs. It is designed to handle vectorized
        observation and factor data where there are unequal sample
        sizes and population variance homogeneity can not be assumed.
        To conduct the Gabriel test, create two vectors: one for your 
        observations and one for the factor level of each observation. 
        The function, rgabriel, conduct the test and save the output as
        a vector to input into the gabriel.plot function, which produces 
        a confidence interval plot for Multiple Comparison.",2013-12-28,Yihui XIE,https://github.com/yufree/rgabriel,TRUE,https://github.com/yufree/rgabriel,10466,1,1543899855
Rgb,"Classes and methods to efficiently handle (slice, annotate, draw ...) genomic features (such as genes or transcripts), and an interactive interface to browse them.",2018-03-18,Sylvain Mareschal,http://bioinformatics.ovsa.fr/Rgb,TRUE,https://github.com/maressyl/r.rgb,5853,0,1553184623
rgbif,"A programmatic interface to the Web Service methods
    provided by the Global Biodiversity Information Facility ('GBIF';
    <https://www.gbif.org/developer/summary>). 'GBIF' is a database
    of species occurrence records from sources all over the globe.
    'rgbif' includes functions for searching for taxonomic names,
    retrieving information on data providers, getting species occurrence
    records, getting counts of occurrence records, and using the 'GBIF' 
    tile map service to make 'rasters' summarizing huge amounts of data.",2019-02-26,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),"https://github.com/ropensci/rgbif,
https://ropensci.github.io/rgbif,
https://ropensci.github.io/occurrence-manual",TRUE,https://github.com/ropensci/rgbif,92173,86,1554334475
Rgbp,"We utilize  approximate Bayesian machinery to fit two-level conjugate hierarchical models on overdispersed Gaussian, Poisson, and Binomial data and evaluates whether the resulting approximate Bayesian interval estimates for random effects meet the nominal confidence levels via frequency coverage evaluation. The data that Rgbp assumes comprise observed sufficient statistic for each random effect, such as an average or a proportion of each group, without population-level data.  The approximate Bayesian tool equipped with the adjustment for density maximization produces approximate point and interval estimates for model parameters including second-level variance component, regression coefficients, and random effect. For the Binomial data, the package provides an option to produce  posterior samples of all the model parameters via the acceptance-rejection method. The package provides a quick way to evaluate coverage rates of the resultant Bayesian interval estimates for random effects via a parametric bootstrapping, which we call frequency method checking.",2018-05-17,Joseph Kelly,NA,TRUE,https://github.com/jyklly/rgbp,11794,1,1526570640
rgdax,"Allow access to both public and private end points to Coinbase Pro (erstwhile GDAX) 
    cryptocurrency exchange. For authenticated flow, users must have valid api, secret and passphrase to be able to connect.",2019-01-07,Dheeraj Agarwal,https://github.com/DheerajAgarwal/rgdax/,TRUE,https://github.com/dheerajagarwal/rgdax,4035,19,1546727485
RGeckoboard,Provides an interface to Geckoboard.,2018-07-10,Meinhard Ploner,"https://github.com/ploner/RGeckoboard, https://www.geckoboard.com",TRUE,https://github.com/ploner/rgeckoboard,1620,1,1551283699
RGENERATEPREC,"The method 'generate()' is extended for spatial multi-site
    stochastic generation of daily precipitation. It generates precipitation
    occurrence in several sites using logit regression (Generalized Linear
    Models) and D.S. Wilks' approach (Journal of Hydrology, 1998).",2017-02-11,Emanuele Cordano,https://github.com/ecor/RGENERATEPREC,TRUE,https://github.com/ecor/rgenerateprec,9495,1,1551718269
rgeopat2,"Supports analysis of spatial data processed with the 'GeoPAT' 2
    software <http://sil.uc.edu/cms/index.php?id=geopat2>. 
    Available features include creation of a grid based on the 'GeoPAT' 2
    grid header file and reading a 'GeoPAT' 2 text outputs.",2018-09-16,Jakub Nowosad  (<https://orcid.org/0000-0002-1057-3721>),https://github.com/Nowosad/rgeopat2,TRUE,https://github.com/nowosad/rgeopat2,5231,9,1547469137
rggobi,"A command-line interface to 'GGobi', an interactive and dynamic
    graphics package. 'Rggobi' complements the graphical user interface of
    'GGobi' providing a way to fluidly transition between analysis and
    exploration, as well as automating common tasks.",2018-07-07,Duncan Temple Lang <duncan@research.bell-labs.com>,"https://github.com/ggobi/rggobi, http://www.ggobi.org/rggobi",TRUE,https://github.com/ggobi/rggobi,139732,9,1530895137
rglobi,"A programmatic interface to the web service methods
    provided by Global Biotic Interactions (GloBI). GloBI provides 
    access to spatial-temporal species interaction records from 
    sources all over the world. rglobi provides methods to search 
    species interactions by location, interaction type, and 
    taxonomic name. In addition, it supports Cypher, a graph query
    language, to allow for executing custom queries on the GloBI 
    aggregate species interaction data set.",2019-03-28,Jorrit Poelen,https://github.com/ropensci/rglobi,TRUE,https://github.com/ropensci/rglobi,15956,11,1553796868
RGoogleAnalytics,"Provides functions for accessing and retrieving data from the
    Google Analytics API.",2018-10-09,Michael Pearmain. Contributions from Nick Mihailowski,NA,TRUE,https://github.com/manueldefrancisco/rgoogleanalytics,48060,0,1539092401
RGreenplum,"
    Fully 'DBI'-compliant interface to 'Greenplum' <https://greenplum.org/>,
    an open-source parallel database. This is an extension of the 'RPostgres'
    package <https://github.com/r-dbi/RPostgres>.",2018-06-24,Michael Williams,https://github.com/mwillumz/RGreenplum,TRUE,https://github.com/mwillumz/rgreenplum,2439,0,1529629328
rgsp,Functions to calculate Sample Number and Average Sample Number for Repetitive Group Sampling Plan Based on Cpk as given in Aslam et al. (2013) (<DOI:10.1080/00949655.2012.663374>).,2018-10-26,Muhammad Yaseen,"https://github.com/myaseen208/rgsp,
https://myaseen208.github.io/rgsp/",TRUE,https://github.com/myaseen208/rgsp,1553,0,1538457360
rgw,"Implementation of the affine-invariant method of Goodman & Weare (2010) <DOI:10.2140/camcos.2010.5.65>, a method of producing Monte-Carlo samples from a target distribution.",2016-10-10,Adam Mantz,https://github.com/abmantz/rgw,TRUE,https://github.com/abmantz/rgw,4071,1,1530218121
rhandsontable,"An R interface to the 'Handsontable' JavaScript library, which is a
    minimalist Excel-like data grid editor.  See <https://handsontable.com/> for details.",2018-11-20,Jonathan Owen,http://jrowen.github.io/rhandsontable/,TRUE,https://github.com/jrowen/rhandsontable,111212,240,1550938654
rhierbaps,"Implements the hierarchical Bayesian analysis of populations structure (hierBAPS) 
  algorithm of Cheng et al. (2013) <doi:10.1093/molbev/mst028> for clustering DNA sequences 
  from multiple sequence alignments in FASTA format. 
  The implementation includes improved defaults and plotting capabilities 
  and unlike the original 'MATLAB' version removes singleton SNPs by default.",2018-10-10,Gerry Tonkin-Hill,https://github.com/gtonkinhill/rhierbaps,TRUE,https://github.com/gtonkinhill/rhierbaps,2152,8,1553105635
rhli,"Complete access from 'R' to the FIS 'MarketMap 
    C-Toolkit' ('FAME C-HLI'). 'FAME' is a fully integrated software and database 
    management system from FIS that provides the following capabilities: 
    Time series and cross-sectional data management;
    Financial calculation, data analysis, econometrics, and forecasting;
    Table generation and detailed multicolor, presentation-quality report writing;
    Multicolor, presentation-quality graphics;
    ""What-if"" analysis;
    Application development and structured programming;
    Data transfer to and from other applications;
    Tools for building customized graphical user interfaces.",2018-08-17,Kevin Keane,https://github.com/qomaio/rhli,TRUE,https://github.com/qomaio/rhli,1503,1,1534615540
rhmmer,"
    'HMMER' is a profile hidden Markov model tool used primarily for sequence
    analysis in bioinformatics (<http://hmmer.org/>). 'rhmmer' provides
    utilities for parsing the 'HMMER' output into tidy data frames.",2017-12-19,Zebulun Arendsee,https://github.com/arendsee/rhmmer,TRUE,https://github.com/arendsee/rhmmer,2406,3,1544501915
rhub,"Run 'R CMD check' on any of the 'R-hub' (<https://builder.r-hub.io/>)
    architectures, from the command line. The current architectures include
    'Windows', 'macOS', 'Solaris' and various 'Linux' distributions.",2019-03-25,Gábor Csárdi,"https://github.com/r-hub/rhub, https://r-hub.github.io/rhub/",TRUE,https://github.com/r-hub/rhub,53762,231,1554196837
ridge,"Linear and logistic ridge regression functions. Additionally includes special functions for 
            genome-wide single-nucleotide polymorphism (SNP) data.",2019-03-15,Steffen Moritz  (<https://orcid.org/0000-0002-0085-1804>),http://github.com/SteffenMoritz/ridge,TRUE,https://github.com/steffenmoritz/ridge,39595,6,1553528824
riem,"Allows to get weather data from Automated Surface Observing System (ASOS) stations (airports) in the
    whole world thanks to the Iowa Environment Mesonet website.",2016-09-10,Maëlle Salmon,http://github.com/ropenscilabs/riem,TRUE,https://github.com/ropenscilabs/riem,10106,21,1553523835
RiemBase,"We provide a number of algorithms to estimate fundamental statistics including Fréchet mean and geometric median for manifold-valued data. Also, C++ header files are contained that implement elementary operations on manifolds such as Sphere, Grassmann, and others. See Bhattacharya and Bhattacharya (2012) <doi:10.1017/CBO9781139094764> if you are interested in statistics on manifolds, and Absil et al (2007) <isbn:978-0-691-13298-3> on computational aspects of optimization on matrix manifolds.",2019-02-05,Kisung You  (<https://orcid.org/0000-0002-8584-459X>),http://github.com/kisungyou/RiemBase,TRUE,https://github.com/kisungyou/riembase,1935,0,1549397411
riingo,"Functionality to download stock prices, cryptocurrency data, and
   more from the 'Tiingo' API <https://api.tiingo.com/>.",2018-04-16,Davis Vaughan,https://github.com/business-science/riingo,TRUE,https://github.com/business-science/riingo,2337,21,1530834573
rijkspalette,"Create colour palettes based on famous paintings. Using the 
    function rijksPalette(), you can search for any painting in the collection
    of the Dutch Rijksmuseum and generate a colour palette from it. This package 
    was developed using the fantastic Rijksmuseum API 
    <https://www.rijksmuseum.nl/api>.",2019-02-07,Erik-Jan van Kesteren,https://vankesteren.github.io/rijkspalette,TRUE,https://github.com/vankesteren/rijkspalette,1962,7,1549558256
RInno,"Installs shiny apps packaged as stand-alone Electron apps using Inno Setup, an open source software that builds installers for Windows programs <http://www.jrsoftware.org/ishelp/>.",2018-09-21,Jon Hill,www.ficonsulting.com,TRUE,https://github.com/ficonsulting/rinno,11360,166,1549479912
RInside,"C++ classes to embed R in C++ applications
 A C++ class providing the R interpreter is offered by this package
 making it easier to have ""R inside"" your C++ application. As R itself
 is embedded into your application, a shared library build of R is
 required. This works on Linux, OS X and even on Windows provided you
 use the same tools used to build R itself. d Numerous examples are
 provided in the eight subdirectories of the examples/ directory of
 the installed package: standard, 'mpi' (for parallel computing), 'qt'
 (showing how to embed 'RInside' inside a Qt GUI application), 'wt'
 (showing how to build a ""web-application"" using the Wt toolkit),
 'armadillo' (for 'RInside' use with 'RcppArmadillo') and 'eigen' (for
 'RInside' use with 'RcppEigen').  The examples use 'GNUmakefile(s)'
 with GNU extensions, so a GNU make is required (and will use the
 'GNUmakefile' automatically). 'Doxygen'-generated documentation of
 the C++ classes is available at the 'RInside' website as well.",2019-03-06,Dirk Eddelbuettel and Romain Francois,http://dirk.eddelbuettel.com/code/rinside.html,TRUE,https://github.com/eddelbuettel/rinside,45142,79,1551889741
rintrojs,"A wrapper for the 'Intro.js' library (For more info: <http://www.introjs.com>). 
  This package makes it easy to include step-by-step introductions, and clickable hints in a 'Shiny' 
  application. It supports both static introductions in the UI, and programmatic introductions from 
  the server-side. ",2017-07-04,Carl Ganz,https://github.com/carlganz/rintrojs,TRUE,https://github.com/carlganz/rintrojs,16965,64,1524588981
rio,"Streamlined data import and export by making assumptions that
    the user is probably willing to make: 'import()' and 'export()' determine
    the data structure from the file extension, reasonable defaults are used for
    data import and export (e.g., 'stringsAsFactors=FALSE'), web-based import is
    natively supported (including from SSL/HTTPS), compressed files can be read
    directly without explicit decompression, and fast import packages are used where
    appropriate. An additional convenience function, 'convert()', provides a simple
    method for converting between file types.",2018-11-26,Thomas J. Leeper  (<https://orcid.org/0000-0003-4097-6326>),https://github.com/leeper/rio,TRUE,https://github.com/leeper/rio,1722825,364,1551195622
rise,"Implements techniques for educational resource inspection, selection, and evaluation (RISE) described in Bodily, Nyland, and Wiley (2017) 
    <doi:10.19173/irrodl.v18i2.2952>.	Automates the process of identifying learning materials that are not effectively supporting student learning in 
    technology-mediated courses by synthesizing information about access to course content and performance on assessments.",2018-10-04,David Wiley,NA,TRUE,https://github.com/lumenlearning/rise,1801,4,1547489424
riskclustr,"A collection of functions related to the study of etiologic heterogeneity both across disease subtypes and across individual tumor markers. The included functions allow one to quantify the extent of etiologic heterogeneity in the context of a case-control study, and provide p-values to test for etiologic heterogeneity across individual risk factors.",2019-01-17,Emily C. Zabor,"http://www.emilyzabor.com/riskclustr/,
https://github.com/zabore/riskclustr",TRUE,https://github.com/zabore/riskclustr,503,1,1553712566
riskParityPortfolio,"Fast design of risk parity portfolios for financial investment.
    The goal of the risk parity portfolio formulation is to equalize or distribute
    the risk contributions of the different assets, which is missing if we simply
    consider the overall volatility of the portfolio as in the mean-variance
    Markowitz portfolio. In addition to the vanilla formulation, where the risk
    contributions are perfectly equalized subject to no shortselling and budget
    constraints, many other formulations are considered that allow for box
    constraints and shortselling, as well as the inclusion of additional
    objectives like the expected return and overall variance. See vignette for
    a detailed documentation and comparison, with several illustrative examples.
    The package is based on the papers:
    Y. Feng, and D. P. Palomar (2015). SCRIP: Successive Convex Optimization Methods
    for Risk Parity Portfolio Design. IEEE Trans. on Signal Processing, vol. 63,
    no. 19, pp. 5285-5300. <doi:10.1109/TSP.2015.2452219>.
    F. Spinu (2013), An Algorithm for Computing Risk Parity Weights.
    <doi:10.2139/ssrn.2297383>.
    T. Griveau-Billion, J. Richard, and T. Roncalli (2013). A fast algorithm for computing 
    High-dimensional risk parity portfolios. <arXiv:1311.4057>.",2019-01-08,Daniel P. Palomar,"https://CRAN.R-project.org/package=riskParityPortfolio,
https://github.com/dppalomar/riskParityPortfolio,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2015.2452219",TRUE,https://github.com/dppalomar/riskparityportfolio,1899,14,1552609854
RiskPortfolios,"Collection of functions designed to compute risk-based portfolios as described 
    in Ardia et al. (2017) <doi:10.1007/s10479-017-2474-7> and Ardia et al. (2017) <doi:10.21105/joss.00171>.",2018-08-30,David Ardia,https://github.com/ArdiaD/RiskPortfolios,TRUE,https://github.com/ardiad/riskportfolios,7874,14,1535641388
riskyr,"Risk-related information (like the prevalence of conditions and the sensitivity and specificity of diagnostic tests or treatment decisions) can be expressed in terms of probabilities or frequencies. By providing a toolbox of methods and metrics, 'riskyr' computes, translates, and visualizes risk-related information in a variety of ways. Offering multiple complementary perspectives on the interplay between key parameters renders teaching and training of risk literacy more transparent. ",2019-01-03,Hansjoerg Neth,"http://riskyr.org, https://github.com/hneth/riskyr",TRUE,https://github.com/hneth/riskyr,2666,7,1553234292
ritis,"An interface to the Integrated Taxonomic Information System ('ITIS')
    (<https://www.itis.gov>). Includes functions to work with the 'ITIS' REST
    API methods (<https://www.itis.gov/ws_description.html>), as well as the
    'Solr' web service (<https://www.itis.gov/solr_documentation.html>).",2018-12-18,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/ritis,TRUE,https://github.com/ropensci/ritis,69335,9,1547096564
rivr,"A tool for undergraduate and graduate courses in open-channel
    hydraulics. Provides functions for computing normal and critical depths,
    steady-state water surface profiles (e.g. backwater curves) and unsteady flow
    computations (e.g. flood wave routing).",2019-03-12,Michael C Koohafkan,https://github.com/mkoohafkan/rivr,TRUE,https://github.com/mkoohafkan/rivr,10019,8,1553316889
rJava,"Low-level interface to Java VM very much like .C/.Call and friends. Allows creation of objects, calling methods and accessing fields.",2019-03-29,Simon Urbanek <simon.urbanek@r-project.org>,http://www.rforge.net/rJava/,TRUE,https://github.com/s-u/rjava,7071944,174,1553782269
RJDemetra,"Interface around 'JDemetra+' (<https://github.com/jdemetra/jdemetra-app>), the seasonal adjustment software officially
    recommended to the members of the European Statistical System (ESS) and the European System of Central Banks.
    It offers full access to all options and outputs of 'JDemetra+', including the two leading seasonal adjustment methods
    TRAMO/SEATS+ and X-12ARIMA/X-13ARIMA-SEATS.",2019-03-04,Alain Quartier-la-Tente,https://github.com/jdemetra/rjdemetra,TRUE,https://github.com/jdemetra/rjdemetra,483,15,1554220116
RJSDMX,"Provides functions to retrieve data and metadata from providers 
			 that disseminate data by means of SDMX web services. 
			 SDMX (Statistical Data and Metadata eXchange) is a standard that 
			 has been developed with the aim of simplifying the exchange of 
			 statistical information. 
			 More about the SDMX standard and the SDMX Web Services 
			 can be found at: <http://sdmx.org>.",2018-08-22,Attilio Mattiocco,https://github.com/amattioc/SDMX/,TRUE,https://github.com/amattioc/sdmx,16116,53,1550504118
rjsonapi,"Consumer for APIs that Follow the JSON API Specification
    (<http://jsonapi.org/>). Package mostly consumes data - with experimental
    support for serving JSON API data.",2017-01-09,Scott Chamberlain,https://github.com/ropensci/rjsonapi,TRUE,https://github.com/ropensci/rjsonapi,5007,22,1542655704
rLakeAnalyzer,"Standardized methods for calculating common important derived
    physical features of lakes including water density based based on
    temperature, thermal layers, thermocline depth, lake number, Wedderburn
    number, Schmidt stability and others.",2018-03-14,Luke Winslow,NA,TRUE,https://github.com/gleon/rlakeanalyzer,22878,16,1536946758
rlang,"A toolbox for working with base types, core R features
  like the condition system, and core 'Tidyverse' features like tidy
  evaluation.",2019-03-29,Lionel Henry,"http://rlang.r-lib.org, https://github.com/r-lib/rlang",TRUE,https://github.com/r-lib/rlang,12957470,214,1554469308
rlas,Read and write 'las' and 'laz' binary file formats. The LAS file format is a public file format for the interchange of 3-dimensional point cloud data between data users. The LAS specifications are approved by the American Society for Photogrammetry and Remote Sensing <https://www.asprs.org/committee-general/laser-las-file-format-exchange-activities.html>. The LAZ file format is an open and lossless compression scheme for binary LAS format versions 1.0 to 1.3 <https://www.laszip.org/>.,2019-02-08,Jean-Romain Roussel,https://github.com/Jean-Romain/rlas,TRUE,https://github.com/jean-romain/rlas,24733,11,1554488706
Rlda,"Estimates the Bayesian LDA model for mixed-membership clustering based on different types of data
    (i.e., Multinomial, Bernoulli, and Binomial entries). Albuquerque, Valle and Li (2019) <doi:10.1016/j.knosys.2018.10.024>.",2018-12-13,Pedro Albuquerque and Denis Valle and Daijiang Li,https://www.sciencedirect.com/science/article/pii/S0950705118305100,TRUE,https://github.com/pedrobsb/rlda,5501,5,1544701988
Rlgt,"An implementation of a number of Global Trend models for time series forecasting 
    that are Bayesian generalizations and extensions of some Exponential Smoothing models. 
    The main differences/additions include 1) nonlinear global trend, 2) Student-t error 
    distribution, and 3) a function for the error size, so heteroscedasticity. The methods 
    are particularly useful for short time series. When tested on the well-known M3 dataset,
    they are able to outperform all classical time series algorithms. The models are fitted 
    with MCMC using the 'rstan' package.",2019-02-22,Christoph Bergmeir,https://github.com/cbergmeir/Rlgt,TRUE,https://github.com/cbergmeir/rlgt,474,4,1551501014
Rlibeemd,"An R interface for libeemd (Luukko, Helske, Räsänen, 2016) <doi:10.1007/s00180-015-0603-9>, 
    a C library of highly efficient parallelizable functions  for performing the ensemble empirical mode decomposition (EEMD), 
    its complete variant (CEEMDAN), the regular empirical mode decomposition (EMD), and bivariate EMD (BEMD). 
    Due to the possible portability issues CRAN version no longer supports OpenMP, you can install OpenMP-supported version 
    from GitHub: <https://github.com/helske/Rlibeemd/>.",2018-12-19,Jouni Helske  (R interface,NA,TRUE,https://github.com/helske/rlibeemd,21018,11,1545225456
RLRsim,"Rapid, simulation-based exact (restricted) likelihood ratio tests
    for testing the presence of variance components/nonparametric terms for
    models fit with nlme::lme(),lme4::lmer(), lmeTest::lmer(), gamm4::gamm4(),
    mgcv::gamm() and SemiPar::spm().",2016-11-04,Fabian Scheipl,https://github.com/fabian-s/RLRsim,TRUE,https://github.com/fabian-s/rlrsim,66383,5,1541178941
RLumShiny,"A collection of 'shiny' applications for the R package
    'Luminescence'. These mainly, but not exclusively, include applications for
    plotting chronometric data from e.g. luminescence or radiocarbon dating. It
    further provides access to bootstraps tooltip and popover functionality and
    contains the 'jscolor.js' library with a custom 'shiny' output binding.",2019-01-11,Christoph Burow  (<https://orcid.org/0000-0002-5023-4046>),https://tzerk.github.io/RLumShiny/,TRUE,https://github.com/tzerk/rlumshiny,18454,2,1552655285
rly,R implementation of the common parsing tools 'lex' and 'yacc'.,2018-09-10,Marek Jagielski,https://github.com/systemincloud/rly,TRUE,https://github.com/systemincloud/rly,7846,18,1551915304
rmapshaper,"Edit and simplify 'geojson', 'Spatial', and 'sf' objects.
    This is wrapper around the 'mapshaper' 'JavaScript' library by Matthew Bloch 
    <https://github.com/mbloch/mapshaper/> to perform topologically-aware
    polygon simplification, as well as other operations such as clipping,
    erasing, dissolving, and converting 'multi-part' to 'single-part' geometries.
    It relies on the 'geojsonio' package for working with 'geojson' objects, the 'sf' 
    package for working with 'sf' objects, and the 'sp' and 'rgdal' packages for 
    working with 'Spatial' objects.",2018-10-16,Andy Teucher,https://github.com/ateucher/rmapshaper,TRUE,https://github.com/ateucher/rmapshaper,129029,84,1550024116
rmapzen,"Provides an interface to 'Mapzen'-based APIs (including 
    geocode.earth, Nextzen, and NYC GeoSearch) for geographic search 
    and geocoding, isochrone calculation, and vector data to draw map tiles. 
    See <https://mapzen.com/documentation/> for more information. The original 
    Mapzen has gone out of business, but 'rmapzen' can be set up to work with 
    any provider who implements the Mapzen API. ",2018-10-07,Tarak Shah,https://tarakc02.github.io/rmapzen/,TRUE,https://github.com/tarakc02/rmapzen,4893,33,1538940535
RMariaDB,Implements a 'DBI'-compliant interface to 'MariaDB' (<https://mariadb.org/>) and 'MySQL' (<https://www.mysql.com/>) databases.,2018-05-06,Kirill Müller  (<https://orcid.org/0000-0002-1416-3412>),"https://github.com/r-dbi/RMariaDB,
https://downloads.mariadb.org/connector-c/",TRUE,https://github.com/r-dbi/rmariadb,46129,59,1548620781
RmarineHeatWaves,"Given a time series of daily temperatures, the package provides tools
    to detect extreme thermal events, including marine heat waves, and to
    calculate the exceedances above or below specified threshold values.
    It outputs the properties of all detected events and exceedances.",2018-06-04,Albertus J. Smit  (R implementation.),https://github.com/ajsmit/RmarineHeatWaves,TRUE,https://github.com/ajsmit/rmarineheatwaves,9126,3,1539579101
rmarkdown,Convert R Markdown documents into a variety of formats.,2019-03-14,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://rmarkdown.rstudio.com,TRUE,https://github.com/rstudio/rmarkdown,8470937,1466,1554486808
rmatio,"Read and write 'Matlab' MAT files from R. The 'rmatio'
    package supports reading MAT version 4, MAT version 5 and MAT
    compressed version 5. The 'rmatio' package can write version 5 MAT
    files and version 5 files with variable compression.",2019-03-18,"Stefan Widgren  (Author of the R interface to the C-library
    matio)",https://github.com/stewid/rmatio,TRUE,https://github.com/stewid/rmatio,41852,6,1552933691
RMAWGEN,"S3 and S4 functions are implemented for spatial multi-site
    stochastic generation of daily time series of temperature and
    precipitation. These tools make use of Vector AutoRegressive models (VARs).
    The weather generator model is then saved as an object and is calibrated by
    daily instrumental ""Gaussianized"" time series through the 'vars' package
    tools. Once obtained this model, it can it can be used for weather
    generations and be adapted to work with several climatic monthly time
    series.",2017-02-11,Emanuele Cordano,"https://github.com/ecor/RMAWGEN,
https://docs.google.com/file/d/0B66otCUk3Bv6V3RPbm1mUG4zVHc/edit,
http://presentations.copernicus.org/EGU2012-14026_presentation.pdf,
http://presentations.copernicus.org/EGU2012-5404_presentation.pdf",TRUE,https://github.com/ecor/rmawgen,27902,0,1551691721
RMCriteria,Provides a methodology to solve most of multicriteria ranking problems using partial and total pre-order from Promethee methods. Albuquerque & Montenegro (2015) <doi:10.1080/03610926.2014.942432>.,2019-01-17,Pedro Albuquerque and Gustavo Monteiro,NA,TRUE,https://github.com/lamfo-unb/rmcriteria,2372,3,1547740109
rmd,"The 'rmd' package manages multiple R markdown packages. These R markdown packages include currently 'rmarkdown', 'knitr', 'bookdown', 'bookdownplus', 'blogdown', 'rticles',  'tinytex', 'xaringan', 'citr',  and 'mindr'. They can be installed and loaded in a single step with the 'rmd' package. The conflicts between these packages are evaluated as well.",2019-02-01,Peng Zhao,https://github.com/pzhaonet/rmd,TRUE,https://github.com/pzhaonet/rmd,1204,18,1554441762
rmda,"Provides tools to evaluate the value of using a risk prediction instrument to decide treatment or intervention (versus no treatment or intervention).  Given one or more risk prediction instruments (risk models) that estimate the probability of a binary outcome, rmda provides functions to estimate and display decision curves and other figures that help assess the population impact of using a risk model for clinical decision making.   Here, ""population"" refers to the relevant patient population. Decision curves display estimates of the (standardized) net benefit over a range of probability thresholds used to categorize observations as 'high risk'. The curves help evaluate a treatment policy that recommends treatment for patients who are estimated to be 'high risk' by comparing the population impact of a risk-based policy to ""treat all"" and ""treat none"" intervention policies.  Curves can be estimated using data from a prospective cohort.  In addition, rmda can estimate decision curves using data from a case-control study if an estimate of the population outcome prevalence is available.  Version 1.4 of the package provides an alternative framing of the decision problem for situations where treatment is the standard-of-care and a risk model might be used to recommend that low-risk patients (i.e., patients below some risk threshold) opt out of treatment. Confidence intervals calculated using the bootstrap can be computed and displayed. A wrapper function to calculate cross-validated curves using k-fold cross-validation is also provided. ",2018-07-17,Marshall Brown,"http://mdbrown.github.io/rmda/, https://github.com/mdbrown/rmda",TRUE,https://github.com/mdbrown/rmda,5628,12,1539724796
rmdformats,"HTML formats and templates for 'rmarkdown' documents, with some extra
    features such as automatic table of contents, lightboxed figures, dynamic
    crosstab helper.",2019-02-19,Julien Barnier,https://github.com/juba/rmdformats,TRUE,https://github.com/juba/rmdformats,29569,312,1552253783
rmdshower,"'R' 'Markdown' format for 'shower' presentations, see
   <https://github.com/shower/shower>.",2018-02-04,Doug Ashton,https://github.com/mangothecat/rmdshower,TRUE,https://github.com/mangothecat/rmdshower,8577,113,1529359910
rMEA,"A suite of tools useful to read, visualize and export bivariate motion energy time-series. Lagged synchrony between subjects can be analyzed through windowed cross-correlation. Surrogate data generation allows an estimation of pseudosynchrony that helps to estimate the effect size of the observed synchronization. Ramseyer & Tschacher (2011) <doi:10.1037/a0023419>.",2019-03-22,Johann R. Kleinbub,https://github.com/kleinbub/rMEA http://www.psync.ch,TRUE,https://github.com/kleinbub/rmea,2211,1,1553252870
rmetalog,"Implementation of the metalog distribution in R.
    The metalog distribution is a modern, highly flexible, data-driven distribution. 
    Metalogs are developed by Keelin (2016) <doi:10.1287/deca.2016.0338>.
    This package provides functions to build these distributions from raw data. 
    Resulting metalog objects are then useful for exploratory and probabilistic analysis.",2018-09-18,Isaac Faber  (<https://orcid.org/0000-0002-4478-9598>),NA,TRUE,https://github.com/isaacfab/rmetalog,1361,8,1554164918
rmio,"Provides header files of 'mio', a cross-platform C++11 header-only 
    library for memory mapped file IO <https://github.com/mandreyel/mio>.",2019-02-22,Florian Privé,https://github.com/privefl/rmio,TRUE,https://github.com/privefl/rmio,1269,2,1550414949
RMixpanel,"Provides an interface to many endpoints of Mixpanel's Data Export, Engage and JQL API. The R functions allow for event and profile data export as well as for segmentation, retention, funnel and addiction analysis. Results are always parsed into convenient R objects. Furthermore it is possible to load and update profiles. ",2018-10-23,Meinhard Ploner,"https://github.com/ploner/RMixpanel, http://www.mixpanel.com",TRUE,https://github.com/ploner/rmixpanel,13417,11,1540312464
rmonad,"
    A monadic solution to pipeline analysis. All operations -- and the errors,
    warnings and messages they emit -- are merged into a directed graph. Infix
    binary operators mediate when values are stored, how exceptions are
    handled, and where pipelines branch and merge. The resulting structure may
    be queried for debugging or report generation. 'rmonad' complements, rather
    than competes with, non-monadic pipeline packages like 'magrittr' or
    'pipeR'. This work is funded by the NSF (award number 1546858).",2018-03-10,Zebulun Arendsee,https://github.com/arendsee/rmonad,TRUE,https://github.com/arendsee/rmonad,4167,47,1539109346
RMTL,"Efficient solvers for 10 regularized multi-task learning algorithms applicable for regression, classification, joint feature selection, task clustering, low-rank learning, sparse learning and network incorporation. Based on the accelerated gradient descent method, the algorithms feature a state-of-art computational complexity O(1/k^2). Sparse model structure is induced by the solving the proximal operator. The detail of the package is described in the paper of Han Cao and Emanuel Schwarz (2018) <doi:10.1093/bioinformatics/bty831>.",2019-02-27,Han Cao,https://github.com/transbioZI/RMTL,TRUE,https://github.com/transbiozi/rmtl,287,5,1553540693
rmumps,"Some basic features of MUMPS (Multifrontal Massively Parallel
         sparse direct Solver) are wrapped in a class whose methods can be used
         for sequentially solving a sparse linear system (symmetric or not)
         with one or many right hand sides (dense or sparse).
         There is a possibility to do separately symbolic analysis,
         LU (or LDL^t) factorization and system solving.
         Third part ordering libraries are included and can be used: PORD, METIS, SCOTCH.
         MUMPS method was first described in Amestoy et al. (2001) <doi:10.1137/S0895479899358194>
         and Amestoy et al. (2006) <doi:10.1016/j.parco.2005.07.004>.",2018-12-18,Serguei Sokol,"http://mumps.enseeiht.fr/, https://github.com/sgsokol/rmumps/",TRUE,https://github.com/sgsokol/rmumps,10925,5,1545148690
rmutil,"A toolkit of functions for nonlinear regression and repeated
    measurements not to be used by itself but called by other Lindsey packages such
    as 'gnlm', 'stable', 'growth', 'repeated', and 'event' 
    (available at <http://www.commanster.eu/rcode.html>).",2019-03-04,Bruce Swihart,http://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/rmutil,62598,0,1551715966
rmweather,"An integrated set of tools to allow data users to conduct 
    meteorological normalisation on air quality data. This meteorological 
    normalisation technique uses predictive random forest models to remove 
    variation of pollutant concentrations so trends and interventions can be 
    explored in a robust way. For examples, see Grange et al. (2018) 
    <doi:10.5194/acp-18-6223-2018> and Grange and Carslaw (2019) 
    <doi:10.1016/j.scitotenv.2018.10.344>.",2018-11-12,Stuart K. Grange  (<https://orcid.org/0000-0003-4093-3596>),https://github.com/skgrange/rmweather,TRUE,https://github.com/skgrange/rmweather,2355,3,1550753748
RMySQL,"Legacy 'DBI' interface to 'MySQL' / 'MariaDB' based on old code
    ported from S-PLUS. A modern 'MySQL' client based on 'Rcpp' is available 
    from the 'RMariaDB' package.",2019-03-04,Jeroen Ooms  (<https://orcid.org/0000-0002-4035-0289>),https://downloads.mariadb.org/connector-c/ (upstream),TRUE,https://github.com/r-dbi/rmysql,1576768,186,1551704059
rnaturalearth,Facilitates mapping by making natural earth map data from <http://www.naturalearthdata.com/> more easily available to R users.,2017-03-21,Andy South,https://github.com/ropenscilabs/rnaturalearth,TRUE,https://github.com/ropenscilabs/rnaturalearth,38447,113,1537913827
rnaturalearthdata,Vector map data from <http://www.naturalearthdata.com/>. Access functions are provided in the accompanying package 'rnaturalearth'.,2017-02-21,Andy South,https://github.com/ropenscilabs/rnaturalearthdata,TRUE,https://github.com/ropenscilabs/rnaturalearthdata,22720,6,1530794974
rncl,"An interface to the Nexus Class Library which allows parsing
    of NEXUS, Newick and other phylogenetic tree file formats. It provides
    elements of the file that can be used to build phylogenetic objects
    such as ape's 'phylo' or phylobase's 'phylo4(d)'. This functionality
    is demonstrated with 'read_newick_phylo()' and 'read_nexus_phylo()'.",2018-07-27,"Francois Michonneau 
    (<https://orcid.org/0000-0002-9092-966X>)",https://github.com/fmichonneau/rncl,TRUE,https://github.com/fmichonneau/rncl,96470,7,1532696022
RNeXML,"Provides access to phyloinformatic data in 'NeXML' format.  The
    package should add new functionality to R such as the possibility to
    manipulate 'NeXML' objects in more various and refined way and compatibility
    with 'ape' objects.",2019-01-24,Carl Boettiger  (<https://orcid.org/0000-0002-1642-628X>),https://github.com/ropensci/RNeXML,TRUE,https://github.com/ropensci/rnexml,88318,10,1548201673
rngtools,"Provides a set of functions for working with
    Random Number Generators (RNGs). In particular, a generic
    S4 framework is defined for getting/setting the current RNG, or RNG data
    that are embedded into objects for reproducibility.
    Notably, convenient default methods greatly facilitate the way current
    RNG settings can be changed.",2018-05-15,Renaud Gaujoux,https://renozao.github.io/rngtools,TRUE,https://github.com/renozao/rngtools,1358098,3,1526382838
RNifti,"Provides very fast read and write access to images stored in the
    NIfTI-1 and ANALYZE-7.5 formats, with seamless synchronisation between
    compiled C and interpreted R code. Also provides a C/C++ API that can be
    used by other packages. Not to be confused with 'RNiftyReg', which performs
    image registration.",2018-10-19,Jon Clayden,https://github.com/jonclayden/RNifti,TRUE,https://github.com/jonclayden/rnifti,53589,16,1542968849
RNiftyReg,"Provides an 'R' interface to the 'NiftyReg' image registration tools
    <http://sourceforge.net/projects/niftyreg/>. Linear and nonlinear registration
    are supported, in two and three dimensions.",2019-03-20,Jon Clayden,https://github.com/jonclayden/RNiftyReg,TRUE,https://github.com/jonclayden/rniftyreg,25543,16,1552858022
Rnightlights,"Extracts raster and zonal statistics
    from satellite nightlight rasters downloaded from the United States 
    National Oceanic and Atmospheric Administration (<http://www.noaa.gov>) 
    free data repositories. Both the DMSP-OLS annual and SNPP-VIIRS monthly 
    nightlight raster data are supported. Satellite nightlight raster tiles are 
    downloaded and cropped to the country boundaries using shapefiles from the GADM
    database of Global Administrative Areas (<http://gadm.org>). Zonal statistics
    are then calculated at the lowest administrative boundary for the selected
    country and cached locally for future retrieval. Finally, a simple data
    explorer/browser is included that allows one to visualize the cached data e.g.
    graphing, mapping and clustering regional data.",2018-10-13,Christopher Njuguna,https://github.com/chrisvwn/Rnightlights,TRUE,https://github.com/chrisvwn/rnightlights,7308,21,1553689638
Rnmr1D,Perform the complete processing of a set of proton nuclear magnetic resonance spectra from the free induction decay (raw data) and based on a processing sequence (macro-command file). An additional file specifies all the spectra to be considered by associating their sample code as well as the levels of experimental factors to which they belong. More detail can be found in Jacob et al. (2017) <doi:10.1007/s11306-017-1178-y>.,2019-03-27,Daniel Jacob  (<https://orcid.org/0000-0002-6687-7169>),https://github.com/INRA/Rnmr1D,TRUE,https://github.com/inra/rnmr1d,1727,0,1553869168
rnn,Implementation of a Recurrent Neural Network in R.,2018-06-21,Bastiaan Quast,"http://qua.st/rnn, https://github.com/bquast/rnn",TRUE,https://github.com/bquast/rnn,25136,47,1541067425
rnoaa,"Client for many 'NOAA' data sources including the 'NCDC' climate
    'API' at <https://www.ncdc.noaa.gov/cdo-web/webservices/v2>, with functions for
    each of the 'API' 'endpoints': data, data categories, data sets, data types,
    locations, location categories, and stations. In addition, we have an interface
    for 'NOAA' sea ice data, the 'NOAA' severe weather inventory, 'NOAA' Historical
    Observing 'Metadata' Repository ('HOMR') data, 'NOAA' storm data via 'IBTrACS',
    tornado data via the 'NOAA' storm prediction center, and more.",2019-01-14,Scott Chamberlain,https://github.com/ropensci/rnoaa,TRUE,https://github.com/ropensci/rnoaa,99625,192,1551280039
rnrfa,"Utility functions to retrieve data from the UK National River Flow Archive (<http://nrfa.ceh.ac.uk/>). The package contains R wrappers to the UK NRFA data temporary-API. There are functions to retrieve stations falling in a bounding box, to generate a map and extracting time series and general information.",2018-11-20,Claudia Vitolo,http://cvitolo.github.io/rnrfa/,TRUE,https://github.com/cvitolo/rnrfa,17939,6,1552076521
Rnumerai,"Routines to interact with the Numerai Machine Learning Tournament
  API <https://numer.ai>. The functionality includes the ability to automatically download the
  current tournament data, submit predictions, and to get information for your
  user. General 'GraphQL' queries can also be executed.",2018-05-01,Eric Hare,https://github.com/Omni-Analytics-Group/Rnumerai,TRUE,https://github.com/omni-analytics-group/rnumerai,2770,16,1553621318
roadoi,"This web client interfaces Unpaywall <https://unpaywall.org/products/api>, formerly
    oaDOI, a service finding free full-texts of academic papers by linking DOIs with 
    open access journals and repositories. It provides unified access to various data sources 
    for open access full-text links including Crossref and the Directory of Open Access 
    Journals (DOAJ). API usage is free and no registration is required.",2018-08-07,Najko Jahn,https://github.com/ropensci/roadoi,TRUE,https://github.com/ropensci/roadoi,5940,33,1543252785
RobinHood,"Execute API calls to the RobinHood <https://robinhood.com> investing platform. Functionality includes accessing account data and current holdings, retrieving investment statistics and quotes, placing and canceling orders, getting market trading hours, searching investments by popular tag, and interacting with watch lists.",2019-04-06,Joseph Blubaugh,https://github.com/JestonBlu/RobinHood,TRUE,https://github.com/jestonblu/robinhood,524,3,1554553218
robis,Client for the Ocean Biogeographic Information System (<https://obis.org>).,2019-02-27,Pieter Provoost,https://github.com/iobis/robis,TRUE,https://github.com/iobis/robis,4331,17,1551190909
robotstxt,"Provides functions to download and parse 'robots.txt' files.
        Ultimately the package makes it easy to check if bots
        (spiders, crawler, scrapers, ...) are allowed to access specific
        resources on a domain.",2018-07-18,Peter Meissner,https://github.com/ropensci/robotstxt,TRUE,https://github.com/ropensci/robotstxt,10650,41,1547155808
robustlmm,"A method to fit linear mixed effects models robustly.
    Robustness is achieved by modification of the scoring equations
    combined with the Design Adaptive Scale approach.",2019-02-03,Manuel Koller,https://github.com/kollerma/robustlmm,TRUE,https://github.com/kollerma/robustlmm,34158,10,1549268154
rocTree,"Receiver Operating Characteristic (ROC)-guided survival trees and forests algorithms are implemented, providing a unified framework for tree-structured analysis with censored survival outcomes. A time-invariant partition scheme on the survivor population was considered to incorporate time-dependent covariates. Motivated by ideas of randomized tests, generalized time-dependent ROC curves were used to evaluate the performance of survival trees and establish the optimality of the target hazard function. The optimality of the target hazard function motivates us to use a weighted average of the time-dependent area under the curve (AUC) on a set of time points to evaluate the prediction performance of survival trees and to guide splitting and pruning. A detailed description of the implemented methods can be found in Sun et al. (2019) <arXiv:1809.05627>.",2019-03-24,Sy Han Chiou,http://github.com/stc04003/rocTree,TRUE,https://github.com/stc04003/roctree,90,0,1553098818
Rodam,"'ODAM' (Open Data for Access and Mining) is a framework that implements a simple way to make research data broadly accessible and fully available for reuse, including by a script language such as R. The main purpose is to make a data set accessible online with a minimal effort from the data provider, and to allow any scientists or bioinformaticians to be able to explore the data set and then extract a subpart or the totality of the data according to their needs. The Rodam package has only one class, 'odamws', that provides methods to allow you to retrieve online data using 'ODAM' Web Services. This obviously requires that data are implemented according the 'ODAM' approach , namely that the data subsets were deposited in the suitable data repository in the form of TSV files associated with  their metadata also described  in TSV files. See <http://www.slideshare.net/danieljacob771282/odam-open-data-access-and-mining>.",2019-03-21,Daniel Jacob  (<https://orcid.org/0000-0002-6687-7169>),https://github.com/INRA/ODAM,TRUE,https://github.com/inra/odam,4839,2,1539763168
rodeo,"Provides an R6 class and several utility methods to
    facilitate the implementation of models based on ordinary
    differential equations. The heart of the package is a code generator
    that creates compiled 'Fortran' (or 'R') code which can be passed to
    a numerical solver. There is direct support for solvers contained
    in packages 'deSolve' and 'rootSolve'.",2018-03-07,David Kneis <david.kneis@tu-dresden.de>,https://github.com/dkneis/rodeo,TRUE,https://github.com/dkneis/rodeo,6584,3,1526071919
rodham,"Fetch and process Hillary Rodham Clinton's ""personal"" emails.",2017-07-18,John Coene,https://github.com/JohnCoene/rodham,TRUE,https://github.com/johncoene/rodham,6237,1,1547453186
ROI.plugin.clp,"Enhances the R Optimization Infrastructure (ROI) package by registering
	     the COIN-OR Clp open-source solver from the COIN-OR suite <https://projects.coin-or.org/>.
	     It allows for solving linear programming with continuous objective variables 
	     keeping sparse constraints definition.",2017-09-20,Benoit Thieurmel,"https://github.com/datastorm-open/ROI.plugin.clp,
https://projects.coin-or.org/Clp",TRUE,https://github.com/datastorm-open/roi.plugin.clp,4585,2,1523353301
roll,Fast and efficient computation of rolling statistics for time-series data.,2019-02-06,Jason Foster,https://github.com/jjf234/roll,TRUE,https://github.com/jjf234/roll,26367,42,1550514838
rollmatch,"Functions to perform propensity score matching on rolling entry interventions for which a suitable ""entry"" date is not observed for nonparticipants. For more details, please reference Witman, Beadles, Liu, Larsen, Kafali, Gandhi, Amico, and Hoerger (2018) <https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-6773.13086>.",2019-02-19,Rob Chew,https://github.com/RTIInternational/rollmatch,TRUE,https://github.com/rtiinternational/rollmatch,3009,1,1550584340
rollply,"Apply a function in a moving window, then
    combine the results in a data frame.",2016-03-24,Alexandre Genin <alex@lecairn.org>,"http://alex.lecairn.org/rollply.html,
https://github.com/alexgenin/rollply",TRUE,https://github.com/alexgenin/rollply,7010,5,1526768502
rollRegres,"Methods for fast rolling and expanding linear regression models. That is, series of linear regression models estimated on either an expanding window of data or a moving window of data. The methods use rank-one updates and downdates of the upper triangular matrix from a QR decomposition (see Dongarra, Moler, Bunch, and Stewart (1979) <doi:10.1137/1.9781611971811>).",2018-09-12,Benjamin Christoffersen,https://github.com/boennecd/rollRegres,TRUE,https://github.com/boennecd/rollregres,3149,3,1536777015
rolypoly,"Using enrichment of genome-wide association summary statistics to
  identify trait-relevant cellular functional annotations.",2017-03-16,Diego Calderon,https://github.com/dcalderon/rolypoly,TRUE,https://github.com/dcalderon/rolypoly,3657,10,1528671235
ropenaq,"Allows access to air quality data from the API of the OpenAQ
    platform <https://docs.openaq.org/>, with the different services the API offers
    (getting measurements for a given query, getting latest measurements, getting
    lists of available countries/cities/locations). This package has been peer-reviewed by rOpenSci (v. 0.1.0).",2019-01-31,Maëlle Salmon,http://github.com/ropensci/ropenaq,TRUE,https://github.com/ropensci/ropenaq,10324,36,1553523857
ropendata,"'Rapid7' collects 'cybersecurity' data and makes it available via
    their 'Open Data' <http://opendata.rapid7.com> portal which has an API. Tools are
    provided to assist in querying for available data sets and downloading any
    data set authorized to a free, registered account.",2019-02-08,Bob Rudis  (<https://orcid.org/0000-0001-5670-2640>),https://github.com/brudis-r7/ropendata,TRUE,https://github.com/brudis-r7/ropendata,483,8,1548020050
ROpenDota,"Provides a client for the API of OpenDota. OpenDota is a web service which is provide DOTA2 real time data. Data is collected through the Steam WebAPI. With ROpenDota you can easily grab the latest DOTA2 statistics in R programming such as latest match on official international competition, analyzing your or enemy performance to learn their strategies,etc. Please see <https://github.com/rosdyana/ROpenDota> for more information.",2018-06-13,Rosdyana Kusuma,https://github.com/rosdyana/ROpenDota,TRUE,https://github.com/rosdyana/ropendota,3635,2,1540957753
ropercenter,"Reproducible, programmatic retrieval of datasets from the
    Roper Center data archive.  The Roper Center for Public Opinion
    Research <https://ropercenter.cornell.edu> maintains the largest 
    archive of public opinion data in existence, but researchers using
    these datasets are caught in a bind.  The Center's terms and conditions
    bar redistribution of downloaded datasets, but to ensure that one's 
    work can be reproduced, assessed, and built upon by others, one must
    provide access to the raw data one employed.  The `ropercenter`
    package cuts this knot by providing registered users with programmatic,
    reproducible access to Roper Center datasets from within R.",2018-06-28,Frederick Solt,https://github.com/fsolt/ropercenter,TRUE,https://github.com/fsolt/ropercenter,3863,2,1537450851
Ropj,"Read the data from Origin(R) project files ('*.opj')
	<https://www.originlab.com/doc/User-Guide/Origin-File-Types>.
	No write support is planned. More object types may be available
	to be imported later.",2019-03-14,Ivan Krylov,https://github.com/aitap/Ropj,TRUE,https://github.com/aitap/ropj,493,0,1552573971
roptim,"Perform general purpose optimization in R using C++. A unified 
    wrapper interface is provided to call C functions of the five optimization 
    algorithms ('Nelder-Mead', 'BFGS', 'CG', 'L-BFGS-B' and 'SANN') underlying 
    optim().",2018-11-12,Yi Pan,https://github.com/ypan1988/roptim/,TRUE,https://github.com/ypan1988/roptim,1820,2,1547655549
rorcid,"Client for the 'Orcid.org' 'API' (<https://orcid.org/>).
    Functions included for searching for people, searching by 'DOI',
    and searching by 'Orcid' 'ID'.",2018-02-11,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rorcid,TRUE,https://github.com/ropensci/rorcid,9372,54,1540838121
rosetta,"When teaching statistics, it can often be desirable to
  uncouple the content from specific software packages. To easy such
  efforts, the Rosetta Stats website (<https://rosettastats.com>) allows
  comparing analyses in different packages. This package is the companion
  to the Rosetta Stats website, aiming to provide functions that produce
  output that is similar to output from other statistical packages, thereby
  facilitating 'software-agnostic' teaching of statistics.",2019-02-08,Gjalt-Jorn Peters,https://rosetta.opens.science,TRUE,https://github.com/psytext/rosetta,446,0,1549283799
rosm,"Download and plot Open Street Map <http://www.openstreetmap.org/>,
    Bing Maps <http://www.bing.com/maps> and other tiled map sources. Use to create 
    basemaps quickly and add hillshade to vector-based maps.",2019-03-15,Dewey Dunnington  (<https://orcid.org/0000-0002-9415-4582>),https://github.com/paleolimbot/rosm,TRUE,https://github.com/paleolimbot/rosm,40001,13,1552668659
rospca,"Implementation of robust sparse PCA using the ROSPCA algorithm 
             of Hubert et al. (2016) <DOI:10.1080/00401706.2015.1093962>.",2018-02-26,Tom Reynkens  (<https://orcid.org/0000-0002-5516-5107>),https://github.com/TReynkens/rospca,TRUE,https://github.com/treynkens/rospca,5702,6,1540050399
rosr,"Creates reproducible academic projects with integrated academic elements, including datasets, references, codes, images, manuscripts, dissertations, slides and so on. These elements are well connected so that they can be easily synchronized and updated. ",2019-03-23,Peng Zhao,https://github.com/pzhaonet/rosr,TRUE,https://github.com/pzhaonet/rosr,606,17,1553979244
rotl,"An interface to the 'Open Tree of Life' API to retrieve
    phylogenetic trees, information about studies used to assemble the synthetic
    tree, and utilities to match taxonomic names to 'Open Tree identifiers'. The
    'Open Tree of Life' aims at assembling a comprehensive phylogenetic tree for all
    named species.",2019-02-15,"Francois Michonneau 
    (<https://orcid.org/0000-0002-9092-966X>)",https://github.com/ropensci/rotl,TRUE,https://github.com/ropensci/rotl,87072,21,1553530626
RoughSets,"Implementations of algorithms for data analysis
    based on the rough set theory (RST) and the fuzzy rough set theory (FRST). We
    not only provide implementations for the basic concepts of RST and FRST but also
    popular algorithms that derive from those theories. The methods included in the
    package can be divided into several categories based on their functionality:
    discretization, feature selection, instance selection, rule induction and classification
    based on nearest neighbors. RST was introduced by Zdzisław Pawlak in 1982
    as a sophisticated mathematical tool to
    model and process imprecise or incomplete information. By using
    the indiscernibility relation for objects/instances, RST does not require
    additional parameters to analyze the data. FRST is an extension of RST. The
    FRST combines concepts of vagueness and indiscernibility that are expressed
    with fuzzy sets (as proposed by Zadeh, in 1965) and RST.",2015-09-05,Lala Septem Riza,https://github.com/janusza/RoughSets,TRUE,https://github.com/janusza/roughsets,23452,16,1527626237
roundhouse,"An R wrapper to the 'Internet Chuck Norris database' ('ICNDb') API for 
  generating random Chuck Norris facts.",2018-09-16,Brandon Greenwell,ttps://github.com/bgreenwell/roundhouse,TRUE,https://github.com/bgreenwell/roundhouse,1556,2,1537840120
rowr,"Provides utilities which interact with all R objects as
    if they were arranged in rows.  It allows more consistent and predictable 
    output to common functions, and generalizes a number of utility functions to
    to be failsafe with any number and type of input objects.",2016-12-22,Craig Varrichio <canthony427@gmail.com>,https://github.com/cvarrichio/rowr,TRUE,https://github.com/cvarrichio/rowr,37335,6,1524159326
roxygen2,"Generate your Rd documentation, 'NAMESPACE' file, and collation 
    field using specially formatted comments. Writing documentation in-line
    with code makes it easier to keep your documentation up-to-date as your
    requirements change. 'Roxygen2' is inspired by the 'Doxygen' system for C++.",2018-11-07,Hadley Wickham,https://github.com/klutometis/roxygen,TRUE,https://github.com/klutometis/roxygen,1503169,322,1543790772
rPackedBar,Packed bar charts are a variation of treemaps for visualizing skewed data.  The concept was introduced by Xan Gregg at 'JMP'.,2019-03-18,Adam Spannbauer,https://github.com/AdamSpannbauer/rPackedBar,TRUE,https://github.com/adamspannbauer/rpackedbar,2423,0,1552912110
RPANDA,"Implements macroevolutionary analyses on phylogenetic trees. See
    Morlon et al. (2010) <DOI:10.1371/journal.pbio.1000493>, Morlon et al. (2011)
    <DOI:10.1073/pnas.1102543108>, Condamine et al. (2013) <DOI:10.1111/ele.12062>, 
    Morlon et al. (2014) <DOI:10.1111/ele.12251>, Manceau et al. (2015) <DOI:10.1111/ele.12415>,
    Lewitus & Morlon (2016) <DOI:10.1093/sysbio/syv116>, Drury et al. (2016) <DOI:10.1093/sysbio/syw020>,
    Manceau et al. (2016) <DOI:10.1093/sysbio/syw115>, Morlon et al. (2016) <DOI:10.1111/2041-210X.12526>, 
    Clavel & Morlon (2017) <DOI:10.1073/pnas.1606868114>, Drury et al. (2017) <DOI:10.1093/sysbio/syx079>, 
    Lewitus & Morlon (2017) <DOI:10.1093/sysbio/syx095>, Drury et al. (2018) <DOI:10.1371/journal.pbio.2003563> 
    and Clavel et al. (2019) <DOI:10.1093/sysbio/syy045>.",2019-01-30,Hélène Morlon,https://github.com/hmorlon/PANDA,TRUE,https://github.com/hmorlon/panda,13576,10,1553526485
rpdo,"Monthly Pacific Decadal Oscillation (PDO) index
    values from January 1900 to present.",2018-11-17,Joe Thorley  (<https://orcid.org/0000-0002-7683-4592>),https://github.com/poissonconsulting/rpdo,TRUE,https://github.com/poissonconsulting/rpdo,10638,2,1542498886
rpf,"The purpose of this package is to factor out logic and math common
    to Item Factor Analysis fitting, diagnostics, and analysis. It is
    envisioned as core support code suitable for more specialized IRT packages
    to build upon. Complete access to optimized C functions are made available
    with R_RegisterCCallable().",2019-03-08,Joshua Pritikin,https://github.com/jpritikin/rpf,TRUE,https://github.com/jpritikin/rpf,206517,0,1551820184
rphylopic,"Work with 'Phylopic' web service (<http://phylopic.org/api/>) 
    to get 'silhouette' images of 'organisms', search names, and more.
    Includes functions for adding 'silhouettes' to both base plots and
    ggplot2 plots.",2018-11-19,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/sckott/rphylopic,TRUE,https://github.com/sckott/rphylopic,1105,58,1542661582
rplos,"A programmatic interface to the 'SOLR' based
    search API (<http://api.plos.org/>) provided by the Public
    Library of Science journals to search their articles.
    Functions are included for searching for articles, retrieving
    articles, making plots, doing 'faceted' searches,
    'highlight' searches, and viewing results of 'highlighted'
    searches in a browser.",2018-08-14,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rplos,TRUE,https://github.com/ropensci/rplos,35719,263,1547100997
Rpolyhedra,A polyhedra database scraped from various sources as R6 objects and 'rgl' visualizing capabilities.,2019-03-26,Alejandro Baranek,https://github.com/ropensci/Rpolyhedra,TRUE,https://github.com/ropensci/rpolyhedra,5761,7,1553619159
rpostgis,"Provides an interface between R and 'PostGIS'-enabled
    'PostgreSQL' databases to transparently transfer spatial
    data. Both vector (points, lines, polygons) and raster data are
    supported in read and write modes. Also provides convenience
    functions to execute common procedures in 'PostgreSQL/PostGIS'.",2018-11-12,David Bucklin,https://mablab.org/rpostgis/index.html,TRUE,https://github.com/mablab/rpostgis,16647,41,1542053102
rpostgisLT,"Integrates R and the 'PostgreSQL/PostGIS' database 
    system to build and manage animal trajectory (movement) data sets. 
    The package relies on 'ltraj' objects from the R package 'adehabitatLT',
    building the analogous 'pgtraj' data structure in 'PostGIS'. Functions
    allow users to seamlessly transfer between 'ltraj' and 'pgtraj', as
    well as build new 'pgtraj' directly from location data stored in the 
    database.",2018-03-02,"Balázs Dukai  (Package creator during Google Summer of Code
    2016 and 2017)",https://github.com/mablab/rpostgisLT,TRUE,https://github.com/mablab/rpostgislt,4698,9,1528891875
RPostgres,"
    Fully 'DBI'-compliant 'Rcpp'-backed interface to 'PostgreSQL' <https://www.postgresql.org/>,
    an open-source relational database.",2018-05-06,Kirill Müller  (<https://orcid.org/0000-0002-1416-3412>),https://github.com/r-dbi/RPostgres,TRUE,https://github.com/r-dbi/rpostgres,72160,164,1552857432
RPostgreSQL,"Database interface and 'PostgreSQL' driver for 'R'.
 This package provides a Database Interface 'DBI' compliant 
 driver for 'R' to access 'PostgreSQL' database systems.  
 In order to build and install this package from source, 'PostgreSQL' 
 itself must be present your system to provide 'PostgreSQL' functionality 
 via its libraries and header files. These files are provided as
 'postgresql-devel' package under some Linux distributions.
 On 'macOS' and 'Microsoft Windows' system the attached 'libpq' library source will be used.",2017-06-24,Joe Conway,"https://github.com/tomoakin/RPostgreSQL,
https://cran.r-project.org/package=DBI,
http://www.postgresql.org",TRUE,https://github.com/tomoakin/rpostgresql,982727,37,1534740860
rppo,"An R interface to the Global Plant Phenology Data Portal,
    which is accessible online at <https://www.plantphenology.org/>.",2018-06-06,John Deck,https://github.com/ropensci/rppo,TRUE,https://github.com/ropensci/rppo,1672,0,1528303249
rPraat,"Read, write and manipulate 'Praat' TextGrid, PitchTier, Pitch, IntensityTier, Formant, and Collection files <http://www.fon.hum.uva.nl/praat/>.",2019-04-01,Tomas Boril,https://github.com/bbTomas/rPraat/,TRUE,https://github.com/bbtomas/rpraat,4707,7,1554114322
RPresto,"Implements a 'DBI' compliant interface to Presto. Presto is
    an open source distributed SQL query engine for running interactive
    analytic queries against data sources of all sizes ranging from
    gigabytes to petabytes: <https://prestodb.io/>.",2018-10-23,Onur Ismail Filiz,https://github.com/prestodb/RPresto,TRUE,https://github.com/prestodb/rpresto,19762,94,1554149782
rprev,"Estimates disease prevalence for a given index date, using existing
    registry data extended with Monte Carlo simulations.",2019-03-12,Stuart Lacy,https://github.com/stulacy/rprev-dev,TRUE,https://github.com/stulacy/rprev-dev,6061,0,1552408581
rprojroot,"Robust, reliable and flexible paths to files below a
    project root. The 'root' of a project is defined as a directory
    that matches a certain criterion, e.g., it contains a certain
    regular file.",2018-01-03,Kirill Müller,"https://github.com/krlmlr/rprojroot,
https://krlmlr.github.io/rprojroot",TRUE,https://github.com/krlmlr/rprojroot,5262402,103,1529529766
RProtoBuf,"Protocol Buffers are a way of encoding structured data in an
 efficient yet extensible format. Google uses Protocol Buffers for almost all
 of its internal 'RPC' protocols and file formats.  Additional documentation
 is available in two included vignettes one of which corresponds to our 'JSS'
 paper (2016, <doi:10.18637/jss.v071.i02>. Either version 2 or 3 of the
 'Protocol Buffers' 'API' is supported.",2018-11-03,Romain Francois,https://github.com/eddelbuettel/rprotobuf,TRUE,https://github.com/eddelbuettel/rprotobuf,45103,34,1551006337
rpubchem,"Access PubChem data (compounds, substance, assays) using R.
 Structural information is provided in the form of SMILES strings. 
 It currently only provides access to a subset of the 
 precalculated data stored by PubChem. Bio-assay data can be accessed to 
 obtain descriptions as well as the actual data. It is also possible to search for assay ID's by keyword. ",2016-12-27,Rajarshi Guha,"https://github.com/rajarshi/cdkr,
https://pubchem.ncbi.nlm.nih.gov/",TRUE,https://github.com/rajarshi/cdkr,17326,26,1549160533
RPyGeo,"Provides access to ArcGIS geoprocessing tools by building an 
             interface between R and the ArcPy Python side-package via the 
             reticulate package. ",2018-11-14,Alexander Brenning,https://github.com/fapola/RPyGeo,TRUE,https://github.com/fapola/rpygeo,17881,12,1551970835
rqdatatable,"Implements the 'rquery' piped Codd-style query algebra using 'data.table'.  This allows
   for a high-speed in memory implementation of Codd-style data manipulation tools.",2019-02-25,John Mount,"https://github.com/WinVector/rqdatatable/,
https://winvector.github.io/rqdatatable/",TRUE,https://github.com/winvector/rqdatatable,6738,24,1551058674
RQEntangle,"It computes the Schmidt decomposition of bipartite quantum systems, discrete or continuous,
    and their respective entanglement metrics. See Artur Ekert, Peter L. Knight (1995) <doi:10.1119/1.17904> 
    for more details.",2019-01-04,Kwan-Yuet Ho,https://github.com/stephenhky/RQEntangle,TRUE,https://github.com/stephenhky/rqentangle,2048,0,1546561004
RQGIS,"Establishes an interface between R and 'QGIS', i.e. it allows
    the user to access 'QGIS' functionalities from the R console. It achieves this
    by using the 'QGIS' Python API via the command line. Hence, RQGIS extends R's
    statistical power by the incredible vast geo-functionality of 'QGIS' (including
    also 'GDAL', 'SAGA'- and 'GRASS'-GIS among other third-party providers).
    This in turn creates a powerful environment for advanced and innovative
    (geo-)statistical geocomputing. 'QGIS' is licensed under GPL version 2 or
    greater and is available from <http://www.qgis.org/en/site/>.",2018-08-13,Jannes Muenchow  (<https://orcid.org/0000-0001-7834-4717>),https://github.com/jannes-m/RQGIS,TRUE,https://github.com/jannes-m/rqgis,22845,169,1543949711
RQuantLib,"The 'RQuantLib' package makes parts of 'QuantLib' accessible from R
 The 'QuantLib' project aims to provide a comprehensive software framework
 for quantitative finance. The goal is to provide a standard open source library
 for quantitative analysis, modeling, trading, and risk management of financial
 assets.",2019-03-17,Dirk Eddelbuettel,http://dirk.eddelbuettel.com/code/rquantlib.html,TRUE,https://github.com/eddelbuettel/rquantlib,84672,65,1552848618
rquery,"A piped query generator based on Edgar F. Codd's relational
    algebra, and on production experience using 'SQL' and 'dplyr' at big data
    scale.  The design represents an attempt to make 'SQL' more teachable by
    denoting composition by a sequential pipeline notation instead of nested
    queries or functions.   The implementation delivers reliable high 
    performance data processing on large data systems such as 'Spark',
    databases, and 'data.table'. Package features include: data processing trees
    or pipelines as observable objects (able to report both columns
    produced and columns used), optimized 'SQL' generation as an explicit
    user visible table modeling step, plus explicit query reasoning and checking.",2019-03-10,John Mount,"https://github.com/WinVector/rquery/,
https://winvector.github.io/rquery/",TRUE,https://github.com/winvector/rquery,18650,77,1552480376
rr2,"Three methods to calculate R2 for models with correlated errors, 
    including Phylogenetic GLS, Phylogenetic Logistic Regression, Linear Mixed 
    Models (LMMs), and Generalized Linear Mixed Models (GLMMs). See details in 
    Ives 2018 <doi:10.1093/sysbio/syy060>.",2019-02-04,Anthony Ives,https://github.com/arives/rr2,TRUE,https://github.com/arives/rr2,1507,12,1549250093
Rraven,A tool to exchange data between R and 'Raven' sound analysis software <http://www.birds.cornell.edu/brp/raven/RavenOverview.html> (Cornell Lab of Ornithology). Functions work on data formats compatible with the R package 'warbleR'.,2019-03-05,Marcelo Araya-Salas,https://github.com/maRce10/Rraven,TRUE,https://github.com/marce10/rraven,4429,1,1552357659
rredlist,"'IUCN' Red List (<http://apiv3.iucnredlist.org/api/v3/docs>) client.
    The 'IUCN' Red List is a global list of threatened and endangered species.
    Functions cover all of the Red List 'API' routes. An 'API' key is required.",2018-07-19,Scott Chamberlain,https://github.com/ropensci/rredlist,TRUE,https://github.com/ropensci/rredlist,78969,19,1547145149
rrepast,"An R and Repast integration tool for running individual-based
    (IbM) simulation models developed using 'Repast Simphony' Agent-Based framework
    directly from R code supporting multicore execution. This package 
    integrates 'Repast Simphony' models within R environment, making easier 
    the tasks of running and analyzing model output data for 
    automated parameter calibration and for carrying out uncertainty and
    sensitivity analysis using the power of R environment.",2018-06-25,Antonio Prestes Garcia,https://github.com/antonio-pgarcia/rrepast,TRUE,https://github.com/antonio-pgarcia/rrepast,8103,1,1548024574
RRPP,"Linear model calculations are made for many random versions of data.  
    Using residual randomization in a permutation procedure, sums of squares are 
    calculated over many permutations to generate empirical probability distributions 
    for evaluating model effects.  This packaged is described by 
    Collyer & Adams (2018) <doi:10.1111/2041-210X.13029>.  Additionally, coefficients, statistics, fitted values, and residuals generated over many 
    permutations can be used for various procedures including pairwise tests, prediction, classification, and
    model comparison.  This package should provide most tools one could need for the analysis of
    high-dimensional data, especially in ecology and evolutionary biology, but certainly other fields, as well.",2019-04-02,Michael Collyer,https://github.com/mlcollyer/RRPP,TRUE,https://github.com/mlcollyer/rrpp,11169,1,1554316159
RSAGA,"Provides access to geocomputing and terrain analysis functions
    of the geographical information system (GIS) 'SAGA' (System for Automated
    Geoscientific Analyses) from within R by running the command line version of
    SAGA. This package furthermore provides several R functions for handling ASCII
    grids, including a flexible framework for applying local functions (including
    predict methods of fitted models) and focal functions to multiple grids. SAGA
    GIS is available under GPLv2 / LGPLv2 licence from 
    <http://sourceforge.net/projects/saga-gis/>.",2018-11-12,Alexander Brenning  (<https://orcid.org/0000-0001-6640-679X>),https://github.com/r-spatial/RSAGA,TRUE,https://github.com/r-spatial/rsaga,111046,4,1542795406
RSAlgaeR,"Assists in processing reflectance data, developing empirical models using stepwise regression and a generalized linear modeling approach, cross-
    validation, and analysis of trends in water quality conditions (specifically chl-a) and climate conditions using the Theil-Sen estimator.",2018-04-10,Carly Hansen,http://github.com/cahhansen/RSAlgae,TRUE,https://github.com/cahhansen/rsalgae,1947,2,1547878831
rsample,"Classes and functions to create and summarize different types of resampling objects (e.g. bootstrap, cross-validation). ",2019-01-07,Max Kuhn,https://tidymodels.github.io/rsample,TRUE,https://github.com/tidymodels/rsample,54609,132,1548784114
rscala,"'Scala' <http://www.scala-lang.org/> is embedded in 'R' and callbacks from 'Scala' to 'R' are available. Support is provided to write 'R' packages that access 'Scala'. After installation, please run 'rscala::scalaConfig()'.",2018-12-15,David B. Dahl,https://github.com/dbdahl/rscala,TRUE,https://github.com/dbdahl/rscala,35584,75,1553039644
rscopus,"Uses Elsevier 'Scopus' API
    <https://dev.elsevier.com/sc_apis.html> to download 
    information about authors and their citations.",2018-11-19,John Muschelli,"https://dev.elsevier.com/sc_apis.html,
https://github.com/muschellij2/rscopus",TRUE,https://github.com/muschellij2/rscopus,22563,23,1551395154
rscorecard,"A method to download Department of Education College
     Scorecard data using the public API
     <https://collegescorecard.ed.gov/data/documentation/>. It is based on
     the 'dplyr' model of piped commands to select and filter data in a
     single chained function call.  An API key from the U.S. Department of
     Education is required.",2018-11-05,Benjamin Skinner  (<https://orcid.org/0000-0002-0337-7415>),https://github.com/btskinner/rscorecard,TRUE,https://github.com/btskinner/rscorecard,10884,9,1541180520
rsdmx,"Set of classes and methods to read data and metadata documents
  exchanged through the Statistical Data and Metadata Exchange (SDMX) framework,
  currently focusing on the SDMX XML standard format (SDMX-ML).",2018-09-21,Emmanuel Blondel  (<https://orcid.org/0000-0002-5870-5762>),"https://github.com/opensdmx/rsdmx, http://www.sdmx.org",TRUE,https://github.com/opensdmx/rsdmx,46516,73,1537485473
RSelenium,"Provides a set of R bindings for the 'Selenium 2.0 WebDriver'
    (see <https://seleniumhq.github.io/docs/wd.html>
    for more information) using the 'JsonWireProtocol' (see
    <https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol> for more
    information). 'Selenium 2.0 WebDriver' allows driving a web browser
    natively as a user would either locally or on a remote machine using
    the Selenium server it marks a leap forward in terms of web browser
    automation. Selenium automates web browsers (commonly referred to as
    browsers). Using RSelenium you can automate browsers locally or
    remotely.",2019-01-03,John Harrison (original author),http://ropensci.github.io/RSelenium,TRUE,https://github.com/ropensci/rselenium,169121,218,1546291201
RSGHB,"Functions for estimating models using a Hierarchical Bayesian (HB) framework. The flexibility comes in allowing the user to specify the likelihood function directly instead of assuming predetermined model structures. Types of models that can be estimated with this code include the family of discrete choice models (Multinomial Logit, Mixed Logit, Nested Logit, Error Components Logit and Latent Class) as well ordered response models like ordered probit and ordered logit. In addition, the package allows for flexibility in specifying parameters as either fixed (non-varying across individuals) or random with continuous distributions. Parameter distributions supported include normal, positive/negative log-normal, positive/negative censored normal, and the Johnson SB distribution. Kenneth Train's Matlab and Gauss code for doing Hierarchical Bayesian estimation has served as the basis for a few of the functions included in this package. These Matlab/Gauss functions have been rewritten to be optimized within R. Considerable code has been added to increase the flexibility and usability of the code base. Train's original Gauss and Matlab code can be found here: <http://elsa.berkeley.edu/Software/abstracts/train1006mxlhb.html> See Train's chapter on HB in Discrete Choice with Simulation here: <http://elsa.berkeley.edu/books/choice2.html>; and his paper on using HB with non-normal distributions here: <http://eml.berkeley.edu//~train/trainsonnier.pdf>. The authors would also like to thank the invaluable contributions of Stephane Hess and the Choice Modelling Centre: <https://cmc.leeds.ac.uk/>.",2019-01-07,Jeff Dumont,https://github.com/RSGInc/RSGHB,TRUE,https://github.com/rsginc/rsghb,28386,16,1546804936
rsimsum,"Summarise results from simulation studies and compute Monte Carlo
  standard errors of commonly used summary statistics. This package is modelled 
  on the 'simsum' user-written command in 'Stata' (See White I.R., 2010 
  <http://www.stata-journal.com/article.html?article=st0200>).",2019-03-15,"Alessandro Gasparini 
    (<https://orcid.org/0000-0002-8319-7624>)",https://ellessenne.github.io/rsimsum/,TRUE,https://github.com/ellessenne/rsimsum,3169,5,1552660705
rsinaica,"Easy-to-use functions for downloading air quality data from the 
    Mexican National Air Quality Information System (SINAICA).  Allows you to 
    query pollution and meteorological parameters from more than a hundred
    monitoring stations located throughout Mexico. See <https://sinaica.inecc.gob.mx> 
    for more information.",2019-02-04,Diego Valle-Jones,"https://hoyodesmog.diegovalle.net/rsinaica/,
https://github.com/diegovalle/rsinaica",TRUE,https://github.com/diegovalle/rsinaica,2236,6,1550009118
RSiteCatalyst,"Functions for interacting with the Adobe Analytics API V1.4
    (<https://api.omniture.com/admin/1.4/rest/>).",2018-04-22,Willem Paling,NA,TRUE,https://github.com/randyzwitch/rsitecatalyst,54573,121,1544647455
rslurm,"Functions that simplify submitting R scripts to a Slurm 
    workload manager, in part by automating the division of embarrassingly
    parallel calculations across cluster nodes.",2017-10-19,Philippe Marchand,https://github.com/SESYNC-ci/rslurm,TRUE,https://github.com/sesync-ci/rslurm,7541,20,1548174063
RSmartlyIO,"Aims at loading Facebook and Instagram advertising data from
    'Smartly.io' into R. 'Smartly.io' is an online advertising service that enables
    advertisers to display commercial ads on social media networks (see <http://www.smartly.io/> for more information).
    The package offers an interface to query the 'Smartly.io' API and loads data directly into R for further data processing and data analysis.",2019-01-21,Johannes Burkhardt <johannes.burkhardt@gmail.com>,"https://github.com/rstats-lab/RSmartlyIO, https://app.smartly.io",TRUE,https://github.com/rstats-lab/rsmartlyio,6366,3,1548065299
RSNNS,"The Stuttgart Neural Network Simulator (SNNS) is a library
    containing many standard implementations of neural networks. This
    package wraps the SNNS functionality to make it available from
    within R. Using the 'RSNNS' low-level interface, all of the
    algorithmic functionality and flexibility of SNNS can be accessed.
    Furthermore, the package contains a convenient high-level
    interface, so that the most common neural network topologies and
    learning algorithms integrate seamlessly into R.",2018-08-10,Christoph Bergmeir,https://github.com/cbergmeir/RSNNS,TRUE,https://github.com/cbergmeir/rsnns,146530,15,1534211667
rsnps,"A programmatic interface to various 'SNP' 'datasets'
    on the web: 'OpenSNP' (<https://opensnp.org>), and 'NBCIs' 'dbSNP' database
    (<https://www.ncbi.nlm.nih.gov/projects/SNP>). Functions
    are included for searching for 'NCBI'. For 'OpenSNP', functions are included 
    for getting 'SNPs', and data for 'genotypes', 'phenotypes', annotations, 
    and bulk downloads of data by user.",2018-09-20,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rsnps,TRUE,https://github.com/ropensci/rsnps,17723,31,1553833391
RSocrata,"Provides easier interaction with
    'Socrata' open data portals <http://dev.socrata.com>.
    Users can provide a 'Socrata' data set resource URL,
    or a 'Socrata' Open Data API (SoDA) web query,
    or a 'Socrata' ""human-friendly"" URL,
    returns an R data frame. Converts dates to 'POSIX'
    format and manages throttling by 'Socrata'.
    Users can upload data to 'Socrata' portals directly
    from R.",2019-01-25,Hugh Devlin,https://github.com/Chicago/RSocrata,TRUE,https://github.com/chicago/rsocrata,26679,143,1548436751
rsoi,"Downloads Southern Oscillation Index, Oceanic Nino
    Index, North Pacific Gyre Oscillation data, North Atlantic Oscillation
    and Arctic Oscillation. Data sources are described in the README file.",2019-01-11,Sam Albers  (<https://orcid.org/0000-0002-9270-7884>),https://github.com/boshek/rsoi,TRUE,https://github.com/boshek/rsoi,5365,4,1547178942
Rsomoclu,"Somoclu is a massively parallel implementation of self-organizing maps.  It exploits multicore CPUs and it can be accelerated by CUDA. The topology of the map can be planar or toroid and the grid of neurons can be rectangular or hexagonal . Details refer to (Peter Wittek, et al (2017)) <doi:10.18637/jss.v078.i09>.",2019-01-03,Shichao Gao,http://peterwittek.github.io/somoclu/,TRUE,https://github.com/peterwittek/somoclu,18842,173,1546608472
rspa,"Minimally adjust the values of numerical records in a data.frame, such
    that each record satisfies a predefined set of equality and/or inequality
    constraints. The constraints can be defined using the 'validate' package. 
    The core algorithms have recently been moved to the 'lintools' package,
    refer to 'lintools' for a more basic interface and access to a version
    of the algorithm that works with sparse matrices.",2018-07-30,Mark van der Loo,https://github.com/markvanderloo/rspa,TRUE,https://github.com/markvanderloo/rspa,16169,0,1553262596
Rspc,"Implementation of Nelson rules for control charts in 'R'. The 'Rspc' implements some Statistical Process Control methods, namely Levey-Jennings type of I (individuals) chart, Shewhart C (count) chart and Nelson rules (as described in Montgomery, D. C. (2013) Introduction to statistical quality control. Hoboken, NJ: Wiley.). Typical workflow is taking the time series, specify the control limits, and list of Nelson rules you want to evaluate. There are several options how to modify the rules (one sided limits, numerical parameters of rules, etc.). Package is also capable of calculating the control limits from the data (so far only for i-chart and c-chart are implemented).",2018-07-30,Stanislav Matousek (MSD),NA,TRUE,https://github.com/merck/spc_package,1573,0,1532019409
RSpectra,"R interface to the 'Spectra' library
    <https://spectralib.org/> for large-scale eigenvalue and SVD
    problems. It is typically used to compute a few
    eigenvalues/vectors of an n by n matrix, e.g., the k largest eigenvalues,
    which is usually more efficient than eigen() if k << n. This package
    provides the 'eigs()' function that does the similar job as in 'Matlab',
    'Octave', 'Python SciPy' and 'Julia'. It also provides the 'svds()' function
    to calculate the largest k singular values and corresponding
    singular vectors of a real matrix. The matrix to be computed on can be
    dense, sparse, or in the form of an operator defined by the user.",2019-04-04,Yixuan Qiu,https://github.com/yixuan/RSpectra,TRUE,https://github.com/yixuan/rspectra,289402,38,1554515670
rsppfp,"An implementation of functionalities to transform directed graphs that are bound to a set of
  known forbidden paths. There are several transformations, following the rules provided by Villeneuve 
  and Desaulniers (2005) <doi: 10.1016/j.ejor.2004.01.032>, and Hsu et al. (2009) <doi: 10.1007/978-3-642-03095-6_60>. 
  The resulting graph is generated in a data-frame format. See rsppfp website for more information, 
  documentation an examples.",2019-02-19,Melina Vidoni  (<https://orcid.org/0000-0002-4099-1430>),https://github.com/melvidoni/rsppfp,TRUE,https://github.com/melvidoni/rsppfp,1065,2,1550587720
RSQLite,"Embeds the 'SQLite' database engine in R and
    provides an interface compliant with the 'DBI' package. The
    source for the 'SQLite' engine is included.",2018-05-06,Kirill Müller  (<https://orcid.org/0000-0002-1416-3412>),https://github.com/r-dbi/RSQLite,TRUE,https://github.com/r-dbi/rsqlite,3011472,166,1548621779
Rssa,"Methods and tools for Singular Spectrum Analysis including decomposition, forecasting and gap-filling for univariate and multivariate time series.",2017-10-04,Anton Korobeynikov,http://github.com/asl/rssa,TRUE,https://github.com/asl/rssa,34167,32,1530738522
RSSL,"A collection of implementations of semi-supervised classifiers
    and methods to evaluate their performance. The package includes implementations
    of, among others, Implicitly Constrained Learning, Moment Constrained Learning,
    the Transductive SVM, Manifold regularization, Maximum Contrastive Pessimistic
    Likelihood estimation, S4VM and WellSVM.",2019-03-08,Jesse Krijthe,http://www.github.com/jkrijthe/RSSL,TRUE,https://github.com/jkrijthe/rssl,6528,33,1552498353
rstan,"User-facing R functions are provided to parse, compile, test,
    estimate, and analyze Stan models by accessing the header-only Stan library
    provided by the 'StanHeaders' package. The Stan project develops a probabilistic
    programming language that implements full Bayesian statistical inference
    via Markov Chain Monte Carlo, rough Bayesian inference via 'variational'
    approximation, and (optionally penalized) maximum likelihood estimation via
    optimization. In all three cases, automatic differentiation is used to quickly
    and accurately evaluate gradients without burdening the user with the need to
    derive the partial derivatives.",2018-11-07,Ben Goodrich,"http://discourse.mc-stan.org, http://mc-stan.org",TRUE,https://github.com/stan-dev/rstan,585157,543,1553923640
rstanarm,"Estimates previously compiled regression models using the 'rstan'
    package, which provides the R interface to the Stan C++ library for Bayesian
    estimation. Users specify models via the customary R syntax with a formula and
    data.frame plus some additional arguments for priors.",2018-11-10,Simon Wood [cph (R/stan_gamm4.R),"http://discourse.mc-stan.org, http://mc-stan.org/,
http://mc-stan.org/rstanarm/",TRUE,https://github.com/stan-dev/rstanarm,169188,194,1554525767
rstantools,"Provides various tools for developers of R packages interfacing
    with 'Stan' <http://mc-stan.org>, including functions to set up the required 
    package structure, S3 generics and default methods to unify function naming 
    across 'Stan'-based R packages, and vignettes with recommendations for 
    developers.",2018-08-22,Jonah Gabry,"http://discourse.mc-stan.org/, http://mc-stan.org/rstantools/",TRUE,https://github.com/stan-dev/rstantools,178179,15,1544740851
rstap,Estimates previously compiled stap regression models using the 'rstan' package. Users specify models via a custom R syntax with a formula and data.frame plus additional arguments for priors.,2019-02-06,Adam Peterson,https://biostatistics4socialimpact.github.io/rstap,TRUE,https://github.com/biostatistics4socialimpact/rstap,836,3,1552424396
RStata,"A simple R -> Stata interface allowing the user to
    execute Stata commands (both inline and from a .do file)
    from R.",2016-10-27,Luca Braglia,http://github.com/lbraglia/RStata,TRUE,https://github.com/lbraglia/rstata,14074,41,1529048033
RStoolbox,"Toolbox for remote sensing image processing and analysis such as
    calculating spectral indices, principal component transformation, unsupervised
    and supervised classification or fractional cover analyses.",2019-01-08,Benjamin Leutner,"http://bleutner.github.io/RStoolbox,
https://github.com/bleutner/RStoolbox",TRUE,https://github.com/bleutner/rstoolbox,42265,123,1552664098
rstpm2,"R implementation of generalized survival models (GSMs) and smooth accelerated failure time (AFT) models. For the GSMs, g(S(t|x))=eta(t,x) for a link function g, survival S at time t with covariates x and a linear predictor eta(t,x). The main assumption is that the time effect(s) are smooth. For fully parametric models with natural splines, this re-implements Stata's 'stpm2' function, which are flexible parametric survival models developed by Royston and colleagues. We have extended the parametric models to include any smooth parametric smoothers for time. We have also extended the model to include any smooth penalized smoothers from the 'mgcv' package, using penalized likelihood. These models include left truncation, right censoring, interval censoring, gamma frailties and normal random effects. For the smooth AFTs, S(t|x) = S_0(t*eta(t,x)), where the baseline survival function S_0(t)=exp(-exp(eta_0(t))) is modelled for natural splines for eta_0, and the time-dependent cumulative acceleration factor eta(t,x)=\int_0^t exp(eta_1(u,x)) du for log acceleration factor eta_1(u,x).",2019-01-17,Mark Clements,http://github.com/mclements/rstpm2,TRUE,https://github.com/mclements/rstpm2,11272,10,1544954942
rstudioapi,"Access the RStudio API (if available) and provide informative error
    messages when it's not.",2019-03-19,Kevin Ushey,https://github.com/rstudio/rstudioapi,TRUE,https://github.com/rstudio/rstudioapi,6706035,82,1553028236
RSuite,"Supports safe and reproducible solutions development in R.
        It will help you with environment separation per project,
        dependency management, local packages creation and preparing
        deployment packs for your solutions.",2019-03-07,Walerian Sokolowski,https://rsuite.io,TRUE,https://github.com/wlogsolutions/rsuite,3014,20,1554101949
rsunlight,"Interface to 'APIs' for US government data previously under
    the 'Sunlight' Foundation, now under 'ProPublica'
    (<https://www.propublica.org/datastore/'apis'>), and Open States
    (<http://docs.openstates.org/en/latest/api/>). Functions are
    provided to interact with each of the routes in each API.",2018-05-15,Scott Chamberlain,https://github.com/ropengov/rsunlight,TRUE,https://github.com/ropengov/rsunlight,11712,43,1526392102
RSurvey,"A geographic information system (GIS) graphical user interface (GUI) that
  provides data viewing, management, and analysis tools.",2018-04-11,Jason C. Fisher  (<https://orcid.org/0000-0001-9032-8912>),https://github.com/USGS-R/RSurvey,TRUE,https://github.com/usgs-r/rsurvey,28598,10,1523394783
rsvd,"Low-rank matrix decompositions are fundamental tools and widely used for data
  analysis, dimension reduction, and data compression. Classically, highly accurate 
  deterministic matrix algorithms are used for this task. However, the emergence of 
  large-scale data has severely challenged our computational ability to analyze big data. 
  The concept of randomness has been demonstrated as an effective strategy to quickly produce
  approximate answers to familiar problems such as the singular value decomposition (SVD). 
  The rsvd package provides several randomized matrix algorithms such as the randomized 
  singular value decomposition (rsvd), randomized principal component analysis (rpca), 
  randomized robust principal component analysis (rrpca), randomized interpolative 
  decomposition (rid), and the randomized CUR decomposition (rcur). In addition several plot 
  functions are provided. The methods are discussed in detail by Erichson et al. (2016) <arXiv:1608.02148>. ",2018-11-06,N. Benjamin Erichson,https://github.com/erichson/rSVD,TRUE,https://github.com/erichson/rsvd,34731,52,1541446138
RSvgDevice,"A graphics device for R that uses the w3.org xml standard
        for Scalable Vector Graphics.",2014-04-25,T Jake Luciani <jakeluciani@yahoo.com>,https://github.com/mdecorde/RSvgDevice,TRUE,https://github.com/mdecorde/rsvgdevice,11440,127,1524146186
RSwissMaps,"Allows to link data to Swiss administrative divisions (municipalities,
    districts, cantons) and to plot and save customised maps thereof.  Furthermore, the
    package allows to generate tailored templates for data collection.  The used geodata
    is publicly available on the Swiss Federal Statistical Office website
    <https://www.bfs.admin.ch/bfs/de/home/dienstleistungen/geostat/geodaten-bundesstatistik.html>. ",2017-10-02,David Zumbach,NA,TRUE,https://github.com/zumbov2/rswissmaps,4313,12,1538424927
rsyslog,"Functions to write messages to the 'syslog' system logger API,
  available on all 'POSIX'-compatible operating systems. Features include
  tagging messages with a priority level and application type, as well as
  masking (hiding) messages below a given priority level.",2018-07-03,Aaron Jacobs,https://github.com/atheriel/rsyslog,TRUE,https://github.com/atheriel/rsyslog,882,6,1530633939
rt.test,"Performs one-sample t-test based on robustified statistics using median/MAD (TA) and Hodges-Lehmann/Shamos (TB). For more details, see Park and Wang (2018)<arXiv:1807.02215>. This work was partially supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (No. NRF-2017R1A2B4004169).  ",2018-07-10,Chanseok Park,https://github.com/statpnu/R-package,TRUE,https://github.com/statpnu/r-package,1808,0,1531292524
rtdists,"Provides response time distributions (density/PDF,
       distribution function/CDF, quantile function, and random
       generation): (a) Ratcliff diffusion model (Ratcliff &
       McKoon, 2008, <doi:10.1162/neco.2008.12-06-420>) based on C
       code by Andreas and Jochen Voss and (b) linear ballistic
       accumulator (LBA; Brown & Heathcote, 2008,
       <doi:10.1016/j.cogpsych.2007.12.002>) with different
       distributions underlying the drift rate.",2018-08-29,Henrik Singmann  (<https://orcid.org/0000-0002-4842-3657>),https://github.com/rtdists/rtdists/,TRUE,https://github.com/rtdists/rtdists,28807,21,1535534921
RTest,"This provides a framework for R packages developed for
	a regulatory environment. It is based on the 'testthat' unit testing system and provides the adapter
    functionalities for XML-based test case definition as well as for standardized
    reporting of the test results.",2019-01-02,Sebastian Wolf,NA,TRUE,https://github.com/zappingseb/rtest,1722,12,1547198500
rtext,"For natural language processing and analysis of qualitative text
    coding structures which provide a way to bind together text and text data
    are fundamental. The package provides such a structure and accompanying
    methods in form of R6 objects. The 'rtext' class allows for text handling
    and text coding (character or regex based) including data updates on
    text transformations as well as aggregation on various levels.
    Furthermore, the usage of R6 enables inheritance and passing by reference
    which should enable 'rtext' instances to be used as back-end for R based
    graphical text editors or text coding GUIs.",2019-01-23,Peter Meissner,https://github.com/petermeissner/rtext,TRUE,https://github.com/petermeissner/rtext,4963,2,1548706744
rticles,"A suite of custom R Markdown formats and templates for
  authoring journal articles and conference submissions.",2019-03-16,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/rstudio/rticles,TRUE,https://github.com/rstudio/rticles,194288,507,1553548162
rtide,"Calculates tide heights based on tide station harmonics.
    It includes the harmonics data for 637 US stations.
    The harmonics data was converted from <https://github.com/poissonconsulting/rtide/blob/master/data-raw/harmonics-dwf-20151227-free.tar.bz2>,
    NOAA web site data processed by David Flater for 'XTide'.
    The code to calculate tide heights from the harmonics is based on 'XTide'.",2018-08-23,Joe Thorley,https://github.com/poissonconsulting/rtide,TRUE,https://github.com/poissonconsulting/rtide,5846,10,1541188822
rtika,"Extract text or metadata from over a thousand file types, using Apache Tika <https://tika.apache.org/>. Get either plain text or structured XHTML content. ",2019-02-27,Sasha Goodman,http://github.com/ropensci/rtika,TRUE,https://github.com/ropensci/rtika,2657,38,1551213713
rtimes,"Interface to Congress, Campaign Finance, Article Search, and
    Geographic 'APIs' from the New York Times (<http://developer.nytimes.com/>)
    and 'ProPublica' (<https://www.propublica.org/datastore/apis>). This client 
    covers a subset of the New York Times and 'ProPublica' 'APIs'.",2017-08-11,Scott Chamberlain,https://github.com/ropengov/rtimes,TRUE,https://github.com/ropengov/rtimes,10511,51,1550252849
RTransferEntropy,Measuring information flow between time series with Shannon and Rényi transfer entropy. See also Dimpfl and Peter (2013) <doi:10.1515/snde-2012-0044> and Dimpfl and Peter (2014) <doi:10.1016/j.intfin.2014.03.004> for theory and applications to financial time series. Additional references can be found in the theory part of the vignette.,2019-03-12,Simon Behrendt,https://github.com/BZPaper/RTransferEntropy,TRUE,https://github.com/bzpaper/rtransferentropy,2598,3,1552404853
rtrek,"Provides datasets related to the Star Trek fictional universe and functions for working with the data.
    The package also provides access to real world datasets based on the televised series and other related licensed media productions.
    It interfaces with the Star Trek API (STAPI) (<http://stapi.co/>), 
    Memory Alpha (<http://memory-alpha.wikia.com/>), and Memory Beta (<http://memory-beta.wikia.com/>) 
    to retrieve data, metadata and other information relating to Star Trek.
    It also contains several local datasets covering a variety of topics. 
    The package also provides functions for working with data from other Star Trek-related 
    R data packages containing larger datasets not stored in 'rtrek'.",2019-01-11,Matthew Leonawicz  (<https://orcid.org/0000-0001-9452-2771>),https://github.com/leonawicz/rtrek,TRUE,https://github.com/leonawicz/rtrek,1874,25,1548616356
Rtsne,"An R wrapper around the fast T-distributed Stochastic
    Neighbor Embedding implementation by Van der Maaten  (see <https://github.com/lvdmaaten/bhtsne/> for more information on the original implementation).",2018-11-10,Jesse Krijthe,https://github.com/jkrijthe/Rtsne,TRUE,https://github.com/jkrijthe/rtsne,271976,195,1550052637
rtson,"TSON, short for Typed JSON, is a binary-encoded serialization of
    JSON like document that support JavaScript typed data (https://github.com/tercen/TSON).",2016-08-26,Alexandre Maurel,https://github.com/tercen/TSON,TRUE,https://github.com/tercen/tson,6447,4,1536750041
Rttf2pt1,"Contains the program 'ttf2pt1', for use with the
    'extrafont' package. This product includes software developed by the 'TTF2PT1'
    Project and its contributors.",2018-06-29,Winston Chang,https://github.com/wch/Rttf2pt1,TRUE,https://github.com/wch/rttf2pt1,452769,6,1530299514
rtweet,"An implementation of calls designed to collect and
    organize Twitter data via Twitter's REST and stream Application
    Program Interfaces (API), which can be found at the following URL:
    <https://developer.twitter.com/en/docs>.",2018-09-28,Michael W. Kearney  (<https://orcid.org/0000-0002-0730-4694>),https://CRAN.R-project.org/package=rtweet,TRUE,https://github.com/mkearney/rtweet,72440,350,1546020613
rtypeform,"An R interface to the 'typeform' <https://typeform.com> application program interface.
  Also provides functions for downloading your results.",2018-08-28,Colin Gillespie,https://github.com/csgillespie/rtypeform,TRUE,https://github.com/csgillespie/rtypeform,7681,6,1540812367
ruimtehol,"Wraps the 'StarSpace' library <https://github.com/facebookresearch/StarSpace> 
    allowing users to calculate word, sentence, article, document, webpage, link and entity 'embeddings'. 
    By using the 'embeddings', you can perform text based multi-label classification, 
    find similarities between texts and categories, do collaborative-filtering based recommendation 
    as well as content-based recommendation, find out relations between entities, calculate 
    graph 'embeddings' as well as perform semi-supervised learning and multi-task learning on plain text. 
    The techniques are explained in detail in the paper: 'StarSpace: Embed All The Things!' by Wu et al. (2017), available at <arXiv:1709.03856>.",2019-01-28,Jan Wijffels,https://github.com/bnosac/ruimtehol,TRUE,https://github.com/bnosac/ruimtehol,1143,55,1551346487
ruin,"A (not yet exhaustive) collection of common models of risk
    processes in actuarial science, represented as formal S4 classes. Each class
    (risk model) has a simulator of its path, and a plotting function. Further, 
    a Monte-Carlo estimator of a ruin probability for a finite time is
    implemented, using a parallel computation. Currently, the package extends
    two classical risk models Cramer-Lundberg and Sparre Andersen models by
    including capital injections, that are positive jumps (see Breuer L. and
    Badescu A.L. (2014) <doi:10.1080/03461238.2011.636969>). The intent of the
    package is to provide a user-friendly interface for ruin processes'
    simulators, as well as a solid and extensible structure for future
    extensions.",2018-07-30,Iegor Rudnytskyi,http://github.com/irudnyts/ruin,TRUE,https://github.com/irudnyts/ruin,1256,0,1532953088
ruler,"Tools for creating data validation pipelines and tidy reports. This
    package offers a framework for exploring and validating data frame like
    objects using 'dplyr' grammar of data manipulation.",2019-02-15,Evgeni Chasnovski,"https://echasnovski.github.io/ruler/,
https://github.com/echasnovski/ruler",TRUE,https://github.com/echasnovski/ruler,4811,24,1550321965
runner,"Calculates running functions (a.k.a. windowed, rolling, cumulative) 
  with varying window size and missing handling options. Package brings also 
  running streak and running which, what extends beyond range of functions 
  already implemented in R packages.",2019-03-08,Dawid Kałędkowski,NA,TRUE,https://github.com/gogonzo/runner,1676,3,1552731122
runstats,"Provides methods for fast computation of running sample 
    statistics for time series. These include: (1) mean, (2) 
    standard deviation, and (3) variance over a fixed-length window 
    of time-series, (4) correlation, (5) covariance, and (6) 
    Euclidean distance (L2 norm) between short-time pattern and 
    time-series. Implemented methods utilize Convolution Theorem to 
    compute convolutions via Fast Fourier Transform (FFT).",2019-03-13,Marta Karas  (<https://orcid.org/0000-0001-5889-3970>),https://github.com/martakarass/runstats,TRUE,https://github.com/martakarass/runstats,244,0,1552685529
rusk,"By placing on a circle 10 points numbered from 1 to 10, and connecting them by a straight line to the point corresponding to its multiplication by 2. (1 must be connected to 1 * 2 = 2, point 2 must be set to 2 * 2 = 4, point 3 to 3 * 2 = 6 and so on). You will obtain an amazing geometric figure that complicates and beautifies itself by varying the number of points and the multiplication table you use.",2018-05-27,Vincent Guyader,https://github.com/ThinkR-open/rusk,TRUE,https://github.com/thinkr-open/rusk,2306,2,1539978669
rust,"Uses the generalized ratio-of-uniforms (RU) method to simulate
    from univariate and (low-dimensional) multivariate continuous distributions.
    The user specifies the log-density, up to an additive constant. The RU
    algorithm is applied after relocation of mode of the density to zero, and
    the user can choose a tuning parameter r. For details see Wakefield, Gelfand
    and Smith (1991) <DOI:10.1007/BF01889987>, Efficient generation of random
    variates via the ratio-of-uniforms method, Statistics and Computing (1991)
    1, 129-133.  A Box-Cox variable transformation can be used to make the input
    density suitable for the RU method and to improve efficiency.  In the
    multivariate case rotation of axes can also be used to improve efficiency.
    From version 1.2.0 the 'Rcpp' package 
    <https://cran.r-project.org/package=Rcpp> can be used to improve efficiency.",2019-02-10,Paul J. Northrop,http://github.com/paulnorthrop/rust,TRUE,https://github.com/paulnorthrop/rust,15060,0,1551462050
ruta,"Implementation of several unsupervised neural networks,
    from building their architecture to their training and evaluation. Available
    networks are auto-encoders including their main variants: sparse, contractive,
    denoising, robust and variational, as described in Charte et al. (2018)
    <doi:10.1016/j.inffus.2017.12.007>.",2019-03-18,David Charte  (<https://orcid.org/0000-0002-4830-9512>),https://github.com/fdavidcl/ruta,TRUE,https://github.com/fdavidcl/ruta,2015,24,1553251028
rv,"Implements a simulation-based random variable class and a suite of
  methods for extracting parts of random vectors, calculating extremes of random
  vectors, and generating random vectors under a variety of distributions 
  following Kerman and Gelman (2007) <doi:10.1007/s11222-007-9020-4>. ",2019-01-08,Jouni Kerman,https://github.com/jsta/rv,TRUE,https://github.com/jsta/rv,12718,1,1546957892
Rvcg,"Operations on triangular meshes based on 'VCGLIB'. This package
    integrates nicely with the R-package 'rgl' to render the meshes processed by
    'Rvcg'. The Visualization and Computer Graphics Library (VCG for short) is
    an open source portable C++ templated library for manipulation, processing
    and displaying with OpenGL of triangle and tetrahedral meshes. The library,
    composed by more than 100k lines of code, is released under the GPL license,
    and it is the base of most of the software tools of the Visual Computing Lab of
    the Italian National Research Council Institute ISTI <http://vcg.isti.cnr.it>,
    like 'metro' and 'MeshLab'. The 'VCGLIB' source is pulled from trunk
    <https://github.com/cnr-isti-vclab/vcglib> and patched to work with options
    determined by the configure script as well as to work with the header files
    included by 'RcppEigen'.",2018-09-28,Stefan Schlager,"http://github.com/zarquon42b/Rvcg, http://vcg.sf.net/",TRUE,https://github.com/zarquon42b/rvcg,30816,9,1547538518
rversions,"Query the main 'R' 'SVN' repository to find the
    versions 'r-release' and 'r-oldrel' refer to, and also all
    previous 'R' versions and their release dates.",2016-08-02,Gábor Csárdi,https://github.com/metacran/rversions,TRUE,https://github.com/metacran/rversions,725510,10,1553004342
rvertnet,"Retrieve, map and summarize data from the 'VertNet.org' 
    archives (<http://vertnet.org/>).  Functions allow searching by many 
    parameters, including 'taxonomic' names, places, and dates. In addition, 
    there is an interface for conducting spatially delimited searches, and 
    another for requesting large 'datasets' via email.",2018-04-17,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/rvertnet,TRUE,https://github.com/ropensci/rvertnet,36635,5,1540833036
rvest,"Wrappers around the 'xml2' and 'httr' packages to make it easy to
    download, then manipulate, HTML and XML.",2016-06-17,Hadley Wickham,https://github.com/hadley/rvest,TRUE,https://github.com/hadley/rvest,3024612,1045,1553881438
rvg,"Vector Graphics devices for Microsoft 
  PowerPoint and Excel. Functions extending package 'officer' are provided to 
  embed 'DrawingML' graphics into 'Microsoft PowerPoint' presentations and 
  'Microsoft Excel' workbooks.",2019-04-06,David Gohel,https://github.com/davidgohel/rvg,TRUE,https://github.com/davidgohel/rvg,162502,95,1554537952
rvinecopulib,"Provides an interface to 'vinecopulib', a C++ library for vine 
 copula modeling based on 'Boost' and 'Eigen'. The 'rvinecopulib' 
 package implements the core features of the popular 'VineCopula' package, in 
 particular inference algorithms for both vine copula and bivariate copula 
 models. Advantages over 'VineCopula' are a sleeker and more modern API, 
 improved performances, especially in high dimensions, nonparametric and 
 multi-parameter families. The 'rvinecopulib' package includes 'vinecopulib' as
 header-only C++ library (currently version 0.3.0). Thus 
 users do not need to install 'vinecopulib' itself in order to use 
 'rvinecopulib'. Since their initial releases, 'vinecopulib' is licensed under 
 the MIT License, and 'rvinecopulib' is licensed under the GNU GPL version 3.",2018-08-22,Thomas Nagler,NA,TRUE,https://github.com/vinecopulib/rvinecopulib,6240,4,1550069164
rwalkr,Provides API to Melbourne pedestrian data in tidy data form.,2018-12-13,Earo Wang  (<https://orcid.org/0000-0001-6448-5260>),http://pkg.earo.me/rwalkr,TRUE,https://github.com/earowang/rwalkr,7563,5,1544683362
rwavelet,"Perform wavelet analysis (orthogonal, translation invariant, tensorial, 1-2-3d transforms, thresholding, block thresholding, linear,...) with applications to data compression or denoising/regression. The core of the code is a port of 'MATLAB' Wavelab toolbox written by D. Donoho, A. Maleki and M. Shahram (<https://statweb.stanford.edu/~wavelab/>).",2019-03-14,F. Navarro and C. Chesneau,http://github.com/fabnavarro/rwavelet,TRUE,https://github.com/fabnavarro/rwavelet,1727,1,1553519237
RWDataPlyr,"A tool to read and manipulate data generated from 'RiverWare'(TM) 
    <http://www.riverware.org/> simulations. 'RiverWare' and 'RiverSMART' 
    generate data in ""rdf"", ""csv"", and ""nc"" format. This package provides an 
    interface to read, aggregate, and summarize data from one or more 
    simulations in a 'dplyr' pipeline.",2018-08-16,Alan Butler,https://github.com/BoulderCodeHub/RWDataPlyr,TRUE,https://github.com/bouldercodehub/rwdataplyr,1680,2,1550522178
rWind,Tools for download and manage surface wind data from the Global Forecasting System <https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs> and to compute wind connectivity between locations.,2018-11-29,Javier Fernández-López,http://allthiswasfield.blogspot.com.es/,TRUE,https://github.com/jabiologo/rwind,7172,9,1545330744
rwunderground,"Tools for getting historical weather information and forecasts 
    from wunderground.com. Historical weather and forecast data includes, but 
    is not limited to, temperature, humidity, windchill, wind speed, dew point, 
    heat index. Additionally, the weather underground weather API also includes 
    information on sunrise/sunset, tidal conditions, satellite/webcam imagery, 
    weather alerts, hurricane alerts and historical high/low temperatures.",2018-05-01,Alex Shum <alex@ALShum.com>,"https://github.com/ALShum/rwunderground,
http://www.wunderground.com/weather/api",TRUE,https://github.com/alshum/rwunderground,13067,64,1525191232
Rxnat,"Allows communication with Extensible Neuroimaging Archive Toolkit <https://www.xnat.org>. 
  'Rxnat' is using the 'XNAT' REST API to perform data queries and download images.",2019-03-29,Adi Gherman,NA,TRUE,https://github.com/adigherman/rxnat,64,0,1553284880
RxODE,"Facilities for running simulations from ordinary
    differential equation (ODE) models, such as pharmacometrics and other
    compartmental models.  A compilation manager translates the ODE model
    into C, compiles it, and dynamically loads the object code into R for
    improved computational efficiency.  An event table object facilitates
    the specification of complex dosing regimens (optional) and sampling
    schedules.  NB: The use of this package requires both C and
    Fortran compilers, for details on their use with R please see
    Section 6.3, Appendix A, and Appendix D in the ""R Administration and
    Installation"" manual. Also the code is mostly released under GPL.  The
    VODE and LSODA are in the public domain.  The information is available
    in the inst/COPYRIGHTS.",2018-12-10,Wenping Wang,"https://www.r-project.org,
https://github.com/nlmixrdevelopment/RxODE",TRUE,https://github.com/nlmixrdevelopment/rxode,14437,10,1554520977
rxylib,"Provides access to the 'xylib' C library for to import xy 
  data from powder diffraction, spectroscopy and other experimental methods.",2017-12-20,Sebastian Kreutzer,https://github.com/R-Lum/rxylib,TRUE,https://github.com/r-lum/rxylib,3463,5,1550355572
rym,"Allows work with 'Management API' for load counters, segments, filters,
	user permissions and goals list from Yandex Metrica, 'Reporting API' allows you to get 
	information about the statistics of site visits and other data without
	using the web interface, 'Logs API' allows to receive non-aggregated data and 
	'Compatible with Google Analytics Core Reporting API v3' allows 
	receive information about site traffic and other data using field names 
	from Google Analytics Core API.	For more information see official 
	documents <https://tech.yandex.ru/metrika/doc/api2/concept/about-docpage/>.",2019-01-23,Alexey Seleznev <selesnow@gmail.com>,http://selesnow.github.io/rym,TRUE,https://github.com/selesnow/rym,1657,4,1553278297
rzeit2,"Interface to gather newspaper articles from 'DIE ZEIT' and 'ZEIT ONLINE', based on a multilevel query <http://developer.zeit.de/>. A personal API key is required for usage.",2019-01-07,Jan Dix,NA,TRUE,https://github.com/jandix/rzeit2,1971,4,1546862639
s2,"R bindings for Google's s2 library for geometric calculations on
    the sphere.",2018-04-21,Ege Rubak,"https://github.com/spatstat/s2,
https://code.google.com/archive/p/s2-geometry-library/",TRUE,https://github.com/spatstat/s2,5259,14,1550603080
sabre,"Calculates a degree of spatial association between regionalizations 
    or categorical maps using the information-theoretical V-measure 
    (Nowosad and Stepinski (2018) <doi:10.1080/13658816.2018.1511794>). It also
    offers an R implementation of the MapCurve method 
    (Hargrove et al. (2006) <doi:10.1007/s10109-006-0025-x>).",2018-09-17,Jakub Nowosad  (<https://orcid.org/0000-0002-1057-3721>),https://github.com/Nowosad/sabre,TRUE,https://github.com/nowosad/sabre,2433,20,1542282478
saccades,"Functions for detecting eye fixations in raw eye-tracking
    data.  The detection is done using a velocity-based algorithm for
    saccade detection proposed by Ralf Engbert and Reinhold Kliegl in
    2003.  The algorithm labels segments as saccades when the velocity of
    the eye movement exceeds a certain threshold.  Anything between two
    saccades is considered a fixation.  Thus the algorithm is not
    appropriate for data containing episodes of smooth pursuit eye
    movements.",2015-03-18,Titus von der Malsburg,https://github.com/tmalsburg/saccades,TRUE,https://github.com/tmalsburg/saccades,9541,22,1553600528
sads,"Maximum likelihood tools to fit and compare models of species
    abundance distributions and of species rank-abundance distributions.",2018-06-16,Paulo I. Prado,"http://piLaboratory.github.io/sads,
https://github.com/piklprado/sads",TRUE,https://github.com/piklprado/sads,17774,14,1529187008
saeSim,"Tools for the simulation of data in the context of small area
    estimation. Combine all steps of your simulation - from data generation
    over drawing samples to model fitting - in one object. This enables easy
    modification and combination of different scenarios. You can store your
    results in a folder or start the simulation in parallel.",2019-03-28,Sebastian Warnholz,https://wahani.github.io/saeSim,TRUE,https://github.com/wahani/saesim,11512,1,1553773854
safer,"A consistent interface to encrypt and decrypt strings, R objects and files using symmetric and asymmetric key encryption.",2018-07-24,KS Srikanth,https://github.com/talegari/safer,TRUE,https://github.com/talegari/safer,4396,5,1532423522
salesforcer,"An implementation of the 'Salesforce' Platform APIs (REST, SOAP, 
    Bulk 1.0, Bulk 2.0, and Metadata) <https://developer.salesforce.com/page/Salesforce_APIs>. 
    This package is an articulation of the most API methods into R. The API calls 
    return XML or JSON that is parsed tidy data structures. For more details please 
    see the 'Salesforces' API references and this package's website 
    <https://stevenmmortimer.github.io/salesforcer/> for more information, 
    documentation, and examples.",2018-04-13,Steven M. Mortimer,https://github.com/StevenMMortimer/salesforcer,TRUE,https://github.com/stevenmmortimer/salesforcer,2403,18,1545076810
salty,"Take real or simulated data and salt it with errors commonly 
    found in the wild, such as pseudo-OCR errors, Unicode problems, numeric 
    fields with nonsensical punctuation, bad dates, etc.",2018-09-17,Matthew Lincoln  (<https://orcid.org/0000-0002-4387-3384>),https://github.com/mdlincoln/salty,TRUE,https://github.com/mdlincoln/salty,1378,37,1551720271
sampler,"Determine sample sizes, draw samples, and conduct data analysis using data frames. It specifically enables you to determine simple random sample sizes, stratified sample sizes, and complex stratified sample sizes using a secondary variable such as population; draw simple random samples and stratified random samples from sampling data frames; determine which observations are missing from a random sample, missing by strata, duplicated within a dataset; and perform data analysis, including proportions, margins of error and upper and lower bounds for simple, stratified and cluster sample designs. ",2019-01-27,Michael Baldassaro,https://github.com/mbaldassaro/sampler,TRUE,https://github.com/mbaldassaro/sampler,2627,4,1548569094
samplesize,Computes sample size for Student's t-test and for the Wilcoxon-Mann-Whitney test for categorical data. The t-test function allows paired and unpaired (balanced / unbalanced) designs as well as homogeneous and heterogeneous variances. The Wilcoxon function allows for ties.,2016-12-24,Ralph Scherer,https://github.com/shearer/samplesize,TRUE,https://github.com/shearer/samplesize,21349,4,1534968089
samplesizeCMH,"
    Calculates the power and sample size for Cochran-Mantel-Haenszel tests. 
    There are also several helper functions for working with probability,
    odds, relative risk, and odds ratio values.",2017-12-21,Paul Egeler,https://github.com/pegeler/samplesizeCMH,TRUE,https://github.com/pegeler/samplesizecmh,3234,1,1526353991
SamplingBigData,Select sampling methods for probability samples using large data sets.  This includes spatially balanced sampling in multi-dimensional spaces with any prescribed inclusion probabilities. All implementations are written in C with efficient data structures such as k-d trees that easily scale to several million rows on a modern desktop computer. ,2018-09-03,Jonathan Lisic,https://github.com/jlisic/SamplingBigData,TRUE,https://github.com/jlisic/samplingbigdata,2655,6,1536546972
SamplingStrata,"In the field of stratified sampling design, this package
        offers an approach for the determination of the best
        stratification of a sampling frame, the one that ensures the
        minimum sample cost under the condition to satisfy precision
        constraints in a multivariate and multidomain case. This
        approach is based on the use of the genetic algorithm: each
        solution (i.e. a particular partition in strata of the sampling
        frame) is considered as an individual in a population; the
        fitness of all individuals is evaluated applying the
        Bethel-Chromy algorithm to calculate the sampling size
        satisfying precision constraints on the target estimates.
        Functions in the package allows to: (a) analyse the obtained
        results of the optimisation step; (b) assign the new strata
        labels to the sampling frame; (c) select a sample from the new
        frame accordingly to the best allocation. 
        Functions for the execution of the genetic algorithm are a modified 
        version of the functions in the 'genalg' package.  ",2019-01-02,Giulio Barcaroli,https://github.com/barcaroli/SamplingStrata,TRUE,https://github.com/barcaroli/samplingstrata,21348,1,1553015543
saotd,"This analytic is an in initial foray into sentiment analysis.  This analytic will allow a user to access the Twitter API (once they create their own developer account), ingest tweets of their interest, clean / tidy data, perform topic modeling if interested, compute sentiment scores utilizing the x  bing Lexicon, and output visualizations.",2019-04-04,Evan Munson  (<https://orcid.org/0000-0002-9958-6800>),NA,TRUE,https://github.com/evan-l-munson/saotd,4,5,1554432783
sapfluxnetr,"Access, modify, aggregate and plot data from the 'Sapfluxnet' project
  (<http:sapfluxnet.creaf.cat>), the first global database of sap flow measurements.",2019-03-29,Victor Granda  (<https://orcid.org/0000-0002-0469-1991>),https://github.com/sapfluxnet/sapfluxnetr,TRUE,https://github.com/sapfluxnet/sapfluxnetr,83,4,1552503812
SAR,"'Smart Adaptive Recommendations' (SAR) is the name of a fast, scalable, adaptive algorithm for personalized recommendations based on user transactions and item descriptions. It produces easily explainable/interpretable recommendations and handles ""cold item"" and ""semi-cold user"" scenarios. This package provides two implementations of 'SAR': a standalone implementation, and an interface to a web service in Microsoft's 'Azure' cloud: <https://github.com/Microsoft/Product-Recommendations/blob/master/doc/sar.md>. The former allows fast and easy experimentation, and the latter provides robust scalability and extra features for production use.",2019-02-01,Hong Ooi,https://github.com/Hong-Revo/SAR,TRUE,https://github.com/hong-revo/sar,508,12,1553714437
sars,"Implements the basic elements of the multi-model
    inference paradigm for up to twenty species-area relationship models (SAR), using simple
    R list-objects and functions, as in Triantis et al. 2012 <DOI:10.1111/j.1365-2699.2011.02652.x>.
    The package is scalable and users can easily create their own model and data objects. Additional
    SAR related functions are provided.",2019-02-19,Thomas J. Matthews  (<https://orcid.org/0000-0002-7624-244X>),"https://github.com/txm676/sars, https://txm676.github.io/sars/",TRUE,https://github.com/txm676/sars,1762,2,1553527951
SASmarkdown,Settings and functions to extend the 'knitr' 'SAS' engine.,2017-11-30,Doug Hemken  (SSCC,http://www.ssc.wisc.edu/~hemken/SASworkshops/sas.html#writing-sas-documentation,TRUE,https://github.com/hemken/sasmarkdown,3866,0,1553890779
SAVER,"An implementation of a regularized regression prediction and 
    empirical Bayes method to recover the true gene expression profile in 
    noisy and sparse single-cell RNA-seq data. See Huang M, et al (2018) 
    <doi:10.1038/s41592-018-0033-z> for more details.",2018-10-14,Mo Huang,https://github.com/mohuangx/SAVER,TRUE,https://github.com/mohuangx/saver,1718,50,1553623669
sboost,"Creates classifier for binary outcomes using Freund and Schapire's Adaptive 
    Boosting (AdaBoost) algorithm on decision stumps with a fast C++ implementation. 
    This type of classifier is nonlinear, but easy to interpret and visualize. Feature 
    vectors may be a combination of continuous (numeric) and categorical (string, factor)
    elements. Methods for classifier assessment, predictions, and cross-validation also 
    included.",2018-10-28,Jadon Wagstaff,https://github.com/jadonwagstaff/sboost,TRUE,https://github.com/jadonwagstaff/sboost,1081,1,1554558515
sbpiper,"Provides an API for analysing repetitive parameter estimations and simulations of
    mathematical models. Examples of mathematical models are Ordinary Differential equations (ODEs) 
    or Stochastic Differential Equations (SDEs) models. Among the analyses for parameter 
    estimation 'sbpiper' calculates statistics and generates plots for parameter density, PCA of the best 
    fits, parameter profile likelihood estimations (PLEs), and 2D parameter PLEs. These results can 
    be generated using all or a subset of the best computed parameter sets. Among the analyses 
    for model simulation 'sbpiper' calculates statistics and generates plots for deterministic 
    and stochastic time courses via cartesian and heatmap plots. Plots for the scan of one or two model 
    parameters can also be generated. This package is primarily used by the software 'SBpipe'. 
    Citation: Dalle Pezze P, Le Novère N. SBpipe: a collection of pipelines for automating 
    repetitive simulation and analysis tasks. BMC Systems Biology. 2017;11:46. <doi:10.1186/s12918-017-0423-3>.",2018-06-26,Piero Dalle Pezze,https://github.com/pdp10/sbpiper,TRUE,https://github.com/pdp10/sbpiper,2655,0,1530027592
sbtools,"Tools for interacting with U.S. Geological Survey ScienceBase 
    <https://www.sciencebase.gov> interfaces. ScienceBase is a data cataloging and
    collaborative data management platform. Functions included for querying
    ScienceBase, and creating and fetching datasets.",2016-09-27,Tim Kern,https://github.com/USGS-R/sbtools,TRUE,https://github.com/usgs-r/sbtools,5693,13,1537275283
scales,"Graphical scales map data to aesthetics, and provide
    methods for automatically determining breaks and labels
    for axes and legends.",2018-08-09,Hadley Wickham,"https://scales.r-lib.org, https://github.com/r-lib/scales",TRUE,https://github.com/r-lib/scales,13510246,170,1548713674
scanstatistics,"Detection of anomalous space-time clusters using the scan 
    statistics methodology. Focuses on prospective surveillance of data streams, 
    scanning for clusters with ongoing anomalies. Hypothesis testing is made 
    possible by Monte Carlo simulation.",2018-01-24,Benjamin Allévius,https://github.com/BenjaK/scanstatistics,TRUE,https://github.com/benjak/scanstatistics,4929,29,1536590951
scatr,"Allows you to make clean, good-looking scatter plots with the option to 
    easily add marginal density or box plots on the axes. It is also available as a module for 'jamovi'
    (see <https://www.jamovi.org> for more information). 'Scatr' is based on the 
    'cowplot' package by Claus O. Wilke and the 'ggplot2' package by Hadley Wickham.",2017-12-05,Ravi Selker,https://github.com/raviselker/scatr,TRUE,https://github.com/raviselker/scatr,2721,1,1533786899
scatterD3,"Creates 'D3' 'JavaScript' scatterplots from 'R' with interactive
    features : panning, zooming, tooltips, etc.",2018-03-10,Julien Barnier,https://github.com/juba/scatterD3,TRUE,https://github.com/juba/scatterd3,38757,115,1554487729
scclust,"
    Provides wrappers for 'scclust', a C library for computationally efficient
    size-constrained clustering with near-optimal performance.
    See <https://github.com/fsavje/scclust> for more information.",2018-12-13,Fredrik Savje,https://github.com/fsavje/scclust-R,TRUE,https://github.com/fsavje/scclust-r,8171,15,1544713542
scdhlm,"Provides a set of tools for estimating hierarchical linear
    models and effect sizes based on data from single-case designs. 
    Functions are provided for calculating standardized mean difference effect sizes that 
    are directly comparable to standardized mean differences estimated from between-subjects randomized experiments,
    as described in Hedges, Pustejovsky, and Shadish (2012) <DOI:10.1002/jrsm.1052>; 
    Hedges, Pustejovsky, and Shadish (2013) <DOI:10.1002/jrsm.1086>; and 
    Pustejovsky, Hedges, and Shadish (2014) <DOI:10.3102/1076998614547577>. 
    Includes an interactive web interface.",2016-12-20,James Pustejovsky,https://github.com/jepusto/scdhlm,TRUE,https://github.com/jepusto/scdhlm,4570,2,1534790989
SCGLR,"
    An extension of the Fisher Scoring Algorithm to combine PLS regression with GLM 
    estimation in the multivariate context. Covariates can also be grouped in themes.",2018-09-28,Guillaume Cornu  (<https://orcid.org/0000-0002-7523-5176>),"https://scnext.github.io/SCGLR, https://github.com/SCnext/SCGLR,
https://cran.r-project.org/package=SCGLR",TRUE,https://github.com/scnext/scglr,13780,0,1538398634
schoenberg,"Functions for creating and manipulating 12-tone (i.e., dodecaphonic) musical matrices using Arnold Schoenberg's (1923) serialism technique. This package can generate random 12-tone matrices and can generate matrices using a pre-determined sequence of notes. ",2018-06-26,Jeffrey A. Dahlke <dahlk068@umn.edu>,NA,TRUE,https://github.com/jadahlke/schoenberg,2160,0,1530039343
scholar,"Provides functions to extract citation data from Google
    Scholar.  Convenience functions are also provided for comparing
    multiple scholars and predicting future h-index values.",2018-07-03,Guangchuang Yu  (<https://orcid.org/0000-0002-6485-8781>),NA,TRUE,https://github.com/jkeirstead/scholar,25183,161,1542095642
scico,"Colour choice in information visualisation is important in order to
    avoid being mislead by inherent bias in the used colour palette. The 'scico'
    package provides access to the perceptually uniform and colour-blindness 
    friendly palettes developed by Fabio Crameri and released under the 
    ""Scientific Colour-Maps"" moniker. The package contains 24 different palettes 
    and includes both diverging and sequential types.",2018-11-20,Thomas Lin Pedersen,https://github.com/thomasp85/scico,TRUE,https://github.com/thomasp85/scico,13741,98,1542786427
scidb,An R interface to the 'SciDB' array database <http://scidb.org>.,2017-04-14,B. W. Lewis,http://paradigm4.github.io/SciDBR,TRUE,https://github.com/paradigm4/scidbr,13843,48,1554527812
SciViews,"Functions to install SciViews additions to R, and more
        tools.",2018-01-06,Philippe Grosjean,"https://github.com/SciViews/SciViews,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/sciviews,23561,2,1538119970
scmamp,"Given a matrix with results of different algorithms for different
    problems, the package uses statistical tests and corrections to assess the
    differences between algorithms.",2016-10-21,Borja Calvo,NA,TRUE,https://github.com/b0rxa/scmamp,10600,23,1553264354
scopr,"Handling of behavioural data from the Ethoscope platform 
    (Geissmann, Garcia Rodriguez, Beckwith, French, Jamasb and Gilestro (2017) <DOI:10.1371/journal.pbio.2003026>).
    Ethoscopes (<http://gilestrolab.github.io/ethoscope/>) are an open source/open hardware framework made of 
    interconnected raspberry pis (<https://www.raspberrypi.org>) designed to quantify the behaviour of multiple 
    small animals in a distributed and real-time fashion. The default tracking algorithm records primary variables
    such as xy coordinates, dimensions and speed.
    This package is part of the rethomics framework <http://rethomics.github.io/>.",2019-02-15,Quentin Geissmann,https://github.com/rethomics/scopr,TRUE,https://github.com/rethomics/scopr,2125,2,1554501365
scorecard,"
  The `scorecard` package makes the development of credit risk scorecard 
  easier and efficient by providing functions for some common tasks, 
  such as data partition, variable selection, woe binning, scorecard scaling,
  performance evaluation and report generation. These functions can also used
  in the development of machine learning models.
    The references including: 
  1. Refaat, M. (2011, ISBN: 9781447511199). Credit Risk Scorecard: 
  Development and Implementation Using SAS. 
  2. Siddiqi, N. (2006, ISBN: 9780471754510). Credit risk scorecards. 
  Developing and Implementing Intelligent Credit Scoring.",2019-03-26,Shichen Xie,https://github.com/ShichenXie/scorecard,TRUE,https://github.com/shichenxie/scorecard,12921,48,1553264387
scoringRules,"Dictionary-like reference for computing scoring rules in a wide
    range of situations. Covers both parametric forecast distributions (such as
    mixtures of Gaussians) and distributions generated via simulation.",2018-07-30,Alexander Jordan,https://github.com/FK83/scoringRules,TRUE,https://github.com/fk83/scoringrules,13738,16,1553699255
SCORPIUS,"An accurate and easy tool for performing trajectory inference on
  single cells using single-cell RNA sequencing data. In addition, SCORPIUS
  provides functions for discovering the most important genes with respect to
  the reconstructed trajectory, as well as nice visualisation tools.
  Cannoodt et al. (2016) <doi:10.1101/079509>.",2018-06-29,Robrecht Cannoodt  (<https://orcid.org/0000-0003-3641-729X>,http://github.com/rcannood/SCORPIUS,TRUE,https://github.com/rcannood/scorpius,3930,13,1539629825
ScottKnottESD,"The Scott-Knott Effect Size Difference (ESD) test is a mean comparison approach that leverages a hierarchical clustering to partition the set of treatment means (e.g., means of variable importance scores, means of model performance) into statistically distinct groups with non-negligible difference [Tantithamthavorn et al., (2018) <doi:10.1109/TSE.2018.2794977>].",2018-05-08,Chakkrit Tantithamthavorn,https://github.com/klainfo/ScottKnottESD,TRUE,https://github.com/klainfo/scottknottesd,5589,5,1525772742
scPDSI,"Calculating the monthly conventional and self-calibrating Palmer
    Drought Severity Index (PDSI and scPDSI) using the precipitation and potential
    evapotranspiration data. The function to calculate PDSI is based on the C++ 
    source codes developed by Nathan Wells, Steve Goddard and Michael J. Hayes,
    University of Nebraska-Lincoln.
    Reference: Palmer W. (1965). Meteorological drought.
    U.s.department of Commerce Weather Bureau Research Paper,
    <https://www.ncdc.noaa.gov/temp-and-precip/drought/docs/palmer.pdf>;
    Wells N., Goddard S., Hayes M. J. (2004). A Self-Calibrating Palmer Drought Severity Index.
    Journal of Climate, 17(12):2335-2351, <DOI:10.1175/1520-0442(2004)017%3C2335:ASPDSI%3E2.0.CO;2>.",2018-11-18,Ruida Zhong,https://github.com/Sibada/scPDSI,TRUE,https://github.com/sibada/scpdsi,1937,2,1543549472
SCPME,"Estimates a penalized precision matrix via an augmented ADMM algorithm. This package is an implementation of the methods described in ""Shrinking Characteristics of Precision Matrix Estimators"" by Aaron J. Molstad, PhD and Adam J. Rothman, PhD. The manuscript can be found here: <doi:10.1093/biomet/asy023> .",2018-08-13,Matt Galloway,https://github.com/MGallow/SCPME,TRUE,https://github.com/mgallow/scpme,1528,0,1533817587
scriptexec,"Run complex native scripts with a single command, similar to system commands.",2018-10-30,Sagie Gur-Ari,https://github.com/sagiegurari/scriptexec,TRUE,https://github.com/sagiegurari/scriptexec,3888,3,1549617111
scriptuRs,"Full text, in data frames containing one row per verse, of the 
    Standard Works of The Church of Jesus Christ of Latter-day Saints (LDS). 
    These are the Old Testament, (KJV), the New Testament (KJV), the Book of 
    Mormon, the Doctrine and Covenants, and the Pearl of Great Price.",2019-01-09,Andrew Heiss,https://github.com/andrewheiss/scriptuRs,TRUE,https://github.com/andrewheiss/scripturs,650,5,1547192186
scrm,"A coalescent simulator that allows the rapid simulation of
    biological sequences under neutral models of evolution. Different to other
    coalescent based simulations, it has an optional approximation parameter that
    allows for high accuracy while maintaining a linear run time cost for long
    sequences. It is optimized for simulating massive data sets as produced by Next-
    Generation Sequencing technologies for up to several thousand sequences.",2018-11-19,Paul Staab,https://github.com/scrm/scrm-r,TRUE,https://github.com/scrm/scrm-r,16811,7,1542657688
scrobbler,"'Last.fm'<https://www.last.fm> is a music platform focussed on building a 
    detailed profile of a users listening habits. It does this by 'scrobbling' (recording) 
    every track you listen to on other platforms ('spotify', 'youtube', 'soundcloud' etc)
    and transferring them to your 'Last.fm' database. This allows 'Last.fm' to act as a 
    complete record of your entire listening history. 'scrobbler' provides helper functions
    to download and analyse your listening history in R.",2019-01-08,Conor Neilson,https://github.com/condwanaland/scrobbler,TRUE,https://github.com/condwanaland/scrobbler,635,0,1546512541
scrubr,"Clean biological occurrence records. Includes functionality
    for cleaning based on various aspects of spatial coordinates,
    unlikely values due to political 'centroids', coordinates based on
    where collections of specimens are held, and more.",2016-03-08,Scott Chamberlain,https://github.com/ropenscilabs/scrubr,TRUE,https://github.com/ropenscilabs/scrubr,7374,26,1542655831
sctransform,"A normalization method for single-cell UMI count data using a 
  variance stabilizing transformation. The transformation is based on a 
  negative binomial regression model with regularized parameters. As part of the
  same regression framework, this package also provides functions for batch correction, and data
  correction/denoising.",2018-11-18,"Christoph Hafemeister 
    (<https://orcid.org/0000-0001-6365-8254>)",https://github.com/ChristophH/sctransform,TRUE,https://github.com/christophh/sctransform,1075,21,1554153975
sdcHierarchies,"Provides functionality to generate, (interactively) modify (by adding, removing and renaming nodes) and convert nested hierarchies between different formats.
  These tree like structures can be used to define for example complex hierarchical tables used for statistical disclosure control.",2019-03-07,Bernhard Meindl,https://github.com/bernhard-da/sdcHierarchies,TRUE,https://github.com/bernhard-da/sdchierarchies,848,0,1553803642
sdcMicro,"Data from statistical agencies and other institutions are mostly
    confidential. This package can be used for the generation of anonymized
    (micro)data, i.e. for the creation of public- and scientific-use files. In
    addition, various risk estimation methods are included. Note that the package
    includes a graphical user interface that allows to use various methods of this
    package.",2018-05-16,Matthias Templ,https://github.com/sdcTools/sdcMicro,TRUE,https://github.com/sdctools/sdcmicro,30319,29,1549394665
sdcTable,"Methods for statistical disclosure control in
    tabular data such as primary and secondary cell suppression as described for example
    in Hundepol et al. (2012) <doi:10.1002/9781118348239> are covered in this package.",2019-02-28,Bernhard Meindl,https://github.com/sdcTools/sdcTable,TRUE,https://github.com/sdctools/sdctable,28081,1,1551695309
SDLfilter,"Functions to filter GPS and/or Argos locations. The provided
    filters remove temporal and spatial duplicates, fixes located at a given
    height from estimated high tide line, and locations with high error as
    proposed in Shimada et al. (2012) <doi:10.3354/meps09747> and 
    Shimada et al. (2016) <doi:10.1007/s00227-015-2771-0>.",2019-02-27,Takahiro Shimada,https://github.com/TakahiroShimada/SDLfilter,TRUE,https://github.com/takahiroshimada/sdlfilter,4029,2,1551142192
sdmpredictors,"Terrestrial and marine predictors for species distribution modelling
    from multiple sources, including WorldClim <http://www.worldclim.org/>,,
    ENVIREM <http://envirem.github.io/>, Bio-ORACLE <http://bio-oracle.org/>
    and MARSPEC <http://www.marspec.org/>.",2018-07-19,Samuel Bosch,http://www.samuelbosch.com/p/sdmpredictors.html,TRUE,https://github.com/lifewatch/sdmpredictors,6319,10,1532003476
searchable,"Provides functionality for searching / subsetting and slicing named
    objects using 'stringr/i'-style modifiers by case (in)sensitivity,
    regular expressions or fixed expressions; searches uses the standard '['
    operator and allows specification of default search behavior to either the
    search target (named object) and/or the search pattern.",2015-04-08,DecisionPatterns,https://github.com/decisionpatterns/searchable,TRUE,https://github.com/decisionpatterns/searchable,8477,10,1546703844
searchConsoleR,"Provides an interface with the Google Search Console,
    formally called Google Webmaster Tools.",2018-01-03,Mark Edmondson,http://code.markedmondson.me/searchConsoleR/,TRUE,https://github.com/markedmondson1234/searchconsoler,17621,80,1548453059
searcher,"Provides a search interface to look up terms
    on 'Google', 'Bing', 'ixquick', 'DuckDuckGo', 'StackOverflow', 'GitHub', and 'BitBucket'.
    Upon searching, a browser window will open with the aforementioned search
    results.",2018-07-01,James Balamuta  (<https://orcid.org/0000-0003-2826-8458>),https://github.com/coatless/searcher,TRUE,https://github.com/coatless/searcher,3315,46,1531596241
seas,"Capable of deriving seasonal statistics, such as ""normals"", and
  analysis of seasonal data, such as departures. This package also has
  graphics capabilities for representing seasonal data, including boxplots for
  seasonal parameters, and bars for summed normals. There are many specific
  functions related to climatology, including precipitation normals,
  temperature normals, cumulative precipitation departures and precipitation
  interarrivals. However, this package is designed to represent any
  time-varying parameter with a discernible seasonal signal, such as found
  in hydrology and ecology.",2018-06-02,Mike Toews,https://github.com/mwtoews/seas,TRUE,https://github.com/mwtoews/seas,27989,6,1551405134
seasonal,"Easy-to-use interface to X-13-ARIMA-SEATS, the seasonal adjustment
    software by the US Census Bureau. It offers full access to almost all
    options and outputs of X-13, including X-11 and SEATS, automatic ARIMA model
    search, outlier detection and support for user defined holiday variables,
    such as Chinese New Year or Indian Diwali. A graphical user interface can be
    used through the 'seasonalview' package. Uses the X-13-binaries from the
    'x13binary' package.",2018-12-20,Christoph Sax  (<https://orcid.org/0000-0002-7192-7044>),http://www.seasonal.website,TRUE,https://github.com/christophsax/seasonal,134652,81,1545291590
securitytxt,"When security risks in web services are discovered by independent
   security researchers who understand the severity of the risk, they
   often lack the channels to properly disclose them. As a result,
   security issues may be left unreported. The 'security.txt' 'Web Security Policies'
   specification defines an 'IETF' draft standard <https://tools.ietf.org/html/draft-foudil-securitytxt-00>
   to help organizations define the process for security researchers to securely 
   disclose security vulnerabilities. Tools are provided to help identify and 
   parse 'security.txt' files to enable analysis of the usage and adoption of these policies.",2017-10-21,Bob Rudis  (0000-0001-5670-2640),https://github.com/hrbrmstr/securitytxt,TRUE,https://github.com/hrbrmstr/securitytxt,2824,5,1528371962
seeclickfixr,"Provides a wrapper to access data from the SeeClickFix
  web API for R. SeeClickFix is a central platform employed by many cities
  that allows citizens to request their city's services. This package
  creates several functions to work with all the built-in calls to the
  SeeClickFix API. Allows users to download service request data from
  numerous locations in easy-to-use dataframe format manipulable in
  standard R functions.",2016-12-07,Justin de Benedictis-Kessner,NA,TRUE,https://github.com/justindbk/seeclickfixr,6212,1,1544563628
segmenTier,"A dynamic programming solution to segmentation based on
        maximization of arbitrary similarity measures within segments.
	The general idea, theory and this implementation are described in
	Machne, Murray & Stadler (2017) <doi:10.1038/s41598-017-12401-8>.
	In addition to the core algorithm, the package provides time-series
	processing and clustering functions as described in the publication.
	These are generally applicable where a `k-means` clustering yields
	meaningful results, and have been specifically developed for
	clustering of the Discrete Fourier Transform of periodic gene
	expression data (`circadian' or `yeast metabolic oscillations').
	This clustering approach is outlined in the supplemental material of
	Machne & Murray (2012) <doi:10.1371/journal.pone.0037906>), and here
	is used as a basis of segment similarity measures. Notably, the
	time-series processing and clustering functions can also be used as
	stand-alone tools, independent of segmentation, e.g., for 
        transcriptome data already mapped to genes.",2019-02-18,Rainer Machne,https://github.com/raim/segmenTier,TRUE,https://github.com/raim/segmentier,361,0,1549871166
segmentr,"Given a likelihood provided by the user, this package applies it
    to a given matrix dataset in order to find change points in the data that
    maximize the sum of the likelihoods of all the segments. This package provides
    a handful of algorithms with different time complexities and assumption compromises
    so the user is able to choose the best one for the problem at hand. The implementation
    of the segmentation algorithms in this package are based on the paper by Bruno M. de Castro,
	Florencia Leonardi (2018) <arXiv:1501.01756>. The Berlin
	weather sample dataset was provided by Deutscher Wetterdienst <https://dwd.de/>.
	You can find all the references in the Acknowledgments section of this package's
	repository via the URL below.",2019-01-17,Thales Mello,https://github.com/thalesmello/segmentr,TRUE,https://github.com/thalesmello/segmentr,598,1,1553633253
segregation,"Computes entropy-based segregation indices, as developed by
    Theil (1971) <isbn:978-0471858454>, with a focus on
    the Mutual Information Index (M) and Theil's Information Index (H).
    The M, further described by Mora and Ruiz-Castillo (2011) <doi:10.1111/j.1467-9531.2011.01237.x>
    and Frankel and Volij (2011) <doi:10.1016/j.jet.2010.10.008>,
    is a measure of segregation that is highly decomposable. The package provides
    tools to decompose the index by units and groups (local segregation),
    and by within and between terms.
    Includes standard error estimation by bootstrapping.",2019-01-14,Benjamin Elbers  (<https://orcid.org/0000-0001-5392-3448>),http://github.com/elbersb/segregation,TRUE,https://github.com/elbersb/segregation,2464,4,1553521914
selectr,"Translates a CSS3 selector into an equivalent XPath
  expression. This allows us to use CSS selectors when working with
  the XML package as it can only evaluate XPath expressions. Also
  provided are convenience functions useful for using CSS selectors on
  XML nodes. This package is a port of the Python package 'cssselect'
  (<https://cssselect.readthedocs.io/>).",2018-04-06,Simon Potter,https://sjp.co.nz/projects/selectr,TRUE,https://github.com/sjp/selectr,2746869,26,1554194599
semantic.dashboard,"Basic functions for creating semantic UI dashboard.
  This package adds support for a powerful UI library semantic UI -
  <http://semantic-ui.com/> to your dashboard and enables you to
  stay compatible with 'shinydashboard' functionalities. ",2018-04-23,Dominik Krzeminski,NA,TRUE,https://github.com/appsilon/semantic.dashboard,5119,91,1540562960
semPlot,Path diagrams and visual analysis of various SEM packages' output.,2019-04-05,Sacha Epskamp,https://github.com/SachaEpskamp/semPlot,TRUE,https://github.com/sachaepskamp/semplot,191279,34,1554459804
sensiPhy,"An implementation of sensitivity analysis for phylogenetic comparative
 methods. The package is an umbrella of statistical and graphical methods that 
 estimate and report different types of uncertainty in PCM:
 (i) Species Sampling uncertainty (sample size; influential species and clades).
 (ii) Phylogenetic uncertainty (different topologies and/or branch lengths).
 (iii) Data uncertainty (intraspecific variation and measurement error).",2018-09-11,Gustavo Paterno,https://github.com/paternogbc/sensiPhy,TRUE,https://github.com/paternogbc/sensiphy,6432,6,1536448989
sensobol,"It allows to rapidly compute, bootstrap and plot up to third-order Sobol' indices
    using the estimators by Saltelli et al. 2010 <doi:10.1016/j.cpc.2009.09.018> and 
    Jansen 1999 <doi:10.1016/S0010-4655(98)00154-4>. The 'sensobol' package also implements
    the algorithm by Khorashadi Zadeh et al. 2017 <doi:10.1016/j.envsoft.2017.02.001> to 
    calculate the approximation error in the computation of Sobol' first and
    total indices, an approach that allows to robustly screen influential from non-influential
    model inputs. Finally, it also provides functions to obtain publication-ready figures
    of the model output uncertainty and sensitivity-related analysis.",2019-03-12,Arnald Puy  (<https://orcid.org/0000-0001-9469-2156>),http://github.com/arnaldpuy/sensobol,TRUE,https://github.com/arnaldpuy/sensobol,280,0,1554397698
SentimentAnalysis,"Performs a sentiment analysis of textual contents in R. This implementation
    utilizes various existing dictionaries, such as Harvard IV, or finance-specific 
    dictionaries. Furthermore, it can also create customized dictionaries. The latter 
    uses LASSO regularization as a statistical approach to select relevant terms based on 
    an exogenous response variable. ",2019-03-26,Stefan Feuerriegel,https://github.com/sfeuerriegel/SentimentAnalysis,TRUE,https://github.com/sfeuerriegel/sentimentanalysis,20106,92,1553567082
sentimentr,"Calculate text polarity sentiment at the sentence level and
         optionally aggregate by rows or grouping variable(s).",2019-03-22,Tyler Rinker,http://github.com/trinker/sentimentr,TRUE,https://github.com/trinker/sentimentr,50900,239,1553220976
sentometrics,"Optimized prediction based on textual sentiment, accounting for the intrinsic challenge that sentiment can be computed and pooled across texts and time in various ways. See Ardia et al. (2018) <doi:10.2139/ssrn.3067734>.",2018-12-18,Samuel Borms,https://github.com/sborms/sentometrics,TRUE,https://github.com/sborms/sentometrics,3917,24,1551092152
seplyr,"The 'seplyr' (standard evaluation plying) package supplies improved
    standard evaluation adapter methods for important common 'dplyr' data manipulation tasks.
    In addition the 'seplyr' package supplies several new ""key operations
    bound together"" methods.  These include 'group_summarize()' (which
    combines grouping, arranging and calculation in an atomic unit),
    'add_group_summaries()' (which joins grouped summaries into a 'data.frame'
    in a well documented manner), 'add_group_indices()' (which adds
    per-group identifiers to a 'data.frame' without depending on row-order),
    'partition_mutate_qt()' (which optimizes mutate sequences), and 'if_else_device()'
    (which simulates per-row if-else blocks in expression sequences).",2019-01-02,John Mount,"https://github.com/WinVector/seplyr/,
https://winvector.github.io/seplyr/",TRUE,https://github.com/winvector/seplyr,14318,45,1546446493
seqHMM,"Designed for fitting hidden (latent) Markov models and mixture
    hidden Markov models for social sequence data and other categorical time series.
    Also some more restricted versions of these type of models are available: Markov
    models, mixture Markov models, and latent class models. The package supports
    models for one or multiple subjects with one or multiple parallel sequences
    (channels). External covariates can be added to explain cluster membership in
    mixture models. The package provides functions for evaluating and comparing
    models, as well as functions for visualizing of multichannel sequence data and
    hidden Markov models. Models are estimated using maximum likelihood via the EM
    algorithm and/or direct numerical maximization with analytical gradients. All
    main algorithms are written in C++ with support for parallel computation. 
    Documentation is available via several vignettes in this page, and the  
    paper by Helske and Helske (2019, <doi:10.18637/jss.v088.i03>).",2019-01-26,Jouni Helske  (<https://orcid.org/0000-0001-7130-793X>),NA,TRUE,https://github.com/helske/seqhmm,11574,41,1553433274
seqMeta,"Computes necessary information to meta analyze region-based
    tests for rare genetic variants (e.g. SKAT, T1) in individual studies, and
    performs meta analysis.",2017-02-09,Arie Voorman,https://github.com/DavisBrian/seqMeta,TRUE,https://github.com/davisbrian/seqmeta,15795,1,1547435195
seqminer,"Integrate sequencing data (Variant call format, e.g. VCF or BCF) or meta-analysis results in R. This package can help you (1) read VCF/BCF/BGEN files by chromosomal ranges (e.g. 1:100-200); (2) read RareMETAL summary statistics files; (3) read tables from a tabix-indexed files; (4) annotate VCF/BCF files; (5) create customized workflow based on Makefile.",2019-01-08,Xiaowei Zhan,http://seqminer.genomic.codes,TRUE,https://github.com/zhanxw/seqminer,22415,14,1553273953
sergeant,"'Apache Drill' is a low-latency distributed query engine designed to enable 
    data exploration and 'analytics' on both relational and non-relational 'datastores', 
    scaling to petabytes of data. Methods are provided that enable working with 'Apache' 
    'Drill' instances via the 'REST' 'API', 'JDBC' interface (optional), 'DBI' 'methods'
    and using 'dplyr'/'dbplyr' idioms.",2017-07-17,Bob Rudis,https://github.com/hrbrmstr/sergeant,TRUE,https://github.com/hrbrmstr/sergeant,3778,97,1547031596
seriation,"Infrastructure for seriation with an implementation of several
    seriation/sequencing techniques to reorder matrices, dissimilarity
    matrices, and dendrograms. Also provides (optimally) reordered heatmaps,
    color images and clustering visualizations like dissimilarity plots, and
    visual assessment of cluster tendency plots (VAT and iVAT).",2018-02-05,Michael Hahsler,http://lyle.smu.edu/IDA/seriation,TRUE,https://github.com/mhahsler/seriation,665465,32,1552491194
serrsBayes,"Sequential Monte Carlo (SMC) algorithms for fitting a generalised additive
    mixed model (GAMM) to surface-enhanced resonance Raman spectroscopy (SERRS),
    using the method of Moores et al. (2016) <arXiv:1604.07299>. Multivariate
    observations of SERRS are highly collinear and lend themselves to a reduced-rank
    representation. The GAMM separates the SERRS signal into three components: a
    sequence of Lorentzian, Gaussian, or pseudo-Voigt peaks; a smoothly-varying baseline;
    and additive white noise. The parameters of each component of the model are estimated
    iteratively using SMC. The posterior distributions of the parameters given the observed
    spectra are represented as a population of weighted particles.",2018-06-05,Matt Moores  (<https://orcid.org/0000-0003-4531-3572>),"https://github.com/mooresm/serrsBayes,
https://mooresm.github.io/serrsBayes",TRUE,https://github.com/mooresm/serrsbayes,2607,1,1535239573
servosphereR,"Functions that facilitate and speed up the analysis of data
    produced by a Syntech servosphere <http://www.ockenfels-syntech.com/products/locomotion-compensation/>,
    which is equipment for studying the movement behavior of arthropods.
    This package is designed to make working with data produced from a 
    servosphere easy for someone new to or unfamiliar with R. The functions
    provided in this package fall into three broad-use categories: functions for
    cleaning raw data produced by the servosphere software, functions for
    deriving movement variables based on position data, and functions for 
    summarizing movement variables for easier analysis. These functions are
    built with functions from the tidyverse package to work efficiently, as a
    single servosphere file may consist of hundreds of thousands of rows of data
    and a user may wish to analyze hundreds of files at a time. Many of the 
    movement variables derivable through this package are described in the 
    following papers:
    Otálora-Luna, Fernando; Dickens, Joseph C. (2011) <doi:10.1371/journal.pone.0020990>
    Party, Virginie; Hanot, Christophe; Busser, Daniela Schmidt; Rochat, Didier; Renou, Michel (2013) <doi:10.1371/journal.pone.0052897>
    Bell, William J.; Kramer, Ernest (1980) <doi:10.1007/BF01402908>
    Becher, Paul G; Guerin, Patrick M. (2009) <doi:10.1016/j.jinsphys.2009.01.006>.",2019-03-06,Jacob T. Wittman,http://github.com/wittja01/servosphereR,TRUE,https://github.com/wittja01/servospherer,269,0,1550604517
servr,"Start an HTTP server in R to serve static files, or dynamic
    documents that can be converted to HTML files (e.g., R Markdown) under a
    given directory.",2019-03-04,Yihui Xie  (<https://orcid.org/0000-0003-0645-5666>),https://github.com/yihui/servr,TRUE,https://github.com/yihui/servr,147829,182,1551734960
settings,"Provides option settings management that goes
    beyond R's default 'options' function. With this package, users can define
    their own option settings manager holding option names, default values and 
    (if so desired) ranges or sets of allowed option values that will be 
    automatically checked. Settings can then be retrieved, altered and reset 
    to defaults with ease. For R programmers and package developers it offers 
    cloning and merging functionality which allows for conveniently defining 
    global and local options, possibly in a multilevel options hierarchy. See 
    the package vignette for some examples concerning functions, S4 classes, 
    and reference classes. There are convenience functions to reset par() 
    and options() to their 'factory defaults'.",2015-10-27,Mark van der Loo,https://github.com/markvanderloo/settings,TRUE,https://github.com/markvanderloo/settings,35252,5,1552906443
Seurat,"A toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. 'Seurat' aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See Satija R, Farrell J, Gennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, and Butler A and Satija R (2017) <doi:10.1101/164889> for more details.",2018-07-20,Rahul Satija (<https://orcid.org/0000-0001-9448-8833>),"http://www.satijalab.org/seurat,
https://github.com/satijalab/seurat",TRUE,https://github.com/satijalab/seurat,96832,391,1542638527
sf,"Support for simple features, a standardized way to
    encode spatial vector data. Binds to 'GDAL' for reading and writing
    data, to 'GEOS' for geometrical operations, and to 'PROJ' for
    projection conversions and datum transformations.",2019-02-21,Edzer Pebesma  (<https://orcid.org/0000-0001-8049-7069>),https://github.com/r-spatial/sf/,TRUE,https://github.com/r-spatial/sf,1033315,497,1554487721
sFFLHD,"Gives design points from a sequential full factorial-based
 Latin hypercube design, as described in Duan, Ankenman, Sanchez,
 and Sanchez (2015, Technometrics,
 <doi:10.1080/00401706.2015.1108233>).",2018-05-17,Collin Erickson,https://github.com/CollinErickson/sFFLHD,TRUE,https://github.com/collinerickson/sfflhd,4926,0,1550265073
SFtools,"Contains space filling based tools for
    machine learning and data mining. Some functions offer
    several computational techniques and deal with the out of
    memory for large big data by using the ff package.",2017-06-28,Mohamed Laib and Mikhail Kanevski,https://sites.google.com/site/mohamedlaibwebpage/,TRUE,https://github.com/mlaib/sftools,3053,0,1524475856
sglOptim,"Fast generic solver for sparse group lasso optimization
        problems. The loss (objective) function must be defined in a
        C++ module. The optimization problem is solved using a
        coordinate gradient descent algorithm. Convergence of the
        algorithm is established (see reference) and the algorithm is
        applicable to a broad class of loss functions. Use of parallel
        computing for cross validation and subsampling is supported
        through the 'foreach' and 'doParallel' packages. Development
        version is on GitHub, please report package issues on GitHub.",2018-10-21,Martin Vincent,"https://dx.doi.org/10.1016/j.csda.2013.06.004,
https://github.com/nielsrhansen/sglOptim",TRUE,https://github.com/nielsrhansen/sgloptim,15132,0,1540067813
sgmcmc,"Provides functions that performs popular stochastic gradient Markov chain Monte Carlo (SGMCMC) methods on user specified models. The required gradients are automatically calculated using 'TensorFlow' <https://www.tensorflow.org/>, an efficient library for numerical computation. This means only the log likelihood and log prior functions need to be specified. The methods implemented include stochastic gradient Langevin dynamics (SGLD), stochastic gradient Hamiltonian Monte Carlo (SGHMC), stochastic gradient Nose-Hoover thermostat (SGNHT) and their respective control variate versions for increased efficiency. References: M. Welling, Y. W. Teh (2011) <http://www.icml-2011.org/papers/398_icmlpaper.pdf>; T. Chen, E. B. Fox, C. E. Guestrin (2014) <arXiv:1402.4102>; N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, H. Neven (2014) <https://papers.nips.cc/paper/5592-bayesian-sampling-using-stochastic-gradient-thermostats>; J. Baker, P. Fearnhead, E. B. Fox, C. Nemeth (2017) <arXiv:1706.05439>.",2018-09-14,Jack Baker,https://github.com/STOR-i/sgmcmc,TRUE,https://github.com/stor-i/sgmcmc,3783,13,1550482621
SGP,"Functions to calculate student growth percentiles and percentile growth projections/trajectories for students using large scale,
        longitudinal assessment data.  Functions use quantile regression to estimate the conditional density associated
        with each student's achievement history.  Percentile growth projections/trajectories are calculated using the coefficient matrices derived from
	the quantile regression analyses and specify what percentile growth is required for students to reach future achievement targets.",2019-02-20,Damian W. Betebenner,"https://sgp.io, https://github.com/CenterForAssessment/SGP,
https://CRAN.R-project.org/package=SGP",TRUE,https://github.com/centerforassessment/sgp,22417,16,1552326479
SGPdata,Data sets utilized by the 'SGP' package as exemplars for users to conduct their own student growth percentiles (SGP) analyses.,2019-01-05,Damian W. Betebenner,"https://CenterForAssessment.github.io/SGPdata,
https://github.com/CenterForAssessment/SGPdata,
https://cran.r-project.org/package=SGPdata",TRUE,https://github.com/centerforassessment/sgpdata,18227,2,1552000902
shades,"Functions for easily manipulating colours, creating colour scales and calculating colour distances.",2019-01-07,Jon Clayden,https://github.com/jonclayden/shades,TRUE,https://github.com/jonclayden/shades,10833,51,1547552151
shadow,"Functions for calculating: (1) shadow height, (2) logical shadow flag, (3) shadow footprint, (4) Sky View Factor and (5) radiation load. Basic required inputs include a polygonal layer of obstacle outlines along with their heights (i.e. ""extruded polygons""), sun azimuth and sun elevation. The package also provides functions for related preliminary calculations: breaking polygons into line segments, determining azimuth of line segments, shifting segments by azimuth and distance, constructing the footprint of a line-of-sight between an observer and the sun, and creating a 3D grid covering the surface area of extruded polygons.",2019-01-07,Michael Dorman,NA,TRUE,https://github.com/michaeldorman/shadow,8478,8,1546264691
shadowtext,"Implement shadowtextGrob() for 'grid' and geom_shadowtext() layer for 'ggplot2'.
             These functions create/draw text grob with background shadow.",2018-12-07,Guangchuang Yu,https://github.com/GuangchuangYu/shadowtext/,TRUE,https://github.com/guangchuangyu/shadowtext,4058,10,1544162473
shallot,"Implementations are provided for the models described in the paper D. B. Dahl, R. Day, J. Tsai (2017) <DOI:10.1080/01621459.2016.1165103>. The Ewens, Ewens-Pitman, Ewens attraction, Ewens-Pitman attraction, and ddCRP distributions are available for prior and posterior simulation. Posterior simulation is based on a user-supplied likelihood. Supporting functions for partition estimation and plotting are also provided.",2018-10-31,David B. Dahl,https://github.com/dbdahl/shallot,TRUE,https://github.com/dbdahl/shallot,6807,1,1553298895
shapper,"Provides SHAP explanations of machine learning models. In applied machine learning, there is a strong belief that we need to strike a balance between interpretability and accuracy. However, in field of the Interpretable Machine Learning, there are more and more new ideas for explaining black-box models. One of the best known method for local explanations is SHapley Additive exPlanations (SHAP) introduced by Lundberg, S., et al., (2016) <arXiv:1705.07874> The SHAP method is used to calculate influences of variables on the particular observation. This method is based on Shapley values, a technique used in game theory. The R package 'shapper' is a port of the Python library 'shap'. ",2019-03-02,Alicja Gosiewska,https://github.com/ModelOriented/shapper,TRUE,https://github.com/modeloriented/shapper,496,12,1554239250
shar,"
  Analyse species-habitat associations in R. Therefore, information about the 
  location of the species is needed and about the environmental conditions. To test 
  for significance habitat associations, one of the two components is randomized. 
  Methods are mainly based on Plotkin et al. (2000) <doi:10.1006/jtbi.2000.2158> and 
  Harms et al. (2001) <doi:10.1111/j.1365-2745.2001.00615.x>.",2019-03-25,"Maximillian H.K. Hesselbarth 
    (<https://orcid.org/0000-0003-1125-9918>)",https://r-spatialecology.github.io/shar,TRUE,https://github.com/r-spatialecology/shar,877,2,1554192058
SharpeR,"A collection of tools for analyzing significance of assets,
    funds, and trading strategies, based on the Sharpe ratio and overfit 
    of the same. Provides density, distribution, quantile and random generation 
    of the Sharpe ratio distribution based on normal returns, as well
    as the optimal Sharpe ratio over multiple assets. Computes confidence intervals
    on the Sharpe and provides a test of equality of Sharpe ratios based on 
    the Delta method.",2018-10-07,Steven E. Pav  (<https://orcid.org/0000-0002-4197-6195>),https://github.com/shabbychef/SharpeR,TRUE,https://github.com/shabbychef/sharper,21862,12,1538939705
sharpshootR,"Miscellaneous soil data management, summary, visualization, and conversion utilities to support soil survey.",2016-08-30,USDA-NRCS Soil Survey Staff,https://github.com/ncss-tech/sharpshootR,TRUE,https://github.com/ncss-tech/sharpshootr,13905,5,1551481029
SHELF,"Implements various methods for eliciting a probability distribution
    for a single parameter from an expert or a group of experts. The expert
    provides a small number of probability judgements, corresponding
    to points on his or her cumulative distribution function. A range of parametric
    distributions can then be fitted and displayed, with feedback provided in the
    form of fitted probabilities and percentiles. For multiple experts, a weighted
    linear pool can be calculated. Also includes functions for eliciting beliefs
    about population distributions, eliciting multivariate distributions using a
    Gaussian copula, eliciting a Dirichlet distribution, and eliciting distributions 
    for variance parameters in a random effects meta-analysis model. R Shiny apps  
    for most of the methods are included. ",2019-03-26,Jeremy Oakley,https://github.com/OakleyJ/SHELF,TRUE,https://github.com/oakleyj/shelf,10161,0,1554368709
shiftR,"Fast enrichment analysis for locally correlated statistics
        via circular permutations.
        The analysis can be performed at multiple significance thresholds
        for both primary and auxiliary data sets with
        efficient correction for multiple testing.",2019-03-22,Andrey A Shabalin  (<https://orcid.org/0000-0003-0309-6821>),https://github.com/andreyshabalin/shiftR,TRUE,https://github.com/andreyshabalin/shiftr,2645,0,1553326728
shiny,"Makes it incredibly easy to build interactive web
    applications with R. Automatic ""reactive"" binding between inputs and
    outputs and extensive prebuilt widgets make it possible to build
    beautiful, responsive, and powerful applications with minimal effort.",2018-11-02,Winston Chang,http://shiny.rstudio.com,TRUE,https://github.com/rstudio/shiny,7550819,3340,1551473039
shiny.i18n,"It provides easy internationalization of Shiny
    applications. It can be used as standalone translation package
    to translate reports, interactive visualizations or
    graphical elements as well.",2018-09-13,Dominik Krzemiński,http://github.com/Appsilon/shiny.i18n,TRUE,https://github.com/appsilon/shiny.i18n,1959,43,1553505941
shiny.semantic,"Creating a great user interface for your Shiny apps
    can be a hassle, especially if you want to work purely in R
    and don't want to use, for instance HTML templates. This
    package adds support for a powerful UI library Semantic UI -
    <http://semantic-ui.com/>. It also supports universal UI input 
    binding that works with various DOM elements.",2018-05-11,Filip Stachura,NA,TRUE,https://github.com/appsilon/shiny.semantic,9519,181,1554479099
shinyAce,"Ace editor bindings to enable a rich text editing environment
    within Shiny.",2019-01-03,Vincent Nijs,NA,TRUE,https://github.com/trestletech/shinyace,136797,144,1549134540
shinyanimate,An extension of 'animate.css' that allows user to easily add animations to any UI element in 'shiny' app using the elements id.,2019-01-13,Swechhya Bista,https://github.com/Swechhya/shinyanimate,TRUE,https://github.com/swechhya/shinyanimate,3250,21,1547371254
shinycssloaders,Create a lightweight Shiny wrapper for the css-loaders created by Luke Hass <https://github.com/lukehaas/css-loaders>. Wrapping a Shiny output will automatically show a loader when the output is (re)calculating.,2017-05-12,Andras Sali  (Creator of Shiny-wrapper code),https://github.com/andrewsali/shinycssloaders,TRUE,https://github.com/andrewsali/shinycssloaders,70277,145,1552509580
shinydashboard,"Create dashboards with 'Shiny'. This package provides
    a theme on top of 'Shiny', making it easy to create attractive dashboards.",2018-10-17,Winston Chang,http://rstudio.github.io/shinydashboard/,TRUE,https://github.com/rstudio/shinydashboard,684914,557,1539794142
shinydashboardPlus,"Extend 'shinydashboard' with 'AdminLTE2' components. 
             'AdminLTE2' is a free 'Bootstrap 3' dashboard template available
             at <https://adminlte.io>.
             Customize boxes, add timelines and a lot more. ",2018-09-20,David Granjon,"https://github.com/DivadNojnarg/shinydashboardPlus,
http://130.60.24.205/shinydashboardPlus/#",TRUE,https://github.com/divadnojnarg/shinydashboardplus,28508,136,1554559285
shinyEffects,"Add fancy CSS effects to your 'shinydashboards' or 'shiny' apps.
             100% compatible with 'shinydashboardPlus' and 'bs4Dash'.",2018-11-18,David Granjon,"https://github.com/DivadNojnarg/shinyEffects,
https://divadnojnarg.github.io/shinyEffects/",TRUE,https://github.com/divadnojnarg/shinyeffects,1377,17,1546555196
shinyFiles,"Provides functionality for client-side navigation of
    the server side file system in shiny apps. In case the app is running
    locally this gives the user direct access to the file system without the
    need to ""download"" files to a temporary location. Both file and folder
    selection as well as file saving is available.",2018-11-12,Thomas Lin Pedersen,https://github.com/thomasp85/shinyFiles,TRUE,https://github.com/thomasp85/shinyfiles,101226,100,1548642307
shinyhelper,"Creates a lightweight way to add markdown helpfiles to 'shiny' apps,
    using modal dialog boxes, with no need to observe each help button separately.",2018-10-28,Chris Mason-Thom,NA,TRUE,https://github.com/cwthom/shinyhelper,3164,37,1540846354
shinyhttr,"Modifies the progress() function from 'httr' package to let it 
      send output to progressBar() function from 'shinyWidgets' package. 
      It is just a tweak at the original functions from 'httr' package to 
      make it smooth for 'shiny' developers.",2019-03-22,Athos Damiani,https://github.com/curso-r/shinyhttr,TRUE,https://github.com/curso-r/shinyhttr,130,8,1552966792
ShinyItemAnalysis,"Interactive shiny application for analysis of educational tests and
    their items.",2019-02-25,Patricia Martinkova,NA,TRUE,https://github.com/patriciamar/shinyitemanalysis,13542,11,1554364129
shinyjqui,"An extension to shiny that brings interactions and animation effects from
    'jQuery UI' library.",2018-07-25,Yang Tang,https://github.com/yang-tang/shinyjqui,TRUE,https://github.com/yang-tang/shinyjqui,24449,137,1553177457
shinyjs,"Perform common useful JavaScript operations in Shiny apps that will
    greatly improve your apps without having to know any JavaScript. Examples
    include: hiding an element, disabling an input, resetting an input back to
    its original value, delaying code execution by a few seconds, and many more
    useful functions for both the end user and the developer. 'shinyjs' can also
    be used to easily call your own custom JavaScript functions from R.",2018-01-08,Dean Attali,https://deanattali.com/shinyjs,TRUE,https://github.com/daattali/shinyjs,669593,422,1552629009
shinyLP,"Provides functions that wrap HTML Bootstrap
    components code to enable the design and layout of informative landing home
    pages for Shiny applications. This can lead to a better user experience for
    the users and writing less HTML for the developer.",2018-04-25,Jasmine Dumas,https://github.com/jasdumas/shinyLP,TRUE,https://github.com/jasdumas/shinylp,9327,67,1543078808
shinystan,"A graphical user interface for interactive Markov chain Monte
    Carlo (MCMC) diagnostics and plots and tables helpful for analyzing a
    posterior sample. The interface is powered by the 'Shiny' web
    application framework from 'RStudio' and works with the output of MCMC 
    programs written in any programming language (and has extended 
    functionality for 'Stan' models fit using the 'rstan' and 'rstanarm' 
    packages).",2018-05-01,Jonah Gabry,"http://mc-stan.org/, http://discourse.mc-stan.org",TRUE,https://github.com/stan-dev/shinystan,229873,144,1540484371
shinytest,"For automated testing of Shiny applications, using a headless
    browser, driven through 'WebDriver'.",2018-05-07,Winston Chang,https://github.com/rstudio/shinytest,TRUE,https://github.com/rstudio/shinytest,11341,137,1549899985
shinyTree,"Exposes bindings to jsTree -- a JavaScript library
    that supports interactive trees -- to enable a rich, editable trees in
    Shiny.",2018-10-05,Mike Schaffer,NA,TRUE,https://github.com/trestletech/shinytree,21197,81,1553873074
shinyWidgets,"Collection of custom input controls and user interface components for 'Shiny' applications. 
  Give your applications a unique and colorful style !",2019-03-18,Victor Perrier,https://github.com/dreamRs/shinyWidgets,TRUE,https://github.com/dreamrs/shinywidgets,148024,283,1552929275
ShortForm,"Performs automatic creation of short forms of scales with an 
    ant colony optimization algorithm and a Tabu search. As implemented in the 
    package, the ant colony algorithm randomly selects items to build a model of 
    a specified length, then updates the probability of item selection according 
    to the fit of the best model within each set of searches. The algorithm 
    continues until the same items are selected by multiple ants a given number 
    of times in a row. On the other hand, the Tabu search changes one parameter at
    a time to be either free, constrained, or fixed while keeping track of the
    changes made and putting changes that result in worse fit in a ""tabu"" list
    so that the algorithm does not revisit them for some number of searches. 
    See Leite, Huang, & Marcoulides (2008) <doi:10.1080/00273170802285743> for
    an applied example of the ant colony algorithm, and Marcoulides & Falk (2018)
    <doi:10.1080/10705511.2017.1409074> for an applied example of the Tabu search.",2018-10-17,Anthony Raborn,https://github.com/AnthonyRaborn/ShortForm,TRUE,https://github.com/anthonyraborn/shortform,4118,2,1539789471
showtext,"Making it easy to use various types of fonts ('TrueType',
    'OpenType', Type 1, web fonts, etc.) in R graphs, and supporting most output
    formats of R graphics including PNG, PDF and SVG. Text glyphs will be converted
    into polygons or raster images, hence after the plot has been created, it no
    longer relies on the font files. No external software such as 'Ghostscript' is
    needed to use this package.",2019-01-10,"Yixuan Qiu and authors/contributors of the
    included software. See file AUTHORS for details.",https://github.com/yixuan/showtext,TRUE,https://github.com/yixuan/showtext,169190,221,1547135610
SHT,"We provide a collection of statistical hypothesis testing procedures ranging from classical to modern methods for non-trivial settings such as high-dimensional scenario. For the general treatment of statistical hypothesis testing, see the book by Lehmann and Romano (2005) <doi:10.1007/0-387-27605-X>.",2019-03-11,Kisung You  (<https://orcid.org/0000-0002-8584-459X>),https://github.com/kisungyou/SHT,TRUE,https://github.com/kisungyou/sht,309,2,1553185120
shutterstock,"Access 'Shutterstock' API from R. The 'Shutterstock' API presents
    access to search, view, license and download the media and information
    from the 'Shutterstock's library <https://api-reference.shutterstock.com/>.",2019-02-03,Metin Yazici,https://github.com/strboul/shutterstock-r,TRUE,https://github.com/strboul/shutterstock-r,532,2,1551474811
sievePH,"Implements semiparametric estimation and testing procedures for a continuous, possibly multivariate, mark-specific hazard ratio (treatment/placebo) of an event of interest in a randomized treatment efficacy trial with a time-to-event endpoint, as described in Juraska M and Gilbert PB (2013), Mark-specific hazard ratio model with multivariate continuous marks: an application to vaccine efficacy. Biometrics 69(2):328 337, and in Juraska M and Gilbert PB (2015), Mark-specific hazard ratio model with missing multivariate marks. Lifetime Data Analysis 22(4): 606-25. The former considers continuous multivariate marks fully observed in all subjects who experience the event of interest, whereas the latter extends the previous work to allow multivariate marks that are subject to missingness-at-random. For models with missing marks, two estimators are implemented based on (i) inverse probability weighting (IPW) of complete cases, and (ii) augmentation of the IPW estimating functions by leveraging correlations between the mark and auxiliary data to 'impute' the expected profile score vectors for subjects with missing marks. The augmented IPW estimator is doubly robust and recommended for use with incomplete mark data. The methods make two key assumptions: (i) the time-to-event is assumed to be conditionally independent of the mark given treatment, and (ii) the weight function in the semiparametric density ratio/biased sampling model is assumed to be exponential. Diagnostic testing procedures for evaluating validity of both assumptions are implemented. Summary and plotting functions are provided for estimation and inferential results.",2019-02-26,Michal Juraska,https://github.com/mjuraska/sievePH,TRUE,https://github.com/mjuraska/sieveph,321,0,1551208816
sigmajs,"Interface to 'sigma.js' graph visualization library including animations, plugins and shiny proxies.",2018-11-18,John Coene  (<https://orcid.org/0000-0002-6637-4107>),http://sigmajs.john-coene.com/,TRUE,https://github.com/johncoene/sigmajs,2134,35,1552229273
sigmaNet,"Create interactive graph visualizations using 'Sigma.js' <http://sigmajs.org/>.  This package is meant to be used in conjunction
    with 'igraph', replacing the (somewhat underwhelming) plotting features of the package.  The idea is to quickly render
    graphs, regardless of their size, in a way that allows for easy, iterative modification of aesthetics.  Because 
    'Sigma.js' is a 'javascript' library, the visualizations are inherently interactive and are well suited for integration
    with 'Shiny' apps.  While there are several 'htmlwidgets' focused on network visualization, they tend to underperform on 
    medium to large sized graphs.  'Sigma.js' was designed for larger network visualizations and this package aims to 
    make those strengths available to 'R' users.",2018-04-23,Ian Kloo,https://github.com/iankloo/sigmaNet,TRUE,https://github.com/iankloo/sigmanet,2837,27,1529638092
signalHsmm,"Predicts the presence of signal peptides in eukaryotic protein
    using hidden semi-Markov models. The implemented algorithm can be accessed from
    both the command line and GUI.",2018-11-15,"Michal Burdukiewicz 
    (<https://orcid.org/0000-0001-8926-582X>)",https://github.com/michbur/signalhsmm,TRUE,https://github.com/michbur/signalhsmm,7406,1,1542272094
sigr,"Succinctly and correctly format statistical summaries of
    various models and tests (F-test, Chi-Sq-test, Fisher-test, T-test, and rank-significance).  The main purpose is unified reporting 
    of experimental results, working around issue such as the difficulty of
    extracting model summary facts (such as with 'lm'/'glm').  This package also
    includes empirical tests, such as bootstrap estimates.",2019-02-20,John Mount,"https://github.com/WinVector/sigr/,
https://winvector.github.io/sigr/",TRUE,https://github.com/winvector/sigr,23533,21,1550677280
Sim.DiffProc,"It provides users with a wide range of tools to simulate, estimate, analyze, and visualize the dynamics of stochastic differential systems in both forms Ito and Stratonovich. Statistical analysis with parallel Monte Carlo and moment equations methods of SDE's. Enabled many searchers in different domains to use these equations to modeling practical problems in financial and actuarial modeling and other areas of application, e.g., modeling and simulate of first passage time problem in shallow water using the attractive center (Boukhetala K, 1996) ISBN:1-56252-342-2. ",2018-11-28,Arsalane Chouaib Guidoum,https://github.com/acguidoum/Sim.DiffProc,TRUE,https://github.com/acguidoum/sim.diffproc,39714,2,1543408069
simboot,"Provides estimation of simultaneous bootstrap and asymptotic confidence intervals for diversity indices, namely the Shannon and the Simpson index. Several pre--specified multiple comparison types are available to choose. Further user--defined contrast matrices are applicable. In addition, simboot estimates adjusted as well as unadjusted p--values for two of the three proposed bootstrap methods. Further simboot allows for comparing biological diversities of two or more groups while simultaneously testing a user-defined selection of Hill numbers of orders q, which are considered as appropriate and useful indices for measuring diversity.",2017-03-14,Ralph Scherer,"https://github.com/shearer/simboot,
http://shearer.github.io/simboot/",TRUE,https://github.com/shearer/simboot,12721,2,1534968284
simcausal,"A flexible tool for simulating complex longitudinal data using
    structural equations, with emphasis on problems in causal inference.
    Specify interventions and simulate from intervened data generating
    distributions. Define and evaluate treatment-specific means, the average
    treatment effects and coefficients from working marginal structural models.
    User interface designed to facilitate the conduct of transparent and
    reproducible simulation studies, and allows concise expression of complex
    functional dependencies for a large number of time-varying nodes. See the
    package vignette for more information, documentation and examples.",2019-01-07,Oleg Sofrygin,https://github.com/osofr/simcausal,TRUE,https://github.com/osofr/simcausal,10039,20,1546642489
simcdm,"Provides efficient R and 'C++' routines to simulate cognitive diagnostic
    model data for Deterministic Input, Noisy ""And"" Gate ('DINA') and
    reduced Reparameterized Unified Model ('rRUM') from 
    Culpepper and Hudson (2017) <doi: 10.1177/0146621617707511>,
    Culpepper (2015) <doi:10.3102/1076998615595403>, and
    de la Torre (2009) <doi:10.3102/1076998607309474>.",2019-03-10,James Joseph Balamuta,https://github.com/tmsalab/simcdm,TRUE,https://github.com/tmsalab/simcdm,1169,0,1552197787
SimCorMultRes,Simulates correlated multinomial responses conditional on a marginal model specification.,2018-07-10,Anestis Touloumis  (0000-0002-5965-1639),http://github.com/AnestisTouloumis/SimCorMultRes,TRUE,https://github.com/anestistouloumis/simcormultres,14499,5,1541416552
SimCorrMix,"Generate continuous (normal, non-normal, or mixture distributions), binary, ordinal, 
    and count (regular or zero-inflated, Poisson or Negative Binomial) variables with a specified 
    correlation matrix, or one continuous variable with a mixture distribution.  This package can 
    be used to simulate data sets that mimic real-world clinical or genetic data sets (i.e., 
    plasmodes, as in Vaughan et al., 2009 <DOI:10.1016/j.csda.2008.02.032>).  The methods 
    extend those found in the 'SimMultiCorrData' R package.  Standard normal variables with an 
    imposed intermediate correlation matrix are transformed to generate the desired distributions.  
    Continuous variables are simulated using either Fleishman (1978)'s third order 
    <DOI:10.1007/BF02293811> or Headrick (2002)'s fifth order 
    <DOI:10.1016/S0167-9473(02)00072-5> polynomial transformation method (the power method 
    transformation, PMT).  Non-mixture distributions require the user to specify mean, variance, 
    skewness, standardized kurtosis, and standardized fifth and sixth cumulants.  Mixture 
    distributions require these inputs for the component distributions plus the mixing 
    probabilities.  Simulation occurs at the component level for continuous mixture 
    distributions.  The target correlation matrix is specified in terms of correlations with 
    components of continuous mixture variables.  These components are transformed into the 
    desired mixture variables using random multinomial variables based on the mixing 
    probabilities.  However, the package provides functions to approximate expected correlations 
    with continuous mixture variables given target correlations with the components. Binary and 
    ordinal variables are simulated using a modification of ordsample() in package 'GenOrd'.  
    Count variables are simulated using the inverse CDF method.  There are two simulation 
    pathways which calculate intermediate correlations involving count variables differently.  
    Correlation Method 1 adapts Yahav and Shmueli's 2012 method <DOI:10.1002/asmb.901> and 
    performs best with large count variable means and positive correlations or small means and 
    negative correlations.  Correlation Method 2 adapts Barbiero and Ferrari's 2015 
    modification of the 'GenOrd' package <DOI:10.1002/asmb.2072> and performs best under the 
    opposite scenarios.  The optional error loop may be used to improve the accuracy of the 
    final correlation matrix.  The package also contains functions to calculate the 
    standardized cumulants of continuous mixture distributions, check parameter inputs, 
    calculate feasible correlation boundaries, and summarize and plot simulated variables.",2018-07-01,Allison Cynthia Fialkowski,https://github.com/AFialkowski/SimCorrMix,TRUE,https://github.com/afialkowski/simcorrmix,2308,0,1530449161
SimDesign,"Provides tools to help safely and efficiently organize Monte Carlo simulations in R.
    The package controls the structure and back-end of Monte Carlo simulations
    by utilizing a general generate-analyse-summarise strategy. The functions provided control
    common simulation issues such as re-simulating non-convergent results, support parallel
    back-end and MPI distributed computations, save and restore temporary files,
    aggregate results across independent nodes, and provide native support for debugging.
    For a pedagogical introduction to the package refer to 
    Sigal and Chalmers (2016) <doi:10.1080/10691898.2016.1246953>.",2019-01-18,Phil Chalmers,"https://github.com/philchalmers/SimDesign,
https://github.com/philchalmers/SimDesign/wiki",TRUE,https://github.com/philchalmers/simdesign,35261,22,1553356868
SimilaR,"An Implementation of a novel method to determine similarity of R 
    functions based on program dependence graphs, 
    see Bartoszuk, Gagolewski (2017) <doi:10.1109/FUZZ-IEEE.2017.8015582>. 
    Possible use cases include
    plagiarism detection among students' homework assignments.",2019-02-25,Maciej Bartoszuk,http://similar.rexamine.com/,TRUE,https://github.com/bartoszukm/similar,2246,2,1554478669
SimInf,"Provides an efficient and very flexible framework to
    conduct data-driven epidemiological modeling in realistic large
    scale disease spread simulations. The framework integrates
    infection dynamics in subpopulations as continuous-time Markov
    chains using the Gillespie stochastic simulation algorithm and
    incorporates available data such as births, deaths and movements
    as scheduled events at predefined time-points. Using C code for
    the numerical solvers and 'OpenMP' (if available) to divide work
    over multiple processors ensures high performance when simulating
    a sample outcome. One of our design goals was to make the package
    extendable and enable usage of the numerical solvers from other R
    extension packages in order to facilitate complex epidemiological
    research. The package contains template models and can be extended
    with user-defined models.",2018-11-20,Stefan Widgren  (<https://orcid.org/0000-0001-5745-2284>),https://github.com/stewid/SimInf,TRUE,https://github.com/stewid/siminf,8488,8,1553935605
simIReff,"Provides tools for the stochastic simulation of effectiveness scores to mitigate
  data-related limitations of Information Retrieval evaluation research, as described in Urbano and
  Nagler (2018) <doi:10.1145/3209978.3210043>. These tools include: fitting, selection and plotting
  distributions to model system effectiveness, transformation towards a prespecified expected value,
  proxy to fitting of copula models based on these distributions, and simulation of new evaluation
  data from these distributions and copula models.",2018-06-15,Julián Urbano,https://github.com/julian-urbano/simIReff/,TRUE,https://github.com/julian-urbano/simireff,1588,0,1531752121
simmer,"A process-oriented and trajectory-based Discrete-Event Simulation
    (DES) package for R. It is designed as a generic yet powerful framework. The
    architecture encloses a robust and fast simulation core written in 'C++' with
    automatic monitoring capabilities. It provides a rich and flexible R API that
    revolves around the concept of trajectory, a common path in the simulation
    model for entities of the same type. Documentation about 'simmer' is provided
    by several vignettes included in this package, via the paper by Ucar, Smeets
    & Azcorra (2018, <arXiv:1705.09746>), and the paper by Ucar, Hernández, 
    Serrano & Azcorra (2018, <doi:10.1109/MCOM.2018.1700960>);
    see 'citation(""simmer"")' for details.",2019-03-14,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer",TRUE,https://github.com/r-simmer/simmer,34434,119,1552666852
simmer.bricks,Provides wrappers for common activity patterns in 'simmer' trajectories.,2019-01-09,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer.bricks",TRUE,https://github.com/r-simmer/simmer.bricks,3097,4,1547029796
simmer.plot,A set of plotting methods for 'simmer' trajectories and simulations.,2019-03-10,Iñaki Ucar,"http://r-simmer.org, https://github.com/r-simmer/simmer.plot",TRUE,https://github.com/r-simmer/simmer.plot,14365,6,1553714381
SimMultiCorrData,"Generate continuous (normal or non-normal), binary, ordinal, and count (Poisson or Negative 
    Binomial) variables with a specified correlation matrix.  It can also produce a single continuous 
    variable.  This package can be used to simulate data sets that mimic real-world situations (i.e. 
    clinical or genetic data sets, plasmodes).  All variables are generated from standard normal 
    variables with an imposed intermediate correlation matrix.  Continuous variables are simulated 
    by specifying mean, variance, skewness, standardized kurtosis, and fifth and sixth standardized 
    cumulants using either Fleishman's third-order (<DOI:10.1007/BF02293811>) or Headrick's 
    fifth-order (<DOI:10.1016/S0167-9473(02)00072-5>) polynomial transformation.  Binary and 
    ordinal variables are simulated using a modification of the ordsample() function from 'GenOrd'.  
    Count variables are simulated using the inverse cdf method.  There are two simulation pathways 
    which differ primarily according to the calculation of the intermediate correlation matrix.  In 
    Correlation Method 1, the intercorrelations involving count variables are determined using a 
    simulation based, logarithmic correlation correction (adapting Yahav and Shmueli's 2012 method, 
    <DOI:10.1002/asmb.901>).  In Correlation Method 2, the count variables are treated as ordinal 
    (adapting Barbiero and Ferrari's 2015 modification of GenOrd, <DOI:10.1002/asmb.2072>).  
    There is an optional error loop that corrects the final correlation matrix to be within a 
    user-specified precision value of the target matrix.  The package also includes functions to 
    calculate standardized cumulants for theoretical distributions or from real data sets, check 
    if a target correlation matrix is within the possible correlation bounds (given the distributions 
    of the simulated variables), summarize results (numerically or graphically), to verify valid power 
    method pdfs, and to calculate lower standardized kurtosis bounds.",2018-06-28,Allison Cynthia Fialkowski,https://github.com/AFialkowski/SimMultiCorrData,TRUE,https://github.com/afialkowski/simmulticorrdata,4374,3,1530204676
SimPhe,"Provides functions to simulate single or multiple, independent or correlated phenotype(s) with additive, dominance effects and their interactions. Also includes functions to generate phenotype(s) with specific heritability. Flexible and user-friendly options for simulation.",2018-09-13,Beibei Jiang <beibei_jiang@psych.mpg.de> and Benno Pütz,https://github.com/beibeiJ/SimPhe,TRUE,https://github.com/beibeij/simphe,4325,1,1536849439
simpleboot,Simple bootstrap routines.,2019-02-20,Roger D. Peng <rpeng@jhsph.edu>,https://github.com/rdpeng/simpleboot,TRUE,https://github.com/rdpeng/simpleboot,36742,6,1548779294
simPop,"Tools and methods to simulate populations for surveys based
    on auxiliary data. The tools include model-based methods, calibration and
    combinatorial optimization algorithms. The package was developed with support of
    the International Household Survey Network, DFID Trust Fund TF011722 and funds
    from the World bank.",2018-05-29,Bernhard Meindl,https://github.com/statistikat/simPop,TRUE,https://github.com/statistikat/simpop,14813,8,1549984622
simputation,"Easy to use interfaces to a number of imputation methods
        that fit in the not-a-pipe operator of the 'magrittr' package.",2017-05-19,Mark van der Loo,https://github.com/markvanderloo/simputation,TRUE,https://github.com/markvanderloo/simputation,10344,46,1553262495
simr,"Calculate power for generalised linear mixed models, using
    simulation. Designed to work with models fit using the 'lme4' package.
    Described in Green and MacLeod, 2016 <doi:10.1111/2041-210X.12504>.",2019-01-29,Green Peter  (<https://orcid.org/0000-0002-0238-9852>),https://github.com/pitakakariki/simr,TRUE,https://github.com/pitakakariki/simr,19569,26,1548730359
simrel,"Simulate multivariate linear model data is useful in research and education weather 
    for comparison or create data with specific properties. This package lets user to simulate
    linear model data of wide range of properties with few tuning parameters.
    The package also consist of function to create plots for the simulation
    objects and A shiny app as RStudio gadget. It can be a handy tool for model comparison, 
    testing and many other purposes.",2019-04-01,Raju Rimal,https://simulatr.github.io/simrel/,TRUE,https://github.com/simulatr/simrel,9388,1,1554559697
SimRepeat,"Generate correlated systems of statistical equations which represent 
    repeated measurements or clustered data.  These systems contain either: a) continuous normal, 
    non-normal, and mixture variables based on the techniques of Headrick and Beasley (2004) 
    <DOI:10.1081/SAC-120028431> or b) continuous (normal, non-normal and mixture), ordinal, 
    and count (regular or zero-inflated, Poisson and Negative Binomial) variables based on the 
    hierarchical linear models (HLM) approach.  Headrick and Beasley's method for continuous 
    variables calculates the beta (slope) coefficients based on the target correlations between 
    independent variables and between outcomes and independent variables.  The package provides 
    functions to calculate the expected correlations between outcomes, between outcomes and error 
    terms, and between outcomes and independent variables, extending Headrick and Beasley's 
    equations to include mixture variables.  These theoretical values can be compared to the 
    simulated correlations.  The HLM approach requires specification of the beta coefficients, 
    but permits group and subject-level independent variables, interactions among independent 
    variables, and fixed and random effects, providing more flexibility in the system of 
    equations.  Both methods permit simulation of data sets that mimic real-world clinical or 
    genetic data sets (i.e. plasmodes, as in Vaughan et al., 2009, <10.1016/j.csda.2008.02.032>).  
    The techniques extend those found in the 'SimMultiCorrData' and 'SimCorrMix' packages.  
    Standard normal variables with an imposed intermediate correlation matrix are transformed 
    to generate the desired distributions.  Continuous variables are simulated using either 
    Fleishman's third-order (<DOI:10.1007/BF02293811>) or Headrick's fifth-order 
    (<DOI:10.1016/S0167-9473(02)00072-5>) power method transformation (PMT).  Simulation 
    occurs at the component-level for continuous mixture distributions.  These components are 
    transformed into the desired mixture variables using random multinomial variables based on 
    the mixing probabilities.  The target correlation matrices are specified in terms of 
    correlations with components of continuous mixture variables.  Binary and ordinal variables 
    are simulated by discretizing the normal variables at quantiles defined by the marginal 
    distributions.  Count variables are simulated using the inverse CDF method.  There are 
    two simulation pathways for the multi-variable type systems which differ by intermediate 
    correlations involving count variables.  Correlation Method 1 adapts Yahav and Shmueli's 
    2012 method <DOI:10.1002/asmb.901> and performs best with large count variable means and 
    positive correlations or small means and negative correlations.  Correlation Method 2 
    adapts Barbiero and Ferrari's 2015 modification of the 'GenOrd' package 
    <DOI:10.1002/asmb.2072> and performs best under the opposite scenarios.  There are 
    three methods available for correcting non-positive definite correlation matrices.  The 
    optional error loop may be used to improve the accuracy of the final correlation matrices.  
    The package also provides function to check parameter inputs and summarize the simulated 
    systems of equations.",2018-04-16,Allison Cynthia Fialkowski,https://github.com/AFialkowski/SimRepeat,TRUE,https://github.com/afialkowski/simrepeat,1757,2,1529611627
SiMRiv,"Provides functions to generate and analyze spatially-explicit individual-based multistate movements in rivers,
  heterogeneous and homogeneous spaces. This is done by incorporating landscape bias on local behaviour, based on
  resistance rasters. Although originally conceived and designed to simulate trajectories of species constrained to
  linear habitats/dendritic ecological networks (e.g. river networks), the simulation algorithm is built to be
  highly flexible and can be applied to any (aquatic, semi-aquatic or terrestrial) organism, independently on the
  landscape in which it moves. Thus, the user will be able to use the package to simulate movements either in
  homogeneous landscapes, heterogeneous landscapes (e.g. semi-aquatic animal moving mainly along rivers but also using
  the matrix), or even in highly contrasted landscapes (e.g. fish in a river network). The algorithm and its input
  parameters are the same for all cases, so that results are comparable. Simulated trajectories can then be used as
  mechanistic null models (Potts & Lewis 2014, <DOI:10.1098/rspb.2014.0231>) to test a variety of 'Movement Ecology'
  hypotheses (Nathan et al. 2008, <DOI:10.1073/pnas.0800375105>), including landscape effects (e.g. resources, 
  infrastructures) on animal movement and species site fidelity, or for predictive purposes (e.g. road mortality risk,
  dispersal/connectivity). The package should be relevant to explore a broad spectrum of ecological phenomena, such as
  those at the interface of animal behaviour, management, landscape and movement ecology, disease and invasive species
  spread, and population dynamics.",2018-01-31,Miguel Porto,"https://www.r-project.org, https://github.com/miguel-porto/SiMRiv",TRUE,https://github.com/miguel-porto/simriv,6180,4,1545838470
simstandard,Creates simulated data from structural equation models with standardized loading.,2019-01-07,W. Joel Schneider  (<https://orcid.org/0000-0002-8393-5316>),https://github.com/wjschne/simstandard,TRUE,https://github.com/wjschne/simstandard,1426,1,1546671088
simsurv,"Simulate survival times from standard parametric survival 
    distributions (exponential, Weibull, Gompertz), 2-component mixture 
    distributions, or a user-defined hazard, log hazard, cumulative hazard,
    or log cumulative hazard function. Baseline covariates can be included 
    under a proportional hazards assumption. 
    Time dependent effects (i.e. non-proportional hazards) can be included by 
    interacting covariates with linear time or a user-defined function of time.
    Clustered event times are also accommodated. 
    The 2-component mixture distributions can allow for a variety of flexible
    baseline hazard functions reflecting those seen in practice. 
    If the user wishes to provide a user-defined 
    hazard or log hazard function then this is possible, and the resulting
    cumulative hazard function does not need to have a closed-form solution. 
    Note that this package is modelled on the 'survsim' package available in 
    the 'Stata' software (see Crowther and Lambert (2012) 
    <http://www.stata-journal.com/sjpdf.html?articlenum=st0275> or 
    Crowther and Lambert (2013) <doi:10.1002/sim.5823>).",2019-02-01,Sam Brilleman,NA,TRUE,https://github.com/sambrilleman/simsurv,4920,6,1550814317
simtimer,"Handles datetimes as integers for the usage inside
        Discrete-Event Simulations (DES). The conversion is made using
        the internally generic function as.numeric() of the base
        package. DES is described in Simulation Modeling and Analysis
        by Averill Law and David Kelton (1999) <doi:10.2307/2288169>.",2019-01-22,Adrian Staempfli,http://github.com/ims-fhs/simtimer,TRUE,https://github.com/ims-fhs/simtimer,2676,0,1548148321
simTool,"Tool for statistical simulations that have two components. 
    One component generates the data and the other one
    analyzes the data. The main aims of the package are the reduction
    of the administrative source code (mainly loops and management code for the
    results) and a simple applicability of the package that allows the user to
    quickly learn how to work with it. Parallel computing is
    also supported. Finally, convenient functions are provided to summarize the
    simulation results.",2019-03-22,Marsel Scheer,https://github.com/MarselScheer/simTool,TRUE,https://github.com/marselscheer/simtool,10551,3,1551477522
simukde,"Generates random values from a univariate and multivariate continuous distribution by using kernel density estimation based on a sample. Duong (2017) <doi:10.18637/jss.v021.i07>, Christian P. Robert and George Casella (2010 ISBN:978-1-4419-1575-7) <doi:10.1007/978-1-4419-1576-4>.",2018-10-07,MAKHGAL Ganbold,https://github.com/galaamn/simukde,TRUE,https://github.com/galaamn/simukde,1993,0,1538893733
simulator,"A framework for performing simulations such as those common in
    methodological statistics papers.  The design principles of this package
    are described in greater depth in Bien, J. (2016) ""The simulator: An Engine
    to Streamline Simulations,"" which is available at
    <http://faculty.bscb.cornell.edu/~bien/simulator.pdf>.",2016-07-12,Jacob Bien,http://github.com/jacobbien/simulator,TRUE,https://github.com/jacobbien/simulator,5284,30,1531988420
simule,"This is an R implementation of a constrained l1 minimization approach for estimating multiple Sparse Gaussian or Nonparanormal Graphical Models (SIMULE). The SIMULE algorithm can be used to estimate multiple related precision matrices. For instance, it can identify context-specific gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogenous data sets, this tool can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(simuleDemo) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Ritambhara Singh, Yanjun Qi (2017) <DOI:10.1007/s10994-017-5635-7>.",2018-07-02,Beilun Wang,https://github.com/QData/SIMULE,TRUE,https://github.com/qdata/simule,4478,4,1530647767
sinew,"Create 'roxygen2' skeleton populated with information scraped from the
         within the function script. Also creates field entries for imports in the
         'DESCRIPTION' and import in the 'NAMESPACE' files. Can be run from the R
         console or through the 'RStudio' 'addin' menu.",2018-08-31,Jonathan Sidi  (<https://orcid.org/0000-0002-4222-1819>),https://github.com/metrumresearchgroup/sinew,TRUE,https://github.com/metrumresearchgroup/sinew,6143,82,1545493413
SingleCaseES,"
  Provides R functions for calculating basic effect size indices for 
  single-case designs, including several non-overlap measures and parametric 
  effect size measures, and for estimating the gradual effects model developed 
  by Swan and Pustejovsky (2018) <DOI:10.1080/00273171.2018.1466681>. 
  Standard errors and confidence intervals (based on the assumption that the outcome 
  measurements are mutually independent) are provided for the subset of effect sizes 
  indices with known sampling distributions.",2019-01-07,James E. Pustejovsky,https://github.com/jepusto/SingleCaseES,TRUE,https://github.com/jepusto/singlecasees,2203,2,1553178413
sinx,"Displays a pseudorandom message from a database of quotations. It works as an advanced version of the package 'fortunes', while 'sinx' supports multi-byte languages such as Chinese. The databases of 'sinx' can be given in markdown format, which is easier and more friendly than spread sheets for users.",2019-03-22,Peng Zhao,https://github.com/pzhaonet/sinx,TRUE,https://github.com/pzhaonet/sinx,127,2,1554235173
SIRItoGTFS,"Allows the user to compare SIRI (Service Interface for Real Time Information) data sets to their GTFS (General Transit Feed Specification) counterparts, a ""Request_id"" column us needed for the SIRI data frame in order to subset parts of it for use.   ",2018-05-21,Dror Bogin,"https://github.com/bogind/SIRItoGTFS,
http://user47094.vs.easily.co.uk/siri/documentation.htm,
https://developers.google.com/transit/gtfs/",TRUE,https://github.com/bogind/siritogtfs,2366,0,1535711719
sirt,"
    Supplementary functions for item response models aiming
    to complement existing R packages. The functionality includes among others
    multidimensional compensatory and noncompensatory IRT models
    (Reckase, 2009, <doi:10.1007/978-0-387-89976-3>), 
    MCMC for hierarchical IRT models and testlet models
    (Fox, 2010, <doi:10.1007/978-1-4419-0742-4>), 
    NOHARM (McDonald, 1982, <doi:10.1177/014662168200600402>), 
    Rasch copula model (Braeken, 2011, <doi:10.1007/s11336-010-9190-4>;
    Schroeders, Robitzsch & Schipolowski, 2014, <doi:10.1111/jedm.12054>),
    faceted and hierarchical rater models (DeCarlo, Kim & Johnson, 2011,
    <doi:10.1111/j.1745-3984.2011.00143.x>),
    ordinal IRT model (ISOP; Scheiblechner, 1995, <doi:10.1007/BF02301417>), 
    DETECT statistic (Stout, Habing, Douglas & Kim, 1996, 
    <doi:10.1177/014662169602000403>), local structural equation modeling 
    (LSEM; Hildebrandt, Luedtke, Robitzsch, Sommer & Wilhelm, 2016,
    <doi:10.1080/00273171.2016.1142856>).",2019-03-18,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/sirt,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/sirt,258850,7,1554111996
sitar,"Functions for fitting and plotting SITAR (Super
    Imposition by Translation And Rotation) growth curve models. SITAR is
    a shape-invariant model with a regression B-spline mean curve and
    subject-specific random effects on both the measurement and age
    scales.  The model was first described by Lindstrom (1995)
    <doi:10.1002/sim.4780141807> and developed as the SITAR method by Cole
    et al (2010) <doi:10.1093/ije/dyq115>.",2019-03-12,Tim Cole  (<https://orcid.org/0000-0001-5711-8200>),https://github.com/statist7/sitar,TRUE,https://github.com/statist7/sitar,15864,3,1554043266
sitmo,"Provided within are two high quality and fast PPRNGs that may be
    used in an 'OpenMP' parallel environment. In addition, there is a generator
    for one dimensional low-discrepancy sequence. The objective of this library
    to consolidate the distribution of the 'sitmo' (C++98 & C++11), 'threefry' and
    'vandercorput' (C++11-only) engines on CRAN by enabling others to link to the
    header files inside of 'sitmo' instead of including a copy of each engine
    within their individual package. Lastly, the package contains example
    implementations using the 'sitmo' package and three accompanying vignette that
    provide additional information.",2019-01-07,James Balamuta,"https://github.com/coatless/sitmo,
http://thecoatlessprofessor.com/projects/sitmo/,
https://github.com/stdfin/random/",TRUE,https://github.com/coatless/sitmo,8474,5,1546629730
SiZer,"Calculates and plots the SiZer map for scatterplot data.  A 
  SiZer map is a way of examining when the p-th derivative of a 
  scatterplot-smoother is significantly negative, possibly zero or 
  significantly positive across a range of smoothing bandwidths.",2018-05-29,Derek Sonderegger,https://github.com/dereksonderegger/SiZer,TRUE,https://github.com/dereksonderegger/sizer,17313,0,1527281585
sjlabelled,"Collection of functions dealing with labelled data, like reading and 
    writing data between R and other statistical software packages like 'SPSS',
    'SAS' or 'Stata', and working with labelled data. This includes easy ways 
    to get, set or change value and variable label attributes, to convert 
    labelled vectors into factors or numeric (and vice versa), or to deal with 
    multiple declared missing values.",2019-03-10,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>),https://strengejacke.github.io/sjlabelled,TRUE,https://github.com/strengejacke/sjlabelled,257636,27,1552672296
sjmisc,"Collection of miscellaneous utility functions, supporting data 
    transformation tasks like recoding, dichotomizing or grouping variables, 
    setting and replacing missing values. The data transformation functions 
    also support labelled data, and all integrate seamlessly into a 
    'tidyverse'-workflow.",2019-03-16,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>),https://strengejacke.github.io/sjmisc,TRUE,https://github.com/strengejacke/sjmisc,359139,78,1552809005
sjPlot,"Collection of plotting and table output functions for data
    visualization. Results of various statistical analyses (that are commonly used
    in social sciences) can be visualized using this package, including simple and
    cross tabulated frequencies, histograms, box plots, (generalized) linear models,
    mixed effects models, principal component analysis and correlation matrices, 
    cluster analyses, scatter plots, stacked scales, effects plots of regression 
    models (including interaction terms) and much more. This package supports
    labelled data.",2018-12-18,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>),https://strengejacke.github.io/sjPlot/,TRUE,https://github.com/strengejacke/sjplot,295374,253,1554236453
sjstats,"Collection of convenient functions for common statistical computations,
             which are not directly provided by R's base or stats packages.
             This package aims at providing, first, shortcuts for statistical
             measures, which otherwise could only be calculated with additional
             effort (like standard errors or root mean squared errors). Second,
             these shortcut functions are generic (if appropriate), and can be
             applied not only to vectors, but also to other objects as well
             (e.g., the Coefficient of Variation can be computed for vectors,
             linear models, or linear mixed models; the r2()-function returns
             the r-squared value for 'lm', 'glm', 'merMod' and other model objects).
             The focus of most functions lies on summary statistics or fit
             measures for regression models, including generalized linear
             models, mixed effects models and Bayesian models. However, some 
             of the functions also deal with other statistical measures, 
             like Cronbach's Alpha, Cramer's V, Phi etc.",2019-03-15,Daniel Lüdecke  (<https://orcid.org/0000-0002-8895-3206>),"https://github.com/strengejacke/sjstats,
https://strengejacke.github.io/sjstats",TRUE,https://github.com/strengejacke/sjstats,272074,100,1553677318
skeleSim,"A shiny interface and supporting tools to guide users in choosing
    appropriate simulations, setting parameters, calculating summary genetic
    statistics, and organizing data output, all within the R environment. In
    addition to supporting existing forward and reverse-time simulators, new
    simulators can be integrated into the environment relatively easily.",2017-11-27,Allan Strand,https://github.com/christianparobek/skeleSim,TRUE,https://github.com/christianparobek/skelesim,4486,3,1550607627
skeletor,"A tool for bootstrapping new packages with useful defaults,
    including a test suite outline that passes checks and helpers for running
    tests, checking test coverage, building vignettes, and more. Package
    skeletons it creates are set up for pushing your package to
    'GitHub' and using other hosted services for building and test automation.",2017-04-09,Neal Richardson,https://github.com/nealrichardson/skeletor,TRUE,https://github.com/nealrichardson/skeletor,4052,10,1537477533
skimr,"A simple to use summary function that can be used with pipes
    and displays nicely in the console. The default summary statistics may be 
    modified by the user as can the default formatting. Support for data frames 
    and vectors is included, and users can implement their own skim methods for
    specific object types as described in a vignette. Default summaries include
    support for inline spark graphs. Instructions for managing these on 
    specific operating systems are given in the ""Using skimr"" vignette and the 
    README.",2019-02-25,Elin Waring,https://github.com/ropenscilabs/skimr,TRUE,https://github.com/ropenscilabs/skimr,90814,594,1554256292
skm,"Algorithms for solving selective k-means problem,
    which is defined as finding k rows in an m x n matrix such that 
    the sum of each column minimal is minimized. 
    In the scenario when m == n and each cell value in matrix is a 
    valid distance metric, this is equivalent to a k-means problem. 
    The selective k-means extends the k-means problem in the sense 
    that it is possible to have m != n, often the case m < n which 
    implies the search is limited within a small subset of rows. 
    Also, the selective k-means extends the k-means problem in the 
    sense that the instance in row set can be instance not seen in 
    the column set, e.g., select 2 from 3 internet service provider
    (row) for 5 houses (column) such that minimize the overall cost 
    (cell value) - overall cost is the sum of the column minimal of
    the selected 2 service provider.",2017-01-23,Guang Yang,http://github.com/gyang274/skm,TRUE,https://github.com/gyang274/skm,3835,0,1532463073
skpr,"Generates and evaluates D, I, A, Alias, E, T, and G optimal designs. Supports generation and evaluation of split/split-split/.../N-split plot designs. Includes parametric and Monte Carlo power evaluation functions, and supports calculating power for censored responses. Provides a framework to evaluate power using functions provided in other packages or written by the user. Includes a Shiny graphical user interface that displays the underlying code used to create and evaluate the design to improve ease-of-use and make analyses more reproducible.",2018-11-13,Tyler Morgan-Wall,https://github.com/tylermorganwall/skpr,TRUE,https://github.com/tylermorganwall/skpr,6647,51,1552935239
skynet,"A flexible tool that allows generating bespoke
    air transport statistics for urban studies based on publicly available
    data from the Bureau of Transport Statistics (BTS) in the United States
    <https://www.transtats.bts.gov/databases.asp?Mode_ID=1&Mode_Desc=Aviation&Subject_ID2=0>.",2018-12-12,Filipe Teixeira,https://github.com/FilipeamTeixeira/skynet,TRUE,https://github.com/filipeamteixeira/skynet,3718,5,1554135319
SkyWatchr,"Query and download satellite imagery and climate/atmospheric datasets using the SkyWatch API. 
     Search datasets by wavelength (band), cloud cover, resolution, location, date, etc.
     Get the query results as data frame and as HTML. To learn more about the SkyWatch API, see <https://github.com/skywatchspaceapps/api>.",2017-07-01,Ali Santacruz,https://github.com/amsantac/SkyWatchr,TRUE,https://github.com/amsantac/skywatchr,5081,15,1527386733
slackr,"'Slack' <http://slack.com/> provides a service for teams to
    collaborate by sharing messages, images, links, files and more. Functions are provided
    that make it possible to interact with the 'Slack' platform 'API'. When
    you need to share information or data from R, rather than resort to copy/
    paste in e-mails or other services like 'Skype' <http://www.skype.com/>, you
    can use this package to send well-formatted output from multiple R objects and
    expressions to all teammates at the same time with little effort. You can also
    send images from the current graphics device, R objects, and upload files.",2016-07-20,Bob Rudis,http://github.com/hrbrmstr/slackr,TRUE,https://github.com/hrbrmstr/slackr,113426,221,1526505131
sleepr,"Use behavioural variables to score activity and infer sleep from bouts of immobility. 
    It is primarily designed to score sleep in fruit flies from Drosophila Activity Monitor (TriKinetics) and Ethoscope data.
    It implements sleep scoring using the ""five-minute rule"" (Hendricks et al. (2000) <DOI:10.1016/S0896-6273(00)80877-6>),
    activity classification for Ethoscopes (Geissmann et al. (2017) <DOI:10.1371/journal.pbio.2003026>) 
    and a new algorithm to detect when animals are dead.",2018-10-30,Quentin Geissmann,https://github.com/rethomics/sleepr,TRUE,https://github.com/rethomics/sleepr,1294,2,1554501020
sleepwalk,"A tool to interactively explore the
  embeddings created by dimension reduction methods such as 
  Principal Components Analysis (PCA), Multidimensional Scaling (MDS), 
  T-distributed Stochastic Neighbour Embedding (t-SNE),
  Uniform Manifold Approximation and Projection (UMAP) or any other.",2019-04-04,Svetlana Ovchinnikova,https://anders-biostat.github.io/sleepwalk/,TRUE,https://github.com/anders-biostat/sleepwalk,3,51,1554301009
slickR,"Create and customize interactive carousels using the 'Slick'
    JavaScript library and the 'htmlwidgets' package. The carousels can contain plots
    produced in R, images, 'iframes', videos and other 'htmlwidgets'.
    These carousels can be used directly from the R console, from 'RStudio', 
    in Shiny apps and R Markdown documents.",2018-03-06,Jonathan Sidi,https://github.com/metrumresearchgroup/slickR,TRUE,https://github.com/metrumresearchgroup/slickr,7108,68,1554120748
sloop,"A collection of helper functions designed to help
    you to better understand object oriented programming in R,
    particularly using 'S3'.",2019-02-17,Hadley Wickham,"https://github.com/r-lib/sloop, https://sloop.r-lib.org",TRUE,https://github.com/r-lib/sloop,2797,68,1550416340
slouch,"An implementation of a phylogenetic comparative method. It can fit univariate among-species Ornstein-Uhlenbeck models of phenotypic trait evolution, where the trait evolves towards a primary optimum. The optimum can be modelled as a single parameter, as multiple discrete regimes on the phylogenetic tree, and/or with continuous covariates. See also Hansen (1997) doi:10.2307/2411186, Butler & King (2004) doi:10.1086/426002, Hansen et al. (2008) doi:10.1111/j.1558-5646.2008.00412.x.",2019-03-21,Bjørn Tore Kopperud,http://github.com/kopperud/slouch,TRUE,https://github.com/kopperud/slouch,1585,0,1553165942
slowraker,"A mostly pure-R implementation of the RAKE algorithm (Rose, S., Engel, D., Cramer, N. and Cowley, W. (2010) <doi:10.1002/9780470689646.ch1>), which can be used to extract keywords from documents without any training data.",2017-11-02,Christopher Baker,https://crew102.github.io/slowraker/index.html,TRUE,https://github.com/crew102/slowraker,3717,5,1549486691
smaa,Implementation of the Stochastic Multi-Criteria Acceptability Analysis (SMAA) family of Multiple Criteria Decision Analysis (MCDA) methods.,2018-05-21,Gert van Valkenhoef,http://github.com/gertvv/rsmaa,TRUE,https://github.com/gertvv/rsmaa,13878,5,1526899363
SmallCountRounding,"A statistical disclosure control tool to protect frequency tables in cases where small values are sensitive. The function PLSrounding() performs small count rounding of necessary inner cells so that all small frequencies of cross-classifications to be published (publishable cells) are rounded. This is equivalent to changing micro data since frequencies of unique combinations are changed. Thus, additivity and consistency are guaranteed. The methodology is described in Langsrud and Heldal (2018) <https://www.researchgate.net/publication/327768398>.",2019-02-28,Øyvind Langsrud,https://github.com/statisticsnorway/SmallCountRounding,TRUE,https://github.com/statisticsnorway/smallcountrounding,1336,2,1552484395
smam,"Animal movement models including moving-resting process
    with embedded Brownian motion according to
    Yan et al. (2014) <doi:10.1007/s10144-013-0428-8>,
    Pozdnyakov et al. (2017) <doi:10.1007/s11009-017-9547-6>,
    Brownian motion with measurement error according to
    Pozdnyakov et al. (2014) <doi:10.1890/13-0532.1>,
    and moving-resting-handling process with embedded Brownian motion,
    Pozdnyakov et al. (2018) <arXiv:1806.00849>.",2018-10-18,Chaoran Hu,https://github.com/ChaoranHu/smam,TRUE,https://github.com/chaoranhu/smam,12981,0,1554056680
smapr,"
    Facilitates programmatic access to NASA Soil Moisture Active
    Passive (SMAP) data with R. It includes functions to search for, acquire,
    and extract SMAP data.",2018-09-24,Maxwell Joseph,https://github.com/ropensci/smapr,TRUE,https://github.com/ropensci/smapr,6066,44,1554139689
smartdata,"Eases data preprocessing tasks, providing a data flow based 
   on a pipe operator which eases cleansing, transformation, oversampling, 
   or instance/feature selection operations.",2019-01-19,Ignacio Cordón,http://github.com/ncordon/smartdata,TRUE,https://github.com/ncordon/smartdata,2136,6,1547991929
SmCCNet,"
    A canonical correlation based framework for constructing phenotype-specific multi-omics networks by integrating multiple omics data types and a quantitative phenotype of interest. ",2019-03-04,W. Jenny Shi,https://github.com/KechrisLab/SmCCNet,TRUE,https://github.com/kechrislab/smccnet,244,1,1541640384
SMFilter,"Provides the filtering algorithms for the state space models on the Stiefel manifold as well as the corresponding sampling algorithms for uniform, vector Langevin-Bingham and matrix Langevin-Bingham distributions on the Stiefel manifold.",2018-12-12,Yukai Yang,https://github.com/yukai-yang/SMFilter,TRUE,https://github.com/yukai-yang/smfilter,1032,2,1546398005
smoof,"Provides generators for a high number of both single- and multi-
    objective test functions which are frequently used for the benchmarking of
    (numerical) optimization algorithms. Moreover, it offers a set of convenient
    functions to generate, plot and work with objective functions.",2017-08-14,Jakob Bossek,https://github.com/jakobbossek/smoof,TRUE,https://github.com/jakobbossek/smoof,36585,16,1537848315
smooth,"Functions implementing Single Source of Error state space models for purposes
             of time series analysis and forecasting. The package includes Exponential Smoothing,
             SARIMA, Complex Exponential Smoothing, Simple Moving Average, Vector Exponential
             Smoothing in state space forms, several simulation functions and intermittent demand
             state space models.",2018-12-02,"Ivan Svetunkov  (Lecturer at Centre for Marketing Analytics
    and Forecasting",https://github.com/config-i1/smooth,TRUE,https://github.com/config-i1/smooth,137705,36,1554077805
smoothr,"Tools for smoothing and tidying spatial features (i.e. lines and 
    polygons) to make them more aesthetically pleasing. Smooth curves, fill 
    holes, and remove small fragments from lines and polygons.",2018-12-11,"Matthew Strimas-Mackey 
    (<https://orcid.org/0000-0001-8929-7776>)","http://strimas.com/smoothr, https://github.com/mstrimas/smoothr",TRUE,https://github.com/mstrimas/smoothr,3678,46,1544498097
smovie,"Provides movies to help students to understand statistical 
  concepts.  The 'rpanel' package  <https://cran.r-project.org/package=rpanel> 
  is used to create interactive plots that move to illustrate key statistical 
  ideas and methods.  There are movies to: visualise probability distributions
  (including user-supplied ones); illustrate sampling distributions of the
  sample mean (central limit theorem), the sample maximum (extremal types 
  theorem) and (the Fisher transformation of the) Pearson product moment 
  correlation coefficient; examine the influence of an individual observation 
  in simple linear regression; illustrate key concepts in statistical 
  hypothesis testing. Also provided are dpqr functions for the distribution of 
  the Fisher transformation of the correlation coefficient under sampling from 
  a bivariate normal distribution.",2018-04-21,Paul J. Northrop,http://github.com/paulnorthrop/smovie,TRUE,https://github.com/paulnorthrop/smovie,2626,0,1548232180
snakecase,"A consistent, flexible and easy to use tool to parse and convert strings into cases like snake or camel among others.",2018-08-14,Malte Grosser,https://github.com/Tazinho/snakecase,TRUE,https://github.com/tazinho/snakecase,232471,76,1550697632
snotelr,"Programmatic interface to the 'SNOTEL' snow data
  (<https://www.wcc.nrcs.usda.gov/snow/>). Provides easy downloads of snow 
  data into your R work space or a local directory. Additional post-processing 
  routines to extract snow season indexes are provided.",2019-01-08,Koen Hufkens,https://github.com/khufkens/snotelr,TRUE,https://github.com/khufkens/snotelr,722,3,1552637239
sofa,"Provides an interface to the 'NoSQL' database 'CouchDB'
    (<http://couchdb.apache.org>). Methods are provided for managing
    databases within 'CouchDB', including creating/deleting/updating/transferring,
    and managing documents within databases. One can connect with a local
    'CouchDB' instance, or a remote 'CouchDB' databases such as 'Cloudant'
    (<https://docs.cloudant.com>). Documents can be inserted directly from
    vectors, lists, data.frames, and 'JSON'. Targeted at 'CouchDB' v2 or
    greater.",2018-01-03,Scott Chamberlain,https://github.com/ropensci/sofa,TRUE,https://github.com/ropensci/sofa,6814,29,1549637959
soilcarbon,"A tool for importing, visualizing, and analyzing the soil carbon database created by the Powell Center working group.",2017-08-04,J Grey Monroe,https://powellcenter-soilcarbon.github.io/soilcarbon/,TRUE,https://github.com/powellcenter-soilcarbon/soilcarbon,3534,12,1535021537
soilDB,A collection of functions for reading data from USDA-NCSS soil databases.,2019-01-15,Dylan Beaudette,http://ncss-tech.github.io/AQP/,TRUE,https://github.com/ncss-tech/soildb,28071,12,1553276765
soiltexture,"""The Soil Texture Wizard"" is a set of R functions designed to produce texture triangles (also called texture plots, texture diagrams, texture ternary plots), classify and transform soil textures data. These functions virtually allows to plot any soil texture triangle (classification) into any triangle geometry (isosceles, right-angled triangles, etc.). This set of function is expected to be useful to people using soil textures data from different soil texture classification or different particle size systems. Many (> 15) texture triangles from all around the world are predefined in the package. A simple text based graphical user interface is provided: soiltexture_gui().",2018-09-20,Julien Moeys,https://github.com/julienmoeys/soiltexture,TRUE,https://github.com/julienmoeys/soiltexture,28121,6,1542289169
solaR,Calculation methods of solar radiation and performance of photovoltaic systems from daily and intradaily irradiation data sources.,2016-04-16,Oscar Perpiñán Lamigueiro,http://oscarperpinan.github.io/solar/,TRUE,https://github.com/oscarperpinan/solar,20774,22,1553564439
solarius,"SOLAR is the standard software program to perform linkage and
    association mappings of the quantitative trait loci (QTLs) in pedigrees of
    arbitrary size and complexity. This package allows the user to exploit the
    variance component methods implemented in SOLAR. It automates such routine
    operations as formatting pedigree and phenotype data. It also parses the model
    output and contains summary and plotting functions for exploration of the
    results. In addition, solarius enables parallel computing of the linkage and
    association analyses, that makes the calculation of genome-wide scans more
    efficient. See <http://solar.txbiomedgenetics.org/> for more information about
    SOLAR.",2015-12-13,Andrey Ziyatdinov,https://github.com/ugcd/solarius,TRUE,https://github.com/ugcd/solarius,3958,3,1535825898
solartime,"Provide utilities to work with solar time, 
  i.e. where noon is exactly when sun culminates.
  Provides functions for computing sun position and times of sunrise and sunset.",2018-12-03,Thomas Wutzler,https://github.com/bgctw/solartime,TRUE,https://github.com/bgctw/solartime,1086,0,1544434346
solitude,"Isolation forest is anomaly detection method introduced by the paper Isolation based Anomaly Detection (Liu, Ting and Zhou <doi:10.1145/2133360.2133363>).",2018-11-14,Komala Sheshachala Srikanth,https://github.com/talegari/solitude,TRUE,https://github.com/talegari/solitude,1224,0,1543845088
solrad,"For surface energy models and estimation of solar positions and components with varying topography, time and locations. The functions calculate solar top-of-atmosphere, open, diffuse and direct components, atmospheric transmittance and diffuse factors, day length, sunrise and sunset, solar azimuth, zenith, altitude, incidence, and hour angles, earth declination angle, equation of time, and solar constant. Details about the methods and equations are explained in Seyednasrollah, Bijan, Mukesh Kumar, and Timothy E. Link. 'On the role of vegetation density on net snow cover radiation at the forest floor.' Journal of Geophysical Research: Atmospheres 118.15 (2013): 8359-8374, <doi:10.1002/jgrd.50575>.",2018-11-05,Bijan Seyednasrollah,https://github.com/bnasr/solrad/,TRUE,https://github.com/bnasr/solrad,2226,2,1541431556
solrium,"Provides a set of functions for querying and parsing data
    from 'Solr' (<http://lucene.apache.org/solr>) 'endpoints' (local and
    remote), including search, 'faceting', 'highlighting', 'stats', and
    'more like this'. In addition, some functionality is included for
    creating, deleting, and updating documents in a 'Solr' 'database'.",2018-12-13,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/solrium,TRUE,https://github.com/ropensci/solrium,70957,57,1544722807
solvebio,"R language bindings for SolveBio's API.
    SolveBio is a biomedical knowledge hub that enables life science
    organizations to collect and harmonize the complex, disparate
    ""multi-omic"" data essential for today's R&D and BI needs.
    For more information, visit <https://www.solvebio.com>.",2018-10-25,David Caplan,https://github.com/solvebio/solvebio-r,TRUE,https://github.com/solvebio/solvebio-r,6649,1,1540469930
soma,"This package provides an R implementation of the Self-Organising Migrating Algorithm, a general-purpose, stochastic optimisation algorithm. The approach is similar to that of genetic algorithms, although it is based on the idea of a series of ``migrations'' by a fixed set of individuals, rather than the development of successive generations. It can be applied to any cost-minimisation problem with a bounded parameter space, and is robust to local minima.",2014-11-25,Jon Clayden; based on the work of Ivan Zelinka,"https://github.com/jonclayden/soma/,
http://www.ft.utb.cz/people/zelinka/soma/",TRUE,https://github.com/jonclayden/soma,58827,4,1532684138
SOMbrero,"The stochastic (also called on-line) version of the Self-Organising
             Map (SOM) algorithm is provided. Different versions of the
             algorithm are implemented, for numeric and relational data and for
             contingency tables as described, respectively, in Kohonen (2001)
             <isbn:3-540-67921-9>, Olteanu & Villa-Vialaneix (2005)
             <doi:10.1016/j.neucom.2013.11.047> and Cottrell et al (2004)
             <doi:10.1016/j.neunet.2004.07.010>. The package also contains many
             plotting features (to help the user interpret the results) and a
             graphical user interface based on 'shiny'.",2019-03-07,Nathalie Vialaneix,NA,TRUE,https://github.com/tuxette/sombrero,13483,10,1551976044
SongEvo,"Simulates the cultural evolution of quantitative traits of bird song. 'SongEvo' is an individual- (agent-) based model. 'SongEvo' is spatially-explicit and can be parameterized with, and tested against, measured song data. Functions are available for model implementation, sensitivity analyses, parameter optimization, model validation, and hypothesis testing. ",2019-03-05,Raymond Danner,NA,TRUE,https://github.com/raydanner/songevo,264,2,1551555910
sotkanet,"Access data from the sotkanet open data portal
        <https://www.sotkanet.fi/sotkanet/fi/index>.",2017-05-16,Leo Lahti,https://github.com/ropengov/sotkanet,TRUE,https://github.com/ropengov/sotkanet,11403,5,1531412762
soundecology,Functions to calculate indices for soundscape ecology and other ecology research that uses audio recordings.,2018-03-05,Luis J. Villanueva-Rivera and Bryan C. Pijanowski,http://ljvillanueva.github.io/soundecology/,TRUE,https://github.com/ljvillanueva/soundecology,16653,13,1550498759
SoundexBR,"The SoundexBR package provides an algorithm for decoding names
    into phonetic codes, as pronounced in Portuguese. The goal is for
    homophones to be encoded to the same representation so that they can be
    matched despite minor differences in spelling. The algorithm mainly encodes
    consonants; a vowel will not be encoded unless it is the first letter. The
    soundex code resultant consists of a four digits long string composed by
    one letter followed by three numerical digits: the letter is the first
    letter of the name, and the digits encode the remaining consonants.",2015-07-14,Daniel Marcelino,NA,TRUE,https://github.com/danielmarcelino/soundexbr,9596,8,1554561391
sourcetools,"Tools for the reading and tokenization of R code. The
    'sourcetools' package provides both an R and C++ interface for the tokenization
    of R code, and helpers for interacting with the tokenized representation of R
    code.",2018-04-25,Kevin Ushey,NA,TRUE,https://github.com/kevinushey/sourcetools,4905611,65,1534136113
sp,"Classes and methods for spatial
  data; the classes document where the spatial location information
  resides, for 2D or 3D data. Utility functions are provided, e.g. for
  plotting data as maps, spatial selection, as well as methods for
  retrieving coordinates, for subsetting, print, summary, etc.",2018-06-05,Edzer Pebesma,https://github.com/edzer/sp/ https://edzer.github.io/sp/,TRUE,https://github.com/edzer/sp,5199559,78,1553187739
spaa,"Miscellaneous functions for analysing species association
        and niche overlap.",2016-06-09,Jinlong Zhang,https://github.com/helixcn/spaa,TRUE,https://github.com/helixcn/spaa,25660,1,1526547992
spacetime,"Classes and methods for spatio-temporal data, including space-time regular lattices, sparse lattices, irregular data, and trajectories; utility functions for plotting data as map sequences (lattice or animation) or multiple time series; methods for spatial and temporal selection and subsetting, as well as for spatial/temporal/spatio-temporal matching or aggregation, retrieving coordinates, print, summary, etc.",2018-07-17,Edzer Pebesma  (<https://orcid.org/0000-0001-8049-7069>),http://github.com/edzer/spacetime,TRUE,https://github.com/edzer/spacetime,451565,35,1554474392
spacyr,"An R wrapper to the 'Python' 'spaCy' 'NLP' library,
    from <http://spacy.io>.",2018-12-15,Kenneth Benoit,https://spacyr.quanteda.io,TRUE,https://github.com/quanteda/spacyr,117659,131,1554418338
spAddins,"A set of RStudio addins that are designed to be used in
             combination with user-defined RStudio keyboard shortcuts. These
             addins either:
             1) insert text at a cursor position (e.g. insert
             operators %>%, <<-, %$%, etc.),
             2) replace symbols in selected pieces of text (e.g., convert
             backslashes to forward slashes which results in stings like
             ""c:\data\"" converted into ""c:/data/"") or
             3) enclose text with special symbols (e.g., converts ""bold"" into
             ""**bold**"") which is convenient for editing R Markdown files.",2017-12-14,Vilmantas Gegzna,https://github.com/GegznaV/spAddins,TRUE,https://github.com/gegznav/spaddins,5638,6,1551284271
SpaDES,"Metapackage for implementing a variety of event-based models, with
    a focus on spatially explicit models. These include raster-based,
    event-based, and agent-based models. The core simulation components
    (provided by 'SpaDES.core') are built upon a discrete event simulation (DES;
    see Matloff (2011) ch 7.8.3 <https://nostarch.com/artofr.htm>)
    framework that facilitates modularity, and easily enables the user to
    include additional functionality by running user-built simulation modules
    (see also 'SpaDES.tools'). Included are numerous tools to visualize rasters
    and other maps (via 'quickPlot'), and caching methods for reproducible
    simulations (via 'reproducible'). Additional functionality is provided by
    the 'SpaDES.addins' and 'SpaDES.shiny' packages.",2019-02-03,Alex M Chubaty  (<https://orcid.org/0000-0001-7146-8135>),"http://spades.predictiveecology.org,
https://github.com/PredictiveEcology/SpaDES",TRUE,https://github.com/predictiveecology/spades,13239,27,1549211565
SpaDES.addins,"Provides 'RStudio' addins for 'SpaDES' packages and 'SpaDES' module
    development. See '?SpaDES.addins' for an overview of the tools provided.",2019-02-03,Alex M Chubaty  (<https://orcid.org/0000-0001-7146-8135>),"http://spades-addins.predictiveecology.org/,
https://github.com/PredictiveEcology/SpaDES.addins",TRUE,https://github.com/predictiveecology/spades.addins,6011,0,1549222337
SpaDES.core,"Provide the core discrete event simulation (DES) framework for
    implementing spatially explicit simulation models. The core DES components 
    facilitate modularity, and easily enable the user to include additional
    functionality by running user-built simulation modules. Now includes (experimental)
    conditional scheduling.",2019-03-19,Alex M Chubaty  (<https://orcid.org/0000-0001-7146-8135>),"http://spades-core.predictiveecology.org/,
https://github.com/PredictiveEcology/SpaDES.core",TRUE,https://github.com/predictiveecology/spades.core,11001,4,1552962689
SpaDES.tools,"Provides GIS and map utilities, plus additional modeling tools for
    developing cellular automata, dynamic raster models,  and agent based models
    in 'SpaDES'.
    Included are various methods for spatial spreading, spatial agents, GIS
    operations, random map generation, and others.
    See '?SpaDES.tools' for an categorized overview of these additional tools.",2019-03-19,Alex M Chubaty  (<https://orcid.org/0000-0001-7146-8135>),"http://spades-tools.predictiveecology.org,
https://github.com/PredictiveEcology/SpaDES.tools",TRUE,https://github.com/predictiveecology/spades.tools,10580,1,1553010792
spaero,"Implements methods for anticipating the emergence and eradication
    of infectious diseases from surveillance time series. Also provides support
    for computational experiments testing the performance of such methods.",2018-12-16,Eamon ODea,NA,TRUE,https://github.com/e3bo/spaero,5721,0,1545071800
spant,"Tools for reading, visualising and processing Magnetic Resonance
    Spectroscopy data.",2018-11-05,Martin Wilson,NA,TRUE,https://github.com/martin3141/spant,5340,2,1554130964
spark.sas7bdat,Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark' from R. 'Apache Spark' is an open source cluster computing framework available at <http://spark.apache.org>. This R package uses the 'spark-sas7bdat' 'Spark' package (<https://spark-packages.org/package/saurfang/spark-sas7bdat>) to import and process 'SAS' data in parallel using 'Spark'. Hereby allowing to execute 'dplyr' statements in parallel on top of 'SAS' data.,2016-12-27,Jan Wijffels,https://github.com/bnosac/spark.sas7bdat,TRUE,https://github.com/bnosac/spark.sas7bdat,4959,18,1532955011
sparkavro,"Load Avro Files into 'Apache Spark' using 'sparklyr'. This
    allows to read files from 'Apache Avro' <https://avro.apache.org/>.",2018-11-10,Aki Ariga,NA,TRUE,https://github.com/chezou/sparkavro,18103,6,1541846241
sparkbq,"A 'sparklyr' extension package providing an integration with Google 'BigQuery'.
  It supports direct import/export where records are directly streamed from/to 'BigQuery'.
  In addition, data may be imported/exported via intermediate data extracts on Google 'Cloud Storage'.",2018-08-02,Martin Studer,"http://www.mirai-solutions.com,
https://github.com/miraisolutions/sparkbq",TRUE,https://github.com/miraisolutions/sparkbq,1914,9,1533631821
sparklyr,"R interface to Apache Spark, a fast and general engine for big data
    processing, see <http://spark.apache.org>. This package supports connecting to
    local and remote Apache Spark clusters, provides a 'dplyr' compatible back-end,
    and provides an interface to Spark's built-in machine learning algorithms.",2019-02-25,Javier Luraschi,http://spark.rstudio.com,TRUE,https://github.com/rstudio/sparklyr,998555,631,1554474768
sparklyr.nested,A 'sparklyr' extension adding the capability to work easily with nested data.,2018-11-14,Matt Pollock,NA,TRUE,https://github.com/mitre/sparklyr.nested,2650,21,1545416484
sparkTable,Create sparklines and graphical tables for documents and websites.,2016-12-13,Alexander Kowarik,https://github.com/alexkowa/sparkTable,TRUE,https://github.com/alexkowa/sparktable,20837,44,1530617208
sparr,"Provides functions to estimate kernel-smoothed spatial and spatio-temporal densities and relative risk functions, and perform subsequent inference. Methodological details can be found in the accompanying tutorial: Davies et al. (2018) <DOI:10.1002/sim.7577>.",2018-09-16,Tilman M. Davies,"http://tilmandavies.github.io/sparr,
https://github.com/tilmandavies/sparr",TRUE,https://github.com/tilmandavies/sparr,33935,1,1543956887
sparseEigen,"Computation of sparse eigenvectors of a matrix (aka sparse PCA)
    with running time 2-3 orders of magnitude lower than existing methods and
    better final performance in terms of recovery of sparsity pattern and 
    estimation of numerical values. Can handle covariance matrices as well as 
    data matrices with real or complex-valued entries. Different levels of 
    sparsity can be specified for each individual ordered eigenvector and the 
    method is robust in parameter selection. See vignette for a detailed 
    documentation and comparison, with several illustrative examples. 
    The package is based on the paper:
    K. Benidis, Y. Sun, P. Babu, and D. P. Palomar (2016). ""Orthogonal Sparse PCA 
    and Covariance Estimation via Procrustes Reformulation,"" IEEE Transactions on 
    Signal Processing <doi:10.1109/TSP.2016.2605073>.",2017-12-21,Daniel P. Palomar,"https://github.com/dppalomar/sparseEigen,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2016.2605073",TRUE,https://github.com/dppalomar/sparseeigen,2243,5,1545491678
sparseIndexTracking,"Computation of sparse portfolios for financial index tracking, i.e., joint
    selection of a subset of the assets that compose the index and computation 
    of their relative weights (capital allocation). The level of sparsity of the 
    portfolios, i.e., the number of selected assets, is controlled through a 
    regularization parameter. Different tracking measures are available, namely, 
    the empirical tracking error (ETE), downside risk (DR), Huber empirical 
    tracking error (HETE), and Huber downside risk (HDR). See vignette for a 
    detailed documentation and comparison, with several illustrative examples.
    The package is based on the paper:
    K. Benidis, Y. Feng, and D. P. Palomar, ""Sparse Portfolios for High-Dimensional 
    Financial Index Tracking,"" IEEE Trans. on Signal Processing, vol. 66, no. 1, 
    pp. 155-170, Jan. 2018. <doi:10.1109/TSP.2017.2762286>.",2018-05-17,Daniel P. Palomar,"https://github.com/dppalomar/sparseIndexTracking,
https://www.danielppalomar.com,
https://doi.org/10.1109/TSP.2017.2762286",TRUE,https://github.com/dppalomar/sparseindextracking,1760,13,1545491652
sparsepca,"Sparse principal component analysis (SPCA) attempts to find sparse weight vectors (loadings), i.e., a weight vector with only a few 'active' (nonzero) values. This approach provides better interpretability for the principal components in high-dimensional data settings. This is, because the principal components are formed as a linear combination of only a few of the original variables. This package provides efficient routines to compute SPCA. Specifically, a variable projection solver is used to compute the sparse solution. In addition, a fast randomized accelerated SPCA routine and a robust SPCA routine is provided. Robust SPCA allows to capture grossly corrupted entries in the data. The methods are discussed in detail by N. Benjamin Erichson et al. (2018) <arXiv:1804.00341>. ",2018-04-11,N. Benjamin Erichson,https://github.com/erichson/spca,TRUE,https://github.com/erichson/spca,2480,24,1523132100
sparsepp,"Provides interface to 'sparsepp' - fast, memory efficient hash map. 
    It is derived from Google's excellent 'sparsehash' implementation.
    We believe 'sparsepp' provides an unparalleled combination of performance and memory usage, 
    and will outperform your compiler's unordered_map on both counts. 
    Only Google's 'dense_hash_map' is consistently faster, at the cost of much greater 
    memory usage (especially when the final size of the map is not known in advance).",2018-09-22,Dmitriy Selivanov,"https://github.com/greg7mdp/sparsepp,
https://github.com/dselivanov/r-sparsepp",TRUE,https://github.com/greg7mdp/sparsepp,48701,868,1554076464
sparsevar,"A wrapper for sparse VAR/VECM time series models estimation
             using penalties like ENET, SCAD and MCP.",2016-11-07,Simone Vazzoler,http://github.com/svazzole/sparsevar,TRUE,https://github.com/svazzole/sparsevar,8314,4,1543144147
spartan,"Computer simulations are becoming a popular technique to use in attempts to further our understanding of complex systems. 'spartan', first described in our 2013 publication in PLoS Computational Biology, provided code for four techniques described in available literature which aid the analysis of simulation results, at both single and multiple timepoints in the simulation run. The first technique addresses aleatory uncertainty in the system caused through inherent stochasticity, and determines the number of replicate runs necessary to generate a representative result. The second examines how robust a simulation is to parameter perturbation, through the use of a one-at-a-time parameter analysis technique. Thirdly, a latin hypercube based sensitivity analysis technique is included which can elucidate non-linear effects between parameters and indicate implications of epistemic uncertainty with reference to the system being modelled. Finally, a further sensitivity analysis technique, the extended Fourier Amplitude Sampling Test (eFAST) has been included to partition the variance in simulation results between input parameters, to determine the parameters which have a significant effect on simulation behaviour. Version 1.3 added support for Netlogo simulations, aiding simulation developers who use Netlogo to build their simulations perform the same analyses. Version 2.0 added the ability to read all simulations in from a single CSV file in addition to the prescribed folder structure in previous versions. Version 3.0 offers significant additional functionality that permits the creation of emulations of simulation results, derived using the same sampling techniques in the global sensitivity analysis techniques, and the generation of combinations of these machine learning algorithms to one create one predictive tool, more commonly known as an ensemble model. Version 3.0 also improved the standard of the graphs produced in the original sensitivity analysis techniques, and introduced a polar plot to examine parameter sensitivity.",2018-11-19,Kieran Alden,http://www.york.ac.uk/ycil/software/spartan,TRUE,https://github.com/kalden/spartan,15344,0,1551098176
SpatialEpi,Methods and data for cluster detection and disease mapping.,2018-06-02,Albert Y. Kim,https://github.com/rudeboybert/SpatialEpi,TRUE,https://github.com/rudeboybert/spatialepi,58151,7,1527949626
SpatialEpiApp,"Runs a Shiny web application that allows to visualize spatial and spatio-temporal disease data, estimate disease risk and detect clusters. The application allows to fit Bayesian disease models to obtain risk estimates and their uncertainty by using the 'R-INLA' package, <http://www.r-inla.org>, and to detect clusters by using the scan statistics implemented in 'SaTScan', <https://www.satscan.org>. The application allows user interaction and creates interactive visualizations such as maps supporting padding and zooming and tables that allow for filtering. It also enables the generation of reports containing the analyses performed.",2017-08-28,Paula Moraga,https://github.com/Paula-Moraga/SpatialEpiApp,TRUE,https://github.com/paula-moraga/spatialepiapp,5254,7,1547411821
SpatialGraph,"Provision of the S4 SpatialGraph class built on top of objects provided by 'igraph' and 'sp' packages, and associated utilities. See the documentation of the SpatialGraph-class within this package for further description. An example of how from a few points one can arrive to a SpatialGraph is provided in the function sl2sg().  ",2018-11-27,Javier Garcia-Pintado,https://github.com/garciapintado/SpatialGraph,TRUE,https://github.com/garciapintado/spatialgraph,1252,3,1543573296
SpatialPosition,"Computes spatial position models: Stewart potentials, Reilly
    catchment areas, Huff catchment areas.",2017-09-06,Timothée Giraud,https://github.com/Groupe-ElementR/SpatialPosition,TRUE,https://github.com/groupe-elementr/spatialposition,15953,23,1553771208
spatialreg,"A collection of all the estimation functions for spatial cross-sectional models (on lattice/areal data using spatial weights matrices) contained up to now in 'spdep', 'sphet' and 'spse'. These model fitting functions include maximum likelihood methods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973, ISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially described by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The models are further described by 'Anselin' (1988) <doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and spatial general method of moment models initially proposed by 'Kelejian' and 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999) <doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC fitting methods proposed by 'LeSage' and 'Pace' (2009) <doi:10.1201/9781420064254> are implemented for the family of cross-sectional spatial regression models. Methods for fitting the log determinant term in maximum likelihood and MCMC fitting are compared by 'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting methods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both of these articles include extensive lists of references. 'spatialreg' >= 1.1-* correspond to 'spdep' >= 1.1-1, in which the model fitting functions are deprecated and pass through to 'spatialreg', but will mask those in 'spatialreg'. From versions 1.2-*, the functions will be made defunct in 'spdep'.",2019-04-01,Roger Bivand  (<https://orcid.org/0000-0003-2392-6140>),"https://github.com/r-spatial/spatialreg/,
https://r-spatial.github.io/spatialreg/",TRUE,https://github.com/r-spatial/spatialreg,35,4,1554275056
spatialwarnings,Tools to compute and assess significance of early-warnings signals (EWS) of ecosystem degradation on raster data sets. EWS are metrics derived from the observed spatial structure of an ecosystem -- e.g. spatial autocorrelation -- that increase before an ecosystem undergoes a non-linear transition (Genin et al. (2018) <doi:10.1111/2041-210X.13058>).,2018-12-20,Alain Danet,https://github.com/spatial-ews/spatialwarnings,TRUE,https://github.com/spatial-ews/spatialwarnings,3175,4,1548001264
spatsoc,"Detects spatial and temporal groups in GPS relocations. 
    It can be used to convert GPS relocations to 
    gambit-of-the-group format to build proximity-based social networks. 
    In addition, the randomizations function provides data-stream 
    randomization methods suitable for GPS data. ",2019-04-05,Alec L. Robitaille  (<https://orcid.org/0000-0002-4706-1762>),"https://spatsoc.gitlab.io, https://github.com/ropensci/spatsoc",TRUE,https://github.com/ropensci/spatsoc,1920,14,1554507401
spatstat,"Comprehensive open-source toolbox for analysing Spatial Point Patterns. Focused mainly on two-dimensional point patterns, including multitype/marked points, in any spatial region. Also supports three-dimensional point patterns, space-time point patterns in any number of dimensions, point patterns on a linear network, and patterns of other geometrical objects. Supports spatial covariate data such as pixel images. 
	Contains over 2000 functions for plotting spatial data, exploratory data analysis, model-fitting, simulation, spatial sampling, model diagnostics, and formal inference. 
	Data types include point patterns, line segment patterns, spatial windows, pixel images, tessellations, and linear networks. 
	Exploratory methods include quadrat counts, K-functions and their simulation envelopes, nearest neighbour distance and empty space statistics, Fry plots, pair correlation function, kernel smoothed intensity, relative risk estimation with cross-validated bandwidth selection, mark correlation functions, segregation indices, mark dependence diagnostics, and kernel estimates of covariate effects. Formal hypothesis tests of random pattern (chi-squared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.
	Parametric models can be fitted to point pattern data using the functions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs and Cox point processes, Neyman-Scott cluster processes, and determinantal point processes. Models may involve dependence on covariates, inter-point interaction, cluster formation and dependence on marks. Models are fitted by maximum likelihood, logistic regression, minimum contrast, and composite likelihood methods. 
	A model can be fitted to a list of point patterns (replicated point pattern data) using the function mppm(). The model can include random effects and fixed effects depending on the experimental design, in addition to all the features listed above.
	Fitted point process models can be simulated, automatically. Formal hypothesis tests of a fitted model are supported (likelihood ratio test, analysis of deviance, Monte Carlo tests) along with basic tools for model selection (stepwise(), AIC()) and variable selection (sdr). Tools for validating the fitted model include simulation envelopes, residuals, residual plots and Q-Q plots, leverage and influence diagnostics, partial residuals, and added variable plots.",2019-03-22,Adrian Baddeley <Adrian.Baddeley@curtin.edu.au>,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat,609789,81,1554438107
spatstat.data,Contains all the datasets for the 'spatstat' package.,2018-10-04,Adrian Baddeley,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat.data,219648,4,1538392651
spatstat.utils,"Contains utility functions for the 'spatstat' package
             which may also be useful for other purposes.",2018-10-31,Adrian Baddeley,http://www.spatstat.org,TRUE,https://github.com/spatstat/spatstat.utils,294715,3,1551774044
spbabel,"Tools to convert from specific formats to more general forms of 
    spatial data. Using tables to store the actual entities present in spatial
    data provides flexibility, and the functions here deliberately 
    minimize the level of interpretation applied, leaving that for specific 
    applications. Includes support for simple features,  round-trip for 'Spatial' classes and long-form 
    tables, analogous to 'ggplot2::fortify'. There is also a more 'normal form' representation
    that decomposes simple features and their kin to tables of objects, parts, and unique coordinates. ",2019-01-08,Michael D. Sumner,https://mdsumner.github.io/spbabel,TRUE,https://github.com/mdsumner/spbabel,16326,19,1546992234
spData,"Diverse spatial datasets for demonstrating, benchmarking and teaching spatial data analysis. 
    It includes R data of class sf (defined by the package 'sf'), Spatial ('sp'), and nb ('spdep').
    Unlike other spatial data packages such as 'rnaturalearth' and 'maps', 
    it also contains data stored in a range of file formats including GeoJSON, ESRI Shapefile and GeoPackage. 
    Some of the datasets are designed to illustrate specific analysis techniques.
    cycle_hire() and cycle_hire_osm(), for example, is designed to illustrate point pattern analysis techniques.",2019-01-07,Roger Bivand (<https://orcid.org/0000-0003-2392-6140>),https://github.com/Nowosad/spData,TRUE,https://github.com/nowosad/spdata,709573,33,1554482415
spdep,"A collection of functions to create spatial weights matrix
  objects from polygon 'contiguities', from point patterns by distance and
  tessellations, for summarizing these objects, and for permitting their
  use in spatial data analysis, including regional aggregation by minimum
  spanning tree; a collection of tests for spatial 'autocorrelation',
  including global 'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord'
  (1973, ISBN: 0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel'
  general cross product statistic, Empirical Bayes estimates and
  'Assunção/Reis' (1999) <doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO;2-I> Index, 'Getis/Ord' G ('Getis' and 'Ord' 1992)
  <doi:10.1111/j.1538-4632.1992.tb00261.x> and multicoloured
  join count statistics, 'APLE' ('Li 'et al.' )
  <doi:10.1111/j.1538-4632.2007.00708.x>, local 'Moran's I'
  ('Anselin' 1995) <doi:10.1111/j.1538-4632.1995.tb00338.x> and
  'Getis/Ord' G ('Ord' and 'Getis' 1995)
  <doi:10.1111/j.1538-4632.1995.tb00912.x>,
  'saddlepoint' approximations ('Tiefelsdorf' 2002)
  <doi:10.1111/j.1538-4632.2002.tb01084.x> and exact tests
  for global and local 'Moran's I' ('Bivand et al.' 2009)
  <doi:10.1016/j.csda.2008.07.021> and 'LOSH' local indicators
  of spatial heteroscedasticity ('Ord' and 'Getis')
  <doi:10.1007/s00168-011-0492-y>. The implementation of most of
  the measures is described in 'Bivand' and 'Wong' (2018)
  <doi:10.1007/s11749-018-0599-x>.
  'spdep' >= 1.1-1 corresponds to 'spatialreg' >= 1.1-1, in which the model
  fitting functions are deprecated and pass through to 'spatialreg', but
  will mask those in 'spatialreg'. From versions 1.2-1, the functions will
  be made defunct in 'spdep'.
  For now 'spatialreg' only has functions from 'spdep', where they are shown
  as deprecated. 'spatialreg' only loads the namespace of 'spdep'; if you
  attach 'spdep', the same functions in the other package will be masked.
  Some feed through adequately, others do not.",2019-04-05,Roger Bivand  (<https://orcid.org/0000-0003-2392-6140>),https://github.com/r-spatial/spdep/,TRUE,https://github.com/r-spatial/spdep,1075618,44,1554484209
spdplyr,"Methods for 'dplyr' verbs for 'sp' 'Spatial' classes. The basic 
    verbs that modify data attributes, remove or re-arrange rows are supported
    and provide complete 'Spatial' analogues of the input data. The group by
    and summarize work flow returns a non-topological spatial union. There is 
    limited support for joins, with left and inner to copy attributes from 
    another table. ",2019-02-04,Michael D. Sumner,https://github.com/mdsumner/spdplyr,TRUE,https://github.com/mdsumner/spdplyr,10881,31,1549250332
spduration,"An implementation of split-population duration regression models. 
    Unlike regular duration models, split-population duration models are
    mixture models that accommodate the presence of a sub-population that is 
    not at risk for failure, e.g. cancer patients who have been cured by 
    treatment. This package implements Weibull and Loglogistic forms for the 
    duration component, and focuses on data with time-varying covariates. 
    These models were originally formulated in Boag (1949) 
    <http://www.jstor.org/stable/2983694> and Berkson and Gage (1952) 
    <http://www.jstor.org/stable/2281318>, and extended in Schmidt and Witte 
    (1989) <doi:10.1016/0304-4076(89)90034-1>.",2018-05-04,Andreas Beger  (<https://orcid.org/0000-0003-1883-3169>),"https://github.com/andybega/spduration,
https://andybeger.com/spduration",TRUE,https://github.com/andybega/spduration,8427,4,1545402534
specklestar,A set of functions for obtaining positional parameters and magnitude difference between components of binary and multiple stellar systems from series of speckle images.,2018-02-08,Denis Rastegaev,https://drastega.github.io/docs/specklestar_vignette.html,TRUE,https://github.com/drastega/specklestar,2083,0,1548162029
spectacles,"Stores and eases the manipulation of spectra and associated data,
    with dedicated classes for spatial and soil-related data.",2017-12-22,Pierre Roudier,https://github.com/pierreroudier/spectacles/,TRUE,https://github.com/pierreroudier/spectacles,2727,3,1543202539
spectrolab,"Input/Output, processing and visualization of spectra taken with different spectrometers, including SVC (Spectra Vista), ASD and PSR (Spectral Evolution). Implements an S3 class 'spectra' that other packages can build on. Provides methods to access, plot, manipulate, splice sensor overlap, vector normalize and smooth spectra.",2018-10-28,Jose Eduardo Meireles,https://github.com/meireles/spectrolab,TRUE,https://github.com/meireles/spectrolab,3885,3,1540737352
spef,"Functions for fitting semiparametric regression models for
        panel count survival data. An overview of the package can be found 
        in Wang and Yan (2011) <doi:10.1016/j.cmpb.2010.10.005> and
	Chiou et al. (2018) <doi:10.1111/insr.12271>.",2018-08-01,Sy Han (Steven) Chiou,http://github.com/stc04003/spef,TRUE,https://github.com/stc04003/spef,7072,0,1544667114
spemd,"This implementation of the Empirical Mode Decomposition (EMD) works in 2 dimensions simultaneously, and 
    can be applied on spatial data. It can handle both gridded or un-gridded datasets.",2018-07-01,Pierre Roudier,https://github.com/pierreroudier/spemd,TRUE,https://github.com/pierreroudier/spemd,1576,0,1530592576
sperrorest,"Implements spatial error estimation and 
   permutation-based variable importance measures for predictive models using 
   spatial cross-validation and spatial block bootstrap.",2018-03-27,Alexander Brenning  (<https://orcid.org/0000-0001-6640-679X>),NA,TRUE,https://github.com/pat-s/sperrorest,18225,9,1551192403
spex,"Functions to produce a fully fledged 'geo-spatial' object extent as a
    'SpatialPolygonsDataFrame'. Also included are functions to generate polygons
    from raster data using 'quadmesh' techniques, a round number buffered extent, and
    general spatial-extent and 'raster-like' extent helpers missing from the originating
    packages. Some latitude-based tools for polar maps are included. ",2018-06-07,Michael D. Sumner,https://mdsumner.github.io/spex/,TRUE,https://github.com/mdsumner/spex,8148,17,1528209042
spFSR,"An implementation of feature selection and ranking via simultaneous perturbation
    stochastic approximation (SPSA-FSR) based on works by V. Aksakalli and M. Malekipirbazari 
    (2015) <arXiv:1508.07630> and Zeren D. Yenice and et al. (2018) <arXiv:1804.05589>.
    The SPSA-FSR algorithm searches for a locally optimal set of features that yield the best 
    predictive performance using a specified error measure such as mean squared error (for 
    regression problems) and accuracy rate (for classification problems). This package requires 
    an object of class 'task' and an object of class 'Learner' from the 'mlr' package.",2018-05-11,Vural Aksakalli,"https://www.featureranking.com/, https://arxiv.org/abs/1804.05589",TRUE,https://github.com/yongkai17/spfsr,2102,0,1538482446
spikeSlabGAM,"Bayesian variable selection, model choice, and regularized
    estimation for (spatial) generalized additive mixed regression models
    via stochastic search variable selection with spike-and-slab priors.",2018-09-17,Fabian Scheipl,https://github.com/fabian-s/spikeSlabGAM,TRUE,https://github.com/fabian-s/spikeslabgam,19046,5,1554310059
spind,"Functions for spatial methods based on generalized estimating equations (GEE) and
  wavelet-revised methods (WRM), functions for scaling by wavelet multiresolution regression (WMRR),
  conducting multi-model inference, and stepwise model selection. Further, contains functions 
  for spatially corrected model accuracy measures.",2018-07-20,Gudrun Carl,https://github.com/levisc8/spind,TRUE,https://github.com/levisc8/spind,7934,1,1544566567
splines2,"Constructs B-splines and its integral, monotone splines
    (M-splines) and its integral (I-splines), convex splines (C-splines),
    and their derivatives of given order. Piecewise constant basis is
    allowed for B-splines and M-splines. See
    De Boor (1978) <doi:10.1002/zamm.19800600129>,
    Ramsay (1988) <doi:10.1214/ss/1177012761>, and
    Meyer (2008) <doi:10.1214/08-AOAS167> for more information.",2018-06-14,Wenjie Wang,https://github.com/wenjie2wang/splines2,TRUE,https://github.com/wenjie2wang/splines2,38396,3,1529078726
splinetree,Builds regression trees and random forests for longitudinal or functional data using a spline projection method. Implements and extends the work of Yu and Lambert (1999) <doi:10.1080/10618600.1999.10474847>. This method allows trees and forests to be built while considering either level and shape or only shape of response trajectories. ,2019-01-07,Anna Neufeld,https://github.com/anna-neufeld/splinetree,TRUE,https://github.com/anna-neufeld/splinetree,1305,1,1547015165
splithalf,"A series of functions to calculate the split 
    half reliability of RT based tasks. The core function performs a Monte Carlo
    procedure to process a user defined number of random splits in order to 
    provide a better reliability estimate. The current functions target the dot-
    probe task, however, can be modified for other tasks.",2018-03-17,Sam Parsons,http://github.com/sdparsons/splithalf,TRUE,https://github.com/sdparsons/splithalf,3947,2,1554471497
splitstackshape,"Online data collection tools like Google Forms often export
    multiple-response questions with data concatenated in cells. The
    concat.split (cSplit) family of functions splits such data into separate 
    cells. The package also includes functions to stack groups of columns and 
    to reshape wide data, even when the data are ""unbalanced""---something 
    which reshape (from base R) does not handle, and which melt and dcast from 
    reshape2 do not easily handle.",2018-07-23,Ananda Mahto,http://github.com/mrdwab/splitstackshape,TRUE,https://github.com/mrdwab/splitstackshape,145933,36,1532400739
splot,"Automates common plotting tasks to ease data exploration.
  Makes density plots (potentially overlaid on histograms),
  scatter plots with prediction lines, or bar or line plots with error bars.
  For each type, y, or x and y variables can be plotted at levels of other variables,
  all with minimal specification.",2019-01-18,Micah Iserman,https://miserman.github.io/splot,TRUE,https://github.com/miserman/splot,4097,0,1553725266
spMaps,"Build custom Europe SpatialPolygonsDataFrame, if you don't know what is a SpatialPolygonsDataFrame see SpatialPolygons() in 'sp', by example for mapLayout() in 'antaresViz'. Antares is a powerful software developed by RTE to simulate and study electric power systems (more information about 'Antares' here: <https://antares.rte-france.com>).",2018-05-22,Jalal-Edine ZAWAM,https://github.com/rte-antares-rpackage/antaresMaps,TRUE,https://github.com/rte-antares-rpackage/antaresmaps,3787,0,1527090383
spocc,"A programmatic interface to many species occurrence data sources,
    including Global Biodiversity Information Facility ('GBIF'), 'USGSs'
    Biodiversity Information Serving Our Nation ('BISON'), 'iNaturalist',
    Berkeley 'Ecoinformatics' Engine, 'eBird', Integrated Digitized
    'Biocollections' ('iDigBio'), 'VertNet', Ocean 'Biogeographic' Information
    System ('OBIS'), and Atlas of Living Australia ('ALA'). Includes
    functionality for retrieving species occurrence data, and combining
    those data.",2018-11-15,Scott Chamberlain  (<https://orcid.org/0000-0003-1444-9135>),https://github.com/ropensci/spocc,TRUE,https://github.com/ropensci/spocc,38039,64,1548712673
spongebob,"Convert text (and text in R objects) to Mocking SpongeBob case 
             <https://knowyourmeme.com/memes/mocking-spongebob> and show them 
             off in fun ways. 
             CoNVErT TexT (AnD TeXt In r ObJeCtS) To MOCkINg SpoNgebOb CAsE
             <https://knowyourmeme.com/memes/mocking-spongebob> aND shOw tHem 
             OFf IN Fun WayS. ",2019-03-02,Jay Qi,https://github.com/jayqi/spongebob,TRUE,https://github.com/jayqi/spongebob,1718,2,1552877198
sport,"Calculates ratings for two-player or 
  multi-player challenges. Methods included in package such as are able to 
  estimate ratings (players strengths) and their evolution in time, also able to 
  predict output of challenge. Algorithms are based on Bayesian Approximation 
  Method, and they don't involve any matrix inversions nor likelihood estimation. 
  Parameters are updated sequentially, and computation doesn't require any 
  additional RAM to make estimation feasible. Additionally, base of the package 
  is written in C++ what makes sport computation even faster. Methods used in the 
  package refers to Mark E. Glickman (1999) <http://www.glicko.net/research/glicko.pdf>; 
  Mark E. Glickman (2001) <doi:10.1080/02664760120059219>; 
  Ruby C. Weng, Chih-Jen Lin (2011) <http://jmlr.csail.mit.edu/papers/volume12/weng11a/weng11a.pdf>; 
  W. Penny, Stephen J. Roberts (1999) <doi:10.1109/IJCNN.1999.832603>.",2019-01-07,Dawid Kałędkowski,https://github.com/gogonzo/sport,TRUE,https://github.com/gogonzo/sport,1686,3,1546900548
spotifyr,"An R wrapper for pulling data from the 'Spotify' Web API 
  <http://developer.spotify.com/web-api> in bulk. It allows you to enter 
  an artist's name and retrieve their entire discography in seconds, along 
  with audio features and lyrics from Genius Lyrics <https://www.genius.com>. 
  You can also pull song and playlist information for a given 'Spotify' user.",2019-03-12,Charlie Thompson,http://github.com/charlie86/spotifyr,TRUE,https://github.com/charlie86/spotifyr,6492,109,1553091265
spray,Sparse arrays interpreted as multivariate polynomials.,2019-03-28,Robin K. S. Hankin  (<https://orcid.org/0000-0001-5982-0415>),https://github.com/RobinHankin/spray.git,TRUE,https://github.com/robinhankin/spray,5449,0,1553828123
spsur,"A collection of functions to test and estimate Seemingly 
    Unrelated Regression (usually called SUR) models, with spatial structure, by maximum 
    likelihood and three-stage least squares. The package estimates the 
    most common spatial specifications, that is, SUR with Spatial Lag of 
    X regressors (called SUR-SLX), SUR with Spatial Lag Model (called SUR-SLM), 
    SUR with Spatial Error Model (called SUR-SEM), SUR with Spatial Durbin Model (called SUR-SDM), 
    SUR with Spatial Durbin Error Model (called SUR-SDEM), 
    SUR with Spatial Autoregressive terms and Spatial Autoregressive 
    Disturbances (called SUR-SARAR) and SUR with Spatially Independent Model (called SUR-SIM).
    The methodology of these models can be found in next references
    Mur, J., Lopez, F., and Herrera, M. (2010) <doi:10.1080/17421772.2010.516443> 
    Lopez, F.A., Mur, J., and Angulo, A. (2014) <doi:10.1007/s00168-014-0624-2>.",2019-03-23,Roman Minguez,http://github.com/rominsal/spsur,TRUE,https://github.com/rominsal/spsur,480,1,1550842110
SPUTNIK,"A set of tools for the peak filtering of mass spectrometry
  imaging data (MSI or IMS) based on spatial distribution of signal. Given a 
  region-of-interest (ROI), representing the spatial region where the informative
  signal is expected to be localized, a series of filters determine which peak
  signals are characterized by an implausible spatial distribution. The filters
  reduce the dataset dimensionality and increase its information vs noise ratio,
  improving the quality of the unsupervised analysis results, reducing data
  dimensionality and simplifying the chemical interpretation.",2018-10-25,Paolo Inglese,https://github.com/paoloinglese/SPUTNIK,TRUE,https://github.com/paoloinglese/sputnik,4339,1,1545160591
SPYvsSPY,"Data on the Spy vs. Spy comic strip of Mad magazine, created and
   written by Antonio Prohias.",2017-10-02,Steven E. Pav,https://github.com/shabbychef/SPYvsSPY,TRUE,https://github.com/shabbychef/spyvsspy,2587,6,1527313199
sqldf,"The sqldf() function is typically passed a single argument which 
	is an SQL select statement where the table names are ordinary R data 
	frame names.  sqldf() transparently sets up a database, imports the 
	data frames into that database, performs the SQL select or other
	statement and returns the result using a heuristic to determine which 
	class to assign to each column of the returned data frame.  The sqldf() 
	or read.csv.sql() functions can also be used to read filtered files 
	into R even if the original files are larger than R itself can handle.
	'RSQLite', 'RH2', 'RMySQL' and 'RPostgreSQL' backends are supported.",2017-06-28,G. Grothendieck <ggrothendieck@gmail.com>,"https://github.com/ggrothendieck/sqldf,
https://groups.google.com/group/sqldf",TRUE,https://github.com/ggrothendieck/sqldf,1354937,162,1529460480
SqlRender,"A rendering tool for parameterized SQL that also translates into
  different SQL dialects.  These dialects include 'Microsoft Sql Server', 'Oracle', 
  'PostgreSql', 'Amazon RedShift', 'Apache Impala', 'IBM Netezza', 'Google BigQuery', 'Microsoft PDW', and 'SQLite'.",2019-02-15,Martijn Schuemie,"https://ohdsi.github.io/SqlRender,
https://github.com/OHDSI/SqlRender",TRUE,https://github.com/ohdsi/sqlrender,17082,20,1552457519
sqlscore,"Provides utilities for generating SQL queries (particularly CREATE
    TABLE statements) from R model objects. The most important use case is
    generating SQL to score a generalized linear model or related model
    represented as an R object, in which case the package handles parsing
    formula operators and including the model's response function.",2019-03-17,William Brannon,https://github.com/wwbrannon/sqlscore/,TRUE,https://github.com/wwbrannon/sqlscore,6432,8,1552841313
squid,"A simulation-based tool made to help researchers to become familiar with
    multilevel variations, and to build up sampling designs for their study. 
    This tool has two main objectives: First, it provides an educational tool useful for students, 
    teachers and researchers who want to learn to use mixed-effects models. 
    Users can experience how the mixed-effects model framework can be used to understand 
    distinct biological phenomena by interactively exploring simulated multilevel data. 
    Second, it offers research opportunities to those who are already familiar with 
    mixed-effects models, as it enables the generation of data sets that users may download 
    and use for a range of simulation-based statistical analyses such as power 
    and sensitivity analysis of multilevel and multivariate data.",2016-06-20,Hassen Allegue,https://github.com/hallegue/squid,TRUE,https://github.com/hallegue/squid,4869,11,1553371541
srvyr,"Use piping, verbs like 'group_by' and 'summarize', and other
    'dplyr' inspired syntactic style when calculating summary statistics on survey
    data using functions from the 'survey' package.",2019-01-20,Greg Freedman Ellis,"http://gdfe.co/srvyr, https://github.com/gergness/srvyr",TRUE,https://github.com/gergness/srvyr,28526,66,1548185091
ss3sim,"Develops a framework for fisheries stock assessment simulation
    testing with Stock Synthesis 3 (SS3) as described in Anderson et al.
    (2014) <doi:10.1371/journal.pone.0092725>.",2017-04-19,Sean Anderson,https://github.com/ss3sim/ss3sim,TRUE,https://github.com/ss3sim/ss3sim,11889,14,1554303243
SSBtools,"Functions used by other packages from Statistics Norway are gathered. General data manipulation functions, and functions for hierarchical computations are included. The hierarchy specification functions are useful within statistical disclosure control.",2019-01-21,Øyvind Langsrud,https://github.com/statisticsnorway/SSBtools,TRUE,https://github.com/statisticsnorway/ssbtools,5303,1,1551443498
SSDM,"Allows to map species richness and endemism based on stacked
    species distribution models (SSDM). Individuals SDMs can be created using a
    single or multiple algorithms (ensemble SDMs). For each species, an SDM can
    yield a habitat suitability map, a binary map, a between-algorithm variance
    map, and can assess variable importance, algorithm accuracy, and between-
    algorithm correlation. Methods to stack individual SDMs include summing
    individual probabilities and thresholding then summing. Thresholding can be
    based on a specific evaluation metric or by drawing repeatedly from a Bernoulli
    distribution. The SSDM package also provides a user-friendly interface.",2018-01-29,Sylvain Schmitt,https://github.com/sylvainschmitt/SSDM,TRUE,https://github.com/sylvainschmitt/ssdm,7660,13,1550835489
ssdtools,"Species sensitivity distributions are cumulative probability 
  distributions which are fitted to toxicity concentrations for multiple species.
  The ssdtools package uses Maximum Likelihood to fit
  log-normal, log-logistic, log-Gumbel, Gompertz, gamma or Weibull distributions.
  Multiple distributions can be averaged using Information Criteria.
  Confidence intervals can be calculated for the fitted cumulative distribution 
  function or specific hazard concentrations (percentiles).
  Confidence intervals are currently produced by bootstrapping.",2018-11-25,Joe Thorley,https://github.com/bcgov/ssdtools,TRUE,https://github.com/bcgov/ssdtools,1372,7,1552348412
ssMousetrack,"Estimates previously compiled state-space modeling for mouse-tracking experiments using the 'rstan' package, which provides the R interface to the Stan C++ library for Bayesian estimation. ",2019-01-16,Antonio Calcagnì,NA,TRUE,https://github.com/antcalcagni/ssmousetrack,998,0,1547740367
stability,"Functionalities to perform Stability Analysis of Genotype by Environment Interaction (GEI) to identify superior and stable genotypes under diverse environments. It performs Eberhart & Russel's ANOVA (1966) (<doi:10.2135/cropsci1966.0011183X000600010011x>), Finlay and Wilkinson (1963) Joint Linear Regression (<doi:10.1071/AR9630742>), Wricke (1962, 1964) Ecovalence, Shukla's stability variance parameter (1972) (<doi:10.1038/hdy.1972.87>)  and Kang's (1991) (<doi:10.2134/agronj1991.00021962008300010037x>) simultaneous selection for high yielding and stable parameter.",2018-10-02,Muhammad Yaseen,"https://github.com/myaseen208/stability,
https://myaseen208.github.io/stability/",TRUE,https://github.com/myaseen208/stability,3604,0,1538565106
stable,"Density, distribution, quantile and hazard functions of a
    stable variate; generalized regression models for the parameters
    of a stable distribution. See the README for how to make equivalent calls
    to those of 'stabledist'. See github for Journal article.",2019-02-04,Bruce Swihart,http://www.commanster.eu/rcode.html,TRUE,https://github.com/swihart/stable,32290,3,1549305704
stabm,"An implementation of many measures for the assessment of the stability
    of feature selection. Both simple measures and measures which take into account
    the similarities between features are available, see Bommert et al. (2017) <doi:10.1155/2017/7907163>.",2019-02-22,Andrea Bommert,https://github.com/bommert/stabm,TRUE,https://github.com/bommert/stabm,275,1,1550825501
stackoverflow,"Helper functions collected from StackOverflow.com, a
    question and answer site for professional and enthusiast programmers.",2018-11-25,Neal Fultz <nfultz@gmail.com> and the StackOverflow.com community,"https://github.com/nfultz/stackoverflow http://stackoverflow.com
http://stats.stackexchange.com/",TRUE,https://github.com/nfultz/stackoverflow,7610,2,1553883797
stacomiR,"Graphical outputs and treatment for a database of fish pass
    monitoring. It is a part of the 'STACOMI' open source project developed in
    France by the French Agency for Biodiversity (AFB) institute to centralize
    data obtained by fish pass monitoring. This version is available in French and
    English. See <http://stacomir.r-forge.r-project.org/> for more information on
    'STACOMI'.     ",2019-03-06,Cedric Briand,http://stacomir.r-forge.r-project.org/,TRUE,https://github.com/marionlegrandlogrami/stacomir,3581,3,1551946784
stapler,"An implementation of Simultaneous Truth and 
    Performance Level Estimation (STAPLE) <doi:10.1109/TMI.2004.828354>.  This
    method is used when there are multiple raters for an object, typically an
    image, and this method fuses these ratings into one rating.  It uses an
    expectation-maximization method to estimate this rating and the individual
    specificity/sensitivity for each rater.",2019-03-07,John Muschelli,https://github.com/muschellij2/stapler,TRUE,https://github.com/muschellij2/stapler,2955,0,1551883569
staplr,"Provides function to manipulate PDF files: 
    fill out PDF forms;
    merge multiple PDF files into one; 
    remove selected pages from a file;
    rename multiple files in a directory;
    rotate entire pdf document; 
    rotate selected pages of a pdf file;
    Select pages from a file;
    splits single input PDF document into individual pages;
    splits single input PDF document into parts from given points.",2019-02-13,Priyanga Dilini Talagala,NA,TRUE,https://github.com/pridiltal/staplr,5656,164,1553505251
staRdom,"This is a user-friendly way to run a parallel factor (PARAFAC) analysis (Harshman, 1971) <doi:10.1121/1.1977523> on excitation emission matrix (EEM) data from dissolved organic matter (DOM) samples (Murphy et al., 2013) <doi:10.1039/c3ay41160e>. The analysis includes profound methods for model validation. Some additional functions allow the calculation of absorbance slope parameters and create beautiful plots.",2019-02-13,Matthias Pucher,https://cran.r-project.org/package=staRdom,TRUE,https://github.com/matthiaspucher/stardom,2411,2,1550073068
stars,"Reading, manipulating, writing and plotting
    spatiotemporal arrays (raster and vector data cubes) in R, using GDAL
    bindings provided by sf, and NetCDF bindings by ncmeta and RNetCDF.",2019-02-24,Edzer Pebesma  (<https://orcid.org/0000-0001-8049-7069>),https://github.com/r-spatial/stars/,TRUE,https://github.com/r-spatial/stars,71469,223,1554562175
STARTS,"
    Contains functions for estimating the STARTS model of
    Kenny and Zautra (1995, 2001) <DOI:10.1037/0022-006X.63.1.52>,
    <DOI:10.1037/10409-008>. Penalized maximum likelihood
    estimation and Markov Chain Monte Carlo estimation are
    also provided, see Luedtke, Robitzsch and Wagner (2018) 
    <DOI:10.1037/met0000155>.",2018-12-13,Alexander Robitzsch,"https://github.com/alexanderrobitzsch/STARTS,
https://sites.google.com/site/alexanderrobitzsch2/software",TRUE,https://github.com/alexanderrobitzsch/starts,5347,1,1544778239
startup,Adds support for R startup configuration via '.Renviron.d' and '.Rprofile.d' directories in addition to '.Renviron' and '.Rprofile' files.  This makes it possible to keep private / secret environment variables separate from other environment variables.  It also makes it easier to share specific startup settings by simply copying a file to a directory.,2018-08-25,Henrik Bengtsson,https://github.com/HenrikBengtsson/startup,TRUE,https://github.com/henrikbengtsson/startup,7616,68,1535235690
Stat2Data,"Datasets for the textbook Stat2: Modeling with Regression and ANOVA (second edition). 
    The package also includes data for the first edition, Stat2: Building Models for a World of Data
    and a few functions for plotting diagnostics.",2019-01-04,Ann Cannon,https://github.com/statmanrobin/Stat2Data,TRUE,https://github.com/statmanrobin/stat2data,47189,0,1550801676
statar,"A set of tools inspired by 'Stata' to explore data.frames ('summarize',
    'tabulate', 'xtile', 'pctile', 'binscatter', elapsed quarters/month, lead/lag).",2019-02-20,Matthieu Gomez,https://github.com/matthieugomez/statar,TRUE,https://github.com/matthieugomez/statar,19585,36,1550688219
statebins,"Cartogram heatmaps are an alternative to choropleth maps for USA States
    and are based on work by the Washington Post graphics department in their report
    on ""The states most threatened by trade"". ""State bins"" preserve as much of the
    geographic placement of the states as possible but has the look and feel of a
    traditional heatmap. Functions are provided that allow for use of a binned,
    discrete scale, a continuous scale or manually specified colors depending on
    what is needed for the underlying data.",2015-12-21,Bob Rudis (@hrbrmstr),http://github.com/hrbrmstr/statebins,TRUE,https://github.com/hrbrmstr/statebins,15749,82,1535230279
states,"Create panel data consisting of independent states from 1816 to
    the present. The package includes the Gleditsch & Ward (G&W) and Correlates
    of War (COW) lists of independent states, as well as helper functions for 
    working with state panel data and standardizing other data sources to 
    create country-year/month/etc. data. ",2019-01-11,Andreas Beger  (<https://orcid.org/0000-0003-1883-3169>),"https://github.com/andybega/states, https://andybeger.com/states",TRUE,https://github.com/andybega/states,4240,9,1547285733
statip,"A collection of miscellaneous statistical functions for 
    probability distributions: dbern(), pbern(), qbern(), rbern() for 
    the Bernoulli distribution, and distr2name(), name2distr() for 
    distribution names; 
    probability density estimation: densityfun(); 
    most frequent value estimation: mfv(), mfv1(); 
    calculation of the Hellinger distance: hellinger(); 
    use of classical kernels: kernelfun(), kernel_properties(); 
    univariate piecewise-constant regression: picor(). ",2018-07-31,Paul Poncet,https://github.com/paulponcet/statip,TRUE,https://github.com/paulponcet/statip,30147,0,1554450323
statnet,"Statnet is a collection of packages for statistical network analysis that are 
  designed to work together because they share common data representations and 'API' 
  design.  They provide an integrated set of tools for the representation, 
  visualization, analysis, and simulation of many different forms of network data.  
  This package is designed to make it easy to install and load the 
  key 'statnet' packages in a single step.  Learn more about 'statnet' 
  at <http://www.statnet.org>.  For an introduction to functions in this package, 
  type help(package='statnet').",2018-10-22,Martina Morris,http://statnet.org,TRUE,https://github.com/statnet/statnet,152311,8,1543432209
statnet.common,Non-statistical utilities used by the software developed by the Statnet Project. They may also be of use to others.,2019-01-08,Pavel N. Krivitsky,http://www.statnet.org,TRUE,https://github.com/statnet/statnet.common,524259,3,1549831290
stats19,"Tools to help download, process and analyse the UK road collision data collected using the
  'STATS19' form. The data are provided as 'CSV' files with detailed road safety data about the
  circumstances of car crashes and other incidents on the roads resulting in 
  casualties in Great Britain from 1979, the types
  (including make and model) of vehicles involved and the consequential casualties.  The
  statistics relate only to personal casualties on public roads that are reported
  to the police, and subsequently recorded, using the 'STATS19' accident reporting form. See
  the Department for Transportation website 
  <https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data> for more
  information on these data.",2019-04-03,Robin Lovelace  (<https://orcid.org/0000-0001-5679-6536>),https://itsleeds.github.io/stats19/,TRUE,https://github.com/ropensci/stats19,2700,12,1554279775
steemr,"Steem is a blockchain-based social media platform (see <https://en.wikipedia.org/wiki/Steemit>). The Steem social activity data are saved in the Steem blockchain, the SteemDB database, the SteemSQL database, and so on. 'steemr' is an R package that downloads the Steem data from the SteemDB and SteemSQL servers, re-organizes the data in a user-friendly way, and visualizes the data for further analysis.",2019-01-16,Peng Zhao <pzhao@pzhao.net>,https://github.com/pzhaonet/steemr,TRUE,https://github.com/pzhaonet/steemr,1814,1,1536439080
SteinerNet,"A set of functions for finding and analysing Steiner trees. It has applications in
    biological pathway network analysis. Sadeghi (2013) <doi:10.1186/1471-2105-14-144>.",2018-08-19,Afshin Sadeghi <sadeghi.afshin@gmail.com>,https://github.com/krashkov/SteinerNet,TRUE,https://github.com/krashkov/steinernet,3487,0,1545405073
stemmatology,"Explore and analyse the genealogy of textual or musical traditions, from their variants, with various stemmatological methods, mainly the disagreement-based algorithms suggested by Camps and Cafiero (2015) <doi:10.1484/M.LECTIO-EB.5.102565>.",2018-05-27,Jean-Baptiste Camps ; Florian Cafiero,https://github.com/Jean-Baptiste-Camps/stemmatology,TRUE,https://github.com/jean-baptiste-camps/stemmatology,1706,4,1527515394
STEPCAM,"Collection of model estimation, and model plotting functions 
             related to the STEPCAM family of community assembly models. 
             STEPCAM is a STEPwise Community Assembly Model that infers 
             the relative contribution of Dispersal Assembly, Habitat Filtering 
             and Limiting Similarity from a dataset consisting of the 
             combination of trait and abundance data. See also <http://onlinelibrary.wiley.com/wol1/doi/10.1890/14-0454.1/abstract> for more information.",2016-09-21,Thijs Janzen,https://github.com/thijsjanzen/STEPCAM,TRUE,https://github.com/thijsjanzen/stepcam,11328,4,1552648033
stevedore,"Work with containers over the Docker API.  Rather than
    using system calls to interact with a docker client, using the
    API directly means that we can receive richer information from
    docker.  The interface in the package is automatically generated
    using the 'OpenAPI' (a.k.a., 'swagger') specification, and all
    return values are checked in order to make them type stable.",2019-01-02,Rich FitzJohn,https://github.com/richfitz/stevedore,TRUE,https://github.com/richfitz/stevedore,1758,94,1546418009
stlcsb,"The Citizens' Service Bureau of the City of St. Louis is a clearing house for 
    non-emergency service requests. This package provides functions for downloading, 
    categorizing problem requests, cleaning and subsetting CSB data, and projecting the data
    using the x and y coordinates included with CSB data releases.",2019-02-22,Christopher Prener  (<https://orcid.org/0000-0002-4310-9888>),https://github.com/slu-openGIS/stlcsb,TRUE,https://github.com/slu-opengis/stlcsb,506,2,1550872086
stm,"The Structural Topic Model (STM) allows researchers 
  to estimate topic models with document-level covariates. 
  The package also includes tools for model selection, visualization,
  and estimation of topic-covariate regressions. Methods developed in
  Roberts et al (2014) <doi:10.1111/ajps.12103> and 
  Roberts et al (2016) <doi:10.1080/01621459.2016.1141684>.",2018-01-28,Margaret Roberts,http://structuraltopicmodel.com,TRUE,https://github.com/bstewart/stm,74198,198,1554238367
STMedianPolish,"Analyses spatio-temporal data, decomposing data in n-dimensional arrays and using the median polish technique.",2017-03-08,William Martínez,https://github.com/WilliamAMartinez/STMedianPolish,TRUE,https://github.com/williamamartinez/stmedianpolish,8592,0,1525507191
stminsights,"This app enables interactive validation, interpretation and visualization of structural topic models from the 'stm' package by Roberts and others (2014) <doi:10.1111/ajps.12103>. It also includes helper functions for model diagnostics and extracting data from effect estimates.",2018-11-24,Carsten Schwemmer  (<https://orcid.org/0000-0001-9084-946X>),https://github.com/cschwem2er/stminsights,TRUE,https://github.com/cschwem2er/stminsights,3239,40,1548105621
StMoMo,"Implementation of the family of generalised age-period-cohort
    stochastic mortality models. This family of models encompasses many models
    proposed in the actuarial and demographic literature including the 
    Lee-Carter (1992) <doi:10.2307/2290201> and
    the Cairns-Blake-Dowd (2006) <doi:10.1111/j.1539-6975.2006.00195.x> models. 
    It includes functions for fitting mortality models, analysing their 
    goodness-of-fit and performing mortality projections and simulations.",2018-04-13,Andres Villegas <andresmauriciovillegas@gmail.com>,http://github.com/amvillegas/StMoMo,TRUE,https://github.com/amvillegas/stmomo,14800,4,1524017947
StMoSim,Plots a QQ-Norm Plot with several Gaussian simulations.,2018-11-19,Matthias Salvisberg,NA,TRUE,https://github.com/matthiassalvisberg/stmosim,13544,0,1542641619
stopwords,"Provides multiple sources of stopwords, for use in text analysis and natural language processing.",2017-12-14,David Muhr,https://github.com/davnn/stopwords,TRUE,https://github.com/davnn/stopwords,256037,57,1546466538
stormwindmodel,"Allows users to input tracking data for a hurricane
    or other tropical storm, along with a data frame of grid points at which
    to model wind speeds. Functions in this package will then calculate wind
    speeds at each point based on wind model equations. This modeling framework
    is currently set up to model winds for North American locations with 
    Atlantic basin storms. This work was supported 
    in part by grants from the National Institute of Environmental Health 
    Sciences (R00ES022631), the National Science Foundation (1331399), and the 
    Department of Energy (DE-FG02-08ER64644).",2018-10-15,Brooke Anderson,https://github.com/geanders/stormwindmodel,TRUE,https://github.com/geanders/stormwindmodel,4563,5,1539564875
storr,"Creates and manages simple key-value stores.  These can
    use a variety of approaches for storing the data.  This package
    implements the base methods and support for file system, in-memory
    and DBI-based database stores.",2018-10-18,Rich FitzJohn,https://github.com/richfitz/storr,TRUE,https://github.com/richfitz/storr,35034,67,1547474136
stplanr,"Tools for transport planning with an emphasis on spatial transport
    data and non-motorized modes. Enables common transport planning tasks including:
    downloading and cleaning transport datasets; creating geographic ""desire lines""
    from origin-destination (OD) data; route assignment, locally and via
    interfaces to routing services such as <http://cyclestreets.net/>;
    calculation of route segment attributes such as bearing and aggregate flow;
    and 'travel watershed' analysis.
    See Lovelace and Ellison (2018) <doi:10.32614/RJ-2018-053>.",2019-03-22,Robin Lovelace  (<https://orcid.org/0000-0001-5679-6536>),"https://github.com/ropensci/stplanr,
https://ropensci.github.io/stplanr/",TRUE,https://github.com/ropensci/stplanr,33770,131,1553860126
strapgod,"Create data frames with virtual groups that can be used with 
    'dplyr' to efficiently compute resampled statistics, generate the data for
    hypothetical outcome plots, and fit multiple models on resampled variations
    of the original data.",2019-03-16,Davis Vaughan,https://github.com/DavisVaughan/strapgod,TRUE,https://github.com/davisvaughan/strapgod,269,38,1552746996
strataG,"A toolkit for analyzing stratified population genetic data. 
  Functions are provided for summarizing and checking loci 
  (haploid, diploid, and polyploid), single stranded DNA sequences,
  calculating most population subdivision metrics, and running external programs 
  such as structure and fastsimcoal. The package is further described in 
  Archer et al (2016) <doi:10.1111/1755-0998.12559>.",2017-04-11,Eric Archer,https://github.com/EricArcher/strataG,TRUE,https://github.com/ericarcher/stratag,16280,9,1528446721
stratEst,"Variants of the strategy frequency estimation method by Dal Bo & Frechette (2011) <doi:10.1257/aer.101.1.411>, including the adaptation to estimate choice parameters of behavior strategies by Breitmoser (2015) <doi:10.1257/aer.20130675>, and the extension in the spirit of latent-class regression by Dvorak & Fehrler (2018) <doi:10.2139/ssrn.2986445>. ",2019-01-25,Fabian Dvorak,http://github.com/fdvorak/stratEst,TRUE,https://github.com/fdvorak/stratest,1312,2,1554475666
STraTUS,"For a single, known pathogen phylogeny, provides functions for enumeration of the set of compatible epidemic transmission trees, and for uniform sampling from that set. Optional arguments allow for incomplete sampling with a known number of missing individuals, multiple sampling, and known infection time limits. Always assumed are a complete transmission bottleneck and no superinfection or reinfection. See Hall and Colijn <doi:10.1101/160812> for methodology.",2019-03-18,Matthew Hall,http://github.com/mdhall272/STraTUS/,TRUE,https://github.com/mdhall272/stratus,154,1,1552926926
stream,A framework for data stream modeling and associated data mining tasks such as clustering and classification. The development of this package was supported in part by NSF IIS-0948893 and NIH R21HG005912.,2018-06-02,Michael Hahsler,http://lyle.smu.edu/IDA/TRACDS/,TRUE,https://github.com/mhahsler/stream,25568,21,1546541350
streamMOA,"Interface for data stream clustering algorithms implemented in the MOA (Massive Online Analysis) framework (Albert Bifet, Geoff Holmes, Richard Kirkby, Bernhard Pfahringer (2010). MOA: Massive Online Analysis, Journal of Machine Learning Research 11: 1601-1604).",2019-03-20,Michael Hahsler,NA,TRUE,https://github.com/mhahsler/streammoa,14535,4,1552583138
strex,"There are some things that I wish were easier with the 'stringr' 
    or 'stringi' packages. The foremost of these is the extraction of numbers 
    from strings. 'stringr' and 'stringi' make you figure out the regular 
    expression for yourself; 'strex' takes care of this for you. There are many 
    other handy functionalities in 'strex'. Contributions to this package are 
    encouraged: it is intended as a miscellany of string manipulation functions 
    that cannot be found in 'stringi' or 'stringr'.",2018-11-30,Rory Nolan  (<https://orcid.org/0000-0002-5239-4043>),https://rorynolan.github.io/strex/,TRUE,https://github.com/rorynolan/strex,23243,19,1543589891
strider,"The strided iterator adapts multidimensional buffers to work with 
  the C++ standard library and range-based for-loops. Given a pointer or iterator
  into a multidimensional data buffer, one can generate an iterator range using
  make_strided to construct strided versions of the standard library's begin and
  end. For constructing range-based for-loops, a strided_range class is provided.
  These help authors to avoid integer-based indexing, which in some cases can impede
  algorithm performance and introduce indexing errors. This library exists
  primarily to expose the header file to other R projects.",2019-01-26,Tim Keitt,https://github.com/thk686/strider,TRUE,https://github.com/thk686/strider,2841,3,1547743038
stringdist,"Implements an approximate string matching version of R's native
    'match' function. Can calculate various string distances based on edits
    (Damerau-Levenshtein, Hamming, Levenshtein, optimal sting alignment), qgrams (q-
    gram, cosine, jaccard distance) or heuristic metrics (Jaro, Jaro-Winkler). An
    implementation of soundex is provided as well. Distances can be computed between
    character vectors while taking proper care of encoding or between integer
    vectors representing generic sequences. This package is built for speed and
    runs in parallel by using 'openMP'. An API for C or C++ is exposed as well.",2018-06-08,Mark van der Loo,https://github.com/markvanderloo/stringdist,TRUE,https://github.com/markvanderloo/stringdist,1010959,164,1553262691
stringi,"Fast, correct, consistent, portable,
    as well as convenient character string/text processing in every locale
    and any native encoding. Owing to the use of the 'ICU'
    (International Components for Unicode) library,
    the package provides 'R' users with platform-independent functions
    known to 'Java', 'Perl', 'Python', 'PHP', and 'Ruby' programmers. Available
    features include: pattern searching (e.g., with 'Java'-like regular
    expressions or the 'Unicode' collation algorithm), random string generation,
    case mapping, string transliteration, concatenation,
    Unicode normalization, date-time formatting and parsing, and many more.",2019-03-12,Marek Gagolewski  (<https://orcid.org/0000-0003-0637-6028>),"http://www.gagolewski.com/software/stringi/
http://site.icu-project.org/ http://www.unicode.org/",TRUE,https://github.com/gagolews/stringi,17047943,151,1552477422
stringr,"A consistent, simple and easy to use set of
    wrappers around the fantastic 'stringi' package. All function and
    argument names (and positions) are consistent, all functions deal with
    ""NA""'s and zero length vectors in the same way, and the output from
    one function is easy to feed into the input of another.",2019-02-10,Hadley Wickham,"http://stringr.tidyverse.org, https://github.com/tidyverse/stringr",TRUE,https://github.com/tidyverse/stringr,16809542,322,1550787280
strip,"The strip function deletes components of R model outputs that are useless for specific purposes, such as predict[ing], print[ing], summary[izing], etc.",2018-10-29,Paul Poncet,https://github.com/paulponcet/strip,TRUE,https://github.com/paulponcet/strip,5167,2,1542326343
striprtf,Extracts plain text from RTF (Rich Text Format) file.,2019-01-03,Kota Mori,https://github.com/kota7/striprtf,TRUE,https://github.com/kota7/striprtf,14710,9,1546527085
StroupGLMM,"R Codes and Datasets for Stroup, W. W. (2012). Generalized Linear Mixed Models: Modern Concepts, Methods and Applications, CRC Press.",2016-04-19,Muhammad Yaseen,https://github.com/MYaseen208/StroupGLMM,TRUE,https://github.com/myaseen208/stroupglmm,5190,3,1525707521
strvalidator,"An open source platform for validation and process control.
    Tools to analyze data from internal validation of forensic short tandem
    repeat (STR) kits are provided. The tools are developed to provide
    the necessary data to conform with guidelines for internal validation
    issued by the European Network of Forensic Science Institutes (ENFSI)
    DNA Working Group, and the Scientific Working Group on DNA Analysis Methods
    (SWGDAM). A front-end graphical user interface is provided.
    More information about each function can be found in the
    respective help documentation.",2019-03-22,Oskar Hansson,https://sites.google.com/site/forensicapps/strvalidator,TRUE,https://github.com/oskarhansson/strvalidator,16838,2,1553590884
STV,"Implementations of the Single Transferable Vote counting 
    system. By default, it uses the Cambridge method for surplus allocation
    and Droop method for quota calculation.  Fractional surplus allocation
    and the Hare quota are available as options.",2019-03-07,John Emerson,https://github.com/jayemerson/STV,TRUE,https://github.com/jayemerson/stv,2112,1,1551992095
styler,"Pretty-prints R code without changing the
    user's formatting intent.",2018-11-20,Lorenz Walthert,https://github.com/r-lib/styler,TRUE,https://github.com/r-lib/styler,99717,268,1552645746
stylest,Estimates distinctiveness in speakers' (authors') style. Fits models that can be used for predicting speakers of new texts. Methods developed in Spirling et al (2018) <doi:10.2139/ssrn.3235506> (working paper).,2018-09-16,Leslie Huang,https://github.com/leslie-huang/stylest,TRUE,https://github.com/leslie-huang/stylest,1423,24,1537193760
stylo,"Supervised and unsupervised multivariate methods, supplemented by GUI and some visualizations, to perform various analyses in the field of computational stylistics, authorship attribution, etc. For further reference, see Eder et al. (2016), <https://journal.r-project.org/archive/2016/RJ-2016-007/index.html> You are also encouraged to visit the Computational Stylistics Group's website <https://computationalstylistics.github.io/>, where a reasonable amount of information about the package and related projects are provided.",2019-01-21,Maciej Eder,https://github.com/computationalstylistics/stylo,TRUE,https://github.com/computationalstylistics/stylo,36376,60,1550067791
subplex,"The subplex algorithm for unconstrained optimization, developed by Tom Rowan <http://www.netlib.org/opt/subplex.tgz>.",2018-04-05,Aaron A. King,https://github.com/kingaa/subplex/,TRUE,https://github.com/kingaa/subplex,139006,1,1545226335
subprocess,"Create and handle multiple sub-processes in R, exchange
  data over standard input and output streams, control their life cycle.",2018-08-13,Lukasz Bartnik,https://github.com/lbartnik/subprocess,TRUE,https://github.com/lbartnik/subprocess,89939,41,1545099661
sugrrants,"Provides 'ggplot2' graphics for analysing time
    series data. It aims to fit into the 'tidyverse' and grammar of
    graphics framework for handling temporal data.",2019-04-06,Earo Wang  (<https://orcid.org/0000-0001-6448-5260>),https://pkg.earo.me/sugrrants,TRUE,https://github.com/earowang/sugrrants,11037,36,1554526130
summariser,"Functions to speed up the exploratory analysis of simple
    datasets using 'dplyr' and 'ggplot2'. Functions are provided to do the 
    common tasks of calculating confidence intervals and visualising the 
    results. ",2017-03-23,Conor Neilson,https://github.com/condwanaland/summariser,TRUE,https://github.com/condwanaland/summariser,4969,0,1546555173
summarytools,"Data frame summaries, cross-tabulations,
  weight-enabled frequency tables and common univariate
  statistics in concise tables available in a variety of
  formats (plain ASCII, Markdown and HTML). A good 
  point-of-entry for exploring data, both for experienced
  and new R users.",2019-02-22,Dominic Comtois,https://github.com/dcomtois/summarytools,TRUE,https://github.com/dcomtois/summarytools,60649,214,1553759599
SUMMER,"Provides methods for estimating, projecting, and plotting spatio-temporal 
  under-five mortality rates, described in Mercer et al. (2015) <doi:10.1214/15-AOAS872>
  and Li et al. (2019) <doi:10.1371/journal.pone.0210645>.",2019-04-02,Bryan D Martin,https://github.com/bryandmartin/SUMMER,TRUE,https://github.com/bryandmartin/summer,3534,3,1554159803
sunburstR,"Make interactive 'd3.js' sequence sunburst diagrams in R with the
    convenience and infrastructure of an 'htmlwidget'.",2019-03-04,Mike Bostock,https://github.com/timelyportfolio/sunburstR,TRUE,https://github.com/timelyportfolio/sunburstr,108202,124,1551661058
suncalc,"Get sun position, sunlight phases (times for sunrise, sunset, dusk, etc.),
        moon position and lunar phase for the given location and time. Most calculations are based on the 
        formulas given in Astronomy Answers articles about position of the sun and the planets : 
        <https://www.aa.quae.nl/en/reken/zonpositie.html>.",2019-04-03,Benoit Thieurmel  (R interface),https://github.com/datastorm-open/suncalc,TRUE,https://github.com/datastorm-open/suncalc,228721,10,1554276086
sundialr,"Provides a way to call the functions in 'SUNDIALS' C ODE solving library (<https://computation.llnl.gov/projects/sundials>). Currently the serial version of ODE solver, 'CVODE' from the library can be accessed. The package requires ODE to be written as an 'R' or 'Rcpp' function and does not require the 'SUNDIALS' library to be installed on the local machine.",2019-01-12,Satyaprakash Nayak,https://github.com/sn248/sundialr,TRUE,https://github.com/sn248/sundialr,1816,2,1547344944
supc,"Implements the self-updating process clustering algorithms proposed
    in Shiu and Chen (2016) <doi:10.1080/00949655.2015.1049605>.",2018-08-26,Wush Wu,https://github.com/wush978/supc,TRUE,https://github.com/wush978/supc,4279,4,1535304993
SuperExactTest,"Identification of sets of objects with shared features is a common operation in all disciplines. Analysis of intersections among multiple sets is fundamental for in-depth understanding of their complex relationships. This package implements a theoretical framework for efficient computation of statistical distributions of multi-set intersections based upon combinatorial theory, and provides multiple scalable techniques for visualizing the intersection statistics. The statistical algorithm behind this package was published in Wang et al. (2015) <doi:10.1038/srep16923>.",2019-02-26,Minghui Wang,https://github.com/mw201608/SuperExactTest/,TRUE,https://github.com/mw201608/superexacttest,8977,0,1550272988
SuperLearner,"Implements the super learner prediction method and contains a
    library of prediction algorithms to be used in the super learner.",2018-08-11,Eric Polley,https://github.com/ecpolley/SuperLearner,TRUE,https://github.com/ecpolley/superlearner,43135,155,1542388238
superml,"The idea is to provide a standard interface 
             to users who use both R and Python for building machine learning models. 
             This package provides a scikit-learn's fit, predict interface to 
             train machine learning models in R.    ",2019-03-16,Manish Saraswat,https://github.com/saraswatmks/superml,TRUE,https://github.com/saraswatmks/superml,954,13,1552710526
supernova,"Produces ANOVA tables in the format used by Judd, McClelland, and Ryan (2017, ISBN:978-1138819832) in their introductory textbook, Data Analysis. This includes proportional reduction in error and formatting to improve ease the transition between the book and R.",2019-01-29,Jim Stigler,https://github.com/UCLATALL/supernova,TRUE,https://github.com/uclatall/supernova,2699,2,1548781155
sure,"An implementation of the surrogate approach to residuals and 
  diagnostics for ordinal and general regression models; for details, see Liu 
  and Zhang (2017) <doi:10.1080/01621459.2017.1292915>. These residuals can be 
  used to construct standard residual plots for model diagnostics (e.g., 
  residual-vs-fitted value plots, residual-vs-covariate plots, Q-Q plots, etc.). 
  The package also provides an 'autoplot' function for producing standard 
  diagnostic plots using 'ggplot2' graphics. The package currently supports 
  cumulative link models from packages 'MASS', 'ordinal', 'rms', and 'VGAM'. 
  Support for binary regression models using the standard 'glm' function is also 
  available.",2017-09-19,Brandon Greenwell,https://github.com/AFIT-R/sure,TRUE,https://github.com/afit-r/sure,3177,1,1536708226
survBootOutliers,"Three new methods to perform outlier detection in a survival context. In total there are six methods provided, the first three methods are traditional residual-based outlier detection methods, the second three are the concordance-based. Package developed during the work on the two following publications: Pinto J., Carvalho A. and Vinga S. (2015) <doi:10.5220/0005225300750082>; Pinto J.D., Carvalho A.M., Vinga S. (2015) <doi:10.1007/978-3-319-27926-8_22>.",2018-05-28,Joao Pinto <joao.pinto@tecnico.ulisboa.pt>,https://github.com/jonydog/survBootOutliers,TRUE,https://github.com/jonydog/survbootoutliers,1748,0,1527457299
surveydata,"Data obtained from surveys contains information not only about the
    survey responses, but also the survey metadata, e.g. the original survey
    questions and the answer options. The 'surveydata' package makes it easy to
    keep track of this metadata, and to easily extract columns with
    specific questions.",2019-01-23,Andrie de Vries,http://andrie.github.io/surveydata/index.html,TRUE,https://github.com/andrie/surveydata,14176,11,1549645864
surveysd,Calculate point estimates and their standard errors in complex household surveys using bootstrap replicates. Bootstrapping considers survey design with a rotating panel. A comprehensive description of the methodology can be found under <https://statistikat.github.io/surveysd/articles/methodology.html>.,2019-01-25,Johannes Gussenbauer,https://github.com/statistikat/surveysd,TRUE,https://github.com/statistikat/surveysd,519,2,1548938311
survHE,"Contains a suite of functions for survival analysis in health economics. These can be used to run survival models under a frequentist (based on maximum likelihood) or a Bayesian approach (both based on Integrated Nested Laplace Approximation or Hamiltonian Monte Carlo). The user can specify a set of parametric models using a common notation and select the preferred mode of inference. The results can also be post-processed to produce probabilistic sensitivity analysis and can be used to export the output to an Excel file (e.g. for a Markov model, as often done by modellers and practitioners).",2018-11-09,Gianluca Baio,"https://github.com/giabaio/survHE,
http://www.statistica.it/gianluca",TRUE,https://github.com/giabaio/survhe,4771,11,1541672559
survival,"Contains the core survival analysis routines, including
	     definition of Surv objects, 
	     Kaplan-Meier and Aalen-Johansen (multi-state) curves, Cox models,
	     and parametric accelerated failure time models.",2019-04-01,Terry M Therneau,https://github.com/therneau/survival,TRUE,https://github.com/therneau/survival,3820126,76,1554129665
survminer,"Contains the function 'ggsurvplot()' for drawing easily beautiful
    and 'ready-to-publish' survival curves with the 'number at risk' table
    and 'censoring count plot'. Other functions are also available to plot 
    adjusted curves for `Cox` model and to visually examine 'Cox' model assumptions.",2018-08-04,Alboukadel Kassambara,http://www.sthda.com/english/rpkgs/survminer/,TRUE,https://github.com/kassambara/survminer,200454,179,1548888440
survtmle,"Targeted estimates of marginal cumulative incidence in survival
    settings with and without competing risks, including estimators that respect
    bounds (Benkeser, Carone, and Gilbert. Statistics in Medicine, 2017.
    <doi:10.1002/sim.7337>).",2018-04-13,David Benkeser,https://github.com/benkeser/survtmle,TRUE,https://github.com/benkeser/survtmle,3238,11,1543369745
survutils,"Functional programming principles to iteratively run Cox 
    regression and plot its results. The results are reported in tidy data 
    frames. Additional utility functions are available for working with 
    other aspects of survival analysis such as survival curves, C-statistics, 
    etc.",2018-07-22,Fong Chun Chan,https://github.com/tinyheero/survutils,TRUE,https://github.com/tinyheero/survutils,4035,6,1532185542
survxai,"Survival models may have very different structures. This package contains functions 
  for creating a unified representation of a survival models, which can be further processed by various 
  survival explainers. Tools implemented in 'survxai' help to understand how input variables are used in 
  the model and what impact do they have on the final model prediction. Currently, four explanation methods are implemented. 
  We can divide them into two groups: local and global.",2018-08-24,Aleksandra Grudziaz,https://mi2datalab.github.io/survxai/,TRUE,https://github.com/mi2datalab/survxai,1512,3,1554195878
sValues,"Implements the s-values proposed by Ed. Leamer.
    It provides a context-minimal approach for sensitivity analysis using extreme
    bounds to assess the sturdiness of regression coefficients.",2018-07-15,Carlos Cinelli,NA,TRUE,https://github.com/carloscinelli/svalues,7009,1,1531451013
svd,"R bindings to SVD and eigensolvers (PROPACK, nuTRLan).",2019-04-05,Anton Korobeynikov,http://github.com/asl/svd,TRUE,https://github.com/asl/svd,96198,19,1554409080
svDialogs,"Rapidly construct standard dialog boxes for your GUI, including 
  message boxes, input boxes, list, file or directory selection, ... In case R
  cannot display GUI dialog boxes, a simpler command line version of these
  interactive elements is also provided as fallback solution.",2018-04-26,Philippe Grosjean,"https://github.com/SciViews/svDialogs,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/svdialogs,44673,0,1533039866
svglite,"A graphics device for R that produces 'Scalable Vector Graphics'.
  'svglite' is a fork of the older 'RSvgDevice' package.",2017-09-11,Lionel Henry,https://github.com/r-lib/svglite,TRUE,https://github.com/r-lib/svglite,560243,127,1524146186
svGUI,"The SciViews svGUI package eases the management of Graphical User
  Interfaces (GUI) in R. It is independent from any particular GUI widgets (Tk,
  Gtk2, native, ...). It centralizes info about GUI elements currently used,
  and it dispatches GUI calls to the particular toolkits in use in function of
  the context (is R run at the terminal, within a Tk application, a HTML page?).",2018-04-23,Philippe Grosjean,"https://github.com/SciViews/svGUI,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/svgui,48856,0,1524745079
svMisc,"Miscellaneous functions for SciViews or general use: manage a
  temporary environment attached to the search path for temporary variables you
  do not want to save() or load(), test if Aqua, Mac, Win, ... Show progress
  bar, etc.",2018-06-30,Philippe Grosjean,"https://github.com/SciViews/svMisc,
http://www.sciviews.org/SciViews-R",TRUE,https://github.com/sciviews/svmisc,39984,0,1529504574
swagger,"A collection of 'HTML', 'JavaScript', and 'CSS' assets that
  dynamically generate beautiful documentation from a 'Swagger' compliant API:
  <https://swagger.io/specification/>.",2018-03-23,Javier Luraschi,https://github.com/rstudio/swagger,TRUE,https://github.com/rstudio/swagger,12874,26,1546631347
swephR,"The Swiss Ephemeris is a high precision ephemeris based upon the
    DE431 ephemerides from NASA's JPL. It covers the time range 13201 BC to
    AD 17191. This package uses the semi-analytic theory by Steve Moshier.
    For faster and more accurate calculations, the compressed Swiss Ephemeris
    data is available in the 'swephRdata' package. To access this data package,
    run 'install.packages(""swephRdata"", repos = ""https://rstub.github.io/drat/"",
    type = ""source"")'. The size of the 'swephRdata' package is approximately
    115 MB. The user can also use the original JPL DE431 data.",2019-02-18,Ralf Stubner,"https://github.com/rstub/swephR/, http://www.astro.com/swisseph/",TRUE,https://github.com/rstub/swephr,387,1,1554029040
swfscMisc,"Collection of conversion, analytical, geodesic, mapping, and
    plotting functions. Used to support packages and code written by
    researchers at the Southwest Fisheries Science Center of the National
    Oceanic and Atmospheric Administration.",2016-08-23,Eric Archer,https://github.com/EricArcher/swfscMisc,TRUE,https://github.com/ericarcher/swfscmisc,19164,0,1527624089
switchr,"Provides an abstraction for managing, installing,
    and switching between sets of installed R packages. This allows users to
    maintain multiple package libraries simultaneously, e.g. to maintain
    strict, package-version-specific reproducibility of many analyses, or
    work within a development/production release paradigm. Introduces a
    generalized package installation process which supports multiple repository
    and non-repository sources and tracks package provenance.",2018-11-15,Gabriel Becker,https://github.com/gmbecker/switchr,TRUE,https://github.com/gmbecker/switchr,18076,41,1542244001
switchrGist,"Provides a simple plugin to the switchr
	     framework which allows users to publish package and
	     session manifests as gists.",2018-11-07,Gabriel Becker,https://github.com/gmbecker/switchrGist,TRUE,https://github.com/gmbecker/switchrgist,5878,3,1541546965
